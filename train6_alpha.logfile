  0%|          | 0/1001 [00:00<?, ?it/s]  0%|          | 4/1001 [00:00<00:25, 39.24it/s]  1%|          | 8/1001 [00:00<00:25, 39.31it/s]  1%|          | 12/1001 [00:00<00:25, 39.49it/s]  2%|▏         | 16/1001 [00:00<00:24, 39.47it/s]  2%|▏         | 20/1001 [00:00<00:24, 39.40it/s]  2%|▏         | 24/1001 [00:00<00:24, 39.46it/s]  3%|▎         | 28/1001 [00:00<00:24, 39.46it/s]  3%|▎         | 32/1001 [00:00<00:24, 39.53it/s]  4%|▎         | 36/1001 [00:00<00:24, 39.48it/s]  4%|▍         | 40/1001 [00:01<00:24, 39.55it/s]  4%|▍         | 44/1001 [00:01<00:24, 39.20it/s]  5%|▍         | 48/1001 [00:01<00:24, 38.73it/s]  5%|▌         | 52/1001 [00:01<00:24, 38.98it/s]  6%|▌         | 56/1001 [00:01<00:24, 39.17it/s]  6%|▌         | 60/1001 [00:01<00:23, 39.37it/s]  6%|▋         | 64/1001 [00:01<00:23, 39.49it/s]  7%|▋         | 69/1001 [00:01<00:23, 39.77it/s]  7%|▋         | 73/1001 [00:01<00:23, 39.76it/s]  8%|▊         | 77/1001 [00:01<00:23, 39.68it/s]  8%|▊         | 82/1001 [00:02<00:22, 40.02it/s]  9%|▊         | 86/1001 [00:02<00:22, 39.84it/s]  9%|▉         | 90/1001 [00:02<00:22, 39.76it/s]  9%|▉         | 94/1001 [00:02<00:22, 39.62it/s] 10%|▉         | 98/1001 [00:02<00:22, 39.72it/s] 10%|█         | 102/1001 [00:02<00:22, 39.70it/s] 11%|█         | 107/1001 [00:02<00:22, 39.83it/s] 11%|█         | 112/1001 [00:02<00:22, 39.92it/s] 12%|█▏        | 116/1001 [00:02<00:22, 39.92it/s] 12%|█▏        | 120/1001 [00:03<00:22, 39.90it/s] 12%|█▏        | 125/1001 [00:03<00:21, 40.03it/s] 13%|█▎        | 130/1001 [00:03<00:21, 39.98it/s] 13%|█▎        | 135/1001 [00:03<00:21, 40.91it/s] 14%|█▍        | 140/1001 [00:03<00:20, 41.11it/s] 14%|█▍        | 145/1001 [00:03<00:20, 41.82it/s] 15%|█▍        | 150/1001 [00:03<00:20, 42.39it/s] 15%|█▌        | 155/1001 [00:03<00:19, 42.33it/s] 16%|█▌        | 160/1001 [00:03<00:20, 41.51it/s] 16%|█▋        | 165/1001 [00:04<00:20, 41.14it/s] 17%|█▋        | 170/1001 [00:04<00:20, 41.19it/s] 17%|█▋        | 175/1001 [00:04<00:20, 41.18it/s] 18%|█▊        | 180/1001 [00:04<00:19, 41.24it/s] 18%|█▊        | 185/1001 [00:04<00:19, 41.26it/s] 19%|█▉        | 190/1001 [00:04<00:19, 41.47it/s] 19%|█▉        | 195/1001 [00:04<00:19, 41.80it/s] 20%|█▉        | 200/1001 [00:04<00:18, 42.23it/s] 20%|██        | 205/1001 [00:05<00:18, 42.33it/s] 21%|██        | 210/1001 [00:05<00:18, 42.34it/s] 21%|██▏       | 215/1001 [00:05<00:18, 42.34it/s] 22%|██▏       | 220/1001 [00:05<00:18, 42.50it/s] 22%|██▏       | 225/1001 [00:05<00:18, 42.63it/s] 23%|██▎       | 230/1001 [00:05<00:18, 42.54it/s] 23%|██▎       | 235/1001 [00:05<00:17, 42.90it/s] 24%|██▍       | 240/1001 [00:05<00:17, 42.98it/s] 24%|██▍       | 245/1001 [00:06<00:17, 42.89it/s] 25%|██▍       | 250/1001 [00:06<00:17, 42.94it/s] 25%|██▌       | 255/1001 [00:06<00:17, 42.91it/s] 26%|██▌       | 260/1001 [00:06<00:17, 42.32it/s] 26%|██▋       | 265/1001 [00:06<00:17, 42.54it/s] 27%|██▋       | 270/1001 [00:06<00:17, 42.29it/s] 27%|██▋       | 275/1001 [00:06<00:17, 42.44it/s] 28%|██▊       | 280/1001 [00:06<00:17, 42.03it/s] 28%|██▊       | 285/1001 [00:06<00:17, 42.00it/s] 29%|██▉       | 290/1001 [00:07<00:17, 41.66it/s] 29%|██▉       | 295/1001 [00:07<00:16, 41.79it/s] 30%|██▉       | 300/1001 [00:07<00:16, 41.90it/s] 30%|███       | 305/1001 [00:07<00:16, 41.88it/s] 31%|███       | 310/1001 [00:07<00:16, 41.78it/s] 31%|███▏      | 315/1001 [00:07<00:16, 41.61it/s] 32%|███▏      | 320/1001 [00:07<00:16, 41.82it/s] 32%|███▏      | 325/1001 [00:07<00:16, 41.58it/s] 33%|███▎      | 330/1001 [00:08<00:16, 41.12it/s] 33%|███▎      | 335/1001 [00:08<00:16, 41.41it/s] 34%|███▍      | 340/1001 [00:08<00:15, 41.36it/s] 34%|███▍      | 345/1001 [00:08<00:15, 41.02it/s] 35%|███▍      | 350/1001 [00:08<00:15, 41.48it/s] 35%|███▌      | 355/1001 [00:08<00:15, 41.88it/s] 36%|███▌      | 360/1001 [00:08<00:15, 42.44it/s] 36%|███▋      | 365/1001 [00:08<00:15, 42.03it/s] 37%|███▋      | 370/1001 [00:08<00:15, 42.02it/s] 37%|███▋      | 375/1001 [00:09<00:15, 41.56it/s] 38%|███▊      | 380/1001 [00:09<00:14, 41.87it/s] 38%|███▊      | 385/1001 [00:09<00:14, 42.30it/s] 39%|███▉      | 390/1001 [00:09<00:14, 41.87it/s] 39%|███▉      | 395/1001 [00:09<00:14, 41.90it/s] 40%|███▉      | 400/1001 [00:09<00:14, 41.45it/s] 40%|████      | 405/1001 [00:09<00:14, 41.59it/s] 41%|████      | 410/1001 [00:09<00:14, 42.15it/s] 41%|████▏     | 415/1001 [00:10<00:14, 41.64it/s] 42%|████▏     | 420/1001 [00:10<00:13, 42.04it/s] 42%|████▏     | 425/1001 [00:10<00:13, 41.62it/s] 43%|████▎     | 430/1001 [00:10<00:13, 41.65it/s] 43%|████▎     | 435/1001 [00:10<00:13, 41.72it/s] 44%|████▍     | 440/1001 [00:10<00:13, 41.65it/s] 44%|████▍     | 445/1001 [00:10<00:13, 42.31it/s] 45%|████▍     | 450/1001 [00:10<00:13, 42.07it/s] 45%|████▌     | 455/1001 [00:11<00:12, 42.13it/s] 46%|████▌     | 460/1001 [00:11<00:12, 42.38it/s] 46%|████▋     | 465/1001 [00:11<00:12, 42.01it/s] 47%|████▋     | 470/1001 [00:11<00:12, 42.10it/s] 47%|████▋     | 475/1001 [00:11<00:12, 40.89it/s] 48%|████▊     | 480/1001 [00:11<00:12, 40.97it/s] 48%|████▊     | 485/1001 [00:11<00:12, 41.23it/s] 49%|████▉     | 490/1001 [00:11<00:12, 41.95it/s] 49%|████▉     | 495/1001 [00:11<00:11, 42.24it/s] 50%|████▉     | 500/1001 [00:12<00:11, 42.16it/s] 50%|█████     | 505/1001 [00:12<00:11, 41.78it/s] 51%|█████     | 510/1001 [00:12<00:11, 42.24it/s] 51%|█████▏    | 515/1001 [00:12<00:11, 41.48it/s] 52%|█████▏    | 520/1001 [00:12<00:11, 41.80it/s] 52%|█████▏    | 525/1001 [00:12<00:11, 41.30it/s] 53%|█████▎    | 530/1001 [00:12<00:11, 41.91it/s] 53%|█████▎    | 535/1001 [00:12<00:11, 41.77it/s] 54%|█████▍    | 540/1001 [00:13<00:11, 41.39it/s] 54%|█████▍    | 545/1001 [00:13<00:10, 41.64it/s] 55%|█████▍    | 550/1001 [00:13<00:10, 41.25it/s] 55%|█████▌    | 555/1001 [00:13<00:10, 41.61it/s] 56%|█████▌    | 560/1001 [00:13<00:10, 41.57it/s] 56%|█████▋    | 565/1001 [00:13<00:10, 41.37it/s] 57%|█████▋    | 570/1001 [00:13<00:10, 41.56it/s] 57%|█████▋    | 575/1001 [00:13<00:10, 41.23it/s] 58%|█████▊    | 580/1001 [00:14<00:10, 41.68it/s] 58%|█████▊    | 585/1001 [00:14<00:10, 41.29it/s] 59%|█████▉    | 590/1001 [00:14<00:09, 41.50it/s] 59%|█████▉    | 595/1001 [00:14<00:09, 41.43it/s] 60%|█████▉    | 600/1001 [00:14<00:09, 41.79it/s] 60%|██████    | 605/1001 [00:14<00:09, 42.37it/s] 61%|██████    | 610/1001 [00:14<00:09, 41.79it/s] 61%|██████▏   | 615/1001 [00:14<00:09, 42.00it/s] 62%|██████▏   | 620/1001 [00:14<00:09, 41.61it/s] 62%|██████▏   | 625/1001 [00:15<00:08, 42.08it/s] 63%|██████▎   | 630/1001 [00:15<00:08, 41.72it/s] 63%|██████▎   | 635/1001 [00:15<00:08, 41.46it/s] 64%|██████▍   | 640/1001 [00:15<00:08, 41.64it/s] 64%|██████▍   | 645/1001 [00:15<00:08, 41.36it/s] 65%|██████▍   | 650/1001 [00:15<00:08, 41.43it/s] 65%|██████▌   | 655/1001 [00:15<00:08, 41.49it/s] 66%|██████▌   | 660/1001 [00:15<00:08, 41.25it/s] 66%|██████▋   | 665/1001 [00:16<00:08, 41.71it/s] 67%|██████▋   | 670/1001 [00:16<00:07, 42.00it/s] 67%|██████▋   | 675/1001 [00:16<00:07, 41.59it/s] 68%|██████▊   | 680/1001 [00:16<00:07, 41.61it/s] 68%|██████▊   | 685/1001 [00:16<00:07, 41.89it/s] 69%|██████▉   | 690/1001 [00:16<00:07, 42.22it/s] 69%|██████▉   | 695/1001 [00:16<00:07, 42.11it/s] 70%|██████▉   | 700/1001 [00:16<00:07, 42.06it/s] 70%|███████   | 705/1001 [00:17<00:07, 41.97it/s] 71%|███████   | 710/1001 [00:17<00:06, 41.96it/s] 71%|███████▏  | 715/1001 [00:17<00:06, 41.99it/s] 72%|███████▏  | 720/1001 [00:17<00:06, 41.71it/s] 72%|███████▏  | 725/1001 [00:17<00:06, 41.77it/s] 73%|███████▎  | 730/1001 [00:17<00:06, 41.51it/s] 73%|███████▎  | 735/1001 [00:17<00:06, 41.66it/s] 74%|███████▍  | 740/1001 [00:17<00:06, 41.51it/s] 74%|███████▍  | 745/1001 [00:17<00:06, 41.59it/s] 75%|███████▍  | 750/1001 [00:18<00:06, 41.70it/s] 75%|███████▌  | 755/1001 [00:18<00:05, 41.56it/s] 76%|███████▌  | 760/1001 [00:18<00:05, 41.41it/s] 76%|███████▋  | 765/1001 [00:18<00:05, 41.39it/s] 77%|███████▋  | 770/1001 [00:18<00:05, 41.34it/s] 77%|███████▋  | 775/1001 [00:18<00:05, 42.00it/s] 78%|███████▊  | 780/1001 [00:18<00:05, 42.25it/s] 78%|███████▊  | 785/1001 [00:18<00:05, 42.23it/s] 79%|███████▉  | 790/1001 [00:19<00:04, 42.88it/s] 79%|███████▉  | 795/1001 [00:19<00:04, 43.35it/s] 80%|███████▉  | 800/1001 [00:19<00:04, 42.54it/s] 80%|████████  | 805/1001 [00:19<00:04, 42.61it/s] 81%|████████  | 810/1001 [00:19<00:04, 42.02it/s] 81%|████████▏ | 815/1001 [00:19<00:04, 41.85it/s] 82%|████████▏ | 820/1001 [00:19<00:04, 41.78it/s] 82%|████████▏ | 825/1001 [00:19<00:04, 41.83it/s] 83%|████████▎ | 830/1001 [00:19<00:04, 42.38it/s] 83%|████████▎ | 835/1001 [00:20<00:03, 41.87it/s] 84%|████████▍ | 840/1001 [00:20<00:03, 41.67it/s] 84%|████████▍ | 845/1001 [00:20<00:03, 41.35it/s] 85%|████████▍ | 850/1001 [00:20<00:03, 41.54it/s] 85%|████████▌ | 855/1001 [00:20<00:03, 41.61it/s] 86%|████████▌ | 860/1001 [00:20<00:03, 41.25it/s] 86%|████████▋ | 865/1001 [00:20<00:03, 41.48it/s] 87%|████████▋ | 870/1001 [00:20<00:03, 41.54it/s] 87%|████████▋ | 875/1001 [00:21<00:03, 40.99it/s] 88%|████████▊ | 880/1001 [00:21<00:02, 41.03it/s] 88%|████████▊ | 885/1001 [00:21<00:02, 41.35it/s] 89%|████████▉ | 890/1001 [00:21<00:02, 41.73it/s] 89%|████████▉ | 895/1001 [00:21<00:02, 41.97it/s] 90%|████████▉ | 900/1001 [00:21<00:02, 41.43it/s] 90%|█████████ | 905/1001 [00:21<00:02, 41.64it/s] 91%|█████████ | 910/1001 [00:21<00:02, 41.47it/s] 91%|█████████▏| 915/1001 [00:22<00:02, 42.12it/s] 92%|█████████▏| 920/1001 [00:22<00:01, 42.26it/s] 92%|█████████▏| 925/1001 [00:22<00:01, 42.39it/s] 93%|█████████▎| 930/1001 [00:22<00:01, 42.35it/s] 93%|█████████▎| 935/1001 [00:22<00:01, 42.27it/s] 94%|█████████▍| 940/1001 [00:22<00:01, 42.54it/s] 94%|█████████▍| 945/1001 [00:22<00:01, 42.46it/s] 95%|█████████▍| 950/1001 [00:22<00:01, 43.15it/s] 95%|█████████▌| 955/1001 [00:22<00:01, 42.90it/s] 96%|█████████▌| 960/1001 [00:23<00:00, 42.82it/s] 96%|█████████▋| 965/1001 [00:23<00:00, 42.73it/s] 97%|█████████▋| 970/1001 [00:23<00:00, 42.09it/s] 97%|█████████▋| 975/1001 [00:23<00:00, 42.38it/s] 98%|█████████▊| 980/1001 [00:23<00:00, 42.07it/s] 98%|█████████▊| 985/1001 [00:23<00:00, 42.52it/s] 99%|█████████▉| 990/1001 [00:23<00:00, 42.19it/s] 99%|█████████▉| 995/1001 [00:23<00:00, 41.94it/s]100%|█████████▉| 1000/1001 [00:24<00:00, 42.28it/s]100%|██████████| 1001/1001 [00:24<00:00, 41.59it/s]
  0%|          | 0/90000 [00:00<?, ?it/s]  0%|          | 1/90000 [00:12<310:51:59, 12.43s/it]  0%|          | 23/90000 [00:12<9:41:57,  2.58it/s]   0%|          | 48/90000 [00:12<3:49:58,  6.52it/s]  0%|          | 71/90000 [00:12<2:10:29, 11.49it/s]  0%|          | 95/90000 [00:12<1:20:59, 18.50it/s]  0%|          | 118/90000 [00:12<54:43, 27.37it/s]   0%|          | 142/90000 [00:13<38:04, 39.33it/s]  0%|          | 166/90000 [00:13<27:38, 54.18it/s]  0%|          | 190/90000 [00:13<20:51, 71.75it/s]  0%|          | 213/90000 [00:13<16:29, 90.73it/s]  0%|          | 236/90000 [00:13<13:29, 110.94it/s]  0%|          | 259/90000 [00:13<11:23, 131.32it/s]  0%|          | 282/90000 [00:13<09:58, 149.78it/s]  0%|          | 306/90000 [00:13<08:51, 168.77it/s]  0%|          | 330/90000 [00:13<08:04, 185.18it/s]  0%|          | 354/90000 [00:13<07:33, 197.75it/s]  0%|          | 379/90000 [00:14<07:07, 209.86it/s]  0%|          | 403/90000 [00:14<07:03, 211.43it/s]  0%|          | 426/90000 [00:14<07:04, 211.16it/s]  0%|          | 449/90000 [00:14<06:59, 213.72it/s]  1%|          | 473/90000 [00:14<06:46, 220.41it/s]  1%|          | 496/90000 [00:14<06:45, 220.73it/s]  1%|          | 519/90000 [00:14<06:40, 223.38it/s]  1%|          | 543/90000 [00:14<06:35, 226.03it/s]  1%|          | 568/90000 [00:14<06:24, 232.39it/s]  1%|          | 592/90000 [00:15<06:22, 233.72it/s]  1%|          | 616/90000 [00:15<06:24, 232.56it/s]  1%|          | 640/90000 [00:15<06:29, 229.35it/s]  1%|          | 664/90000 [00:15<06:41, 222.34it/s]  1%|          | 687/90000 [00:15<06:42, 221.98it/s]  1%|          | 711/90000 [00:15<06:37, 224.40it/s]  1%|          | 736/90000 [00:15<06:29, 229.12it/s]  1%|          | 761/90000 [00:15<06:21, 234.16it/s]  1%|          | 785/90000 [00:15<06:28, 229.59it/s]  1%|          | 809/90000 [00:15<06:32, 227.26it/s]  1%|          | 832/90000 [00:16<06:31, 227.91it/s]  1%|          | 855/90000 [00:16<06:31, 227.87it/s]  1%|          | 880/90000 [00:16<06:24, 231.70it/s]  1%|          | 904/90000 [00:16<06:24, 231.52it/s]  1%|          | 929/90000 [00:16<06:19, 234.62it/s]  1%|          | 953/90000 [00:16<06:24, 231.56it/s]  1%|          | 977/90000 [00:16<06:26, 230.63it/s]  1%|          | 1001/90000 [00:16<06:25, 230.80it/s]  1%|          | 1025/90000 [00:16<06:26, 230.10it/s]  1%|          | 1049/90000 [00:17<06:32, 226.68it/s]  1%|          | 1072/90000 [00:17<06:35, 224.92it/s]  1%|          | 1096/90000 [00:17<06:31, 227.25it/s]  1%|          | 1119/90000 [00:17<06:30, 227.75it/s]  1%|▏         | 1142/90000 [00:17<06:37, 223.41it/s]  1%|▏         | 1165/90000 [00:17<06:37, 223.42it/s]  1%|▏         | 1188/90000 [00:17<06:39, 222.09it/s]  1%|▏         | 1211/90000 [00:17<06:47, 218.14it/s]  1%|▏         | 1234/90000 [00:17<06:46, 218.42it/s]  1%|▏         | 1258/90000 [00:17<06:35, 224.37it/s]  1%|▏         | 1282/90000 [00:18<06:27, 228.80it/s]  1%|▏         | 1305/90000 [00:18<06:27, 228.98it/s]  1%|▏         | 1329/90000 [00:18<06:25, 229.95it/s]  2%|▏         | 1353/90000 [00:18<06:21, 232.53it/s]  2%|▏         | 1377/90000 [00:18<06:18, 234.26it/s]  2%|▏         | 1401/90000 [00:18<06:27, 228.63it/s]  2%|▏         | 1425/90000 [00:18<06:22, 231.39it/s]  2%|▏         | 1449/90000 [00:18<06:22, 231.37it/s]  2%|▏         | 1474/90000 [00:18<06:17, 234.43it/s]  2%|▏         | 1499/90000 [00:18<06:13, 236.71it/s]  2%|▏         | 1523/90000 [00:19<06:13, 236.90it/s]  2%|▏         | 1547/90000 [00:19<06:13, 236.82it/s]  2%|▏         | 1571/90000 [00:19<06:20, 232.61it/s]  2%|▏         | 1595/90000 [00:19<06:32, 225.34it/s]  2%|▏         | 1618/90000 [00:19<06:37, 222.36it/s]  2%|▏         | 1643/90000 [00:19<06:28, 227.56it/s]  2%|▏         | 1667/90000 [00:19<06:26, 228.71it/s]  2%|▏         | 1690/90000 [00:19<06:26, 228.39it/s]  2%|▏         | 1714/90000 [00:19<06:25, 229.16it/s]  2%|▏         | 1739/90000 [00:20<06:19, 232.27it/s]  2%|▏         | 1763/90000 [00:20<06:27, 227.67it/s]  2%|▏         | 1786/90000 [00:20<06:28, 226.85it/s]  2%|▏         | 1810/90000 [00:20<06:25, 228.77it/s]  2%|▏         | 1834/90000 [00:20<06:24, 229.14it/s]  2%|▏         | 1858/90000 [00:20<06:21, 230.80it/s]  2%|▏         | 1882/90000 [00:20<06:18, 232.65it/s]  2%|▏         | 1906/90000 [00:20<06:25, 228.73it/s]  2%|▏         | 1931/90000 [00:20<06:16, 233.85it/s]  2%|▏         | 1955/90000 [00:20<06:15, 234.17it/s]  2%|▏         | 1979/90000 [00:21<06:17, 233.12it/s]  2%|▏         | 2003/90000 [00:21<06:18, 232.54it/s]  2%|▏         | 2027/90000 [00:21<06:26, 227.41it/s]  2%|▏         | 2051/90000 [00:21<06:25, 227.86it/s]  2%|▏         | 2074/90000 [00:21<06:26, 227.28it/s]  2%|▏         | 2097/90000 [00:21<06:25, 228.02it/s]  2%|▏         | 2121/90000 [00:21<06:20, 230.87it/s]  2%|▏         | 2145/90000 [00:21<06:20, 230.84it/s]  2%|▏         | 2169/90000 [00:21<06:19, 231.16it/s]  2%|▏         | 2193/90000 [00:22<06:20, 230.85it/s]  2%|▏         | 2217/90000 [00:22<06:23, 228.94it/s]  2%|▏         | 2241/90000 [00:22<06:20, 230.88it/s]  3%|▎         | 2265/90000 [00:22<06:22, 229.17it/s]  3%|▎         | 2289/90000 [00:22<06:20, 230.28it/s]  3%|▎         | 2313/90000 [00:22<06:16, 232.62it/s]  3%|▎         | 2337/90000 [00:22<06:22, 228.98it/s]  3%|▎         | 2360/90000 [00:22<06:23, 228.79it/s]  3%|▎         | 2383/90000 [00:22<06:30, 224.31it/s]  3%|▎         | 2407/90000 [00:22<06:25, 227.48it/s]  3%|▎         | 2431/90000 [00:23<06:21, 229.71it/s]  3%|▎         | 2454/90000 [00:23<06:26, 226.56it/s]  3%|▎         | 2477/90000 [00:23<06:28, 225.54it/s]  3%|▎         | 2500/90000 [00:23<06:27, 226.00it/s]  3%|▎         | 2523/90000 [00:23<06:25, 226.69it/s]  3%|▎         | 2548/90000 [00:23<06:16, 232.17it/s]  3%|▎         | 2573/90000 [00:23<06:12, 234.94it/s]  3%|▎         | 2598/90000 [00:23<06:05, 238.99it/s]  3%|▎         | 2622/90000 [00:23<06:09, 236.59it/s]  3%|▎         | 2646/90000 [00:23<06:10, 235.62it/s]  3%|▎         | 2671/90000 [00:24<06:07, 237.31it/s]  3%|▎         | 2696/90000 [00:24<06:04, 239.49it/s]  3%|▎         | 2720/90000 [00:24<06:16, 232.04it/s]  3%|▎         | 2744/90000 [00:24<06:15, 232.58it/s]  3%|▎         | 2768/90000 [00:24<06:21, 228.79it/s]  3%|▎         | 2791/90000 [00:24<06:27, 224.89it/s]  3%|▎         | 2814/90000 [00:24<06:26, 225.62it/s]  3%|▎         | 2838/90000 [00:24<06:20, 228.82it/s]  3%|▎         | 2861/90000 [00:24<06:20, 228.79it/s]  3%|▎         | 2885/90000 [00:25<06:18, 230.10it/s]  3%|▎         | 2910/90000 [00:25<06:12, 233.58it/s]  3%|▎         | 2934/90000 [00:25<06:13, 233.07it/s]  3%|▎         | 2958/90000 [00:25<06:17, 230.44it/s]  3%|▎         | 2983/90000 [00:25<06:09, 235.79it/s]  3%|▎         | 3007/90000 [00:25<06:16, 231.31it/s]  3%|▎         | 3031/90000 [00:25<06:15, 231.31it/s]  3%|▎         | 3055/90000 [00:25<06:15, 231.49it/s]  3%|▎         | 3079/90000 [00:25<06:14, 232.28it/s]  3%|▎         | 3103/90000 [00:25<06:13, 232.53it/s]  3%|▎         | 3127/90000 [00:26<06:18, 229.41it/s]  4%|▎         | 3151/90000 [00:26<06:18, 229.65it/s]  4%|▎         | 3176/90000 [00:26<06:10, 234.10it/s]  4%|▎         | 3200/90000 [00:26<06:09, 235.17it/s]  4%|▎         | 3224/90000 [00:26<06:09, 234.86it/s]  4%|▎         | 3248/90000 [00:26<06:14, 231.92it/s]  4%|▎         | 3272/90000 [00:26<06:12, 232.98it/s]  4%|▎         | 3296/90000 [00:26<06:15, 231.16it/s]  4%|▎         | 3320/90000 [00:26<06:13, 231.80it/s]  4%|▎         | 3344/90000 [00:26<06:17, 229.45it/s]  4%|▎         | 3368/90000 [00:27<06:15, 230.88it/s]  4%|▍         | 3392/90000 [00:27<06:15, 230.42it/s]  4%|▍         | 3416/90000 [00:27<06:11, 232.94it/s]  4%|▍         | 3441/90000 [00:27<06:06, 236.04it/s]  4%|▍         | 3465/90000 [00:27<06:08, 235.15it/s]  4%|▍         | 3489/90000 [00:27<06:12, 232.17it/s]  4%|▍         | 3513/90000 [00:27<06:18, 228.73it/s]  4%|▍         | 3537/90000 [00:27<06:15, 230.09it/s]  4%|▍         | 3561/90000 [00:27<06:11, 232.73it/s]  4%|▍         | 3585/90000 [00:28<06:18, 228.33it/s]  4%|▍         | 3609/90000 [00:28<06:16, 229.38it/s]  4%|▍         | 3633/90000 [00:28<06:15, 230.31it/s]  4%|▍         | 3657/90000 [00:28<06:17, 228.89it/s]  4%|▍         | 3682/90000 [00:28<06:10, 232.72it/s]  4%|▍         | 3706/90000 [00:28<06:15, 229.88it/s]  4%|▍         | 3730/90000 [00:28<06:19, 227.43it/s]  4%|▍         | 3754/90000 [00:28<06:16, 228.99it/s]  4%|▍         | 3778/90000 [00:28<06:15, 229.59it/s]  4%|▍         | 3803/90000 [00:28<06:11, 232.27it/s]  4%|▍         | 3827/90000 [00:29<06:11, 231.78it/s]  4%|▍         | 3851/90000 [00:29<06:11, 231.96it/s]  4%|▍         | 3875/90000 [00:29<06:09, 233.06it/s]  4%|▍         | 3899/90000 [00:29<06:11, 231.59it/s]  4%|▍         | 3923/90000 [00:29<06:13, 230.29it/s]  4%|▍         | 3947/90000 [00:29<06:11, 231.66it/s]  4%|▍         | 3971/90000 [00:29<06:12, 231.10it/s]  4%|▍         | 3995/90000 [00:29<06:11, 231.60it/s]  4%|▍         | 4019/90000 [00:29<06:20, 226.16it/s]  4%|▍         | 4043/90000 [00:30<06:15, 228.95it/s]  5%|▍         | 4066/90000 [00:30<06:18, 226.90it/s]  5%|▍         | 4090/90000 [00:30<06:14, 229.36it/s]  5%|▍         | 4113/90000 [00:30<06:15, 228.46it/s]  5%|▍         | 4136/90000 [00:30<06:20, 225.67it/s]  5%|▍         | 4160/90000 [00:30<06:17, 227.18it/s]  5%|▍         | 4183/90000 [00:30<06:27, 221.62it/s]  5%|▍         | 4206/90000 [00:30<06:31, 218.94it/s]  5%|▍         | 4230/90000 [00:30<06:24, 223.29it/s]  5%|▍         | 4254/90000 [00:30<06:17, 226.97it/s]  5%|▍         | 4277/90000 [00:31<06:19, 225.70it/s]  5%|▍         | 4300/90000 [00:31<06:20, 225.01it/s]  5%|▍         | 4323/90000 [00:31<06:18, 226.35it/s]  5%|▍         | 4347/90000 [00:31<06:15, 228.03it/s]  5%|▍         | 4372/90000 [00:31<06:06, 233.50it/s]  5%|▍         | 4396/90000 [00:31<06:12, 230.00it/s]  5%|▍         | 4420/90000 [00:31<06:09, 231.37it/s]  5%|▍         | 4444/90000 [00:31<06:08, 232.20it/s]  5%|▍         | 4468/90000 [00:31<06:07, 232.57it/s]  5%|▍         | 4492/90000 [00:31<06:12, 229.64it/s]  5%|▌         | 4515/90000 [00:32<06:15, 227.50it/s]  5%|▌         | 4539/90000 [00:32<06:12, 229.69it/s]  5%|▌         | 4562/90000 [00:32<06:15, 227.42it/s]  5%|▌         | 4586/90000 [00:32<06:15, 227.37it/s]  5%|▌         | 4609/90000 [00:32<06:17, 226.18it/s]  5%|▌         | 4633/90000 [00:32<06:13, 228.74it/s]  5%|▌         | 4656/90000 [00:32<06:14, 227.91it/s]  5%|▌         | 4679/90000 [00:32<06:15, 227.24it/s]  5%|▌         | 4704/90000 [00:32<06:08, 231.61it/s]  5%|▌         | 4728/90000 [00:33<06:08, 231.49it/s]  5%|▌         | 4752/90000 [00:33<06:04, 233.74it/s]  5%|▌         | 4776/90000 [00:33<06:04, 233.57it/s]  5%|▌         | 4800/90000 [00:33<06:10, 230.22it/s]  5%|▌         | 4824/90000 [00:33<06:11, 229.43it/s]  5%|▌         | 4847/90000 [00:33<06:11, 229.39it/s]  5%|▌         | 4870/90000 [00:33<06:12, 228.24it/s]  5%|▌         | 4894/90000 [00:33<06:12, 228.73it/s]  5%|▌         | 4918/90000 [00:33<06:09, 230.29it/s]  5%|▌         | 4942/90000 [00:33<06:05, 233.03it/s]  6%|▌         | 4966/90000 [00:34<06:10, 229.64it/s]  6%|▌         | 4990/90000 [00:34<06:06, 231.69it/s]  6%|▌         | 5014/90000 [00:34<06:07, 231.12it/s]  6%|▌         | 5038/90000 [00:34<06:09, 230.12it/s]  6%|▌         | 5063/90000 [00:34<06:01, 235.24it/s]  6%|▌         | 5087/90000 [00:34<06:04, 233.12it/s]  6%|▌         | 5111/90000 [00:34<06:03, 233.54it/s]  6%|▌         | 5136/90000 [00:34<05:58, 237.03it/s]  6%|▌         | 5160/90000 [00:34<06:03, 233.41it/s]  6%|▌         | 5184/90000 [00:34<06:07, 230.85it/s]  6%|▌         | 5208/90000 [00:35<06:05, 231.74it/s]  6%|▌         | 5232/90000 [00:35<06:07, 230.43it/s]  6%|▌         | 5256/90000 [00:35<06:08, 230.07it/s]  6%|▌         | 5280/90000 [00:35<06:14, 226.17it/s]  6%|▌         | 5303/90000 [00:35<06:17, 224.51it/s]  6%|▌         | 5327/90000 [00:35<06:11, 227.75it/s]  6%|▌         | 5350/90000 [00:35<06:14, 226.18it/s]  6%|▌         | 5374/90000 [00:35<06:09, 229.20it/s]  6%|▌         | 5397/90000 [00:35<06:17, 223.88it/s]  6%|▌         | 5421/90000 [00:36<06:10, 228.53it/s]  6%|▌         | 5444/90000 [00:36<06:10, 227.95it/s]  6%|▌         | 5467/90000 [00:36<06:14, 225.74it/s]  6%|▌         | 5490/90000 [00:36<06:18, 223.20it/s]  6%|▌         | 5513/90000 [00:36<06:17, 223.54it/s]  6%|▌         | 5538/90000 [00:36<06:07, 229.77it/s]  6%|▌         | 5561/90000 [00:36<06:10, 227.84it/s]  6%|▌         | 5584/90000 [00:36<06:18, 222.77it/s]  6%|▌         | 5608/90000 [00:36<06:13, 226.06it/s]  6%|▋         | 5633/90000 [00:36<06:05, 231.14it/s]  6%|▋         | 5657/90000 [00:37<06:18, 222.97it/s]  6%|▋         | 5681/90000 [00:37<06:13, 225.60it/s]  6%|▋         | 5704/90000 [00:37<06:13, 225.70it/s]  6%|▋         | 5727/90000 [00:37<06:15, 224.22it/s]  6%|▋         | 5750/90000 [00:37<06:21, 221.08it/s]  6%|▋         | 5773/90000 [00:37<06:16, 223.60it/s]  6%|▋         | 5796/90000 [00:37<06:17, 223.16it/s]  6%|▋         | 5820/90000 [00:37<06:10, 227.07it/s]  6%|▋         | 5843/90000 [00:37<06:10, 227.19it/s]  7%|▋         | 5868/90000 [00:38<06:03, 231.31it/s]  7%|▋         | 5892/90000 [00:38<06:11, 226.15it/s]  7%|▋         | 5915/90000 [00:38<06:10, 227.02it/s]  7%|▋         | 5938/90000 [00:38<06:14, 224.48it/s]  7%|▋         | 5962/90000 [00:38<06:07, 228.53it/s]  7%|▋         | 5986/90000 [00:38<06:05, 230.07it/s]  7%|▋         | 6010/90000 [00:38<06:08, 228.21it/s]  7%|▋         | 6033/90000 [00:38<06:08, 228.10it/s]  7%|▋         | 6059/90000 [00:38<05:55, 236.14it/s]  7%|▋         | 6083/90000 [00:38<06:02, 231.29it/s]  7%|▋         | 6107/90000 [00:39<06:07, 228.12it/s]  7%|▋         | 6131/90000 [00:39<06:02, 231.05it/s]  7%|▋         | 6155/90000 [00:39<06:03, 230.51it/s]  7%|▋         | 6179/90000 [00:39<06:01, 231.89it/s]  7%|▋         | 6203/90000 [00:39<06:03, 230.38it/s]  7%|▋         | 6227/90000 [00:39<06:06, 228.48it/s]  7%|▋         | 6250/90000 [00:39<06:07, 227.65it/s]  7%|▋         | 6273/90000 [00:39<06:12, 224.66it/s]  7%|▋         | 6297/90000 [00:39<06:08, 226.98it/s]  7%|▋         | 6321/90000 [00:39<06:04, 229.61it/s]  7%|▋         | 6345/90000 [00:40<06:01, 231.22it/s]  7%|▋         | 6370/90000 [00:40<05:58, 233.53it/s]  7%|▋         | 6394/90000 [00:40<06:07, 227.69it/s]  7%|▋         | 6418/90000 [00:40<06:04, 229.31it/s]  7%|▋         | 6442/90000 [00:40<06:01, 231.41it/s]  7%|▋         | 6466/90000 [00:40<06:08, 226.76it/s]  7%|▋         | 6489/90000 [00:40<06:08, 226.62it/s]  7%|▋         | 6512/90000 [00:40<06:06, 227.59it/s]  7%|▋         | 6535/90000 [00:40<06:08, 226.20it/s]  7%|▋         | 6559/90000 [00:41<06:04, 229.18it/s]  7%|▋         | 6582/90000 [00:41<06:06, 227.60it/s]  7%|▋         | 6605/90000 [00:41<06:12, 223.59it/s]  7%|▋         | 6628/90000 [00:41<06:11, 224.36it/s]  7%|▋         | 6651/90000 [00:41<06:11, 224.22it/s]  7%|▋         | 6674/90000 [00:41<06:11, 224.54it/s]  7%|▋         | 6697/90000 [00:41<06:09, 225.26it/s]  7%|▋         | 6721/90000 [00:41<06:06, 227.38it/s]  7%|▋         | 6744/90000 [00:41<06:10, 224.67it/s]  8%|▊         | 6768/90000 [00:41<06:06, 227.37it/s]  8%|▊         | 6791/90000 [00:42<06:22, 217.33it/s]  8%|▊         | 6815/90000 [00:42<06:15, 221.72it/s]  8%|▊         | 6838/90000 [00:42<06:13, 222.56it/s]  8%|▊         | 6861/90000 [00:42<06:19, 219.06it/s]  8%|▊         | 6884/90000 [00:42<06:16, 220.96it/s]  8%|▊         | 6908/90000 [00:42<06:11, 223.70it/s]  8%|▊         | 6931/90000 [00:42<06:10, 224.25it/s]  8%|▊         | 6956/90000 [00:42<06:01, 229.88it/s]  8%|▊         | 6980/90000 [00:42<05:57, 232.10it/s]  8%|▊         | 7004/90000 [00:43<06:11, 223.53it/s]  8%|▊         | 7029/90000 [00:43<06:02, 228.76it/s]  8%|▊         | 7052/90000 [00:43<06:03, 227.99it/s]  8%|▊         | 7075/90000 [00:43<06:03, 228.29it/s]  8%|▊         | 7099/90000 [00:43<05:59, 230.81it/s]  8%|▊         | 7123/90000 [00:43<06:02, 228.84it/s]  8%|▊         | 7147/90000 [00:43<05:59, 230.65it/s]  8%|▊         | 7171/90000 [00:43<05:57, 231.46it/s]  8%|▊         | 7195/90000 [00:43<06:02, 228.53it/s]  8%|▊         | 7218/90000 [00:43<06:11, 222.98it/s]  8%|▊         | 7241/90000 [00:44<06:10, 223.23it/s]  8%|▊         | 7264/90000 [00:44<06:10, 223.50it/s]  8%|▊         | 7287/90000 [00:44<06:11, 222.55it/s]  8%|▊         | 7310/90000 [00:44<06:12, 221.93it/s]  8%|▊         | 7333/90000 [00:44<06:17, 219.27it/s]  8%|▊         | 7356/90000 [00:44<06:14, 220.49it/s]  8%|▊         | 7380/90000 [00:44<06:05, 226.01it/s]  8%|▊         | 7403/90000 [00:44<06:12, 221.91it/s]  8%|▊         | 7427/90000 [00:44<06:08, 224.33it/s]  8%|▊         | 7450/90000 [00:44<06:06, 225.39it/s]  8%|▊         | 7473/90000 [00:45<06:05, 225.79it/s]  8%|▊         | 7496/90000 [00:45<06:07, 224.75it/s]  8%|▊         | 7519/90000 [00:45<06:11, 222.23it/s]  8%|▊         | 7542/90000 [00:45<06:15, 219.62it/s]  8%|▊         | 7565/90000 [00:45<06:14, 220.18it/s]  8%|▊         | 7588/90000 [00:45<06:16, 218.91it/s]  8%|▊         | 7613/90000 [00:45<06:07, 224.31it/s]  8%|▊         | 7636/90000 [00:45<06:04, 225.70it/s]  9%|▊         | 7659/90000 [00:45<06:11, 221.78it/s]  9%|▊         | 7682/90000 [00:46<06:18, 217.65it/s]  9%|▊         | 7704/90000 [00:46<06:22, 214.98it/s]  9%|▊         | 7728/90000 [00:46<06:11, 221.30it/s]  9%|▊         | 7751/90000 [00:46<06:12, 221.03it/s]  9%|▊         | 7774/90000 [00:46<06:10, 222.03it/s]  9%|▊         | 7797/90000 [00:46<06:08, 222.95it/s]  9%|▊         | 7820/90000 [00:46<06:05, 224.89it/s]  9%|▊         | 7843/90000 [00:46<06:08, 222.95it/s]  9%|▊         | 7866/90000 [00:46<06:08, 222.83it/s]  9%|▉         | 7889/90000 [00:46<06:09, 221.97it/s]  9%|▉         | 7913/90000 [00:47<06:06, 224.04it/s]  9%|▉         | 7937/90000 [00:47<06:00, 227.83it/s]  9%|▉         | 7961/90000 [00:47<05:58, 228.87it/s]  9%|▉         | 7984/90000 [00:47<06:13, 219.77it/s]  9%|▉         | 8009/90000 [00:47<06:02, 226.05it/s]  9%|▉         | 8032/90000 [00:47<06:03, 225.50it/s]  9%|▉         | 8056/90000 [00:47<05:57, 229.04it/s]  9%|▉         | 8080/90000 [00:47<05:55, 230.22it/s]  9%|▉         | 8104/90000 [00:47<05:57, 229.18it/s]  9%|▉         | 8127/90000 [00:48<06:02, 226.15it/s]  9%|▉         | 8151/90000 [00:48<05:56, 229.42it/s]  9%|▉         | 8174/90000 [00:48<05:56, 229.32it/s]  9%|▉         | 8197/90000 [00:48<06:00, 227.03it/s]  9%|▉         | 8221/90000 [00:48<05:55, 229.97it/s]  9%|▉         | 8245/90000 [00:48<05:55, 230.22it/s]  9%|▉         | 8269/90000 [00:48<05:56, 228.95it/s]  9%|▉         | 8292/90000 [00:48<06:01, 225.91it/s]  9%|▉         | 8317/90000 [00:48<05:53, 230.76it/s]  9%|▉         | 8341/90000 [00:48<05:51, 232.04it/s]  9%|▉         | 8365/90000 [00:49<05:50, 232.80it/s]  9%|▉         | 8389/90000 [00:49<05:53, 231.02it/s]  9%|▉         | 8413/90000 [00:49<06:01, 225.92it/s]  9%|▉         | 8436/90000 [00:49<06:05, 222.86it/s]  9%|▉         | 8460/90000 [00:49<05:58, 227.21it/s]  9%|▉         | 8483/90000 [00:49<05:58, 227.27it/s]  9%|▉         | 8506/90000 [00:49<06:09, 220.74it/s]  9%|▉         | 8529/90000 [00:49<06:05, 222.72it/s] 10%|▉         | 8553/90000 [00:49<06:02, 224.80it/s] 10%|▉         | 8576/90000 [00:50<06:01, 225.14it/s] 10%|▉         | 8601/90000 [00:50<05:53, 230.44it/s] 10%|▉         | 8625/90000 [00:50<05:56, 228.32it/s] 10%|▉         | 8649/90000 [00:50<05:54, 229.37it/s] 10%|▉         | 8672/90000 [00:50<05:55, 228.64it/s] 10%|▉         | 8696/90000 [00:50<05:53, 229.84it/s] 10%|▉         | 8720/90000 [00:50<05:52, 230.71it/s] 10%|▉         | 8744/90000 [00:50<05:55, 228.58it/s] 10%|▉         | 8768/90000 [00:50<05:53, 229.85it/s] 10%|▉         | 8792/90000 [00:50<05:51, 231.34it/s] 10%|▉         | 8816/90000 [00:51<05:52, 230.53it/s] 10%|▉         | 8840/90000 [00:51<05:54, 228.91it/s] 10%|▉         | 8864/90000 [00:51<05:50, 231.16it/s] 10%|▉         | 8888/90000 [00:51<05:51, 230.84it/s] 10%|▉         | 8912/90000 [00:51<05:50, 231.48it/s] 10%|▉         | 8936/90000 [00:51<05:58, 226.07it/s] 10%|▉         | 8959/90000 [00:51<06:02, 223.40it/s] 10%|▉         | 8982/90000 [00:51<06:01, 223.95it/s] 10%|█         | 9005/90000 [00:51<06:05, 221.37it/s] 10%|█         | 9029/90000 [00:51<06:00, 224.56it/s] 10%|█         | 9052/90000 [00:52<06:02, 223.19it/s] 10%|█         | 9075/90000 [00:52<06:07, 220.28it/s] 10%|█         | 9098/90000 [00:52<06:09, 218.83it/s] 10%|█         | 9121/90000 [00:52<06:06, 220.47it/s] 10%|█         | 9146/90000 [00:52<05:57, 226.08it/s] 10%|█         | 9169/90000 [00:52<05:59, 224.88it/s] 10%|█         | 9192/90000 [00:52<05:57, 226.17it/s] 10%|█         | 9217/90000 [00:52<05:51, 229.65it/s] 10%|█         | 9240/90000 [00:52<06:01, 223.45it/s] 10%|█         | 9263/90000 [00:53<06:00, 224.24it/s] 10%|█         | 9286/90000 [00:53<06:01, 223.09it/s] 10%|█         | 9309/90000 [00:53<06:02, 222.80it/s] 10%|█         | 9332/90000 [00:53<05:59, 224.55it/s] 10%|█         | 9355/90000 [00:53<05:57, 225.58it/s] 10%|█         | 9379/90000 [00:53<05:55, 226.65it/s] 10%|█         | 9404/90000 [00:53<05:47, 232.16it/s] 10%|█         | 9428/90000 [00:53<05:51, 229.20it/s] 11%|█         | 9451/90000 [00:53<05:55, 226.84it/s] 11%|█         | 9474/90000 [00:53<06:02, 222.19it/s] 11%|█         | 9497/90000 [00:54<06:05, 220.02it/s] 11%|█         | 9520/90000 [00:54<06:12, 216.09it/s] 11%|█         | 9542/90000 [00:54<06:14, 214.75it/s] 11%|█         | 9564/90000 [00:54<06:21, 210.95it/s] 11%|█         | 9587/90000 [00:54<06:15, 214.01it/s] 11%|█         | 9609/90000 [00:54<06:15, 213.95it/s] 11%|█         | 9631/90000 [00:54<06:23, 209.63it/s] 11%|█         | 9654/90000 [00:54<06:17, 212.99it/s] 11%|█         | 9678/90000 [00:54<06:08, 218.25it/s] 11%|█         | 9700/90000 [00:55<06:19, 211.55it/s] 11%|█         | 9722/90000 [00:55<06:16, 213.25it/s] 11%|█         | 9744/90000 [00:55<06:19, 211.71it/s] 11%|█         | 9766/90000 [00:55<06:19, 211.51it/s] 11%|█         | 9788/90000 [00:55<06:20, 210.89it/s] 11%|█         | 9810/90000 [00:55<06:22, 209.59it/s] 11%|█         | 9833/90000 [00:55<06:13, 214.41it/s] 11%|█         | 9855/90000 [00:55<06:18, 211.61it/s] 11%|█         | 9877/90000 [00:55<06:16, 212.89it/s] 11%|█         | 9899/90000 [00:55<06:14, 213.99it/s] 11%|█         | 9921/90000 [00:56<06:19, 211.22it/s] 11%|█         | 9944/90000 [00:56<06:13, 214.56it/s] 11%|█         | 9966/90000 [00:56<06:17, 212.14it/s] 11%|█         | 9988/90000 [00:56<06:16, 212.45it/s] 11%|█         | 10010/90000 [00:56<06:20, 210.43it/s] 11%|█         | 10032/90000 [00:56<06:23, 208.79it/s] 11%|█         | 10053/90000 [00:56<06:22, 208.81it/s] 11%|█         | 10075/90000 [00:56<06:18, 211.34it/s] 11%|█         | 10097/90000 [00:56<06:21, 209.32it/s] 11%|█         | 10118/90000 [00:57<06:27, 205.96it/s] 11%|█▏        | 10140/90000 [00:57<06:23, 208.18it/s] 11%|█▏        | 10162/90000 [00:57<06:23, 208.11it/s] 11%|█▏        | 10183/90000 [00:57<06:23, 208.11it/s] 11%|█▏        | 10206/90000 [00:57<06:14, 213.30it/s] 11%|█▏        | 10228/90000 [00:57<06:14, 213.12it/s] 11%|█▏        | 10250/90000 [00:57<06:18, 210.85it/s] 11%|█▏        | 10272/90000 [00:57<06:18, 210.62it/s] 11%|█▏        | 10294/90000 [00:57<06:20, 209.32it/s] 11%|█▏        | 10317/90000 [00:57<06:14, 213.00it/s] 11%|█▏        | 10339/90000 [00:58<06:16, 211.68it/s] 12%|█▏        | 10361/90000 [00:58<06:19, 210.04it/s] 12%|█▏        | 10385/90000 [00:58<06:07, 216.85it/s] 12%|█▏        | 10407/90000 [00:58<06:06, 217.29it/s] 12%|█▏        | 10429/90000 [00:58<06:12, 213.86it/s] 12%|█▏        | 10451/90000 [00:58<06:09, 215.25it/s] 12%|█▏        | 10473/90000 [00:58<06:18, 210.30it/s] 12%|█▏        | 10495/90000 [00:58<06:21, 208.37it/s] 12%|█▏        | 10517/90000 [00:58<06:20, 208.97it/s] 12%|█▏        | 10538/90000 [00:59<06:21, 208.18it/s] 12%|█▏        | 10560/90000 [00:59<06:19, 209.29it/s] 12%|█▏        | 10582/90000 [00:59<06:15, 211.37it/s] 12%|█▏        | 10605/90000 [00:59<06:09, 214.70it/s] 12%|█▏        | 10627/90000 [00:59<06:07, 215.83it/s] 12%|█▏        | 10649/90000 [00:59<06:15, 211.43it/s] 12%|█▏        | 10671/90000 [00:59<06:14, 211.96it/s] 12%|█▏        | 10693/90000 [00:59<06:11, 213.25it/s] 12%|█▏        | 10715/90000 [00:59<06:17, 210.19it/s] 12%|█▏        | 10737/90000 [00:59<06:15, 211.27it/s] 12%|█▏        | 10761/90000 [01:00<06:00, 219.63it/s] 12%|█▏        | 10783/90000 [01:00<06:05, 216.78it/s] 12%|█▏        | 10806/90000 [01:00<05:59, 220.49it/s] 12%|█▏        | 10829/90000 [01:00<05:55, 222.89it/s] 12%|█▏        | 10852/90000 [01:00<06:00, 219.43it/s] 12%|█▏        | 10874/90000 [01:00<06:12, 212.38it/s] 12%|█▏        | 10896/90000 [01:00<06:13, 211.97it/s] 12%|█▏        | 10918/90000 [01:00<06:13, 211.98it/s] 12%|█▏        | 10941/90000 [01:00<06:05, 216.29it/s] 12%|█▏        | 10963/90000 [01:00<06:04, 216.71it/s] 12%|█▏        | 10985/90000 [01:01<06:04, 216.55it/s] 12%|█▏        | 11007/90000 [01:01<06:10, 213.41it/s] 12%|█▏        | 11029/90000 [01:01<06:06, 215.27it/s] 12%|█▏        | 11052/90000 [01:01<06:02, 217.72it/s] 12%|█▏        | 11074/90000 [01:01<06:02, 217.93it/s] 12%|█▏        | 11099/90000 [01:01<05:51, 224.64it/s] 12%|█▏        | 11122/90000 [01:01<05:53, 223.45it/s] 12%|█▏        | 11145/90000 [01:01<05:52, 223.97it/s] 12%|█▏        | 11170/90000 [01:01<05:42, 230.39it/s] 12%|█▏        | 11194/90000 [01:02<05:45, 228.23it/s] 12%|█▏        | 11218/90000 [01:02<05:41, 230.78it/s] 12%|█▏        | 11242/90000 [01:02<05:40, 231.02it/s] 13%|█▎        | 11266/90000 [01:02<05:45, 227.84it/s] 13%|█▎        | 11289/90000 [01:02<05:44, 228.23it/s] 13%|█▎        | 11312/90000 [01:02<05:46, 227.03it/s] 13%|█▎        | 11335/90000 [01:02<05:49, 224.99it/s] 13%|█▎        | 11359/90000 [01:02<05:47, 226.29it/s] 13%|█▎        | 11382/90000 [01:02<05:53, 222.71it/s] 13%|█▎        | 11405/90000 [01:02<05:49, 224.82it/s] 13%|█▎        | 11428/90000 [01:03<05:54, 221.48it/s] 13%|█▎        | 11451/90000 [01:03<05:57, 219.57it/s] 13%|█▎        | 11473/90000 [01:03<06:03, 216.31it/s] 13%|█▎        | 11497/90000 [01:03<05:55, 220.98it/s] 13%|█▎        | 11520/90000 [01:03<05:53, 222.22it/s] 13%|█▎        | 11544/90000 [01:03<05:46, 226.60it/s] 13%|█▎        | 11568/90000 [01:03<05:44, 227.90it/s] 13%|█▎        | 11591/90000 [01:03<05:49, 224.06it/s] 13%|█▎        | 11614/90000 [01:03<05:52, 222.13it/s] 13%|█▎        | 11638/90000 [01:03<05:47, 225.30it/s] 13%|█▎        | 11661/90000 [01:04<05:47, 225.22it/s] 13%|█▎        | 11685/90000 [01:04<05:44, 227.19it/s] 13%|█▎        | 11708/90000 [01:04<05:50, 223.61it/s] 13%|█▎        | 11731/90000 [01:04<06:00, 217.37it/s] 13%|█▎        | 11754/90000 [01:04<05:54, 220.72it/s] 13%|█▎        | 11777/90000 [01:04<05:56, 219.59it/s] 13%|█▎        | 11799/90000 [01:04<06:01, 216.55it/s] 13%|█▎        | 11822/90000 [01:04<05:56, 219.33it/s] 13%|█▎        | 11844/90000 [01:04<05:56, 219.11it/s] 13%|█▎        | 11867/90000 [01:05<05:52, 221.60it/s] 13%|█▎        | 11892/90000 [01:05<05:42, 228.06it/s] 13%|█▎        | 11915/90000 [01:05<05:41, 228.34it/s] 13%|█▎        | 11939/90000 [01:05<05:39, 229.91it/s] 13%|█▎        | 11962/90000 [01:05<05:46, 225.38it/s] 13%|█▎        | 11985/90000 [01:05<05:52, 221.28it/s] 13%|█▎        | 12008/90000 [01:05<05:51, 221.87it/s] 13%|█▎        | 12032/90000 [01:05<05:44, 226.43it/s] 13%|█▎        | 12055/90000 [01:05<05:50, 222.60it/s] 13%|█▎        | 12078/90000 [01:05<05:46, 224.58it/s] 13%|█▎        | 12101/90000 [01:06<05:46, 225.06it/s] 13%|█▎        | 12124/90000 [01:06<05:46, 224.43it/s] 13%|█▎        | 12147/90000 [01:06<05:44, 225.91it/s] 14%|█▎        | 12170/90000 [01:06<05:44, 226.24it/s] 14%|█▎        | 12193/90000 [01:06<05:45, 225.35it/s] 14%|█▎        | 12216/90000 [01:06<05:44, 225.73it/s] 14%|█▎        | 12239/90000 [01:06<05:43, 226.32it/s] 14%|█▎        | 12262/90000 [01:06<05:48, 222.78it/s] 14%|█▎        | 12286/90000 [01:06<05:43, 226.39it/s] 14%|█▎        | 12309/90000 [01:06<05:43, 226.24it/s] 14%|█▎        | 12332/90000 [01:07<05:50, 221.66it/s] 14%|█▎        | 12355/90000 [01:07<05:53, 219.53it/s] 14%|█▍        | 12379/90000 [01:07<05:45, 224.37it/s] 14%|█▍        | 12402/90000 [01:07<05:44, 225.48it/s] 14%|█▍        | 12425/90000 [01:07<05:42, 226.66it/s] 14%|█▍        | 12448/90000 [01:07<05:57, 217.00it/s] 14%|█▍        | 12470/90000 [01:07<05:57, 217.08it/s] 14%|█▍        | 12493/90000 [01:07<05:53, 219.25it/s] 14%|█▍        | 12517/90000 [01:07<05:45, 224.49it/s] 14%|█▍        | 12540/90000 [01:08<05:46, 223.25it/s] 14%|█▍        | 12563/90000 [01:08<05:44, 224.78it/s] 14%|█▍        | 12586/90000 [01:08<05:50, 220.89it/s] 14%|█▍        | 12609/90000 [01:08<05:53, 218.82it/s] 14%|█▍        | 12632/90000 [01:08<05:52, 219.25it/s] 14%|█▍        | 12655/90000 [01:08<05:48, 222.13it/s] 14%|█▍        | 12678/90000 [01:08<05:50, 220.87it/s] 14%|█▍        | 12702/90000 [01:08<05:42, 225.41it/s] 14%|█▍        | 12725/90000 [01:08<05:50, 220.62it/s] 14%|█▍        | 12749/90000 [01:08<05:43, 224.68it/s] 14%|█▍        | 12773/90000 [01:09<05:39, 227.54it/s] 14%|█▍        | 12796/90000 [01:09<05:47, 222.04it/s] 14%|█▍        | 12819/90000 [01:09<05:45, 223.54it/s] 14%|█▍        | 12842/90000 [01:09<05:53, 218.44it/s] 14%|█▍        | 12864/90000 [01:09<06:01, 213.66it/s] 14%|█▍        | 12886/90000 [01:09<06:00, 213.90it/s] 14%|█▍        | 12908/90000 [01:09<05:58, 215.32it/s] 14%|█▍        | 12930/90000 [01:09<06:00, 213.66it/s] 14%|█▍        | 12952/90000 [01:09<06:03, 211.86it/s] 14%|█▍        | 12974/90000 [01:10<06:01, 213.12it/s] 14%|█▍        | 12999/90000 [01:10<05:49, 220.58it/s] 14%|█▍        | 13022/90000 [01:10<05:52, 218.57it/s] 14%|█▍        | 13045/90000 [01:10<05:48, 220.96it/s] 15%|█▍        | 13068/90000 [01:10<05:49, 220.25it/s] 15%|█▍        | 13092/90000 [01:10<05:43, 223.98it/s] 15%|█▍        | 13116/90000 [01:10<05:37, 227.75it/s] 15%|█▍        | 13139/90000 [01:10<05:41, 225.18it/s] 15%|█▍        | 13162/90000 [01:10<05:48, 220.18it/s] 15%|█▍        | 13185/90000 [01:10<05:48, 220.67it/s] 15%|█▍        | 13208/90000 [01:11<05:54, 216.34it/s] 15%|█▍        | 13231/90000 [01:11<05:49, 219.74it/s] 15%|█▍        | 13254/90000 [01:11<05:55, 216.03it/s] 15%|█▍        | 13276/90000 [01:11<05:53, 217.15it/s] 15%|█▍        | 13299/90000 [01:11<05:47, 220.41it/s] 15%|█▍        | 13323/90000 [01:11<05:41, 224.31it/s] 15%|█▍        | 13346/90000 [01:11<05:40, 224.87it/s] 15%|█▍        | 13370/90000 [01:11<05:35, 228.36it/s] 15%|█▍        | 13393/90000 [01:11<05:36, 227.97it/s] 15%|█▍        | 13416/90000 [01:11<05:36, 227.71it/s] 15%|█▍        | 13439/90000 [01:12<05:37, 226.66it/s] 15%|█▍        | 13462/90000 [01:12<05:39, 225.64it/s] 15%|█▍        | 13485/90000 [01:12<05:37, 226.68it/s] 15%|█▌        | 13508/90000 [01:12<05:36, 227.33it/s] 15%|█▌        | 13531/90000 [01:12<05:39, 225.23it/s] 15%|█▌        | 13554/90000 [01:12<05:39, 224.99it/s] 15%|█▌        | 13578/90000 [01:12<05:37, 226.55it/s] 15%|█▌        | 13601/90000 [01:12<05:39, 224.87it/s] 15%|█▌        | 13624/90000 [01:12<05:45, 221.02it/s] 15%|█▌        | 13647/90000 [01:13<05:47, 219.91it/s] 15%|█▌        | 13670/90000 [01:13<05:47, 219.93it/s] 15%|█▌        | 13693/90000 [01:13<05:48, 218.80it/s] 15%|█▌        | 13716/90000 [01:13<05:46, 220.14it/s] 15%|█▌        | 13740/90000 [01:13<05:37, 225.78it/s] 15%|█▌        | 13763/90000 [01:13<05:41, 223.14it/s] 15%|█▌        | 13786/90000 [01:13<05:41, 222.90it/s] 15%|█▌        | 13809/90000 [01:13<05:38, 224.90it/s] 15%|█▌        | 13832/90000 [01:13<05:39, 224.25it/s] 15%|█▌        | 13855/90000 [01:13<05:41, 222.96it/s] 15%|█▌        | 13879/90000 [01:14<05:37, 225.62it/s] 15%|█▌        | 13902/90000 [01:14<05:37, 225.30it/s] 15%|█▌        | 13925/90000 [01:14<05:35, 226.44it/s] 15%|█▌        | 13948/90000 [01:14<05:37, 225.51it/s] 16%|█▌        | 13971/90000 [01:14<05:41, 222.44it/s] 16%|█▌        | 13994/90000 [01:14<05:43, 221.34it/s] 16%|█▌        | 14017/90000 [01:14<05:44, 220.76it/s] 16%|█▌        | 14040/90000 [01:14<05:50, 216.43it/s] 16%|█▌        | 14063/90000 [01:14<05:48, 217.97it/s] 16%|█▌        | 14086/90000 [01:14<05:43, 221.32it/s] 16%|█▌        | 14109/90000 [01:15<05:39, 223.44it/s] 16%|█▌        | 14132/90000 [01:15<05:42, 221.36it/s] 16%|█▌        | 14157/90000 [01:15<05:34, 226.65it/s] 16%|█▌        | 14180/90000 [01:15<05:37, 224.83it/s] 16%|█▌        | 14203/90000 [01:15<05:38, 224.12it/s] 16%|█▌        | 14226/90000 [01:15<05:38, 223.96it/s] 16%|█▌        | 14249/90000 [01:15<05:37, 224.53it/s] 16%|█▌        | 14272/90000 [01:15<05:42, 221.42it/s] 16%|█▌        | 14295/90000 [01:15<05:42, 221.32it/s] 16%|█▌        | 14318/90000 [01:16<05:41, 221.87it/s] 16%|█▌        | 14341/90000 [01:16<05:39, 222.86it/s] 16%|█▌        | 14364/90000 [01:16<05:38, 223.37it/s] 16%|█▌        | 14387/90000 [01:16<05:39, 222.43it/s] 16%|█▌        | 14411/90000 [01:16<05:35, 225.47it/s] 16%|█▌        | 14434/90000 [01:16<05:38, 223.07it/s] 16%|█▌        | 14458/90000 [01:16<05:32, 227.22it/s] 16%|█▌        | 14481/90000 [01:16<05:35, 224.92it/s] 16%|█▌        | 14504/90000 [01:16<05:36, 224.11it/s] 16%|█▌        | 14527/90000 [01:16<05:35, 225.11it/s] 16%|█▌        | 14550/90000 [01:17<05:40, 221.75it/s] 16%|█▌        | 14574/90000 [01:17<05:36, 224.03it/s] 16%|█▌        | 14597/90000 [01:17<05:39, 221.93it/s] 16%|█▌        | 14620/90000 [01:17<05:38, 222.85it/s] 16%|█▋        | 14643/90000 [01:17<05:36, 223.94it/s] 16%|█▋        | 14666/90000 [01:17<05:38, 222.84it/s] 16%|█▋        | 14689/90000 [01:17<05:41, 220.74it/s] 16%|█▋        | 14712/90000 [01:17<05:44, 218.36it/s] 16%|█▋        | 14736/90000 [01:17<05:36, 223.47it/s] 16%|█▋        | 14759/90000 [01:18<05:36, 223.35it/s] 16%|█▋        | 14782/90000 [01:18<05:37, 222.58it/s] 16%|█▋        | 14805/90000 [01:18<05:37, 222.65it/s] 16%|█▋        | 14828/90000 [01:18<05:36, 223.52it/s] 17%|█▋        | 14852/90000 [01:18<05:32, 225.83it/s] 17%|█▋        | 14875/90000 [01:18<05:35, 223.78it/s] 17%|█▋        | 14898/90000 [01:18<05:39, 220.96it/s] 17%|█▋        | 14921/90000 [01:18<05:38, 221.82it/s] 17%|█▋        | 14944/90000 [01:18<05:38, 221.74it/s] 17%|█▋        | 14968/90000 [01:18<05:31, 226.46it/s] 17%|█▋        | 14991/90000 [01:19<05:37, 222.07it/s] 17%|█▋        | 15014/90000 [01:19<05:36, 222.87it/s] 17%|█▋        | 15037/90000 [01:19<05:39, 221.13it/s] 17%|█▋        | 15060/90000 [01:19<05:39, 220.54it/s] 17%|█▋        | 15085/90000 [01:19<05:31, 226.31it/s] 17%|█▋        | 15109/90000 [01:19<05:27, 228.66it/s] 17%|█▋        | 15132/90000 [01:19<05:38, 221.48it/s] 17%|█▋        | 15157/90000 [01:19<05:28, 227.77it/s] 17%|█▋        | 15181/90000 [01:19<05:25, 229.58it/s] 17%|█▋        | 15204/90000 [01:19<05:31, 225.68it/s] 17%|█▋        | 15227/90000 [01:20<05:30, 226.16it/s] 17%|█▋        | 15250/90000 [01:20<05:31, 225.52it/s] 17%|█▋        | 15273/90000 [01:20<05:33, 224.07it/s] 17%|█▋        | 15297/90000 [01:20<05:29, 226.41it/s] 17%|█▋        | 15321/90000 [01:20<05:27, 227.88it/s] 17%|█▋        | 15344/90000 [01:20<05:29, 226.52it/s] 17%|█▋        | 15368/90000 [01:20<05:26, 228.27it/s] 17%|█▋        | 15391/90000 [01:20<05:28, 227.30it/s] 17%|█▋        | 15414/90000 [01:20<05:30, 225.85it/s] 17%|█▋        | 15437/90000 [01:21<05:35, 222.44it/s] 17%|█▋        | 15461/90000 [01:21<05:30, 225.55it/s] 17%|█▋        | 15485/90000 [01:21<05:24, 229.60it/s] 17%|█▋        | 15508/90000 [01:21<05:28, 227.09it/s] 17%|█▋        | 15531/90000 [01:21<05:32, 223.72it/s] 17%|█▋        | 15555/90000 [01:21<05:30, 225.30it/s] 17%|█▋        | 15580/90000 [01:21<05:22, 230.58it/s] 17%|█▋        | 15604/90000 [01:21<05:25, 228.48it/s] 17%|█▋        | 15628/90000 [01:21<05:24, 229.09it/s] 17%|█▋        | 15651/90000 [01:21<05:29, 225.53it/s] 17%|█▋        | 15674/90000 [01:22<05:32, 223.62it/s] 17%|█▋        | 15697/90000 [01:22<05:33, 222.80it/s] 17%|█▋        | 15722/90000 [01:22<05:25, 228.51it/s] 17%|█▋        | 15745/90000 [01:22<05:30, 224.41it/s] 18%|█▊        | 15769/90000 [01:22<05:27, 226.63it/s] 18%|█▊        | 15792/90000 [01:22<05:26, 227.01it/s] 18%|█▊        | 15816/90000 [01:22<05:23, 229.43it/s] 18%|█▊        | 15839/90000 [01:22<05:29, 225.35it/s] 18%|█▊        | 15863/90000 [01:22<05:25, 227.86it/s] 18%|█▊        | 15886/90000 [01:23<05:26, 226.90it/s] 18%|█▊        | 15910/90000 [01:23<05:23, 228.92it/s] 18%|█▊        | 15933/90000 [01:23<05:23, 229.12it/s] 18%|█▊        | 15956/90000 [01:23<05:24, 227.92it/s] 18%|█▊        | 15979/90000 [01:23<05:27, 225.70it/s] 18%|█▊        | 16003/90000 [01:23<05:22, 229.10it/s] 18%|█▊        | 16026/90000 [01:23<05:23, 228.97it/s] 18%|█▊        | 16049/90000 [01:23<05:30, 223.73it/s] 18%|█▊        | 16073/90000 [01:23<05:26, 226.46it/s] 18%|█▊        | 16096/90000 [01:23<05:31, 223.11it/s] 18%|█▊        | 16120/90000 [01:24<05:26, 226.38it/s] 18%|█▊        | 16143/90000 [01:24<05:28, 224.67it/s] 18%|█▊        | 16168/90000 [01:24<05:24, 227.81it/s] 18%|█▊        | 16191/90000 [01:24<05:23, 228.37it/s] 18%|█▊        | 16214/90000 [01:24<05:27, 225.56it/s] 18%|█▊        | 16237/90000 [01:24<05:26, 225.67it/s] 18%|█▊        | 16260/90000 [01:24<05:25, 226.22it/s] 18%|█▊        | 16283/90000 [01:24<05:26, 225.70it/s] 18%|█▊        | 16307/90000 [01:24<05:23, 227.95it/s] 18%|█▊        | 16330/90000 [01:24<05:27, 224.73it/s] 18%|█▊        | 16353/90000 [01:25<05:27, 224.96it/s] 18%|█▊        | 16377/90000 [01:25<05:22, 228.08it/s] 18%|█▊        | 16400/90000 [01:25<05:26, 225.37it/s] 18%|█▊        | 16423/90000 [01:25<05:30, 222.35it/s] 18%|█▊        | 16447/90000 [01:25<05:26, 225.04it/s] 18%|█▊        | 16470/90000 [01:25<05:25, 225.60it/s] 18%|█▊        | 16493/90000 [01:25<05:25, 226.15it/s] 18%|█▊        | 16517/90000 [01:25<05:23, 227.00it/s] 18%|█▊        | 16540/90000 [01:25<05:25, 225.59it/s] 18%|█▊        | 16564/90000 [01:25<05:22, 227.51it/s] 18%|█▊        | 16587/90000 [01:26<05:28, 223.81it/s] 18%|█▊        | 16610/90000 [01:26<05:33, 220.27it/s] 18%|█▊        | 16634/90000 [01:26<05:27, 224.32it/s] 19%|█▊        | 16657/90000 [01:26<05:31, 221.56it/s] 19%|█▊        | 16681/90000 [01:26<05:24, 225.62it/s] 19%|█▊        | 16704/90000 [01:26<05:26, 224.26it/s] 19%|█▊        | 16727/90000 [01:26<05:37, 217.42it/s] 19%|█▊        | 16750/90000 [01:26<05:34, 218.71it/s] 19%|█▊        | 16773/90000 [01:26<05:30, 221.43it/s] 19%|█▊        | 16796/90000 [01:27<05:31, 220.85it/s] 19%|█▊        | 16819/90000 [01:27<05:32, 220.41it/s] 19%|█▊        | 16842/90000 [01:27<05:30, 221.06it/s] 19%|█▊        | 16866/90000 [01:27<05:25, 224.91it/s] 19%|█▉        | 16889/90000 [01:27<05:27, 223.41it/s] 19%|█▉        | 16912/90000 [01:27<05:29, 221.97it/s] 19%|█▉        | 16935/90000 [01:27<05:31, 220.70it/s] 19%|█▉        | 16958/90000 [01:27<05:31, 220.66it/s] 19%|█▉        | 16981/90000 [01:27<05:32, 219.49it/s] 19%|█▉        | 17003/90000 [01:27<05:32, 219.26it/s] 19%|█▉        | 17025/90000 [01:28<05:37, 215.94it/s] 19%|█▉        | 17047/90000 [01:28<05:44, 212.03it/s] 19%|█▉        | 17071/90000 [01:28<05:31, 219.89it/s] 19%|█▉        | 17094/90000 [01:28<05:34, 217.94it/s] 19%|█▉        | 17118/90000 [01:28<05:29, 221.30it/s] 19%|█▉        | 17141/90000 [01:28<05:36, 216.39it/s] 19%|█▉        | 17163/90000 [01:28<05:38, 215.30it/s] 19%|█▉        | 17185/90000 [01:28<05:40, 214.15it/s] 19%|█▉        | 17207/90000 [01:28<05:38, 215.36it/s] 19%|█▉        | 17230/90000 [01:29<05:35, 217.20it/s] 19%|█▉        | 17252/90000 [01:29<05:41, 213.04it/s] 19%|█▉        | 17274/90000 [01:29<05:49, 208.38it/s] 19%|█▉        | 17296/90000 [01:29<05:44, 211.19it/s] 19%|█▉        | 17318/90000 [01:29<05:40, 213.47it/s] 19%|█▉        | 17340/90000 [01:29<05:46, 209.88it/s] 19%|█▉        | 17362/90000 [01:29<05:46, 209.88it/s] 19%|█▉        | 17384/90000 [01:29<05:43, 211.41it/s] 19%|█▉        | 17406/90000 [01:29<05:40, 213.07it/s] 19%|█▉        | 17429/90000 [01:29<05:33, 217.44it/s] 19%|█▉        | 17451/90000 [01:30<05:32, 217.92it/s] 19%|█▉        | 17474/90000 [01:30<05:29, 220.20it/s] 19%|█▉        | 17497/90000 [01:30<05:30, 219.63it/s] 19%|█▉        | 17519/90000 [01:30<05:31, 218.39it/s] 19%|█▉        | 17542/90000 [01:30<05:29, 220.20it/s] 20%|█▉        | 17565/90000 [01:30<05:38, 213.76it/s] 20%|█▉        | 17587/90000 [01:30<05:41, 212.12it/s] 20%|█▉        | 17609/90000 [01:30<05:37, 214.38it/s] 20%|█▉        | 17631/90000 [01:30<05:40, 212.71it/s] 20%|█▉        | 17653/90000 [01:31<05:39, 212.90it/s] 20%|█▉        | 17675/90000 [01:31<05:39, 212.99it/s] 20%|█▉        | 17697/90000 [01:31<05:38, 213.84it/s] 20%|█▉        | 17721/90000 [01:31<05:28, 219.99it/s] 20%|█▉        | 17744/90000 [01:31<05:28, 220.25it/s] 20%|█▉        | 17767/90000 [01:31<05:30, 218.24it/s] 20%|█▉        | 17789/90000 [01:31<05:31, 218.02it/s] 20%|█▉        | 17812/90000 [01:31<05:28, 219.50it/s] 20%|█▉        | 17837/90000 [01:31<05:19, 225.85it/s] 20%|█▉        | 17861/90000 [01:31<05:15, 228.60it/s] 20%|█▉        | 17884/90000 [01:32<05:21, 224.25it/s] 20%|█▉        | 17907/90000 [01:32<05:23, 222.87it/s] 20%|█▉        | 17930/90000 [01:32<05:27, 220.35it/s] 20%|█▉        | 17953/90000 [01:32<05:27, 219.66it/s] 20%|█▉        | 17976/90000 [01:32<05:26, 220.58it/s] 20%|█▉        | 17999/90000 [01:32<05:31, 217.26it/s] 20%|██        | 18023/90000 [01:32<05:23, 222.32it/s] 20%|██        | 18046/90000 [01:32<05:22, 223.03it/s] 20%|██        | 18069/90000 [01:32<05:23, 222.15it/s] 20%|██        | 18092/90000 [01:33<05:24, 221.63it/s] 20%|██        | 18115/90000 [01:33<05:25, 220.95it/s] 20%|██        | 18138/90000 [01:33<05:21, 223.51it/s] 20%|██        | 18162/90000 [01:33<05:16, 226.77it/s] 20%|██        | 18185/90000 [01:33<05:17, 225.88it/s] 20%|██        | 18209/90000 [01:33<05:13, 228.99it/s] 20%|██        | 18233/90000 [01:33<05:13, 229.28it/s] 20%|██        | 18257/90000 [01:33<05:11, 230.25it/s] 20%|██        | 18281/90000 [01:33<05:21, 222.98it/s] 20%|██        | 18304/90000 [01:33<05:20, 223.73it/s] 20%|██        | 18327/90000 [01:34<05:18, 224.97it/s] 20%|██        | 18350/90000 [01:34<05:17, 225.86it/s] 20%|██        | 18374/90000 [01:34<05:14, 227.66it/s] 20%|██        | 18397/90000 [01:34<05:13, 228.28it/s] 20%|██        | 18420/90000 [01:34<05:16, 226.11it/s] 20%|██        | 18445/90000 [01:34<05:09, 230.86it/s] 21%|██        | 18469/90000 [01:34<05:06, 233.24it/s] 21%|██        | 18493/90000 [01:34<05:14, 227.18it/s] 21%|██        | 18518/90000 [01:34<05:07, 232.46it/s] 21%|██        | 18542/90000 [01:34<05:15, 226.47it/s] 21%|██        | 18565/90000 [01:35<05:14, 226.80it/s] 21%|██        | 18590/90000 [01:35<05:08, 231.13it/s] 21%|██        | 18614/90000 [01:35<05:11, 229.11it/s] 21%|██        | 18638/90000 [01:35<05:09, 230.73it/s] 21%|██        | 18663/90000 [01:35<05:05, 233.49it/s] 21%|██        | 18687/90000 [01:35<05:08, 231.28it/s] 21%|██        | 18711/90000 [01:35<05:11, 228.96it/s] 21%|██        | 18734/90000 [01:35<05:15, 226.02it/s] 21%|██        | 18757/90000 [01:35<05:16, 225.19it/s] 21%|██        | 18781/90000 [01:36<05:11, 228.37it/s] 21%|██        | 18805/90000 [01:36<05:08, 231.09it/s] 21%|██        | 18829/90000 [01:36<05:09, 230.30it/s] 21%|██        | 18853/90000 [01:36<05:17, 224.09it/s] 21%|██        | 18876/90000 [01:36<05:17, 223.91it/s] 21%|██        | 18900/90000 [01:36<05:13, 227.07it/s] 21%|██        | 18923/90000 [01:36<05:13, 226.83it/s] 21%|██        | 18948/90000 [01:36<05:04, 232.98it/s] 21%|██        | 18972/90000 [01:36<05:06, 231.77it/s] 21%|██        | 18996/90000 [01:36<05:09, 229.31it/s] 21%|██        | 19020/90000 [01:37<05:09, 229.43it/s] 21%|██        | 19043/90000 [01:37<05:09, 229.07it/s] 21%|██        | 19068/90000 [01:37<05:05, 232.22it/s] 21%|██        | 19092/90000 [01:37<05:13, 226.26it/s] 21%|██        | 19116/90000 [01:37<05:11, 227.61it/s] 21%|██▏       | 19139/90000 [01:37<05:11, 227.22it/s] 21%|██▏       | 19163/90000 [01:37<05:08, 229.68it/s] 21%|██▏       | 19186/90000 [01:37<05:09, 228.84it/s] 21%|██▏       | 19211/90000 [01:37<05:06, 231.00it/s] 21%|██▏       | 19235/90000 [01:38<05:12, 226.65it/s] 21%|██▏       | 19259/90000 [01:38<05:07, 229.93it/s] 21%|██▏       | 19283/90000 [01:38<05:09, 228.23it/s] 21%|██▏       | 19306/90000 [01:38<05:13, 225.36it/s] 21%|██▏       | 19330/90000 [01:38<05:09, 228.69it/s] 22%|██▏       | 19353/90000 [01:38<05:10, 227.75it/s] 22%|██▏       | 19376/90000 [01:38<05:15, 223.90it/s] 22%|██▏       | 19401/90000 [01:38<05:07, 229.49it/s] 22%|██▏       | 19426/90000 [01:38<05:04, 231.73it/s] 22%|██▏       | 19450/90000 [01:38<05:01, 233.68it/s] 22%|██▏       | 19474/90000 [01:39<05:01, 233.76it/s] 22%|██▏       | 19499/90000 [01:39<04:57, 236.81it/s] 22%|██▏       | 19523/90000 [01:39<04:59, 234.99it/s] 22%|██▏       | 19547/90000 [01:39<05:05, 230.56it/s] 22%|██▏       | 19571/90000 [01:39<05:06, 230.13it/s] 22%|██▏       | 19595/90000 [01:39<05:04, 230.94it/s] 22%|██▏       | 19620/90000 [01:39<05:01, 233.47it/s] 22%|██▏       | 19644/90000 [01:39<05:02, 232.52it/s] 22%|██▏       | 19668/90000 [01:39<05:04, 230.67it/s] 22%|██▏       | 19692/90000 [01:39<05:01, 233.31it/s] 22%|██▏       | 19716/90000 [01:40<05:11, 225.79it/s] 22%|██▏       | 19741/90000 [01:40<05:05, 229.61it/s] 22%|██▏       | 19765/90000 [01:40<05:07, 228.30it/s] 22%|██▏       | 19788/90000 [01:40<05:07, 228.22it/s] 22%|██▏       | 19812/90000 [01:40<05:04, 230.17it/s] 22%|██▏       | 19838/90000 [01:40<04:56, 236.51it/s] 22%|██▏       | 19862/90000 [01:40<04:56, 236.52it/s] 22%|██▏       | 19887/90000 [01:40<04:53, 239.12it/s] 22%|██▏       | 19911/90000 [01:40<04:58, 234.43it/s] 22%|██▏       | 19935/90000 [01:41<05:03, 230.58it/s] 22%|██▏       | 19959/90000 [01:41<05:07, 227.51it/s] 22%|██▏       | 19983/90000 [01:41<05:08, 227.03it/s] 22%|██▏       | 20007/90000 [01:41<05:04, 229.60it/s] 22%|██▏       | 20030/90000 [01:41<05:12, 223.84it/s] 22%|██▏       | 20053/90000 [01:41<05:12, 223.95it/s] 22%|██▏       | 20077/90000 [01:41<05:07, 227.08it/s] 22%|██▏       | 20100/90000 [01:41<05:07, 227.46it/s] 22%|██▏       | 20123/90000 [01:41<05:07, 226.95it/s] 22%|██▏       | 20147/90000 [01:41<05:04, 229.16it/s] 22%|██▏       | 20171/90000 [01:42<05:01, 231.69it/s] 22%|██▏       | 20195/90000 [01:42<05:08, 226.32it/s] 22%|██▏       | 20218/90000 [01:42<05:12, 222.98it/s] 22%|██▏       | 20242/90000 [01:42<05:09, 225.67it/s] 23%|██▎       | 20266/90000 [01:42<05:05, 228.16it/s] 23%|██▎       | 20289/90000 [01:42<05:09, 224.99it/s] 23%|██▎       | 20313/90000 [01:42<05:08, 226.09it/s] 23%|██▎       | 20336/90000 [01:42<05:09, 224.78it/s] 23%|██▎       | 20359/90000 [01:42<05:10, 224.64it/s] 23%|██▎       | 20383/90000 [01:43<05:06, 227.28it/s] 23%|██▎       | 20407/90000 [01:43<05:04, 228.63it/s] 23%|██▎       | 20430/90000 [01:43<05:03, 228.99it/s] 23%|██▎       | 20454/90000 [01:43<05:01, 230.39it/s] 23%|██▎       | 20478/90000 [01:43<05:01, 230.48it/s] 23%|██▎       | 20502/90000 [01:43<04:59, 231.98it/s] 23%|██▎       | 20526/90000 [01:43<04:57, 233.60it/s] 23%|██▎       | 20550/90000 [01:43<05:03, 228.84it/s] 23%|██▎       | 20573/90000 [01:43<05:09, 223.97it/s] 23%|██▎       | 20598/90000 [01:43<05:02, 229.08it/s] 23%|██▎       | 20621/90000 [01:44<05:06, 226.05it/s] 23%|██▎       | 20644/90000 [01:44<05:14, 220.87it/s] 23%|██▎       | 20668/90000 [01:44<05:09, 223.91it/s] 23%|██▎       | 20691/90000 [01:44<05:07, 225.40it/s] 23%|██▎       | 20715/90000 [01:44<05:05, 226.77it/s] 23%|██▎       | 20738/90000 [01:44<05:07, 225.24it/s] 23%|██▎       | 20761/90000 [01:44<05:08, 224.20it/s] 23%|██▎       | 20784/90000 [01:44<05:06, 225.66it/s] 23%|██▎       | 20807/90000 [01:44<05:08, 224.44it/s] 23%|██▎       | 20830/90000 [01:44<05:07, 224.91it/s] 23%|██▎       | 20853/90000 [01:45<05:08, 224.34it/s] 23%|██▎       | 20876/90000 [01:45<05:06, 225.87it/s] 23%|██▎       | 20900/90000 [01:45<05:02, 228.16it/s] 23%|██▎       | 20925/90000 [01:45<04:56, 233.12it/s] 23%|██▎       | 20949/90000 [01:45<04:57, 231.96it/s] 23%|██▎       | 20973/90000 [01:45<04:55, 233.52it/s] 23%|██▎       | 20997/90000 [01:45<04:56, 233.10it/s] 23%|██▎       | 21022/90000 [01:45<04:52, 235.86it/s] 23%|██▎       | 21046/90000 [01:45<04:57, 232.15it/s] 23%|██▎       | 21070/90000 [01:46<04:56, 232.84it/s] 23%|██▎       | 21094/90000 [01:46<05:05, 225.73it/s] 23%|██▎       | 21117/90000 [01:46<05:04, 226.30it/s] 23%|██▎       | 21141/90000 [01:46<05:01, 228.72it/s] 24%|██▎       | 21164/90000 [01:46<05:03, 226.79it/s] 24%|██▎       | 21188/90000 [01:46<04:59, 230.11it/s] 24%|██▎       | 21212/90000 [01:46<05:00, 228.55it/s] 24%|██▎       | 21235/90000 [01:46<05:03, 226.34it/s] 24%|██▎       | 21259/90000 [01:46<05:02, 227.27it/s] 24%|██▎       | 21283/90000 [01:46<04:57, 230.65it/s] 24%|██▎       | 21307/90000 [01:47<04:59, 229.70it/s] 24%|██▎       | 21330/90000 [01:47<05:01, 227.71it/s] 24%|██▎       | 21354/90000 [01:47<04:58, 229.70it/s] 24%|██▍       | 21378/90000 [01:47<04:55, 232.25it/s] 24%|██▍       | 21402/90000 [01:47<04:56, 231.45it/s] 24%|██▍       | 21426/90000 [01:47<04:54, 233.03it/s] 24%|██▍       | 21450/90000 [01:47<05:01, 227.51it/s] 24%|██▍       | 21475/90000 [01:47<04:55, 231.64it/s] 24%|██▍       | 21500/90000 [01:47<04:52, 234.07it/s] 24%|██▍       | 21524/90000 [01:47<04:58, 229.69it/s] 24%|██▍       | 21548/90000 [01:48<04:54, 232.58it/s] 24%|██▍       | 21572/90000 [01:48<04:58, 229.55it/s] 24%|██▍       | 21595/90000 [01:48<04:59, 228.66it/s] 24%|██▍       | 21618/90000 [01:48<04:59, 228.66it/s] 24%|██▍       | 21642/90000 [01:48<04:56, 230.19it/s] 24%|██▍       | 21666/90000 [01:48<04:54, 231.93it/s] 24%|██▍       | 21691/90000 [01:48<04:48, 237.08it/s] 24%|██▍       | 21715/90000 [01:48<04:50, 234.93it/s] 24%|██▍       | 21740/90000 [01:48<04:46, 238.41it/s] 24%|██▍       | 21764/90000 [01:49<04:53, 232.67it/s] 24%|██▍       | 21789/90000 [01:49<04:48, 236.24it/s] 24%|██▍       | 21813/90000 [01:49<04:47, 237.15it/s] 24%|██▍       | 21837/90000 [01:49<04:48, 236.15it/s] 24%|██▍       | 21861/90000 [01:49<04:52, 232.82it/s] 24%|██▍       | 21886/90000 [01:49<04:49, 234.97it/s] 24%|██▍       | 21910/90000 [01:49<04:52, 233.02it/s] 24%|██▍       | 21934/90000 [01:49<04:51, 233.38it/s] 24%|██▍       | 21959/90000 [01:49<04:48, 235.95it/s] 24%|██▍       | 21983/90000 [01:49<04:52, 232.63it/s] 24%|██▍       | 22007/90000 [01:50<04:53, 231.86it/s] 24%|██▍       | 22031/90000 [01:50<04:55, 229.80it/s] 25%|██▍       | 22055/90000 [01:50<04:53, 231.65it/s] 25%|██▍       | 22079/90000 [01:50<04:53, 231.10it/s] 25%|██▍       | 22103/90000 [01:50<04:52, 231.82it/s] 25%|██▍       | 22128/90000 [01:50<04:50, 233.94it/s] 25%|██▍       | 22152/90000 [01:50<04:56, 229.13it/s] 25%|██▍       | 22175/90000 [01:50<04:58, 227.40it/s] 25%|██▍       | 22199/90000 [01:50<04:55, 229.57it/s] 25%|██▍       | 22223/90000 [01:50<04:52, 231.84it/s] 25%|██▍       | 22247/90000 [01:51<04:50, 233.02it/s] 25%|██▍       | 22271/90000 [01:51<04:48, 234.58it/s] 25%|██▍       | 22295/90000 [01:51<04:48, 234.28it/s] 25%|██▍       | 22319/90000 [01:51<04:51, 232.45it/s] 25%|██▍       | 22343/90000 [01:51<04:50, 232.92it/s] 25%|██▍       | 22367/90000 [01:51<04:53, 230.13it/s] 25%|██▍       | 22391/90000 [01:51<04:50, 232.67it/s] 25%|██▍       | 22415/90000 [01:51<04:53, 230.62it/s] 25%|██▍       | 22439/90000 [01:51<04:57, 227.21it/s] 25%|██▍       | 22463/90000 [01:52<04:52, 230.67it/s] 25%|██▍       | 22487/90000 [01:52<04:50, 232.70it/s] 25%|██▌       | 22512/90000 [01:52<04:44, 237.20it/s] 25%|██▌       | 22536/90000 [01:52<04:48, 233.84it/s] 25%|██▌       | 22561/90000 [01:52<04:45, 236.02it/s] 25%|██▌       | 22585/90000 [01:52<04:45, 236.29it/s] 25%|██▌       | 22609/90000 [01:52<04:45, 236.01it/s] 25%|██▌       | 22633/90000 [01:52<04:44, 237.06it/s] 25%|██▌       | 22657/90000 [01:52<04:47, 233.89it/s] 25%|██▌       | 22682/90000 [01:52<04:45, 235.72it/s] 25%|██▌       | 22706/90000 [01:53<04:44, 236.92it/s] 25%|██▌       | 22730/90000 [01:53<04:46, 234.96it/s] 25%|██▌       | 22754/90000 [01:53<04:46, 234.65it/s] 25%|██▌       | 22778/90000 [01:53<04:46, 234.55it/s] 25%|██▌       | 22802/90000 [01:53<04:46, 234.33it/s] 25%|██▌       | 22826/90000 [01:53<04:48, 232.56it/s] 25%|██▌       | 22851/90000 [01:53<04:45, 235.36it/s] 25%|██▌       | 22875/90000 [01:53<04:47, 233.17it/s] 25%|██▌       | 22899/90000 [01:53<04:49, 231.75it/s] 25%|██▌       | 22924/90000 [01:53<04:45, 235.08it/s] 25%|██▌       | 22948/90000 [01:54<04:49, 231.67it/s] 26%|██▌       | 22972/90000 [01:54<04:47, 232.96it/s] 26%|██▌       | 22997/90000 [01:54<04:43, 235.96it/s] 26%|██▌       | 23021/90000 [01:54<04:46, 234.01it/s] 26%|██▌       | 23045/90000 [01:54<04:49, 231.62it/s] 26%|██▌       | 23070/90000 [01:54<04:44, 235.25it/s] 26%|██▌       | 23094/90000 [01:54<04:48, 231.86it/s] 26%|██▌       | 23118/90000 [01:54<04:49, 231.06it/s] 26%|██▌       | 23142/90000 [01:54<04:50, 230.03it/s] 26%|██▌       | 23166/90000 [01:55<04:48, 231.28it/s] 26%|██▌       | 23190/90000 [01:55<04:47, 232.12it/s] 26%|██▌       | 23214/90000 [01:55<04:48, 231.62it/s] 26%|██▌       | 23238/90000 [01:55<04:48, 231.18it/s] 26%|██▌       | 23262/90000 [01:55<04:48, 231.39it/s] 26%|██▌       | 23286/90000 [01:55<04:48, 231.35it/s] 26%|██▌       | 23311/90000 [01:55<04:43, 234.86it/s] 26%|██▌       | 23335/90000 [01:55<04:46, 232.89it/s] 26%|██▌       | 23359/90000 [01:55<04:46, 232.78it/s] 26%|██▌       | 23383/90000 [01:55<04:49, 229.88it/s] 26%|██▌       | 23406/90000 [01:56<04:50, 229.18it/s] 26%|██▌       | 23431/90000 [01:56<04:45, 232.92it/s] 26%|██▌       | 23455/90000 [01:56<04:48, 230.68it/s] 26%|██▌       | 23479/90000 [01:56<04:46, 231.86it/s] 26%|██▌       | 23503/90000 [01:56<04:45, 233.32it/s] 26%|██▌       | 23527/90000 [01:56<04:47, 231.03it/s] 26%|██▌       | 23551/90000 [01:56<04:51, 228.19it/s] 26%|██▌       | 23575/90000 [01:56<04:47, 230.73it/s] 26%|██▌       | 23599/90000 [01:56<04:46, 231.97it/s] 26%|██▌       | 23623/90000 [01:57<04:46, 231.92it/s] 26%|██▋       | 23647/90000 [01:57<04:43, 233.75it/s] 26%|██▋       | 23672/90000 [01:57<04:40, 236.05it/s] 26%|██▋       | 23696/90000 [01:57<04:39, 237.09it/s] 26%|██▋       | 23721/90000 [01:57<04:37, 238.99it/s] 26%|██▋       | 23745/90000 [01:57<04:37, 238.41it/s] 26%|██▋       | 23769/90000 [01:57<04:41, 234.96it/s] 26%|██▋       | 23793/90000 [01:57<04:43, 233.36it/s] 26%|██▋       | 23817/90000 [01:57<04:43, 233.85it/s] 26%|██▋       | 23841/90000 [01:57<04:44, 232.28it/s] 27%|██▋       | 23865/90000 [01:58<04:48, 229.39it/s] 27%|██▋       | 23889/90000 [01:58<04:47, 229.77it/s] 27%|██▋       | 23912/90000 [01:58<04:48, 229.07it/s] 27%|██▋       | 23935/90000 [01:58<04:48, 228.84it/s] 27%|██▋       | 23959/90000 [01:58<04:47, 229.36it/s] 27%|██▋       | 23983/90000 [01:58<04:45, 231.43it/s] 27%|██▋       | 24007/90000 [01:58<04:49, 228.18it/s] 27%|██▋       | 24033/90000 [01:58<04:40, 235.20it/s] 27%|██▋       | 24057/90000 [01:58<04:44, 231.66it/s] 27%|██▋       | 24081/90000 [01:58<04:49, 227.61it/s] 27%|██▋       | 24105/90000 [01:59<04:45, 230.83it/s] 27%|██▋       | 24129/90000 [01:59<04:44, 231.40it/s] 27%|██▋       | 24154/90000 [01:59<04:40, 234.66it/s] 27%|██▋       | 24178/90000 [01:59<04:47, 228.71it/s] 27%|██▋       | 24203/90000 [01:59<04:40, 234.77it/s] 27%|██▋       | 24227/90000 [01:59<04:39, 235.26it/s] 27%|██▋       | 24251/90000 [01:59<04:38, 236.05it/s] 27%|██▋       | 24275/90000 [01:59<04:41, 233.57it/s] 27%|██▋       | 24299/90000 [01:59<04:41, 233.47it/s] 27%|██▋       | 24323/90000 [02:00<04:44, 230.55it/s] 27%|██▋       | 24347/90000 [02:00<04:45, 230.29it/s] 27%|██▋       | 24371/90000 [02:00<04:45, 229.72it/s] 27%|██▋       | 24394/90000 [02:00<04:47, 228.40it/s] 27%|██▋       | 24418/90000 [02:00<04:44, 230.89it/s] 27%|██▋       | 24442/90000 [02:00<04:48, 226.98it/s] 27%|██▋       | 24467/90000 [02:00<04:41, 232.47it/s] 27%|██▋       | 24491/90000 [02:00<04:39, 234.50it/s] 27%|██▋       | 24516/90000 [02:00<04:37, 236.28it/s] 27%|██▋       | 24540/90000 [02:00<04:41, 232.58it/s] 27%|██▋       | 24564/90000 [02:01<04:40, 233.41it/s] 27%|██▋       | 24588/90000 [02:01<04:39, 234.06it/s] 27%|██▋       | 24612/90000 [02:01<04:38, 234.72it/s] 27%|██▋       | 24636/90000 [02:01<04:40, 232.89it/s] 27%|██▋       | 24661/90000 [02:01<04:37, 235.84it/s] 27%|██▋       | 24686/90000 [02:01<04:33, 239.17it/s] 27%|██▋       | 24710/90000 [02:01<04:36, 235.96it/s] 27%|██▋       | 24734/90000 [02:01<04:37, 235.49it/s] 28%|██▊       | 24759/90000 [02:01<04:34, 237.72it/s] 28%|██▊       | 24783/90000 [02:01<04:40, 232.35it/s] 28%|██▊       | 24807/90000 [02:02<04:42, 230.69it/s] 28%|██▊       | 24832/90000 [02:02<04:38, 234.25it/s] 28%|██▊       | 24856/90000 [02:02<04:39, 233.48it/s] 28%|██▊       | 24880/90000 [02:02<04:41, 230.98it/s] 28%|██▊       | 24904/90000 [02:02<04:45, 227.76it/s] 28%|██▊       | 24927/90000 [02:02<04:51, 223.51it/s] 28%|██▊       | 24950/90000 [02:02<04:48, 225.20it/s] 28%|██▊       | 24973/90000 [02:02<04:47, 226.41it/s] 28%|██▊       | 24996/90000 [02:02<04:48, 225.37it/s] 28%|██▊       | 25019/90000 [02:03<04:47, 226.33it/s] 28%|██▊       | 25042/90000 [02:03<04:48, 225.18it/s] 28%|██▊       | 25066/90000 [02:03<04:45, 227.61it/s] 28%|██▊       | 25089/90000 [02:03<04:48, 224.70it/s] 28%|██▊       | 25113/90000 [02:03<04:44, 227.92it/s] 28%|██▊       | 25137/90000 [02:03<04:42, 229.75it/s] 28%|██▊       | 25161/90000 [02:03<04:38, 232.61it/s] 28%|██▊       | 25186/90000 [02:03<04:34, 236.51it/s] 28%|██▊       | 25210/90000 [02:03<04:34, 236.19it/s] 28%|██▊       | 25234/90000 [02:03<04:33, 237.01it/s] 28%|██▊       | 25259/90000 [02:04<04:30, 239.01it/s] 28%|██▊       | 25283/90000 [02:04<04:33, 236.72it/s] 28%|██▊       | 25307/90000 [02:04<04:33, 236.37it/s] 28%|██▊       | 25331/90000 [02:04<04:35, 234.56it/s] 28%|██▊       | 25355/90000 [02:04<04:36, 233.60it/s] 28%|██▊       | 25379/90000 [02:04<04:38, 231.74it/s] 28%|██▊       | 25403/90000 [02:04<04:36, 233.45it/s] 28%|██▊       | 25429/90000 [02:04<04:30, 238.50it/s] 28%|██▊       | 25454/90000 [02:04<04:28, 240.46it/s] 28%|██▊       | 25479/90000 [02:04<04:32, 236.37it/s] 28%|██▊       | 25504/90000 [02:05<04:31, 237.76it/s] 28%|██▊       | 25528/90000 [02:05<04:34, 234.71it/s] 28%|██▊       | 25552/90000 [02:05<04:37, 232.28it/s] 28%|██▊       | 25576/90000 [02:05<04:37, 232.25it/s] 28%|██▊       | 25600/90000 [02:05<04:37, 232.23it/s] 28%|██▊       | 25624/90000 [02:05<04:40, 229.34it/s] 28%|██▊       | 25649/90000 [02:05<04:35, 233.49it/s] 29%|██▊       | 25673/90000 [02:05<04:35, 233.68it/s] 29%|██▊       | 25697/90000 [02:05<04:34, 234.15it/s] 29%|██▊       | 25721/90000 [02:06<04:33, 235.03it/s] 29%|██▊       | 25745/90000 [02:06<04:37, 231.18it/s] 29%|██▊       | 25769/90000 [02:06<04:35, 233.27it/s] 29%|██▊       | 25793/90000 [02:06<04:43, 226.33it/s] 29%|██▊       | 25816/90000 [02:06<04:47, 223.00it/s] 29%|██▊       | 25839/90000 [02:06<04:51, 219.83it/s] 29%|██▊       | 25863/90000 [02:06<04:44, 225.26it/s] 29%|██▉       | 25887/90000 [02:06<04:41, 227.53it/s] 29%|██▉       | 25910/90000 [02:06<04:49, 221.62it/s] 29%|██▉       | 25933/90000 [02:06<04:46, 223.95it/s] 29%|██▉       | 25958/90000 [02:07<04:38, 229.93it/s] 29%|██▉       | 25983/90000 [02:07<04:32, 234.92it/s] 29%|██▉       | 26007/90000 [02:07<04:33, 233.88it/s] 29%|██▉       | 26032/90000 [02:07<04:30, 236.18it/s] 29%|██▉       | 26057/90000 [02:07<04:29, 237.65it/s] 29%|██▉       | 26081/90000 [02:07<04:30, 236.24it/s] 29%|██▉       | 26105/90000 [02:07<04:33, 233.92it/s] 29%|██▉       | 26129/90000 [02:07<04:34, 233.04it/s] 29%|██▉       | 26153/90000 [02:07<04:32, 234.38it/s] 29%|██▉       | 26177/90000 [02:08<04:32, 234.46it/s] 29%|██▉       | 26201/90000 [02:08<04:33, 233.44it/s] 29%|██▉       | 26225/90000 [02:08<04:35, 231.56it/s] 29%|██▉       | 26249/90000 [02:08<04:33, 233.17it/s] 29%|██▉       | 26273/90000 [02:08<04:32, 234.22it/s] 29%|██▉       | 26297/90000 [02:08<04:31, 234.52it/s] 29%|██▉       | 26322/90000 [02:08<04:29, 236.46it/s] 29%|██▉       | 26346/90000 [02:08<04:32, 233.36it/s] 29%|██▉       | 26370/90000 [02:08<04:35, 231.31it/s] 29%|██▉       | 26395/90000 [02:08<04:30, 235.33it/s] 29%|██▉       | 26420/90000 [02:09<04:26, 238.31it/s] 29%|██▉       | 26444/90000 [02:09<04:26, 238.39it/s] 29%|██▉       | 26468/90000 [02:09<04:26, 238.21it/s] 29%|██▉       | 26492/90000 [02:09<04:27, 237.34it/s] 29%|██▉       | 26516/90000 [02:09<04:29, 235.78it/s] 29%|██▉       | 26540/90000 [02:09<04:31, 233.32it/s] 30%|██▉       | 26565/90000 [02:09<04:27, 237.42it/s] 30%|██▉       | 26589/90000 [02:09<04:26, 238.02it/s] 30%|██▉       | 26614/90000 [02:09<04:23, 240.91it/s] 30%|██▉       | 26639/90000 [02:09<04:22, 241.32it/s] 30%|██▉       | 26664/90000 [02:10<04:24, 239.82it/s] 30%|██▉       | 26688/90000 [02:10<04:25, 238.11it/s] 30%|██▉       | 26712/90000 [02:10<04:33, 231.08it/s] 30%|██▉       | 26737/90000 [02:10<04:30, 233.88it/s] 30%|██▉       | 26762/90000 [02:10<04:27, 236.10it/s] 30%|██▉       | 26786/90000 [02:10<04:30, 233.91it/s] 30%|██▉       | 26810/90000 [02:10<04:32, 232.28it/s] 30%|██▉       | 26834/90000 [02:10<04:30, 233.88it/s] 30%|██▉       | 26858/90000 [02:10<04:30, 233.01it/s] 30%|██▉       | 26882/90000 [02:11<04:33, 230.94it/s] 30%|██▉       | 26906/90000 [02:11<04:33, 230.55it/s] 30%|██▉       | 26930/90000 [02:11<04:36, 228.51it/s] 30%|██▉       | 26954/90000 [02:11<04:33, 230.89it/s] 30%|██▉       | 26978/90000 [02:11<04:31, 231.81it/s] 30%|███       | 27002/90000 [02:11<04:32, 231.44it/s] 30%|███       | 27026/90000 [02:11<04:36, 227.63it/s] 30%|███       | 27052/90000 [02:11<04:27, 235.47it/s] 30%|███       | 27076/90000 [02:11<04:29, 233.67it/s] 30%|███       | 27100/90000 [02:11<04:29, 233.35it/s] 30%|███       | 27124/90000 [02:12<04:35, 228.57it/s] 30%|███       | 27149/90000 [02:12<04:31, 231.22it/s] 30%|███       | 27174/90000 [02:12<04:28, 234.18it/s] 30%|███       | 27198/90000 [02:12<04:29, 232.71it/s] 30%|███       | 27222/90000 [02:12<04:28, 233.50it/s] 30%|███       | 27246/90000 [02:12<04:27, 234.69it/s] 30%|███       | 27270/90000 [02:12<04:29, 232.98it/s] 30%|███       | 27294/90000 [02:12<04:31, 231.07it/s] 30%|███       | 27318/90000 [02:12<04:30, 231.69it/s] 30%|███       | 27342/90000 [02:12<04:29, 232.31it/s] 30%|███       | 27366/90000 [02:13<04:31, 230.50it/s] 30%|███       | 27391/90000 [02:13<04:27, 233.80it/s] 30%|███       | 27415/90000 [02:13<04:30, 231.71it/s] 30%|███       | 27439/90000 [02:13<04:27, 233.83it/s] 31%|███       | 27464/90000 [02:13<04:25, 235.76it/s] 31%|███       | 27488/90000 [02:13<04:24, 236.42it/s] 31%|███       | 27512/90000 [02:13<04:24, 235.86it/s] 31%|███       | 27538/90000 [02:13<04:19, 240.57it/s] 31%|███       | 27563/90000 [02:13<04:20, 239.93it/s] 31%|███       | 27587/90000 [02:14<04:23, 236.52it/s] 31%|███       | 27611/90000 [02:14<04:29, 231.28it/s] 31%|███       | 27635/90000 [02:14<04:35, 226.05it/s] 31%|███       | 27659/90000 [02:14<04:32, 228.66it/s] 31%|███       | 27682/90000 [02:14<04:32, 229.02it/s] 31%|███       | 27706/90000 [02:14<04:31, 229.52it/s] 31%|███       | 27729/90000 [02:14<04:32, 228.59it/s] 31%|███       | 27752/90000 [02:14<04:41, 220.95it/s] 31%|███       | 27776/90000 [02:14<04:37, 224.03it/s] 31%|███       | 27800/90000 [02:14<04:33, 227.71it/s] 31%|███       | 27825/90000 [02:15<04:28, 231.68it/s] 31%|███       | 27849/90000 [02:15<04:27, 232.46it/s] 31%|███       | 27873/90000 [02:15<04:27, 231.91it/s] 31%|███       | 27898/90000 [02:15<04:22, 236.23it/s] 31%|███       | 27922/90000 [02:15<04:26, 233.00it/s] 31%|███       | 27946/90000 [02:15<04:28, 231.16it/s] 31%|███       | 27970/90000 [02:15<04:25, 233.38it/s] 31%|███       | 27994/90000 [02:15<04:29, 230.01it/s] 31%|███       | 28018/90000 [02:15<04:27, 231.62it/s] 31%|███       | 28042/90000 [02:16<04:26, 232.13it/s] 31%|███       | 28067/90000 [02:16<04:22, 235.61it/s] 31%|███       | 28092/90000 [02:16<04:19, 238.57it/s] 31%|███       | 28116/90000 [02:16<04:23, 235.28it/s] 31%|███▏      | 28140/90000 [02:16<04:21, 236.20it/s] 31%|███▏      | 28164/90000 [02:16<04:23, 234.96it/s] 31%|███▏      | 28188/90000 [02:16<04:22, 235.73it/s] 31%|███▏      | 28212/90000 [02:16<04:21, 236.56it/s] 31%|███▏      | 28236/90000 [02:16<04:22, 235.48it/s] 31%|███▏      | 28260/90000 [02:16<04:25, 232.23it/s] 31%|███▏      | 28284/90000 [02:17<04:27, 230.39it/s] 31%|███▏      | 28308/90000 [02:17<04:26, 231.62it/s] 31%|███▏      | 28332/90000 [02:17<04:23, 233.77it/s] 32%|███▏      | 28356/90000 [02:17<04:25, 231.84it/s] 32%|███▏      | 28380/90000 [02:17<04:29, 228.76it/s] 32%|███▏      | 28405/90000 [02:17<04:25, 232.35it/s] 32%|███▏      | 28429/90000 [02:17<04:27, 230.12it/s] 32%|███▏      | 28454/90000 [02:17<04:23, 233.78it/s] 32%|███▏      | 28478/90000 [02:17<04:28, 229.13it/s] 32%|███▏      | 28501/90000 [02:17<04:28, 229.17it/s] 32%|███▏      | 28524/90000 [02:18<04:32, 225.61it/s] 32%|███▏      | 28547/90000 [02:18<04:31, 226.04it/s] 32%|███▏      | 28573/90000 [02:18<04:23, 233.03it/s] 32%|███▏      | 28597/90000 [02:18<04:23, 232.63it/s] 32%|███▏      | 28621/90000 [02:18<04:22, 233.38it/s] 32%|███▏      | 28645/90000 [02:18<04:21, 234.73it/s] 32%|███▏      | 28669/90000 [02:18<04:25, 230.78it/s] 32%|███▏      | 28694/90000 [02:18<04:20, 235.70it/s] 32%|███▏      | 28718/90000 [02:18<04:21, 234.43it/s] 32%|███▏      | 28742/90000 [02:19<04:21, 233.88it/s] 32%|███▏      | 28766/90000 [02:19<04:22, 233.05it/s] 32%|███▏      | 28790/90000 [02:19<04:27, 229.09it/s] 32%|███▏      | 28813/90000 [02:19<04:32, 224.40it/s] 32%|███▏      | 28838/90000 [02:19<04:25, 230.54it/s] 32%|███▏      | 28862/90000 [02:19<04:30, 225.75it/s] 32%|███▏      | 28886/90000 [02:19<04:28, 227.66it/s] 32%|███▏      | 28910/90000 [02:19<04:24, 230.86it/s] 32%|███▏      | 28934/90000 [02:19<04:25, 229.72it/s] 32%|███▏      | 28957/90000 [02:19<04:30, 225.39it/s] 32%|███▏      | 28980/90000 [02:20<04:31, 225.06it/s] 32%|███▏      | 29004/90000 [02:20<04:27, 228.07it/s] 32%|███▏      | 29028/90000 [02:20<04:26, 228.82it/s] 32%|███▏      | 29051/90000 [02:20<04:27, 227.71it/s] 32%|███▏      | 29074/90000 [02:20<04:30, 225.60it/s] 32%|███▏      | 29097/90000 [02:20<04:33, 222.90it/s] 32%|███▏      | 29120/90000 [02:20<04:39, 217.84it/s] 32%|███▏      | 29143/90000 [02:20<04:38, 218.54it/s] 32%|███▏      | 29165/90000 [02:20<04:39, 217.91it/s] 32%|███▏      | 29187/90000 [02:21<04:39, 217.42it/s] 32%|███▏      | 29209/90000 [02:21<04:39, 217.80it/s] 32%|███▏      | 29232/90000 [02:21<04:36, 219.80it/s] 33%|███▎      | 29255/90000 [02:21<04:35, 220.13it/s] 33%|███▎      | 29278/90000 [02:21<04:37, 219.06it/s] 33%|███▎      | 29300/90000 [02:21<04:39, 217.11it/s] 33%|███▎      | 29322/90000 [02:21<04:39, 217.20it/s] 33%|███▎      | 29344/90000 [02:21<04:40, 216.22it/s] 33%|███▎      | 29368/90000 [02:21<04:35, 220.11it/s] 33%|███▎      | 29391/90000 [02:21<04:40, 216.09it/s] 33%|███▎      | 29414/90000 [02:22<04:38, 217.55it/s] 33%|███▎      | 29437/90000 [02:22<04:36, 218.91it/s] 33%|███▎      | 29459/90000 [02:22<04:37, 217.79it/s] 33%|███▎      | 29481/90000 [02:22<04:38, 217.03it/s] 33%|███▎      | 29504/90000 [02:22<04:36, 218.74it/s] 33%|███▎      | 29526/90000 [02:22<04:42, 214.00it/s] 33%|███▎      | 29548/90000 [02:22<04:47, 209.98it/s] 33%|███▎      | 29570/90000 [02:22<04:44, 212.53it/s] 33%|███▎      | 29592/90000 [02:22<04:44, 212.34it/s] 33%|███▎      | 29614/90000 [02:22<04:45, 211.83it/s] 33%|███▎      | 29636/90000 [02:23<04:42, 213.90it/s] 33%|███▎      | 29658/90000 [02:23<04:40, 214.83it/s] 33%|███▎      | 29680/90000 [02:23<04:42, 213.56it/s] 33%|███▎      | 29702/90000 [02:23<04:43, 212.43it/s] 33%|███▎      | 29726/90000 [02:23<04:34, 219.67it/s] 33%|███▎      | 29748/90000 [02:23<04:35, 218.70it/s] 33%|███▎      | 29770/90000 [02:23<04:35, 218.44it/s] 33%|███▎      | 29794/90000 [02:23<04:27, 224.72it/s] 33%|███▎      | 29817/90000 [02:23<04:29, 223.14it/s] 33%|███▎      | 29841/90000 [02:24<04:25, 226.46it/s] 33%|███▎      | 29865/90000 [02:24<04:23, 228.10it/s] 33%|███▎      | 29888/90000 [02:24<04:31, 221.12it/s] 33%|███▎      | 29911/90000 [02:24<04:30, 222.15it/s] 33%|███▎      | 29934/90000 [02:24<04:30, 221.74it/s] 33%|███▎      | 29957/90000 [02:24<04:29, 222.65it/s] 33%|███▎      | 29980/90000 [02:24<04:29, 222.44it/s] 33%|███▎      | 30004/90000 [02:24<04:25, 225.57it/s] 33%|███▎      | 30030/90000 [02:24<04:17, 232.61it/s] 33%|███▎      | 30054/90000 [02:24<04:16, 234.15it/s] 33%|███▎      | 30078/90000 [02:25<04:21, 229.04it/s] 33%|███▎      | 30101/90000 [02:25<04:27, 223.65it/s] 33%|███▎      | 30124/90000 [02:25<04:26, 224.53it/s] 33%|███▎      | 30147/90000 [02:25<04:25, 225.31it/s] 34%|███▎      | 30170/90000 [02:25<04:24, 226.63it/s] 34%|███▎      | 30194/90000 [02:25<04:23, 227.08it/s] 34%|███▎      | 30217/90000 [02:25<04:29, 221.84it/s] 34%|███▎      | 30241/90000 [02:25<04:26, 224.41it/s] 34%|███▎      | 30264/90000 [02:25<04:26, 224.36it/s] 34%|███▎      | 30287/90000 [02:25<04:26, 224.07it/s] 34%|███▎      | 30310/90000 [02:26<04:28, 222.16it/s] 34%|███▎      | 30333/90000 [02:26<04:27, 222.68it/s] 34%|███▎      | 30356/90000 [02:26<04:25, 224.81it/s] 34%|███▍      | 30380/90000 [02:26<04:23, 226.52it/s] 34%|███▍      | 30404/90000 [02:26<04:19, 229.43it/s] 34%|███▍      | 30428/90000 [02:26<04:19, 229.50it/s] 34%|███▍      | 30451/90000 [02:26<04:25, 224.67it/s] 34%|███▍      | 30476/90000 [02:26<04:18, 230.14it/s] 34%|███▍      | 30500/90000 [02:26<04:16, 231.84it/s] 34%|███▍      | 30524/90000 [02:27<04:19, 229.00it/s] 34%|███▍      | 30547/90000 [02:27<04:19, 228.98it/s] 34%|███▍      | 30570/90000 [02:27<04:19, 229.21it/s] 34%|███▍      | 30595/90000 [02:27<04:15, 232.06it/s] 34%|███▍      | 30619/90000 [02:27<04:14, 232.95it/s] 34%|███▍      | 30643/90000 [02:27<04:19, 229.10it/s] 34%|███▍      | 30667/90000 [02:27<04:15, 232.18it/s] 34%|███▍      | 30691/90000 [02:27<04:14, 232.96it/s] 34%|███▍      | 30715/90000 [02:27<04:20, 227.45it/s] 34%|███▍      | 30740/90000 [02:27<04:15, 231.59it/s] 34%|███▍      | 30765/90000 [02:28<04:13, 234.00it/s] 34%|███▍      | 30789/90000 [02:28<04:16, 230.80it/s] 34%|███▍      | 30813/90000 [02:28<04:17, 230.19it/s] 34%|███▍      | 30837/90000 [02:28<04:17, 229.54it/s] 34%|███▍      | 30860/90000 [02:28<04:19, 228.13it/s] 34%|███▍      | 30884/90000 [02:28<04:15, 231.44it/s] 34%|███▍      | 30908/90000 [02:28<04:16, 230.42it/s] 34%|███▍      | 30932/90000 [02:28<04:19, 228.05it/s] 34%|███▍      | 30955/90000 [02:28<04:20, 226.36it/s] 34%|███▍      | 30978/90000 [02:28<04:19, 227.19it/s] 34%|███▍      | 31001/90000 [02:29<04:20, 226.53it/s] 34%|███▍      | 31024/90000 [02:29<04:24, 223.30it/s] 34%|███▍      | 31048/90000 [02:29<04:18, 227.65it/s] 35%|███▍      | 31071/90000 [02:29<04:20, 226.56it/s] 35%|███▍      | 31094/90000 [02:29<04:24, 222.39it/s] 35%|███▍      | 31118/90000 [02:29<04:21, 225.48it/s] 35%|███▍      | 31141/90000 [02:29<04:25, 221.74it/s] 35%|███▍      | 31164/90000 [02:29<04:27, 220.20it/s] 35%|███▍      | 31187/90000 [02:29<04:24, 221.96it/s] 35%|███▍      | 31210/90000 [02:30<04:22, 223.66it/s] 35%|███▍      | 31233/90000 [02:30<04:21, 224.45it/s] 35%|███▍      | 31257/90000 [02:30<04:19, 226.36it/s] 35%|███▍      | 31281/90000 [02:30<04:17, 227.74it/s] 35%|███▍      | 31306/90000 [02:30<04:11, 233.19it/s] 35%|███▍      | 31331/90000 [02:30<04:08, 236.15it/s] 35%|███▍      | 31355/90000 [02:30<04:08, 236.09it/s] 35%|███▍      | 31379/90000 [02:30<04:09, 235.31it/s] 35%|███▍      | 31403/90000 [02:30<04:07, 236.54it/s] 35%|███▍      | 31427/90000 [02:30<04:11, 233.30it/s] 35%|███▍      | 31451/90000 [02:31<04:15, 228.90it/s] 35%|███▍      | 31475/90000 [02:31<04:12, 231.70it/s] 35%|███▍      | 31499/90000 [02:31<04:14, 230.05it/s] 35%|███▌      | 31523/90000 [02:31<04:11, 232.69it/s] 35%|███▌      | 31547/90000 [02:31<04:14, 229.25it/s] 35%|███▌      | 31570/90000 [02:31<04:14, 229.23it/s] 35%|███▌      | 31593/90000 [02:31<04:16, 227.44it/s] 35%|███▌      | 31616/90000 [02:31<04:16, 227.21it/s] 35%|███▌      | 31639/90000 [02:31<04:17, 226.22it/s] 35%|███▌      | 31663/90000 [02:32<04:16, 227.83it/s] 35%|███▌      | 31687/90000 [02:32<04:15, 228.57it/s] 35%|███▌      | 31710/90000 [02:32<04:14, 228.94it/s] 35%|███▌      | 31734/90000 [02:32<04:12, 230.71it/s] 35%|███▌      | 31758/90000 [02:32<04:23, 221.27it/s] 35%|███▌      | 31782/90000 [02:32<04:18, 224.85it/s] 35%|███▌      | 31805/90000 [02:32<04:20, 223.68it/s] 35%|███▌      | 31829/90000 [02:32<04:16, 226.63it/s] 35%|███▌      | 31854/90000 [02:32<04:12, 229.93it/s] 35%|███▌      | 31878/90000 [02:32<04:11, 230.85it/s] 35%|███▌      | 31902/90000 [02:33<04:09, 232.91it/s] 35%|███▌      | 31926/90000 [02:33<04:12, 229.95it/s] 36%|███▌      | 31950/90000 [02:33<04:10, 231.68it/s] 36%|███▌      | 31974/90000 [02:33<04:13, 228.88it/s] 36%|███▌      | 31998/90000 [02:33<04:12, 229.34it/s] 36%|███▌      | 32021/90000 [02:33<04:13, 228.43it/s] 36%|███▌      | 32044/90000 [02:33<04:13, 228.26it/s] 36%|███▌      | 32067/90000 [02:33<04:16, 225.92it/s] 36%|███▌      | 32090/90000 [02:33<04:15, 226.92it/s] 36%|███▌      | 32113/90000 [02:33<04:17, 224.88it/s] 36%|███▌      | 32137/90000 [02:34<04:14, 227.55it/s] 36%|███▌      | 32160/90000 [02:34<04:17, 224.82it/s] 36%|███▌      | 32183/90000 [02:34<04:15, 225.90it/s] 36%|███▌      | 32207/90000 [02:34<04:14, 227.14it/s] 36%|███▌      | 32231/90000 [02:34<04:13, 227.81it/s] 36%|███▌      | 32254/90000 [02:34<04:14, 226.75it/s] 36%|███▌      | 32277/90000 [02:34<04:17, 224.03it/s] 36%|███▌      | 32300/90000 [02:34<04:27, 215.37it/s] 36%|███▌      | 32322/90000 [02:34<04:29, 214.00it/s] 36%|███▌      | 32346/90000 [02:35<04:21, 220.11it/s] 36%|███▌      | 32369/90000 [02:35<04:24, 217.65it/s] 36%|███▌      | 32393/90000 [02:35<04:18, 223.11it/s] 36%|███▌      | 32416/90000 [02:35<04:18, 222.41it/s] 36%|███▌      | 32439/90000 [02:35<04:19, 221.99it/s] 36%|███▌      | 32462/90000 [02:35<04:19, 221.93it/s] 36%|███▌      | 32485/90000 [02:35<04:18, 222.58it/s] 36%|███▌      | 32508/90000 [02:35<04:25, 216.90it/s] 36%|███▌      | 32530/90000 [02:35<04:25, 216.68it/s] 36%|███▌      | 32554/90000 [02:35<04:20, 220.40it/s] 36%|███▌      | 32577/90000 [02:36<04:19, 221.04it/s] 36%|███▌      | 32600/90000 [02:36<04:18, 222.04it/s] 36%|███▌      | 32623/90000 [02:36<04:19, 220.98it/s] 36%|███▋      | 32646/90000 [02:36<04:25, 215.92it/s] 36%|███▋      | 32669/90000 [02:36<04:23, 217.35it/s] 36%|███▋      | 32691/90000 [02:36<04:24, 216.37it/s] 36%|███▋      | 32713/90000 [02:36<04:24, 216.42it/s] 36%|███▋      | 32735/90000 [02:36<04:24, 216.32it/s] 36%|███▋      | 32757/90000 [02:36<04:24, 216.66it/s] 36%|███▋      | 32779/90000 [02:37<04:25, 215.49it/s] 36%|███▋      | 32801/90000 [02:37<04:28, 212.84it/s] 36%|███▋      | 32823/90000 [02:37<04:31, 210.34it/s] 36%|███▋      | 32846/90000 [02:37<04:24, 215.92it/s] 37%|███▋      | 32868/90000 [02:37<04:24, 216.02it/s] 37%|███▋      | 32890/90000 [02:37<04:23, 217.13it/s] 37%|███▋      | 32912/90000 [02:37<04:24, 216.10it/s] 37%|███▋      | 32934/90000 [02:37<04:30, 210.64it/s] 37%|███▋      | 32956/90000 [02:37<04:33, 208.82it/s] 37%|███▋      | 32978/90000 [02:37<04:31, 210.05it/s] 37%|███▋      | 33001/90000 [02:38<04:26, 214.01it/s] 37%|███▋      | 33024/90000 [02:38<04:23, 216.49it/s] 37%|███▋      | 33047/90000 [02:38<04:18, 220.22it/s] 37%|███▋      | 33070/90000 [02:38<04:18, 220.63it/s] 37%|███▋      | 33093/90000 [02:38<04:18, 220.01it/s] 37%|███▋      | 33116/90000 [02:38<04:17, 221.17it/s] 37%|███▋      | 33139/90000 [02:38<04:17, 220.56it/s] 37%|███▋      | 33162/90000 [02:38<04:17, 220.94it/s] 37%|███▋      | 33186/90000 [02:38<04:13, 224.19it/s] 37%|███▋      | 33209/90000 [02:38<04:17, 220.16it/s] 37%|███▋      | 33233/90000 [02:39<04:12, 224.88it/s] 37%|███▋      | 33256/90000 [02:39<04:14, 222.94it/s] 37%|███▋      | 33279/90000 [02:39<04:20, 217.97it/s] 37%|███▋      | 33301/90000 [02:39<04:22, 216.02it/s] 37%|███▋      | 33324/90000 [02:39<04:19, 218.57it/s] 37%|███▋      | 33347/90000 [02:39<04:15, 221.41it/s] 37%|███▋      | 33370/90000 [02:39<04:17, 220.14it/s] 37%|███▋      | 33393/90000 [02:39<04:15, 221.26it/s] 37%|███▋      | 33418/90000 [02:39<04:08, 227.68it/s] 37%|███▋      | 33441/90000 [02:40<04:10, 225.89it/s] 37%|███▋      | 33467/90000 [02:40<04:02, 233.56it/s] 37%|███▋      | 33491/90000 [02:40<04:02, 233.02it/s] 37%|███▋      | 33515/90000 [02:40<04:06, 229.33it/s] 37%|███▋      | 33539/90000 [02:40<04:04, 230.62it/s] 37%|███▋      | 33563/90000 [02:40<04:06, 229.28it/s] 37%|███▋      | 33587/90000 [02:40<04:04, 230.33it/s] 37%|███▋      | 33611/90000 [02:40<04:07, 228.26it/s] 37%|███▋      | 33634/90000 [02:40<04:09, 226.17it/s] 37%|███▋      | 33657/90000 [02:40<04:09, 225.71it/s] 37%|███▋      | 33681/90000 [02:41<04:05, 229.80it/s] 37%|███▋      | 33706/90000 [02:41<04:01, 232.67it/s] 37%|███▋      | 33730/90000 [02:41<04:07, 227.44it/s] 38%|███▊      | 33753/90000 [02:41<04:09, 225.70it/s] 38%|███▊      | 33776/90000 [02:41<04:09, 225.61it/s] 38%|███▊      | 33799/90000 [02:41<04:08, 226.08it/s] 38%|███▊      | 33822/90000 [02:41<04:12, 222.33it/s] 38%|███▊      | 33845/90000 [02:41<04:11, 223.00it/s] 38%|███▊      | 33868/90000 [02:41<04:10, 224.48it/s] 38%|███▊      | 33892/90000 [02:42<04:05, 228.62it/s] 38%|███▊      | 33916/90000 [02:42<04:02, 231.22it/s] 38%|███▊      | 33940/90000 [02:42<04:08, 226.04it/s] 38%|███▊      | 33965/90000 [02:42<04:02, 231.46it/s] 38%|███▊      | 33989/90000 [02:42<04:03, 229.96it/s] 38%|███▊      | 34013/90000 [02:42<04:01, 231.69it/s] 38%|███▊      | 34037/90000 [02:42<04:01, 231.92it/s] 38%|███▊      | 34061/90000 [02:42<04:00, 232.29it/s] 38%|███▊      | 34085/90000 [02:42<04:05, 227.62it/s] 38%|███▊      | 34108/90000 [02:42<04:10, 222.86it/s] 38%|███▊      | 34131/90000 [02:43<04:15, 218.95it/s] 38%|███▊      | 34155/90000 [02:43<04:09, 223.63it/s] 38%|███▊      | 34178/90000 [02:43<04:16, 217.21it/s] 38%|███▊      | 34200/90000 [02:43<04:16, 217.89it/s] 38%|███▊      | 34222/90000 [02:43<04:15, 218.47it/s] 38%|███▊      | 34245/90000 [02:43<04:12, 220.68it/s] 38%|███▊      | 34268/90000 [02:43<04:11, 221.72it/s] 38%|███▊      | 34291/90000 [02:43<04:15, 218.10it/s] 38%|███▊      | 34313/90000 [02:43<04:16, 216.97it/s] 38%|███▊      | 34335/90000 [02:44<04:21, 212.58it/s] 38%|███▊      | 34357/90000 [02:44<04:20, 213.35it/s] 38%|███▊      | 34379/90000 [02:44<04:27, 207.75it/s] 38%|███▊      | 34403/90000 [02:44<04:19, 214.24it/s] 38%|███▊      | 34425/90000 [02:44<04:25, 209.30it/s] 38%|███▊      | 34448/90000 [02:44<04:20, 213.24it/s] 38%|███▊      | 34470/90000 [02:44<04:21, 212.48it/s] 38%|███▊      | 34492/90000 [02:44<04:23, 210.57it/s] 38%|███▊      | 34514/90000 [02:44<04:22, 211.56it/s] 38%|███▊      | 34536/90000 [02:44<04:24, 209.34it/s] 38%|███▊      | 34559/90000 [02:45<04:18, 214.55it/s] 38%|███▊      | 34582/90000 [02:45<04:14, 217.33it/s] 38%|███▊      | 34604/90000 [02:45<04:14, 217.66it/s] 38%|███▊      | 34626/90000 [02:45<04:16, 215.64it/s] 38%|███▊      | 34649/90000 [02:45<04:12, 219.19it/s] 39%|███▊      | 34671/90000 [02:45<04:14, 217.67it/s] 39%|███▊      | 34695/90000 [02:45<04:09, 221.86it/s] 39%|███▊      | 34718/90000 [02:45<04:12, 219.22it/s] 39%|███▊      | 34740/90000 [02:45<04:12, 218.45it/s] 39%|███▊      | 34763/90000 [02:45<04:12, 219.03it/s] 39%|███▊      | 34786/90000 [02:46<04:09, 221.01it/s] 39%|███▊      | 34809/90000 [02:46<04:12, 218.57it/s] 39%|███▊      | 34832/90000 [02:46<04:09, 221.42it/s] 39%|███▊      | 34855/90000 [02:46<04:09, 220.83it/s] 39%|███▉      | 34878/90000 [02:46<04:08, 221.49it/s] 39%|███▉      | 34901/90000 [02:46<04:09, 220.87it/s] 39%|███▉      | 34924/90000 [02:46<04:06, 223.52it/s] 39%|███▉      | 34947/90000 [02:46<04:08, 221.16it/s] 39%|███▉      | 34970/90000 [02:46<04:06, 223.67it/s] 39%|███▉      | 34993/90000 [02:47<04:07, 222.70it/s] 39%|███▉      | 35016/90000 [02:47<04:06, 223.35it/s] 39%|███▉      | 35040/90000 [02:47<04:00, 228.21it/s] 39%|███▉      | 35064/90000 [02:47<03:57, 231.16it/s] 39%|███▉      | 35088/90000 [02:47<03:59, 229.62it/s] 39%|███▉      | 35112/90000 [02:47<03:58, 229.97it/s] 39%|███▉      | 35136/90000 [02:47<04:02, 226.14it/s] 39%|███▉      | 35159/90000 [02:47<04:03, 225.09it/s] 39%|███▉      | 35182/90000 [02:47<04:07, 221.07it/s] 39%|███▉      | 35206/90000 [02:47<04:02, 226.32it/s] 39%|███▉      | 35229/90000 [02:48<04:03, 225.35it/s] 39%|███▉      | 35252/90000 [02:48<04:01, 226.48it/s] 39%|███▉      | 35276/90000 [02:48<03:58, 229.38it/s] 39%|███▉      | 35299/90000 [02:48<04:02, 225.78it/s] 39%|███▉      | 35322/90000 [02:48<04:04, 223.87it/s] 39%|███▉      | 35345/90000 [02:48<04:06, 221.41it/s] 39%|███▉      | 35368/90000 [02:48<04:07, 220.54it/s] 39%|███▉      | 35391/90000 [02:48<04:05, 222.80it/s] 39%|███▉      | 35414/90000 [02:48<04:04, 223.25it/s] 39%|███▉      | 35437/90000 [02:48<04:05, 222.70it/s] 39%|███▉      | 35461/90000 [02:49<04:01, 225.66it/s] 39%|███▉      | 35484/90000 [02:49<04:04, 222.65it/s] 39%|███▉      | 35508/90000 [02:49<04:00, 226.94it/s] 39%|███▉      | 35531/90000 [02:49<04:00, 226.14it/s] 40%|███▉      | 35554/90000 [02:49<04:02, 224.21it/s] 40%|███▉      | 35577/90000 [02:49<04:01, 225.46it/s] 40%|███▉      | 35600/90000 [02:49<04:01, 225.36it/s] 40%|███▉      | 35623/90000 [02:49<04:02, 224.05it/s] 40%|███▉      | 35646/90000 [02:49<04:04, 222.75it/s] 40%|███▉      | 35669/90000 [02:50<04:02, 223.94it/s] 40%|███▉      | 35694/90000 [02:50<03:57, 228.69it/s] 40%|███▉      | 35718/90000 [02:50<03:54, 231.57it/s] 40%|███▉      | 35742/90000 [02:50<03:53, 231.93it/s] 40%|███▉      | 35766/90000 [02:50<03:57, 228.42it/s] 40%|███▉      | 35790/90000 [02:50<03:55, 230.08it/s] 40%|███▉      | 35814/90000 [02:50<03:53, 231.78it/s] 40%|███▉      | 35838/90000 [02:50<03:54, 230.85it/s] 40%|███▉      | 35862/90000 [02:50<03:53, 231.41it/s] 40%|███▉      | 35886/90000 [02:50<03:53, 231.54it/s] 40%|███▉      | 35910/90000 [02:51<03:53, 231.37it/s] 40%|███▉      | 35934/90000 [02:51<03:53, 232.03it/s] 40%|███▉      | 35958/90000 [02:51<03:55, 229.36it/s] 40%|███▉      | 35981/90000 [02:51<04:00, 224.35it/s] 40%|████      | 36005/90000 [02:51<03:59, 225.77it/s] 40%|████      | 36028/90000 [02:51<03:58, 225.88it/s] 40%|████      | 36051/90000 [02:51<03:57, 226.83it/s] 40%|████      | 36074/90000 [02:51<03:57, 227.43it/s] 40%|████      | 36097/90000 [02:51<03:56, 227.96it/s] 40%|████      | 36120/90000 [02:51<03:56, 227.71it/s] 40%|████      | 36143/90000 [02:52<03:56, 228.09it/s] 40%|████      | 36166/90000 [02:52<04:02, 222.33it/s] 40%|████      | 36190/90000 [02:52<03:57, 226.75it/s] 40%|████      | 36214/90000 [02:52<03:55, 228.54it/s] 40%|████      | 36238/90000 [02:52<03:53, 230.22it/s] 40%|████      | 36262/90000 [02:52<03:56, 226.77it/s] 40%|████      | 36285/90000 [02:52<03:56, 227.08it/s] 40%|████      | 36309/90000 [02:52<03:54, 229.28it/s] 40%|████      | 36333/90000 [02:52<03:53, 229.83it/s] 40%|████      | 36356/90000 [02:53<03:53, 229.86it/s] 40%|████      | 36379/90000 [02:53<03:58, 224.52it/s] 40%|████      | 36403/90000 [02:53<03:56, 226.65it/s] 40%|████      | 36426/90000 [02:53<04:01, 221.52it/s] 40%|████      | 36449/90000 [02:53<04:08, 215.73it/s] 41%|████      | 36472/90000 [02:53<04:06, 217.30it/s] 41%|████      | 36495/90000 [02:53<04:03, 220.09it/s] 41%|████      | 36518/90000 [02:53<04:04, 218.88it/s] 41%|████      | 36541/90000 [02:53<04:03, 219.56it/s] 41%|████      | 36565/90000 [02:53<03:59, 222.73it/s] 41%|████      | 36588/90000 [02:54<03:59, 223.34it/s] 41%|████      | 36613/90000 [02:54<03:53, 228.93it/s] 41%|████      | 36638/90000 [02:54<03:48, 233.90it/s] 41%|████      | 36662/90000 [02:54<03:47, 234.03it/s] 41%|████      | 36686/90000 [02:54<03:46, 234.94it/s] 41%|████      | 36710/90000 [02:54<03:47, 234.31it/s] 41%|████      | 36734/90000 [02:54<03:48, 233.43it/s] 41%|████      | 36758/90000 [02:54<03:50, 230.86it/s] 41%|████      | 36782/90000 [02:54<03:53, 227.93it/s] 41%|████      | 36805/90000 [02:55<03:55, 226.31it/s] 41%|████      | 36828/90000 [02:55<03:55, 225.35it/s] 41%|████      | 36851/90000 [02:55<03:57, 224.10it/s] 41%|████      | 36875/90000 [02:55<03:52, 228.18it/s] 41%|████      | 36899/90000 [02:55<03:53, 227.79it/s] 41%|████      | 36922/90000 [02:55<03:52, 227.80it/s] 41%|████      | 36945/90000 [02:55<03:53, 227.18it/s] 41%|████      | 36968/90000 [02:55<03:52, 227.90it/s] 41%|████      | 36992/90000 [02:55<03:49, 230.49it/s] 41%|████      | 37016/90000 [02:55<03:50, 229.51it/s] 41%|████      | 37039/90000 [02:56<03:52, 227.88it/s] 41%|████      | 37063/90000 [02:56<03:49, 231.04it/s] 41%|████      | 37088/90000 [02:56<03:44, 235.24it/s] 41%|████      | 37112/90000 [02:56<03:45, 234.64it/s] 41%|████▏     | 37136/90000 [02:56<03:50, 229.36it/s] 41%|████▏     | 37159/90000 [02:56<03:54, 225.26it/s] 41%|████▏     | 37183/90000 [02:56<03:53, 226.03it/s] 41%|████▏     | 37207/90000 [02:56<03:50, 228.94it/s] 41%|████▏     | 37230/90000 [02:56<03:54, 225.45it/s] 41%|████▏     | 37253/90000 [02:56<03:55, 224.09it/s] 41%|████▏     | 37276/90000 [02:57<03:59, 219.75it/s] 41%|████▏     | 37299/90000 [02:57<03:58, 220.94it/s] 41%|████▏     | 37322/90000 [02:57<03:56, 222.62it/s] 41%|████▏     | 37345/90000 [02:57<03:55, 223.55it/s] 42%|████▏     | 37368/90000 [02:57<03:56, 222.41it/s] 42%|████▏     | 37391/90000 [02:57<03:57, 221.22it/s] 42%|████▏     | 37414/90000 [02:57<03:59, 219.91it/s] 42%|████▏     | 37438/90000 [02:57<03:53, 224.74it/s] 42%|████▏     | 37462/90000 [02:57<03:52, 226.35it/s] 42%|████▏     | 37485/90000 [02:58<03:52, 225.71it/s] 42%|████▏     | 37509/90000 [02:58<03:50, 227.49it/s] 42%|████▏     | 37532/90000 [02:58<03:51, 226.87it/s] 42%|████▏     | 37556/90000 [02:58<03:50, 227.09it/s] 42%|████▏     | 37579/90000 [02:58<03:56, 221.99it/s] 42%|████▏     | 37602/90000 [02:58<03:53, 224.04it/s] 42%|████▏     | 37625/90000 [02:58<03:58, 219.20it/s] 42%|████▏     | 37648/90000 [02:58<03:57, 220.77it/s] 42%|████▏     | 37671/90000 [02:58<03:57, 220.44it/s] 42%|████▏     | 37694/90000 [02:58<03:57, 220.65it/s] 42%|████▏     | 37718/90000 [02:59<03:52, 225.09it/s] 42%|████▏     | 37741/90000 [02:59<03:52, 224.65it/s] 42%|████▏     | 37765/90000 [02:59<03:50, 226.25it/s] 42%|████▏     | 37789/90000 [02:59<03:47, 229.76it/s] 42%|████▏     | 37812/90000 [02:59<03:56, 220.89it/s] 42%|████▏     | 37835/90000 [02:59<03:55, 221.64it/s] 42%|████▏     | 37858/90000 [02:59<03:54, 221.95it/s] 42%|████▏     | 37881/90000 [02:59<03:55, 221.04it/s] 42%|████▏     | 37906/90000 [02:59<03:49, 227.45it/s] 42%|████▏     | 37929/90000 [02:59<03:48, 227.95it/s] 42%|████▏     | 37952/90000 [03:00<03:52, 223.95it/s] 42%|████▏     | 37975/90000 [03:00<03:52, 224.17it/s] 42%|████▏     | 37998/90000 [03:00<03:51, 224.23it/s] 42%|████▏     | 38021/90000 [03:00<03:50, 225.03it/s] 42%|████▏     | 38046/90000 [03:00<03:43, 232.07it/s] 42%|████▏     | 38070/90000 [03:00<03:47, 228.67it/s] 42%|████▏     | 38094/90000 [03:00<03:45, 230.66it/s] 42%|████▏     | 38118/90000 [03:00<03:43, 232.55it/s] 42%|████▏     | 38142/90000 [03:00<03:43, 231.74it/s] 42%|████▏     | 38166/90000 [03:01<03:43, 232.10it/s] 42%|████▏     | 38190/90000 [03:01<03:43, 231.82it/s] 42%|████▏     | 38214/90000 [03:01<03:47, 227.17it/s] 42%|████▏     | 38237/90000 [03:01<03:50, 224.31it/s] 43%|████▎     | 38261/90000 [03:01<03:47, 227.30it/s] 43%|████▎     | 38285/90000 [03:01<03:44, 230.18it/s] 43%|████▎     | 38309/90000 [03:01<03:45, 229.35it/s] 43%|████▎     | 38332/90000 [03:01<03:45, 229.30it/s] 43%|████▎     | 38356/90000 [03:01<03:42, 231.87it/s] 43%|████▎     | 38380/90000 [03:01<03:45, 228.88it/s] 43%|████▎     | 38404/90000 [03:02<03:43, 230.38it/s] 43%|████▎     | 38428/90000 [03:02<03:45, 229.05it/s] 43%|████▎     | 38451/90000 [03:02<03:45, 229.10it/s] 43%|████▎     | 38475/90000 [03:02<03:43, 230.12it/s] 43%|████▎     | 38499/90000 [03:02<03:44, 229.91it/s] 43%|████▎     | 38522/90000 [03:02<03:44, 229.54it/s] 43%|████▎     | 38546/90000 [03:02<03:41, 232.56it/s] 43%|████▎     | 38570/90000 [03:02<03:42, 231.25it/s] 43%|████▎     | 38594/90000 [03:02<03:42, 230.99it/s] 43%|████▎     | 38619/90000 [03:02<03:37, 235.80it/s] 43%|████▎     | 38643/90000 [03:03<03:40, 232.59it/s] 43%|████▎     | 38667/90000 [03:03<03:39, 233.52it/s] 43%|████▎     | 38691/90000 [03:03<03:38, 234.45it/s] 43%|████▎     | 38715/90000 [03:03<03:38, 234.97it/s] 43%|████▎     | 38739/90000 [03:03<03:38, 234.49it/s] 43%|████▎     | 38763/90000 [03:03<03:37, 235.35it/s] 43%|████▎     | 38787/90000 [03:03<03:38, 234.73it/s] 43%|████▎     | 38811/90000 [03:03<03:37, 235.86it/s] 43%|████▎     | 38835/90000 [03:03<03:39, 232.75it/s] 43%|████▎     | 38859/90000 [03:04<03:38, 234.28it/s] 43%|████▎     | 38884/90000 [03:04<03:35, 237.23it/s] 43%|████▎     | 38908/90000 [03:04<03:36, 236.36it/s] 43%|████▎     | 38932/90000 [03:04<03:35, 237.36it/s] 43%|████▎     | 38956/90000 [03:04<03:38, 233.63it/s] 43%|████▎     | 38980/90000 [03:04<03:39, 232.71it/s] 43%|████▎     | 39004/90000 [03:04<03:41, 229.74it/s] 43%|████▎     | 39029/90000 [03:04<03:38, 233.31it/s] 43%|████▎     | 39053/90000 [03:04<03:38, 232.76it/s] 43%|████▎     | 39078/90000 [03:04<03:34, 237.60it/s] 43%|████▎     | 39102/90000 [03:05<03:35, 236.08it/s] 43%|████▎     | 39126/90000 [03:05<03:35, 235.74it/s] 44%|████▎     | 39150/90000 [03:05<03:36, 235.28it/s] 44%|████▎     | 39174/90000 [03:05<03:38, 232.80it/s] 44%|████▎     | 39198/90000 [03:05<03:42, 228.25it/s] 44%|████▎     | 39221/90000 [03:05<03:48, 222.28it/s] 44%|████▎     | 39244/90000 [03:05<03:46, 224.39it/s] 44%|████▎     | 39267/90000 [03:05<03:48, 222.12it/s] 44%|████▎     | 39290/90000 [03:05<03:46, 223.95it/s] 44%|████▎     | 39315/90000 [03:05<03:39, 230.76it/s] 44%|████▎     | 39339/90000 [03:06<03:38, 231.65it/s] 44%|████▎     | 39363/90000 [03:06<03:42, 227.84it/s] 44%|████▍     | 39386/90000 [03:06<03:42, 227.80it/s] 44%|████▍     | 39410/90000 [03:06<03:40, 229.32it/s] 44%|████▍     | 39435/90000 [03:06<03:37, 232.68it/s] 44%|████▍     | 39459/90000 [03:06<03:39, 229.96it/s] 44%|████▍     | 39483/90000 [03:06<03:40, 229.59it/s] 44%|████▍     | 39508/90000 [03:06<03:37, 232.58it/s] 44%|████▍     | 39532/90000 [03:06<03:36, 233.44it/s] 44%|████▍     | 39557/90000 [03:07<03:33, 236.35it/s] 44%|████▍     | 39581/90000 [03:07<03:34, 235.40it/s] 44%|████▍     | 39605/90000 [03:07<03:34, 234.47it/s] 44%|████▍     | 39630/90000 [03:07<03:33, 235.61it/s] 44%|████▍     | 39654/90000 [03:07<03:35, 233.92it/s] 44%|████▍     | 39678/90000 [03:07<03:37, 231.76it/s] 44%|████▍     | 39702/90000 [03:07<03:40, 228.24it/s] 44%|████▍     | 39725/90000 [03:07<03:40, 228.16it/s] 44%|████▍     | 39749/90000 [03:07<03:38, 229.70it/s] 44%|████▍     | 39773/90000 [03:07<03:36, 231.55it/s] 44%|████▍     | 39797/90000 [03:08<03:37, 230.77it/s] 44%|████▍     | 39821/90000 [03:08<03:38, 230.09it/s] 44%|████▍     | 39845/90000 [03:08<03:39, 228.27it/s] 44%|████▍     | 39870/90000 [03:08<03:35, 232.10it/s] 44%|████▍     | 39894/90000 [03:08<03:35, 232.99it/s] 44%|████▍     | 39918/90000 [03:08<03:38, 229.59it/s] 44%|████▍     | 39941/90000 [03:08<03:39, 228.45it/s] 44%|████▍     | 39965/90000 [03:08<03:37, 230.07it/s] 44%|████▍     | 39989/90000 [03:08<03:34, 232.85it/s] 44%|████▍     | 40013/90000 [03:09<03:33, 234.46it/s] 44%|████▍     | 40038/90000 [03:09<03:31, 236.52it/s] 45%|████▍     | 40062/90000 [03:09<03:32, 234.50it/s] 45%|████▍     | 40086/90000 [03:09<03:34, 233.22it/s] 45%|████▍     | 40110/90000 [03:09<03:32, 235.17it/s] 45%|████▍     | 40134/90000 [03:09<03:33, 233.99it/s] 45%|████▍     | 40158/90000 [03:09<03:35, 230.98it/s] 45%|████▍     | 40183/90000 [03:09<03:34, 232.72it/s] 45%|████▍     | 40207/90000 [03:09<03:36, 230.15it/s] 45%|████▍     | 40231/90000 [03:09<03:37, 228.54it/s] 45%|████▍     | 40254/90000 [03:10<03:37, 228.54it/s] 45%|████▍     | 40277/90000 [03:10<03:39, 226.89it/s] 45%|████▍     | 40300/90000 [03:10<03:38, 227.17it/s] 45%|████▍     | 40324/90000 [03:10<03:38, 227.03it/s] 45%|████▍     | 40349/90000 [03:10<03:34, 230.96it/s] 45%|████▍     | 40373/90000 [03:10<03:33, 232.45it/s] 45%|████▍     | 40397/90000 [03:10<03:35, 230.40it/s] 45%|████▍     | 40421/90000 [03:10<03:34, 231.18it/s] 45%|████▍     | 40445/90000 [03:10<03:34, 231.14it/s] 45%|████▍     | 40469/90000 [03:10<03:32, 232.97it/s] 45%|████▍     | 40493/90000 [03:11<03:33, 232.42it/s] 45%|████▌     | 40517/90000 [03:11<03:34, 230.86it/s] 45%|████▌     | 40542/90000 [03:11<03:30, 234.64it/s] 45%|████▌     | 40567/90000 [03:11<03:28, 237.30it/s] 45%|████▌     | 40591/90000 [03:11<03:30, 235.12it/s] 45%|████▌     | 40615/90000 [03:11<03:30, 234.25it/s] 45%|████▌     | 40639/90000 [03:11<03:29, 235.83it/s] 45%|████▌     | 40663/90000 [03:11<03:31, 233.42it/s] 45%|████▌     | 40687/90000 [03:11<03:35, 228.88it/s] 45%|████▌     | 40710/90000 [03:12<03:35, 228.95it/s] 45%|████▌     | 40734/90000 [03:12<03:33, 230.70it/s] 45%|████▌     | 40758/90000 [03:12<03:36, 227.53it/s] 45%|████▌     | 40782/90000 [03:12<03:33, 230.98it/s] 45%|████▌     | 40806/90000 [03:12<03:31, 232.28it/s] 45%|████▌     | 40831/90000 [03:12<03:29, 234.83it/s] 45%|████▌     | 40855/90000 [03:12<03:30, 233.83it/s] 45%|████▌     | 40879/90000 [03:12<03:29, 234.42it/s] 45%|████▌     | 40903/90000 [03:12<03:30, 233.63it/s] 45%|████▌     | 40927/90000 [03:12<03:30, 233.59it/s] 46%|████▌     | 40951/90000 [03:13<03:32, 230.43it/s] 46%|████▌     | 40975/90000 [03:13<03:33, 229.19it/s] 46%|████▌     | 40999/90000 [03:13<03:32, 230.98it/s] 46%|████▌     | 41023/90000 [03:13<03:34, 228.84it/s] 46%|████▌     | 41048/90000 [03:13<03:30, 233.02it/s] 46%|████▌     | 41072/90000 [03:13<03:30, 232.78it/s] 46%|████▌     | 41096/90000 [03:13<03:31, 231.68it/s] 46%|████▌     | 41121/90000 [03:13<03:28, 234.63it/s] 46%|████▌     | 41145/90000 [03:13<03:29, 233.09it/s] 46%|████▌     | 41169/90000 [03:13<03:33, 229.16it/s] 46%|████▌     | 41193/90000 [03:14<03:32, 229.94it/s] 46%|████▌     | 41218/90000 [03:14<03:28, 233.45it/s] 46%|████▌     | 41242/90000 [03:14<03:30, 231.33it/s] 46%|████▌     | 41266/90000 [03:14<03:33, 228.61it/s] 46%|████▌     | 41290/90000 [03:14<03:33, 228.04it/s] 46%|████▌     | 41313/90000 [03:14<03:34, 226.61it/s] 46%|████▌     | 41338/90000 [03:14<03:30, 230.71it/s] 46%|████▌     | 41362/90000 [03:14<03:35, 225.41it/s] 46%|████▌     | 41385/90000 [03:14<03:36, 224.77it/s] 46%|████▌     | 41408/90000 [03:15<03:35, 225.63it/s] 46%|████▌     | 41433/90000 [03:15<03:31, 230.04it/s] 46%|████▌     | 41457/90000 [03:15<03:30, 230.61it/s] 46%|████▌     | 41481/90000 [03:15<03:31, 229.50it/s] 46%|████▌     | 41505/90000 [03:15<03:28, 232.16it/s] 46%|████▌     | 41529/90000 [03:15<03:31, 229.57it/s] 46%|████▌     | 41553/90000 [03:15<03:31, 229.51it/s] 46%|████▌     | 41576/90000 [03:15<03:34, 225.41it/s] 46%|████▌     | 41599/90000 [03:15<03:35, 224.77it/s] 46%|████▌     | 41622/90000 [03:15<03:35, 224.00it/s] 46%|████▋     | 41646/90000 [03:16<03:32, 227.39it/s] 46%|████▋     | 41669/90000 [03:16<03:37, 221.72it/s] 46%|████▋     | 41693/90000 [03:16<03:35, 224.62it/s] 46%|████▋     | 41716/90000 [03:16<03:34, 225.06it/s] 46%|████▋     | 41740/90000 [03:16<03:30, 228.98it/s] 46%|████▋     | 41763/90000 [03:16<03:32, 227.19it/s] 46%|████▋     | 41786/90000 [03:16<03:34, 224.71it/s] 46%|████▋     | 41809/90000 [03:16<03:34, 224.41it/s] 46%|████▋     | 41832/90000 [03:16<03:34, 224.86it/s] 47%|████▋     | 41855/90000 [03:17<03:33, 225.48it/s] 47%|████▋     | 41878/90000 [03:17<03:35, 223.76it/s] 47%|████▋     | 41902/90000 [03:17<03:30, 228.03it/s] 47%|████▋     | 41926/90000 [03:17<03:29, 229.67it/s] 47%|████▋     | 41949/90000 [03:17<03:32, 225.67it/s] 47%|████▋     | 41972/90000 [03:17<03:32, 226.12it/s] 47%|████▋     | 41995/90000 [03:17<03:36, 221.79it/s] 47%|████▋     | 42018/90000 [03:17<03:35, 223.00it/s] 47%|████▋     | 42041/90000 [03:17<03:33, 224.25it/s] 47%|████▋     | 42065/90000 [03:17<03:31, 226.93it/s] 47%|████▋     | 42091/90000 [03:18<03:23, 235.47it/s] 47%|████▋     | 42115/90000 [03:18<03:23, 235.13it/s] 47%|████▋     | 42139/90000 [03:18<03:25, 233.06it/s] 47%|████▋     | 42164/90000 [03:18<03:22, 235.85it/s] 47%|████▋     | 42188/90000 [03:18<03:23, 235.11it/s] 47%|████▋     | 42212/90000 [03:18<03:25, 232.72it/s] 47%|████▋     | 42237/90000 [03:18<03:22, 235.97it/s] 47%|████▋     | 42261/90000 [03:18<03:26, 231.31it/s] 47%|████▋     | 42285/90000 [03:18<03:25, 231.65it/s] 47%|████▋     | 42309/90000 [03:18<03:23, 233.99it/s] 47%|████▋     | 42333/90000 [03:19<03:26, 231.15it/s] 47%|████▋     | 42357/90000 [03:19<03:27, 230.11it/s] 47%|████▋     | 42381/90000 [03:19<03:26, 230.94it/s] 47%|████▋     | 42405/90000 [03:19<03:28, 227.85it/s] 47%|████▋     | 42429/90000 [03:19<03:26, 230.16it/s] 47%|████▋     | 42454/90000 [03:19<03:22, 234.96it/s] 47%|████▋     | 42479/90000 [03:19<03:19, 237.80it/s] 47%|████▋     | 42503/90000 [03:19<03:21, 235.78it/s] 47%|████▋     | 42527/90000 [03:19<03:23, 233.13it/s] 47%|████▋     | 42551/90000 [03:20<03:27, 228.26it/s] 47%|████▋     | 42575/90000 [03:20<03:26, 229.19it/s] 47%|████▋     | 42598/90000 [03:20<03:26, 229.29it/s] 47%|████▋     | 42621/90000 [03:20<03:27, 228.67it/s] 47%|████▋     | 42646/90000 [03:20<03:22, 233.97it/s] 47%|████▋     | 42670/90000 [03:20<03:22, 233.30it/s] 47%|████▋     | 42694/90000 [03:20<03:22, 234.03it/s] 47%|████▋     | 42719/90000 [03:20<03:20, 235.88it/s] 47%|████▋     | 42744/90000 [03:20<03:18, 238.60it/s] 48%|████▊     | 42768/90000 [03:20<03:19, 236.68it/s] 48%|████▊     | 42792/90000 [03:21<03:18, 237.64it/s] 48%|████▊     | 42817/90000 [03:21<03:16, 239.74it/s] 48%|████▊     | 42841/90000 [03:21<03:17, 238.48it/s] 48%|████▊     | 42865/90000 [03:21<03:19, 236.21it/s] 48%|████▊     | 42889/90000 [03:21<03:21, 234.36it/s] 48%|████▊     | 42914/90000 [03:21<03:17, 238.57it/s] 48%|████▊     | 42938/90000 [03:21<03:17, 237.92it/s] 48%|████▊     | 42962/90000 [03:21<03:17, 238.14it/s] 48%|████▊     | 42987/90000 [03:21<03:16, 239.23it/s] 48%|████▊     | 43011/90000 [03:21<03:19, 235.79it/s] 48%|████▊     | 43035/90000 [03:22<03:21, 233.30it/s] 48%|████▊     | 43059/90000 [03:22<03:22, 232.30it/s] 48%|████▊     | 43083/90000 [03:22<03:22, 232.21it/s] 48%|████▊     | 43107/90000 [03:22<03:21, 232.60it/s] 48%|████▊     | 43131/90000 [03:22<03:23, 229.99it/s] 48%|████▊     | 43155/90000 [03:22<03:21, 232.17it/s] 48%|████▊     | 43181/90000 [03:22<03:15, 240.07it/s] 48%|████▊     | 43206/90000 [03:22<03:14, 240.40it/s] 48%|████▊     | 43231/90000 [03:22<03:17, 237.23it/s] 48%|████▊     | 43255/90000 [03:23<03:18, 235.05it/s] 48%|████▊     | 43279/90000 [03:23<03:19, 234.21it/s] 48%|████▊     | 43303/90000 [03:23<03:22, 230.77it/s] 48%|████▊     | 43328/90000 [03:23<03:19, 234.03it/s] 48%|████▊     | 43352/90000 [03:23<03:21, 231.62it/s] 48%|████▊     | 43376/90000 [03:23<03:24, 227.95it/s] 48%|████▊     | 43400/90000 [03:23<03:22, 230.53it/s] 48%|████▊     | 43424/90000 [03:23<03:20, 232.09it/s] 48%|████▊     | 43449/90000 [03:23<03:18, 234.79it/s] 48%|████▊     | 43473/90000 [03:23<03:17, 235.25it/s] 48%|████▊     | 43497/90000 [03:24<03:19, 233.01it/s] 48%|████▊     | 43521/90000 [03:24<03:20, 232.25it/s] 48%|████▊     | 43545/90000 [03:24<03:23, 228.09it/s] 48%|████▊     | 43569/90000 [03:24<03:20, 231.03it/s] 48%|████▊     | 43593/90000 [03:24<03:25, 226.14it/s] 48%|████▊     | 43618/90000 [03:24<03:20, 230.78it/s] 48%|████▊     | 43642/90000 [03:24<03:21, 230.16it/s] 49%|████▊     | 43667/90000 [03:24<03:18, 233.06it/s] 49%|████▊     | 43691/90000 [03:24<03:21, 230.27it/s] 49%|████▊     | 43715/90000 [03:25<03:25, 225.40it/s] 49%|████▊     | 43738/90000 [03:25<03:28, 222.10it/s] 49%|████▊     | 43763/90000 [03:25<03:21, 229.94it/s] 49%|████▊     | 43787/90000 [03:25<03:21, 229.63it/s] 49%|████▊     | 43811/90000 [03:25<03:19, 231.22it/s] 49%|████▊     | 43835/90000 [03:25<03:18, 232.00it/s] 49%|████▊     | 43860/90000 [03:25<03:16, 234.40it/s] 49%|████▉     | 43885/90000 [03:25<03:14, 237.55it/s] 49%|████▉     | 43909/90000 [03:25<03:16, 234.90it/s] 49%|████▉     | 43934/90000 [03:25<03:14, 237.45it/s] 49%|████▉     | 43960/90000 [03:26<03:10, 241.63it/s] 49%|████▉     | 43985/90000 [03:26<03:09, 242.41it/s] 49%|████▉     | 44010/90000 [03:26<03:11, 240.68it/s] 49%|████▉     | 44035/90000 [03:26<03:11, 239.74it/s] 49%|████▉     | 44059/90000 [03:26<03:12, 238.54it/s] 49%|████▉     | 44084/90000 [03:26<03:10, 241.29it/s] 49%|████▉     | 44109/90000 [03:26<03:08, 243.02it/s] 49%|████▉     | 44134/90000 [03:26<03:11, 239.27it/s] 49%|████▉     | 44158/90000 [03:26<03:12, 238.09it/s] 49%|████▉     | 44182/90000 [03:26<03:17, 231.53it/s] 49%|████▉     | 44206/90000 [03:27<03:18, 230.51it/s] 49%|████▉     | 44230/90000 [03:27<03:16, 233.24it/s] 49%|████▉     | 44254/90000 [03:27<03:14, 234.95it/s] 49%|████▉     | 44278/90000 [03:27<03:13, 235.86it/s] 49%|████▉     | 44303/90000 [03:27<03:11, 239.16it/s] 49%|████▉     | 44327/90000 [03:27<03:15, 233.63it/s] 49%|████▉     | 44352/90000 [03:27<03:13, 236.47it/s] 49%|████▉     | 44376/90000 [03:27<03:12, 237.33it/s] 49%|████▉     | 44400/90000 [03:27<03:13, 235.28it/s] 49%|████▉     | 44424/90000 [03:28<03:12, 236.43it/s] 49%|████▉     | 44448/90000 [03:28<03:14, 234.55it/s] 49%|████▉     | 44472/90000 [03:28<03:14, 234.65it/s] 49%|████▉     | 44497/90000 [03:28<03:12, 236.46it/s] 49%|████▉     | 44521/90000 [03:28<03:14, 233.40it/s] 49%|████▉     | 44545/90000 [03:28<03:16, 231.38it/s] 50%|████▉     | 44569/90000 [03:28<03:19, 228.18it/s] 50%|████▉     | 44592/90000 [03:28<03:20, 227.02it/s] 50%|████▉     | 44617/90000 [03:28<03:16, 231.44it/s] 50%|████▉     | 44642/90000 [03:28<03:12, 235.80it/s] 50%|████▉     | 44666/90000 [03:29<03:12, 235.58it/s] 50%|████▉     | 44690/90000 [03:29<03:13, 233.75it/s] 50%|████▉     | 44715/90000 [03:29<03:12, 235.01it/s] 50%|████▉     | 44739/90000 [03:29<03:12, 235.42it/s] 50%|████▉     | 44763/90000 [03:29<03:14, 233.03it/s] 50%|████▉     | 44787/90000 [03:29<03:13, 233.67it/s] 50%|████▉     | 44811/90000 [03:29<03:14, 232.36it/s] 50%|████▉     | 44835/90000 [03:29<03:12, 234.49it/s] 50%|████▉     | 44859/90000 [03:29<03:15, 230.58it/s] 50%|████▉     | 44883/90000 [03:29<03:16, 230.01it/s] 50%|████▉     | 44907/90000 [03:30<03:16, 229.03it/s] 50%|████▉     | 44931/90000 [03:30<03:15, 230.17it/s] 50%|████▉     | 44956/90000 [03:30<03:12, 233.61it/s] 50%|████▉     | 44980/90000 [03:30<03:12, 233.50it/s] 50%|█████     | 45004/90000 [03:30<03:13, 231.97it/s] 50%|█████     | 45028/90000 [03:30<03:13, 232.29it/s] 50%|█████     | 45054/90000 [03:30<03:08, 238.50it/s] 50%|█████     | 45078/90000 [03:30<03:09, 237.16it/s] 50%|█████     | 45103/90000 [03:30<03:08, 238.47it/s] 50%|█████     | 45127/90000 [03:31<03:10, 236.15it/s] 50%|█████     | 45151/90000 [03:31<03:11, 234.32it/s] 50%|█████     | 45175/90000 [03:31<03:13, 231.85it/s] 50%|█████     | 45200/90000 [03:31<03:09, 236.02it/s] 50%|█████     | 45224/90000 [03:31<03:09, 236.87it/s] 50%|█████     | 45248/90000 [03:31<03:08, 237.67it/s] 50%|█████     | 45272/90000 [03:31<03:12, 231.87it/s] 50%|█████     | 45297/90000 [03:31<03:10, 234.40it/s] 50%|█████     | 45321/90000 [03:31<03:12, 232.60it/s] 50%|█████     | 45345/90000 [03:31<03:12, 231.85it/s] 50%|█████     | 45369/90000 [03:32<03:11, 232.81it/s] 50%|█████     | 45393/90000 [03:32<03:13, 230.89it/s] 50%|█████     | 45418/90000 [03:32<03:08, 235.91it/s] 50%|█████     | 45442/90000 [03:32<03:09, 235.18it/s] 51%|█████     | 45466/90000 [03:32<03:09, 234.59it/s] 51%|█████     | 45491/90000 [03:32<03:08, 236.65it/s] 51%|█████     | 45515/90000 [03:32<03:07, 237.43it/s] 51%|█████     | 45539/90000 [03:32<03:08, 235.70it/s] 51%|█████     | 45563/90000 [03:32<03:07, 236.90it/s] 51%|█████     | 45587/90000 [03:32<03:10, 233.41it/s] 51%|█████     | 45611/90000 [03:33<03:09, 234.27it/s] 51%|█████     | 45635/90000 [03:33<03:11, 232.25it/s] 51%|█████     | 45659/90000 [03:33<03:09, 233.70it/s] 51%|█████     | 45684/90000 [03:33<03:07, 235.73it/s] 51%|█████     | 45708/90000 [03:33<03:07, 236.03it/s] 51%|█████     | 45732/90000 [03:33<03:08, 235.03it/s] 51%|█████     | 45756/90000 [03:33<03:14, 227.58it/s] 51%|█████     | 45779/90000 [03:33<03:13, 228.08it/s] 51%|█████     | 45803/90000 [03:33<03:12, 229.49it/s] 51%|█████     | 45826/90000 [03:34<03:15, 226.41it/s] 51%|█████     | 45850/90000 [03:34<03:12, 229.14it/s] 51%|█████     | 45874/90000 [03:34<03:10, 231.69it/s] 51%|█████     | 45898/90000 [03:34<03:11, 230.56it/s] 51%|█████     | 45922/90000 [03:34<03:09, 232.27it/s] 51%|█████     | 45946/90000 [03:34<03:07, 234.41it/s] 51%|█████     | 45970/90000 [03:34<03:06, 235.49it/s] 51%|█████     | 45994/90000 [03:34<03:06, 236.22it/s] 51%|█████     | 46018/90000 [03:34<03:10, 230.99it/s] 51%|█████     | 46042/90000 [03:34<03:09, 232.44it/s] 51%|█████     | 46066/90000 [03:35<03:08, 233.07it/s] 51%|█████     | 46090/90000 [03:35<03:09, 231.82it/s] 51%|█████     | 46114/90000 [03:35<03:10, 230.54it/s] 51%|█████▏    | 46138/90000 [03:35<03:09, 231.39it/s] 51%|█████▏    | 46162/90000 [03:35<03:08, 232.21it/s] 51%|█████▏    | 46186/90000 [03:35<03:08, 232.57it/s] 51%|█████▏    | 46211/90000 [03:35<03:06, 235.22it/s] 51%|█████▏    | 46235/90000 [03:35<03:07, 232.95it/s] 51%|█████▏    | 46259/90000 [03:35<03:06, 234.90it/s] 51%|█████▏    | 46283/90000 [03:35<03:05, 236.27it/s] 51%|█████▏    | 46307/90000 [03:36<03:07, 233.43it/s] 51%|█████▏    | 46331/90000 [03:36<03:05, 235.22it/s] 52%|█████▏    | 46355/90000 [03:36<03:05, 235.21it/s] 52%|█████▏    | 46379/90000 [03:36<03:07, 233.16it/s] 52%|█████▏    | 46403/90000 [03:36<03:07, 232.62it/s] 52%|█████▏    | 46427/90000 [03:36<03:06, 233.46it/s] 52%|█████▏    | 46451/90000 [03:36<03:06, 233.75it/s] 52%|█████▏    | 46475/90000 [03:36<03:08, 231.30it/s] 52%|█████▏    | 46500/90000 [03:36<03:05, 234.23it/s] 52%|█████▏    | 46524/90000 [03:37<03:05, 234.87it/s] 52%|█████▏    | 46548/90000 [03:37<03:05, 234.70it/s] 52%|█████▏    | 46572/90000 [03:37<03:04, 235.20it/s] 52%|█████▏    | 46598/90000 [03:37<03:00, 240.23it/s] 52%|█████▏    | 46623/90000 [03:37<03:03, 236.75it/s] 52%|█████▏    | 46648/90000 [03:37<03:02, 237.91it/s] 52%|█████▏    | 46673/90000 [03:37<03:00, 240.69it/s] 52%|█████▏    | 46698/90000 [03:37<03:03, 236.45it/s] 52%|█████▏    | 46723/90000 [03:37<03:01, 238.29it/s] 52%|█████▏    | 46747/90000 [03:37<03:02, 236.95it/s] 52%|█████▏    | 46771/90000 [03:38<03:02, 236.68it/s] 52%|█████▏    | 46796/90000 [03:38<03:02, 237.30it/s] 52%|█████▏    | 46820/90000 [03:38<03:01, 237.57it/s] 52%|█████▏    | 46844/90000 [03:38<03:02, 236.34it/s] 52%|█████▏    | 46868/90000 [03:38<03:02, 236.88it/s] 52%|█████▏    | 46892/90000 [03:38<03:02, 236.05it/s] 52%|█████▏    | 46916/90000 [03:38<03:04, 234.06it/s] 52%|█████▏    | 46940/90000 [03:38<03:03, 235.04it/s] 52%|█████▏    | 46964/90000 [03:38<03:05, 232.44it/s] 52%|█████▏    | 46988/90000 [03:38<03:06, 231.13it/s] 52%|█████▏    | 47012/90000 [03:39<03:05, 232.24it/s] 52%|█████▏    | 47036/90000 [03:39<03:03, 233.74it/s] 52%|█████▏    | 47060/90000 [03:39<03:03, 233.73it/s] 52%|█████▏    | 47085/90000 [03:39<03:02, 235.41it/s] 52%|█████▏    | 47110/90000 [03:39<02:59, 238.34it/s] 52%|█████▏    | 47134/90000 [03:39<03:00, 237.82it/s] 52%|█████▏    | 47158/90000 [03:39<03:02, 234.77it/s] 52%|█████▏    | 47183/90000 [03:39<03:01, 235.29it/s] 52%|█████▏    | 47207/90000 [03:39<03:02, 234.30it/s] 52%|█████▏    | 47231/90000 [03:40<03:02, 234.55it/s] 53%|█████▎    | 47256/90000 [03:40<03:00, 236.55it/s] 53%|█████▎    | 47281/90000 [03:40<02:58, 239.75it/s] 53%|█████▎    | 47305/90000 [03:40<03:00, 236.19it/s] 53%|█████▎    | 47329/90000 [03:40<03:04, 230.98it/s] 53%|█████▎    | 47353/90000 [03:40<03:05, 229.95it/s] 53%|█████▎    | 47378/90000 [03:40<03:01, 235.43it/s] 53%|█████▎    | 47402/90000 [03:40<03:01, 234.70it/s] 53%|█████▎    | 47426/90000 [03:40<03:01, 234.92it/s] 53%|█████▎    | 47450/90000 [03:40<03:05, 229.26it/s] 53%|█████▎    | 47474/90000 [03:41<03:05, 229.84it/s] 53%|█████▎    | 47498/90000 [03:41<03:06, 227.46it/s] 53%|█████▎    | 47521/90000 [03:41<03:07, 226.97it/s] 53%|█████▎    | 47544/90000 [03:41<03:07, 226.93it/s] 53%|█████▎    | 47568/90000 [03:41<03:06, 228.06it/s] 53%|█████▎    | 47591/90000 [03:41<03:07, 226.71it/s] 53%|█████▎    | 47615/90000 [03:41<03:03, 230.44it/s] 53%|█████▎    | 47640/90000 [03:41<03:01, 233.66it/s] 53%|█████▎    | 47664/90000 [03:41<03:00, 233.94it/s] 53%|█████▎    | 47688/90000 [03:41<03:01, 233.08it/s] 53%|█████▎    | 47712/90000 [03:42<03:02, 231.44it/s] 53%|█████▎    | 47736/90000 [03:42<03:01, 232.66it/s] 53%|█████▎    | 47760/90000 [03:42<03:03, 230.62it/s] 53%|█████▎    | 47784/90000 [03:42<03:02, 230.81it/s] 53%|█████▎    | 47808/90000 [03:42<03:03, 230.09it/s] 53%|█████▎    | 47832/90000 [03:42<03:04, 228.89it/s] 53%|█████▎    | 47855/90000 [03:42<03:04, 228.77it/s] 53%|█████▎    | 47878/90000 [03:42<03:05, 226.92it/s] 53%|█████▎    | 47901/90000 [03:42<03:09, 221.92it/s] 53%|█████▎    | 47924/90000 [03:43<03:08, 223.66it/s] 53%|█████▎    | 47947/90000 [03:43<03:09, 222.16it/s] 53%|█████▎    | 47970/90000 [03:43<03:07, 224.41it/s] 53%|█████▎    | 47993/90000 [03:43<03:10, 220.68it/s] 53%|█████▎    | 48016/90000 [03:43<03:12, 218.08it/s] 53%|█████▎    | 48039/90000 [03:43<03:11, 219.00it/s] 53%|█████▎    | 48061/90000 [03:43<03:12, 217.52it/s] 53%|█████▎    | 48083/90000 [03:43<03:12, 217.21it/s] 53%|█████▎    | 48105/90000 [03:43<03:13, 216.33it/s] 53%|█████▎    | 48127/90000 [03:43<03:13, 216.41it/s] 54%|█████▎    | 48151/90000 [03:44<03:09, 220.31it/s] 54%|█████▎    | 48174/90000 [03:44<03:12, 217.17it/s] 54%|█████▎    | 48196/90000 [03:44<03:15, 213.82it/s] 54%|█████▎    | 48220/90000 [03:44<03:10, 218.97it/s] 54%|█████▎    | 48244/90000 [03:44<03:05, 224.54it/s] 54%|█████▎    | 48268/90000 [03:44<03:04, 226.11it/s] 54%|█████▎    | 48291/90000 [03:44<03:05, 224.97it/s] 54%|█████▎    | 48314/90000 [03:44<03:06, 223.90it/s] 54%|█████▎    | 48337/90000 [03:44<03:08, 221.19it/s] 54%|█████▎    | 48360/90000 [03:45<03:07, 221.64it/s] 54%|█████▍    | 48383/90000 [03:45<03:08, 220.80it/s] 54%|█████▍    | 48407/90000 [03:45<03:04, 225.00it/s] 54%|█████▍    | 48431/90000 [03:45<03:03, 226.52it/s] 54%|█████▍    | 48454/90000 [03:45<03:07, 220.99it/s] 54%|█████▍    | 48477/90000 [03:45<03:06, 223.09it/s] 54%|█████▍    | 48501/90000 [03:45<03:03, 226.71it/s] 54%|█████▍    | 48524/90000 [03:45<03:05, 223.91it/s] 54%|█████▍    | 48547/90000 [03:45<03:05, 224.04it/s] 54%|█████▍    | 48570/90000 [03:45<03:06, 222.69it/s] 54%|█████▍    | 48594/90000 [03:46<03:02, 226.87it/s] 54%|█████▍    | 48617/90000 [03:46<03:03, 226.13it/s] 54%|█████▍    | 48640/90000 [03:46<03:04, 224.17it/s] 54%|█████▍    | 48664/90000 [03:46<03:03, 225.86it/s] 54%|█████▍    | 48687/90000 [03:46<03:03, 225.21it/s] 54%|█████▍    | 48710/90000 [03:46<03:05, 222.81it/s] 54%|█████▍    | 48734/90000 [03:46<03:01, 227.39it/s] 54%|█████▍    | 48759/90000 [03:46<02:57, 231.77it/s] 54%|█████▍    | 48783/90000 [03:46<02:59, 229.13it/s] 54%|█████▍    | 48807/90000 [03:46<02:58, 231.40it/s] 54%|█████▍    | 48831/90000 [03:47<03:00, 228.42it/s] 54%|█████▍    | 48854/90000 [03:47<02:59, 228.76it/s] 54%|█████▍    | 48877/90000 [03:47<03:00, 228.05it/s] 54%|█████▍    | 48900/90000 [03:47<03:04, 222.91it/s] 54%|█████▍    | 48923/90000 [03:47<03:02, 224.59it/s] 54%|█████▍    | 48946/90000 [03:47<03:02, 224.70it/s] 54%|█████▍    | 48969/90000 [03:47<03:03, 223.06it/s] 54%|█████▍    | 48992/90000 [03:47<03:04, 222.75it/s] 54%|█████▍    | 49015/90000 [03:47<03:02, 224.37it/s] 54%|█████▍    | 49038/90000 [03:48<03:01, 225.24it/s] 55%|█████▍    | 49061/90000 [03:48<03:05, 220.92it/s] 55%|█████▍    | 49084/90000 [03:48<03:03, 222.74it/s] 55%|█████▍    | 49107/90000 [03:48<03:02, 224.19it/s] 55%|█████▍    | 49131/90000 [03:48<03:00, 226.51it/s] 55%|█████▍    | 49156/90000 [03:48<02:56, 231.66it/s] 55%|█████▍    | 49180/90000 [03:48<03:00, 226.13it/s] 55%|█████▍    | 49205/90000 [03:48<02:56, 230.87it/s] 55%|█████▍    | 49229/90000 [03:48<02:55, 231.80it/s] 55%|█████▍    | 49253/90000 [03:48<03:00, 225.46it/s] 55%|█████▍    | 49276/90000 [03:49<03:01, 224.14it/s] 55%|█████▍    | 49300/90000 [03:49<03:00, 225.36it/s] 55%|█████▍    | 49323/90000 [03:49<03:03, 221.41it/s] 55%|█████▍    | 49346/90000 [03:49<03:02, 222.56it/s] 55%|█████▍    | 49369/90000 [03:49<03:01, 223.75it/s] 55%|█████▍    | 49392/90000 [03:49<03:00, 225.23it/s] 55%|█████▍    | 49416/90000 [03:49<02:56, 229.53it/s] 55%|█████▍    | 49439/90000 [03:49<02:59, 226.03it/s] 55%|█████▍    | 49463/90000 [03:49<02:56, 229.04it/s] 55%|█████▍    | 49488/90000 [03:49<02:53, 232.90it/s] 55%|█████▌    | 49512/90000 [03:50<02:54, 231.57it/s] 55%|█████▌    | 49536/90000 [03:50<02:56, 229.22it/s] 55%|█████▌    | 49561/90000 [03:50<02:53, 232.82it/s] 55%|█████▌    | 49585/90000 [03:50<02:53, 233.16it/s] 55%|█████▌    | 49609/90000 [03:50<02:54, 232.01it/s] 55%|█████▌    | 49633/90000 [03:50<02:54, 231.70it/s] 55%|█████▌    | 49658/90000 [03:50<02:52, 234.44it/s] 55%|█████▌    | 49682/90000 [03:50<02:52, 234.00it/s] 55%|█████▌    | 49706/90000 [03:50<02:55, 229.98it/s] 55%|█████▌    | 49730/90000 [03:51<02:56, 227.84it/s] 55%|█████▌    | 49753/90000 [03:51<02:57, 226.79it/s] 55%|█████▌    | 49777/90000 [03:51<02:55, 228.56it/s] 55%|█████▌    | 49801/90000 [03:51<02:54, 230.11it/s] 55%|█████▌    | 49825/90000 [03:51<02:53, 231.38it/s] 55%|█████▌    | 49850/90000 [03:51<02:51, 234.40it/s] 55%|█████▌    | 49874/90000 [03:51<02:53, 230.89it/s] 55%|█████▌    | 49898/90000 [03:51<02:53, 230.99it/s] 55%|█████▌    | 49923/90000 [03:51<02:50, 234.46it/s] 55%|█████▌    | 49947/90000 [03:51<02:53, 231.43it/s] 56%|█████▌    | 49972/90000 [03:52<02:49, 235.68it/s] 56%|█████▌    | 49996/90000 [03:52<02:55, 228.55it/s] 56%|█████▌    | 50020/90000 [03:52<02:53, 230.70it/s] 56%|█████▌    | 50044/90000 [03:52<02:52, 231.69it/s] 56%|█████▌    | 50068/90000 [03:52<02:52, 231.22it/s] 56%|█████▌    | 50092/90000 [03:52<02:54, 229.03it/s] 56%|█████▌    | 50116/90000 [03:52<02:52, 231.73it/s] 56%|█████▌    | 50141/90000 [03:52<02:49, 234.87it/s] 56%|█████▌    | 50165/90000 [03:52<02:48, 236.15it/s] 56%|█████▌    | 50189/90000 [03:53<02:53, 230.08it/s] 56%|█████▌    | 50213/90000 [03:53<02:53, 229.88it/s] 56%|█████▌    | 50237/90000 [03:53<02:53, 229.81it/s] 56%|█████▌    | 50261/90000 [03:53<02:51, 232.11it/s] 56%|█████▌    | 50285/90000 [03:53<02:50, 232.39it/s] 56%|█████▌    | 50309/90000 [03:53<02:52, 230.48it/s] 56%|█████▌    | 50333/90000 [03:53<02:53, 228.52it/s] 56%|█████▌    | 50356/90000 [03:53<02:56, 224.04it/s] 56%|█████▌    | 50379/90000 [03:53<02:57, 223.27it/s] 56%|█████▌    | 50403/90000 [03:53<02:55, 225.41it/s] 56%|█████▌    | 50426/90000 [03:54<02:57, 223.03it/s] 56%|█████▌    | 50449/90000 [03:54<02:58, 221.78it/s] 56%|█████▌    | 50472/90000 [03:54<02:58, 221.91it/s] 56%|█████▌    | 50496/90000 [03:54<02:56, 223.73it/s] 56%|█████▌    | 50520/90000 [03:54<02:55, 224.89it/s] 56%|█████▌    | 50543/90000 [03:54<02:57, 222.59it/s] 56%|█████▌    | 50566/90000 [03:54<02:56, 223.92it/s] 56%|█████▌    | 50589/90000 [03:54<02:57, 222.60it/s] 56%|█████▌    | 50612/90000 [03:54<02:56, 222.73it/s] 56%|█████▋    | 50635/90000 [03:55<02:55, 224.60it/s] 56%|█████▋    | 50658/90000 [03:55<02:58, 220.97it/s] 56%|█████▋    | 50681/90000 [03:55<02:57, 221.99it/s] 56%|█████▋    | 50704/90000 [03:55<02:57, 221.86it/s] 56%|█████▋    | 50728/90000 [03:55<02:54, 225.32it/s] 56%|█████▋    | 50751/90000 [03:55<02:53, 226.56it/s] 56%|█████▋    | 50774/90000 [03:55<02:53, 226.50it/s] 56%|█████▋    | 50799/90000 [03:55<02:49, 231.93it/s] 56%|█████▋    | 50823/90000 [03:55<02:49, 231.72it/s] 56%|█████▋    | 50847/90000 [03:55<02:48, 232.59it/s] 57%|█████▋    | 50871/90000 [03:56<02:54, 224.42it/s] 57%|█████▋    | 50895/90000 [03:56<02:52, 227.17it/s] 57%|█████▋    | 50918/90000 [03:56<02:52, 226.51it/s] 57%|█████▋    | 50941/90000 [03:56<02:54, 223.37it/s] 57%|█████▋    | 50965/90000 [03:56<02:51, 227.21it/s] 57%|█████▋    | 50989/90000 [03:56<02:49, 229.74it/s] 57%|█████▋    | 51012/90000 [03:56<02:51, 227.06it/s] 57%|█████▋    | 51035/90000 [03:56<02:53, 224.63it/s] 57%|█████▋    | 51058/90000 [03:56<02:55, 221.97it/s] 57%|█████▋    | 51082/90000 [03:56<02:52, 225.36it/s] 57%|█████▋    | 51105/90000 [03:57<02:57, 219.38it/s] 57%|█████▋    | 51128/90000 [03:57<02:54, 222.35it/s] 57%|█████▋    | 51151/90000 [03:57<02:55, 221.93it/s] 57%|█████▋    | 51175/90000 [03:57<02:51, 226.56it/s] 57%|█████▋    | 51199/90000 [03:57<02:49, 228.96it/s] 57%|█████▋    | 51222/90000 [03:57<02:49, 228.89it/s] 57%|█████▋    | 51245/90000 [03:57<02:49, 228.55it/s] 57%|█████▋    | 51268/90000 [03:57<02:51, 225.91it/s] 57%|█████▋    | 51291/90000 [03:57<02:54, 221.55it/s] 57%|█████▋    | 51314/90000 [03:58<02:54, 221.29it/s] 57%|█████▋    | 51337/90000 [03:58<02:55, 219.96it/s] 57%|█████▋    | 51360/90000 [03:58<02:54, 221.68it/s] 57%|█████▋    | 51383/90000 [03:58<02:54, 221.12it/s] 57%|█████▋    | 51406/90000 [03:58<02:58, 216.29it/s] 57%|█████▋    | 51428/90000 [03:58<02:58, 216.10it/s] 57%|█████▋    | 51450/90000 [03:58<02:57, 216.88it/s] 57%|█████▋    | 51472/90000 [03:58<02:57, 217.18it/s] 57%|█████▋    | 51494/90000 [03:58<03:00, 213.89it/s] 57%|█████▋    | 51516/90000 [03:58<03:00, 213.48it/s] 57%|█████▋    | 51538/90000 [03:59<02:59, 213.76it/s] 57%|█████▋    | 51561/90000 [03:59<02:57, 216.30it/s] 57%|█████▋    | 51583/90000 [03:59<02:57, 216.25it/s] 57%|█████▋    | 51605/90000 [03:59<03:00, 212.85it/s] 57%|█████▋    | 51628/90000 [03:59<02:56, 217.24it/s] 57%|█████▋    | 51650/90000 [03:59<02:56, 217.74it/s] 57%|█████▋    | 51673/90000 [03:59<02:53, 220.51it/s] 57%|█████▋    | 51696/90000 [03:59<02:53, 220.40it/s] 57%|█████▋    | 51719/90000 [03:59<02:57, 216.09it/s] 57%|█████▋    | 51741/90000 [03:59<02:57, 215.38it/s] 58%|█████▊    | 51764/90000 [04:00<02:55, 218.06it/s] 58%|█████▊    | 51786/90000 [04:00<02:55, 218.24it/s] 58%|█████▊    | 51810/90000 [04:00<02:51, 222.21it/s] 58%|█████▊    | 51833/90000 [04:00<02:51, 222.68it/s] 58%|█████▊    | 51856/90000 [04:00<02:54, 218.09it/s] 58%|█████▊    | 51878/90000 [04:00<02:54, 217.89it/s] 58%|█████▊    | 51901/90000 [04:00<02:53, 219.28it/s] 58%|█████▊    | 51924/90000 [04:00<02:51, 221.55it/s] 58%|█████▊    | 51947/90000 [04:00<02:50, 222.94it/s] 58%|█████▊    | 51970/90000 [04:01<02:51, 221.87it/s] 58%|█████▊    | 51993/90000 [04:01<02:52, 220.07it/s] 58%|█████▊    | 52016/90000 [04:01<02:51, 221.69it/s] 58%|█████▊    | 52039/90000 [04:01<02:52, 219.84it/s] 58%|█████▊    | 52062/90000 [04:01<02:51, 220.68it/s] 58%|█████▊    | 52085/90000 [04:01<02:52, 219.92it/s] 58%|█████▊    | 52107/90000 [04:01<02:55, 215.89it/s] 58%|█████▊    | 52129/90000 [04:01<02:56, 214.82it/s] 58%|█████▊    | 52152/90000 [04:01<02:53, 217.69it/s] 58%|█████▊    | 52174/90000 [04:01<02:56, 214.36it/s] 58%|█████▊    | 52196/90000 [04:02<02:55, 215.66it/s] 58%|█████▊    | 52218/90000 [04:02<02:57, 213.41it/s] 58%|█████▊    | 52241/90000 [04:02<02:53, 217.33it/s] 58%|█████▊    | 52263/90000 [04:02<02:53, 217.89it/s] 58%|█████▊    | 52285/90000 [04:02<02:55, 215.15it/s] 58%|█████▊    | 52307/90000 [04:02<02:58, 211.08it/s] 58%|█████▊    | 52329/90000 [04:02<02:56, 213.36it/s] 58%|█████▊    | 52352/90000 [04:02<02:54, 215.79it/s] 58%|█████▊    | 52376/90000 [04:02<02:50, 220.20it/s] 58%|█████▊    | 52399/90000 [04:03<02:54, 215.56it/s] 58%|█████▊    | 52421/90000 [04:03<02:57, 212.05it/s] 58%|█████▊    | 52443/90000 [04:03<02:56, 213.14it/s] 58%|█████▊    | 52465/90000 [04:03<02:59, 208.96it/s] 58%|█████▊    | 52486/90000 [04:03<03:02, 205.35it/s] 58%|█████▊    | 52507/90000 [04:03<03:07, 200.47it/s] 58%|█████▊    | 52528/90000 [04:03<03:09, 197.72it/s] 58%|█████▊    | 52548/90000 [04:03<03:11, 195.76it/s] 58%|█████▊    | 52568/90000 [04:03<03:13, 193.68it/s] 58%|█████▊    | 52589/90000 [04:03<03:09, 196.94it/s] 58%|█████▊    | 52610/90000 [04:04<03:08, 198.59it/s] 58%|█████▊    | 52630/90000 [04:04<03:10, 195.97it/s] 59%|█████▊    | 52651/90000 [04:04<03:07, 198.82it/s] 59%|█████▊    | 52671/90000 [04:04<03:07, 199.14it/s] 59%|█████▊    | 52691/90000 [04:04<03:09, 196.37it/s] 59%|█████▊    | 52713/90000 [04:04<03:05, 200.75it/s] 59%|█████▊    | 52735/90000 [04:04<03:00, 206.28it/s] 59%|█████▊    | 52757/90000 [04:04<02:58, 208.31it/s] 59%|█████▊    | 52778/90000 [04:04<03:00, 206.22it/s] 59%|█████▊    | 52799/90000 [04:05<03:00, 206.19it/s] 59%|█████▊    | 52820/90000 [04:05<03:00, 205.89it/s] 59%|█████▊    | 52841/90000 [04:05<03:03, 202.60it/s] 59%|█████▊    | 52864/90000 [04:05<02:57, 208.70it/s] 59%|█████▉    | 52886/90000 [04:05<02:55, 211.38it/s] 59%|█████▉    | 52908/90000 [04:05<02:58, 207.61it/s] 59%|█████▉    | 52929/90000 [04:05<02:59, 206.42it/s] 59%|█████▉    | 52950/90000 [04:05<03:00, 205.64it/s] 59%|█████▉    | 52971/90000 [04:05<03:04, 200.94it/s] 59%|█████▉    | 52992/90000 [04:05<03:06, 198.75it/s] 59%|█████▉    | 53012/90000 [04:06<03:06, 198.01it/s] 59%|█████▉    | 53036/90000 [04:06<02:57, 208.72it/s] 59%|█████▉    | 53058/90000 [04:06<02:56, 209.84it/s] 59%|█████▉    | 53082/90000 [04:06<02:50, 216.15it/s] 59%|█████▉    | 53105/90000 [04:06<02:48, 219.50it/s] 59%|█████▉    | 53127/90000 [04:06<02:52, 214.10it/s] 59%|█████▉    | 53149/90000 [04:06<02:53, 211.87it/s] 59%|█████▉    | 53172/90000 [04:06<02:51, 215.23it/s] 59%|█████▉    | 53195/90000 [04:06<02:48, 218.81it/s] 59%|█████▉    | 53217/90000 [04:06<02:51, 214.38it/s] 59%|█████▉    | 53239/90000 [04:07<02:51, 213.90it/s] 59%|█████▉    | 53262/90000 [04:07<02:48, 218.13it/s] 59%|█████▉    | 53284/90000 [04:07<02:52, 212.83it/s] 59%|█████▉    | 53306/90000 [04:07<02:53, 211.91it/s] 59%|█████▉    | 53328/90000 [04:07<02:51, 213.89it/s] 59%|█████▉    | 53351/90000 [04:07<02:48, 217.21it/s] 59%|█████▉    | 53373/90000 [04:07<02:49, 216.44it/s] 59%|█████▉    | 53395/90000 [04:07<02:49, 215.99it/s] 59%|█████▉    | 53417/90000 [04:07<02:51, 213.38it/s] 59%|█████▉    | 53439/90000 [04:08<02:53, 210.93it/s] 59%|█████▉    | 53463/90000 [04:08<02:48, 217.12it/s] 59%|█████▉    | 53487/90000 [04:08<02:45, 221.24it/s] 59%|█████▉    | 53510/90000 [04:08<02:44, 222.42it/s] 59%|█████▉    | 53533/90000 [04:08<02:44, 221.14it/s] 60%|█████▉    | 53556/90000 [04:08<02:48, 216.30it/s] 60%|█████▉    | 53578/90000 [04:08<02:50, 213.88it/s] 60%|█████▉    | 53600/90000 [04:08<02:49, 214.82it/s] 60%|█████▉    | 53622/90000 [04:08<02:55, 206.94it/s] 60%|█████▉    | 53643/90000 [04:08<02:55, 207.27it/s] 60%|█████▉    | 53665/90000 [04:09<02:53, 209.25it/s] 60%|█████▉    | 53686/90000 [04:09<02:54, 208.55it/s] 60%|█████▉    | 53708/90000 [04:09<02:51, 211.66it/s] 60%|█████▉    | 53730/90000 [04:09<02:52, 210.71it/s] 60%|█████▉    | 53752/90000 [04:09<02:51, 211.86it/s] 60%|█████▉    | 53774/90000 [04:09<02:51, 210.94it/s] 60%|█████▉    | 53796/90000 [04:09<02:52, 210.13it/s] 60%|█████▉    | 53819/90000 [04:09<02:47, 215.50it/s] 60%|█████▉    | 53841/90000 [04:09<02:49, 213.79it/s] 60%|█████▉    | 53863/90000 [04:10<02:48, 214.63it/s] 60%|█████▉    | 53885/90000 [04:10<02:48, 213.74it/s] 60%|█████▉    | 53909/90000 [04:10<02:44, 219.46it/s] 60%|█████▉    | 53931/90000 [04:10<02:48, 213.98it/s] 60%|█████▉    | 53953/90000 [04:10<02:49, 212.18it/s] 60%|█████▉    | 53976/90000 [04:10<02:46, 216.03it/s] 60%|█████▉    | 53998/90000 [04:10<02:50, 211.75it/s] 60%|██████    | 54020/90000 [04:10<02:50, 210.68it/s] 60%|██████    | 54042/90000 [04:10<02:49, 212.38it/s] 60%|██████    | 54064/90000 [04:10<02:50, 210.52it/s] 60%|██████    | 54086/90000 [04:11<02:53, 207.28it/s] 60%|██████    | 54107/90000 [04:11<02:55, 204.28it/s] 60%|██████    | 54128/90000 [04:11<02:56, 203.27it/s] 60%|██████    | 54150/90000 [04:11<02:54, 205.85it/s] 60%|██████    | 54171/90000 [04:11<02:55, 204.70it/s] 60%|██████    | 54193/90000 [04:11<02:52, 207.82it/s] 60%|██████    | 54214/90000 [04:11<02:52, 207.28it/s] 60%|██████    | 54235/90000 [04:11<02:56, 202.71it/s] 60%|██████    | 54256/90000 [04:11<02:58, 200.35it/s] 60%|██████    | 54277/90000 [04:12<02:59, 199.50it/s] 60%|██████    | 54297/90000 [04:12<02:59, 198.38it/s] 60%|██████    | 54317/90000 [04:12<03:00, 197.32it/s] 60%|██████    | 54337/90000 [04:12<03:03, 194.28it/s] 60%|██████    | 54360/90000 [04:12<02:55, 203.43it/s] 60%|██████    | 54381/90000 [04:12<02:54, 203.73it/s] 60%|██████    | 54403/90000 [04:12<02:51, 207.70it/s] 60%|██████    | 54425/90000 [04:12<02:50, 208.43it/s] 60%|██████    | 54446/90000 [04:12<02:54, 204.31it/s] 61%|██████    | 54467/90000 [04:12<02:52, 205.60it/s] 61%|██████    | 54490/90000 [04:13<02:49, 210.11it/s] 61%|██████    | 54512/90000 [04:13<02:51, 206.58it/s] 61%|██████    | 54536/90000 [04:13<02:45, 214.22it/s] 61%|██████    | 54558/90000 [04:13<02:45, 214.19it/s] 61%|██████    | 54580/90000 [04:13<02:45, 214.64it/s] 61%|██████    | 54604/90000 [04:13<02:41, 219.81it/s] 61%|██████    | 54627/90000 [04:13<02:40, 219.95it/s] 61%|██████    | 54650/90000 [04:13<02:40, 220.26it/s] 61%|██████    | 54673/90000 [04:13<02:39, 221.14it/s] 61%|██████    | 54696/90000 [04:13<02:37, 223.57it/s] 61%|██████    | 54719/90000 [04:14<02:41, 218.75it/s] 61%|██████    | 54741/90000 [04:14<02:43, 215.76it/s] 61%|██████    | 54763/90000 [04:14<02:48, 209.25it/s] 61%|██████    | 54786/90000 [04:14<02:43, 214.89it/s] 61%|██████    | 54808/90000 [04:14<02:43, 215.36it/s] 61%|██████    | 54830/90000 [04:14<02:44, 214.20it/s] 61%|██████    | 54853/90000 [04:14<02:41, 217.33it/s] 61%|██████    | 54876/90000 [04:14<02:41, 218.11it/s] 61%|██████    | 54898/90000 [04:14<02:41, 217.46it/s] 61%|██████    | 54920/90000 [04:15<02:41, 216.85it/s] 61%|██████    | 54942/90000 [04:15<02:43, 214.53it/s] 61%|██████    | 54964/90000 [04:15<02:44, 212.68it/s] 61%|██████    | 54986/90000 [04:15<02:43, 214.58it/s] 61%|██████    | 55009/90000 [04:15<02:41, 216.80it/s] 61%|██████    | 55031/90000 [04:15<02:41, 216.04it/s] 61%|██████    | 55053/90000 [04:15<02:43, 214.17it/s] 61%|██████    | 55075/90000 [04:15<02:43, 214.02it/s] 61%|██████    | 55097/90000 [04:15<02:41, 215.64it/s] 61%|██████    | 55119/90000 [04:15<02:41, 215.57it/s] 61%|██████▏   | 55141/90000 [04:16<02:41, 215.33it/s] 61%|██████▏   | 55163/90000 [04:16<02:41, 215.64it/s] 61%|██████▏   | 55186/90000 [04:16<02:39, 218.47it/s] 61%|██████▏   | 55208/90000 [04:16<02:39, 217.93it/s] 61%|██████▏   | 55232/90000 [04:16<02:36, 222.73it/s] 61%|██████▏   | 55255/90000 [04:16<02:37, 220.57it/s] 61%|██████▏   | 55278/90000 [04:16<02:40, 216.98it/s] 61%|██████▏   | 55302/90000 [04:16<02:35, 223.24it/s] 61%|██████▏   | 55325/90000 [04:16<02:36, 222.07it/s] 61%|██████▏   | 55348/90000 [04:16<02:37, 220.13it/s] 62%|██████▏   | 55371/90000 [04:17<02:35, 222.42it/s] 62%|██████▏   | 55394/90000 [04:17<02:37, 219.72it/s] 62%|██████▏   | 55417/90000 [04:17<02:35, 222.01it/s] 62%|██████▏   | 55441/90000 [04:17<02:32, 225.99it/s] 62%|██████▏   | 55464/90000 [04:17<02:33, 225.14it/s] 62%|██████▏   | 55487/90000 [04:17<02:32, 226.54it/s] 62%|██████▏   | 55510/90000 [04:17<02:36, 220.66it/s] 62%|██████▏   | 55533/90000 [04:17<02:35, 221.88it/s] 62%|██████▏   | 55556/90000 [04:17<02:35, 222.16it/s] 62%|██████▏   | 55579/90000 [04:18<02:34, 222.26it/s] 62%|██████▏   | 55602/90000 [04:18<02:33, 223.54it/s] 62%|██████▏   | 55625/90000 [04:18<02:33, 223.56it/s] 62%|██████▏   | 55648/90000 [04:18<02:34, 222.32it/s] 62%|██████▏   | 55671/90000 [04:18<02:34, 221.57it/s] 62%|██████▏   | 55695/90000 [04:18<02:32, 224.46it/s] 62%|██████▏   | 55718/90000 [04:18<02:32, 225.45it/s] 62%|██████▏   | 55741/90000 [04:18<02:32, 224.13it/s] 62%|██████▏   | 55764/90000 [04:18<02:32, 225.14it/s] 62%|██████▏   | 55788/90000 [04:18<02:30, 226.73it/s] 62%|██████▏   | 55812/90000 [04:19<02:30, 227.12it/s] 62%|██████▏   | 55835/90000 [04:19<02:30, 227.18it/s] 62%|██████▏   | 55858/90000 [04:19<02:30, 226.46it/s] 62%|██████▏   | 55881/90000 [04:19<02:32, 223.61it/s] 62%|██████▏   | 55904/90000 [04:19<02:33, 222.05it/s] 62%|██████▏   | 55927/90000 [04:19<02:35, 219.60it/s] 62%|██████▏   | 55950/90000 [04:19<02:33, 221.42it/s] 62%|██████▏   | 55973/90000 [04:19<02:33, 221.40it/s] 62%|██████▏   | 55996/90000 [04:19<02:32, 223.17it/s] 62%|██████▏   | 56019/90000 [04:19<02:31, 223.64it/s] 62%|██████▏   | 56042/90000 [04:20<02:31, 223.65it/s] 62%|██████▏   | 56065/90000 [04:20<02:30, 225.22it/s] 62%|██████▏   | 56088/90000 [04:20<02:31, 224.17it/s] 62%|██████▏   | 56111/90000 [04:20<02:30, 225.09it/s] 62%|██████▏   | 56134/90000 [04:20<02:31, 223.71it/s] 62%|██████▏   | 56157/90000 [04:20<02:34, 218.62it/s] 62%|██████▏   | 56180/90000 [04:20<02:33, 221.02it/s] 62%|██████▏   | 56203/90000 [04:20<02:33, 219.90it/s] 62%|██████▏   | 56226/90000 [04:20<02:36, 215.29it/s] 62%|██████▏   | 56249/90000 [04:21<02:34, 217.86it/s] 63%|██████▎   | 56271/90000 [04:21<02:34, 217.66it/s] 63%|██████▎   | 56294/90000 [04:21<02:34, 217.87it/s] 63%|██████▎   | 56317/90000 [04:21<02:32, 220.75it/s] 63%|██████▎   | 56340/90000 [04:21<02:32, 221.12it/s] 63%|██████▎   | 56364/90000 [04:21<02:30, 223.26it/s] 63%|██████▎   | 56387/90000 [04:21<02:33, 219.39it/s] 63%|██████▎   | 56411/90000 [04:21<02:30, 223.37it/s] 63%|██████▎   | 56435/90000 [04:21<02:27, 227.39it/s] 63%|██████▎   | 56458/90000 [04:21<02:29, 224.57it/s] 63%|██████▎   | 56482/90000 [04:22<02:26, 228.79it/s] 63%|██████▎   | 56505/90000 [04:22<02:29, 224.34it/s] 63%|██████▎   | 56528/90000 [04:22<02:28, 225.80it/s] 63%|██████▎   | 56552/90000 [04:22<02:26, 227.82it/s] 63%|██████▎   | 56575/90000 [04:22<02:29, 223.77it/s] 63%|██████▎   | 56599/90000 [04:22<02:27, 226.08it/s] 63%|██████▎   | 56622/90000 [04:22<02:28, 224.46it/s] 63%|██████▎   | 56645/90000 [04:22<02:28, 224.46it/s] 63%|██████▎   | 56668/90000 [04:22<02:28, 224.69it/s] 63%|██████▎   | 56691/90000 [04:23<02:30, 221.82it/s] 63%|██████▎   | 56714/90000 [04:23<02:31, 220.37it/s] 63%|██████▎   | 56738/90000 [04:23<02:28, 224.12it/s] 63%|██████▎   | 56761/90000 [04:23<02:30, 220.62it/s] 63%|██████▎   | 56784/90000 [04:23<02:29, 221.92it/s] 63%|██████▎   | 56807/90000 [04:23<02:33, 216.63it/s] 63%|██████▎   | 56829/90000 [04:23<02:33, 216.37it/s] 63%|██████▎   | 56852/90000 [04:23<02:30, 220.10it/s] 63%|██████▎   | 56875/90000 [04:23<02:32, 217.25it/s] 63%|██████▎   | 56899/90000 [04:23<02:29, 221.97it/s] 63%|██████▎   | 56923/90000 [04:24<02:27, 225.00it/s] 63%|██████▎   | 56946/90000 [04:24<02:31, 217.64it/s] 63%|██████▎   | 56968/90000 [04:24<02:31, 217.53it/s] 63%|██████▎   | 56990/90000 [04:24<02:34, 214.25it/s] 63%|██████▎   | 57013/90000 [04:24<02:31, 218.43it/s] 63%|██████▎   | 57035/90000 [04:24<02:31, 217.81it/s] 63%|██████▎   | 57057/90000 [04:24<02:35, 211.92it/s] 63%|██████▎   | 57079/90000 [04:24<02:33, 213.91it/s] 63%|██████▎   | 57102/90000 [04:24<02:30, 218.42it/s] 63%|██████▎   | 57124/90000 [04:24<02:30, 218.29it/s] 63%|██████▎   | 57147/90000 [04:25<02:29, 219.60it/s] 64%|██████▎   | 57170/90000 [04:25<02:29, 220.33it/s] 64%|██████▎   | 57193/90000 [04:25<02:29, 219.18it/s] 64%|██████▎   | 57215/90000 [04:25<02:30, 217.59it/s] 64%|██████▎   | 57237/90000 [04:25<02:31, 216.66it/s] 64%|██████▎   | 57259/90000 [04:25<02:30, 217.39it/s] 64%|██████▎   | 57281/90000 [04:25<02:30, 217.98it/s] 64%|██████▎   | 57303/90000 [04:25<02:30, 217.33it/s] 64%|██████▎   | 57326/90000 [04:25<02:29, 218.44it/s] 64%|██████▎   | 57348/90000 [04:26<02:30, 216.30it/s] 64%|██████▎   | 57370/90000 [04:26<02:32, 214.52it/s] 64%|██████▍   | 57392/90000 [04:26<02:31, 215.26it/s] 64%|██████▍   | 57414/90000 [04:26<02:32, 213.24it/s] 64%|██████▍   | 57436/90000 [04:26<02:32, 213.43it/s] 64%|██████▍   | 57458/90000 [04:26<02:31, 214.97it/s] 64%|██████▍   | 57481/90000 [04:26<02:29, 218.16it/s] 64%|██████▍   | 57504/90000 [04:26<02:28, 218.97it/s] 64%|██████▍   | 57526/90000 [04:26<02:31, 214.95it/s] 64%|██████▍   | 57550/90000 [04:26<02:27, 219.52it/s] 64%|██████▍   | 57574/90000 [04:27<02:25, 223.49it/s] 64%|██████▍   | 57597/90000 [04:27<02:26, 220.92it/s] 64%|██████▍   | 57620/90000 [04:27<02:28, 218.51it/s] 64%|██████▍   | 57642/90000 [04:27<02:29, 216.33it/s] 64%|██████▍   | 57664/90000 [04:27<02:29, 216.99it/s] 64%|██████▍   | 57687/90000 [04:27<02:26, 220.06it/s] 64%|██████▍   | 57710/90000 [04:27<02:26, 220.63it/s] 64%|██████▍   | 57733/90000 [04:27<02:25, 221.34it/s] 64%|██████▍   | 57756/90000 [04:27<02:28, 217.80it/s] 64%|██████▍   | 57778/90000 [04:28<02:30, 213.93it/s] 64%|██████▍   | 57802/90000 [04:28<02:26, 219.56it/s] 64%|██████▍   | 57824/90000 [04:28<02:29, 215.63it/s] 64%|██████▍   | 57848/90000 [04:28<02:26, 220.20it/s] 64%|██████▍   | 57871/90000 [04:28<02:28, 216.77it/s] 64%|██████▍   | 57895/90000 [04:28<02:24, 221.50it/s] 64%|██████▍   | 57918/90000 [04:28<02:30, 213.30it/s] 64%|██████▍   | 57941/90000 [04:28<02:28, 216.04it/s] 64%|██████▍   | 57964/90000 [04:28<02:26, 218.09it/s] 64%|██████▍   | 57986/90000 [04:28<02:29, 213.87it/s] 64%|██████▍   | 58008/90000 [04:29<02:30, 212.88it/s] 64%|██████▍   | 58031/90000 [04:29<02:27, 216.49it/s] 65%|██████▍   | 58053/90000 [04:29<02:30, 212.86it/s] 65%|██████▍   | 58076/90000 [04:29<02:27, 216.31it/s] 65%|██████▍   | 58098/90000 [04:29<02:30, 212.37it/s] 65%|██████▍   | 58120/90000 [04:29<02:30, 212.06it/s] 65%|██████▍   | 58143/90000 [04:29<02:26, 216.90it/s] 65%|██████▍   | 58166/90000 [04:29<02:25, 219.31it/s] 65%|██████▍   | 58190/90000 [04:29<02:22, 223.91it/s] 65%|██████▍   | 58214/90000 [04:30<02:20, 225.62it/s] 65%|██████▍   | 58238/90000 [04:30<02:19, 227.68it/s] 65%|██████▍   | 58261/90000 [04:30<02:21, 225.03it/s] 65%|██████▍   | 58286/90000 [04:30<02:16, 231.63it/s] 65%|██████▍   | 58310/90000 [04:30<02:15, 233.07it/s] 65%|██████▍   | 58334/90000 [04:30<02:17, 229.86it/s] 65%|██████▍   | 58358/90000 [04:30<02:19, 226.10it/s] 65%|██████▍   | 58381/90000 [04:30<02:21, 223.33it/s] 65%|██████▍   | 58404/90000 [04:30<02:22, 221.23it/s] 65%|██████▍   | 58427/90000 [04:30<02:23, 220.08it/s] 65%|██████▍   | 58451/90000 [04:31<02:22, 222.08it/s] 65%|██████▍   | 58474/90000 [04:31<02:23, 220.33it/s] 65%|██████▍   | 58499/90000 [04:31<02:19, 225.62it/s] 65%|██████▌   | 58523/90000 [04:31<02:17, 229.22it/s] 65%|██████▌   | 58547/90000 [04:31<02:16, 230.94it/s] 65%|██████▌   | 58571/90000 [04:31<02:16, 230.82it/s] 65%|██████▌   | 58595/90000 [04:31<02:17, 228.27it/s] 65%|██████▌   | 58618/90000 [04:31<02:18, 227.38it/s] 65%|██████▌   | 58643/90000 [04:31<02:15, 231.59it/s] 65%|██████▌   | 58667/90000 [04:31<02:18, 226.53it/s] 65%|██████▌   | 58691/90000 [04:32<02:16, 229.66it/s] 65%|██████▌   | 58715/90000 [04:32<02:15, 230.10it/s] 65%|██████▌   | 58739/90000 [04:32<02:17, 226.61it/s] 65%|██████▌   | 58763/90000 [04:32<02:15, 229.81it/s] 65%|██████▌   | 58787/90000 [04:32<02:18, 225.16it/s] 65%|██████▌   | 58810/90000 [04:32<02:18, 225.83it/s] 65%|██████▌   | 58834/90000 [04:32<02:17, 227.46it/s] 65%|██████▌   | 58857/90000 [04:32<02:18, 225.35it/s] 65%|██████▌   | 58881/90000 [04:32<02:17, 226.34it/s] 65%|██████▌   | 58904/90000 [04:33<02:16, 226.99it/s] 65%|██████▌   | 58927/90000 [04:33<02:19, 222.57it/s] 66%|██████▌   | 58950/90000 [04:33<02:19, 223.11it/s] 66%|██████▌   | 58973/90000 [04:33<02:18, 223.32it/s] 66%|██████▌   | 58996/90000 [04:33<02:18, 223.15it/s] 66%|██████▌   | 59020/90000 [04:33<02:16, 226.39it/s] 66%|██████▌   | 59045/90000 [04:33<02:13, 231.26it/s] 66%|██████▌   | 59069/90000 [04:33<02:12, 232.75it/s] 66%|██████▌   | 59093/90000 [04:33<02:13, 231.98it/s] 66%|██████▌   | 59117/90000 [04:33<02:14, 228.78it/s] 66%|██████▌   | 59140/90000 [04:34<02:15, 227.48it/s] 66%|██████▌   | 59163/90000 [04:34<02:16, 226.58it/s] 66%|██████▌   | 59186/90000 [04:34<02:17, 223.81it/s] 66%|██████▌   | 59210/90000 [04:34<02:16, 226.00it/s] 66%|██████▌   | 59234/90000 [04:34<02:14, 228.80it/s] 66%|██████▌   | 59259/90000 [04:34<02:12, 232.34it/s] 66%|██████▌   | 59283/90000 [04:34<02:14, 229.14it/s] 66%|██████▌   | 59306/90000 [04:34<02:17, 223.34it/s] 66%|██████▌   | 59329/90000 [04:34<02:19, 220.40it/s] 66%|██████▌   | 59352/90000 [04:35<02:19, 220.01it/s] 66%|██████▌   | 59376/90000 [04:35<02:16, 224.33it/s] 66%|██████▌   | 59399/90000 [04:35<02:18, 221.67it/s] 66%|██████▌   | 59422/90000 [04:35<02:18, 220.41it/s] 66%|██████▌   | 59447/90000 [04:35<02:15, 225.80it/s] 66%|██████▌   | 59471/90000 [04:35<02:13, 228.90it/s] 66%|██████▌   | 59495/90000 [04:35<02:12, 230.10it/s] 66%|██████▌   | 59520/90000 [04:35<02:10, 233.22it/s] 66%|██████▌   | 59544/90000 [04:35<02:12, 230.12it/s] 66%|██████▌   | 59568/90000 [04:35<02:14, 225.83it/s] 66%|██████▌   | 59593/90000 [04:36<02:10, 232.57it/s] 66%|██████▌   | 59617/90000 [04:36<02:10, 232.47it/s] 66%|██████▋   | 59641/90000 [04:36<02:11, 230.73it/s] 66%|██████▋   | 59665/90000 [04:36<02:11, 230.57it/s] 66%|██████▋   | 59689/90000 [04:36<02:10, 232.20it/s] 66%|██████▋   | 59713/90000 [04:36<02:09, 233.93it/s] 66%|██████▋   | 59737/90000 [04:36<02:11, 230.81it/s] 66%|██████▋   | 59761/90000 [04:36<02:09, 232.88it/s] 66%|██████▋   | 59785/90000 [04:36<02:10, 231.91it/s] 66%|██████▋   | 59809/90000 [04:37<02:13, 225.36it/s] 66%|██████▋   | 59832/90000 [04:37<02:14, 224.89it/s] 67%|██████▋   | 59855/90000 [04:37<02:15, 222.51it/s] 67%|██████▋   | 59878/90000 [04:37<02:16, 220.31it/s] 67%|██████▋   | 59901/90000 [04:37<02:18, 217.83it/s] 67%|██████▋   | 59923/90000 [04:37<02:18, 217.83it/s] 67%|██████▋   | 59947/90000 [04:37<02:16, 220.83it/s] 67%|██████▋   | 59970/90000 [04:37<02:16, 219.92it/s] 67%|██████▋   | 59992/90000 [04:37<02:17, 217.46it/s] 67%|██████▋   | 60016/90000 [04:37<02:15, 221.62it/s] 67%|██████▋   | 60039/90000 [04:38<02:14, 222.98it/s] 67%|██████▋   | 60062/90000 [04:38<02:16, 219.89it/s] 67%|██████▋   | 60085/90000 [04:38<02:16, 219.95it/s] 67%|██████▋   | 60108/90000 [04:38<02:17, 217.55it/s] 67%|██████▋   | 60130/90000 [04:38<02:17, 217.59it/s] 67%|██████▋   | 60152/90000 [04:38<02:18, 214.90it/s] 67%|██████▋   | 60175/90000 [04:38<02:16, 218.51it/s] 67%|██████▋   | 60198/90000 [04:38<02:15, 219.39it/s] 67%|██████▋   | 60221/90000 [04:38<02:14, 221.23it/s] 67%|██████▋   | 60244/90000 [04:39<02:14, 221.23it/s] 67%|██████▋   | 60267/90000 [04:39<02:14, 220.25it/s] 67%|██████▋   | 60290/90000 [04:39<02:15, 219.86it/s] 67%|██████▋   | 60313/90000 [04:39<02:14, 220.92it/s] 67%|██████▋   | 60336/90000 [04:39<02:15, 219.62it/s] 67%|██████▋   | 60359/90000 [04:39<02:13, 222.45it/s] 67%|██████▋   | 60382/90000 [04:39<02:14, 220.06it/s] 67%|██████▋   | 60405/90000 [04:39<02:16, 217.31it/s] 67%|██████▋   | 60428/90000 [04:39<02:15, 218.37it/s] 67%|██████▋   | 60451/90000 [04:39<02:13, 220.87it/s] 67%|██████▋   | 60474/90000 [04:40<02:14, 220.03it/s] 67%|██████▋   | 60497/90000 [04:40<02:14, 218.54it/s] 67%|██████▋   | 60519/90000 [04:40<02:14, 218.43it/s] 67%|██████▋   | 60541/90000 [04:40<02:17, 215.01it/s] 67%|██████▋   | 60564/90000 [04:40<02:14, 219.16it/s] 67%|██████▋   | 60589/90000 [04:40<02:10, 225.83it/s] 67%|██████▋   | 60612/90000 [04:40<02:12, 221.58it/s] 67%|██████▋   | 60635/90000 [04:40<02:12, 220.97it/s] 67%|██████▋   | 60658/90000 [04:40<02:12, 221.40it/s] 67%|██████▋   | 60681/90000 [04:40<02:14, 217.41it/s] 67%|██████▋   | 60703/90000 [04:41<02:14, 217.39it/s] 67%|██████▋   | 60725/90000 [04:41<02:14, 217.09it/s] 67%|██████▋   | 60748/90000 [04:41<02:13, 218.76it/s] 68%|██████▊   | 60771/90000 [04:41<02:12, 220.72it/s] 68%|██████▊   | 60794/90000 [04:41<02:13, 218.52it/s] 68%|██████▊   | 60816/90000 [04:41<02:14, 217.34it/s] 68%|██████▊   | 60838/90000 [04:41<02:13, 217.76it/s] 68%|██████▊   | 60860/90000 [04:41<02:14, 217.09it/s] 68%|██████▊   | 60882/90000 [04:41<02:14, 216.19it/s] 68%|██████▊   | 60904/90000 [04:42<02:15, 214.99it/s] 68%|██████▊   | 60926/90000 [04:42<02:16, 213.22it/s] 68%|██████▊   | 60949/90000 [04:42<02:13, 217.81it/s] 68%|██████▊   | 60971/90000 [04:42<02:13, 218.12it/s] 68%|██████▊   | 60993/90000 [04:42<02:12, 218.31it/s] 68%|██████▊   | 61016/90000 [04:42<02:12, 218.98it/s] 68%|██████▊   | 61038/90000 [04:42<02:13, 216.53it/s] 68%|██████▊   | 61060/90000 [04:42<02:14, 214.63it/s] 68%|██████▊   | 61082/90000 [04:42<02:13, 216.00it/s] 68%|██████▊   | 61104/90000 [04:42<02:14, 214.17it/s] 68%|██████▊   | 61127/90000 [04:43<02:13, 216.14it/s] 68%|██████▊   | 61149/90000 [04:43<02:14, 215.24it/s] 68%|██████▊   | 61171/90000 [04:43<02:14, 214.70it/s] 68%|██████▊   | 61193/90000 [04:43<02:15, 212.99it/s] 68%|██████▊   | 61215/90000 [04:43<02:15, 213.17it/s] 68%|██████▊   | 61237/90000 [04:43<02:14, 213.12it/s] 68%|██████▊   | 61260/90000 [04:43<02:12, 216.71it/s] 68%|██████▊   | 61283/90000 [04:43<02:10, 219.49it/s] 68%|██████▊   | 61305/90000 [04:43<02:13, 215.20it/s] 68%|██████▊   | 61328/90000 [04:43<02:10, 219.16it/s] 68%|██████▊   | 61351/90000 [04:44<02:10, 218.93it/s] 68%|██████▊   | 61374/90000 [04:44<02:09, 220.22it/s] 68%|██████▊   | 61397/90000 [04:44<02:10, 219.28it/s] 68%|██████▊   | 61419/90000 [04:44<02:12, 215.92it/s] 68%|██████▊   | 61443/90000 [04:44<02:09, 219.76it/s] 68%|██████▊   | 61466/90000 [04:44<02:09, 220.62it/s] 68%|██████▊   | 61489/90000 [04:44<02:07, 223.06it/s] 68%|██████▊   | 61513/90000 [04:44<02:05, 226.98it/s] 68%|██████▊   | 61537/90000 [04:44<02:04, 228.46it/s] 68%|██████▊   | 61560/90000 [04:45<02:05, 226.94it/s] 68%|██████▊   | 61583/90000 [04:45<02:07, 222.51it/s] 68%|██████▊   | 61607/90000 [04:45<02:05, 225.99it/s] 68%|██████▊   | 61630/90000 [04:45<02:06, 224.62it/s] 69%|██████▊   | 61653/90000 [04:45<02:06, 223.86it/s] 69%|██████▊   | 61676/90000 [04:45<02:05, 224.91it/s] 69%|██████▊   | 61699/90000 [04:45<02:05, 225.83it/s] 69%|██████▊   | 61722/90000 [04:45<02:05, 224.80it/s] 69%|██████▊   | 61745/90000 [04:45<02:05, 224.37it/s] 69%|██████▊   | 61768/90000 [04:45<02:05, 224.54it/s] 69%|██████▊   | 61792/90000 [04:46<02:04, 226.73it/s] 69%|██████▊   | 61815/90000 [04:46<02:08, 219.36it/s] 69%|██████▊   | 61838/90000 [04:46<02:07, 221.28it/s] 69%|██████▊   | 61861/90000 [04:46<02:06, 223.25it/s] 69%|██████▉   | 61884/90000 [04:46<02:05, 224.93it/s] 69%|██████▉   | 61909/90000 [04:46<02:01, 230.71it/s] 69%|██████▉   | 61933/90000 [04:46<02:01, 230.10it/s] 69%|██████▉   | 61957/90000 [04:46<02:02, 228.76it/s] 69%|██████▉   | 61981/90000 [04:46<02:01, 230.82it/s] 69%|██████▉   | 62005/90000 [04:46<02:00, 232.70it/s] 69%|██████▉   | 62029/90000 [04:47<02:00, 233.04it/s] 69%|██████▉   | 62053/90000 [04:47<02:00, 231.29it/s] 69%|██████▉   | 62077/90000 [04:47<02:01, 230.14it/s] 69%|██████▉   | 62101/90000 [04:47<01:59, 232.52it/s] 69%|██████▉   | 62125/90000 [04:47<02:00, 232.12it/s] 69%|██████▉   | 62149/90000 [04:47<01:59, 232.49it/s] 69%|██████▉   | 62173/90000 [04:47<01:58, 233.88it/s] 69%|██████▉   | 62197/90000 [04:47<01:58, 234.44it/s] 69%|██████▉   | 62221/90000 [04:47<02:01, 228.14it/s] 69%|██████▉   | 62246/90000 [04:48<01:59, 231.78it/s] 69%|██████▉   | 62270/90000 [04:48<02:00, 230.12it/s] 69%|██████▉   | 62294/90000 [04:48<02:01, 228.84it/s] 69%|██████▉   | 62318/90000 [04:48<02:01, 228.60it/s] 69%|██████▉   | 62341/90000 [04:48<02:01, 228.55it/s] 69%|██████▉   | 62364/90000 [04:48<02:00, 228.67it/s] 69%|██████▉   | 62388/90000 [04:48<02:00, 228.74it/s] 69%|██████▉   | 62411/90000 [04:48<02:01, 226.21it/s] 69%|██████▉   | 62434/90000 [04:48<02:03, 222.93it/s] 69%|██████▉   | 62458/90000 [04:48<02:01, 226.23it/s] 69%|██████▉   | 62481/90000 [04:49<02:02, 224.35it/s] 69%|██████▉   | 62504/90000 [04:49<02:01, 225.47it/s] 69%|██████▉   | 62527/90000 [04:49<02:01, 226.07it/s] 70%|██████▉   | 62551/90000 [04:49<02:00, 227.85it/s] 70%|██████▉   | 62574/90000 [04:49<02:00, 228.08it/s] 70%|██████▉   | 62597/90000 [04:49<02:00, 226.99it/s] 70%|██████▉   | 62620/90000 [04:49<02:00, 226.41it/s] 70%|██████▉   | 62644/90000 [04:49<02:00, 226.36it/s] 70%|██████▉   | 62668/90000 [04:49<02:00, 226.41it/s] 70%|██████▉   | 62692/90000 [04:49<01:59, 229.43it/s] 70%|██████▉   | 62717/90000 [04:50<01:57, 233.16it/s] 70%|██████▉   | 62741/90000 [04:50<01:55, 234.99it/s] 70%|██████▉   | 62765/90000 [04:50<01:58, 230.60it/s] 70%|██████▉   | 62789/90000 [04:50<01:58, 229.02it/s] 70%|██████▉   | 62813/90000 [04:50<01:57, 231.65it/s] 70%|██████▉   | 62837/90000 [04:50<01:57, 231.46it/s] 70%|██████▉   | 62861/90000 [04:50<01:56, 232.77it/s] 70%|██████▉   | 62885/90000 [04:50<01:58, 229.54it/s] 70%|██████▉   | 62909/90000 [04:50<01:56, 232.13it/s] 70%|██████▉   | 62933/90000 [04:51<01:55, 233.91it/s] 70%|██████▉   | 62957/90000 [04:51<01:56, 233.04it/s] 70%|██████▉   | 62981/90000 [04:51<01:57, 230.88it/s] 70%|███████   | 63006/90000 [04:51<01:55, 233.99it/s] 70%|███████   | 63031/90000 [04:51<01:53, 237.23it/s] 70%|███████   | 63055/90000 [04:51<01:54, 235.28it/s] 70%|███████   | 63079/90000 [04:51<01:55, 233.52it/s] 70%|███████   | 63103/90000 [04:51<01:56, 231.62it/s] 70%|███████   | 63128/90000 [04:51<01:53, 235.73it/s] 70%|███████   | 63152/90000 [04:51<01:54, 234.34it/s] 70%|███████   | 63176/90000 [04:52<01:53, 235.70it/s] 70%|███████   | 63201/90000 [04:52<01:52, 237.51it/s] 70%|███████   | 63226/90000 [04:52<01:52, 237.68it/s] 70%|███████   | 63250/90000 [04:52<01:54, 233.49it/s] 70%|███████   | 63274/90000 [04:52<01:54, 233.39it/s] 70%|███████   | 63298/90000 [04:52<01:57, 226.80it/s] 70%|███████   | 63322/90000 [04:52<01:56, 228.29it/s] 70%|███████   | 63346/90000 [04:52<01:56, 229.15it/s] 70%|███████   | 63370/90000 [04:52<01:55, 230.68it/s] 70%|███████   | 63394/90000 [04:53<01:55, 229.38it/s] 70%|███████   | 63418/90000 [04:53<01:54, 232.34it/s] 70%|███████   | 63442/90000 [04:53<01:55, 229.95it/s] 71%|███████   | 63466/90000 [04:53<01:55, 230.59it/s] 71%|███████   | 63490/90000 [04:53<01:55, 230.29it/s] 71%|███████   | 63514/90000 [04:53<01:57, 225.97it/s] 71%|███████   | 63538/90000 [04:53<01:56, 227.29it/s] 71%|███████   | 63562/90000 [04:53<01:55, 228.87it/s] 71%|███████   | 63586/90000 [04:53<01:54, 229.91it/s] 71%|███████   | 63611/90000 [04:53<01:52, 233.96it/s] 71%|███████   | 63636/90000 [04:54<01:51, 237.19it/s] 71%|███████   | 63660/90000 [04:54<01:52, 234.87it/s] 71%|███████   | 63685/90000 [04:54<01:51, 236.31it/s] 71%|███████   | 63709/90000 [04:54<01:52, 233.59it/s] 71%|███████   | 63733/90000 [04:54<01:52, 234.44it/s] 71%|███████   | 63757/90000 [04:54<01:52, 233.69it/s] 71%|███████   | 63781/90000 [04:54<01:52, 232.25it/s] 71%|███████   | 63805/90000 [04:54<01:53, 231.70it/s] 71%|███████   | 63829/90000 [04:54<01:53, 230.07it/s] 71%|███████   | 63853/90000 [04:54<01:52, 231.40it/s] 71%|███████   | 63877/90000 [04:55<01:53, 230.34it/s] 71%|███████   | 63902/90000 [04:55<01:52, 232.87it/s] 71%|███████   | 63926/90000 [04:55<01:51, 233.15it/s] 71%|███████   | 63950/90000 [04:55<01:51, 233.13it/s] 71%|███████   | 63974/90000 [04:55<01:50, 234.71it/s] 71%|███████   | 63998/90000 [04:55<01:50, 235.02it/s] 71%|███████   | 64022/90000 [04:55<01:50, 234.18it/s] 71%|███████   | 64046/90000 [04:55<01:51, 232.11it/s] 71%|███████   | 64070/90000 [04:55<01:55, 224.45it/s] 71%|███████   | 64095/90000 [04:56<01:52, 230.95it/s] 71%|███████   | 64120/90000 [04:56<01:50, 234.84it/s] 71%|███████▏  | 64144/90000 [04:56<01:51, 232.49it/s] 71%|███████▏  | 64169/90000 [04:56<01:49, 235.93it/s] 71%|███████▏  | 64193/90000 [04:56<01:49, 236.43it/s] 71%|███████▏  | 64217/90000 [04:56<01:49, 234.57it/s] 71%|███████▏  | 64241/90000 [04:56<01:49, 235.57it/s] 71%|███████▏  | 64265/90000 [04:56<01:52, 228.77it/s] 71%|███████▏  | 64289/90000 [04:56<01:51, 230.26it/s] 71%|███████▏  | 64313/90000 [04:56<01:52, 228.81it/s] 71%|███████▏  | 64336/90000 [04:57<01:52, 227.88it/s] 72%|███████▏  | 64360/90000 [04:57<01:51, 230.90it/s] 72%|███████▏  | 64385/90000 [04:57<01:49, 234.42it/s] 72%|███████▏  | 64409/90000 [04:57<01:48, 235.52it/s] 72%|███████▏  | 64433/90000 [04:57<01:49, 234.53it/s] 72%|███████▏  | 64457/90000 [04:57<01:48, 234.97it/s] 72%|███████▏  | 64481/90000 [04:57<01:49, 232.32it/s] 72%|███████▏  | 64505/90000 [04:57<01:49, 232.99it/s] 72%|███████▏  | 64530/90000 [04:57<01:47, 235.86it/s] 72%|███████▏  | 64554/90000 [04:57<01:49, 232.31it/s] 72%|███████▏  | 64579/90000 [04:58<01:47, 237.29it/s] 72%|███████▏  | 64603/90000 [04:58<01:49, 231.04it/s] 72%|███████▏  | 64627/90000 [04:58<01:50, 229.62it/s] 72%|███████▏  | 64651/90000 [04:58<01:49, 231.72it/s] 72%|███████▏  | 64675/90000 [04:58<01:49, 232.12it/s] 72%|███████▏  | 64700/90000 [04:58<01:47, 234.62it/s] 72%|███████▏  | 64724/90000 [04:58<01:47, 234.21it/s] 72%|███████▏  | 64748/90000 [04:58<01:48, 232.38it/s] 72%|███████▏  | 64773/90000 [04:58<01:47, 235.12it/s] 72%|███████▏  | 64798/90000 [04:59<01:46, 236.63it/s] 72%|███████▏  | 64822/90000 [04:59<01:46, 236.10it/s] 72%|███████▏  | 64847/90000 [04:59<01:45, 237.34it/s] 72%|███████▏  | 64871/90000 [04:59<01:46, 234.87it/s] 72%|███████▏  | 64895/90000 [04:59<01:46, 235.17it/s] 72%|███████▏  | 64920/90000 [04:59<01:45, 236.64it/s] 72%|███████▏  | 64944/90000 [04:59<01:45, 236.69it/s] 72%|███████▏  | 64968/90000 [04:59<01:46, 234.28it/s] 72%|███████▏  | 64992/90000 [04:59<01:46, 235.58it/s] 72%|███████▏  | 65016/90000 [04:59<01:46, 234.02it/s] 72%|███████▏  | 65040/90000 [05:00<01:46, 235.42it/s] 72%|███████▏  | 65065/90000 [05:00<01:45, 237.46it/s] 72%|███████▏  | 65089/90000 [05:00<01:46, 233.55it/s] 72%|███████▏  | 65113/90000 [05:00<01:47, 231.66it/s] 72%|███████▏  | 65137/90000 [05:00<01:46, 232.77it/s] 72%|███████▏  | 65161/90000 [05:00<01:46, 234.15it/s] 72%|███████▏  | 65185/90000 [05:00<01:45, 234.38it/s] 72%|███████▏  | 65209/90000 [05:00<01:45, 235.02it/s] 72%|███████▏  | 65233/90000 [05:00<01:45, 234.24it/s] 73%|███████▎  | 65257/90000 [05:00<01:47, 229.25it/s] 73%|███████▎  | 65281/90000 [05:01<01:47, 230.29it/s] 73%|███████▎  | 65306/90000 [05:01<01:45, 234.03it/s] 73%|███████▎  | 65330/90000 [05:01<01:46, 231.30it/s] 73%|███████▎  | 65354/90000 [05:01<01:47, 229.46it/s] 73%|███████▎  | 65377/90000 [05:01<01:48, 226.25it/s] 73%|███████▎  | 65401/90000 [05:01<01:46, 230.19it/s] 73%|███████▎  | 65425/90000 [05:01<01:48, 227.29it/s] 73%|███████▎  | 65448/90000 [05:01<01:48, 227.22it/s] 73%|███████▎  | 65473/90000 [05:01<01:46, 230.85it/s] 73%|███████▎  | 65497/90000 [05:02<01:45, 231.83it/s] 73%|███████▎  | 65521/90000 [05:02<01:46, 229.10it/s] 73%|███████▎  | 65546/90000 [05:02<01:44, 234.63it/s] 73%|███████▎  | 65570/90000 [05:02<01:46, 228.37it/s] 73%|███████▎  | 65593/90000 [05:02<01:47, 226.24it/s] 73%|███████▎  | 65618/90000 [05:02<01:45, 230.80it/s] 73%|███████▎  | 65642/90000 [05:02<01:46, 228.85it/s] 73%|███████▎  | 65666/90000 [05:02<01:45, 230.66it/s] 73%|███████▎  | 65690/90000 [05:02<01:44, 233.32it/s] 73%|███████▎  | 65714/90000 [05:02<01:45, 230.19it/s] 73%|███████▎  | 65738/90000 [05:03<01:44, 232.65it/s] 73%|███████▎  | 65762/90000 [05:03<01:45, 228.90it/s] 73%|███████▎  | 65786/90000 [05:03<01:44, 231.67it/s] 73%|███████▎  | 65810/90000 [05:03<01:43, 232.62it/s] 73%|███████▎  | 65834/90000 [05:03<01:43, 234.13it/s] 73%|███████▎  | 65858/90000 [05:03<01:42, 235.10it/s] 73%|███████▎  | 65882/90000 [05:03<01:42, 235.15it/s] 73%|███████▎  | 65906/90000 [05:03<01:43, 232.37it/s] 73%|███████▎  | 65930/90000 [05:03<01:45, 228.75it/s] 73%|███████▎  | 65953/90000 [05:04<01:45, 228.47it/s] 73%|███████▎  | 65977/90000 [05:04<01:44, 229.44it/s] 73%|███████▎  | 66000/90000 [05:04<01:45, 227.65it/s] 73%|███████▎  | 66023/90000 [05:04<01:45, 226.77it/s] 73%|███████▎  | 66047/90000 [05:04<01:44, 229.01it/s] 73%|███████▎  | 66070/90000 [05:04<01:44, 228.98it/s] 73%|███████▎  | 66094/90000 [05:04<01:43, 231.53it/s] 73%|███████▎  | 66118/90000 [05:04<01:45, 226.61it/s] 73%|███████▎  | 66141/90000 [05:04<01:45, 225.21it/s] 74%|███████▎  | 66164/90000 [05:04<01:46, 223.38it/s] 74%|███████▎  | 66188/90000 [05:05<01:45, 225.11it/s] 74%|███████▎  | 66211/90000 [05:05<01:47, 220.96it/s] 74%|███████▎  | 66234/90000 [05:05<01:47, 222.08it/s] 74%|███████▎  | 66257/90000 [05:05<01:45, 224.06it/s] 74%|███████▎  | 66282/90000 [05:05<01:42, 230.27it/s] 74%|███████▎  | 66306/90000 [05:05<01:41, 232.43it/s] 74%|███████▎  | 66330/90000 [05:05<01:41, 232.95it/s] 74%|███████▎  | 66354/90000 [05:05<01:42, 231.42it/s] 74%|███████▍  | 66378/90000 [05:05<01:43, 228.21it/s] 74%|███████▍  | 66403/90000 [05:05<01:41, 232.42it/s] 74%|███████▍  | 66427/90000 [05:06<01:42, 229.15it/s] 74%|███████▍  | 66450/90000 [05:06<01:43, 227.74it/s] 74%|███████▍  | 66473/90000 [05:06<01:44, 225.04it/s] 74%|███████▍  | 66497/90000 [05:06<01:43, 227.95it/s] 74%|███████▍  | 66521/90000 [05:06<01:42, 229.67it/s] 74%|███████▍  | 66544/90000 [05:06<01:43, 225.90it/s] 74%|███████▍  | 66568/90000 [05:06<01:42, 229.64it/s] 74%|███████▍  | 66593/90000 [05:06<01:39, 234.44it/s] 74%|███████▍  | 66617/90000 [05:06<01:40, 232.65it/s] 74%|███████▍  | 66641/90000 [05:07<01:40, 233.45it/s] 74%|███████▍  | 66665/90000 [05:07<01:41, 230.93it/s] 74%|███████▍  | 66689/90000 [05:07<01:41, 229.80it/s] 74%|███████▍  | 66713/90000 [05:07<01:41, 229.69it/s] 74%|███████▍  | 66738/90000 [05:07<01:39, 232.98it/s] 74%|███████▍  | 66762/90000 [05:07<01:41, 230.02it/s] 74%|███████▍  | 66786/90000 [05:07<01:40, 231.58it/s] 74%|███████▍  | 66810/90000 [05:07<01:41, 229.49it/s] 74%|███████▍  | 66835/90000 [05:07<01:39, 233.79it/s] 74%|███████▍  | 66861/90000 [05:07<01:37, 238.27it/s] 74%|███████▍  | 66885/90000 [05:08<01:38, 235.86it/s] 74%|███████▍  | 66909/90000 [05:08<01:37, 235.62it/s] 74%|███████▍  | 66934/90000 [05:08<01:37, 237.54it/s] 74%|███████▍  | 66959/90000 [05:08<01:36, 239.20it/s] 74%|███████▍  | 66983/90000 [05:08<01:36, 238.56it/s] 74%|███████▍  | 67007/90000 [05:08<01:37, 235.85it/s] 74%|███████▍  | 67031/90000 [05:08<01:37, 234.63it/s] 75%|███████▍  | 67055/90000 [05:08<01:39, 231.12it/s] 75%|███████▍  | 67079/90000 [05:08<01:39, 229.42it/s] 75%|███████▍  | 67103/90000 [05:09<01:39, 230.76it/s] 75%|███████▍  | 67127/90000 [05:09<01:38, 231.54it/s] 75%|███████▍  | 67151/90000 [05:09<01:38, 231.01it/s] 75%|███████▍  | 67175/90000 [05:09<01:38, 231.46it/s] 75%|███████▍  | 67199/90000 [05:09<01:38, 231.24it/s] 75%|███████▍  | 67223/90000 [05:09<01:39, 229.99it/s] 75%|███████▍  | 67247/90000 [05:09<01:38, 230.71it/s] 75%|███████▍  | 67271/90000 [05:09<01:38, 229.86it/s] 75%|███████▍  | 67294/90000 [05:09<01:38, 229.63it/s] 75%|███████▍  | 67318/90000 [05:09<01:38, 231.21it/s] 75%|███████▍  | 67342/90000 [05:10<01:38, 231.04it/s] 75%|███████▍  | 67366/90000 [05:10<01:37, 232.65it/s] 75%|███████▍  | 67390/90000 [05:10<01:38, 229.37it/s] 75%|███████▍  | 67415/90000 [05:10<01:37, 232.33it/s] 75%|███████▍  | 67439/90000 [05:10<01:36, 233.85it/s] 75%|███████▍  | 67463/90000 [05:10<01:36, 234.23it/s] 75%|███████▍  | 67487/90000 [05:10<01:36, 233.36it/s] 75%|███████▌  | 67511/90000 [05:10<01:36, 234.12it/s] 75%|███████▌  | 67535/90000 [05:10<01:35, 234.42it/s] 75%|███████▌  | 67559/90000 [05:10<01:37, 230.23it/s] 75%|███████▌  | 67583/90000 [05:11<01:37, 228.90it/s] 75%|███████▌  | 67608/90000 [05:11<01:36, 232.57it/s] 75%|███████▌  | 67632/90000 [05:11<01:35, 234.17it/s] 75%|███████▌  | 67656/90000 [05:11<01:36, 230.57it/s] 75%|███████▌  | 67681/90000 [05:11<01:35, 234.02it/s] 75%|███████▌  | 67705/90000 [05:11<01:36, 232.20it/s] 75%|███████▌  | 67730/90000 [05:11<01:33, 236.95it/s] 75%|███████▌  | 67755/90000 [05:11<01:33, 238.02it/s] 75%|███████▌  | 67779/90000 [05:11<01:36, 231.02it/s] 75%|███████▌  | 67803/90000 [05:12<01:36, 230.30it/s] 75%|███████▌  | 67827/90000 [05:12<01:36, 228.79it/s] 75%|███████▌  | 67850/90000 [05:12<01:36, 228.72it/s] 75%|███████▌  | 67874/90000 [05:12<01:35, 230.52it/s] 75%|███████▌  | 67898/90000 [05:12<01:38, 225.08it/s] 75%|███████▌  | 67921/90000 [05:12<01:38, 225.08it/s] 75%|███████▌  | 67945/90000 [05:12<01:36, 228.70it/s] 76%|███████▌  | 67969/90000 [05:12<01:36, 228.69it/s] 76%|███████▌  | 67993/90000 [05:12<01:36, 228.91it/s] 76%|███████▌  | 68016/90000 [05:12<01:36, 227.27it/s] 76%|███████▌  | 68040/90000 [05:13<01:35, 229.56it/s] 76%|███████▌  | 68064/90000 [05:13<01:35, 229.82it/s] 76%|███████▌  | 68087/90000 [05:13<01:35, 228.60it/s] 76%|███████▌  | 68111/90000 [05:13<01:35, 229.13it/s] 76%|███████▌  | 68134/90000 [05:13<01:35, 228.67it/s] 76%|███████▌  | 68157/90000 [05:13<01:35, 228.36it/s] 76%|███████▌  | 68182/90000 [05:13<01:33, 232.58it/s] 76%|███████▌  | 68207/90000 [05:13<01:32, 234.71it/s] 76%|███████▌  | 68231/90000 [05:13<01:32, 235.12it/s] 76%|███████▌  | 68256/90000 [05:13<01:31, 238.11it/s] 76%|███████▌  | 68280/90000 [05:14<01:31, 236.91it/s] 76%|███████▌  | 68304/90000 [05:14<01:32, 235.44it/s] 76%|███████▌  | 68328/90000 [05:14<01:31, 236.24it/s] 76%|███████▌  | 68352/90000 [05:14<01:32, 233.96it/s] 76%|███████▌  | 68376/90000 [05:14<01:33, 231.99it/s] 76%|███████▌  | 68400/90000 [05:14<01:33, 231.84it/s] 76%|███████▌  | 68424/90000 [05:14<01:35, 225.42it/s] 76%|███████▌  | 68448/90000 [05:14<01:34, 227.15it/s] 76%|███████▌  | 68471/90000 [05:14<01:35, 224.67it/s] 76%|███████▌  | 68496/90000 [05:15<01:33, 229.95it/s] 76%|███████▌  | 68520/90000 [05:15<01:33, 229.18it/s] 76%|███████▌  | 68543/90000 [05:15<01:35, 224.72it/s] 76%|███████▌  | 68568/90000 [05:15<01:33, 229.09it/s] 76%|███████▌  | 68592/90000 [05:15<01:32, 232.15it/s] 76%|███████▌  | 68616/90000 [05:15<01:33, 228.86it/s] 76%|███████▋  | 68640/90000 [05:15<01:32, 230.43it/s] 76%|███████▋  | 68664/90000 [05:15<01:31, 232.87it/s] 76%|███████▋  | 68688/90000 [05:15<01:33, 228.61it/s] 76%|███████▋  | 68712/90000 [05:15<01:32, 229.75it/s] 76%|███████▋  | 68736/90000 [05:16<01:32, 231.08it/s] 76%|███████▋  | 68760/90000 [05:16<01:32, 228.65it/s] 76%|███████▋  | 68784/90000 [05:16<01:31, 230.75it/s] 76%|███████▋  | 68808/90000 [05:16<01:31, 232.65it/s] 76%|███████▋  | 68834/90000 [05:16<01:28, 238.60it/s] 77%|███████▋  | 68858/90000 [05:16<01:30, 233.65it/s] 77%|███████▋  | 68882/90000 [05:16<01:31, 230.57it/s] 77%|███████▋  | 68906/90000 [05:16<01:30, 232.47it/s] 77%|███████▋  | 68930/90000 [05:16<01:29, 234.39it/s] 77%|███████▋  | 68954/90000 [05:17<01:30, 232.35it/s] 77%|███████▋  | 68978/90000 [05:17<01:31, 230.30it/s] 77%|███████▋  | 69002/90000 [05:17<01:30, 230.97it/s] 77%|███████▋  | 69026/90000 [05:17<01:30, 232.73it/s] 77%|███████▋  | 69050/90000 [05:17<01:31, 229.85it/s] 77%|███████▋  | 69074/90000 [05:17<01:31, 228.23it/s] 77%|███████▋  | 69097/90000 [05:17<01:31, 228.34it/s] 77%|███████▋  | 69120/90000 [05:17<01:33, 224.45it/s] 77%|███████▋  | 69145/90000 [05:17<01:31, 229.04it/s] 77%|███████▋  | 69169/90000 [05:17<01:30, 231.21it/s] 77%|███████▋  | 69193/90000 [05:18<01:29, 233.07it/s] 77%|███████▋  | 69217/90000 [05:18<01:29, 232.88it/s] 77%|███████▋  | 69241/90000 [05:18<01:29, 232.73it/s] 77%|███████▋  | 69265/90000 [05:18<01:29, 232.56it/s] 77%|███████▋  | 69289/90000 [05:18<01:29, 232.13it/s] 77%|███████▋  | 69313/90000 [05:18<01:29, 230.12it/s] 77%|███████▋  | 69338/90000 [05:18<01:27, 235.51it/s] 77%|███████▋  | 69363/90000 [05:18<01:27, 236.72it/s] 77%|███████▋  | 69387/90000 [05:18<01:28, 233.41it/s] 77%|███████▋  | 69412/90000 [05:18<01:26, 237.90it/s] 77%|███████▋  | 69436/90000 [05:19<01:26, 236.47it/s] 77%|███████▋  | 69460/90000 [05:19<01:27, 236.00it/s] 77%|███████▋  | 69484/90000 [05:19<01:28, 232.09it/s] 77%|███████▋  | 69508/90000 [05:19<01:28, 232.12it/s] 77%|███████▋  | 69532/90000 [05:19<01:27, 233.81it/s] 77%|███████▋  | 69556/90000 [05:19<01:26, 235.06it/s] 77%|███████▋  | 69582/90000 [05:19<01:24, 240.77it/s] 77%|███████▋  | 69607/90000 [05:19<01:25, 239.36it/s] 77%|███████▋  | 69631/90000 [05:19<01:25, 238.41it/s] 77%|███████▋  | 69655/90000 [05:20<01:26, 236.11it/s] 77%|███████▋  | 69680/90000 [05:20<01:25, 237.77it/s] 77%|███████▋  | 69704/90000 [05:20<01:25, 236.67it/s] 77%|███████▋  | 69728/90000 [05:20<01:26, 233.79it/s] 78%|███████▊  | 69752/90000 [05:20<01:26, 233.68it/s] 78%|███████▊  | 69777/90000 [05:20<01:25, 235.46it/s] 78%|███████▊  | 69801/90000 [05:20<01:27, 230.59it/s] 78%|███████▊  | 69825/90000 [05:20<01:26, 233.04it/s] 78%|███████▊  | 69849/90000 [05:20<01:26, 233.39it/s] 78%|███████▊  | 69873/90000 [05:20<01:27, 229.96it/s] 78%|███████▊  | 69897/90000 [05:21<01:27, 230.79it/s] 78%|███████▊  | 69921/90000 [05:21<01:27, 228.54it/s] 78%|███████▊  | 69945/90000 [05:21<01:26, 231.12it/s] 78%|███████▊  | 69970/90000 [05:21<01:25, 234.72it/s] 78%|███████▊  | 69995/90000 [05:21<01:24, 237.40it/s] 78%|███████▊  | 70019/90000 [05:21<01:25, 233.92it/s] 78%|███████▊  | 70043/90000 [05:21<01:25, 233.74it/s] 78%|███████▊  | 70067/90000 [05:21<01:26, 231.52it/s] 78%|███████▊  | 70092/90000 [05:21<01:24, 234.96it/s] 78%|███████▊  | 70116/90000 [05:21<01:24, 235.97it/s] 78%|███████▊  | 70140/90000 [05:22<01:23, 236.96it/s] 78%|███████▊  | 70165/90000 [05:22<01:23, 236.79it/s] 78%|███████▊  | 70189/90000 [05:22<01:24, 235.26it/s] 78%|███████▊  | 70213/90000 [05:22<01:24, 234.78it/s] 78%|███████▊  | 70238/90000 [05:22<01:23, 237.48it/s] 78%|███████▊  | 70263/90000 [05:22<01:21, 240.90it/s] 78%|███████▊  | 70288/90000 [05:22<01:21, 240.45it/s] 78%|███████▊  | 70313/90000 [05:22<01:22, 240.01it/s] 78%|███████▊  | 70338/90000 [05:22<01:22, 238.30it/s] 78%|███████▊  | 70362/90000 [05:23<01:23, 236.48it/s] 78%|███████▊  | 70386/90000 [05:23<01:22, 237.40it/s] 78%|███████▊  | 70410/90000 [05:23<01:24, 232.99it/s] 78%|███████▊  | 70434/90000 [05:23<01:24, 230.52it/s] 78%|███████▊  | 70458/90000 [05:23<01:24, 230.49it/s] 78%|███████▊  | 70482/90000 [05:23<01:23, 233.20it/s] 78%|███████▊  | 70506/90000 [05:23<01:24, 231.61it/s] 78%|███████▊  | 70530/90000 [05:23<01:24, 231.60it/s] 78%|███████▊  | 70555/90000 [05:23<01:22, 234.56it/s] 78%|███████▊  | 70579/90000 [05:23<01:23, 233.05it/s] 78%|███████▊  | 70603/90000 [05:24<01:22, 233.93it/s] 78%|███████▊  | 70628/90000 [05:24<01:21, 237.55it/s] 79%|███████▊  | 70653/90000 [05:24<01:21, 238.75it/s] 79%|███████▊  | 70677/90000 [05:24<01:22, 235.04it/s] 79%|███████▊  | 70701/90000 [05:24<01:21, 236.45it/s] 79%|███████▊  | 70725/90000 [05:24<01:22, 234.59it/s] 79%|███████▊  | 70749/90000 [05:24<01:21, 236.01it/s] 79%|███████▊  | 70773/90000 [05:24<01:22, 232.01it/s] 79%|███████▊  | 70797/90000 [05:24<01:22, 233.93it/s] 79%|███████▊  | 70822/90000 [05:24<01:20, 236.86it/s] 79%|███████▊  | 70846/90000 [05:25<01:21, 234.28it/s] 79%|███████▊  | 70870/90000 [05:25<01:21, 234.24it/s] 79%|███████▉  | 70894/90000 [05:25<01:21, 235.47it/s] 79%|███████▉  | 70918/90000 [05:25<01:20, 235.85it/s] 79%|███████▉  | 70942/90000 [05:25<01:21, 232.57it/s] 79%|███████▉  | 70966/90000 [05:25<01:21, 233.86it/s] 79%|███████▉  | 70990/90000 [05:25<01:22, 231.41it/s] 79%|███████▉  | 71014/90000 [05:25<01:23, 227.67it/s] 79%|███████▉  | 71038/90000 [05:25<01:22, 230.55it/s] 79%|███████▉  | 71063/90000 [05:26<01:20, 234.75it/s] 79%|███████▉  | 71087/90000 [05:26<01:20, 233.93it/s] 79%|███████▉  | 71111/90000 [05:26<01:20, 235.35it/s] 79%|███████▉  | 71135/90000 [05:26<01:20, 235.25it/s] 79%|███████▉  | 71159/90000 [05:26<01:19, 236.04it/s] 79%|███████▉  | 71183/90000 [05:26<01:20, 234.52it/s] 79%|███████▉  | 71207/90000 [05:26<01:20, 232.72it/s] 79%|███████▉  | 71231/90000 [05:26<01:21, 230.71it/s] 79%|███████▉  | 71256/90000 [05:26<01:20, 233.35it/s] 79%|███████▉  | 71280/90000 [05:26<01:20, 232.75it/s] 79%|███████▉  | 71304/90000 [05:27<01:21, 230.31it/s] 79%|███████▉  | 71330/90000 [05:27<01:18, 237.21it/s] 79%|███████▉  | 71354/90000 [05:27<01:20, 231.37it/s] 79%|███████▉  | 71378/90000 [05:27<01:19, 233.02it/s] 79%|███████▉  | 71402/90000 [05:27<01:20, 232.10it/s] 79%|███████▉  | 71426/90000 [05:27<01:21, 228.56it/s] 79%|███████▉  | 71451/90000 [05:27<01:19, 232.32it/s] 79%|███████▉  | 71476/90000 [05:27<01:18, 235.11it/s] 79%|███████▉  | 71501/90000 [05:27<01:18, 236.58it/s] 79%|███████▉  | 71525/90000 [05:27<01:18, 235.18it/s] 79%|███████▉  | 71549/90000 [05:28<01:19, 232.02it/s] 80%|███████▉  | 71573/90000 [05:28<01:18, 233.41it/s] 80%|███████▉  | 71597/90000 [05:28<01:18, 233.24it/s] 80%|███████▉  | 71621/90000 [05:28<01:19, 231.54it/s] 80%|███████▉  | 71645/90000 [05:28<01:19, 232.13it/s] 80%|███████▉  | 71669/90000 [05:28<01:19, 231.19it/s] 80%|███████▉  | 71693/90000 [05:28<01:19, 229.87it/s] 80%|███████▉  | 71718/90000 [05:28<01:17, 235.55it/s] 80%|███████▉  | 71742/90000 [05:28<01:17, 236.26it/s] 80%|███████▉  | 71766/90000 [05:29<01:17, 234.24it/s] 80%|███████▉  | 71790/90000 [05:29<01:18, 232.02it/s] 80%|███████▉  | 71814/90000 [05:29<01:17, 233.85it/s] 80%|███████▉  | 71838/90000 [05:29<01:17, 234.46it/s] 80%|███████▉  | 71862/90000 [05:29<01:18, 232.33it/s] 80%|███████▉  | 71887/90000 [05:29<01:16, 236.76it/s] 80%|███████▉  | 71911/90000 [05:29<01:17, 234.78it/s] 80%|███████▉  | 71935/90000 [05:29<01:16, 235.37it/s] 80%|███████▉  | 71960/90000 [05:29<01:15, 237.84it/s] 80%|███████▉  | 71984/90000 [05:29<01:17, 233.58it/s] 80%|████████  | 72008/90000 [05:30<01:16, 234.94it/s] 80%|████████  | 72032/90000 [05:30<01:16, 234.30it/s] 80%|████████  | 72057/90000 [05:30<01:15, 238.59it/s] 80%|████████  | 72081/90000 [05:30<01:16, 234.94it/s] 80%|████████  | 72105/90000 [05:30<01:15, 236.04it/s] 80%|████████  | 72129/90000 [05:30<01:15, 235.33it/s] 80%|████████  | 72153/90000 [05:30<01:15, 235.57it/s] 80%|████████  | 72177/90000 [05:30<01:15, 236.07it/s] 80%|████████  | 72201/90000 [05:30<01:16, 231.27it/s] 80%|████████  | 72225/90000 [05:30<01:17, 229.84it/s] 80%|████████  | 72249/90000 [05:31<01:17, 229.44it/s] 80%|████████  | 72274/90000 [05:31<01:16, 232.50it/s] 80%|████████  | 72299/90000 [05:31<01:14, 236.14it/s] 80%|████████  | 72323/90000 [05:31<01:16, 232.55it/s] 80%|████████  | 72347/90000 [05:31<01:15, 234.23it/s] 80%|████████  | 72371/90000 [05:31<01:15, 233.96it/s] 80%|████████  | 72395/90000 [05:31<01:15, 234.31it/s] 80%|████████  | 72419/90000 [05:31<01:15, 232.73it/s] 80%|████████  | 72443/90000 [05:31<01:15, 232.30it/s] 81%|████████  | 72468/90000 [05:32<01:14, 235.01it/s] 81%|████████  | 72492/90000 [05:32<01:14, 234.22it/s] 81%|████████  | 72516/90000 [05:32<01:14, 233.54it/s] 81%|████████  | 72541/90000 [05:32<01:13, 236.67it/s] 81%|████████  | 72565/90000 [05:32<01:13, 236.73it/s] 81%|████████  | 72589/90000 [05:32<01:14, 233.72it/s] 81%|████████  | 72614/90000 [05:32<01:13, 236.18it/s] 81%|████████  | 72638/90000 [05:32<01:13, 237.00it/s] 81%|████████  | 72662/90000 [05:32<01:12, 237.78it/s] 81%|████████  | 72687/90000 [05:32<01:12, 240.34it/s] 81%|████████  | 72712/90000 [05:33<01:13, 235.01it/s] 81%|████████  | 72736/90000 [05:33<01:13, 235.33it/s] 81%|████████  | 72761/90000 [05:33<01:12, 238.06it/s] 81%|████████  | 72785/90000 [05:33<01:12, 236.56it/s] 81%|████████  | 72809/90000 [05:33<01:12, 237.49it/s] 81%|████████  | 72833/90000 [05:33<01:12, 237.48it/s] 81%|████████  | 72858/90000 [05:33<01:11, 238.09it/s] 81%|████████  | 72883/90000 [05:33<01:11, 238.69it/s] 81%|████████  | 72907/90000 [05:33<01:12, 235.51it/s] 81%|████████  | 72932/90000 [05:33<01:11, 237.40it/s] 81%|████████  | 72957/90000 [05:34<01:11, 238.00it/s] 81%|████████  | 72981/90000 [05:34<01:12, 233.86it/s] 81%|████████  | 73006/90000 [05:34<01:12, 235.30it/s] 81%|████████  | 73030/90000 [05:34<01:12, 232.73it/s] 81%|████████  | 73054/90000 [05:34<01:12, 234.26it/s] 81%|████████  | 73079/90000 [05:34<01:11, 235.97it/s] 81%|████████  | 73103/90000 [05:34<01:12, 234.47it/s] 81%|████████▏ | 73127/90000 [05:34<01:11, 234.78it/s] 81%|████████▏ | 73152/90000 [05:34<01:10, 237.85it/s] 81%|████████▏ | 73177/90000 [05:35<01:10, 238.90it/s] 81%|████████▏ | 73201/90000 [05:35<01:10, 237.62it/s] 81%|████████▏ | 73225/90000 [05:35<01:11, 234.76it/s] 81%|████████▏ | 73249/90000 [05:35<01:11, 232.88it/s] 81%|████████▏ | 73273/90000 [05:35<01:11, 232.72it/s] 81%|████████▏ | 73297/90000 [05:35<01:11, 232.34it/s] 81%|████████▏ | 73321/90000 [05:35<01:12, 228.84it/s] 81%|████████▏ | 73346/90000 [05:35<01:11, 232.67it/s] 82%|████████▏ | 73370/90000 [05:35<01:11, 232.03it/s] 82%|████████▏ | 73394/90000 [05:35<01:11, 230.93it/s] 82%|████████▏ | 73419/90000 [05:36<01:10, 234.61it/s] 82%|████████▏ | 73443/90000 [05:36<01:12, 228.98it/s] 82%|████████▏ | 73467/90000 [05:36<01:11, 231.10it/s] 82%|████████▏ | 73492/90000 [05:36<01:10, 234.28it/s] 82%|████████▏ | 73517/90000 [05:36<01:09, 237.51it/s] 82%|████████▏ | 73541/90000 [05:36<01:09, 235.42it/s] 82%|████████▏ | 73565/90000 [05:36<01:10, 232.04it/s] 82%|████████▏ | 73589/90000 [05:36<01:11, 230.38it/s] 82%|████████▏ | 73614/90000 [05:36<01:09, 234.15it/s] 82%|████████▏ | 73638/90000 [05:37<01:09, 234.25it/s] 82%|████████▏ | 73662/90000 [05:37<01:09, 233.41it/s] 82%|████████▏ | 73686/90000 [05:37<01:10, 232.53it/s] 82%|████████▏ | 73710/90000 [05:37<01:10, 232.05it/s] 82%|████████▏ | 73734/90000 [05:37<01:09, 233.83it/s] 82%|████████▏ | 73758/90000 [05:37<01:10, 229.78it/s] 82%|████████▏ | 73782/90000 [05:37<01:10, 230.90it/s] 82%|████████▏ | 73806/90000 [05:37<01:09, 233.16it/s] 82%|████████▏ | 73830/90000 [05:37<01:09, 233.67it/s] 82%|████████▏ | 73855/90000 [05:37<01:08, 235.93it/s] 82%|████████▏ | 73879/90000 [05:38<01:08, 236.78it/s] 82%|████████▏ | 73903/90000 [05:38<01:08, 234.71it/s] 82%|████████▏ | 73928/90000 [05:38<01:07, 237.56it/s] 82%|████████▏ | 73952/90000 [05:38<01:09, 232.48it/s] 82%|████████▏ | 73976/90000 [05:38<01:08, 233.59it/s] 82%|████████▏ | 74000/90000 [05:38<01:09, 230.32it/s] 82%|████████▏ | 74024/90000 [05:38<01:09, 231.40it/s] 82%|████████▏ | 74048/90000 [05:38<01:08, 233.06it/s] 82%|████████▏ | 74073/90000 [05:38<01:07, 236.58it/s] 82%|████████▏ | 74097/90000 [05:38<01:07, 233.95it/s] 82%|████████▏ | 74121/90000 [05:39<01:07, 234.81it/s] 82%|████████▏ | 74146/90000 [05:39<01:06, 237.58it/s] 82%|████████▏ | 74170/90000 [05:39<01:09, 228.09it/s] 82%|████████▏ | 74194/90000 [05:39<01:09, 228.56it/s] 82%|████████▏ | 74217/90000 [05:39<01:09, 227.41it/s] 82%|████████▏ | 74240/90000 [05:39<01:09, 227.86it/s] 83%|████████▎ | 74264/90000 [05:39<01:08, 229.29it/s] 83%|████████▎ | 74287/90000 [05:39<01:08, 228.49it/s] 83%|████████▎ | 74312/90000 [05:39<01:07, 231.64it/s] 83%|████████▎ | 74336/90000 [05:40<01:07, 231.40it/s] 83%|████████▎ | 74360/90000 [05:40<01:07, 230.38it/s] 83%|████████▎ | 74384/90000 [05:40<01:09, 224.95it/s] 83%|████████▎ | 74408/90000 [05:40<01:08, 227.65it/s] 83%|████████▎ | 74431/90000 [05:40<01:08, 227.84it/s] 83%|████████▎ | 74454/90000 [05:40<01:08, 227.73it/s] 83%|████████▎ | 74478/90000 [05:40<01:07, 229.53it/s] 83%|████████▎ | 74502/90000 [05:40<01:07, 229.80it/s] 83%|████████▎ | 74525/90000 [05:40<01:09, 222.54it/s] 83%|████████▎ | 74548/90000 [05:40<01:09, 223.74it/s] 83%|████████▎ | 74571/90000 [05:41<01:09, 222.94it/s] 83%|████████▎ | 74595/90000 [05:41<01:08, 226.09it/s] 83%|████████▎ | 74619/90000 [05:41<01:07, 227.24it/s] 83%|████████▎ | 74642/90000 [05:41<01:07, 226.18it/s] 83%|████████▎ | 74665/90000 [05:41<01:07, 225.59it/s] 83%|████████▎ | 74690/90000 [05:41<01:06, 231.94it/s] 83%|████████▎ | 74716/90000 [05:41<01:04, 237.45it/s] 83%|████████▎ | 74740/90000 [05:41<01:04, 234.86it/s] 83%|████████▎ | 74764/90000 [05:41<01:04, 235.99it/s] 83%|████████▎ | 74788/90000 [05:41<01:05, 230.58it/s] 83%|████████▎ | 74812/90000 [05:42<01:05, 230.36it/s] 83%|████████▎ | 74836/90000 [05:42<01:06, 228.83it/s] 83%|████████▎ | 74860/90000 [05:42<01:05, 229.99it/s] 83%|████████▎ | 74884/90000 [05:42<01:05, 230.99it/s] 83%|████████▎ | 74908/90000 [05:42<01:05, 230.21it/s] 83%|████████▎ | 74932/90000 [05:42<01:06, 225.20it/s] 83%|████████▎ | 74956/90000 [05:42<01:06, 227.87it/s] 83%|████████▎ | 74979/90000 [05:42<01:06, 226.05it/s] 83%|████████▎ | 75002/90000 [05:42<01:06, 225.81it/s] 83%|████████▎ | 75026/90000 [05:43<01:05, 229.62it/s] 83%|████████▎ | 75050/90000 [05:43<01:04, 232.47it/s] 83%|████████▎ | 75074/90000 [05:43<01:04, 230.34it/s] 83%|████████▎ | 75099/90000 [05:43<01:03, 235.21it/s] 83%|████████▎ | 75123/90000 [05:43<01:04, 231.74it/s] 83%|████████▎ | 75147/90000 [05:43<01:05, 225.98it/s] 84%|████████▎ | 75171/90000 [05:43<01:04, 229.10it/s] 84%|████████▎ | 75195/90000 [05:43<01:04, 229.51it/s] 84%|████████▎ | 75218/90000 [05:43<01:05, 226.78it/s] 84%|████████▎ | 75242/90000 [05:43<01:04, 229.13it/s] 84%|████████▎ | 75266/90000 [05:44<01:03, 231.20it/s] 84%|████████▎ | 75290/90000 [05:44<01:03, 231.41it/s] 84%|████████▎ | 75314/90000 [05:44<01:04, 228.91it/s] 84%|████████▎ | 75337/90000 [05:44<01:05, 224.48it/s] 84%|████████▎ | 75361/90000 [05:44<01:03, 228.93it/s] 84%|████████▍ | 75385/90000 [05:44<01:03, 230.45it/s] 84%|████████▍ | 75409/90000 [05:44<01:03, 228.05it/s] 84%|████████▍ | 75434/90000 [05:44<01:02, 231.23it/s] 84%|████████▍ | 75458/90000 [05:44<01:03, 230.41it/s] 84%|████████▍ | 75482/90000 [05:45<01:05, 223.10it/s] 84%|████████▍ | 75505/90000 [05:45<01:05, 222.21it/s] 84%|████████▍ | 75529/90000 [05:45<01:03, 226.45it/s] 84%|████████▍ | 75552/90000 [05:45<01:03, 226.92it/s] 84%|████████▍ | 75576/90000 [05:45<01:02, 230.00it/s] 84%|████████▍ | 75600/90000 [05:45<01:04, 222.47it/s] 84%|████████▍ | 75624/90000 [05:45<01:03, 225.81it/s] 84%|████████▍ | 75647/90000 [05:45<01:03, 224.76it/s] 84%|████████▍ | 75671/90000 [05:45<01:03, 226.09it/s] 84%|████████▍ | 75694/90000 [05:45<01:03, 225.96it/s] 84%|████████▍ | 75718/90000 [05:46<01:02, 228.47it/s] 84%|████████▍ | 75742/90000 [05:46<01:02, 229.74it/s] 84%|████████▍ | 75766/90000 [05:46<01:01, 230.73it/s] 84%|████████▍ | 75790/90000 [05:46<01:01, 230.53it/s] 84%|████████▍ | 75814/90000 [05:46<01:01, 231.85it/s] 84%|████████▍ | 75838/90000 [05:46<01:00, 232.85it/s] 84%|████████▍ | 75862/90000 [05:46<01:00, 233.66it/s] 84%|████████▍ | 75886/90000 [05:46<01:01, 229.19it/s] 84%|████████▍ | 75911/90000 [05:46<01:00, 232.69it/s] 84%|████████▍ | 75935/90000 [05:47<01:00, 232.91it/s] 84%|████████▍ | 75959/90000 [05:47<01:00, 231.88it/s] 84%|████████▍ | 75983/90000 [05:47<01:00, 229.97it/s] 84%|████████▍ | 76007/90000 [05:47<01:00, 229.95it/s] 84%|████████▍ | 76031/90000 [05:47<01:00, 229.89it/s] 85%|████████▍ | 76054/90000 [05:47<01:00, 229.90it/s] 85%|████████▍ | 76078/90000 [05:47<00:59, 232.57it/s] 85%|████████▍ | 76102/90000 [05:47<01:00, 230.37it/s] 85%|████████▍ | 76126/90000 [05:47<01:00, 229.02it/s] 85%|████████▍ | 76151/90000 [05:47<00:59, 231.41it/s] 85%|████████▍ | 76175/90000 [05:48<01:00, 228.54it/s] 85%|████████▍ | 76199/90000 [05:48<00:59, 230.05it/s] 85%|████████▍ | 76223/90000 [05:48<01:00, 229.36it/s] 85%|████████▍ | 76248/90000 [05:48<00:58, 233.96it/s] 85%|████████▍ | 76272/90000 [05:48<00:58, 232.84it/s] 85%|████████▍ | 76296/90000 [05:48<00:58, 233.69it/s] 85%|████████▍ | 76320/90000 [05:48<00:59, 230.60it/s] 85%|████████▍ | 76344/90000 [05:48<00:59, 227.92it/s] 85%|████████▍ | 76367/90000 [05:48<01:00, 226.11it/s] 85%|████████▍ | 76390/90000 [05:48<01:00, 224.66it/s] 85%|████████▍ | 76413/90000 [05:49<01:00, 223.47it/s] 85%|████████▍ | 76437/90000 [05:49<00:59, 226.46it/s] 85%|████████▍ | 76461/90000 [05:49<00:59, 226.68it/s] 85%|████████▍ | 76484/90000 [05:49<00:59, 225.77it/s] 85%|████████▌ | 76507/90000 [05:49<00:59, 226.25it/s] 85%|████████▌ | 76532/90000 [05:49<00:58, 231.10it/s] 85%|████████▌ | 76556/90000 [05:49<00:57, 233.06it/s] 85%|████████▌ | 76580/90000 [05:49<00:58, 230.69it/s] 85%|████████▌ | 76604/90000 [05:49<00:58, 228.25it/s] 85%|████████▌ | 76628/90000 [05:50<00:58, 229.32it/s] 85%|████████▌ | 76652/90000 [05:50<00:58, 229.53it/s] 85%|████████▌ | 76676/90000 [05:50<00:57, 231.37it/s] 85%|████████▌ | 76700/90000 [05:50<00:57, 231.12it/s] 85%|████████▌ | 76724/90000 [05:50<00:57, 231.67it/s] 85%|████████▌ | 76748/90000 [05:50<00:56, 232.64it/s] 85%|████████▌ | 76772/90000 [05:50<00:57, 231.10it/s] 85%|████████▌ | 76797/90000 [05:50<00:55, 236.01it/s] 85%|████████▌ | 76821/90000 [05:50<00:57, 230.26it/s] 85%|████████▌ | 76845/90000 [05:50<00:56, 230.80it/s] 85%|████████▌ | 76869/90000 [05:51<00:56, 232.32it/s] 85%|████████▌ | 76893/90000 [05:51<00:55, 234.56it/s] 85%|████████▌ | 76918/90000 [05:51<00:55, 237.62it/s] 85%|████████▌ | 76942/90000 [05:51<00:55, 236.16it/s] 86%|████████▌ | 76966/90000 [05:51<00:55, 234.35it/s] 86%|████████▌ | 76990/90000 [05:51<00:55, 234.42it/s] 86%|████████▌ | 77014/90000 [05:51<00:55, 235.41it/s] 86%|████████▌ | 77038/90000 [05:51<00:55, 234.21it/s] 86%|████████▌ | 77062/90000 [05:51<00:55, 234.14it/s] 86%|████████▌ | 77086/90000 [05:51<00:55, 234.25it/s] 86%|████████▌ | 77110/90000 [05:52<00:55, 234.24it/s] 86%|████████▌ | 77134/90000 [05:52<00:55, 232.63it/s] 86%|████████▌ | 77158/90000 [05:52<00:55, 229.85it/s] 86%|████████▌ | 77182/90000 [05:52<00:55, 231.08it/s] 86%|████████▌ | 77206/90000 [05:52<00:55, 231.59it/s] 86%|████████▌ | 77230/90000 [05:52<00:54, 232.49it/s] 86%|████████▌ | 77254/90000 [05:52<00:54, 234.23it/s] 86%|████████▌ | 77278/90000 [05:52<00:54, 235.26it/s] 86%|████████▌ | 77302/90000 [05:52<00:54, 233.78it/s] 86%|████████▌ | 77326/90000 [05:53<00:54, 230.81it/s] 86%|████████▌ | 77351/90000 [05:53<00:54, 233.83it/s] 86%|████████▌ | 77375/90000 [05:53<00:53, 235.21it/s] 86%|████████▌ | 77399/90000 [05:53<00:53, 233.43it/s] 86%|████████▌ | 77423/90000 [05:53<00:53, 234.25it/s] 86%|████████▌ | 77448/90000 [05:53<00:53, 235.41it/s] 86%|████████▌ | 77472/90000 [05:53<00:54, 230.48it/s] 86%|████████▌ | 77497/90000 [05:53<00:53, 233.56it/s] 86%|████████▌ | 77521/90000 [05:53<00:53, 234.91it/s] 86%|████████▌ | 77545/90000 [05:53<00:53, 230.95it/s] 86%|████████▌ | 77570/90000 [05:54<00:52, 235.20it/s] 86%|████████▌ | 77594/90000 [05:54<00:53, 231.76it/s] 86%|████████▌ | 77618/90000 [05:54<00:53, 230.29it/s] 86%|████████▋ | 77643/90000 [05:54<00:52, 233.75it/s] 86%|████████▋ | 77667/90000 [05:54<00:52, 234.11it/s] 86%|████████▋ | 77691/90000 [05:54<00:53, 231.68it/s] 86%|████████▋ | 77715/90000 [05:54<00:52, 233.20it/s] 86%|████████▋ | 77739/90000 [05:54<00:53, 227.12it/s] 86%|████████▋ | 77762/90000 [05:54<00:53, 227.31it/s] 86%|████████▋ | 77785/90000 [05:55<00:54, 225.83it/s] 86%|████████▋ | 77808/90000 [05:55<00:54, 224.83it/s] 86%|████████▋ | 77831/90000 [05:55<00:55, 220.96it/s] 87%|████████▋ | 77854/90000 [05:55<00:55, 219.39it/s] 87%|████████▋ | 77877/90000 [05:55<00:54, 221.68it/s] 87%|████████▋ | 77900/90000 [05:55<00:54, 220.28it/s] 87%|████████▋ | 77923/90000 [05:55<00:54, 221.79it/s] 87%|████████▋ | 77947/90000 [05:55<00:53, 225.55it/s] 87%|████████▋ | 77972/90000 [05:55<00:51, 232.31it/s] 87%|████████▋ | 77996/90000 [05:55<00:52, 230.51it/s] 87%|████████▋ | 78020/90000 [05:56<00:51, 230.65it/s] 87%|████████▋ | 78044/90000 [05:56<00:52, 228.80it/s] 87%|████████▋ | 78067/90000 [05:56<00:52, 227.58it/s] 87%|████████▋ | 78090/90000 [05:56<00:53, 223.24it/s] 87%|████████▋ | 78113/90000 [05:56<00:52, 224.69it/s] 87%|████████▋ | 78137/90000 [05:56<00:52, 227.29it/s] 87%|████████▋ | 78160/90000 [05:56<00:52, 227.51it/s] 87%|████████▋ | 78183/90000 [05:56<00:51, 227.43it/s] 87%|████████▋ | 78207/90000 [05:56<00:51, 228.35it/s] 87%|████████▋ | 78230/90000 [05:56<00:53, 220.86it/s] 87%|████████▋ | 78253/90000 [05:57<00:53, 221.03it/s] 87%|████████▋ | 78276/90000 [05:57<00:52, 222.01it/s] 87%|████████▋ | 78299/90000 [05:57<00:52, 223.29it/s] 87%|████████▋ | 78324/90000 [05:57<00:51, 227.71it/s] 87%|████████▋ | 78350/90000 [05:57<00:49, 234.58it/s] 87%|████████▋ | 78374/90000 [05:57<00:51, 226.26it/s] 87%|████████▋ | 78397/90000 [05:57<00:51, 226.88it/s] 87%|████████▋ | 78420/90000 [05:57<00:50, 227.52it/s] 87%|████████▋ | 78443/90000 [05:57<00:50, 227.44it/s] 87%|████████▋ | 78468/90000 [05:58<00:49, 231.78it/s] 87%|████████▋ | 78492/90000 [05:58<00:49, 233.32it/s] 87%|████████▋ | 78516/90000 [05:58<00:48, 234.93it/s] 87%|████████▋ | 78540/90000 [05:58<00:49, 229.63it/s] 87%|████████▋ | 78564/90000 [05:58<00:49, 229.32it/s] 87%|████████▋ | 78588/90000 [05:58<00:49, 230.39it/s] 87%|████████▋ | 78613/90000 [05:58<00:48, 234.12it/s] 87%|████████▋ | 78637/90000 [05:58<00:48, 235.27it/s] 87%|████████▋ | 78661/90000 [05:58<00:48, 231.56it/s] 87%|████████▋ | 78685/90000 [05:58<00:49, 230.21it/s] 87%|████████▋ | 78709/90000 [05:59<00:50, 224.80it/s] 87%|████████▋ | 78734/90000 [05:59<00:48, 231.25it/s] 88%|████████▊ | 78758/90000 [05:59<00:48, 230.31it/s] 88%|████████▊ | 78782/90000 [05:59<00:48, 231.08it/s] 88%|████████▊ | 78806/90000 [05:59<00:48, 228.45it/s] 88%|████████▊ | 78829/90000 [05:59<00:49, 223.85it/s] 88%|████████▊ | 78854/90000 [05:59<00:48, 230.43it/s] 88%|████████▊ | 78878/90000 [05:59<00:47, 232.16it/s] 88%|████████▊ | 78902/90000 [05:59<00:47, 231.37it/s] 88%|████████▊ | 78926/90000 [06:00<00:48, 230.46it/s] 88%|████████▊ | 78950/90000 [06:00<00:48, 227.26it/s] 88%|████████▊ | 78974/90000 [06:00<00:47, 230.86it/s] 88%|████████▊ | 78998/90000 [06:00<00:47, 230.43it/s] 88%|████████▊ | 79022/90000 [06:00<00:47, 230.37it/s] 88%|████████▊ | 79046/90000 [06:00<00:47, 231.16it/s] 88%|████████▊ | 79070/90000 [06:00<00:47, 229.26it/s] 88%|████████▊ | 79093/90000 [06:00<00:48, 226.55it/s] 88%|████████▊ | 79117/90000 [06:00<00:47, 228.83it/s] 88%|████████▊ | 79140/90000 [06:00<00:47, 228.02it/s] 88%|████████▊ | 79165/90000 [06:01<00:46, 231.86it/s] 88%|████████▊ | 79189/90000 [06:01<00:46, 232.44it/s] 88%|████████▊ | 79213/90000 [06:01<00:47, 229.23it/s] 88%|████████▊ | 79236/90000 [06:01<00:47, 227.11it/s] 88%|████████▊ | 79260/90000 [06:01<00:46, 230.22it/s] 88%|████████▊ | 79284/90000 [06:01<00:46, 230.59it/s] 88%|████████▊ | 79308/90000 [06:01<00:47, 227.17it/s] 88%|████████▊ | 79332/90000 [06:01<00:46, 228.60it/s] 88%|████████▊ | 79357/90000 [06:01<00:45, 231.60it/s] 88%|████████▊ | 79382/90000 [06:01<00:45, 234.24it/s] 88%|████████▊ | 79407/90000 [06:02<00:44, 237.95it/s] 88%|████████▊ | 79431/90000 [06:02<00:44, 235.53it/s] 88%|████████▊ | 79455/90000 [06:02<00:45, 231.85it/s] 88%|████████▊ | 79480/90000 [06:02<00:44, 234.39it/s] 88%|████████▊ | 79504/90000 [06:02<00:44, 234.27it/s] 88%|████████▊ | 79528/90000 [06:02<00:45, 230.70it/s] 88%|████████▊ | 79552/90000 [06:02<00:44, 232.94it/s] 88%|████████▊ | 79576/90000 [06:02<00:45, 231.55it/s] 88%|████████▊ | 79600/90000 [06:02<00:44, 233.01it/s] 88%|████████▊ | 79625/90000 [06:03<00:43, 236.38it/s] 88%|████████▊ | 79649/90000 [06:03<00:44, 233.77it/s] 89%|████████▊ | 79673/90000 [06:03<00:44, 231.73it/s] 89%|████████▊ | 79697/90000 [06:03<00:45, 228.54it/s] 89%|████████▊ | 79720/90000 [06:03<00:45, 226.60it/s] 89%|████████▊ | 79744/90000 [06:03<00:45, 226.66it/s] 89%|████████▊ | 79769/90000 [06:03<00:44, 231.38it/s] 89%|████████▊ | 79793/90000 [06:03<00:44, 229.56it/s] 89%|████████▊ | 79816/90000 [06:03<00:45, 226.09it/s] 89%|████████▊ | 79839/90000 [06:03<00:44, 226.83it/s] 89%|████████▊ | 79862/90000 [06:04<00:45, 223.08it/s] 89%|████████▉ | 79885/90000 [06:04<00:45, 224.04it/s] 89%|████████▉ | 79908/90000 [06:04<00:44, 225.19it/s] 89%|████████▉ | 79931/90000 [06:04<00:45, 223.44it/s] 89%|████████▉ | 79955/90000 [06:04<00:44, 225.85it/s] 89%|████████▉ | 79978/90000 [06:04<00:44, 225.65it/s] 89%|████████▉ | 80002/90000 [06:04<00:43, 228.29it/s] 89%|████████▉ | 80025/90000 [06:04<00:44, 224.31it/s] 89%|████████▉ | 80048/90000 [06:04<00:45, 219.16it/s] 89%|████████▉ | 80071/90000 [06:05<00:45, 220.44it/s] 89%|████████▉ | 80094/90000 [06:05<00:45, 219.41it/s] 89%|████████▉ | 80118/90000 [06:05<00:44, 223.37it/s] 89%|████████▉ | 80141/90000 [06:05<00:44, 223.65it/s] 89%|████████▉ | 80164/90000 [06:05<00:43, 224.65it/s] 89%|████████▉ | 80187/90000 [06:05<00:44, 222.36it/s] 89%|████████▉ | 80210/90000 [06:05<00:44, 219.45it/s] 89%|████████▉ | 80233/90000 [06:05<00:44, 221.19it/s] 89%|████████▉ | 80256/90000 [06:05<00:44, 217.47it/s] 89%|████████▉ | 80279/90000 [06:05<00:44, 220.41it/s] 89%|████████▉ | 80302/90000 [06:06<00:43, 220.77it/s] 89%|████████▉ | 80325/90000 [06:06<00:43, 222.13it/s] 89%|████████▉ | 80348/90000 [06:06<00:43, 222.74it/s] 89%|████████▉ | 80371/90000 [06:06<00:43, 222.91it/s] 89%|████████▉ | 80394/90000 [06:06<00:44, 218.20it/s] 89%|████████▉ | 80417/90000 [06:06<00:43, 220.62it/s] 89%|████████▉ | 80440/90000 [06:06<00:44, 217.10it/s] 89%|████████▉ | 80463/90000 [06:06<00:43, 218.48it/s] 89%|████████▉ | 80485/90000 [06:06<00:43, 217.82it/s] 89%|████████▉ | 80507/90000 [06:07<00:44, 214.81it/s] 89%|████████▉ | 80530/90000 [06:07<00:43, 218.35it/s] 90%|████████▉ | 80552/90000 [06:07<00:44, 212.89it/s] 90%|████████▉ | 80574/90000 [06:07<00:44, 211.94it/s] 90%|████████▉ | 80597/90000 [06:07<00:43, 216.01it/s] 90%|████████▉ | 80620/90000 [06:07<00:42, 219.04it/s] 90%|████████▉ | 80643/90000 [06:07<00:42, 221.78it/s] 90%|████████▉ | 80666/90000 [06:07<00:43, 216.94it/s] 90%|████████▉ | 80688/90000 [06:07<00:43, 214.80it/s] 90%|████████▉ | 80711/90000 [06:07<00:42, 218.50it/s] 90%|████████▉ | 80733/90000 [06:08<00:43, 213.67it/s] 90%|████████▉ | 80755/90000 [06:08<00:44, 209.13it/s] 90%|████████▉ | 80776/90000 [06:08<00:44, 208.59it/s] 90%|████████▉ | 80798/90000 [06:08<00:43, 209.55it/s] 90%|████████▉ | 80821/90000 [06:08<00:43, 212.71it/s] 90%|████████▉ | 80844/90000 [06:08<00:42, 214.44it/s] 90%|████████▉ | 80866/90000 [06:08<00:42, 215.09it/s] 90%|████████▉ | 80889/90000 [06:08<00:41, 218.96it/s] 90%|████████▉ | 80912/90000 [06:08<00:41, 220.78it/s] 90%|████████▉ | 80935/90000 [06:08<00:40, 221.85it/s] 90%|████████▉ | 80959/90000 [06:09<00:40, 225.78it/s] 90%|████████▉ | 80983/90000 [06:09<00:39, 228.79it/s] 90%|█████████ | 81006/90000 [06:09<00:39, 226.35it/s] 90%|█████████ | 81030/90000 [06:09<00:39, 229.91it/s] 90%|█████████ | 81054/90000 [06:09<00:39, 228.77it/s] 90%|█████████ | 81077/90000 [06:09<00:39, 227.09it/s] 90%|█████████ | 81100/90000 [06:09<00:39, 225.56it/s] 90%|█████████ | 81124/90000 [06:09<00:38, 229.00it/s] 90%|█████████ | 81147/90000 [06:09<00:38, 228.13it/s] 90%|█████████ | 81170/90000 [06:10<00:38, 227.34it/s] 90%|█████████ | 81193/90000 [06:10<00:38, 227.56it/s] 90%|█████████ | 81216/90000 [06:10<00:38, 226.91it/s] 90%|█████████ | 81240/90000 [06:10<00:38, 228.90it/s] 90%|█████████ | 81265/90000 [06:10<00:37, 232.04it/s] 90%|█████████ | 81289/90000 [06:10<00:37, 231.88it/s] 90%|█████████ | 81313/90000 [06:10<00:38, 227.81it/s] 90%|█████████ | 81337/90000 [06:10<00:37, 230.94it/s] 90%|█████████ | 81361/90000 [06:10<00:37, 231.17it/s] 90%|█████████ | 81385/90000 [06:10<00:37, 228.51it/s] 90%|█████████ | 81409/90000 [06:11<00:37, 231.34it/s] 90%|█████████ | 81433/90000 [06:11<00:37, 231.31it/s] 91%|█████████ | 81457/90000 [06:11<00:36, 231.94it/s] 91%|█████████ | 81481/90000 [06:11<00:36, 232.54it/s] 91%|█████████ | 81505/90000 [06:11<00:36, 229.91it/s] 91%|█████████ | 81529/90000 [06:11<00:36, 232.13it/s] 91%|█████████ | 81554/90000 [06:11<00:35, 236.24it/s] 91%|█████████ | 81578/90000 [06:11<00:35, 236.76it/s] 91%|█████████ | 81602/90000 [06:11<00:36, 230.91it/s] 91%|█████████ | 81626/90000 [06:11<00:36, 231.78it/s] 91%|█████████ | 81650/90000 [06:12<00:35, 232.85it/s] 91%|█████████ | 81674/90000 [06:12<00:35, 231.98it/s] 91%|█████████ | 81698/90000 [06:12<00:35, 231.42it/s] 91%|█████████ | 81722/90000 [06:12<00:35, 230.97it/s] 91%|█████████ | 81746/90000 [06:12<00:35, 230.31it/s] 91%|█████████ | 81770/90000 [06:12<00:35, 231.47it/s] 91%|█████████ | 81794/90000 [06:12<00:35, 232.49it/s] 91%|█████████ | 81818/90000 [06:12<00:35, 229.38it/s] 91%|█████████ | 81841/90000 [06:12<00:35, 227.12it/s] 91%|█████████ | 81864/90000 [06:13<00:35, 226.60it/s] 91%|█████████ | 81887/90000 [06:13<00:35, 227.49it/s] 91%|█████████ | 81910/90000 [06:13<00:35, 227.93it/s] 91%|█████████ | 81934/90000 [06:13<00:35, 229.84it/s] 91%|█████████ | 81957/90000 [06:13<00:35, 229.30it/s] 91%|█████████ | 81980/90000 [06:13<00:35, 225.70it/s] 91%|█████████ | 82004/90000 [06:13<00:35, 227.00it/s] 91%|█████████ | 82027/90000 [06:13<00:35, 222.60it/s] 91%|█████████ | 82050/90000 [06:13<00:36, 220.01it/s] 91%|█████████ | 82073/90000 [06:13<00:35, 221.02it/s] 91%|█████████ | 82096/90000 [06:14<00:36, 218.41it/s] 91%|█████████ | 82118/90000 [06:14<00:36, 217.68it/s] 91%|█████████▏| 82141/90000 [06:14<00:35, 220.99it/s] 91%|█████████▏| 82164/90000 [06:14<00:36, 217.19it/s] 91%|█████████▏| 82186/90000 [06:14<00:35, 217.60it/s] 91%|█████████▏| 82208/90000 [06:14<00:35, 216.99it/s] 91%|█████████▏| 82231/90000 [06:14<00:35, 219.20it/s] 91%|█████████▏| 82253/90000 [06:14<00:35, 216.24it/s] 91%|█████████▏| 82275/90000 [06:14<00:35, 214.76it/s] 91%|█████████▏| 82298/90000 [06:14<00:35, 218.15it/s] 91%|█████████▏| 82322/90000 [06:15<00:34, 223.06it/s] 91%|█████████▏| 82346/90000 [06:15<00:33, 226.50it/s] 92%|█████████▏| 82370/90000 [06:15<00:33, 229.10it/s] 92%|█████████▏| 82394/90000 [06:15<00:32, 231.24it/s] 92%|█████████▏| 82418/90000 [06:15<00:33, 228.32it/s] 92%|█████████▏| 82441/90000 [06:15<00:33, 227.03it/s] 92%|█████████▏| 82464/90000 [06:15<00:33, 225.01it/s] 92%|█████████▏| 82487/90000 [06:15<00:33, 225.67it/s] 92%|█████████▏| 82510/90000 [06:15<00:33, 225.58it/s] 92%|█████████▏| 82533/90000 [06:16<00:33, 225.37it/s] 92%|█████████▏| 82556/90000 [06:16<00:32, 226.69it/s] 92%|█████████▏| 82579/90000 [06:16<00:33, 220.72it/s] 92%|█████████▏| 82602/90000 [06:16<00:33, 222.63it/s] 92%|█████████▏| 82625/90000 [06:16<00:33, 222.85it/s] 92%|█████████▏| 82649/90000 [06:16<00:32, 224.34it/s] 92%|█████████▏| 82673/90000 [06:16<00:32, 226.29it/s] 92%|█████████▏| 82698/90000 [06:16<00:31, 230.55it/s] 92%|█████████▏| 82722/90000 [06:16<00:32, 223.02it/s] 92%|█████████▏| 82745/90000 [06:16<00:32, 220.20it/s] 92%|█████████▏| 82768/90000 [06:17<00:32, 221.05it/s] 92%|█████████▏| 82791/90000 [06:17<00:32, 223.19it/s] 92%|█████████▏| 82816/90000 [06:17<00:31, 229.13it/s] 92%|█████████▏| 82840/90000 [06:17<00:31, 230.06it/s] 92%|█████████▏| 82864/90000 [06:17<00:31, 223.24it/s] 92%|█████████▏| 82887/90000 [06:17<00:31, 224.37it/s] 92%|█████████▏| 82912/90000 [06:17<00:30, 229.88it/s] 92%|█████████▏| 82936/90000 [06:17<00:30, 228.67it/s] 92%|█████████▏| 82960/90000 [06:17<00:30, 230.29it/s] 92%|█████████▏| 82985/90000 [06:18<00:30, 233.79it/s] 92%|█████████▏| 83009/90000 [06:18<00:30, 232.10it/s] 92%|█████████▏| 83033/90000 [06:18<00:30, 231.11it/s] 92%|█████████▏| 83057/90000 [06:18<00:30, 225.36it/s] 92%|█████████▏| 83081/90000 [06:18<00:30, 226.90it/s] 92%|█████████▏| 83104/90000 [06:18<00:30, 227.69it/s] 92%|█████████▏| 83128/90000 [06:18<00:30, 228.65it/s] 92%|█████████▏| 83151/90000 [06:18<00:30, 224.81it/s] 92%|█████████▏| 83175/90000 [06:18<00:29, 228.54it/s] 92%|█████████▏| 83198/90000 [06:18<00:29, 227.53it/s] 92%|█████████▏| 83221/90000 [06:19<00:29, 227.70it/s] 92%|█████████▏| 83244/90000 [06:19<00:29, 227.50it/s] 93%|█████████▎| 83267/90000 [06:19<00:29, 225.18it/s] 93%|█████████▎| 83290/90000 [06:19<00:29, 226.54it/s] 93%|█████████▎| 83314/90000 [06:19<00:29, 229.11it/s] 93%|█████████▎| 83337/90000 [06:19<00:29, 227.51it/s] 93%|█████████▎| 83361/90000 [06:19<00:29, 228.78it/s] 93%|█████████▎| 83384/90000 [06:19<00:29, 227.56it/s] 93%|█████████▎| 83408/90000 [06:19<00:28, 228.66it/s] 93%|█████████▎| 83431/90000 [06:19<00:29, 225.90it/s] 93%|█████████▎| 83454/90000 [06:20<00:29, 221.96it/s] 93%|█████████▎| 83479/90000 [06:20<00:28, 229.09it/s] 93%|█████████▎| 83502/90000 [06:20<00:28, 227.56it/s] 93%|█████████▎| 83526/90000 [06:20<00:28, 230.58it/s] 93%|█████████▎| 83550/90000 [06:20<00:27, 230.49it/s] 93%|█████████▎| 83574/90000 [06:20<00:27, 230.37it/s] 93%|█████████▎| 83598/90000 [06:20<00:28, 228.50it/s] 93%|█████████▎| 83621/90000 [06:20<00:27, 227.85it/s] 93%|█████████▎| 83646/90000 [06:20<00:27, 233.04it/s] 93%|█████████▎| 83670/90000 [06:21<00:27, 231.50it/s] 93%|█████████▎| 83694/90000 [06:21<00:27, 228.90it/s] 93%|█████████▎| 83717/90000 [06:21<00:27, 228.73it/s] 93%|█████████▎| 83740/90000 [06:21<00:27, 225.86it/s] 93%|█████████▎| 83764/90000 [06:21<00:27, 229.35it/s] 93%|█████████▎| 83787/90000 [06:21<00:27, 225.24it/s] 93%|█████████▎| 83810/90000 [06:21<00:27, 223.79it/s] 93%|█████████▎| 83833/90000 [06:21<00:27, 225.49it/s] 93%|█████████▎| 83858/90000 [06:21<00:26, 229.94it/s] 93%|█████████▎| 83882/90000 [06:21<00:26, 227.47it/s] 93%|█████████▎| 83906/90000 [06:22<00:26, 228.51it/s] 93%|█████████▎| 83930/90000 [06:22<00:26, 231.12it/s] 93%|█████████▎| 83954/90000 [06:22<00:26, 228.44it/s] 93%|█████████▎| 83977/90000 [06:22<00:26, 228.14it/s] 93%|█████████▎| 84000/90000 [06:22<00:26, 228.52it/s] 93%|█████████▎| 84024/90000 [06:22<00:25, 230.05it/s] 93%|█████████▎| 84048/90000 [06:22<00:26, 228.77it/s] 93%|█████████▎| 84072/90000 [06:22<00:25, 231.58it/s] 93%|█████████▎| 84096/90000 [06:22<00:25, 230.66it/s] 93%|█████████▎| 84120/90000 [06:22<00:25, 228.86it/s] 93%|█████████▎| 84143/90000 [06:23<00:25, 228.20it/s] 94%|█████████▎| 84168/90000 [06:23<00:25, 232.45it/s] 94%|█████████▎| 84193/90000 [06:23<00:24, 236.09it/s] 94%|█████████▎| 84217/90000 [06:23<00:24, 235.14it/s] 94%|█████████▎| 84242/90000 [06:23<00:24, 235.63it/s] 94%|█████████▎| 84266/90000 [06:23<00:24, 231.31it/s] 94%|█████████▎| 84291/90000 [06:23<00:24, 235.09it/s] 94%|█████████▎| 84315/90000 [06:23<00:24, 231.94it/s] 94%|█████████▎| 84339/90000 [06:23<00:24, 232.19it/s] 94%|█████████▎| 84363/90000 [06:24<00:24, 230.90it/s] 94%|█████████▍| 84387/90000 [06:24<00:24, 231.38it/s] 94%|█████████▍| 84411/90000 [06:24<00:24, 228.41it/s] 94%|█████████▍| 84435/90000 [06:24<00:24, 229.66it/s] 94%|█████████▍| 84458/90000 [06:24<00:24, 229.57it/s] 94%|█████████▍| 84482/90000 [06:24<00:23, 232.10it/s] 94%|█████████▍| 84506/90000 [06:24<00:23, 230.24it/s] 94%|█████████▍| 84530/90000 [06:24<00:23, 228.41it/s] 94%|█████████▍| 84553/90000 [06:24<00:24, 226.71it/s] 94%|█████████▍| 84578/90000 [06:24<00:23, 229.76it/s] 94%|█████████▍| 84601/90000 [06:25<00:24, 224.73it/s] 94%|█████████▍| 84624/90000 [06:25<00:24, 221.98it/s] 94%|█████████▍| 84648/90000 [06:25<00:23, 226.48it/s] 94%|█████████▍| 84671/90000 [06:25<00:23, 222.99it/s] 94%|█████████▍| 84695/90000 [06:25<00:23, 224.80it/s] 94%|█████████▍| 84719/90000 [06:25<00:23, 227.21it/s] 94%|█████████▍| 84742/90000 [06:25<00:23, 225.26it/s] 94%|█████████▍| 84765/90000 [06:25<00:23, 225.78it/s] 94%|█████████▍| 84789/90000 [06:25<00:22, 228.05it/s] 94%|█████████▍| 84813/90000 [06:26<00:22, 229.56it/s] 94%|█████████▍| 84837/90000 [06:26<00:22, 231.05it/s] 94%|█████████▍| 84861/90000 [06:26<00:22, 230.84it/s] 94%|█████████▍| 84885/90000 [06:26<00:22, 232.41it/s] 94%|█████████▍| 84909/90000 [06:26<00:22, 229.47it/s] 94%|█████████▍| 84933/90000 [06:26<00:21, 230.67it/s] 94%|█████████▍| 84957/90000 [06:26<00:21, 229.85it/s] 94%|█████████▍| 84980/90000 [06:26<00:21, 228.24it/s] 94%|█████████▍| 85003/90000 [06:26<00:22, 225.86it/s] 94%|█████████▍| 85026/90000 [06:26<00:22, 226.02it/s] 94%|█████████▍| 85050/90000 [06:27<00:21, 227.38it/s] 95%|█████████▍| 85073/90000 [06:27<00:21, 225.12it/s] 95%|█████████▍| 85097/90000 [06:27<00:21, 228.36it/s] 95%|█████████▍| 85120/90000 [06:27<00:21, 227.41it/s] 95%|█████████▍| 85143/90000 [06:27<00:21, 222.79it/s] 95%|█████████▍| 85166/90000 [06:27<00:21, 224.56it/s] 95%|█████████▍| 85189/90000 [06:27<00:21, 224.70it/s] 95%|█████████▍| 85212/90000 [06:27<00:21, 225.48it/s] 95%|█████████▍| 85236/90000 [06:27<00:20, 228.59it/s] 95%|█████████▍| 85259/90000 [06:27<00:20, 226.59it/s] 95%|█████████▍| 85282/90000 [06:28<00:21, 223.83it/s] 95%|█████████▍| 85306/90000 [06:28<00:20, 226.24it/s] 95%|█████████▍| 85329/90000 [06:28<00:20, 225.03it/s] 95%|█████████▍| 85352/90000 [06:28<00:20, 223.46it/s] 95%|█████████▍| 85375/90000 [06:28<00:21, 219.62it/s] 95%|█████████▍| 85398/90000 [06:28<00:20, 221.60it/s] 95%|█████████▍| 85421/90000 [06:28<00:20, 221.62it/s] 95%|█████████▍| 85444/90000 [06:28<00:20, 221.60it/s] 95%|█████████▍| 85469/90000 [06:28<00:19, 228.37it/s] 95%|█████████▍| 85492/90000 [06:29<00:19, 228.02it/s] 95%|█████████▌| 85516/90000 [06:29<00:19, 231.19it/s] 95%|█████████▌| 85540/90000 [06:29<00:19, 232.17it/s] 95%|█████████▌| 85564/90000 [06:29<00:19, 229.78it/s] 95%|█████████▌| 85587/90000 [06:29<00:19, 229.30it/s] 95%|█████████▌| 85610/90000 [06:29<00:19, 227.17it/s] 95%|█████████▌| 85633/90000 [06:29<00:19, 227.26it/s] 95%|█████████▌| 85656/90000 [06:29<00:19, 227.50it/s] 95%|█████████▌| 85679/90000 [06:29<00:19, 224.46it/s] 95%|█████████▌| 85702/90000 [06:29<00:19, 225.66it/s] 95%|█████████▌| 85725/90000 [06:30<00:19, 222.81it/s] 95%|█████████▌| 85748/90000 [06:30<00:18, 224.91it/s] 95%|█████████▌| 85772/90000 [06:30<00:18, 227.36it/s] 95%|█████████▌| 85796/90000 [06:30<00:18, 229.72it/s] 95%|█████████▌| 85819/90000 [06:30<00:18, 229.36it/s] 95%|█████████▌| 85843/90000 [06:30<00:18, 229.71it/s] 95%|█████████▌| 85866/90000 [06:30<00:18, 224.83it/s] 95%|█████████▌| 85889/90000 [06:30<00:18, 225.03it/s] 95%|█████████▌| 85912/90000 [06:30<00:18, 223.58it/s] 95%|█████████▌| 85936/90000 [06:30<00:17, 225.99it/s] 96%|█████████▌| 85961/90000 [06:31<00:17, 231.63it/s] 96%|█████████▌| 85985/90000 [06:31<00:17, 226.48it/s] 96%|█████████▌| 86008/90000 [06:31<00:17, 223.30it/s] 96%|█████████▌| 86031/90000 [06:31<00:17, 221.49it/s] 96%|█████████▌| 86054/90000 [06:31<00:17, 222.60it/s] 96%|█████████▌| 86077/90000 [06:31<00:17, 223.59it/s] 96%|█████████▌| 86100/90000 [06:31<00:17, 221.47it/s] 96%|█████████▌| 86123/90000 [06:31<00:17, 221.57it/s] 96%|█████████▌| 86146/90000 [06:31<00:17, 223.90it/s] 96%|█████████▌| 86169/90000 [06:31<00:17, 224.84it/s] 96%|█████████▌| 86192/90000 [06:32<00:16, 224.32it/s] 96%|█████████▌| 86215/90000 [06:32<00:16, 222.95it/s] 96%|█████████▌| 86238/90000 [06:32<00:16, 223.59it/s] 96%|█████████▌| 86261/90000 [06:32<00:16, 224.82it/s] 96%|█████████▌| 86284/90000 [06:32<00:16, 223.04it/s] 96%|█████████▌| 86307/90000 [06:32<00:16, 222.33it/s] 96%|█████████▌| 86330/90000 [06:32<00:16, 223.50it/s] 96%|█████████▌| 86353/90000 [06:32<00:16, 222.57it/s] 96%|█████████▌| 86376/90000 [06:32<00:16, 224.11it/s] 96%|█████████▌| 86399/90000 [06:33<00:16, 224.21it/s] 96%|█████████▌| 86423/90000 [06:33<00:15, 227.94it/s] 96%|█████████▌| 86446/90000 [06:33<00:15, 226.60it/s] 96%|█████████▌| 86470/90000 [06:33<00:15, 228.14it/s] 96%|█████████▌| 86494/90000 [06:33<00:15, 228.66it/s] 96%|█████████▌| 86517/90000 [06:33<00:15, 221.60it/s] 96%|█████████▌| 86540/90000 [06:33<00:15, 223.27it/s] 96%|█████████▌| 86563/90000 [06:33<00:15, 224.34it/s] 96%|█████████▌| 86587/90000 [06:33<00:15, 226.79it/s] 96%|█████████▌| 86610/90000 [06:33<00:15, 225.08it/s] 96%|█████████▋| 86635/90000 [06:34<00:14, 230.42it/s] 96%|█████████▋| 86660/90000 [06:34<00:14, 233.51it/s] 96%|█████████▋| 86684/90000 [06:34<00:14, 234.30it/s] 96%|█████████▋| 86708/90000 [06:34<00:14, 231.22it/s] 96%|█████████▋| 86732/90000 [06:34<00:14, 229.24it/s] 96%|█████████▋| 86756/90000 [06:34<00:13, 231.84it/s] 96%|█████████▋| 86780/90000 [06:34<00:14, 224.81it/s] 96%|█████████▋| 86803/90000 [06:34<00:14, 225.97it/s] 96%|█████████▋| 86826/90000 [06:34<00:14, 225.49it/s] 96%|█████████▋| 86849/90000 [06:35<00:13, 226.61it/s] 97%|█████████▋| 86872/90000 [06:35<00:13, 227.56it/s] 97%|█████████▋| 86897/90000 [06:35<00:13, 231.47it/s] 97%|█████████▋| 86921/90000 [06:35<00:13, 226.00it/s] 97%|█████████▋| 86944/90000 [06:35<00:13, 227.03it/s] 97%|█████████▋| 86967/90000 [06:35<00:13, 225.61it/s] 97%|█████████▋| 86990/90000 [06:35<00:13, 224.73it/s] 97%|█████████▋| 87014/90000 [06:35<00:13, 228.80it/s] 97%|█████████▋| 87037/90000 [06:35<00:12, 228.27it/s] 97%|█████████▋| 87061/90000 [06:35<00:12, 229.51it/s] 97%|█████████▋| 87085/90000 [06:36<00:12, 230.96it/s] 97%|█████████▋| 87109/90000 [06:36<00:12, 225.49it/s] 97%|█████████▋| 87132/90000 [06:36<00:12, 224.67it/s] 97%|█████████▋| 87155/90000 [06:36<00:12, 225.82it/s] 97%|█████████▋| 87179/90000 [06:36<00:12, 226.18it/s] 97%|█████████▋| 87202/90000 [06:36<00:12, 223.85it/s] 97%|█████████▋| 87226/90000 [06:36<00:12, 227.36it/s] 97%|█████████▋| 87250/90000 [06:36<00:12, 228.30it/s] 97%|█████████▋| 87273/90000 [06:36<00:11, 228.16it/s] 97%|█████████▋| 87296/90000 [06:36<00:12, 224.22it/s] 97%|█████████▋| 87321/90000 [06:37<00:11, 229.78it/s] 97%|█████████▋| 87344/90000 [06:37<00:11, 229.28it/s] 97%|█████████▋| 87368/90000 [06:37<00:11, 231.42it/s] 97%|█████████▋| 87392/90000 [06:37<00:11, 226.67it/s] 97%|█████████▋| 87415/90000 [06:37<00:11, 225.15it/s] 97%|█████████▋| 87438/90000 [06:37<00:11, 225.48it/s] 97%|█████████▋| 87461/90000 [06:37<00:11, 226.74it/s] 97%|█████████▋| 87484/90000 [06:37<00:11, 223.95it/s] 97%|█████████▋| 87507/90000 [06:37<00:11, 222.60it/s] 97%|█████████▋| 87530/90000 [06:38<00:11, 224.17it/s] 97%|█████████▋| 87553/90000 [06:38<00:11, 221.13it/s] 97%|█████████▋| 87577/90000 [06:38<00:10, 223.97it/s] 97%|█████████▋| 87601/90000 [06:38<00:10, 227.35it/s] 97%|█████████▋| 87626/90000 [06:38<00:10, 232.75it/s] 97%|█████████▋| 87650/90000 [06:38<00:10, 224.51it/s] 97%|█████████▋| 87674/90000 [06:38<00:10, 228.37it/s] 97%|█████████▋| 87697/90000 [06:38<00:10, 225.72it/s] 97%|█████████▋| 87721/90000 [06:38<00:09, 229.36it/s] 97%|█████████▋| 87744/90000 [06:38<00:09, 225.94it/s] 98%|█████████▊| 87767/90000 [06:39<00:10, 222.52it/s] 98%|█████████▊| 87790/90000 [06:39<00:09, 224.65it/s] 98%|█████████▊| 87813/90000 [06:39<00:09, 223.79it/s] 98%|█████████▊| 87836/90000 [06:39<00:09, 224.47it/s] 98%|█████████▊| 87859/90000 [06:39<00:09, 225.97it/s] 98%|█████████▊| 87882/90000 [06:39<00:09, 224.48it/s] 98%|█████████▊| 87905/90000 [06:39<00:09, 225.62it/s] 98%|█████████▊| 87929/90000 [06:39<00:09, 227.64it/s] 98%|█████████▊| 87954/90000 [06:39<00:08, 231.85it/s] 98%|█████████▊| 87978/90000 [06:39<00:08, 234.03it/s] 98%|█████████▊| 88002/90000 [06:40<00:08, 228.40it/s] 98%|█████████▊| 88026/90000 [06:40<00:08, 228.97it/s] 98%|█████████▊| 88049/90000 [06:40<00:08, 228.04it/s] 98%|█████████▊| 88072/90000 [06:40<00:08, 228.18it/s] 98%|█████████▊| 88097/90000 [06:40<00:08, 231.81it/s] 98%|█████████▊| 88121/90000 [06:40<00:08, 231.25it/s] 98%|█████████▊| 88146/90000 [06:40<00:07, 233.68it/s] 98%|█████████▊| 88170/90000 [06:40<00:07, 232.25it/s] 98%|█████████▊| 88194/90000 [06:40<00:07, 232.06it/s] 98%|█████████▊| 88218/90000 [06:41<00:07, 230.16it/s] 98%|█████████▊| 88242/90000 [06:41<00:07, 230.13it/s] 98%|█████████▊| 88266/90000 [06:41<00:07, 228.13it/s] 98%|█████████▊| 88289/90000 [06:41<00:07, 224.99it/s] 98%|█████████▊| 88312/90000 [06:41<00:07, 223.10it/s] 98%|█████████▊| 88335/90000 [06:41<00:07, 221.52it/s] 98%|█████████▊| 88358/90000 [06:41<00:07, 220.23it/s] 98%|█████████▊| 88381/90000 [06:41<00:07, 217.11it/s] 98%|█████████▊| 88404/90000 [06:41<00:07, 219.31it/s] 98%|█████████▊| 88427/90000 [06:41<00:07, 220.24it/s] 98%|█████████▊| 88450/90000 [06:42<00:07, 217.28it/s] 98%|█████████▊| 88473/90000 [06:42<00:06, 219.38it/s] 98%|█████████▊| 88495/90000 [06:42<00:06, 219.06it/s] 98%|█████████▊| 88518/90000 [06:42<00:06, 221.17it/s] 98%|█████████▊| 88541/90000 [06:42<00:06, 222.75it/s] 98%|█████████▊| 88564/90000 [06:42<00:06, 219.45it/s] 98%|█████████▊| 88588/90000 [06:42<00:06, 223.33it/s] 98%|█████████▊| 88611/90000 [06:42<00:06, 223.46it/s] 98%|█████████▊| 88634/90000 [06:42<00:06, 221.96it/s] 99%|█████████▊| 88657/90000 [06:43<00:06, 222.79it/s] 99%|█████████▊| 88680/90000 [06:43<00:05, 221.08it/s] 99%|█████████▊| 88703/90000 [06:43<00:05, 218.43it/s] 99%|█████████▊| 88726/90000 [06:43<00:05, 220.82it/s] 99%|█████████▊| 88749/90000 [06:43<00:05, 216.72it/s] 99%|█████████▊| 88771/90000 [06:43<00:05, 216.31it/s] 99%|█████████▊| 88793/90000 [06:43<00:05, 212.43it/s] 99%|█████████▊| 88816/90000 [06:43<00:05, 216.33it/s] 99%|█████████▊| 88839/90000 [06:43<00:05, 220.07it/s] 99%|█████████▊| 88862/90000 [06:43<00:05, 222.35it/s] 99%|█████████▉| 88886/90000 [06:44<00:04, 225.46it/s] 99%|█████████▉| 88910/90000 [06:44<00:04, 227.17it/s] 99%|█████████▉| 88933/90000 [06:44<00:04, 225.60it/s] 99%|█████████▉| 88956/90000 [06:44<00:04, 225.29it/s] 99%|█████████▉| 88979/90000 [06:44<00:04, 224.77it/s] 99%|█████████▉| 89002/90000 [06:44<00:04, 223.10it/s] 99%|█████████▉| 89025/90000 [06:44<00:04, 220.54it/s] 99%|█████████▉| 89048/90000 [06:44<00:04, 218.98it/s] 99%|█████████▉| 89071/90000 [06:44<00:04, 220.78it/s] 99%|█████████▉| 89094/90000 [06:44<00:04, 217.69it/s] 99%|█████████▉| 89116/90000 [06:45<00:04, 216.74it/s] 99%|█████████▉| 89139/90000 [06:45<00:03, 218.13it/s] 99%|█████████▉| 89161/90000 [06:45<00:03, 215.38it/s] 99%|█████████▉| 89183/90000 [06:45<00:03, 212.91it/s] 99%|█████████▉| 89205/90000 [06:45<00:03, 213.85it/s] 99%|█████████▉| 89227/90000 [06:45<00:03, 214.27it/s] 99%|█████████▉| 89249/90000 [06:45<00:03, 213.37it/s] 99%|█████████▉| 89271/90000 [06:45<00:03, 212.95it/s] 99%|█████████▉| 89294/90000 [06:45<00:03, 216.49it/s] 99%|█████████▉| 89318/90000 [06:46<00:03, 221.29it/s] 99%|█████████▉| 89341/90000 [06:46<00:03, 214.53it/s] 99%|█████████▉| 89363/90000 [06:46<00:02, 214.37it/s] 99%|█████████▉| 89385/90000 [06:46<00:02, 215.24it/s] 99%|█████████▉| 89407/90000 [06:46<00:02, 216.44it/s] 99%|█████████▉| 89430/90000 [06:46<00:02, 218.46it/s] 99%|█████████▉| 89454/90000 [06:46<00:02, 223.58it/s] 99%|█████████▉| 89477/90000 [06:46<00:02, 220.37it/s] 99%|█████████▉| 89501/90000 [06:46<00:02, 224.90it/s] 99%|█████████▉| 89524/90000 [06:46<00:02, 224.00it/s] 99%|█████████▉| 89547/90000 [06:47<00:02, 220.07it/s]100%|█████████▉| 89570/90000 [06:47<00:01, 216.82it/s]100%|█████████▉| 89592/90000 [06:47<00:01, 215.59it/s]100%|█████████▉| 89614/90000 [06:47<00:01, 214.68it/s]100%|█████████▉| 89636/90000 [06:47<00:01, 215.18it/s]100%|█████████▉| 89659/90000 [06:47<00:01, 217.23it/s]100%|█████████▉| 89681/90000 [06:47<00:01, 215.15it/s]100%|█████████▉| 89704/90000 [06:47<00:01, 218.63it/s]100%|█████████▉| 89726/90000 [06:47<00:01, 217.16it/s]100%|█████████▉| 89748/90000 [06:48<00:01, 217.87it/s]100%|█████████▉| 89770/90000 [06:48<00:01, 218.30it/s]100%|█████████▉| 89792/90000 [06:48<00:00, 214.67it/s]100%|█████████▉| 89814/90000 [06:48<00:00, 214.98it/s]100%|█████████▉| 89836/90000 [06:48<00:00, 215.36it/s]100%|█████████▉| 89859/90000 [06:48<00:00, 217.41it/s]100%|█████████▉| 89883/90000 [06:48<00:00, 223.65it/s]100%|█████████▉| 89906/90000 [06:48<00:00, 221.19it/s]100%|█████████▉| 89929/90000 [06:48<00:00, 221.40it/s]100%|█████████▉| 89952/90000 [06:48<00:00, 217.61it/s]100%|█████████▉| 89974/90000 [06:49<00:00, 214.53it/s]100%|█████████▉| 89996/90000 [06:49<00:00, 211.70it/s]100%|██████████| 90000/90000 [06:49<00:00, 219.95it/s]Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW170104_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW170104_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.1, mode='train', model_dir='models3/GW170104_sample_uniform_100basis_all_mixed_prior_a01/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=100)
Waveform directory data/GW170104_sample_prior_basis/
Model directory models3/GW170104_sample_uniform_100basis_all_mixed_prior_a01/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Learning rate: 0.0002

Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.6328	Cost: 24.94s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 22.1750	Cost: 6.21s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.5424	Cost: 6.12s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 21.4783	Cost: 6.03s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 21.2919	Cost: 5.86s
Train Epoch: 1 	Average Loss: 21.9264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3374

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 21.3745	Cost: 21.83s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 21.2304	Cost: 6.89s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 21.2395	Cost: 6.25s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 21.1531	Cost: 6.12s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 21.0367	Cost: 6.26s
Train Epoch: 2 	Average Loss: 21.1988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2080

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999998026079186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 21.1504	Cost: 25.44s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 21.0080	Cost: 6.24s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 21.0735	Cost: 6.25s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 21.0431	Cost: 6.01s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 21.0160	Cost: 5.85s
Train Epoch: 3 	Average Loss: 21.0830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1183

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019999995558678347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 21.1651	Cost: 23.83s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 21.0361	Cost: 7.10s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 21.0162	Cost: 6.31s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 20.9681	Cost: 6.08s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 20.8978	Cost: 5.89s
Train Epoch: 4 	Average Loss: 20.9963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9902

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.0001999999210431752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 20.9817	Cost: 27.32s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 20.8902	Cost: 6.12s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 20.8618	Cost: 6.11s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 20.8031	Cost: 5.94s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 20.7296	Cost: 5.85s
Train Epoch: 5 	Average Loss: 20.8863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9140

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019999987662997035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 20.8609	Cost: 25.40s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 20.7971	Cost: 6.19s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 20.8203	Cost: 6.17s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 20.7467	Cost: 5.99s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 20.7022	Cost: 5.87s
Train Epoch: 6 	Average Loss: 20.7769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7811

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019999982234717337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 20.7268	Cost: 26.45s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 20.6202	Cost: 6.21s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 20.6605	Cost: 6.16s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 20.6340	Cost: 6.07s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 20.5550	Cost: 5.85s
Train Epoch: 7 	Average Loss: 20.6618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7108

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 20.6089	Cost: 24.21s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 20.5549	Cost: 6.31s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 20.5188	Cost: 6.08s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 20.4959	Cost: 5.99s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 20.4193	Cost: 5.95s
Train Epoch: 8 	Average Loss: 20.5716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6171

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.0001999996841728254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 20.5463	Cost: 21.68s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 20.4593	Cost: 6.23s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 20.5027	Cost: 6.24s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 20.3899	Cost: 5.95s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 20.4699	Cost: 5.89s
Train Epoch: 9 	Average Loss: 20.4921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5579

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 20.5271	Cost: 23.44s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 20.4447	Cost: 6.13s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 20.4458	Cost: 6.11s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 20.4519	Cost: 5.95s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 20.3571	Cost: 5.87s
Train Epoch: 10 	Average Loss: 20.4473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5089

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019999950652018584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 20.3791	Cost: 23.14s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 20.3218	Cost: 6.15s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 20.2761	Cost: 6.23s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 20.4289	Cost: 5.95s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 20.2957	Cost: 5.89s
Train Epoch: 11 	Average Loss: 20.3699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4490

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019999940288952797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 20.4087	Cost: 25.11s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 20.3551	Cost: 6.19s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 20.2218	Cost: 6.58s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 20.3480	Cost: 5.98s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 20.2913	Cost: 6.56s
Train Epoch: 12 	Average Loss: 20.3119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3620

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019999928938932473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 20.2507	Cost: 21.23s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 20.3755	Cost: 6.09s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 20.2417	Cost: 6.08s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 20.1910	Cost: 5.93s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 20.1785	Cost: 5.88s
Train Epoch: 13 	Average Loss: 20.2388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2990

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.0001999991660195873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 20.1823	Cost: 23.46s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 20.1333	Cost: 6.01s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 20.1370	Cost: 6.02s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 20.1925	Cost: 5.95s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 20.0270	Cost: 6.02s
Train Epoch: 14 	Average Loss: 20.1427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1480

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 20.1762	Cost: 21.29s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 20.1060	Cost: 5.98s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 20.0514	Cost: 6.04s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 20.0665	Cost: 5.95s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 19.9451	Cost: 5.91s
Train Epoch: 15 	Average Loss: 20.0800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1646

Learning rate: 0.00019999888967155963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 20.1016	Cost: 22.10s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 19.9974	Cost: 5.94s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 19.9315	Cost: 6.22s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 20.0511	Cost: 5.96s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 19.9449	Cost: 5.91s
Train Epoch: 16 	Average Loss: 20.0089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0385

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001999987366932966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 19.9438	Cost: 20.72s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 19.9608	Cost: 6.02s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 19.9071	Cost: 6.09s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 19.8253	Cost: 5.97s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 19.8846	Cost: 5.88s
Train Epoch: 17 	Average Loss: 19.9290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9614

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019999857384555393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 19.9074	Cost: 19.75s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 19.7388	Cost: 6.00s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 19.7435	Cost: 6.05s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 19.9015	Cost: 5.98s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 19.8062	Cost: 6.00s
Train Epoch: 18 	Average Loss: 19.8316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9009

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.0001999984011283477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 19.7526	Cost: 19.42s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 19.8276	Cost: 6.10s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 19.6877	Cost: 6.66s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 19.6898	Cost: 5.91s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 19.7549	Cost: 5.88s
Train Epoch: 19 	Average Loss: 19.7617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8763

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019999821854169497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 19.6356	Cost: 19.77s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 19.6571	Cost: 6.12s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 19.7131	Cost: 6.45s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 19.6133	Cost: 5.88s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 19.7143	Cost: 5.80s
Train Epoch: 20 	Average Loss: 19.6846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7496

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 19.6579	Cost: 18.95s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 19.6003	Cost: 6.27s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 19.5810	Cost: 6.07s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 19.5916	Cost: 5.94s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 19.6373	Cost: 5.81s
Train Epoch: 21 	Average Loss: 19.6099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7643

Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 19.6450	Cost: 19.98s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 19.5685	Cost: 6.14s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 19.5458	Cost: 6.41s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 19.5344	Cost: 5.91s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 19.5384	Cost: 5.83s
Train Epoch: 22 	Average Loss: 19.5568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6468

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.00019999761156524272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 19.6121	Cost: 19.75s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 19.4629	Cost: 6.45s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 19.4580	Cost: 6.85s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 19.4263	Cost: 6.54s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 19.3932	Cost: 5.89s
Train Epoch: 23 	Average Loss: 19.4897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6214

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 19.4171	Cost: 19.28s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 19.4545	Cost: 6.08s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 19.3492	Cost: 6.08s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 19.3934	Cost: 5.87s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 19.3730	Cost: 5.78s
Train Epoch: 24 	Average Loss: 19.4304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4844

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.00019999715756739833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 19.3821	Cost: 20.37s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 19.4401	Cost: 5.96s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 19.4464	Cost: 6.39s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 19.3927	Cost: 5.87s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 19.3005	Cost: 5.83s
Train Epoch: 25 	Average Loss: 19.3780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4801

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.000199996915764479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 19.4303	Cost: 19.79s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 19.3410	Cost: 6.02s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 19.3799	Cost: 5.99s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 19.2783	Cost: 5.87s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 19.3374	Cost: 5.83s
Train Epoch: 26 	Average Loss: 19.3295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4606

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019999666409225975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 19.2991	Cost: 20.62s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 19.3125	Cost: 5.97s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 19.3211	Cost: 6.00s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 19.2150	Cost: 5.91s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 19.2927	Cost: 5.87s
Train Epoch: 27 	Average Loss: 19.2790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4041

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019999640255076543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 19.3226	Cost: 20.89s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 19.2595	Cost: 6.00s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 19.3385	Cost: 6.15s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 19.1745	Cost: 5.88s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 19.1983	Cost: 5.84s
Train Epoch: 28 	Average Loss: 19.2502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3633

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019999613114002186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 19.2166	Cost: 20.56s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 19.2299	Cost: 6.00s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 19.3276	Cost: 6.07s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 19.0795	Cost: 5.87s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 19.0741	Cost: 6.10s
Train Epoch: 29 	Average Loss: 19.2114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2979

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.0001999958498600558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 19.2566	Cost: 20.19s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 19.1708	Cost: 5.95s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 19.1398	Cost: 6.00s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 19.0625	Cost: 5.88s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 19.0414	Cost: 5.82s
Train Epoch: 30 	Average Loss: 19.1529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2882

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.000199995558710895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 19.1285	Cost: 19.46s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 19.0629	Cost: 6.56s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 19.1738	Cost: 5.99s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 19.0953	Cost: 5.92s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 19.0720	Cost: 6.05s
Train Epoch: 31 	Average Loss: 19.1075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1658

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 0.00019999525769256825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 19.1205	Cost: 20.34s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 19.0215	Cost: 6.01s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 19.0828	Cost: 6.14s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 18.9766	Cost: 5.92s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 18.9903	Cost: 5.97s
Train Epoch: 32 	Average Loss: 19.0526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1864

Learning rate: 0.00019999494680510518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 19.0268	Cost: 20.76s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 18.9956	Cost: 6.01s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 18.9763	Cost: 6.21s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 19.0746	Cost: 6.21s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 18.9363	Cost: 5.92s
Train Epoch: 33 	Average Loss: 19.0108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1677

Learning rate: 0.00019999462604853658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 18.9733	Cost: 21.04s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 19.0190	Cost: 6.01s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 18.9622	Cost: 6.12s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 18.8642	Cost: 5.92s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 19.0505	Cost: 5.91s
Train Epoch: 34 	Average Loss: 18.9790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1384

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019999429542289402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 18.9330	Cost: 21.03s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 18.9581	Cost: 5.99s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 19.0080	Cost: 6.00s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 18.8533	Cost: 5.93s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 18.9268	Cost: 5.97s
Train Epoch: 35 	Average Loss: 18.9210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0451

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.00019999395492821016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 18.9032	Cost: 20.10s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 18.9986	Cost: 6.02s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 18.8851	Cost: 6.06s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 18.8200	Cost: 5.95s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 18.8388	Cost: 6.13s
Train Epoch: 36 	Average Loss: 18.8869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0236

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.0001999936045645186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 18.9432	Cost: 19.58s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 18.9138	Cost: 6.08s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 18.7949	Cost: 6.06s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 18.9688	Cost: 5.94s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 18.8462	Cost: 5.99s
Train Epoch: 37 	Average Loss: 18.8651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9269

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.00019999324433185394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 18.8491	Cost: 19.88s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 18.7771	Cost: 6.05s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 18.7457	Cost: 6.02s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 18.7894	Cost: 5.91s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 18.9397	Cost: 5.97s
Train Epoch: 38 	Average Loss: 18.8070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9694

Learning rate: 0.0001999928742302517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 18.8733	Cost: 20.91s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 18.7328	Cost: 6.17s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 18.7581	Cost: 6.09s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 18.8292	Cost: 5.99s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 18.7569	Cost: 5.85s
Train Epoch: 39 	Average Loss: 18.7849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9154

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019999249425974844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 18.7722	Cost: 20.02s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 18.6677	Cost: 6.05s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 18.7805	Cost: 6.13s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 18.6527	Cost: 5.90s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 18.6813	Cost: 6.03s
Train Epoch: 40 	Average Loss: 18.7521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8709

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 18.7991	Cost: 20.48s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 18.6742	Cost: 6.04s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 18.8178	Cost: 6.07s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 18.7811	Cost: 5.90s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 18.6868	Cost: 6.03s
Train Epoch: 41 	Average Loss: 18.7184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8517

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019999170471218976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 18.6666	Cost: 20.53s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 18.6121	Cost: 6.03s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 18.6598	Cost: 6.08s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 18.6772	Cost: 5.89s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 18.6553	Cost: 6.10s
Train Epoch: 42 	Average Loss: 18.6673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8235

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.0001999912951352123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 18.7096	Cost: 20.41s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 18.6620	Cost: 6.06s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 18.5492	Cost: 6.34s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 18.6027	Cost: 6.06s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 18.7127	Cost: 6.21s
Train Epoch: 43 	Average Loss: 18.6474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7263

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.00019999087568948966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 18.6423	Cost: 20.62s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 18.5723	Cost: 6.09s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 18.5785	Cost: 6.08s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 18.6047	Cost: 5.89s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 18.4950	Cost: 6.08s
Train Epoch: 44 	Average Loss: 18.5995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7536

Learning rate: 0.0001999904463750632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 18.6978	Cost: 20.76s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 18.5739	Cost: 6.05s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 18.6380	Cost: 6.06s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 18.5368	Cost: 5.93s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 18.6295	Cost: 5.84s
Train Epoch: 45 	Average Loss: 18.5872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6911

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019999000719197536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 18.6043	Cost: 20.38s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 18.5630	Cost: 6.16s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 18.5188	Cost: 6.09s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 18.5261	Cost: 5.91s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 18.5036	Cost: 5.87s
Train Epoch: 46 	Average Loss: 18.5639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6600

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 0.00019998955814026943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 18.4744	Cost: 20.53s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 18.3906	Cost: 6.06s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 18.4582	Cost: 6.42s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 18.5804	Cost: 6.16s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 18.4229	Cost: 5.97s
Train Epoch: 47 	Average Loss: 18.5100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5895

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 0.00019998909921998973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 18.6142	Cost: 19.90s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 18.4729	Cost: 6.00s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 18.5365	Cost: 6.42s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 18.4287	Cost: 5.93s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 18.4100	Cost: 5.87s
Train Epoch: 48 	Average Loss: 18.4780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5702

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 0.0001999886304311816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 18.4530	Cost: 20.71s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 18.3844	Cost: 6.10s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 18.5008	Cost: 6.00s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 18.4643	Cost: 5.92s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 18.4239	Cost: 5.87s
Train Epoch: 49 	Average Loss: 18.4513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5972

Learning rate: 0.00019998815177389132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 18.4784	Cost: 20.72s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 18.3481	Cost: 6.54s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 18.3546	Cost: 6.13s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 18.4560	Cost: 5.92s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 18.3837	Cost: 5.87s
Train Epoch: 50 	Average Loss: 18.4172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5529

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 18.4655	Cost: 20.02s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 18.3536	Cost: 6.11s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 18.3773	Cost: 6.21s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 18.4511	Cost: 5.90s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 18.3886	Cost: 6.04s
Train Epoch: 51 	Average Loss: 18.3946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5245

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019998716485405404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 18.3368	Cost: 20.29s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 18.3173	Cost: 6.11s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 18.3546	Cost: 6.03s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 18.2741	Cost: 5.93s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 18.3737	Cost: 5.86s
Train Epoch: 52 	Average Loss: 18.3425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4775

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 0.0001999866565916045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 18.4206	Cost: 20.46s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 18.3542	Cost: 6.01s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 18.3650	Cost: 6.09s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 18.4398	Cost: 5.92s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 18.2636	Cost: 5.97s
Train Epoch: 53 	Average Loss: 18.3194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3965

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 0.0001999861384608676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 18.3692	Cost: 20.53s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 18.2904	Cost: 6.02s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 18.2575	Cost: 6.11s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 18.3294	Cost: 5.89s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 18.3453	Cost: 5.97s
Train Epoch: 54 	Average Loss: 18.3086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4370

Learning rate: 0.00019998561046189446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 18.3148	Cost: 20.56s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 18.2854	Cost: 6.06s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 18.2843	Cost: 6.13s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 18.2908	Cost: 5.91s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 18.1985	Cost: 5.87s
Train Epoch: 55 	Average Loss: 18.2675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3831

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.00019998507259473718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 18.2620	Cost: 20.70s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 18.2213	Cost: 6.01s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 18.2486	Cost: 6.02s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 18.2410	Cost: 5.91s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 18.2388	Cost: 5.86s
Train Epoch: 56 	Average Loss: 18.2272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3050

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019998452485944885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 18.1572	Cost: 20.91s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 18.1440	Cost: 5.94s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 18.2682	Cost: 6.00s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 18.1203	Cost: 5.88s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 18.1779	Cost: 6.12s
Train Epoch: 57 	Average Loss: 18.2115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3209

Learning rate: 0.00019998396725608354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 18.1510	Cost: 20.64s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 18.0676	Cost: 6.06s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 18.1854	Cost: 6.27s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 18.0458	Cost: 5.91s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 18.2558	Cost: 5.82s
Train Epoch: 58 	Average Loss: 18.1615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2445

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 18.0925	Cost: 20.00s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 18.1213	Cost: 5.98s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 18.1896	Cost: 6.00s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 17.9961	Cost: 5.90s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 18.0428	Cost: 5.98s
Train Epoch: 59 	Average Loss: 18.0916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2067

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 18.0946	Cost: 20.29s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 18.0716	Cost: 5.95s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 18.0521	Cost: 6.07s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 18.1065	Cost: 5.87s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 18.0340	Cost: 6.10s
Train Epoch: 60 	Average Loss: 18.0921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1809

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 18.0355	Cost: 19.76s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 18.0885	Cost: 5.95s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 18.0242	Cost: 6.06s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 18.0716	Cost: 6.04s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 17.9967	Cost: 6.20s
Train Epoch: 61 	Average Loss: 18.0384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1335

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 18.0619	Cost: 20.08s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 17.9009	Cost: 6.12s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 18.0271	Cost: 6.04s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 18.0157	Cost: 5.92s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 17.8773	Cost: 6.89s
Train Epoch: 62 	Average Loss: 18.0234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0848

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019998103122006246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 18.0341	Cost: 19.64s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 17.9190	Cost: 6.00s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 18.0737	Cost: 6.08s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 17.9427	Cost: 5.90s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 17.8820	Cost: 5.87s
Train Epoch: 63 	Average Loss: 17.9956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0678

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 0.00019998041440942506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 18.0150	Cost: 19.97s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 17.9733	Cost: 5.93s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 18.0424	Cost: 6.31s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 17.8939	Cost: 6.05s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 17.8028	Cost: 5.98s
Train Epoch: 64 	Average Loss: 17.9857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0767

Learning rate: 0.00019997978773111632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 17.8777	Cost: 20.89s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 17.8653	Cost: 6.21s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 18.0708	Cost: 6.00s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 17.9476	Cost: 5.93s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 17.8892	Cost: 5.86s
Train Epoch: 65 	Average Loss: 17.9324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0131

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 0.00019997915118519813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 17.8885	Cost: 20.04s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 17.7647	Cost: 6.04s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 17.9539	Cost: 6.06s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 17.8628	Cost: 5.94s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 17.8698	Cost: 5.87s
Train Epoch: 66 	Average Loss: 17.9073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0193

Learning rate: 0.0001999785047717333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 17.9403	Cost: 20.33s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 17.9203	Cost: 6.04s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 17.9607	Cost: 6.02s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 17.8532	Cost: 5.90s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 17.8162	Cost: 5.84s
Train Epoch: 67 	Average Loss: 17.8785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0550

Learning rate: 0.00019997784849078566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 17.7906	Cost: 20.39s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 17.8763	Cost: 6.11s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 17.8105	Cost: 6.54s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 17.8114	Cost: 5.87s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 17.8446	Cost: 6.04s
Train Epoch: 68 	Average Loss: 17.8363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9813

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 0.00019997718234242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 17.8418	Cost: 20.67s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 17.7690	Cost: 6.09s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 17.9641	Cost: 6.25s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 17.8607	Cost: 5.87s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 17.8856	Cost: 6.44s
Train Epoch: 69 	Average Loss: 17.8352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9328

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Learning rate: 0.00019997650632670199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 17.9448	Cost: 20.33s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 17.8170	Cost: 6.03s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 17.8761	Cost: 6.03s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 17.8536	Cost: 5.88s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 17.7017	Cost: 5.83s
Train Epoch: 70 	Average Loss: 17.8209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9680

Learning rate: 0.0001999758204436984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 17.8101	Cost: 20.50s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 17.6753	Cost: 6.05s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 17.7920	Cost: 6.69s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 17.8936	Cost: 5.86s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 17.7786	Cost: 5.86s
Train Epoch: 71 	Average Loss: 17.7900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9250

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00019997512469347695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 17.7644	Cost: 21.04s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 17.6464	Cost: 5.97s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 17.8575	Cost: 6.45s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 17.5953	Cost: 5.96s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 17.8677	Cost: 6.26s
Train Epoch: 72 	Average Loss: 17.7564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8765

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 0.00019997441907610624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 17.8806	Cost: 20.28s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 17.7340	Cost: 6.05s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 17.7840	Cost: 6.02s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 17.7415	Cost: 5.91s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 17.7668	Cost: 5.89s
Train Epoch: 73 	Average Loss: 17.7404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8867

Learning rate: 0.00019997370359165596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 17.6947	Cost: 21.33s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 17.7063	Cost: 6.09s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 17.7915	Cost: 6.11s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 17.7869	Cost: 5.87s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 17.6459	Cost: 6.02s
Train Epoch: 74 	Average Loss: 17.7241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8549

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.0001999729782401967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 17.7745	Cost: 21.22s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 17.8024	Cost: 6.06s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 17.7331	Cost: 6.07s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 17.6746	Cost: 5.92s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 17.6941	Cost: 6.07s
Train Epoch: 75 	Average Loss: 17.7109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8368

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 17.7081	Cost: 19.91s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 17.6475	Cost: 6.01s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 17.6499	Cost: 6.02s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 17.7674	Cost: 5.89s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 17.6544	Cost: 6.04s
Train Epoch: 76 	Average Loss: 17.6674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7691

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00019997149793653861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 17.6429	Cost: 20.26s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 17.5724	Cost: 5.98s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 17.7522	Cost: 6.05s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 17.5328	Cost: 5.91s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 17.7384	Cost: 6.05s
Train Epoch: 77 	Average Loss: 17.6501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8005

Learning rate: 0.00019997074298448586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 17.6059	Cost: 20.73s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 17.6133	Cost: 6.15s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 17.5618	Cost: 6.03s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 17.6128	Cost: 5.90s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 17.5443	Cost: 5.85s
Train Epoch: 78 	Average Loss: 17.6127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7850

Learning rate: 0.00019996997816571638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 17.5661	Cost: 20.41s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 17.5313	Cost: 6.07s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 17.7370	Cost: 6.04s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 17.4911	Cost: 6.11s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 17.6821	Cost: 5.95s
Train Epoch: 79 	Average Loss: 17.6429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7820

Learning rate: 0.00019996920348030559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 17.5987	Cost: 20.34s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 17.5180	Cost: 6.07s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 17.5895	Cost: 6.04s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 17.6362	Cost: 6.14s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 17.5430	Cost: 5.95s
Train Epoch: 80 	Average Loss: 17.6177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7680

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892832998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 17.5831	Cost: 19.99s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 17.5150	Cost: 5.98s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 17.6651	Cost: 6.13s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 17.4249	Cost: 5.93s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 17.6996	Cost: 6.01s
Train Epoch: 81 	Average Loss: 17.5843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6803

Saving model as e81_model.pt & e81_waveforms_supplementary.hdf5
Learning rate: 0.00019996762450986697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 17.7030	Cost: 20.09s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 17.5124	Cost: 6.06s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 17.5399	Cost: 6.26s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 17.5110	Cost: 5.88s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 17.4684	Cost: 6.00s
Train Epoch: 82 	Average Loss: 17.5662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6893

Learning rate: 0.00019996682022499498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 17.6485	Cost: 19.90s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 17.4571	Cost: 6.20s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 17.4966	Cost: 6.05s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 17.4246	Cost: 5.94s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 17.5719	Cost: 6.12s
Train Epoch: 83 	Average Loss: 17.5354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6542

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Learning rate: 0.0001999660060737934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 17.5889	Cost: 20.21s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 17.4946	Cost: 6.09s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 17.5455	Cost: 6.09s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 17.5830	Cost: 5.99s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 17.4529	Cost: 6.35s
Train Epoch: 84 	Average Loss: 17.5449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6800

Learning rate: 0.00019996518205634255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 17.4167	Cost: 19.34s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 17.5581	Cost: 6.15s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 17.5935	Cost: 6.06s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 17.6203	Cost: 5.90s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 17.5156	Cost: 5.94s
Train Epoch: 85 	Average Loss: 17.5342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6492

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Learning rate: 0.0001999643481727238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 17.5290	Cost: 20.09s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 17.4281	Cost: 6.04s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 17.4824	Cost: 6.03s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 17.5113	Cost: 5.90s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 17.4212	Cost: 5.85s
Train Epoch: 86 	Average Loss: 17.5010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6196

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 0.0001999635044230194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 17.5475	Cost: 20.82s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 17.4042	Cost: 6.03s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 17.4815	Cost: 6.49s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 17.4046	Cost: 5.88s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 17.5516	Cost: 6.00s
Train Epoch: 87 	Average Loss: 17.4886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6421

Learning rate: 0.00019996265080731267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 17.6619	Cost: 20.86s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 17.4756	Cost: 6.12s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 17.5416	Cost: 6.09s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 17.4633	Cost: 5.94s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 17.5021	Cost: 5.90s
Train Epoch: 88 	Average Loss: 17.4975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5818

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 0.00019996178732568782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 17.4049	Cost: 20.76s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 17.4834	Cost: 6.26s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 17.4217	Cost: 6.13s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 17.4771	Cost: 5.83s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 17.5586	Cost: 5.87s
Train Epoch: 89 	Average Loss: 17.4710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5952

Learning rate: 0.00019996091397823007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 17.5325	Cost: 20.84s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 17.4366	Cost: 6.05s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 17.4843	Cost: 6.47s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 17.2764	Cost: 5.89s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 17.4250	Cost: 6.04s
Train Epoch: 90 	Average Loss: 17.4481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5513

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 0.00019996003076502562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 17.3817	Cost: 20.22s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 17.3697	Cost: 5.98s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 17.3365	Cost: 5.94s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 17.5062	Cost: 5.97s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 17.4943	Cost: 5.85s
Train Epoch: 91 	Average Loss: 17.4183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5994

Learning rate: 0.0001999591376861617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 17.3948	Cost: 21.46s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 17.4441	Cost: 6.04s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 17.4529	Cost: 6.02s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 17.3019	Cost: 5.90s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 17.3161	Cost: 5.96s
Train Epoch: 92 	Average Loss: 17.4121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6100

Learning rate: 0.0001999582347417264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 17.4242	Cost: 21.77s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 17.2599	Cost: 6.08s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 17.4382	Cost: 6.08s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 17.3730	Cost: 5.90s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 17.3478	Cost: 5.89s
Train Epoch: 93 	Average Loss: 17.4104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5674

Learning rate: 0.00019995732193180883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 17.3505	Cost: 21.40s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 17.2009	Cost: 6.02s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 17.3958	Cost: 6.67s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 17.2831	Cost: 5.89s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 17.4052	Cost: 5.87s
Train Epoch: 94 	Average Loss: 17.3790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4905

Saving model as e94_model.pt & e94_waveforms_supplementary.hdf5
Learning rate: 0.00019995639925649909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 17.3904	Cost: 20.24s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 17.3152	Cost: 6.06s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 17.2671	Cost: 6.01s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 17.4017	Cost: 5.91s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 17.2488	Cost: 6.23s
Train Epoch: 95 	Average Loss: 17.3567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5239

Learning rate: 0.00019995546671588827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 17.4363	Cost: 20.12s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 17.3051	Cost: 6.11s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 17.3404	Cost: 6.33s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 17.2818	Cost: 5.91s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 17.3178	Cost: 5.84s
Train Epoch: 96 	Average Loss: 17.3389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4458

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Learning rate: 0.0001999545243100684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 17.3830	Cost: 20.40s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 17.2768	Cost: 6.05s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 17.3017	Cost: 6.01s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 17.3229	Cost: 5.96s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 17.4611	Cost: 5.96s
Train Epoch: 97 	Average Loss: 17.3260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4717

Learning rate: 0.00019995357203913245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 17.3158	Cost: 20.73s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 17.2576	Cost: 6.10s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 17.3781	Cost: 6.03s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 17.3463	Cost: 6.10s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 17.3500	Cost: 5.96s
Train Epoch: 98 	Average Loss: 17.3208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4504

Learning rate: 0.00019995260990317447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 17.2985	Cost: 20.40s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 17.2403	Cost: 6.30s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 17.3062	Cost: 6.51s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 17.2464	Cost: 5.88s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 17.3194	Cost: 5.89s
Train Epoch: 99 	Average Loss: 17.3048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4549

Learning rate: 0.00019995163790228936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 17.3330	Cost: 20.52s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 17.1426	Cost: 6.07s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 17.1908	Cost: 6.10s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 17.3539	Cost: 5.90s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 17.4452	Cost: 5.98s
Train Epoch: 100 	Average Loss: 17.2935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3820

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 0.0001999506560365731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 17.4428	Cost: 20.70s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 17.2454	Cost: 6.04s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 17.4080	Cost: 6.14s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 17.2262	Cost: 5.91s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 17.2948	Cost: 5.86s
Train Epoch: 101 	Average Loss: 17.2807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4108

Learning rate: 0.00019994966430612258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 17.3428	Cost: 20.70s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 17.3422	Cost: 6.00s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 17.1850	Cost: 6.19s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 17.2755	Cost: 5.86s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 17.1543	Cost: 5.84s
Train Epoch: 102 	Average Loss: 17.2561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4089

Learning rate: 0.00019994866271103568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 17.2687	Cost: 20.39s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 17.1653	Cost: 6.47s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 17.1922	Cost: 6.04s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 17.3555	Cost: 5.87s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 17.3390	Cost: 5.81s
Train Epoch: 103 	Average Loss: 17.2604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3740

Saving model as e103_model.pt & e103_waveforms_supplementary.hdf5
Learning rate: 0.0001999476512514112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 17.2667	Cost: 21.08s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 17.0943	Cost: 6.57s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 17.2034	Cost: 6.03s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 17.1827	Cost: 5.89s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 17.2266	Cost: 5.83s
Train Epoch: 104 	Average Loss: 17.2475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3588

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Learning rate: 0.00019994662992734905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 17.3685	Cost: 20.14s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 17.2655	Cost: 6.14s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 17.2538	Cost: 6.26s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 17.1898	Cost: 5.91s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 17.1829	Cost: 5.95s
Train Epoch: 105 	Average Loss: 17.2280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3997

Learning rate: 0.00019994559873894998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 17.1063	Cost: 20.55s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 17.2557	Cost: 6.03s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 17.3562	Cost: 6.00s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 17.2061	Cost: 5.96s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 17.2832	Cost: 5.84s
Train Epoch: 106 	Average Loss: 17.2234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2635

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 0.00019994455768631577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 17.2144	Cost: 20.21s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 17.2231	Cost: 6.36s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 17.2709	Cost: 6.30s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 17.1120	Cost: 5.90s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 17.1404	Cost: 5.85s
Train Epoch: 107 	Average Loss: 17.1989
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3579

Learning rate: 0.00019994350676954918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 17.2491	Cost: 21.41s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 17.1193	Cost: 6.21s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 17.2444	Cost: 6.03s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 17.2177	Cost: 5.87s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 17.2552	Cost: 6.10s
Train Epoch: 108 	Average Loss: 17.2049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3398

Learning rate: 0.00019994244598875392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 17.2662	Cost: 20.83s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 17.0292	Cost: 6.10s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 17.1837	Cost: 6.30s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 17.1563	Cost: 5.91s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 17.2347	Cost: 6.22s
Train Epoch: 109 	Average Loss: 17.1768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2777

Learning rate: 0.00019994137534403472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 17.2045	Cost: 21.14s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 17.1911	Cost: 6.03s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 17.1372	Cost: 6.66s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 17.1579	Cost: 6.01s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 17.0713	Cost: 5.84s
Train Epoch: 110 	Average Loss: 17.1671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3058

Learning rate: 0.00019994029483549723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 17.3367	Cost: 20.52s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 17.2626	Cost: 6.08s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 17.1905	Cost: 6.16s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 17.0762	Cost: 5.92s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 17.1971	Cost: 5.84s
Train Epoch: 111 	Average Loss: 17.1511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2712

Learning rate: 0.00019993920446324803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 17.2707	Cost: 20.80s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 17.1863	Cost: 6.09s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 17.1629	Cost: 6.13s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 17.0285	Cost: 5.92s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 17.1047	Cost: 5.86s
Train Epoch: 112 	Average Loss: 17.1483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2630

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Learning rate: 0.00019993810422739487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 17.2209	Cost: 20.42s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 16.9919	Cost: 6.06s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 17.2343	Cost: 6.33s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 17.0766	Cost: 5.90s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 17.1797	Cost: 6.06s
Train Epoch: 113 	Average Loss: 17.1361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2741

Learning rate: 0.00019993699412804622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 17.1075	Cost: 21.40s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 16.9804	Cost: 6.05s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 17.1075	Cost: 6.45s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 17.1941	Cost: 5.89s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 17.0576	Cost: 6.31s
Train Epoch: 114 	Average Loss: 17.1128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2748

Learning rate: 0.00019993587416531166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 17.2297	Cost: 20.99s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 16.9995	Cost: 6.07s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 17.2326	Cost: 6.16s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 17.1343	Cost: 5.89s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 17.1530	Cost: 6.28s
Train Epoch: 115 	Average Loss: 17.1253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2143

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Learning rate: 0.00019993474433930176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 17.1468	Cost: 20.51s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 17.1185	Cost: 5.92s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 17.1499	Cost: 6.01s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 17.1296	Cost: 5.93s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 17.0805	Cost: 6.00s
Train Epoch: 116 	Average Loss: 17.1050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2292

Learning rate: 0.000199933604650128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 17.1867	Cost: 20.27s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 16.9823	Cost: 6.03s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 17.0973	Cost: 6.04s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 17.2141	Cost: 5.89s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 17.0038	Cost: 5.89s
Train Epoch: 117 	Average Loss: 17.0931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2460

Learning rate: 0.0001999324550979029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 17.0201	Cost: 20.97s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 17.0174	Cost: 6.08s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 17.0956	Cost: 6.38s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 17.0556	Cost: 5.89s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 16.9630	Cost: 5.85s
Train Epoch: 118 	Average Loss: 17.0782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2795

Learning rate: 0.00019993129568273988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 17.1713	Cost: 20.34s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 17.1546	Cost: 6.11s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 17.0524	Cost: 6.17s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 17.0253	Cost: 5.90s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 17.1375	Cost: 6.40s
Train Epoch: 119 	Average Loss: 17.0906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2518

Learning rate: 0.0001999301264047534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 17.0872	Cost: 20.77s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 17.0592	Cost: 6.03s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 17.1644	Cost: 6.08s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 17.1820	Cost: 6.07s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 17.0800	Cost: 5.95s
Train Epoch: 120 	Average Loss: 17.0659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1980

Saving model as e120_model.pt & e120_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 17.2083	Cost: 20.30s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 16.9142	Cost: 5.91s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 16.9966	Cost: 6.07s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 17.0963	Cost: 5.91s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 16.9937	Cost: 6.03s
Train Epoch: 121 	Average Loss: 17.0490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1610

Saving model as e121_model.pt & e121_waveforms_supplementary.hdf5
Learning rate: 0.00019992775826077256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 17.0594	Cost: 20.08s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 16.8966	Cost: 5.94s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 16.9465	Cost: 5.99s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 16.9578	Cost: 5.99s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 16.9692	Cost: 5.97s
Train Epoch: 122 	Average Loss: 17.0148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1641

Learning rate: 0.00019992655939501196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 17.1238	Cost: 20.97s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 17.1660	Cost: 6.14s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 17.1139	Cost: 6.02s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 16.8149	Cost: 5.91s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 17.1253	Cost: 5.88s
Train Epoch: 123 	Average Loss: 17.0216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1758

Learning rate: 0.00019992535066689534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 17.1693	Cost: 19.69s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 16.9040	Cost: 6.09s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 17.0272	Cost: 6.01s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 17.0952	Cost: 5.92s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 16.9813	Cost: 5.84s
Train Epoch: 124 	Average Loss: 17.0053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1672

Learning rate: 0.00019992413207654198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 17.1620	Cost: 21.97s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 17.0844	Cost: 5.93s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 16.9145	Cost: 6.32s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 17.1202	Cost: 6.01s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 16.9973	Cost: 5.86s
Train Epoch: 125 	Average Loss: 17.0174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0998

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 16.9347	Cost: 20.63s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 17.0463	Cost: 6.01s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 16.8187	Cost: 6.04s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 16.9872	Cost: 5.91s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 16.9190	Cost: 5.78s
Train Epoch: 126 	Average Loss: 16.9940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1420

Learning rate: 0.0001999216653096072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 17.1200	Cost: 21.98s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 16.9259	Cost: 6.04s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 17.1025	Cost: 6.23s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 16.9681	Cost: 6.23s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 16.9563	Cost: 5.94s
Train Epoch: 127 	Average Loss: 16.9939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1389

Learning rate: 0.00019992041713326917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 17.0836	Cost: 19.50s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 16.9141	Cost: 6.04s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 17.0055	Cost: 6.84s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 16.9958	Cost: 5.86s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 16.9212	Cost: 5.79s
Train Epoch: 128 	Average Loss: 16.9778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1366

Learning rate: 0.00019991915909518135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 17.0185	Cost: 19.77s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 16.9347	Cost: 6.07s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 16.9941	Cost: 6.30s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 16.9281	Cost: 5.90s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 17.0492	Cost: 5.89s
Train Epoch: 129 	Average Loss: 16.9748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1286

Learning rate: 0.0001999178911954679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 16.9797	Cost: 20.08s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 16.8476	Cost: 6.12s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 17.0878	Cost: 6.26s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 16.9952	Cost: 5.89s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 16.9337	Cost: 5.88s
Train Epoch: 130 	Average Loss: 16.9587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0557

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 0.0001999166134342539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 17.0673	Cost: 21.60s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 16.7436	Cost: 6.03s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 17.0092	Cost: 6.21s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 17.0077	Cost: 5.92s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 17.0477	Cost: 5.83s
Train Epoch: 131 	Average Loss: 16.9496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1131

Learning rate: 0.00019991532581166554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 16.9722	Cost: 20.52s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 16.8493	Cost: 6.06s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 16.8889	Cost: 6.43s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 16.8737	Cost: 5.86s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 16.9979	Cost: 5.83s
Train Epoch: 132 	Average Loss: 16.9492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1172

Learning rate: 0.00019991402832782987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 16.9564	Cost: 21.46s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 16.9752	Cost: 6.05s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 16.9969	Cost: 6.01s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 16.9652	Cost: 5.90s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 16.9131	Cost: 5.84s
Train Epoch: 133 	Average Loss: 16.9435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0322

Saving model as e133_model.pt & e133_waveforms_supplementary.hdf5
Learning rate: 0.00019991272098287494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 16.7890	Cost: 20.45s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 16.8333	Cost: 6.11s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 16.9835	Cost: 6.22s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 16.9545	Cost: 5.92s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 16.9834	Cost: 5.95s
Train Epoch: 134 	Average Loss: 16.9404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0599

Learning rate: 0.00019991140377692977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 16.9123	Cost: 19.98s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 16.8774	Cost: 6.32s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 16.9433	Cost: 6.09s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 16.8821	Cost: 5.94s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 17.0358	Cost: 5.87s
Train Epoch: 135 	Average Loss: 16.9264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1276

Learning rate: 0.0001999100767101244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 16.9992	Cost: 21.64s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 16.8543	Cost: 6.05s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 16.9731	Cost: 6.34s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 16.9292	Cost: 5.90s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 16.8878	Cost: 5.96s
Train Epoch: 136 	Average Loss: 16.8968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0632

Learning rate: 0.00019990873978258976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 16.9402	Cost: 22.05s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 16.9080	Cost: 6.02s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 17.0095	Cost: 6.00s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 16.8855	Cost: 5.88s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 16.7898	Cost: 5.87s
Train Epoch: 137 	Average Loss: 16.9013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0700

Learning rate: 0.0001999073929944578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 16.9859	Cost: 22.30s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 16.8311	Cost: 6.00s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 16.8594	Cost: 6.13s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 16.8528	Cost: 6.11s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 16.6916	Cost: 5.80s
Train Epoch: 138 	Average Loss: 16.8899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9856

Saving model as e138_model.pt & e138_waveforms_supplementary.hdf5
Learning rate: 0.00019990603634586154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 16.9177	Cost: 20.95s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 16.8628	Cost: 6.09s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 16.8043	Cost: 6.07s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 16.8725	Cost: 5.87s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 16.8179	Cost: 5.92s
Train Epoch: 139 	Average Loss: 16.8944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0616

Learning rate: 0.00019990466983693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 16.7535	Cost: 20.56s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 16.8052	Cost: 5.99s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 16.8004	Cost: 6.27s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 16.9796	Cost: 6.51s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 17.0263	Cost: 5.88s
Train Epoch: 140 	Average Loss: 16.8588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0323

Learning rate: 0.00019990329346781236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 16.8513	Cost: 21.64s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 16.9017	Cost: 6.02s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 16.8842	Cost: 6.29s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 16.8203	Cost: 5.87s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 16.7538	Cost: 5.90s
Train Epoch: 141 	Average Loss: 16.8590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0195

Learning rate: 0.00019990190723863022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 16.9943	Cost: 21.04s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 16.8061	Cost: 5.99s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 16.8663	Cost: 6.34s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 16.8533	Cost: 5.86s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 16.7567	Cost: 5.87s
Train Epoch: 142 	Average Loss: 16.8504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9939

Learning rate: 0.00019990051114952508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 16.9709	Cost: 20.99s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 16.8039	Cost: 6.02s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 16.8101	Cost: 6.00s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 16.7584	Cost: 5.88s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 16.8128	Cost: 5.90s
Train Epoch: 143 	Average Loss: 16.8415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9864

Learning rate: 0.0001998991052006348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 16.8437	Cost: 21.63s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 16.8990	Cost: 5.99s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 16.8542	Cost: 6.50s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 16.7488	Cost: 5.89s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 16.7145	Cost: 6.08s
Train Epoch: 144 	Average Loss: 16.8079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9920

Learning rate: 0.0001998976893920981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 16.8033	Cost: 20.96s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 16.8794	Cost: 6.00s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 16.8479	Cost: 6.01s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 16.9171	Cost: 5.86s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 16.6456	Cost: 5.70s
Train Epoch: 145 	Average Loss: 16.8430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9902

Learning rate: 0.00019989626372405477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 16.7819	Cost: 21.98s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 16.8376	Cost: 5.95s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 16.8491	Cost: 6.03s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 16.7954	Cost: 6.14s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 16.8607	Cost: 5.88s
Train Epoch: 146 	Average Loss: 16.8170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0440

Learning rate: 0.00019989482819664545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 16.9292	Cost: 21.02s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 16.7299	Cost: 6.00s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 16.7603	Cost: 6.34s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 16.6735	Cost: 5.82s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 16.8307	Cost: 5.87s
Train Epoch: 147 	Average Loss: 16.8131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9107

Saving model as e147_model.pt & e147_waveforms_supplementary.hdf5
Learning rate: 0.00019989338281001189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 16.8995	Cost: 21.66s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 16.7717	Cost: 5.94s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 16.7763	Cost: 6.05s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 16.7407	Cost: 5.86s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 16.7608	Cost: 5.87s
Train Epoch: 148 	Average Loss: 16.7929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9920

Learning rate: 0.00019989192756429667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 16.8518	Cost: 21.07s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 16.9062	Cost: 5.97s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 16.6747	Cost: 6.45s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 16.8097	Cost: 5.88s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 16.7206	Cost: 6.06s
Train Epoch: 149 	Average Loss: 16.8023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0301

Learning rate: 0.00019989046245964345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 16.8224	Cost: 21.64s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 16.8373	Cost: 5.93s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 16.7253	Cost: 6.17s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 16.6662	Cost: 5.85s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 16.9183	Cost: 5.75s
Train Epoch: 150 	Average Loss: 16.7947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0185

Learning rate: 0.00019988898749619688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 16.8167	Cost: 21.30s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 16.7822	Cost: 6.05s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 16.7798	Cost: 6.21s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 16.7936	Cost: 6.00s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 16.6503	Cost: 5.83s
Train Epoch: 151 	Average Loss: 16.7722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9182

Learning rate: 0.00019988750267410245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 16.7318	Cost: 21.67s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 16.7149	Cost: 6.05s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 16.6461	Cost: 6.95s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 16.6648	Cost: 6.22s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 16.7792	Cost: 5.78s
Train Epoch: 152 	Average Loss: 16.7496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9076

Saving model as e152_model.pt & e152_waveforms_supplementary.hdf5
Learning rate: 0.0001998860079935067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 16.7924	Cost: 20.49s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 16.6633	Cost: 5.99s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 16.5713	Cost: 6.44s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 16.6540	Cost: 5.80s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 16.7889	Cost: 5.95s
Train Epoch: 153 	Average Loss: 16.7321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9374

Learning rate: 0.00019988450345455726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 16.8204	Cost: 21.52s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 16.7407	Cost: 5.89s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 16.7071	Cost: 6.73s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 16.6015	Cost: 5.77s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 16.6819	Cost: 5.82s
Train Epoch: 154 	Average Loss: 16.7474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9281

Learning rate: 0.00019988298905740252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 16.7763	Cost: 21.49s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 16.7137	Cost: 5.96s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 16.7104	Cost: 6.12s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 16.6367	Cost: 5.82s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 16.7383	Cost: 5.71s
Train Epoch: 155 	Average Loss: 16.7245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9229

Learning rate: 0.000199881464802192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 16.7974	Cost: 22.05s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 16.6256	Cost: 5.90s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 16.8488	Cost: 6.67s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 16.7760	Cost: 5.79s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 16.7273	Cost: 6.25s
Train Epoch: 156 	Average Loss: 16.7518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9023

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Learning rate: 0.0001998799306890761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 16.7406	Cost: 20.02s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 16.8302	Cost: 6.01s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 16.7565	Cost: 6.25s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 16.6667	Cost: 5.87s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 16.7142	Cost: 6.12s
Train Epoch: 157 	Average Loss: 16.6989
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9064

Learning rate: 0.00019987838671820622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 17.0271	Cost: 20.57s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 16.6295	Cost: 6.11s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 16.7243	Cost: 6.47s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 16.6205	Cost: 5.95s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 16.7740	Cost: 5.99s
Train Epoch: 158 	Average Loss: 16.7388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8576

Saving model as e158_model.pt & e158_waveforms_supplementary.hdf5
Learning rate: 0.00019987683288973478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 16.7570	Cost: 20.62s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 16.6433	Cost: 6.07s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 16.7244	Cost: 6.08s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 16.6949	Cost: 5.83s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 16.8617	Cost: 5.76s
Train Epoch: 159 	Average Loss: 16.6946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9511

Learning rate: 0.00019987526920381513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 16.6272	Cost: 21.52s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 16.5735	Cost: 5.99s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 16.8425	Cost: 6.63s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 16.5931	Cost: 5.80s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 16.6532	Cost: 6.10s
Train Epoch: 160 	Average Loss: 16.7008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9142

Learning rate: 0.00019987369566060162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 16.7609	Cost: 22.38s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 16.5467	Cost: 6.00s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 16.6385	Cost: 6.18s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 16.6383	Cost: 5.83s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 16.6314	Cost: 5.90s
Train Epoch: 161 	Average Loss: 16.6806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8586

Learning rate: 0.0001998721122602495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 16.6590	Cost: 19.21s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 16.6226	Cost: 6.02s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 16.7129	Cost: 5.98s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 16.5897	Cost: 5.85s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 16.6338	Cost: 5.75s
Train Epoch: 162 	Average Loss: 16.6901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8893

Learning rate: 0.00019987051900291508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 16.8257	Cost: 20.06s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 16.6924	Cost: 6.05s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 16.6220	Cost: 6.77s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 16.6335	Cost: 5.99s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 16.8251	Cost: 5.74s
Train Epoch: 163 	Average Loss: 16.6659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8473

Saving model as e163_model.pt & e163_waveforms_supplementary.hdf5
Learning rate: 0.00019986891588875562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 16.6331	Cost: 21.92s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 16.5521	Cost: 5.92s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 16.5896	Cost: 6.09s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 16.5448	Cost: 5.83s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 16.6041	Cost: 5.74s
Train Epoch: 164 	Average Loss: 16.6436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9077

Learning rate: 0.0001998673029179293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 16.6384	Cost: 20.49s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 16.6347	Cost: 6.00s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 16.8542	Cost: 6.00s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 16.7504	Cost: 5.86s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 16.6650	Cost: 5.78s
Train Epoch: 165 	Average Loss: 16.6805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8650

Learning rate: 0.00019986568009059536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 16.6419	Cost: 19.67s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 16.7372	Cost: 5.94s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 16.5057	Cost: 6.57s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 16.7115	Cost: 5.82s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 16.5632	Cost: 5.75s
Train Epoch: 166 	Average Loss: 16.6572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8591

Learning rate: 0.00019986404740691393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 16.7892	Cost: 21.65s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 16.6186	Cost: 5.92s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 16.6203	Cost: 6.35s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 16.7058	Cost: 5.81s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 16.6873	Cost: 5.72s
Train Epoch: 167 	Average Loss: 16.6566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8265

Saving model as e167_model.pt & e167_waveforms_supplementary.hdf5
Learning rate: 0.00019986240486704617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 16.8564	Cost: 19.87s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 16.5393	Cost: 6.02s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 16.6320	Cost: 6.02s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 16.5526	Cost: 5.86s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 16.6705	Cost: 5.92s
Train Epoch: 168 	Average Loss: 16.6704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8588

Learning rate: 0.00019986075247115415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 16.7844	Cost: 19.58s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 16.5224	Cost: 6.01s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 16.6593	Cost: 6.03s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 16.8441	Cost: 5.87s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 16.5856	Cost: 5.76s
Train Epoch: 169 	Average Loss: 16.6450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8545

Learning rate: 0.00019985909021940103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 16.8698	Cost: 20.51s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 16.5756	Cost: 6.01s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 16.6561	Cost: 6.00s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 16.6754	Cost: 5.84s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 16.5817	Cost: 5.75s
Train Epoch: 170 	Average Loss: 16.6445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8694

Learning rate: 0.0001998574181119508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 16.7285	Cost: 20.50s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 16.6950	Cost: 5.86s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 16.6282	Cost: 6.13s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 16.5892	Cost: 5.85s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 16.5718	Cost: 5.72s
Train Epoch: 171 	Average Loss: 16.6104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9296

Learning rate: 0.00019985573614896853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 16.6865	Cost: 19.45s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 16.7781	Cost: 5.98s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 16.6330	Cost: 6.54s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 16.6395	Cost: 5.83s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 16.5344	Cost: 5.97s
Train Epoch: 172 	Average Loss: 16.6014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8083

Saving model as e172_model.pt & e172_waveforms_supplementary.hdf5
Learning rate: 0.00019985404433062024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 16.5632	Cost: 21.25s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 16.6384	Cost: 6.08s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 16.5788	Cost: 6.16s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 16.5943	Cost: 5.86s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 16.5620	Cost: 5.75s
Train Epoch: 173 	Average Loss: 16.5885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7653

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 0.00019985234265707287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 16.7198	Cost: 21.60s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 16.6531	Cost: 5.92s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 16.5297	Cost: 6.30s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 16.5109	Cost: 5.87s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 16.6101	Cost: 5.94s
Train Epoch: 174 	Average Loss: 16.5846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8604

Learning rate: 0.00019985063112849436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 16.5236	Cost: 21.01s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 16.5612	Cost: 5.72s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 16.6033	Cost: 6.70s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 16.6086	Cost: 5.60s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 16.5982	Cost: 5.87s
Train Epoch: 175 	Average Loss: 16.5977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7962

Learning rate: 0.00019984890974505368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 16.6292	Cost: 21.82s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 16.5986	Cost: 5.94s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 16.6467	Cost: 6.38s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 16.4787	Cost: 5.84s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 16.5462	Cost: 5.83s
Train Epoch: 176 	Average Loss: 16.5743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7939

Learning rate: 0.00019984717850692066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 16.5664	Cost: 21.84s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 16.5142	Cost: 6.21s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 16.5287	Cost: 6.01s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 16.4465	Cost: 5.84s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 16.5774	Cost: 5.94s
Train Epoch: 177 	Average Loss: 16.5620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8131

Learning rate: 0.00019984543741426617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 16.7544	Cost: 22.31s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 16.4011	Cost: 5.91s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 16.5041	Cost: 7.45s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 16.5540	Cost: 5.80s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 16.4777	Cost: 5.87s
Train Epoch: 178 	Average Loss: 16.5709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7515

Saving model as e178_model.pt & e178_waveforms_supplementary.hdf5
Learning rate: 0.0001998436864672621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 16.5169	Cost: 20.55s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 16.5671	Cost: 6.28s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 16.5560	Cost: 6.50s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 16.5088	Cost: 5.83s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 16.5201	Cost: 6.00s
Train Epoch: 179 	Average Loss: 16.5478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8048

Learning rate: 0.00019984192566608125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 16.6177	Cost: 20.21s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 16.5100	Cost: 6.04s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 16.6049	Cost: 6.63s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 16.4559	Cost: 5.82s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 16.3850	Cost: 5.74s
Train Epoch: 180 	Average Loss: 16.5493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8515

Learning rate: 0.00019984015501089739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 16.5646	Cost: 21.96s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 16.5688	Cost: 6.71s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 16.5147	Cost: 7.10s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 16.4173	Cost: 6.60s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 16.5089	Cost: 6.54s
Train Epoch: 181 	Average Loss: 16.5259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8598

Learning rate: 0.00019983837450188524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 16.7186	Cost: 22.26s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 16.4769	Cost: 5.93s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 16.5533	Cost: 6.81s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 16.5102	Cost: 5.93s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 16.5040	Cost: 7.03s
Train Epoch: 182 	Average Loss: 16.5523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7357

Saving model as e182_model.pt & e182_waveforms_supplementary.hdf5
Learning rate: 0.0001998365841392206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 16.5847	Cost: 21.59s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 16.5841	Cost: 6.16s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 16.5409	Cost: 6.81s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 16.4775	Cost: 6.09s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 16.5606	Cost: 6.10s
Train Epoch: 183 	Average Loss: 16.5320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8205

Learning rate: 0.00019983478392308012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 16.6599	Cost: 22.68s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 16.4933	Cost: 6.78s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 16.3821	Cost: 6.26s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 16.5963	Cost: 5.86s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 16.4875	Cost: 5.82s
Train Epoch: 184 	Average Loss: 16.5245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8626

Learning rate: 0.0001998329738536415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 16.6241	Cost: 20.77s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 16.5315	Cost: 6.00s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 16.5222	Cost: 6.43s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 16.3724	Cost: 5.86s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 16.6703	Cost: 5.90s
Train Epoch: 185 	Average Loss: 16.5155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7825

Learning rate: 0.00019983115393108338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 16.5007	Cost: 22.99s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 16.5116	Cost: 5.95s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 16.4804	Cost: 6.09s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 16.4441	Cost: 5.84s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 16.4078	Cost: 5.73s
Train Epoch: 186 	Average Loss: 16.4798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7782

Learning rate: 0.0001998293241555854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 16.7064	Cost: 21.76s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 16.4303	Cost: 6.03s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 16.5032	Cost: 6.81s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 16.4910	Cost: 5.89s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 16.3863	Cost: 5.97s
Train Epoch: 187 	Average Loss: 16.5117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7293

Saving model as e187_model.pt & e187_waveforms_supplementary.hdf5
Learning rate: 0.0001998274845273281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 16.4387	Cost: 20.22s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 16.4649	Cost: 6.22s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 16.6137	Cost: 6.17s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 16.4569	Cost: 6.11s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 16.5057	Cost: 6.06s
Train Epoch: 188 	Average Loss: 16.4890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7103

Saving model as e188_model.pt & e188_waveforms_supplementary.hdf5
Learning rate: 0.00019982563504649309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 16.5323	Cost: 20.17s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 16.3738	Cost: 6.36s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 16.5290	Cost: 6.13s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 16.4499	Cost: 5.75s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 16.4489	Cost: 6.04s
Train Epoch: 189 	Average Loss: 16.4911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7333

Learning rate: 0.00019982377571326284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 16.5241	Cost: 20.12s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 16.5434	Cost: 6.14s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 16.4040	Cost: 6.53s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 16.3878	Cost: 5.94s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 16.5120	Cost: 5.86s
Train Epoch: 190 	Average Loss: 16.4867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7045

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 0.00019982190652782097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 16.5490	Cost: 20.14s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 16.3713	Cost: 6.18s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 16.4884	Cost: 6.70s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 16.3752	Cost: 5.94s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 16.5567	Cost: 5.78s
Train Epoch: 191 	Average Loss: 16.4651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7287

Learning rate: 0.0001998200274903519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 16.7092	Cost: 20.45s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 16.3745	Cost: 6.13s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 16.4468	Cost: 6.08s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 16.4936	Cost: 5.86s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 16.4840	Cost: 5.80s
Train Epoch: 192 	Average Loss: 16.4666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7200

Learning rate: 0.00019981813860104106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 16.5573	Cost: 20.14s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 16.4937	Cost: 6.63s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 16.4168	Cost: 6.12s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 16.4619	Cost: 5.88s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 16.4538	Cost: 5.80s
Train Epoch: 193 	Average Loss: 16.4471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7181

Learning rate: 0.0001998162398600749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 16.5572	Cost: 21.77s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 16.5285	Cost: 5.99s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 16.3805	Cost: 6.76s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 16.3483	Cost: 6.06s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 16.4008	Cost: 5.90s
Train Epoch: 194 	Average Loss: 16.4590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6932

Saving model as e194_model.pt & e194_waveforms_supplementary.hdf5
Learning rate: 0.00019981433126764085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 16.5245	Cost: 21.18s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 16.3255	Cost: 6.18s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 16.2792	Cost: 6.04s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 16.2916	Cost: 5.86s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 16.4004	Cost: 5.91s
Train Epoch: 195 	Average Loss: 16.4548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7235

Learning rate: 0.00019981241282392723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 16.5181	Cost: 21.55s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 16.3393	Cost: 5.99s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 16.3831	Cost: 6.65s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 16.4015	Cost: 5.90s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 16.4452	Cost: 5.89s
Train Epoch: 196 	Average Loss: 16.4248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6945

Learning rate: 0.0001998104845291234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 16.4256	Cost: 20.18s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 16.4793	Cost: 6.01s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 16.3660	Cost: 6.17s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 16.3203	Cost: 5.85s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 16.5046	Cost: 5.78s
Train Epoch: 197 	Average Loss: 16.4352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6715

Saving model as e197_model.pt & e197_waveforms_supplementary.hdf5
Learning rate: 0.00019980854638341968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 16.6718	Cost: 21.93s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 16.3902	Cost: 6.05s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 16.2321	Cost: 6.25s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 16.2775	Cost: 5.84s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 16.4635	Cost: 5.75s
Train Epoch: 198 	Average Loss: 16.4209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6844

Learning rate: 0.00019980659838700736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 16.4242	Cost: 20.48s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 16.4241	Cost: 6.30s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 16.2827	Cost: 6.31s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 16.5050	Cost: 5.87s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 16.4870	Cost: 5.79s
Train Epoch: 199 	Average Loss: 16.4074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7010

Learning rate: 0.0001998046405400787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 16.4434	Cost: 20.09s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 16.3652	Cost: 6.17s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 16.3142	Cost: 6.10s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 16.4855	Cost: 5.99s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 16.3672	Cost: 6.58s
Train Epoch: 200 	Average Loss: 16.4052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6794

Learning rate: 0.00019980267284282693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 16.3665	Cost: 19.65s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 16.2798	Cost: 6.03s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 16.2911	Cost: 6.03s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 16.3323	Cost: 5.84s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 16.2760	Cost: 5.72s
Train Epoch: 201 	Average Loss: 16.3707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7085

Learning rate: 0.00019980069529544622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 16.4750	Cost: 20.39s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 16.3503	Cost: 5.99s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 16.3815	Cost: 6.74s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 16.3811	Cost: 5.82s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 16.4035	Cost: 6.37s
Train Epoch: 202 	Average Loss: 16.3778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6559

Saving model as e202_model.pt & e202_waveforms_supplementary.hdf5
Learning rate: 0.0001997987078981318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 16.4998	Cost: 21.79s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 16.1758	Cost: 5.93s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 16.3929	Cost: 6.58s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 16.3730	Cost: 5.82s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 16.3204	Cost: 5.70s
Train Epoch: 203 	Average Loss: 16.3886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6790

Learning rate: 0.00019979671065107978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 16.5174	Cost: 22.06s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 16.3408	Cost: 6.18s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 16.4258	Cost: 7.58s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 16.2973	Cost: 6.05s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 16.3941	Cost: 6.01s
Train Epoch: 204 	Average Loss: 16.4036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6630

Learning rate: 0.0001997947035544873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 16.4560	Cost: 21.79s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 16.3241	Cost: 6.01s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 16.2862	Cost: 7.14s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 16.3204	Cost: 5.82s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 16.5513	Cost: 6.30s
Train Epoch: 205 	Average Loss: 16.3594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6158

Saving model as e205_model.pt & e205_waveforms_supplementary.hdf5
Learning rate: 0.00019979268660855247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 16.4745	Cost: 20.12s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 16.4005	Cost: 5.95s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 16.2451	Cost: 5.94s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 16.4172	Cost: 5.83s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 16.3283	Cost: 6.01s
Train Epoch: 206 	Average Loss: 16.3741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6429

Learning rate: 0.00019979065981347432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 16.3656	Cost: 21.93s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 16.2584	Cost: 5.97s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 16.3616	Cost: 6.73s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 16.0783	Cost: 5.80s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 16.2411	Cost: 6.22s
Train Epoch: 207 	Average Loss: 16.3401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6459

Learning rate: 0.0001997886231694529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 16.4462	Cost: 21.24s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 16.2975	Cost: 5.99s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 16.3485	Cost: 6.03s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 16.3129	Cost: 5.77s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 16.3904	Cost: 5.68s
Train Epoch: 208 	Average Loss: 16.3610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6234

Learning rate: 0.0001997865766766892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 16.3789	Cost: 20.67s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 16.4213	Cost: 5.95s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 16.4164	Cost: 6.03s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 16.3677	Cost: 5.82s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 16.3256	Cost: 5.74s
Train Epoch: 209 	Average Loss: 16.3539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6571

Learning rate: 0.00019978452033538524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 16.5323	Cost: 21.66s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 16.4155	Cost: 6.09s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 16.4105	Cost: 6.72s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 16.2105	Cost: 6.05s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 16.4048	Cost: 5.84s
Train Epoch: 210 	Average Loss: 16.3563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5808

Saving model as e210_model.pt & e210_waveforms_supplementary.hdf5
Learning rate: 0.00019978245414574395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 16.4805	Cost: 21.73s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 16.2961	Cost: 6.00s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 16.4172	Cost: 6.76s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 16.1631	Cost: 5.90s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 16.3715	Cost: 6.55s
Train Epoch: 211 	Average Loss: 16.3512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6391

Learning rate: 0.00019978037810796924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 16.4357	Cost: 21.26s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 16.2673	Cost: 6.16s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 16.3574	Cost: 6.13s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 16.1870	Cost: 5.84s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 16.2721	Cost: 5.69s
Train Epoch: 212 	Average Loss: 16.3263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6428

Learning rate: 0.000199778292222266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 16.4859	Cost: 22.32s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 16.2631	Cost: 5.99s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 16.3632	Cost: 6.54s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 16.2379	Cost: 5.78s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 16.3444	Cost: 6.04s
Train Epoch: 213 	Average Loss: 16.3420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5529

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Learning rate: 0.00019977619648884015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 16.4853	Cost: 21.83s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 16.1660	Cost: 5.89s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 16.3448	Cost: 6.42s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 16.1160	Cost: 5.79s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 16.3095	Cost: 5.90s
Train Epoch: 214 	Average Loss: 16.3060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5787

Learning rate: 0.0001997740909078985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 16.4442	Cost: 21.84s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 16.2374	Cost: 5.96s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 16.2125	Cost: 6.08s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 16.2396	Cost: 5.96s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 16.2527	Cost: 5.80s
Train Epoch: 215 	Average Loss: 16.3196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7306

Learning rate: 0.0001997719754796489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 16.5663	Cost: 21.13s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 16.3146	Cost: 5.93s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 16.3746	Cost: 6.28s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 16.2129	Cost: 5.83s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 16.2282	Cost: 5.70s
Train Epoch: 216 	Average Loss: 16.3050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6001

Learning rate: 0.00019976985020430003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 16.4307	Cost: 21.17s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 16.1335	Cost: 5.93s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 16.3312	Cost: 7.19s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 16.2343	Cost: 5.79s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 16.3387	Cost: 6.27s
Train Epoch: 217 	Average Loss: 16.2702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6001

Learning rate: 0.00019976771508206176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 16.5515	Cost: 20.91s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 16.1419	Cost: 6.07s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 16.4100	Cost: 6.51s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 16.2095	Cost: 5.88s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 16.3738	Cost: 5.75s
Train Epoch: 218 	Average Loss: 16.3270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5464

Saving model as e218_model.pt & e218_waveforms_supplementary.hdf5
Learning rate: 0.00019976557011314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 16.4282	Cost: 21.18s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 16.2739	Cost: 6.11s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 16.2674	Cost: 6.32s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 16.1700	Cost: 6.00s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 16.3400	Cost: 5.84s
Train Epoch: 219 	Average Loss: 16.2675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5453

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 0.00019976341529776072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 16.4984	Cost: 20.84s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 16.2159	Cost: 6.09s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 16.2538	Cost: 6.23s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 16.2268	Cost: 5.89s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 16.3277	Cost: 5.73s
Train Epoch: 220 	Average Loss: 16.2655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5863

Learning rate: 0.00019976125063612233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 16.3332	Cost: 22.09s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 16.2610	Cost: 6.55s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 16.3196	Cost: 6.13s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 16.3433	Cost: 5.92s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 16.1995	Cost: 5.85s
Train Epoch: 221 	Average Loss: 16.2711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6222

Learning rate: 0.00019975907612844327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 16.3561	Cost: 21.32s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 16.3070	Cost: 5.97s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 16.1700	Cost: 6.18s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 16.1767	Cost: 6.36s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 16.2180	Cost: 5.97s
Train Epoch: 222 	Average Loss: 16.2425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6248

Learning rate: 0.00019975689177493812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 16.3855	Cost: 21.30s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 16.2500	Cost: 6.05s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 16.2520	Cost: 6.92s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 16.3010	Cost: 5.87s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 16.1727	Cost: 6.42s
Train Epoch: 223 	Average Loss: 16.2658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6180

Learning rate: 0.00019975469757582245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 16.3540	Cost: 22.26s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 16.1704	Cost: 5.88s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 16.3257	Cost: 5.95s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 16.2041	Cost: 5.84s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 16.1746	Cost: 5.77s
Train Epoch: 224 	Average Loss: 16.2551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6110

Learning rate: 0.00019975249353131286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 16.5072	Cost: 21.32s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 16.2872	Cost: 5.95s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 16.3133	Cost: 6.33s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 16.2550	Cost: 5.78s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 16.3793	Cost: 6.37s
Train Epoch: 225 	Average Loss: 16.2759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5844

Learning rate: 0.00019975027964162683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 16.4780	Cost: 20.17s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 16.2642	Cost: 5.95s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 16.2146	Cost: 5.98s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 16.1445	Cost: 5.81s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 16.2443	Cost: 5.66s
Train Epoch: 226 	Average Loss: 16.2405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5446

Saving model as e226_model.pt & e226_waveforms_supplementary.hdf5
Learning rate: 0.0001997480559069829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 16.4468	Cost: 20.59s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 16.2430	Cost: 6.05s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 16.2711	Cost: 6.06s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 16.2815	Cost: 6.13s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 16.0038	Cost: 5.88s
Train Epoch: 227 	Average Loss: 16.2431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5519

Learning rate: 0.00019974582232760058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 16.4324	Cost: 21.11s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 16.2521	Cost: 6.30s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 16.1146	Cost: 6.64s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 16.2280	Cost: 5.87s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 16.0393	Cost: 5.92s
Train Epoch: 228 	Average Loss: 16.2236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6302

Learning rate: 0.0001997435789037002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 16.4647	Cost: 22.19s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 15.9392	Cost: 6.13s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 16.2910	Cost: 6.31s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 16.1488	Cost: 5.90s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 16.1861	Cost: 5.83s
Train Epoch: 229 	Average Loss: 16.2132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5520

Learning rate: 0.0001997413256355033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 16.4011	Cost: 20.27s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 16.0689	Cost: 6.01s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 16.3514	Cost: 6.00s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 16.2964	Cost: 5.82s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 16.1926	Cost: 5.75s
Train Epoch: 230 	Average Loss: 16.2288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5346

Saving model as e230_model.pt & e230_waveforms_supplementary.hdf5
Learning rate: 0.0001997390625232322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 16.3052	Cost: 21.55s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 15.9700	Cost: 6.18s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 16.3186	Cost: 6.13s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 16.2942	Cost: 5.95s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 16.3993	Cost: 6.03s
Train Epoch: 231 	Average Loss: 16.2283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6266

Learning rate: 0.00019973678956711026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 16.3841	Cost: 20.90s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 16.1562	Cost: 6.05s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 16.2712	Cost: 6.00s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 16.1867	Cost: 5.84s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 16.1190	Cost: 5.71s
Train Epoch: 232 	Average Loss: 16.2245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6057

Learning rate: 0.00019973450676736185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 16.2649	Cost: 23.35s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 16.2603	Cost: 5.88s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 16.1048	Cost: 6.60s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 16.0410	Cost: 5.82s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 16.1204	Cost: 5.91s
Train Epoch: 233 	Average Loss: 16.2201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4360

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Learning rate: 0.00019973221412421225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 16.2404	Cost: 20.41s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 16.0854	Cost: 6.22s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 16.2134	Cost: 6.64s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 16.1570	Cost: 5.82s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 16.3958	Cost: 5.89s
Train Epoch: 234 	Average Loss: 16.1989
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5846

Learning rate: 0.0001997299116378877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 16.5291	Cost: 20.89s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 16.0794	Cost: 6.06s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 16.0436	Cost: 6.32s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 16.1920	Cost: 5.94s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 16.2593	Cost: 5.87s
Train Epoch: 235 	Average Loss: 16.1760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5481

Learning rate: 0.0001997275993086155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 16.3313	Cost: 21.44s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 16.1458	Cost: 6.32s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 16.1913	Cost: 6.10s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 16.0904	Cost: 6.07s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 16.2101	Cost: 5.86s
Train Epoch: 236 	Average Loss: 16.1728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5170

Learning rate: 0.0001997252771366239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 16.2696	Cost: 21.46s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 16.1217	Cost: 6.07s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 16.2459	Cost: 6.14s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 16.2203	Cost: 5.96s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 16.0548	Cost: 6.11s
Train Epoch: 237 	Average Loss: 16.1797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5486

Learning rate: 0.000199722945122142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 16.4022	Cost: 21.81s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 16.1092	Cost: 6.13s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 16.1226	Cost: 6.24s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 15.9813	Cost: 6.04s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 16.0454	Cost: 5.93s
Train Epoch: 238 	Average Loss: 16.1709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4868

Learning rate: 0.0001997206032654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 16.2438	Cost: 21.65s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 16.0233	Cost: 5.99s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 16.1228	Cost: 5.99s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 15.9813	Cost: 5.80s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 16.1369	Cost: 5.89s
Train Epoch: 239 	Average Loss: 16.1653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5200

Learning rate: 0.00019971825156662903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 16.4139	Cost: 21.50s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 16.0974	Cost: 5.94s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 16.1840	Cost: 6.09s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 15.9547	Cost: 5.79s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 16.0520	Cost: 5.77s
Train Epoch: 240 	Average Loss: 16.1498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5007

Learning rate: 0.00019971589002606117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 16.3651	Cost: 21.28s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 16.1823	Cost: 5.98s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 16.0455	Cost: 6.54s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 16.0642	Cost: 5.59s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 16.2379	Cost: 5.54s
Train Epoch: 241 	Average Loss: 16.1349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4972

Learning rate: 0.00019971351864392958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 16.3565	Cost: 20.94s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 16.1142	Cost: 5.93s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 16.0830	Cost: 5.96s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 15.9389	Cost: 5.80s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 15.9785	Cost: 5.66s
Train Epoch: 242 	Average Loss: 16.1648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5763

Learning rate: 0.00019971113742046817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 16.3485	Cost: 21.32s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 16.0028	Cost: 6.01s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 16.1297	Cost: 6.43s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 16.2051	Cost: 5.92s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 16.0743	Cost: 5.83s
Train Epoch: 243 	Average Loss: 16.1608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4971

Learning rate: 0.00019970874635591207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 16.4187	Cost: 19.47s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 15.9540	Cost: 5.93s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 15.9577	Cost: 5.97s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 16.0572	Cost: 5.80s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 16.0803	Cost: 5.71s
Train Epoch: 244 	Average Loss: 16.1015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4877

Learning rate: 0.00019970634545049727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 16.2979	Cost: 22.06s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 15.9052	Cost: 6.08s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 15.9229	Cost: 6.68s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 16.0060	Cost: 5.90s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 16.0705	Cost: 6.72s
Train Epoch: 245 	Average Loss: 16.1168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4631

Learning rate: 0.0001997039347044607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 16.3171	Cost: 20.72s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 15.9874	Cost: 6.02s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 16.0532	Cost: 6.12s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 16.0588	Cost: 5.84s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 16.0778	Cost: 5.93s
Train Epoch: 246 	Average Loss: 16.1275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5245

Learning rate: 0.00019970151411804023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 16.4738	Cost: 21.84s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 16.0907	Cost: 5.94s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 16.2102	Cost: 6.47s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 15.9594	Cost: 6.04s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 16.1352	Cost: 7.30s
Train Epoch: 247 	Average Loss: 16.1314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4544

Learning rate: 0.00019969908369147485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 16.4484	Cost: 19.90s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 16.1355	Cost: 6.06s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 16.1088	Cost: 6.06s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 16.1466	Cost: 5.85s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 15.9744	Cost: 5.71s
Train Epoch: 248 	Average Loss: 16.1316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4677

Learning rate: 0.00019969664342500438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 16.2759	Cost: 20.22s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 16.1598	Cost: 6.00s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 16.1168	Cost: 6.77s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 15.9337	Cost: 5.82s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 16.0059	Cost: 5.82s
Train Epoch: 249 	Average Loss: 16.0913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4715

Learning rate: 0.00019969419331886966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 16.2152	Cost: 22.25s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 16.0225	Cost: 5.95s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 16.1085	Cost: 6.86s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 16.1152	Cost: 5.88s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 15.9846	Cost: 6.15s
Train Epoch: 250 	Average Loss: 16.0978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4822

Learning rate: 0.0001996917333733126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 16.4257	Cost: 21.68s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 16.0538	Cost: 6.41s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 15.9714	Cost: 6.12s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 15.9942	Cost: 6.46s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 15.9945	Cost: 5.76s
Train Epoch: 251 	Average Loss: 16.1100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5157

Learning rate: 0.00019968926358857587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 16.3572	Cost: 21.74s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 16.0985	Cost: 5.99s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 16.1045	Cost: 6.10s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 16.0847	Cost: 5.93s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 16.0075	Cost: 5.90s
Train Epoch: 252 	Average Loss: 16.1324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4340

Saving model as e252_model.pt & e252_waveforms_supplementary.hdf5
Learning rate: 0.00019968678396490325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 16.3544	Cost: 20.29s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 16.0393	Cost: 6.02s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 16.1964	Cost: 6.01s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 16.2340	Cost: 6.75s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 16.0357	Cost: 6.84s
Train Epoch: 253 	Average Loss: 16.0855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4586

Learning rate: 0.00019968429450253954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 16.3320	Cost: 21.21s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 16.0785	Cost: 6.03s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 16.1583	Cost: 6.99s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 16.1078	Cost: 5.83s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 15.9371	Cost: 6.31s
Train Epoch: 254 	Average Loss: 16.0773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5357

Learning rate: 0.0001996817952017304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 16.4612	Cost: 21.17s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 16.0300	Cost: 6.04s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 16.0519	Cost: 6.19s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 15.9012	Cost: 5.86s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 16.1387	Cost: 5.82s
Train Epoch: 255 	Average Loss: 16.0906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5182

Learning rate: 0.00019967928606272244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 16.5486	Cost: 21.75s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 16.1207	Cost: 6.08s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 16.0185	Cost: 6.31s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 16.0249	Cost: 5.93s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 16.1149	Cost: 6.21s
Train Epoch: 256 	Average Loss: 16.0605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5385

Learning rate: 0.0001996767670857634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 16.3649	Cost: 21.68s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 15.9550	Cost: 6.00s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 16.0588	Cost: 6.61s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 16.1048	Cost: 5.80s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 16.2017	Cost: 5.74s
Train Epoch: 257 	Average Loss: 16.0762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5532

Learning rate: 0.00019967423827110182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 16.3117	Cost: 20.64s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 15.9645	Cost: 6.11s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 16.0074	Cost: 6.07s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 16.0533	Cost: 5.88s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 15.9495	Cost: 6.10s
Train Epoch: 258 	Average Loss: 16.0420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4411

Learning rate: 0.00019967169961898734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 16.3419	Cost: 21.81s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 16.0877	Cost: 6.01s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 16.0717	Cost: 6.94s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 15.9534	Cost: 5.78s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 15.9481	Cost: 6.92s
Train Epoch: 259 	Average Loss: 16.0677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4382

Learning rate: 0.00019966915112967047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 16.3269	Cost: 23.24s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 15.9078	Cost: 5.93s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 16.1383	Cost: 6.28s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 15.8251	Cost: 5.87s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 15.8641	Cost: 5.94s
Train Epoch: 260 	Average Loss: 16.0412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4778

Learning rate: 0.00019966659280340273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 16.3273	Cost: 22.22s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 16.0501	Cost: 5.92s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 15.9868	Cost: 6.37s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 16.0185	Cost: 5.89s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 15.9246	Cost: 5.88s
Train Epoch: 261 	Average Loss: 16.0545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4475

Learning rate: 0.00019966402464043667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 16.3917	Cost: 20.78s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 15.8232	Cost: 6.10s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 15.9714	Cost: 6.85s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 15.9824	Cost: 5.93s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 16.0035	Cost: 5.76s
Train Epoch: 262 	Average Loss: 16.0327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4040

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 0.00019966144664102572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 16.1456	Cost: 21.53s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 15.9318	Cost: 5.94s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 16.1344	Cost: 6.31s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 16.0089	Cost: 5.91s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 15.9621	Cost: 6.23s
Train Epoch: 263 	Average Loss: 16.0177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4610

Learning rate: 0.00019965885880542434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 16.3087	Cost: 19.98s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 16.0307	Cost: 5.98s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 16.0879	Cost: 7.61s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 15.9660	Cost: 6.22s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 15.8857	Cost: 5.75s
Train Epoch: 264 	Average Loss: 16.0141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3589

Saving model as e264_model.pt & e264_waveforms_supplementary.hdf5
Learning rate: 0.00019965626113388794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 16.3276	Cost: 22.51s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 16.0896	Cost: 5.85s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 15.9265	Cost: 5.95s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 15.9437	Cost: 5.81s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 16.0454	Cost: 5.81s
Train Epoch: 265 	Average Loss: 16.0181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4219

Learning rate: 0.00019965365362667288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 16.5390	Cost: 21.61s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 15.9942	Cost: 5.89s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 16.0471	Cost: 7.33s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 15.9042	Cost: 5.76s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 16.0422	Cost: 6.20s
Train Epoch: 266 	Average Loss: 16.0087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3522

Saving model as e266_model.pt & e266_waveforms_supplementary.hdf5
Learning rate: 0.0001996510362840365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 16.3396	Cost: 20.39s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 15.9260	Cost: 6.06s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 15.8426	Cost: 5.97s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 15.8326	Cost: 5.96s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 15.9309	Cost: 5.91s
Train Epoch: 267 	Average Loss: 15.9920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4169

Learning rate: 0.00019964840910623716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 16.3814	Cost: 21.24s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 16.0134	Cost: 6.50s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 15.9333	Cost: 6.01s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 15.9381	Cost: 5.80s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 15.8883	Cost: 5.89s
Train Epoch: 268 	Average Loss: 15.9958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4586

Learning rate: 0.00019964577209353413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 16.2898	Cost: 21.39s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 15.8240	Cost: 6.06s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 16.1022	Cost: 6.10s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 15.8908	Cost: 5.82s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 15.9890	Cost: 6.11s
Train Epoch: 269 	Average Loss: 15.9991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4332

Learning rate: 0.00019964312524618766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 16.1833	Cost: 21.18s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 15.9444	Cost: 5.92s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 15.8767	Cost: 7.20s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 15.9856	Cost: 5.72s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 15.9102	Cost: 5.78s
Train Epoch: 270 	Average Loss: 15.9843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4097

Learning rate: 0.000199640468564459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 16.3165	Cost: 21.84s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 15.9569	Cost: 5.91s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 15.9219	Cost: 6.69s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 15.9769	Cost: 6.31s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 15.9730	Cost: 5.76s
Train Epoch: 271 	Average Loss: 15.9803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4862

Learning rate: 0.00019963780204861037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 16.3739	Cost: 20.60s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 15.9177	Cost: 5.94s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 16.0366	Cost: 5.98s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 15.9595	Cost: 5.81s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 15.9403	Cost: 5.75s
Train Epoch: 272 	Average Loss: 15.9980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4457

Learning rate: 0.0001996351256989049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 15.9189	Cost: 21.00s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 15.9587	Cost: 6.00s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 16.1376	Cost: 6.03s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 15.9832	Cost: 6.25s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 15.9479	Cost: 5.69s
Train Epoch: 273 	Average Loss: 15.9805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3431

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 0.0001996324395156068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 16.3345	Cost: 21.37s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 16.0791	Cost: 5.95s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 16.0327	Cost: 6.24s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 15.9969	Cost: 5.83s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 15.8345	Cost: 6.18s
Train Epoch: 274 	Average Loss: 15.9725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3949

Learning rate: 0.00019962974349898107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 16.2451	Cost: 20.67s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 15.9096	Cost: 6.30s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 15.8719	Cost: 7.83s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 16.1003	Cost: 5.72s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 15.8435	Cost: 5.91s
Train Epoch: 275 	Average Loss: 15.9411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4536

Learning rate: 0.0001996270376492939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 16.1708	Cost: 22.60s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 16.0301	Cost: 5.87s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 16.0586	Cost: 6.00s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 15.9622	Cost: 5.78s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 15.9261	Cost: 5.73s
Train Epoch: 276 	Average Loss: 15.9604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4230

Learning rate: 0.00019962432196681234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 16.2400	Cost: 21.38s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 15.8105	Cost: 5.93s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 16.0316	Cost: 7.05s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 15.7600	Cost: 5.76s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 16.1035	Cost: 5.92s
Train Epoch: 277 	Average Loss: 15.9365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4418

Learning rate: 0.00019962159645180437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 16.2352	Cost: 21.58s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 15.8287	Cost: 5.98s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 15.9633	Cost: 6.89s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 15.9826	Cost: 5.82s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 16.0122	Cost: 5.91s
Train Epoch: 278 	Average Loss: 15.9290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4665

Learning rate: 0.00019961886110453903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 16.2166	Cost: 21.55s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 15.6814	Cost: 5.94s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 15.9562	Cost: 6.62s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 15.6686	Cost: 6.07s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 15.8516	Cost: 5.87s
Train Epoch: 279 	Average Loss: 15.9326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3604

Learning rate: 0.00019961611592528625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 16.2129	Cost: 20.24s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 15.9038	Cost: 6.02s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 16.0677	Cost: 6.02s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 15.8751	Cost: 5.86s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 15.8615	Cost: 5.70s
Train Epoch: 280 	Average Loss: 15.9316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4209

Learning rate: 0.000199613360914317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 16.3323	Cost: 22.53s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 15.8717	Cost: 5.90s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 15.9508	Cost: 6.37s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 15.9099	Cost: 5.95s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 15.9085	Cost: 5.74s
Train Epoch: 281 	Average Loss: 15.9053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3896

Learning rate: 0.00019961059607190318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 16.2848	Cost: 21.50s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 15.7579	Cost: 5.91s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 16.0554	Cost: 6.64s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 15.7789	Cost: 5.81s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 15.9933	Cost: 5.81s
Train Epoch: 282 	Average Loss: 15.9228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3894

Learning rate: 0.00019960782139831766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 16.1831	Cost: 21.07s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 15.8084	Cost: 6.08s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 16.1356	Cost: 6.16s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 15.8063	Cost: 5.87s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 15.6216	Cost: 5.72s
Train Epoch: 283 	Average Loss: 15.9146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4258

Learning rate: 0.00019960503689383428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 16.4356	Cost: 22.26s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 15.9106	Cost: 5.97s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 15.9435	Cost: 6.09s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 15.8488	Cost: 5.71s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 15.8171	Cost: 6.02s
Train Epoch: 284 	Average Loss: 15.8950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3415

Saving model as e284_model.pt & e284_waveforms_supplementary.hdf5
Learning rate: 0.0001996022425587279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 16.1976	Cost: 21.89s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 15.7964	Cost: 5.99s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 16.0416	Cost: 6.64s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 15.7809	Cost: 5.85s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 15.6180	Cost: 6.58s
Train Epoch: 285 	Average Loss: 15.8917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4222

Learning rate: 0.0001995994383932743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 16.2267	Cost: 20.22s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 15.7237	Cost: 6.14s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 15.9398	Cost: 6.18s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 15.8939	Cost: 5.91s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 15.8921	Cost: 5.87s
Train Epoch: 286 	Average Loss: 15.8907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4369

Learning rate: 0.0001995966243977502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 16.2155	Cost: 21.39s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 15.8275	Cost: 6.01s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 15.9317	Cost: 6.55s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 15.9518	Cost: 5.90s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 15.9271	Cost: 6.12s
Train Epoch: 287 	Average Loss: 15.9010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3994

Learning rate: 0.0001995938005724334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 16.1873	Cost: 21.72s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 15.7484	Cost: 6.08s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 15.9149	Cost: 6.47s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 15.7428	Cost: 5.91s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 15.7140	Cost: 6.15s
Train Epoch: 288 	Average Loss: 15.8724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3609

Learning rate: 0.00019959096691760252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 16.3611	Cost: 21.46s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 15.8813	Cost: 6.18s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 15.9497	Cost: 6.40s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 15.8685	Cost: 5.96s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 15.7740	Cost: 6.22s
Train Epoch: 289 	Average Loss: 15.8822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3677

Learning rate: 0.00019958812343353726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 16.3332	Cost: 21.34s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 15.8648	Cost: 6.02s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 15.8887	Cost: 6.38s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 15.7822	Cost: 5.88s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 15.7903	Cost: 6.59s
Train Epoch: 290 	Average Loss: 15.8653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4321

Learning rate: 0.0001995852701205183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 16.1726	Cost: 22.33s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 15.9225	Cost: 6.02s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 15.8327	Cost: 6.20s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 15.8440	Cost: 5.92s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 15.8739	Cost: 5.99s
Train Epoch: 291 	Average Loss: 15.8737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3498

Learning rate: 0.0001995824069788272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 16.3756	Cost: 22.45s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 15.8051	Cost: 6.06s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 15.8201	Cost: 6.36s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 15.7668	Cost: 5.93s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 15.7507	Cost: 6.97s
Train Epoch: 292 	Average Loss: 15.8913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4135

Learning rate: 0.00019957953400874656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 16.3650	Cost: 21.30s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 15.7270	Cost: 6.02s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 15.9489	Cost: 6.05s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 15.8156	Cost: 5.97s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 15.8585	Cost: 6.01s
Train Epoch: 293 	Average Loss: 15.8517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4420

Learning rate: 0.00019957665121055995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 16.1942	Cost: 19.92s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 15.7936	Cost: 6.00s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 15.6944	Cost: 6.42s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 15.9248	Cost: 5.87s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 15.7732	Cost: 6.55s
Train Epoch: 294 	Average Loss: 15.8365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3466

Learning rate: 0.00019957375858455185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 16.0630	Cost: 21.38s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 15.7806	Cost: 5.96s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 15.9576	Cost: 6.48s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 15.9505	Cost: 5.89s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 15.7590	Cost: 6.57s
Train Epoch: 295 	Average Loss: 15.8470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4324

Learning rate: 0.00019957085613100776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 16.1223	Cost: 21.27s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 15.7830	Cost: 6.02s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 15.8232	Cost: 6.27s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 15.6964	Cost: 5.90s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 15.8378	Cost: 6.38s
Train Epoch: 296 	Average Loss: 15.8483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3238

Saving model as e296_model.pt & e296_waveforms_supplementary.hdf5
Learning rate: 0.00019956794385021415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 16.2138	Cost: 22.27s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 15.7898	Cost: 6.09s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 16.0683	Cost: 6.76s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 15.8615	Cost: 6.00s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 15.7704	Cost: 7.16s
Train Epoch: 297 	Average Loss: 15.8604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3848

Learning rate: 0.00019956502174245846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 16.1737	Cost: 20.45s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 15.7926	Cost: 6.20s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 15.8125	Cost: 6.29s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 15.8621	Cost: 6.04s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 15.6697	Cost: 6.73s
Train Epoch: 298 	Average Loss: 15.8342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4077

Learning rate: 0.0001995620898080291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 16.2024	Cost: 20.37s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 15.6843	Cost: 6.07s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 15.8355	Cost: 6.25s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 15.8866	Cost: 6.00s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 15.7590	Cost: 6.74s
Train Epoch: 299 	Average Loss: 15.8024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3686

Learning rate: 0.00019955914804721542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 16.3168	Cost: 21.03s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 15.5883	Cost: 6.10s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 15.6268	Cost: 6.18s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 15.7802	Cost: 6.09s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 15.6478	Cost: 6.04s
Train Epoch: 300 	Average Loss: 15.7975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3478

Learning rate: 0.00019955619646030775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 16.3786	Cost: 20.36s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 15.8158	Cost: 6.17s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 15.9292	Cost: 6.36s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 15.7200	Cost: 6.01s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 15.6918	Cost: 7.35s
Train Epoch: 301 	Average Loss: 15.8003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3731

Learning rate: 0.0001995532350475974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 16.1731	Cost: 20.41s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 15.6917	Cost: 6.14s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 15.8367	Cost: 6.16s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 15.7768	Cost: 6.11s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 15.9295	Cost: 6.90s
Train Epoch: 302 	Average Loss: 15.8045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4729

Learning rate: 0.00019955026380937669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 16.2679	Cost: 20.24s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 15.7450	Cost: 6.13s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 15.8030	Cost: 6.57s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 15.6156	Cost: 6.13s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 15.6249	Cost: 7.24s
Train Epoch: 303 	Average Loss: 15.7780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3513

Learning rate: 0.00019954728274593884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 16.1996	Cost: 20.22s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 15.6832	Cost: 5.98s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 15.7797	Cost: 6.27s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 15.5113	Cost: 6.08s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 15.7978	Cost: 7.58s
Train Epoch: 304 	Average Loss: 15.7882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3262

Learning rate: 0.00019954429185757805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 16.2183	Cost: 20.22s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 15.7460	Cost: 6.07s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 15.8577	Cost: 6.34s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 15.5155	Cost: 6.04s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 15.7013	Cost: 7.31s
Train Epoch: 305 	Average Loss: 15.7931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3502

Learning rate: 0.00019954129114458955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 16.2564	Cost: 20.64s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 15.8425	Cost: 6.13s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 15.7094	Cost: 6.05s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 15.7657	Cost: 6.21s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 15.5968	Cost: 7.11s
Train Epoch: 306 	Average Loss: 15.7653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3300

Learning rate: 0.00019953828060726943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 16.1342	Cost: 20.75s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 15.8006	Cost: 6.11s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 15.7608	Cost: 6.45s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 15.5829	Cost: 6.11s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 15.6540	Cost: 7.33s
Train Epoch: 307 	Average Loss: 15.7484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3734

Learning rate: 0.00019953526024591494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 16.1484	Cost: 20.00s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 15.7073	Cost: 6.02s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 15.8530	Cost: 6.44s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 15.7227	Cost: 6.01s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 15.6903	Cost: 7.64s
Train Epoch: 308 	Average Loss: 15.7464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3827

Learning rate: 0.00019953223006082406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 16.2044	Cost: 20.61s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 15.7965	Cost: 6.09s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 15.7744	Cost: 6.07s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 15.8551	Cost: 6.10s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 15.5667	Cost: 6.55s
Train Epoch: 309 	Average Loss: 15.7502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3186

Saving model as e309_model.pt & e309_waveforms_supplementary.hdf5
Learning rate: 0.00019952919005229592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 16.1605	Cost: 20.70s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 15.7166	Cost: 6.06s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 15.7074	Cost: 6.66s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 15.6936	Cost: 6.13s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 15.6787	Cost: 8.09s
Train Epoch: 310 	Average Loss: 15.7396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4520

Learning rate: 0.00019952614022063054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 16.0987	Cost: 21.03s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 15.6470	Cost: 6.05s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 15.8209	Cost: 6.61s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 15.7578	Cost: 6.05s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 15.6856	Cost: 7.43s
Train Epoch: 311 	Average Loss: 15.7535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3017

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Learning rate: 0.00019952308056612892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 16.2098	Cost: 19.37s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 15.6989	Cost: 6.10s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 15.8303	Cost: 6.10s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 15.7144	Cost: 6.07s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 15.6249	Cost: 6.35s
Train Epoch: 312 	Average Loss: 15.7514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3647

Learning rate: 0.00019952001108909304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 16.5547	Cost: 20.41s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 15.6808	Cost: 6.08s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 15.5963	Cost: 6.17s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 15.7131	Cost: 6.08s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 15.5159	Cost: 7.31s
Train Epoch: 313 	Average Loss: 15.7434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2986

Saving model as e313_model.pt & e313_waveforms_supplementary.hdf5
Learning rate: 0.00019951693178982586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 16.3285	Cost: 20.43s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 15.6643	Cost: 6.08s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 15.6261	Cost: 6.13s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 15.5104	Cost: 5.99s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 15.6593	Cost: 7.03s
Train Epoch: 314 	Average Loss: 15.7232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3055

Learning rate: 0.00019951384266863126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 16.0143	Cost: 21.74s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 15.5830	Cost: 6.12s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 15.6131	Cost: 6.37s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 15.7028	Cost: 5.95s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 15.5742	Cost: 6.93s
Train Epoch: 315 	Average Loss: 15.7412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3034

Learning rate: 0.00019951074372581416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 16.2030	Cost: 20.32s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 15.7336	Cost: 6.08s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 15.8218	Cost: 6.42s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 15.7153	Cost: 6.31s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 15.6982	Cost: 7.12s
Train Epoch: 316 	Average Loss: 15.7546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3857

Learning rate: 0.00019950763496168037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 16.2043	Cost: 20.44s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 15.5413	Cost: 6.00s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 15.6439	Cost: 6.83s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 15.7064	Cost: 6.12s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 15.5837	Cost: 7.16s
Train Epoch: 317 	Average Loss: 15.7204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3501

Learning rate: 0.00019950451637653678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 16.2578	Cost: 20.62s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 15.7943	Cost: 6.00s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 15.7444	Cost: 6.56s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 15.6549	Cost: 5.93s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 15.5303	Cost: 6.41s
Train Epoch: 318 	Average Loss: 15.7374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3339

Learning rate: 0.00019950138797069118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 16.2642	Cost: 21.34s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 15.6025	Cost: 6.12s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 15.5807	Cost: 6.16s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 15.6371	Cost: 5.97s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 15.5579	Cost: 6.62s
Train Epoch: 319 	Average Loss: 15.7064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2929

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Learning rate: 0.00019949824974445222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 16.1499	Cost: 20.02s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 15.4993	Cost: 6.13s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 15.7611	Cost: 6.32s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 15.6270	Cost: 6.00s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 15.6374	Cost: 7.46s
Train Epoch: 320 	Average Loss: 15.7462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3373

Learning rate: 0.00019949510169812976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 16.1214	Cost: 20.01s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 15.7728	Cost: 6.03s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 15.6896	Cost: 6.52s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 15.5579	Cost: 6.01s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 15.5758	Cost: 7.43s
Train Epoch: 321 	Average Loss: 15.6830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4116

Learning rate: 0.00019949194383203438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 16.0547	Cost: 20.45s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 15.5387	Cost: 6.13s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 15.6803	Cost: 6.25s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 15.4546	Cost: 5.97s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 15.6308	Cost: 7.14s
Train Epoch: 322 	Average Loss: 15.6973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3409

Learning rate: 0.00019948877614647787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 16.1712	Cost: 19.93s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 15.4727	Cost: 6.16s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 15.7138	Cost: 6.30s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 15.5291	Cost: 6.24s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 15.5362	Cost: 6.25s
Train Epoch: 323 	Average Loss: 15.6657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2894

Saving model as e323_model.pt & e323_waveforms_supplementary.hdf5
Learning rate: 0.0001994855986417728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 16.3131	Cost: 20.40s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 15.6401	Cost: 6.11s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 15.6204	Cost: 6.99s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 15.6387	Cost: 6.16s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 15.7255	Cost: 7.55s
Train Epoch: 324 	Average Loss: 15.6771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3128

Learning rate: 0.0001994824113182328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 16.1848	Cost: 20.02s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 15.7272	Cost: 6.01s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 15.6896	Cost: 6.03s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 15.5088	Cost: 5.91s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 15.8348	Cost: 6.24s
Train Epoch: 325 	Average Loss: 15.6948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3986

Learning rate: 0.00019947921417617242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 16.0757	Cost: 20.10s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 15.4782	Cost: 6.06s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 15.5862	Cost: 6.10s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 15.6217	Cost: 5.87s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 15.5215	Cost: 5.93s
Train Epoch: 326 	Average Loss: 15.6603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2756

Saving model as e326_model.pt & e326_waveforms_supplementary.hdf5
Learning rate: 0.0001994760072159072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 16.3143	Cost: 20.75s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 15.5446	Cost: 6.03s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 15.6801	Cost: 6.06s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 15.5302	Cost: 5.87s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 15.5086	Cost: 6.01s
Train Epoch: 327 	Average Loss: 15.6608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2817

Learning rate: 0.00019947279043775368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 16.1732	Cost: 21.89s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 15.7846	Cost: 5.97s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 15.7118	Cost: 6.14s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 15.5067	Cost: 5.86s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 15.8583	Cost: 5.98s
Train Epoch: 328 	Average Loss: 15.6622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2794

Learning rate: 0.00019946956384202932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 16.1032	Cost: 20.96s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 15.6338	Cost: 6.02s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 15.5631	Cost: 6.38s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 15.5129	Cost: 5.83s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 15.3866	Cost: 5.94s
Train Epoch: 329 	Average Loss: 15.6554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3501

Learning rate: 0.00019946632742905265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 16.0680	Cost: 21.44s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 15.4922	Cost: 5.98s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 15.5981	Cost: 6.63s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 15.5709	Cost: 6.04s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 15.6284	Cost: 6.32s
Train Epoch: 330 	Average Loss: 15.6469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4469

Learning rate: 0.000199463081199143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 16.2938	Cost: 20.70s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 15.6285	Cost: 6.00s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 15.6582	Cost: 6.10s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 15.4296	Cost: 5.71s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 15.6465	Cost: 6.09s
Train Epoch: 331 	Average Loss: 15.6532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3086

Learning rate: 0.0001994598251526208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 16.0310	Cost: 20.58s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 15.4939	Cost: 6.00s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 15.6525	Cost: 6.16s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 15.5721	Cost: 6.06s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 15.5675	Cost: 6.05s
Train Epoch: 332 	Average Loss: 15.6235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3319

Learning rate: 0.00019945655928980737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 16.3145	Cost: 21.72s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 15.4019	Cost: 6.01s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 15.5102	Cost: 6.13s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 15.4705	Cost: 5.86s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 15.4553	Cost: 5.82s
Train Epoch: 333 	Average Loss: 15.6092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3989

Learning rate: 0.0001994532836110251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 16.0445	Cost: 22.07s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 15.4131	Cost: 6.06s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 15.7656	Cost: 6.10s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 15.3249	Cost: 5.90s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 15.5444	Cost: 6.00s
Train Epoch: 334 	Average Loss: 15.6167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2277

Saving model as e334_model.pt & e334_waveforms_supplementary.hdf5
Learning rate: 0.00019944999811659725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 16.0676	Cost: 21.56s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 15.6600	Cost: 5.91s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 15.5447	Cost: 6.54s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 15.3615	Cost: 5.85s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 15.6919	Cost: 5.91s
Train Epoch: 335 	Average Loss: 15.6102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3803

Learning rate: 0.00019944670280684805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 16.2514	Cost: 20.87s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 15.6170	Cost: 6.10s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 15.6431	Cost: 6.04s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 15.7341	Cost: 5.90s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 15.5199	Cost: 6.00s
Train Epoch: 336 	Average Loss: 15.6463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3077

Learning rate: 0.00019944339768210285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 16.2382	Cost: 20.46s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 15.3914	Cost: 6.02s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 15.5515	Cost: 5.98s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 15.5013	Cost: 5.90s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 15.5694	Cost: 5.90s
Train Epoch: 337 	Average Loss: 15.6222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3858

Learning rate: 0.0001994400827426877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 16.1945	Cost: 21.45s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 15.4606	Cost: 6.38s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 15.6859	Cost: 6.42s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 15.6051	Cost: 5.85s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 15.4871	Cost: 5.98s
Train Epoch: 338 	Average Loss: 15.6030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3162

Learning rate: 0.0001994367579889299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 16.1291	Cost: 21.01s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 15.4119	Cost: 6.21s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 15.5055	Cost: 6.10s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 15.3196	Cost: 5.89s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 15.4161	Cost: 5.84s
Train Epoch: 339 	Average Loss: 15.5604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3290

Learning rate: 0.0001994334234211575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 16.3241	Cost: 21.55s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 15.4470	Cost: 6.19s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 15.5002	Cost: 6.38s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 15.5289	Cost: 5.84s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 15.4639	Cost: 5.97s
Train Epoch: 340 	Average Loss: 15.5704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3275

Learning rate: 0.00019943007903969968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 16.2348	Cost: 20.95s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 15.5841	Cost: 5.96s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 15.4803	Cost: 6.68s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 15.3933	Cost: 5.91s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 15.6511	Cost: 5.80s
Train Epoch: 341 	Average Loss: 15.5818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2971

Learning rate: 0.00019942672484488645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 16.0334	Cost: 21.12s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 15.5169	Cost: 6.06s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 15.5142	Cost: 6.13s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 15.3546	Cost: 5.90s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 15.4626	Cost: 6.12s
Train Epoch: 342 	Average Loss: 15.5617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2465

Learning rate: 0.0001994233608370489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 16.0334	Cost: 21.08s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 15.4577	Cost: 5.83s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 15.5901	Cost: 6.51s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 15.5335	Cost: 5.92s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 15.5105	Cost: 6.41s
Train Epoch: 343 	Average Loss: 15.5764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2857

Learning rate: 0.00019941998701651908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 16.1161	Cost: 20.04s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 15.5264	Cost: 6.03s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 15.5191	Cost: 6.46s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 15.4909	Cost: 5.91s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 15.4006	Cost: 5.94s
Train Epoch: 344 	Average Loss: 15.5837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3050

Learning rate: 0.00019941660338362987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 16.1044	Cost: 21.33s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 15.5013	Cost: 6.26s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 15.6054	Cost: 6.16s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 15.3281	Cost: 5.91s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 15.5598	Cost: 6.04s
Train Epoch: 345 	Average Loss: 15.5624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3250

Learning rate: 0.0001994132099387153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 16.1907	Cost: 20.90s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 15.5397	Cost: 6.22s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 15.4858	Cost: 6.12s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 15.5577	Cost: 5.95s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 15.5350	Cost: 6.03s
Train Epoch: 346 	Average Loss: 15.5687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3165

Learning rate: 0.00019940980668211027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 16.1504	Cost: 21.05s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 15.4569	Cost: 6.04s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 15.5505	Cost: 6.53s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 15.5184	Cost: 5.95s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 15.3154	Cost: 6.07s
Train Epoch: 347 	Average Loss: 15.5517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3164

Learning rate: 0.00019940639361415064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 16.1491	Cost: 22.45s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 15.4187	Cost: 5.96s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 15.5000	Cost: 6.03s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 15.4643	Cost: 5.96s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 15.3363	Cost: 5.84s
Train Epoch: 348 	Average Loss: 15.5494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3629

Learning rate: 0.00019940297073517331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 16.2422	Cost: 21.99s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 15.4223	Cost: 6.05s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 15.4365	Cost: 6.36s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 15.3712	Cost: 5.92s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 15.5123	Cost: 5.97s
Train Epoch: 349 	Average Loss: 15.5390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3710

Learning rate: 0.00019939953804551608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 16.1506	Cost: 20.40s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 15.5311	Cost: 6.05s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 15.5308	Cost: 6.24s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 15.5047	Cost: 5.91s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 15.4412	Cost: 6.05s
Train Epoch: 350 	Average Loss: 15.5269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3152

Learning rate: 0.00019939609554551777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 16.2183	Cost: 20.22s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 15.3474	Cost: 5.92s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 15.4105	Cost: 6.09s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 15.4301	Cost: 5.72s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 15.5635	Cost: 5.89s
Train Epoch: 351 	Average Loss: 15.5319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3183

Learning rate: 0.0001993926432355181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 16.1026	Cost: 21.83s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 15.2903	Cost: 6.04s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 15.6411	Cost: 6.68s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 15.4258	Cost: 5.91s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 15.3755	Cost: 6.52s
Train Epoch: 352 	Average Loss: 15.5262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2516

Learning rate: 0.00019938918111585784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 16.1309	Cost: 21.35s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 15.5146	Cost: 6.24s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 15.4536	Cost: 6.40s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 15.4905	Cost: 5.88s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 15.5005	Cost: 6.36s
Train Epoch: 353 	Average Loss: 15.4940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3094

Learning rate: 0.00019938570918687863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 16.0669	Cost: 20.88s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 15.5102	Cost: 6.04s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 15.5160	Cost: 6.54s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 15.2460	Cost: 6.22s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 15.2518	Cost: 5.85s
Train Epoch: 354 	Average Loss: 15.5159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3510

Learning rate: 0.0001993822274489232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 16.0777	Cost: 22.28s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 15.4067	Cost: 6.00s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 15.4732	Cost: 7.03s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 15.3781	Cost: 5.85s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 15.4586	Cost: 6.83s
Train Epoch: 355 	Average Loss: 15.4955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3480

Learning rate: 0.00019937873590233516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 16.1475	Cost: 21.48s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 15.4104	Cost: 6.08s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 15.3735	Cost: 6.54s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 15.3185	Cost: 6.11s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 15.3272	Cost: 6.07s
Train Epoch: 356 	Average Loss: 15.4953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2491

Learning rate: 0.0001993752345474591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 16.1094	Cost: 20.01s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 15.4922	Cost: 6.06s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 15.3777	Cost: 6.24s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 15.2438	Cost: 5.92s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 15.5179	Cost: 5.85s
Train Epoch: 357 	Average Loss: 15.4992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3817

Learning rate: 0.0001993717233846406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 16.1470	Cost: 21.18s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 15.3206	Cost: 6.10s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 15.4109	Cost: 6.07s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 15.3847	Cost: 5.78s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 15.6460	Cost: 5.94s
Train Epoch: 358 	Average Loss: 15.4797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3659

Learning rate: 0.0001993682024142262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 16.1837	Cost: 21.20s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 15.4759	Cost: 6.12s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 15.2851	Cost: 6.54s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 15.3303	Cost: 6.28s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 15.4730	Cost: 6.60s
Train Epoch: 359 	Average Loss: 15.4762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3380

Learning rate: 0.00019936467163656337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 16.2846	Cost: 21.13s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 15.4191	Cost: 6.16s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 15.5667	Cost: 7.54s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 15.4403	Cost: 5.83s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 15.4154	Cost: 6.00s
Train Epoch: 360 	Average Loss: 15.4905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3027

Learning rate: 0.00019936113105200064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 16.2246	Cost: 20.82s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 15.3825	Cost: 6.02s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 15.5240	Cost: 6.09s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 15.4097	Cost: 5.96s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 15.3668	Cost: 5.97s
Train Epoch: 361 	Average Loss: 15.4808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2699

Learning rate: 0.00019935758066088742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 16.1649	Cost: 20.66s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 15.4182	Cost: 6.22s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 15.5076	Cost: 7.24s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 15.3238	Cost: 5.96s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 15.5047	Cost: 6.72s
Train Epoch: 362 	Average Loss: 15.4564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4040

Learning rate: 0.00019935402046357414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 16.1157	Cost: 21.44s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 15.4269	Cost: 6.27s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 15.4912	Cost: 6.13s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 15.3028	Cost: 5.96s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 15.3911	Cost: 6.61s
Train Epoch: 363 	Average Loss: 15.4494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2711

Learning rate: 0.00019935045046041218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 16.1440	Cost: 21.60s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 15.2730	Cost: 6.19s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 15.3466	Cost: 6.23s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 15.1283	Cost: 5.96s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 15.5470	Cost: 6.61s
Train Epoch: 364 	Average Loss: 15.4210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3693

Learning rate: 0.00019934687065175386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 16.2775	Cost: 21.49s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 15.2613	Cost: 6.13s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 15.2522	Cost: 6.33s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 15.2244	Cost: 5.92s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 15.3401	Cost: 6.68s
Train Epoch: 365 	Average Loss: 15.4487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3499

Learning rate: 0.00019934328103795248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 16.1844	Cost: 20.95s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 15.4992	Cost: 6.07s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 15.3988	Cost: 6.67s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 15.2434	Cost: 5.94s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 15.2210	Cost: 6.65s
Train Epoch: 366 	Average Loss: 15.4198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3247

Learning rate: 0.00019933968161936236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 16.0103	Cost: 20.81s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 15.1342	Cost: 6.04s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 15.2976	Cost: 6.10s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 15.2533	Cost: 5.94s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 15.4335	Cost: 6.42s
Train Epoch: 367 	Average Loss: 15.4175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3732

Learning rate: 0.00019933607239633875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 16.0221	Cost: 20.59s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 15.3608	Cost: 5.99s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 15.2725	Cost: 6.41s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 15.2463	Cost: 5.88s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 15.3204	Cost: 6.90s
Train Epoch: 368 	Average Loss: 15.4013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3293

Learning rate: 0.00019933245336923783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 16.1732	Cost: 20.65s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 15.4447	Cost: 6.49s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 15.4872	Cost: 6.04s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 15.2420	Cost: 6.05s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 15.4448	Cost: 6.53s
Train Epoch: 369 	Average Loss: 15.4317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3507

Learning rate: 0.0001993288245384168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 16.2293	Cost: 19.95s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 15.3832	Cost: 5.99s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 15.4722	Cost: 6.43s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 15.3088	Cost: 6.00s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 15.3999	Cost: 7.07s
Train Epoch: 370 	Average Loss: 15.4309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3196

Learning rate: 0.00019932518590423377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 16.0188	Cost: 20.17s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 15.3821	Cost: 5.97s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 15.3178	Cost: 6.18s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 15.2099	Cost: 6.07s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 15.4611	Cost: 6.39s
Train Epoch: 371 	Average Loss: 15.3878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3717

Learning rate: 0.00019932153746704794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 16.0896	Cost: 20.32s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 15.3787	Cost: 6.11s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 15.3930	Cost: 6.09s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 15.3921	Cost: 6.01s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 15.2696	Cost: 6.13s
Train Epoch: 372 	Average Loss: 15.4124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3609

Learning rate: 0.00019931787922721937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 16.0761	Cost: 20.19s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 15.3204	Cost: 5.99s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 15.3469	Cost: 6.68s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 15.2425	Cost: 6.01s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 15.4167	Cost: 7.04s
Train Epoch: 373 	Average Loss: 15.4264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3645

Learning rate: 0.00019931421118510906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 16.2015	Cost: 20.25s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 15.2370	Cost: 6.10s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 15.2586	Cost: 6.60s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 15.2525	Cost: 6.11s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 15.5473	Cost: 7.52s
Train Epoch: 374 	Average Loss: 15.3784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2853

Learning rate: 0.0001993105333410791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 16.1909	Cost: 20.28s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 15.3420	Cost: 5.95s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 15.2272	Cost: 6.00s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 15.1950	Cost: 5.97s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 15.5148	Cost: 7.44s
Train Epoch: 375 	Average Loss: 15.3837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3165

Learning rate: 0.00019930684569549248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 16.1578	Cost: 19.73s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 15.2071	Cost: 6.06s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 15.2422	Cost: 6.04s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 15.5208	Cost: 5.96s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 15.2575	Cost: 6.61s
Train Epoch: 376 	Average Loss: 15.3779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3103

Learning rate: 0.0001993031482487131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 16.0189	Cost: 20.73s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 15.3035	Cost: 6.11s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 15.3825	Cost: 6.85s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 15.3338	Cost: 6.04s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 15.4099	Cost: 7.66s
Train Epoch: 377 	Average Loss: 15.4060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3686

Learning rate: 0.0001992994410011059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 16.1029	Cost: 19.92s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 15.4133	Cost: 5.98s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 15.3468	Cost: 6.08s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 15.3028	Cost: 5.97s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 15.1400	Cost: 5.96s
Train Epoch: 378 	Average Loss: 15.3727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3223

Learning rate: 0.00019929572395303678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 16.1383	Cost: 19.50s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 15.2737	Cost: 6.12s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 15.3148	Cost: 6.34s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 15.2985	Cost: 5.97s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 15.2022	Cost: 6.98s
Train Epoch: 379 	Average Loss: 15.3659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3215

Learning rate: 0.0001992919971048726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 16.0398	Cost: 19.59s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 15.2294	Cost: 6.05s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 15.4527	Cost: 6.12s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 15.2147	Cost: 5.96s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 15.2961	Cost: 6.40s
Train Epoch: 380 	Average Loss: 15.3591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3082

Learning rate: 0.0001992882604569812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 16.2250	Cost: 20.18s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 15.4023	Cost: 6.04s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 15.4337	Cost: 6.18s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 15.3937	Cost: 6.16s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 15.2557	Cost: 7.07s
Train Epoch: 381 	Average Loss: 15.3642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2783

Learning rate: 0.00019928451400973133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 16.1071	Cost: 21.18s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 15.1212	Cost: 6.03s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 15.3462	Cost: 6.52s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 15.3395	Cost: 6.00s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 15.3216	Cost: 6.35s
Train Epoch: 382 	Average Loss: 15.3590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4032

Learning rate: 0.0001992807577634928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 16.2761	Cost: 20.98s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 15.0711	Cost: 6.70s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 15.1931	Cost: 6.39s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 15.2841	Cost: 5.87s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 15.3128	Cost: 6.39s
Train Epoch: 383 	Average Loss: 15.3342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2594

Learning rate: 0.00019927699171863632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 16.1930	Cost: 19.80s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 15.2366	Cost: 6.07s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 15.2437	Cost: 6.30s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 15.2320	Cost: 6.28s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 15.3078	Cost: 6.45s
Train Epoch: 384 	Average Loss: 15.3018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3184

Learning rate: 0.00019927321587553357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 15.9852	Cost: 19.54s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 15.1405	Cost: 6.02s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 15.3076	Cost: 6.05s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 15.1418	Cost: 6.09s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 15.2742	Cost: 7.29s
Train Epoch: 385 	Average Loss: 15.3151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2894

Learning rate: 0.00019926943023455717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 16.1075	Cost: 19.74s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 15.1823	Cost: 6.09s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 15.2144	Cost: 6.09s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 15.1920	Cost: 6.04s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 15.3076	Cost: 6.56s
Train Epoch: 386 	Average Loss: 15.3019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3478

Learning rate: 0.00019926563479608086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 16.1654	Cost: 20.01s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 15.2419	Cost: 6.05s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 15.1700	Cost: 6.12s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 15.3309	Cost: 6.07s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 15.3102	Cost: 6.11s
Train Epoch: 387 	Average Loss: 15.2934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3575

Learning rate: 0.00019926182956047912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 16.2629	Cost: 20.20s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 15.2567	Cost: 6.10s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 15.1897	Cost: 6.30s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 15.1313	Cost: 5.97s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 15.2136	Cost: 7.40s
Train Epoch: 388 	Average Loss: 15.3127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3739

Learning rate: 0.00019925801452812757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 16.2094	Cost: 19.90s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 15.2250	Cost: 6.04s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 15.0195	Cost: 6.46s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 15.2775	Cost: 6.04s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 15.2133	Cost: 7.13s
Train Epoch: 389 	Average Loss: 15.2843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3675

Learning rate: 0.00019925418969940278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 16.1617	Cost: 19.39s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 15.2395	Cost: 6.00s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 15.2130	Cost: 6.14s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 15.1977	Cost: 5.98s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 15.2927	Cost: 6.05s
Train Epoch: 390 	Average Loss: 15.2995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3766

Learning rate: 0.00019925035507468219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 16.1256	Cost: 20.18s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 15.3318	Cost: 6.03s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 15.2445	Cost: 6.20s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 15.3465	Cost: 5.73s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 15.1592	Cost: 6.80s
Train Epoch: 391 	Average Loss: 15.2990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3211

Learning rate: 0.00019924651065434423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 16.0575	Cost: 20.65s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 15.1750	Cost: 6.00s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 15.2136	Cost: 6.22s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 15.3067	Cost: 6.11s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 15.3524	Cost: 6.06s
Train Epoch: 392 	Average Loss: 15.3080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3309

Learning rate: 0.0001992426564387684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 16.2085	Cost: 20.11s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 15.3497	Cost: 5.96s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 15.1475	Cost: 5.96s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 15.0122	Cost: 5.89s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 15.2194	Cost: 5.91s
Train Epoch: 393 	Average Loss: 15.2922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3760

Learning rate: 0.00019923879242833502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 16.3119	Cost: 19.61s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 15.0835	Cost: 6.04s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 15.2494	Cost: 6.09s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 15.2078	Cost: 5.85s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 15.2206	Cost: 5.95s
Train Epoch: 394 	Average Loss: 15.2674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3622

Learning rate: 0.00019923491862342552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 16.1986	Cost: 20.56s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 15.1339	Cost: 6.01s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 15.1985	Cost: 6.16s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 15.0470	Cost: 5.83s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 15.1661	Cost: 5.95s
Train Epoch: 395 	Average Loss: 15.2903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3720

Learning rate: 0.0001992310350244222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 16.0956	Cost: 19.75s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 15.2355	Cost: 6.07s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 15.3043	Cost: 5.98s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 15.1946	Cost: 5.86s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 15.1490	Cost: 5.90s
Train Epoch: 396 	Average Loss: 15.2469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3949

Learning rate: 0.0001992271416317084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 16.3189	Cost: 21.00s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 15.2441	Cost: 6.01s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 15.0709	Cost: 6.51s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 15.2542	Cost: 5.98s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 15.2041	Cost: 5.95s
Train Epoch: 397 	Average Loss: 15.2966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3061

Learning rate: 0.0001992232384456683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 16.1997	Cost: 20.24s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 15.1108	Cost: 6.00s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 15.4294	Cost: 6.13s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 15.2156	Cost: 5.91s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 15.1207	Cost: 5.95s
Train Epoch: 398 	Average Loss: 15.2521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3997

Learning rate: 0.00019921932546668718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 16.1260	Cost: 20.39s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 14.9887	Cost: 6.09s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 15.1697	Cost: 6.20s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 15.2390	Cost: 5.86s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 15.0386	Cost: 6.02s
Train Epoch: 399 	Average Loss: 15.2548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3825

Learning rate: 0.00019921540269515121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 16.2332	Cost: 19.66s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 15.2258	Cost: 6.01s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 15.1092	Cost: 5.99s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 15.1008	Cost: 5.91s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 15.2857	Cost: 5.88s
Train Epoch: 400 	Average Loss: 15.2400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3675

Learning rate: 0.0001992114701314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 16.1321	Cost: 20.37s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 15.0797	Cost: 6.00s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 15.3197	Cost: 6.37s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 15.1745	Cost: 5.88s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 15.1209	Cost: 6.32s
Train Epoch: 401 	Average Loss: 15.2444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3649

Learning rate: 0.00019920752777596444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 16.1423	Cost: 20.55s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 15.1054	Cost: 5.95s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 15.1164	Cost: 6.08s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 15.1621	Cost: 5.84s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 15.2206	Cost: 5.87s
Train Epoch: 402 	Average Loss: 15.2260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3446

Learning rate: 0.00019920357562909082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 16.0323	Cost: 20.41s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 15.1062	Cost: 5.96s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 15.2937	Cost: 5.98s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 14.9669	Cost: 5.84s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 15.0641	Cost: 5.88s
Train Epoch: 403 	Average Loss: 15.2207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3638

Learning rate: 0.00019919961369121682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 16.1409	Cost: 20.30s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 15.0231	Cost: 5.98s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 14.9812	Cost: 6.03s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 15.1665	Cost: 5.90s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 15.1609	Cost: 5.97s
Train Epoch: 404 	Average Loss: 15.2242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3612

Learning rate: 0.00019919564196273348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 16.0985	Cost: 20.58s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 14.9862	Cost: 6.03s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 15.1954	Cost: 6.10s
Train Epoch: 405 [61440/90000 (68%)]	Loss: 15.1424	Cost: 6.06s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 15.2019	Cost: 6.18s
Train Epoch: 405 	Average Loss: 15.2206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4309

Learning rate: 0.00019919166044403278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 16.2148	Cost: 21.82s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 15.2129	Cost: 5.97s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 15.0890	Cost: 6.63s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 15.0311	Cost: 5.94s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 15.2309	Cost: 6.38s
Train Epoch: 406 	Average Loss: 15.2238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3970

Learning rate: 0.00019918766913550764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 16.2631	Cost: 21.08s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 14.9969	Cost: 5.99s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 15.1362	Cost: 6.38s
Train Epoch: 407 [61440/90000 (68%)]	Loss: 15.0590	Cost: 6.00s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 15.1370	Cost: 6.44s
Train Epoch: 407 	Average Loss: 15.1969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4563

Learning rate: 0.00019918366803755205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 16.2515	Cost: 21.89s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 15.0087	Cost: 6.10s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 15.1745	Cost: 6.87s
Train Epoch: 408 [61440/90000 (68%)]	Loss: 15.1336	Cost: 5.96s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 15.1602	Cost: 6.89s
Train Epoch: 408 	Average Loss: 15.1773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3691

Learning rate: 0.00019917965715056087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 16.0349	Cost: 20.75s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 15.2416	Cost: 5.99s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 15.0258	Cost: 6.26s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 15.1296	Cost: 5.92s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 15.2320	Cost: 7.17s
Train Epoch: 409 	Average Loss: 15.1694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3371

Learning rate: 0.00019917563647492995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 16.0990	Cost: 20.18s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 15.0590	Cost: 6.04s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 15.1854	Cost: 6.78s
Train Epoch: 410 [61440/90000 (68%)]	Loss: 15.1463	Cost: 6.10s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 15.0205	Cost: 7.85s
Train Epoch: 410 	Average Loss: 15.1853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3219

Learning rate: 0.00019917160601105614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 16.0967	Cost: 19.95s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 15.1796	Cost: 6.22s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 15.0312	Cost: 6.14s
Train Epoch: 411 [61440/90000 (68%)]	Loss: 15.1873	Cost: 6.03s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 15.1954	Cost: 6.04s
Train Epoch: 411 	Average Loss: 15.1794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2934

Learning rate: 0.0001991675657593372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 16.1122	Cost: 21.02s
Train Epoch: 412 [20480/90000 (23%)]	Loss: 14.9812	Cost: 6.05s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 15.0352	Cost: 6.43s
Train Epoch: 412 [61440/90000 (68%)]	Loss: 15.1115	Cost: 6.02s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 15.0800	Cost: 7.54s
Train Epoch: 412 	Average Loss: 15.1732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3769

Learning rate: 0.00019916351572017192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 16.0565	Cost: 20.10s
Train Epoch: 413 [20480/90000 (23%)]	Loss: 15.0010	Cost: 6.75s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 15.2933	Cost: 6.16s
Train Epoch: 413 [61440/90000 (68%)]	Loss: 15.0432	Cost: 5.99s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 15.0856	Cost: 5.91s
Train Epoch: 413 	Average Loss: 15.1611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3081

Learning rate: 0.00019915945589396003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 16.1730	Cost: 19.71s
Train Epoch: 414 [20480/90000 (23%)]	Loss: 15.0513	Cost: 6.11s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 15.0664	Cost: 6.07s
Train Epoch: 414 [61440/90000 (68%)]	Loss: 14.9418	Cost: 6.06s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 14.9256	Cost: 6.73s
Train Epoch: 414 	Average Loss: 15.1743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3737

Learning rate: 0.00019915538628110217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 16.2400	Cost: 20.81s
Train Epoch: 415 [20480/90000 (23%)]	Loss: 15.0252	Cost: 6.35s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 14.9610	Cost: 6.28s
Train Epoch: 415 [61440/90000 (68%)]	Loss: 15.1010	Cost: 6.02s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 15.0947	Cost: 6.55s
Train Epoch: 415 	Average Loss: 15.1647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4208

Learning rate: 0.00019915130688200001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 16.2447	Cost: 21.00s
Train Epoch: 416 [20480/90000 (23%)]	Loss: 14.9809	Cost: 6.08s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 15.1106	Cost: 6.30s
Train Epoch: 416 [61440/90000 (68%)]	Loss: 14.9267	Cost: 6.05s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 14.9107	Cost: 7.43s
Train Epoch: 416 	Average Loss: 15.1682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3573

Learning rate: 0.0001991472176970562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 16.3416	Cost: 20.32s
Train Epoch: 417 [20480/90000 (23%)]	Loss: 14.9515	Cost: 6.02s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 15.1044	Cost: 6.15s
Train Epoch: 417 [61440/90000 (68%)]	Loss: 14.9082	Cost: 5.98s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 14.9797	Cost: 5.93s
Train Epoch: 417 	Average Loss: 15.1622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3325

Learning rate: 0.00019914311872667434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 16.2831	Cost: 20.41s
Train Epoch: 418 [20480/90000 (23%)]	Loss: 15.1255	Cost: 6.13s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 15.0714	Cost: 6.41s
Train Epoch: 418 [61440/90000 (68%)]	Loss: 15.1236	Cost: 6.05s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 15.0039	Cost: 6.62s
Train Epoch: 418 	Average Loss: 15.1566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3556

Learning rate: 0.0001991390099712589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 16.0618	Cost: 20.88s
Train Epoch: 419 [20480/90000 (23%)]	Loss: 15.0137	Cost: 6.17s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 14.9192	Cost: 6.29s
Train Epoch: 419 [61440/90000 (68%)]	Loss: 14.9751	Cost: 5.98s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 15.1179	Cost: 6.51s
Train Epoch: 419 	Average Loss: 15.1559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3745

Learning rate: 0.00019913489143121547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 16.2187	Cost: 20.30s
Train Epoch: 420 [20480/90000 (23%)]	Loss: 14.9955	Cost: 6.02s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 15.0550	Cost: 6.08s
Train Epoch: 420 [61440/90000 (68%)]	Loss: 15.1095	Cost: 6.06s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 14.9903	Cost: 7.65s
Train Epoch: 420 	Average Loss: 15.1283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3476

Learning rate: 0.0001991307631069505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 16.4507	Cost: 20.13s
Train Epoch: 421 [20480/90000 (23%)]	Loss: 15.0096	Cost: 6.04s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 15.1224	Cost: 6.43s
Train Epoch: 421 [61440/90000 (68%)]	Loss: 15.0102	Cost: 6.18s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 15.0784	Cost: 7.49s
Train Epoch: 421 	Average Loss: 15.1425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4031

Learning rate: 0.0001991266249988715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 16.1799	Cost: 19.77s
Train Epoch: 422 [20480/90000 (23%)]	Loss: 14.9547	Cost: 6.15s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 15.1767	Cost: 6.10s
Train Epoch: 422 [61440/90000 (68%)]	Loss: 15.0039	Cost: 6.22s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 15.0155	Cost: 6.48s
Train Epoch: 422 	Average Loss: 15.1158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4230

Learning rate: 0.00019912247710738676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 16.3201	Cost: 21.35s
Train Epoch: 423 [20480/90000 (23%)]	Loss: 15.0464	Cost: 6.68s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 15.0720	Cost: 6.64s
Train Epoch: 423 [61440/90000 (68%)]	Loss: 15.0759	Cost: 6.03s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 15.1054	Cost: 6.86s
Train Epoch: 423 	Average Loss: 15.1161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4317

Learning rate: 0.0001991183194329058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 16.2104	Cost: 20.02s
Train Epoch: 424 [20480/90000 (23%)]	Loss: 15.0727	Cost: 6.06s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 15.0404	Cost: 6.01s
Train Epoch: 424 [61440/90000 (68%)]	Loss: 15.0038	Cost: 5.90s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 15.0288	Cost: 6.35s
Train Epoch: 424 	Average Loss: 15.1391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3653

Learning rate: 0.00019911415197583891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 16.1003	Cost: 21.14s
Train Epoch: 425 [20480/90000 (23%)]	Loss: 14.9542	Cost: 6.00s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 15.0026	Cost: 7.12s
Train Epoch: 425 [61440/90000 (68%)]	Loss: 14.9917	Cost: 5.89s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 15.2529	Cost: 7.08s
Train Epoch: 425 	Average Loss: 15.0925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3517

Learning rate: 0.00019910997473659734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 16.2781	Cost: 20.12s
Train Epoch: 426 [20480/90000 (23%)]	Loss: 14.9751	Cost: 6.17s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 14.8834	Cost: 6.14s
Train Epoch: 426 [61440/90000 (68%)]	Loss: 14.8402	Cost: 5.83s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 15.0799	Cost: 6.00s
Train Epoch: 426 	Average Loss: 15.1038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5020

Learning rate: 0.00019910578771559345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 16.2056	Cost: 21.42s
Train Epoch: 427 [20480/90000 (23%)]	Loss: 14.9263	Cost: 6.01s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 15.1240	Cost: 6.06s
Train Epoch: 427 [61440/90000 (68%)]	Loss: 15.1175	Cost: 5.89s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 15.0024	Cost: 6.08s
Train Epoch: 427 	Average Loss: 15.0994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3911

Learning rate: 0.00019910159091324043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 16.2519	Cost: 21.14s
Train Epoch: 428 [20480/90000 (23%)]	Loss: 15.0677	Cost: 5.87s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 15.0557	Cost: 6.91s
Train Epoch: 428 [61440/90000 (68%)]	Loss: 15.0064	Cost: 5.85s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 15.0216	Cost: 6.53s
Train Epoch: 428 	Average Loss: 15.0926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4653

Learning rate: 0.00019909738432995254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 16.4291	Cost: 20.35s
Train Epoch: 429 [20480/90000 (23%)]	Loss: 14.8872	Cost: 6.04s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 15.1016	Cost: 6.50s
Train Epoch: 429 [61440/90000 (68%)]	Loss: 14.9827	Cost: 5.90s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 15.0220	Cost: 6.16s
Train Epoch: 429 	Average Loss: 15.0840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4622

Learning rate: 0.00019909316796614494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 16.3161	Cost: 22.55s
Train Epoch: 430 [20480/90000 (23%)]	Loss: 14.9438	Cost: 5.94s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 15.0455	Cost: 6.46s
Train Epoch: 430 [61440/90000 (68%)]	Loss: 14.8938	Cost: 5.89s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 15.0132	Cost: 6.50s
Train Epoch: 430 	Average Loss: 15.0806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3495

Learning rate: 0.00019908894182223372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 16.2796	Cost: 21.11s
Train Epoch: 431 [20480/90000 (23%)]	Loss: 15.0611	Cost: 5.96s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 14.9016	Cost: 6.30s
Train Epoch: 431 [61440/90000 (68%)]	Loss: 14.9669	Cost: 5.88s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 15.1530	Cost: 6.08s
Train Epoch: 431 	Average Loss: 15.0717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3842

Learning rate: 0.00019908470589863605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 16.1352	Cost: 21.71s
Train Epoch: 432 [20480/90000 (23%)]	Loss: 14.8532	Cost: 6.12s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 15.1624	Cost: 6.21s
Train Epoch: 432 [61440/90000 (68%)]	Loss: 14.8107	Cost: 6.03s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 14.9127	Cost: 5.86s
Train Epoch: 432 	Average Loss: 15.0628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4831

Learning rate: 0.00019908046019576994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 16.3909	Cost: 20.24s
Train Epoch: 433 [20480/90000 (23%)]	Loss: 14.8862	Cost: 6.05s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 15.0313	Cost: 6.16s
Train Epoch: 433 [61440/90000 (68%)]	Loss: 14.8710	Cost: 6.58s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 15.0644	Cost: 6.37s
Train Epoch: 433 	Average Loss: 15.0754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4134

Learning rate: 0.00019907620471405445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 16.2086	Cost: 21.54s
Train Epoch: 434 [20480/90000 (23%)]	Loss: 14.8863	Cost: 6.62s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 15.0439	Cost: 6.02s
Train Epoch: 434 [61440/90000 (68%)]	Loss: 14.9261	Cost: 5.92s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 15.0473	Cost: 5.82s
Train Epoch: 434 	Average Loss: 15.0436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4586

Learning rate: 0.0001990719394539096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 16.4481	Cost: 21.71s
Train Epoch: 435 [20480/90000 (23%)]	Loss: 14.9373	Cost: 5.94s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 14.9850	Cost: 6.52s
Train Epoch: 435 [61440/90000 (68%)]	Loss: 14.8818	Cost: 5.90s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 14.9379	Cost: 6.12s
Train Epoch: 435 	Average Loss: 15.0423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3397

Learning rate: 0.0001990676644157563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 16.0897	Cost: 20.56s
Train Epoch: 436 [20480/90000 (23%)]	Loss: 14.7809	Cost: 6.04s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 14.8971	Cost: 6.45s
Train Epoch: 436 [61440/90000 (68%)]	Loss: 14.9628	Cost: 5.99s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 14.9791	Cost: 5.96s
Train Epoch: 436 	Average Loss: 15.0416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3936

Learning rate: 0.00019906337960001657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 16.2051	Cost: 22.10s
Train Epoch: 437 [20480/90000 (23%)]	Loss: 14.6752	Cost: 5.94s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 14.9294	Cost: 6.46s
Train Epoch: 437 [61440/90000 (68%)]	Loss: 14.9410	Cost: 5.89s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 14.8896	Cost: 5.90s
Train Epoch: 437 	Average Loss: 15.0327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4183

Learning rate: 0.0001990590850071132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 16.1769	Cost: 20.97s
Train Epoch: 438 [20480/90000 (23%)]	Loss: 14.7952	Cost: 6.02s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 14.9095	Cost: 6.24s
Train Epoch: 438 [61440/90000 (68%)]	Loss: 14.9695	Cost: 5.95s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 14.9049	Cost: 6.17s
Train Epoch: 438 	Average Loss: 15.0064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4158

Learning rate: 0.0001990547806374701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 16.3146	Cost: 21.45s
Train Epoch: 439 [20480/90000 (23%)]	Loss: 15.0080	Cost: 5.95s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 14.7515	Cost: 6.58s
Train Epoch: 439 [61440/90000 (68%)]	Loss: 14.9780	Cost: 5.89s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 15.0974	Cost: 6.44s
Train Epoch: 439 	Average Loss: 15.0309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3541

Learning rate: 0.00019905046649151213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 16.0574	Cost: 21.07s
Train Epoch: 440 [20480/90000 (23%)]	Loss: 14.9520	Cost: 6.04s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 14.7910	Cost: 6.74s
Train Epoch: 440 [61440/90000 (68%)]	Loss: 14.9001	Cost: 5.84s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 15.0406	Cost: 6.33s
Train Epoch: 440 	Average Loss: 15.0007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4838

Learning rate: 0.00019904614256966498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 16.2079	Cost: 21.79s
Train Epoch: 441 [20480/90000 (23%)]	Loss: 14.8863	Cost: 6.06s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 14.7864	Cost: 6.62s
Train Epoch: 441 [61440/90000 (68%)]	Loss: 14.9939	Cost: 5.85s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 15.0739	Cost: 5.89s
Train Epoch: 441 	Average Loss: 15.0212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3942

Learning rate: 0.00019904180887235552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 16.1731	Cost: 21.02s
Train Epoch: 442 [20480/90000 (23%)]	Loss: 14.8473	Cost: 5.96s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 15.0963	Cost: 6.51s
Train Epoch: 442 [61440/90000 (68%)]	Loss: 15.0420	Cost: 5.97s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 15.0383	Cost: 6.75s
Train Epoch: 442 	Average Loss: 15.0111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4262

Learning rate: 0.0001990374654000114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 16.1935	Cost: 21.62s
Train Epoch: 443 [20480/90000 (23%)]	Loss: 14.8303	Cost: 6.00s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 14.9319	Cost: 5.97s
Train Epoch: 443 [61440/90000 (68%)]	Loss: 14.8738	Cost: 5.99s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 14.9157	Cost: 5.88s
Train Epoch: 443 	Average Loss: 14.9897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4179

Learning rate: 0.0001990331121530613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 16.2618	Cost: 20.40s
Train Epoch: 444 [20480/90000 (23%)]	Loss: 14.6898	Cost: 6.07s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 14.9259	Cost: 6.45s
Train Epoch: 444 [61440/90000 (68%)]	Loss: 14.7644	Cost: 5.87s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 14.8212	Cost: 5.94s
Train Epoch: 444 	Average Loss: 14.9705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3872

Learning rate: 0.0001990287491319349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 16.3310	Cost: 20.01s
Train Epoch: 445 [20480/90000 (23%)]	Loss: 14.9420	Cost: 6.09s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 14.8903	Cost: 6.05s
Train Epoch: 445 [61440/90000 (68%)]	Loss: 14.7693	Cost: 5.92s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 14.8159	Cost: 5.75s
Train Epoch: 445 	Average Loss: 14.9649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4757

Learning rate: 0.00019902437633706276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 16.2112	Cost: 21.44s
Train Epoch: 446 [20480/90000 (23%)]	Loss: 14.8476	Cost: 5.99s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 14.9023	Cost: 6.09s
Train Epoch: 446 [61440/90000 (68%)]	Loss: 14.8323	Cost: 5.91s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 14.8152	Cost: 5.85s
Train Epoch: 446 	Average Loss: 14.9657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4747

Learning rate: 0.0001990199937688765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 16.0324	Cost: 20.76s
Train Epoch: 447 [20480/90000 (23%)]	Loss: 14.7399	Cost: 6.01s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 14.9486	Cost: 6.95s
Train Epoch: 447 [61440/90000 (68%)]	Loss: 15.0475	Cost: 5.85s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 14.6906	Cost: 5.83s
Train Epoch: 447 	Average Loss: 14.9662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4309

Learning rate: 0.00019901560142780868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 16.3103	Cost: 20.56s
Train Epoch: 448 [20480/90000 (23%)]	Loss: 14.7429	Cost: 6.05s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 14.9409	Cost: 6.25s
Train Epoch: 448 [61440/90000 (68%)]	Loss: 14.9191	Cost: 5.94s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 14.8496	Cost: 5.90s
Train Epoch: 448 	Average Loss: 14.9558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4642

Learning rate: 0.0001990111993142928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 16.1978	Cost: 22.38s
Train Epoch: 449 [20480/90000 (23%)]	Loss: 14.8058	Cost: 5.96s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 15.0350	Cost: 6.53s
Train Epoch: 449 [61440/90000 (68%)]	Loss: 14.8050	Cost: 5.94s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 14.7854	Cost: 6.26s
Train Epoch: 449 	Average Loss: 14.9341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4035

Learning rate: 0.0001990067874287633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 16.2195	Cost: 21.42s
Train Epoch: 450 [20480/90000 (23%)]	Loss: 14.7342	Cost: 6.08s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 14.7712	Cost: 6.06s
Train Epoch: 450 [61440/90000 (68%)]	Loss: 14.7885	Cost: 6.03s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 14.6589	Cost: 6.11s
Train Epoch: 450 	Average Loss: 14.9355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5060

Learning rate: 0.00019900236577165563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 16.1720	Cost: 21.21s
Train Epoch: 451 [20480/90000 (23%)]	Loss: 14.8100	Cost: 6.39s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 14.9304	Cost: 6.31s
Train Epoch: 451 [61440/90000 (68%)]	Loss: 14.5643	Cost: 5.89s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 14.7335	Cost: 6.09s
Train Epoch: 451 	Average Loss: 14.9446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5257

Learning rate: 0.00019899793434340619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 16.3603	Cost: 21.67s
Train Epoch: 452 [20480/90000 (23%)]	Loss: 14.7111	Cost: 5.97s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 15.1429	Cost: 6.59s
Train Epoch: 452 [61440/90000 (68%)]	Loss: 14.7615	Cost: 5.87s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 14.9191	Cost: 6.43s
Train Epoch: 452 	Average Loss: 14.9338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3881

Learning rate: 0.00019899349314445237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 16.0972	Cost: 21.25s
Train Epoch: 453 [20480/90000 (23%)]	Loss: 14.6422	Cost: 5.98s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 14.8807	Cost: 7.03s
Train Epoch: 453 [61440/90000 (68%)]	Loss: 14.7026	Cost: 5.84s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 14.7124	Cost: 6.15s
Train Epoch: 453 	Average Loss: 14.8964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4516

Learning rate: 0.00019898904217523244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 16.4354	Cost: 20.39s
Train Epoch: 454 [20480/90000 (23%)]	Loss: 14.6744	Cost: 6.14s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 14.7289	Cost: 6.02s
Train Epoch: 454 [61440/90000 (68%)]	Loss: 14.7559	Cost: 5.99s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 14.8052	Cost: 5.98s
Train Epoch: 454 	Average Loss: 14.9381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4984

Learning rate: 0.00019898458143618574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 16.5745	Cost: 18.78s
Train Epoch: 455 [20480/90000 (23%)]	Loss: 14.5859	Cost: 6.03s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 14.6324	Cost: 6.07s
Train Epoch: 455 [61440/90000 (68%)]	Loss: 14.7830	Cost: 5.90s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 14.8396	Cost: 5.80s
Train Epoch: 455 	Average Loss: 14.9378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4358

Learning rate: 0.0001989801109277525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 16.2730	Cost: 19.64s
Train Epoch: 456 [20480/90000 (23%)]	Loss: 14.7911	Cost: 6.07s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 14.8473	Cost: 6.03s
Train Epoch: 456 [61440/90000 (68%)]	Loss: 14.7815	Cost: 5.90s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 14.7354	Cost: 5.78s
Train Epoch: 456 	Average Loss: 14.9012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4997

Learning rate: 0.000198975630650374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 16.2379	Cost: 19.59s
Train Epoch: 457 [20480/90000 (23%)]	Loss: 14.6603	Cost: 6.04s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 14.8039	Cost: 6.10s
Train Epoch: 457 [61440/90000 (68%)]	Loss: 14.7787	Cost: 6.04s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 14.8534	Cost: 5.77s
Train Epoch: 457 	Average Loss: 14.8869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5586

Learning rate: 0.0001989711406044923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 16.1274	Cost: 19.78s
Train Epoch: 458 [20480/90000 (23%)]	Loss: 14.7608	Cost: 6.00s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 14.7936	Cost: 6.40s
Train Epoch: 458 [61440/90000 (68%)]	Loss: 14.7092	Cost: 5.88s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 14.7551	Cost: 5.96s
Train Epoch: 458 	Average Loss: 14.8800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4199

Learning rate: 0.0001989666407905507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 16.1897	Cost: 20.77s
Train Epoch: 459 [20480/90000 (23%)]	Loss: 14.5755	Cost: 6.03s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 14.8578	Cost: 6.33s
Train Epoch: 459 [61440/90000 (68%)]	Loss: 14.7533	Cost: 5.87s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 14.7637	Cost: 6.06s
Train Epoch: 459 	Average Loss: 14.8744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4879

Learning rate: 0.00019896213120899325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 16.2259	Cost: 22.17s
Train Epoch: 460 [20480/90000 (23%)]	Loss: 14.7659	Cost: 5.91s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 14.6854	Cost: 6.24s
Train Epoch: 460 [61440/90000 (68%)]	Loss: 14.6132	Cost: 5.79s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 14.6481	Cost: 5.67s
Train Epoch: 460 	Average Loss: 14.8973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5077

Learning rate: 0.00019895761186026497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 16.3297	Cost: 20.30s
Train Epoch: 461 [20480/90000 (23%)]	Loss: 14.7087	Cost: 5.97s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 14.7933	Cost: 5.97s
Train Epoch: 461 [61440/90000 (68%)]	Loss: 14.8744	Cost: 5.83s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 14.6286	Cost: 5.67s
Train Epoch: 461 	Average Loss: 14.8844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5256

Learning rate: 0.000198953082744812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 16.2595	Cost: 20.07s
Train Epoch: 462 [20480/90000 (23%)]	Loss: 14.6515	Cost: 6.09s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 14.7366	Cost: 6.38s
Train Epoch: 462 [61440/90000 (68%)]	Loss: 14.6456	Cost: 5.89s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 14.8452	Cost: 5.74s
Train Epoch: 462 	Average Loss: 14.8719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5068

Learning rate: 0.0001989485438630813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 16.2688	Cost: 22.71s
Train Epoch: 463 [20480/90000 (23%)]	Loss: 14.7459	Cost: 5.92s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 14.7491	Cost: 6.18s
Train Epoch: 463 [61440/90000 (68%)]	Loss: 14.6496	Cost: 5.87s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 14.6855	Cost: 6.03s
Train Epoch: 463 	Average Loss: 14.8528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4824

Learning rate: 0.00019894399521552084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 16.1068	Cost: 21.13s
Train Epoch: 464 [20480/90000 (23%)]	Loss: 14.7492	Cost: 6.01s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 14.9719	Cost: 6.24s
Train Epoch: 464 [61440/90000 (68%)]	Loss: 14.6899	Cost: 5.93s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 14.7306	Cost: 6.00s
Train Epoch: 464 	Average Loss: 14.8727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4409

Learning rate: 0.0001989394368025795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 16.3004	Cost: 20.47s
Train Epoch: 465 [20480/90000 (23%)]	Loss: 14.7105	Cost: 5.94s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 14.8110	Cost: 6.04s
Train Epoch: 465 [61440/90000 (68%)]	Loss: 14.7353	Cost: 5.98s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 14.8020	Cost: 5.66s
Train Epoch: 465 	Average Loss: 14.8863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5069

Learning rate: 0.0001989348686247073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 16.4255	Cost: 20.02s
Train Epoch: 466 [20480/90000 (23%)]	Loss: 14.5809	Cost: 6.18s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 14.7619	Cost: 6.89s
Train Epoch: 466 [61440/90000 (68%)]	Loss: 14.8429	Cost: 5.85s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 14.5354	Cost: 6.59s
Train Epoch: 466 	Average Loss: 14.8416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4936

Learning rate: 0.000198930290682355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 16.1892	Cost: 19.73s
Train Epoch: 467 [20480/90000 (23%)]	Loss: 14.4664	Cost: 5.77s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 14.7184	Cost: 6.29s
Train Epoch: 467 [61440/90000 (68%)]	Loss: 14.7299	Cost: 5.67s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 14.9574	Cost: 6.28s
Train Epoch: 467 	Average Loss: 14.8312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5186

Learning rate: 0.00019892570297597447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 16.3522	Cost: 19.75s
Train Epoch: 468 [20480/90000 (23%)]	Loss: 14.6941	Cost: 6.11s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 14.7028	Cost: 6.18s
Train Epoch: 468 [61440/90000 (68%)]	Loss: 14.5574	Cost: 5.95s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 14.7633	Cost: 5.74s
Train Epoch: 468 	Average Loss: 14.8144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5831

Learning rate: 0.00019892110550601846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 16.2014	Cost: 19.96s
Train Epoch: 469 [20480/90000 (23%)]	Loss: 14.7287	Cost: 6.16s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 14.7311	Cost: 6.09s
Train Epoch: 469 [61440/90000 (68%)]	Loss: 14.7464	Cost: 6.08s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 14.5710	Cost: 5.69s
Train Epoch: 469 	Average Loss: 14.8087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5488

Learning rate: 0.00019891649827294077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 16.2485	Cost: 19.63s
Train Epoch: 470 [20480/90000 (23%)]	Loss: 14.6518	Cost: 6.06s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 14.7743	Cost: 6.30s
Train Epoch: 470 [61440/90000 (68%)]	Loss: 14.5568	Cost: 5.88s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 14.7892	Cost: 6.22s
Train Epoch: 470 	Average Loss: 14.7913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5548

Learning rate: 0.00019891188127719607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 16.2862	Cost: 20.79s
Train Epoch: 471 [20480/90000 (23%)]	Loss: 14.4849	Cost: 6.05s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 14.6124	Cost: 6.72s
Train Epoch: 471 [61440/90000 (68%)]	Loss: 14.5594	Cost: 5.77s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 14.6631	Cost: 6.15s
Train Epoch: 471 	Average Loss: 14.7825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4886

Learning rate: 0.00019890725451924011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 16.1536	Cost: 19.93s
Train Epoch: 472 [20480/90000 (23%)]	Loss: 14.6430	Cost: 6.76s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 14.6938	Cost: 6.77s
Train Epoch: 472 [61440/90000 (68%)]	Loss: 14.7163	Cost: 6.54s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 14.6167	Cost: 6.31s
Train Epoch: 472 	Average Loss: 14.7958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5858

Learning rate: 0.00019890261799952944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 16.3302	Cost: 20.32s
Train Epoch: 473 [20480/90000 (23%)]	Loss: 14.6751	Cost: 6.07s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 14.7452	Cost: 6.16s
Train Epoch: 473 [61440/90000 (68%)]	Loss: 14.6011	Cost: 5.65s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 14.4292	Cost: 5.50s
Train Epoch: 473 	Average Loss: 14.8029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5420

Learning rate: 0.00019889797171852172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 16.4676	Cost: 20.66s
Train Epoch: 474 [20480/90000 (23%)]	Loss: 14.5507	Cost: 6.23s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 14.6763	Cost: 6.19s
Train Epoch: 474 [61440/90000 (68%)]	Loss: 14.5646	Cost: 5.81s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 14.6736	Cost: 5.76s
Train Epoch: 474 	Average Loss: 14.7973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5098

Learning rate: 0.0001988933156766755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 16.1990	Cost: 21.05s
Train Epoch: 475 [20480/90000 (23%)]	Loss: 14.6763	Cost: 5.98s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 14.6747	Cost: 6.58s
Train Epoch: 475 [61440/90000 (68%)]	Loss: 14.5586	Cost: 5.81s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 14.7434	Cost: 5.80s
Train Epoch: 475 	Average Loss: 14.7842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5017

Learning rate: 0.00019888864987445035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 16.4028	Cost: 20.82s
Train Epoch: 476 [20480/90000 (23%)]	Loss: 14.3922	Cost: 5.95s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 14.7416	Cost: 6.79s
Train Epoch: 476 [61440/90000 (68%)]	Loss: 14.6130	Cost: 5.96s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 14.6703	Cost: 5.70s
Train Epoch: 476 	Average Loss: 14.7630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4707

Learning rate: 0.00019888397431230674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 16.1883	Cost: 22.60s
Train Epoch: 477 [20480/90000 (23%)]	Loss: 14.5977	Cost: 5.93s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 14.5359	Cost: 6.85s
Train Epoch: 477 [61440/90000 (68%)]	Loss: 14.6816	Cost: 5.81s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 14.6554	Cost: 5.88s
Train Epoch: 477 	Average Loss: 14.7397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5396

Learning rate: 0.00019887928899070613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 16.4154	Cost: 19.37s
Train Epoch: 478 [20480/90000 (23%)]	Loss: 14.5160	Cost: 5.99s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 14.7337	Cost: 6.00s
Train Epoch: 478 [61440/90000 (68%)]	Loss: 14.5182	Cost: 5.86s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 14.5651	Cost: 5.68s
Train Epoch: 478 	Average Loss: 14.7449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6434

Learning rate: 0.00019887459391011093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 16.3094	Cost: 21.27s
Train Epoch: 479 [20480/90000 (23%)]	Loss: 14.6206	Cost: 6.01s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 14.6986	Cost: 6.05s
Train Epoch: 479 [61440/90000 (68%)]	Loss: 14.6126	Cost: 5.88s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 14.7116	Cost: 5.94s
Train Epoch: 479 	Average Loss: 14.7673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5987

Learning rate: 0.0001988698890709845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 16.3274	Cost: 20.14s
Train Epoch: 480 [20480/90000 (23%)]	Loss: 14.5808	Cost: 6.06s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 14.7949	Cost: 6.03s
Train Epoch: 480 [61440/90000 (68%)]	Loss: 14.6229	Cost: 5.86s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 14.6275	Cost: 5.68s
Train Epoch: 480 	Average Loss: 14.7711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5731

Learning rate: 0.0001988651744737913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 16.2551	Cost: 20.26s
Train Epoch: 481 [20480/90000 (23%)]	Loss: 14.5810	Cost: 6.04s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 14.5339	Cost: 6.21s
Train Epoch: 481 [61440/90000 (68%)]	Loss: 14.5426	Cost: 5.88s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 14.5811	Cost: 5.91s
Train Epoch: 481 	Average Loss: 14.7292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5601

Learning rate: 0.00019886045011899655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 16.2324	Cost: 21.09s
Train Epoch: 482 [20480/90000 (23%)]	Loss: 14.3761	Cost: 5.99s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 14.6931	Cost: 6.37s
Train Epoch: 482 [61440/90000 (68%)]	Loss: 14.5879	Cost: 5.84s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 14.5831	Cost: 5.67s
Train Epoch: 482 	Average Loss: 14.7434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5847

Learning rate: 0.00019885571600706652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 16.4356	Cost: 21.05s
Train Epoch: 483 [20480/90000 (23%)]	Loss: 14.5759	Cost: 6.05s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 14.5970	Cost: 6.04s
Train Epoch: 483 [61440/90000 (68%)]	Loss: 14.5209	Cost: 5.88s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 14.5893	Cost: 5.73s
Train Epoch: 483 	Average Loss: 14.7067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6123

Learning rate: 0.00019885097213846847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 16.3373	Cost: 20.97s
Train Epoch: 484 [20480/90000 (23%)]	Loss: 14.5616	Cost: 6.08s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 14.6933	Cost: 6.47s
Train Epoch: 484 [61440/90000 (68%)]	Loss: 14.5103	Cost: 5.87s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 14.7595	Cost: 5.71s
Train Epoch: 484 	Average Loss: 14.7191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5540

Learning rate: 0.00019884621851367065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 16.6684	Cost: 20.60s
Train Epoch: 485 [20480/90000 (23%)]	Loss: 14.4449	Cost: 5.95s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 14.6502	Cost: 6.23s
Train Epoch: 485 [61440/90000 (68%)]	Loss: 14.6909	Cost: 6.13s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 14.6807	Cost: 6.05s
Train Epoch: 485 	Average Loss: 14.7766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5672

Learning rate: 0.00019884145513314214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 16.3809	Cost: 21.43s
Train Epoch: 486 [20480/90000 (23%)]	Loss: 14.5712	Cost: 5.93s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 14.4967	Cost: 6.78s
Train Epoch: 486 [61440/90000 (68%)]	Loss: 14.3547	Cost: 5.84s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 14.6085	Cost: 6.03s
Train Epoch: 486 	Average Loss: 14.7375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5981

Learning rate: 0.00019883668199735307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 16.4729	Cost: 21.45s
Train Epoch: 487 [20480/90000 (23%)]	Loss: 14.4837	Cost: 5.99s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 14.5543	Cost: 6.60s
Train Epoch: 487 [61440/90000 (68%)]	Loss: 14.3847	Cost: 6.04s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 14.4718	Cost: 6.33s
Train Epoch: 487 	Average Loss: 14.6921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6480

Learning rate: 0.00019883189910677464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 16.4257	Cost: 21.35s
Train Epoch: 488 [20480/90000 (23%)]	Loss: 14.6184	Cost: 6.03s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 14.4856	Cost: 6.41s
Train Epoch: 488 [61440/90000 (68%)]	Loss: 14.5283	Cost: 5.89s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 14.5288	Cost: 6.63s
Train Epoch: 488 	Average Loss: 14.7058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5745

Learning rate: 0.00019882710646187875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 16.5265	Cost: 20.12s
Train Epoch: 489 [20480/90000 (23%)]	Loss: 14.5173	Cost: 6.04s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 14.5071	Cost: 6.55s
Train Epoch: 489 [61440/90000 (68%)]	Loss: 14.4123	Cost: 5.96s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 14.7006	Cost: 6.04s
Train Epoch: 489 	Average Loss: 14.7101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5593

Learning rate: 0.00019882230406313855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 16.4260	Cost: 21.05s
Train Epoch: 490 [20480/90000 (23%)]	Loss: 14.5909	Cost: 6.23s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 14.4514	Cost: 6.28s
Train Epoch: 490 [61440/90000 (68%)]	Loss: 14.5365	Cost: 6.11s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 14.4884	Cost: 6.10s
Train Epoch: 490 	Average Loss: 14.6712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5786

Learning rate: 0.00019881749191102795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 16.2809	Cost: 20.63s
Train Epoch: 491 [20480/90000 (23%)]	Loss: 14.4434	Cost: 6.00s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 14.7612	Cost: 6.33s
Train Epoch: 491 [61440/90000 (68%)]	Loss: 14.5588	Cost: 6.11s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 14.5073	Cost: 6.63s
Train Epoch: 491 	Average Loss: 14.6937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4944

Learning rate: 0.00019881267000602186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 16.3634	Cost: 19.97s
Train Epoch: 492 [20480/90000 (23%)]	Loss: 14.4170	Cost: 6.13s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 14.6472	Cost: 6.05s
Train Epoch: 492 [61440/90000 (68%)]	Loss: 14.4302	Cost: 5.94s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 14.5350	Cost: 5.93s
Train Epoch: 492 	Average Loss: 14.6205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4964

Learning rate: 0.00019880783834859626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 16.4212	Cost: 19.32s
Train Epoch: 493 [20480/90000 (23%)]	Loss: 14.3330	Cost: 6.09s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 14.4904	Cost: 6.08s
Train Epoch: 493 [61440/90000 (68%)]	Loss: 14.3959	Cost: 6.07s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 14.6134	Cost: 6.07s
Train Epoch: 493 	Average Loss: 14.6555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5760

Learning rate: 0.000198802996939228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 16.4378	Cost: 20.47s
Train Epoch: 494 [20480/90000 (23%)]	Loss: 14.4027	Cost: 5.96s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 14.6380	Cost: 6.92s
Train Epoch: 494 [61440/90000 (68%)]	Loss: 14.4842	Cost: 5.81s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 14.6652	Cost: 5.96s
Train Epoch: 494 	Average Loss: 14.6729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6784

Learning rate: 0.0001987981457783948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 16.4076	Cost: 21.53s
Train Epoch: 495 [20480/90000 (23%)]	Loss: 14.4230	Cost: 5.95s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 14.5107	Cost: 6.66s
Train Epoch: 495 [61440/90000 (68%)]	Loss: 14.3619	Cost: 5.87s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 14.3274	Cost: 7.09s
Train Epoch: 495 	Average Loss: 14.6356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6467

Learning rate: 0.00019879328486657562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 16.3516	Cost: 20.72s
Train Epoch: 496 [20480/90000 (23%)]	Loss: 14.6168	Cost: 6.03s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 14.6373	Cost: 6.80s
Train Epoch: 496 [61440/90000 (68%)]	Loss: 14.3957	Cost: 5.93s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 14.5888	Cost: 7.07s
Train Epoch: 496 	Average Loss: 14.6553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6031

Learning rate: 0.0001987884142042501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 16.4290	Cost: 21.38s
Train Epoch: 497 [20480/90000 (23%)]	Loss: 14.3559	Cost: 6.44s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 14.5350	Cost: 6.84s
Train Epoch: 497 [61440/90000 (68%)]	Loss: 14.3433	Cost: 6.38s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 14.3817	Cost: 5.85s
Train Epoch: 497 	Average Loss: 14.6373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5715

Learning rate: 0.00019878353379189899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 16.2778	Cost: 21.33s
Train Epoch: 498 [20480/90000 (23%)]	Loss: 14.4277	Cost: 5.99s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 14.6091	Cost: 7.03s
Train Epoch: 498 [61440/90000 (68%)]	Loss: 14.3414	Cost: 6.04s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 14.4833	Cost: 7.72s
Train Epoch: 498 	Average Loss: 14.6190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7123

Learning rate: 0.00019877864363000396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 16.3385	Cost: 20.43s
Train Epoch: 499 [20480/90000 (23%)]	Loss: 14.6779	Cost: 6.05s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 14.5729	Cost: 6.21s
Train Epoch: 499 [61440/90000 (68%)]	Loss: 14.4791	Cost: 5.89s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 14.5085	Cost: 6.59s
Train Epoch: 499 	Average Loss: 14.6155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5851

Learning rate: 0.00019877374371904765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 16.3674	Cost: 21.68s
Train Epoch: 500 [20480/90000 (23%)]	Loss: 14.3462	Cost: 6.06s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 14.4799	Cost: 6.12s
Train Epoch: 500 [61440/90000 (68%)]	Loss: 14.3795	Cost: 5.89s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 14.3507	Cost: 6.86s
Train Epoch: 500 	Average Loss: 14.6113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6149

Learning rate: 0.00019876883405951367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: 16.4439	Cost: 19.48s
Train Epoch: 501 [20480/90000 (23%)]	Loss: 14.1759	Cost: 6.07s
Train Epoch: 501 [40960/90000 (45%)]	Loss: 14.5508	Cost: 6.21s
Train Epoch: 501 [61440/90000 (68%)]	Loss: 14.4004	Cost: 5.98s
Train Epoch: 501 [81920/90000 (91%)]	Loss: 14.6525	Cost: 6.41s
Train Epoch: 501 	Average Loss: 14.6080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5869

Learning rate: 0.00019876391465188656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: 16.3664	Cost: 21.46s
Train Epoch: 502 [20480/90000 (23%)]	Loss: 14.2193	Cost: 5.98s
Train Epoch: 502 [40960/90000 (45%)]	Loss: 14.6093	Cost: 6.20s
Train Epoch: 502 [61440/90000 (68%)]	Loss: 14.4005	Cost: 5.98s
Train Epoch: 502 [81920/90000 (91%)]	Loss: 14.4189	Cost: 6.41s
Train Epoch: 502 	Average Loss: 14.6101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7008

Learning rate: 0.00019875898549665186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: 16.4282	Cost: 20.34s
Train Epoch: 503 [20480/90000 (23%)]	Loss: 14.4185	Cost: 5.99s
Train Epoch: 503 [40960/90000 (45%)]	Loss: 14.4665	Cost: 6.15s
Train Epoch: 503 [61440/90000 (68%)]	Loss: 14.4951	Cost: 5.96s
Train Epoch: 503 [81920/90000 (91%)]	Loss: 14.4430	Cost: 5.95s
Train Epoch: 503 	Average Loss: 14.6582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5981

Learning rate: 0.0001987540465942961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: 16.3300	Cost: 20.25s
Train Epoch: 504 [20480/90000 (23%)]	Loss: 14.5042	Cost: 6.00s
Train Epoch: 504 [40960/90000 (45%)]	Loss: 14.5790	Cost: 6.00s
Train Epoch: 504 [61440/90000 (68%)]	Loss: 14.5435	Cost: 6.03s
Train Epoch: 504 [81920/90000 (91%)]	Loss: 14.4157	Cost: 7.28s
Train Epoch: 504 	Average Loss: 14.6117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7193

Learning rate: 0.00019874909794530664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: 16.5749	Cost: 20.23s
Train Epoch: 505 [20480/90000 (23%)]	Loss: 14.3409	Cost: 6.44s
Train Epoch: 505 [40960/90000 (45%)]	Loss: 14.2708	Cost: 6.22s
Train Epoch: 505 [61440/90000 (68%)]	Loss: 14.5860	Cost: 5.94s
Train Epoch: 505 [81920/90000 (91%)]	Loss: 14.5257	Cost: 7.44s
Train Epoch: 505 	Average Loss: 14.5928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6892

Learning rate: 0.00019874413955017195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: 16.5386	Cost: 20.26s
Train Epoch: 506 [20480/90000 (23%)]	Loss: 14.3971	Cost: 6.04s
Train Epoch: 506 [40960/90000 (45%)]	Loss: 14.4725	Cost: 6.36s
Train Epoch: 506 [61440/90000 (68%)]	Loss: 14.4536	Cost: 6.27s
Train Epoch: 506 [81920/90000 (91%)]	Loss: 14.4330	Cost: 6.42s
Train Epoch: 506 	Average Loss: 14.5648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5637

Learning rate: 0.00019873917140938142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: 16.3313	Cost: 19.83s
Train Epoch: 507 [20480/90000 (23%)]	Loss: 14.1970	Cost: 6.09s
Train Epoch: 507 [40960/90000 (45%)]	Loss: 14.4755	Cost: 6.48s
Train Epoch: 507 [61440/90000 (68%)]	Loss: 14.1284	Cost: 6.02s
Train Epoch: 507 [81920/90000 (91%)]	Loss: 14.3720	Cost: 7.53s
Train Epoch: 507 	Average Loss: 14.5777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5952

Learning rate: 0.00019873419352342536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: 16.3822	Cost: 20.59s
Train Epoch: 508 [20480/90000 (23%)]	Loss: 14.3143	Cost: 6.09s
Train Epoch: 508 [40960/90000 (45%)]	Loss: 14.5613	Cost: 6.06s
Train Epoch: 508 [61440/90000 (68%)]	Loss: 14.3966	Cost: 6.05s
Train Epoch: 508 [81920/90000 (91%)]	Loss: 14.4495	Cost: 6.57s
Train Epoch: 508 	Average Loss: 14.5657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6779

Learning rate: 0.00019872920589279508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: 16.3401	Cost: 20.68s
Train Epoch: 509 [20480/90000 (23%)]	Loss: 14.1184	Cost: 6.23s
Train Epoch: 509 [40960/90000 (45%)]	Loss: 14.4334	Cost: 6.14s
Train Epoch: 509 [61440/90000 (68%)]	Loss: 14.2323	Cost: 6.21s
Train Epoch: 509 [81920/90000 (91%)]	Loss: 14.4983	Cost: 6.89s
Train Epoch: 509 	Average Loss: 14.5589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7157

Learning rate: 0.0001987242085179828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: 16.2424	Cost: 20.16s
Train Epoch: 510 [20480/90000 (23%)]	Loss: 14.3599	Cost: 6.37s
Train Epoch: 510 [40960/90000 (45%)]	Loss: 14.4131	Cost: 6.14s
Train Epoch: 510 [61440/90000 (68%)]	Loss: 14.2604	Cost: 6.10s
Train Epoch: 510 [81920/90000 (91%)]	Loss: 14.3210	Cost: 6.98s
Train Epoch: 510 	Average Loss: 14.5064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6319

Learning rate: 0.00019871920139948181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: 16.2841	Cost: 21.00s
Train Epoch: 511 [20480/90000 (23%)]	Loss: 14.2541	Cost: 6.02s
Train Epoch: 511 [40960/90000 (45%)]	Loss: 14.4064	Cost: 6.26s
Train Epoch: 511 [61440/90000 (68%)]	Loss: 14.2978	Cost: 6.06s
Train Epoch: 511 [81920/90000 (91%)]	Loss: 14.4661	Cost: 8.13s
Train Epoch: 511 	Average Loss: 14.5591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7539

Learning rate: 0.00019871418453778627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: 16.4490	Cost: 20.30s
Train Epoch: 512 [20480/90000 (23%)]	Loss: 14.4640	Cost: 5.75s
Train Epoch: 512 [40960/90000 (45%)]	Loss: 14.4576	Cost: 6.13s
Train Epoch: 512 [61440/90000 (68%)]	Loss: 14.2523	Cost: 5.82s
Train Epoch: 512 [81920/90000 (91%)]	Loss: 14.4285	Cost: 6.91s
Train Epoch: 512 	Average Loss: 14.5691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6529

Learning rate: 0.00019870915793339126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: 16.2012	Cost: 20.36s
Train Epoch: 513 [20480/90000 (23%)]	Loss: 14.3581	Cost: 6.01s
Train Epoch: 513 [40960/90000 (45%)]	Loss: 14.2732	Cost: 6.61s
Train Epoch: 513 [61440/90000 (68%)]	Loss: 14.2396	Cost: 6.07s
Train Epoch: 513 [81920/90000 (91%)]	Loss: 14.2780	Cost: 7.18s
Train Epoch: 513 	Average Loss: 14.4948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6246

Learning rate: 0.00019870412158679292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: 16.3291	Cost: 21.35s
Train Epoch: 514 [20480/90000 (23%)]	Loss: 14.1915	Cost: 6.02s
Train Epoch: 514 [40960/90000 (45%)]	Loss: 14.4096	Cost: 6.11s
Train Epoch: 514 [61440/90000 (68%)]	Loss: 14.2188	Cost: 6.10s
Train Epoch: 514 [81920/90000 (91%)]	Loss: 14.4606	Cost: 7.34s
Train Epoch: 514 	Average Loss: 14.5203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6414

Learning rate: 0.00019869907549848836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: 16.3367	Cost: 19.87s
Train Epoch: 515 [20480/90000 (23%)]	Loss: 14.2921	Cost: 5.98s
Train Epoch: 515 [40960/90000 (45%)]	Loss: 14.3809	Cost: 6.06s
Train Epoch: 515 [61440/90000 (68%)]	Loss: 14.3330	Cost: 5.96s
Train Epoch: 515 [81920/90000 (91%)]	Loss: 14.2663	Cost: 6.43s
Train Epoch: 515 	Average Loss: 14.5291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6027

Learning rate: 0.0001986940196689756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: 16.3515	Cost: 21.68s
Train Epoch: 516 [20480/90000 (23%)]	Loss: 14.3086	Cost: 6.12s
Train Epoch: 516 [40960/90000 (45%)]	Loss: 14.2517	Cost: 6.07s
Train Epoch: 516 [61440/90000 (68%)]	Loss: 14.4391	Cost: 5.95s
Train Epoch: 516 [81920/90000 (91%)]	Loss: 14.5514	Cost: 7.39s
Train Epoch: 516 	Average Loss: 14.4759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5863

Learning rate: 0.00019868895409875357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: 16.5814	Cost: 19.84s
Train Epoch: 517 [20480/90000 (23%)]	Loss: 14.1603	Cost: 6.09s
Train Epoch: 517 [40960/90000 (45%)]	Loss: 14.4284	Cost: 6.07s
Train Epoch: 517 [61440/90000 (68%)]	Loss: 14.4273	Cost: 5.98s
Train Epoch: 517 [81920/90000 (91%)]	Loss: 14.4368	Cost: 6.13s
Train Epoch: 517 	Average Loss: 14.4770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6740

Learning rate: 0.00019868387878832229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: 16.5781	Cost: 21.32s
Train Epoch: 518 [20480/90000 (23%)]	Loss: 14.1374	Cost: 6.35s
Train Epoch: 518 [40960/90000 (45%)]	Loss: 14.4674	Cost: 6.15s
Train Epoch: 518 [61440/90000 (68%)]	Loss: 14.1664	Cost: 6.08s
Train Epoch: 518 [81920/90000 (91%)]	Loss: 14.2719	Cost: 6.52s
Train Epoch: 518 	Average Loss: 14.4821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6248

Learning rate: 0.00019867879373818264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: 16.5534	Cost: 20.35s
Train Epoch: 519 [20480/90000 (23%)]	Loss: 14.2350	Cost: 6.12s
Train Epoch: 519 [40960/90000 (45%)]	Loss: 14.2254	Cost: 6.32s
Train Epoch: 519 [61440/90000 (68%)]	Loss: 14.1993	Cost: 6.42s
Train Epoch: 519 [81920/90000 (91%)]	Loss: 14.2805	Cost: 6.03s
Train Epoch: 519 	Average Loss: 14.4715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6910

Learning rate: 0.00019867369894883648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: 16.3530	Cost: 20.80s
Train Epoch: 520 [20480/90000 (23%)]	Loss: 14.2985	Cost: 6.06s
Train Epoch: 520 [40960/90000 (45%)]	Loss: 14.4205	Cost: 7.04s
Train Epoch: 520 [61440/90000 (68%)]	Loss: 14.3279	Cost: 6.13s
Train Epoch: 520 [81920/90000 (91%)]	Loss: 14.3587	Cost: 6.27s
Train Epoch: 520 	Average Loss: 14.4829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6737

Learning rate: 0.0001986685944207867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: 16.5636	Cost: 20.36s
Train Epoch: 521 [20480/90000 (23%)]	Loss: 14.4108	Cost: 6.06s
Train Epoch: 521 [40960/90000 (45%)]	Loss: 14.2582	Cost: 6.04s
Train Epoch: 521 [61440/90000 (68%)]	Loss: 14.3149	Cost: 5.93s
Train Epoch: 521 [81920/90000 (91%)]	Loss: 14.2798	Cost: 6.35s
Train Epoch: 521 	Average Loss: 14.4386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6884

Learning rate: 0.00019866348015453705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 16.5068	Cost: 22.14s
Train Epoch: 522 [20480/90000 (23%)]	Loss: 14.2411	Cost: 5.98s
Train Epoch: 522 [40960/90000 (45%)]	Loss: 14.2105	Cost: 6.57s
Train Epoch: 522 [61440/90000 (68%)]	Loss: 14.2240	Cost: 5.97s
Train Epoch: 522 [81920/90000 (91%)]	Loss: 14.3645	Cost: 7.08s
Train Epoch: 522 	Average Loss: 14.4485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8008

Learning rate: 0.0001986583561505923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: 16.2587	Cost: 20.02s
Train Epoch: 523 [20480/90000 (23%)]	Loss: 14.3050	Cost: 6.09s
Train Epoch: 523 [40960/90000 (45%)]	Loss: 14.3562	Cost: 5.99s
Train Epoch: 523 [61440/90000 (68%)]	Loss: 14.1980	Cost: 5.89s
Train Epoch: 523 [81920/90000 (91%)]	Loss: 14.2985	Cost: 5.95s
Train Epoch: 523 	Average Loss: 14.4636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7728

Learning rate: 0.0001986532224094582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: 16.3970	Cost: 21.93s
Train Epoch: 524 [20480/90000 (23%)]	Loss: 14.3435	Cost: 6.02s
Train Epoch: 524 [40960/90000 (45%)]	Loss: 14.2906	Cost: 6.56s
Train Epoch: 524 [61440/90000 (68%)]	Loss: 14.2594	Cost: 5.91s
Train Epoch: 524 [81920/90000 (91%)]	Loss: 14.3432	Cost: 5.90s
Train Epoch: 524 	Average Loss: 14.4387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6554

Learning rate: 0.00019864807893164133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: 16.4580	Cost: 20.92s
Train Epoch: 525 [20480/90000 (23%)]	Loss: 14.1125	Cost: 6.13s
Train Epoch: 525 [40960/90000 (45%)]	Loss: 14.2245	Cost: 6.07s
Train Epoch: 525 [61440/90000 (68%)]	Loss: 14.1818	Cost: 5.85s
Train Epoch: 525 [81920/90000 (91%)]	Loss: 14.1951	Cost: 6.23s
Train Epoch: 525 	Average Loss: 14.4266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6350

Learning rate: 0.00019864292571764947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: 16.3488	Cost: 20.47s
Train Epoch: 526 [20480/90000 (23%)]	Loss: 14.0532	Cost: 5.85s
Train Epoch: 526 [40960/90000 (45%)]	Loss: 14.0729	Cost: 7.70s
Train Epoch: 526 [61440/90000 (68%)]	Loss: 14.1620	Cost: 5.83s
Train Epoch: 526 [81920/90000 (91%)]	Loss: 14.2922	Cost: 6.53s
Train Epoch: 526 	Average Loss: 14.3907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7051

Learning rate: 0.00019863776276799112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: 16.5095	Cost: 21.58s
Train Epoch: 527 [20480/90000 (23%)]	Loss: 14.1543	Cost: 6.00s
Train Epoch: 527 [40960/90000 (45%)]	Loss: 14.3720	Cost: 6.30s
Train Epoch: 527 [61440/90000 (68%)]	Loss: 14.1464	Cost: 5.88s
Train Epoch: 527 [81920/90000 (91%)]	Loss: 14.1658	Cost: 5.76s
Train Epoch: 527 	Average Loss: 14.4106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7281

Learning rate: 0.00019863259008317586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: 16.3312	Cost: 21.44s
Train Epoch: 528 [20480/90000 (23%)]	Loss: 14.0975	Cost: 6.04s
Train Epoch: 528 [40960/90000 (45%)]	Loss: 14.1869	Cost: 6.40s
Train Epoch: 528 [61440/90000 (68%)]	Loss: 14.2591	Cost: 5.92s
Train Epoch: 528 [81920/90000 (91%)]	Loss: 14.4001	Cost: 6.16s
Train Epoch: 528 	Average Loss: 14.4293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7301

Learning rate: 0.00019862740766371425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: 16.6486	Cost: 21.16s
Train Epoch: 529 [20480/90000 (23%)]	Loss: 14.2953	Cost: 5.99s
Train Epoch: 529 [40960/90000 (45%)]	Loss: 14.2989	Cost: 6.49s
Train Epoch: 529 [61440/90000 (68%)]	Loss: 14.1459	Cost: 5.83s
Train Epoch: 529 [81920/90000 (91%)]	Loss: 14.2433	Cost: 6.31s
Train Epoch: 529 	Average Loss: 14.4088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7192

Learning rate: 0.00019862221551011772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: 16.2514	Cost: 19.63s
Train Epoch: 530 [20480/90000 (23%)]	Loss: 14.2273	Cost: 6.08s
Train Epoch: 530 [40960/90000 (45%)]	Loss: 14.1366	Cost: 6.06s
Train Epoch: 530 [61440/90000 (68%)]	Loss: 14.0881	Cost: 5.94s
Train Epoch: 530 [81920/90000 (91%)]	Loss: 14.2350	Cost: 5.82s
Train Epoch: 530 	Average Loss: 14.4080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7462

Learning rate: 0.0001986170136228988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: 16.4317	Cost: 21.08s
Train Epoch: 531 [20480/90000 (23%)]	Loss: 14.2334	Cost: 6.06s
Train Epoch: 531 [40960/90000 (45%)]	Loss: 14.3985	Cost: 6.15s
Train Epoch: 531 [61440/90000 (68%)]	Loss: 14.2925	Cost: 6.54s
Train Epoch: 531 [81920/90000 (91%)]	Loss: 14.3489	Cost: 5.94s
Train Epoch: 531 	Average Loss: 14.4027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7183

Learning rate: 0.00019861180200257079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: 16.4971	Cost: 21.00s
Train Epoch: 532 [20480/90000 (23%)]	Loss: 14.1453	Cost: 6.06s
Train Epoch: 532 [40960/90000 (45%)]	Loss: 14.2163	Cost: 6.36s
Train Epoch: 532 [61440/90000 (68%)]	Loss: 14.0489	Cost: 5.93s
Train Epoch: 532 [81920/90000 (91%)]	Loss: 14.1004	Cost: 6.28s
Train Epoch: 532 	Average Loss: 14.3817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7591

Learning rate: 0.00019860658064964812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: 16.5574	Cost: 21.59s
Train Epoch: 533 [20480/90000 (23%)]	Loss: 14.2243	Cost: 6.09s
Train Epoch: 533 [40960/90000 (45%)]	Loss: 14.2718	Cost: 6.48s
Train Epoch: 533 [61440/90000 (68%)]	Loss: 14.2405	Cost: 5.90s
Train Epoch: 533 [81920/90000 (91%)]	Loss: 14.2958	Cost: 6.22s
Train Epoch: 533 	Average Loss: 14.4110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7386

Learning rate: 0.0001986013495646461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: 16.3580	Cost: 19.53s
Train Epoch: 534 [20480/90000 (23%)]	Loss: 14.1055	Cost: 6.10s
Train Epoch: 534 [40960/90000 (45%)]	Loss: 14.1916	Cost: 6.06s
Train Epoch: 534 [61440/90000 (68%)]	Loss: 14.2587	Cost: 5.92s
Train Epoch: 534 [81920/90000 (91%)]	Loss: 14.2746	Cost: 5.86s
Train Epoch: 534 	Average Loss: 14.4143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7131

Learning rate: 0.00019859610874808106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: 16.4911	Cost: 21.15s
Train Epoch: 535 [20480/90000 (23%)]	Loss: 14.0364	Cost: 6.48s
Train Epoch: 535 [40960/90000 (45%)]	Loss: 14.2717	Cost: 6.02s
Train Epoch: 535 [61440/90000 (68%)]	Loss: 14.1754	Cost: 5.89s
Train Epoch: 535 [81920/90000 (91%)]	Loss: 14.2551	Cost: 6.00s
Train Epoch: 535 	Average Loss: 14.3893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7458

Learning rate: 0.0001985908582004702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: 16.6261	Cost: 21.32s
Train Epoch: 536 [20480/90000 (23%)]	Loss: 14.1822	Cost: 6.28s
Train Epoch: 536 [40960/90000 (45%)]	Loss: 14.2390	Cost: 6.04s
Train Epoch: 536 [61440/90000 (68%)]	Loss: 14.2290	Cost: 5.92s
Train Epoch: 536 [81920/90000 (91%)]	Loss: 14.1780	Cost: 6.08s
Train Epoch: 536 	Average Loss: 14.3451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6891

Learning rate: 0.00019858559792233175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: 16.3290	Cost: 21.11s
Train Epoch: 537 [20480/90000 (23%)]	Loss: 14.0562	Cost: 6.06s
Train Epoch: 537 [40960/90000 (45%)]	Loss: 14.2643	Cost: 6.65s
Train Epoch: 537 [61440/90000 (68%)]	Loss: 14.0962	Cost: 5.92s
Train Epoch: 537 [81920/90000 (91%)]	Loss: 14.1023	Cost: 6.65s
Train Epoch: 537 	Average Loss: 14.3418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7587

Learning rate: 0.00019858032791418486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: 16.4800	Cost: 19.99s
Train Epoch: 538 [20480/90000 (23%)]	Loss: 14.0790	Cost: 6.03s
Train Epoch: 538 [40960/90000 (45%)]	Loss: 14.1859	Cost: 6.01s
Train Epoch: 538 [61440/90000 (68%)]	Loss: 14.1496	Cost: 5.89s
Train Epoch: 538 [81920/90000 (91%)]	Loss: 14.3406	Cost: 5.86s
Train Epoch: 538 	Average Loss: 14.3367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8906

Learning rate: 0.00019857504817654965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: 16.6610	Cost: 21.63s
Train Epoch: 539 [20480/90000 (23%)]	Loss: 14.0200	Cost: 5.97s
Train Epoch: 539 [40960/90000 (45%)]	Loss: 14.1972	Cost: 6.45s
Train Epoch: 539 [61440/90000 (68%)]	Loss: 14.0981	Cost: 5.90s
Train Epoch: 539 [81920/90000 (91%)]	Loss: 14.3335	Cost: 6.51s
Train Epoch: 539 	Average Loss: 14.3567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7039

Learning rate: 0.00019856975870994725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: 16.4894	Cost: 21.83s
Train Epoch: 540 [20480/90000 (23%)]	Loss: 14.0595	Cost: 6.61s
Train Epoch: 540 [40960/90000 (45%)]	Loss: 14.2495	Cost: 6.29s
Train Epoch: 540 [61440/90000 (68%)]	Loss: 14.1687	Cost: 5.91s
Train Epoch: 540 [81920/90000 (91%)]	Loss: 14.1293	Cost: 5.89s
Train Epoch: 540 	Average Loss: 14.3191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7391

Learning rate: 0.0001985644595148997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: 16.5627	Cost: 19.90s
Train Epoch: 541 [20480/90000 (23%)]	Loss: 13.9923	Cost: 6.13s
Train Epoch: 541 [40960/90000 (45%)]	Loss: 14.1743	Cost: 6.09s
Train Epoch: 541 [61440/90000 (68%)]	Loss: 14.1594	Cost: 5.91s
Train Epoch: 541 [81920/90000 (91%)]	Loss: 14.1719	Cost: 6.45s
Train Epoch: 541 	Average Loss: 14.3366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7403

Learning rate: 0.00019855915059192997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: 16.6442	Cost: 20.08s
Train Epoch: 542 [20480/90000 (23%)]	Loss: 14.0939	Cost: 6.12s
Train Epoch: 542 [40960/90000 (45%)]	Loss: 14.1990	Cost: 6.11s
Train Epoch: 542 [61440/90000 (68%)]	Loss: 13.9947	Cost: 6.02s
Train Epoch: 542 [81920/90000 (91%)]	Loss: 14.3104	Cost: 5.82s
Train Epoch: 542 	Average Loss: 14.3399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8251

Learning rate: 0.00019855383194156202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: 16.6741	Cost: 20.80s
Train Epoch: 543 [20480/90000 (23%)]	Loss: 14.0976	Cost: 6.05s
Train Epoch: 543 [40960/90000 (45%)]	Loss: 14.2244	Cost: 6.08s
Train Epoch: 543 [61440/90000 (68%)]	Loss: 13.9088	Cost: 5.68s
Train Epoch: 543 [81920/90000 (91%)]	Loss: 14.2125	Cost: 6.25s
Train Epoch: 543 	Average Loss: 14.3209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7750

Learning rate: 0.00019854850356432085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: 16.6855	Cost: 21.96s
Train Epoch: 544 [20480/90000 (23%)]	Loss: 14.1388	Cost: 6.00s
Train Epoch: 544 [40960/90000 (45%)]	Loss: 14.0998	Cost: 6.46s
Train Epoch: 544 [61440/90000 (68%)]	Loss: 14.0650	Cost: 5.90s
Train Epoch: 544 [81920/90000 (91%)]	Loss: 14.0709	Cost: 6.22s
Train Epoch: 544 	Average Loss: 14.2877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7281

Learning rate: 0.00019854316546073235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: 16.6626	Cost: 21.48s
Train Epoch: 545 [20480/90000 (23%)]	Loss: 14.0927	Cost: 6.21s
Train Epoch: 545 [40960/90000 (45%)]	Loss: 14.0416	Cost: 6.03s
Train Epoch: 545 [61440/90000 (68%)]	Loss: 13.9804	Cost: 5.90s
Train Epoch: 545 [81920/90000 (91%)]	Loss: 13.9946	Cost: 5.87s
Train Epoch: 545 	Average Loss: 14.2690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7753

Learning rate: 0.0001985378176313233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: 16.5602	Cost: 21.80s
Train Epoch: 546 [20480/90000 (23%)]	Loss: 14.0486	Cost: 6.09s
Train Epoch: 546 [40960/90000 (45%)]	Loss: 14.1096	Cost: 6.34s
Train Epoch: 546 [61440/90000 (68%)]	Loss: 14.1611	Cost: 5.94s
Train Epoch: 546 [81920/90000 (91%)]	Loss: 14.3135	Cost: 5.99s
Train Epoch: 546 	Average Loss: 14.2786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8384

Learning rate: 0.00019853246007662156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: 16.6288	Cost: 20.06s
Train Epoch: 547 [20480/90000 (23%)]	Loss: 14.2122	Cost: 6.04s
Train Epoch: 547 [40960/90000 (45%)]	Loss: 13.9584	Cost: 6.35s
Train Epoch: 547 [61440/90000 (68%)]	Loss: 13.9304	Cost: 5.89s
Train Epoch: 547 [81920/90000 (91%)]	Loss: 14.1755	Cost: 6.04s
Train Epoch: 547 	Average Loss: 14.2741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7796

Learning rate: 0.0001985270927971559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: 16.6002	Cost: 21.87s
Train Epoch: 548 [20480/90000 (23%)]	Loss: 13.9467	Cost: 6.03s
Train Epoch: 548 [40960/90000 (45%)]	Loss: 14.1396	Cost: 6.25s
Train Epoch: 548 [61440/90000 (68%)]	Loss: 14.0779	Cost: 5.89s
Train Epoch: 548 [81920/90000 (91%)]	Loss: 14.0893	Cost: 6.01s
Train Epoch: 548 	Average Loss: 14.2602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8218

Learning rate: 0.00019852171579345603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: 16.4838	Cost: 20.67s
Train Epoch: 549 [20480/90000 (23%)]	Loss: 14.1132	Cost: 6.05s
Train Epoch: 549 [40960/90000 (45%)]	Loss: 14.1406	Cost: 6.13s
Train Epoch: 549 [61440/90000 (68%)]	Loss: 13.9141	Cost: 5.95s
Train Epoch: 549 [81920/90000 (91%)]	Loss: 13.9563	Cost: 5.99s
Train Epoch: 549 	Average Loss: 14.2417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7970

Learning rate: 0.0001985163290660526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: 16.5773	Cost: 22.27s
Train Epoch: 550 [20480/90000 (23%)]	Loss: 14.0025	Cost: 6.03s
Train Epoch: 550 [40960/90000 (45%)]	Loss: 14.1890	Cost: 6.76s
Train Epoch: 550 [61440/90000 (68%)]	Loss: 14.0415	Cost: 5.93s
Train Epoch: 550 [81920/90000 (91%)]	Loss: 14.1894	Cost: 6.41s
Train Epoch: 550 	Average Loss: 14.2455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7929

Learning rate: 0.0001985109326154773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: 16.6174	Cost: 20.63s
Train Epoch: 551 [20480/90000 (23%)]	Loss: 14.0698	Cost: 6.11s
Train Epoch: 551 [40960/90000 (45%)]	Loss: 13.8936	Cost: 6.03s
Train Epoch: 551 [61440/90000 (68%)]	Loss: 14.0504	Cost: 5.95s
Train Epoch: 551 [81920/90000 (91%)]	Loss: 14.0524	Cost: 5.99s
Train Epoch: 551 	Average Loss: 14.2735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7660

Learning rate: 0.00019850552644226275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: 16.6157	Cost: 22.37s
Train Epoch: 552 [20480/90000 (23%)]	Loss: 14.1133	Cost: 5.99s
Train Epoch: 552 [40960/90000 (45%)]	Loss: 14.2060	Cost: 6.56s
Train Epoch: 552 [61440/90000 (68%)]	Loss: 14.0011	Cost: 5.88s
Train Epoch: 552 [81920/90000 (91%)]	Loss: 14.0937	Cost: 6.47s
Train Epoch: 552 	Average Loss: 14.2531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8003

Learning rate: 0.0001985001105469425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: 16.6118	Cost: 21.59s
Train Epoch: 553 [20480/90000 (23%)]	Loss: 14.0643	Cost: 6.15s
Train Epoch: 553 [40960/90000 (45%)]	Loss: 14.0199	Cost: 6.52s
Train Epoch: 553 [61440/90000 (68%)]	Loss: 14.1249	Cost: 6.03s
Train Epoch: 553 [81920/90000 (91%)]	Loss: 14.0082	Cost: 5.96s
Train Epoch: 553 	Average Loss: 14.2271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8927

Learning rate: 0.00019849468493005109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: 16.6022	Cost: 21.46s
Train Epoch: 554 [20480/90000 (23%)]	Loss: 13.9177	Cost: 6.06s
Train Epoch: 554 [40960/90000 (45%)]	Loss: 14.0735	Cost: 6.50s
Train Epoch: 554 [61440/90000 (68%)]	Loss: 13.9884	Cost: 5.93s
Train Epoch: 554 [81920/90000 (91%)]	Loss: 14.0677	Cost: 6.39s
Train Epoch: 554 	Average Loss: 14.2218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7566

Learning rate: 0.000198489249592124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: 16.5749	Cost: 20.51s
Train Epoch: 555 [20480/90000 (23%)]	Loss: 13.9032	Cost: 6.20s
Train Epoch: 555 [40960/90000 (45%)]	Loss: 14.0651	Cost: 6.14s
Train Epoch: 555 [61440/90000 (68%)]	Loss: 14.0243	Cost: 5.99s
Train Epoch: 555 [81920/90000 (91%)]	Loss: 14.0341	Cost: 6.40s
Train Epoch: 555 	Average Loss: 14.2321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8411

Learning rate: 0.00019848380453369767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: 16.4797	Cost: 21.45s
Train Epoch: 556 [20480/90000 (23%)]	Loss: 13.9816	Cost: 6.12s
Train Epoch: 556 [40960/90000 (45%)]	Loss: 13.9661	Cost: 6.80s
Train Epoch: 556 [61440/90000 (68%)]	Loss: 13.9733	Cost: 6.04s
Train Epoch: 556 [81920/90000 (91%)]	Loss: 14.1401	Cost: 5.90s
Train Epoch: 556 	Average Loss: 14.2311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8264

Learning rate: 0.00019847834975530955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: 16.4890	Cost: 20.97s
Train Epoch: 557 [20480/90000 (23%)]	Loss: 13.9254	Cost: 6.14s
Train Epoch: 557 [40960/90000 (45%)]	Loss: 14.1666	Cost: 6.05s
Train Epoch: 557 [61440/90000 (68%)]	Loss: 14.0089	Cost: 5.90s
Train Epoch: 557 [81920/90000 (91%)]	Loss: 13.7821	Cost: 5.88s
Train Epoch: 557 	Average Loss: 14.1873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8311

Learning rate: 0.00019847288525749797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: 16.6245	Cost: 22.91s
Train Epoch: 558 [20480/90000 (23%)]	Loss: 14.0976	Cost: 6.03s
Train Epoch: 558 [40960/90000 (45%)]	Loss: 13.9193	Cost: 6.95s
Train Epoch: 558 [61440/90000 (68%)]	Loss: 14.0000	Cost: 5.89s
Train Epoch: 558 [81920/90000 (91%)]	Loss: 14.0368	Cost: 6.36s
Train Epoch: 558 	Average Loss: 14.2210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8671

Learning rate: 0.0001984674110408022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: 16.7460	Cost: 20.17s
Train Epoch: 559 [20480/90000 (23%)]	Loss: 13.8883	Cost: 6.02s
Train Epoch: 559 [40960/90000 (45%)]	Loss: 14.0130	Cost: 6.31s
Train Epoch: 559 [61440/90000 (68%)]	Loss: 14.0073	Cost: 5.87s
Train Epoch: 559 [81920/90000 (91%)]	Loss: 14.0367	Cost: 5.81s
Train Epoch: 559 	Average Loss: 14.2185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8408

Learning rate: 0.0001984619271057626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: 16.5126	Cost: 21.44s
Train Epoch: 560 [20480/90000 (23%)]	Loss: 13.7772	Cost: 5.98s
Train Epoch: 560 [40960/90000 (45%)]	Loss: 13.9841	Cost: 6.64s
Train Epoch: 560 [61440/90000 (68%)]	Loss: 13.9342	Cost: 5.88s
Train Epoch: 560 [81920/90000 (91%)]	Loss: 14.0917	Cost: 5.92s
Train Epoch: 560 	Average Loss: 14.1699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8024

Learning rate: 0.0001984564334529204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: 16.5901	Cost: 21.11s
Train Epoch: 561 [20480/90000 (23%)]	Loss: 13.8360	Cost: 5.94s
Train Epoch: 561 [40960/90000 (45%)]	Loss: 14.0637	Cost: 6.02s
Train Epoch: 561 [61440/90000 (68%)]	Loss: 13.8804	Cost: 5.83s
Train Epoch: 561 [81920/90000 (91%)]	Loss: 14.0656	Cost: 5.74s
Train Epoch: 561 	Average Loss: 14.1796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8567

Learning rate: 0.0001984509300828178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: 16.5562	Cost: 20.61s
Train Epoch: 562 [20480/90000 (23%)]	Loss: 13.8512	Cost: 5.96s
Train Epoch: 562 [40960/90000 (45%)]	Loss: 13.9259	Cost: 5.98s
Train Epoch: 562 [61440/90000 (68%)]	Loss: 13.9733	Cost: 5.84s
Train Epoch: 562 [81920/90000 (91%)]	Loss: 14.0645	Cost: 5.72s
Train Epoch: 562 	Average Loss: 14.1786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8298

Learning rate: 0.00019844541699599793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: 16.5207	Cost: 20.51s
Train Epoch: 563 [20480/90000 (23%)]	Loss: 13.8054	Cost: 6.11s
Train Epoch: 563 [40960/90000 (45%)]	Loss: 14.0419	Cost: 6.21s
Train Epoch: 563 [61440/90000 (68%)]	Loss: 13.7819	Cost: 5.85s
Train Epoch: 563 [81920/90000 (91%)]	Loss: 13.9056	Cost: 5.76s
Train Epoch: 563 	Average Loss: 14.1665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8157

Learning rate: 0.00019843989419300492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: 16.5913	Cost: 21.89s
Train Epoch: 564 [20480/90000 (23%)]	Loss: 13.8481	Cost: 6.06s
Train Epoch: 564 [40960/90000 (45%)]	Loss: 14.0762	Cost: 6.09s
Train Epoch: 564 [61440/90000 (68%)]	Loss: 13.8233	Cost: 6.05s
Train Epoch: 564 [81920/90000 (91%)]	Loss: 13.7766	Cost: 5.99s
Train Epoch: 564 	Average Loss: 14.1450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8567

Learning rate: 0.00019843436167438387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: 16.5944	Cost: 21.57s
Train Epoch: 565 [20480/90000 (23%)]	Loss: 13.8143	Cost: 5.97s
Train Epoch: 565 [40960/90000 (45%)]	Loss: 13.8901	Cost: 6.15s
Train Epoch: 565 [61440/90000 (68%)]	Loss: 13.9513	Cost: 5.91s
Train Epoch: 565 [81920/90000 (91%)]	Loss: 13.8691	Cost: 6.04s
Train Epoch: 565 	Average Loss: 14.1476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8284

Learning rate: 0.00019842881944068082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: 16.4501	Cost: 20.66s
Train Epoch: 566 [20480/90000 (23%)]	Loss: 13.7634	Cost: 6.07s
Train Epoch: 566 [40960/90000 (45%)]	Loss: 13.8981	Cost: 6.15s
Train Epoch: 566 [61440/90000 (68%)]	Loss: 13.7872	Cost: 5.87s
Train Epoch: 566 [81920/90000 (91%)]	Loss: 14.0726	Cost: 5.89s
Train Epoch: 566 	Average Loss: 14.1378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7909

Learning rate: 0.00019842326749244275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: 16.6257	Cost: 20.47s
Train Epoch: 567 [20480/90000 (23%)]	Loss: 13.9137	Cost: 6.06s
Train Epoch: 567 [40960/90000 (45%)]	Loss: 13.9682	Cost: 6.72s
Train Epoch: 567 [61440/90000 (68%)]	Loss: 13.8393	Cost: 5.99s
Train Epoch: 567 [81920/90000 (91%)]	Loss: 14.0364	Cost: 6.11s
Train Epoch: 567 	Average Loss: 14.1447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9619

Learning rate: 0.00019841770583021762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: 16.7397	Cost: 20.87s
Train Epoch: 568 [20480/90000 (23%)]	Loss: 13.7829	Cost: 6.03s
Train Epoch: 568 [40960/90000 (45%)]	Loss: 14.0835	Cost: 6.23s
Train Epoch: 568 [61440/90000 (68%)]	Loss: 13.5882	Cost: 5.93s
Train Epoch: 568 [81920/90000 (91%)]	Loss: 13.8938	Cost: 6.30s
Train Epoch: 568 	Average Loss: 14.1233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9109

Learning rate: 0.00019841213445455434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: 16.5417	Cost: 20.01s
Train Epoch: 569 [20480/90000 (23%)]	Loss: 14.0030	Cost: 6.16s
Train Epoch: 569 [40960/90000 (45%)]	Loss: 13.8455	Cost: 6.17s
Train Epoch: 569 [61440/90000 (68%)]	Loss: 13.6716	Cost: 5.92s
Train Epoch: 569 [81920/90000 (91%)]	Loss: 14.0543	Cost: 5.84s
Train Epoch: 569 	Average Loss: 14.1151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8860

Learning rate: 0.00019840655336600282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: 16.7175	Cost: 21.52s
Train Epoch: 570 [20480/90000 (23%)]	Loss: 13.7684	Cost: 5.92s
Train Epoch: 570 [40960/90000 (45%)]	Loss: 13.9791	Cost: 6.24s
Train Epoch: 570 [61440/90000 (68%)]	Loss: 13.9387	Cost: 5.92s
Train Epoch: 570 [81920/90000 (91%)]	Loss: 13.9967	Cost: 6.34s
Train Epoch: 570 	Average Loss: 14.1218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8782

Learning rate: 0.00019840096256511382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: 16.6712	Cost: 21.92s
Train Epoch: 571 [20480/90000 (23%)]	Loss: 13.7454	Cost: 6.00s
Train Epoch: 571 [40960/90000 (45%)]	Loss: 13.9158	Cost: 6.41s
Train Epoch: 571 [61440/90000 (68%)]	Loss: 13.8067	Cost: 5.90s
Train Epoch: 571 [81920/90000 (91%)]	Loss: 13.9051	Cost: 6.45s
Train Epoch: 571 	Average Loss: 14.0996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9691

Learning rate: 0.0001983953620524392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: 16.7224	Cost: 20.87s
Train Epoch: 572 [20480/90000 (23%)]	Loss: 13.7103	Cost: 6.09s
Train Epoch: 572 [40960/90000 (45%)]	Loss: 13.8433	Cost: 6.57s
Train Epoch: 572 [61440/90000 (68%)]	Loss: 13.9526	Cost: 5.89s
Train Epoch: 572 [81920/90000 (91%)]	Loss: 14.0087	Cost: 6.36s
Train Epoch: 572 	Average Loss: 14.0958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8731

Learning rate: 0.00019838975182853166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: 16.7545	Cost: 20.82s
Train Epoch: 573 [20480/90000 (23%)]	Loss: 13.8770	Cost: 6.15s
Train Epoch: 573 [40960/90000 (45%)]	Loss: 14.0259	Cost: 6.21s
Train Epoch: 573 [61440/90000 (68%)]	Loss: 13.8157	Cost: 6.05s
Train Epoch: 573 [81920/90000 (91%)]	Loss: 13.8710	Cost: 6.05s
Train Epoch: 573 	Average Loss: 14.0818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9380

Learning rate: 0.0001983841318939449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: 16.5825	Cost: 20.60s
Train Epoch: 574 [20480/90000 (23%)]	Loss: 13.7701	Cost: 6.01s
Train Epoch: 574 [40960/90000 (45%)]	Loss: 13.9420	Cost: 6.06s
Train Epoch: 574 [61440/90000 (68%)]	Loss: 13.9286	Cost: 5.91s
Train Epoch: 574 [81920/90000 (91%)]	Loss: 13.7867	Cost: 5.83s
Train Epoch: 574 	Average Loss: 14.0847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0114

Learning rate: 0.00019837850224923363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: 16.6597	Cost: 20.76s
Train Epoch: 575 [20480/90000 (23%)]	Loss: 13.7768	Cost: 6.06s
Train Epoch: 575 [40960/90000 (45%)]	Loss: 13.9133	Cost: 6.46s
Train Epoch: 575 [61440/90000 (68%)]	Loss: 13.6500	Cost: 6.13s
Train Epoch: 575 [81920/90000 (91%)]	Loss: 13.9947	Cost: 6.20s
Train Epoch: 575 	Average Loss: 14.0605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8963

Learning rate: 0.00019837286289495345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: 16.7561	Cost: 21.80s
Train Epoch: 576 [20480/90000 (23%)]	Loss: 13.5753	Cost: 6.01s
Train Epoch: 576 [40960/90000 (45%)]	Loss: 13.9315	Cost: 6.04s
Train Epoch: 576 [61440/90000 (68%)]	Loss: 13.7101	Cost: 5.89s
Train Epoch: 576 [81920/90000 (91%)]	Loss: 13.6642	Cost: 5.90s
Train Epoch: 576 	Average Loss: 14.0236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9634

Learning rate: 0.00019836721383166095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: 16.6159	Cost: 21.06s
Train Epoch: 577 [20480/90000 (23%)]	Loss: 13.8689	Cost: 6.01s
Train Epoch: 577 [40960/90000 (45%)]	Loss: 13.8370	Cost: 6.69s
Train Epoch: 577 [61440/90000 (68%)]	Loss: 13.6663	Cost: 5.89s
Train Epoch: 577 [81920/90000 (91%)]	Loss: 13.8479	Cost: 6.17s
Train Epoch: 577 	Average Loss: 14.0598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9825

Learning rate: 0.00019836155505991362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: 16.7921	Cost: 21.85s
Train Epoch: 578 [20480/90000 (23%)]	Loss: 13.8568	Cost: 5.94s
Train Epoch: 578 [40960/90000 (45%)]	Loss: 13.8977	Cost: 6.48s
Train Epoch: 578 [61440/90000 (68%)]	Loss: 13.6995	Cost: 5.88s
Train Epoch: 578 [81920/90000 (91%)]	Loss: 13.9367	Cost: 6.39s
Train Epoch: 578 	Average Loss: 14.0499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9437

Learning rate: 0.00019835588658027008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: 16.7860	Cost: 20.15s
Train Epoch: 579 [20480/90000 (23%)]	Loss: 13.7980	Cost: 6.05s
Train Epoch: 579 [40960/90000 (45%)]	Loss: 14.0218	Cost: 6.30s
Train Epoch: 579 [61440/90000 (68%)]	Loss: 13.7637	Cost: 5.73s
Train Epoch: 579 [81920/90000 (91%)]	Loss: 13.6505	Cost: 6.19s
Train Epoch: 579 	Average Loss: 14.0338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8612

Learning rate: 0.00019835020839328965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: 16.7594	Cost: 22.12s
Train Epoch: 580 [20480/90000 (23%)]	Loss: 13.9047	Cost: 6.05s
Train Epoch: 580 [40960/90000 (45%)]	Loss: 13.8910	Cost: 6.61s
Train Epoch: 580 [61440/90000 (68%)]	Loss: 13.8351	Cost: 5.93s
Train Epoch: 580 [81920/90000 (91%)]	Loss: 13.8953	Cost: 5.96s
Train Epoch: 580 	Average Loss: 14.0343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0087

Learning rate: 0.0001983445204995328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: 16.8103	Cost: 20.55s
Train Epoch: 581 [20480/90000 (23%)]	Loss: 13.6682	Cost: 6.01s
Train Epoch: 581 [40960/90000 (45%)]	Loss: 13.8733	Cost: 6.18s
Train Epoch: 581 [61440/90000 (68%)]	Loss: 13.5684	Cost: 5.86s
Train Epoch: 581 [81920/90000 (91%)]	Loss: 13.8432	Cost: 5.90s
Train Epoch: 581 	Average Loss: 14.0386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9545

Learning rate: 0.00019833882289956094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: 16.8798	Cost: 22.45s
Train Epoch: 582 [20480/90000 (23%)]	Loss: 13.7517	Cost: 5.93s
Train Epoch: 582 [40960/90000 (45%)]	Loss: 13.7796	Cost: 6.35s
Train Epoch: 582 [61440/90000 (68%)]	Loss: 13.7872	Cost: 5.91s
Train Epoch: 582 [81920/90000 (91%)]	Loss: 13.8704	Cost: 6.45s
Train Epoch: 582 	Average Loss: 14.0233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0180

Learning rate: 0.00019833311559393636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: 16.7808	Cost: 20.63s
Train Epoch: 583 [20480/90000 (23%)]	Loss: 13.7401	Cost: 6.08s
Train Epoch: 583 [40960/90000 (45%)]	Loss: 13.8876	Cost: 6.01s
Train Epoch: 583 [61440/90000 (68%)]	Loss: 13.7605	Cost: 5.88s
Train Epoch: 583 [81920/90000 (91%)]	Loss: 13.8356	Cost: 5.95s
Train Epoch: 583 	Average Loss: 14.0249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9343

Learning rate: 0.00019832739858322235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: 16.8428	Cost: 22.94s
Train Epoch: 584 [20480/90000 (23%)]	Loss: 13.7206	Cost: 6.13s
Train Epoch: 584 [40960/90000 (45%)]	Loss: 13.8169	Cost: 6.92s
Train Epoch: 584 [61440/90000 (68%)]	Loss: 13.7502	Cost: 5.89s
Train Epoch: 584 [81920/90000 (91%)]	Loss: 13.8216	Cost: 5.93s
Train Epoch: 584 	Average Loss: 14.0166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9377

Learning rate: 0.00019832167186798315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: 16.7352	Cost: 20.63s
Train Epoch: 585 [20480/90000 (23%)]	Loss: 13.6883	Cost: 5.77s
Train Epoch: 585 [40960/90000 (45%)]	Loss: 13.9080	Cost: 5.92s
Train Epoch: 585 [61440/90000 (68%)]	Loss: 13.7431	Cost: 5.67s
Train Epoch: 585 [81920/90000 (91%)]	Loss: 13.7470	Cost: 5.99s
Train Epoch: 585 	Average Loss: 14.0069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9507

Learning rate: 0.000198315935448784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: 16.5689	Cost: 21.22s
Train Epoch: 586 [20480/90000 (23%)]	Loss: 13.7271	Cost: 5.78s
Train Epoch: 586 [40960/90000 (45%)]	Loss: 13.8449	Cost: 7.00s
Train Epoch: 586 [61440/90000 (68%)]	Loss: 13.6818	Cost: 5.99s
Train Epoch: 586 [81920/90000 (91%)]	Loss: 13.9139	Cost: 6.20s
Train Epoch: 586 	Average Loss: 13.9975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9530

Learning rate: 0.00019831018932619103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: 16.6693	Cost: 20.41s
Train Epoch: 587 [20480/90000 (23%)]	Loss: 13.6487	Cost: 6.00s
Train Epoch: 587 [40960/90000 (45%)]	Loss: 13.8885	Cost: 6.04s
Train Epoch: 587 [61440/90000 (68%)]	Loss: 13.7265	Cost: 5.96s
Train Epoch: 587 [81920/90000 (91%)]	Loss: 13.8528	Cost: 5.79s
Train Epoch: 587 	Average Loss: 13.9518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9645

Learning rate: 0.00019830443350077136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: 16.6956	Cost: 21.56s
Train Epoch: 588 [20480/90000 (23%)]	Loss: 13.5815	Cost: 6.07s
Train Epoch: 588 [40960/90000 (45%)]	Loss: 13.9221	Cost: 7.19s
Train Epoch: 588 [61440/90000 (68%)]	Loss: 13.7088	Cost: 5.82s
Train Epoch: 588 [81920/90000 (91%)]	Loss: 13.8962	Cost: 6.35s
Train Epoch: 588 	Average Loss: 13.9573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0212

Learning rate: 0.0001982986679730931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: 16.7739	Cost: 19.92s
Train Epoch: 589 [20480/90000 (23%)]	Loss: 13.5417	Cost: 6.01s
Train Epoch: 589 [40960/90000 (45%)]	Loss: 13.6150	Cost: 6.44s
Train Epoch: 589 [61440/90000 (68%)]	Loss: 13.6991	Cost: 5.91s
Train Epoch: 589 [81920/90000 (91%)]	Loss: 13.7188	Cost: 5.99s
Train Epoch: 589 	Average Loss: 13.9493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9890

Learning rate: 0.00019829289274372522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: 16.8490	Cost: 21.95s
Train Epoch: 590 [20480/90000 (23%)]	Loss: 13.8723	Cost: 5.93s
Train Epoch: 590 [40960/90000 (45%)]	Loss: 13.7873	Cost: 6.17s
Train Epoch: 590 [61440/90000 (68%)]	Loss: 13.5006	Cost: 5.88s
Train Epoch: 590 [81920/90000 (91%)]	Loss: 13.7552	Cost: 5.90s
Train Epoch: 590 	Average Loss: 13.9512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0225

Learning rate: 0.00019828710781323776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: 16.7612	Cost: 21.41s
Train Epoch: 591 [20480/90000 (23%)]	Loss: 13.4808	Cost: 6.00s
Train Epoch: 591 [40960/90000 (45%)]	Loss: 13.9350	Cost: 6.20s
Train Epoch: 591 [61440/90000 (68%)]	Loss: 13.3626	Cost: 5.88s
Train Epoch: 591 [81920/90000 (91%)]	Loss: 13.6091	Cost: 6.23s
Train Epoch: 591 	Average Loss: 13.9096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0082

Learning rate: 0.00019828131318220168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: 16.6451	Cost: 20.22s
Train Epoch: 592 [20480/90000 (23%)]	Loss: 13.6298	Cost: 6.71s
Train Epoch: 592 [40960/90000 (45%)]	Loss: 14.0043	Cost: 6.76s
Train Epoch: 592 [61440/90000 (68%)]	Loss: 13.6395	Cost: 6.55s
Train Epoch: 592 [81920/90000 (91%)]	Loss: 13.7138	Cost: 6.31s
Train Epoch: 592 	Average Loss: 13.9718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0252

Learning rate: 0.00019827550885118884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: 16.7727	Cost: 21.95s
Train Epoch: 593 [20480/90000 (23%)]	Loss: 13.6818	Cost: 6.72s
Train Epoch: 593 [40960/90000 (45%)]	Loss: 13.7993	Cost: 6.73s
Train Epoch: 593 [61440/90000 (68%)]	Loss: 13.5778	Cost: 6.17s
Train Epoch: 593 [81920/90000 (91%)]	Loss: 13.7326	Cost: 5.97s
Train Epoch: 593 	Average Loss: 13.9212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0205

Learning rate: 0.00019826969482077218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: 16.8216	Cost: 20.80s
Train Epoch: 594 [20480/90000 (23%)]	Loss: 13.7599	Cost: 5.92s
Train Epoch: 594 [40960/90000 (45%)]	Loss: 13.6901	Cost: 6.15s
Train Epoch: 594 [61440/90000 (68%)]	Loss: 13.6869	Cost: 5.92s
Train Epoch: 594 [81920/90000 (91%)]	Loss: 13.5319	Cost: 6.57s
Train Epoch: 594 	Average Loss: 13.8935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0419

Learning rate: 0.00019826387109152545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: 16.7308	Cost: 20.81s
Train Epoch: 595 [20480/90000 (23%)]	Loss: 13.5981	Cost: 5.99s
Train Epoch: 595 [40960/90000 (45%)]	Loss: 13.6820	Cost: 6.03s
Train Epoch: 595 [61440/90000 (68%)]	Loss: 13.6375	Cost: 5.96s
Train Epoch: 595 [81920/90000 (91%)]	Loss: 13.7257	Cost: 7.31s
Train Epoch: 595 	Average Loss: 13.9069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9654

Learning rate: 0.00019825803766402344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: 16.8131	Cost: 21.14s
Train Epoch: 596 [20480/90000 (23%)]	Loss: 13.6615	Cost: 5.97s
Train Epoch: 596 [40960/90000 (45%)]	Loss: 13.7800	Cost: 6.71s
Train Epoch: 596 [61440/90000 (68%)]	Loss: 13.6592	Cost: 5.85s
Train Epoch: 596 [81920/90000 (91%)]	Loss: 13.7110	Cost: 6.02s
Train Epoch: 596 	Average Loss: 13.8865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9959

Learning rate: 0.00019825219453884193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: 16.7962	Cost: 21.58s
Train Epoch: 597 [20480/90000 (23%)]	Loss: 13.5948	Cost: 6.03s
Train Epoch: 597 [40960/90000 (45%)]	Loss: 13.6190	Cost: 6.92s
Train Epoch: 597 [61440/90000 (68%)]	Loss: 13.6205	Cost: 6.02s
Train Epoch: 597 [81920/90000 (91%)]	Loss: 13.7536	Cost: 7.50s
Train Epoch: 597 	Average Loss: 13.9087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0425

Learning rate: 0.00019824634171655754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: 16.9712	Cost: 21.15s
Train Epoch: 598 [20480/90000 (23%)]	Loss: 13.5926	Cost: 5.96s
Train Epoch: 598 [40960/90000 (45%)]	Loss: 13.5989	Cost: 6.48s
Train Epoch: 598 [61440/90000 (68%)]	Loss: 13.7707	Cost: 5.80s
Train Epoch: 598 [81920/90000 (91%)]	Loss: 13.7132	Cost: 6.10s
Train Epoch: 598 	Average Loss: 13.9207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0025

Learning rate: 0.000198240479197748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: 16.8335	Cost: 20.20s
Train Epoch: 599 [20480/90000 (23%)]	Loss: 13.7824	Cost: 6.19s
Train Epoch: 599 [40960/90000 (45%)]	Loss: 13.7477	Cost: 6.20s
Train Epoch: 599 [61440/90000 (68%)]	Loss: 13.6123	Cost: 6.10s
Train Epoch: 599 [81920/90000 (91%)]	Loss: 13.6042	Cost: 5.95s
Train Epoch: 599 	Average Loss: 13.8901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9963

Learning rate: 0.00019823460698299188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: 16.8806	Cost: 22.04s
Train Epoch: 600 [20480/90000 (23%)]	Loss: 13.5618	Cost: 6.36s
Train Epoch: 600 [40960/90000 (45%)]	Loss: 13.7110	Cost: 6.49s
Train Epoch: 600 [61440/90000 (68%)]	Loss: 13.4604	Cost: 5.79s
Train Epoch: 600 [81920/90000 (91%)]	Loss: 13.7558	Cost: 5.93s
Train Epoch: 600 	Average Loss: 13.8549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0421

Learning rate: 0.00019822872507286872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: 16.9227	Cost: 19.40s
Train Epoch: 601 [20480/90000 (23%)]	Loss: 13.4730	Cost: 6.12s
Train Epoch: 601 [40960/90000 (45%)]	Loss: 13.7328	Cost: 6.28s
Train Epoch: 601 [61440/90000 (68%)]	Loss: 13.4125	Cost: 5.79s
Train Epoch: 601 [81920/90000 (91%)]	Loss: 13.5609	Cost: 5.66s
Train Epoch: 601 	Average Loss: 13.8361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0107

Learning rate: 0.00019822283346795905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: 16.8535	Cost: 19.37s
Train Epoch: 602 [20480/90000 (23%)]	Loss: 13.4319	Cost: 6.03s
Train Epoch: 602 [40960/90000 (45%)]	Loss: 13.7338	Cost: 6.02s
Train Epoch: 602 [61440/90000 (68%)]	Loss: 13.5129	Cost: 5.84s
Train Epoch: 602 [81920/90000 (91%)]	Loss: 13.6464	Cost: 5.64s
Train Epoch: 602 	Average Loss: 13.8280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0017

Learning rate: 0.0001982169321688444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: 16.6794	Cost: 21.10s
Train Epoch: 603 [20480/90000 (23%)]	Loss: 13.4800	Cost: 5.98s
Train Epoch: 603 [40960/90000 (45%)]	Loss: 13.6270	Cost: 7.16s
Train Epoch: 603 [61440/90000 (68%)]	Loss: 13.4134	Cost: 5.75s
Train Epoch: 603 [81920/90000 (91%)]	Loss: 13.6140	Cost: 6.41s
Train Epoch: 603 	Average Loss: 13.8426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0688

Learning rate: 0.00019821102117610715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: 16.7205	Cost: 20.55s
Train Epoch: 604 [20480/90000 (23%)]	Loss: 13.5009	Cost: 5.95s
Train Epoch: 604 [40960/90000 (45%)]	Loss: 13.6005	Cost: 6.68s
Train Epoch: 604 [61440/90000 (68%)]	Loss: 13.5789	Cost: 5.77s
Train Epoch: 604 [81920/90000 (91%)]	Loss: 13.7307	Cost: 6.01s
Train Epoch: 604 	Average Loss: 13.8273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1130

Learning rate: 0.00019820510049033073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: 16.8885	Cost: 19.95s
Train Epoch: 605 [20480/90000 (23%)]	Loss: 13.4790	Cost: 6.49s
Train Epoch: 605 [40960/90000 (45%)]	Loss: 13.7814	Cost: 6.49s
Train Epoch: 605 [61440/90000 (68%)]	Loss: 13.5459	Cost: 5.76s
Train Epoch: 605 [81920/90000 (91%)]	Loss: 13.6450	Cost: 5.66s
Train Epoch: 605 	Average Loss: 13.8426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0672

Learning rate: 0.0001981991701120995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: 16.8806	Cost: 20.08s
Train Epoch: 606 [20480/90000 (23%)]	Loss: 13.4131	Cost: 5.95s
Train Epoch: 606 [40960/90000 (45%)]	Loss: 13.7231	Cost: 6.37s
Train Epoch: 606 [61440/90000 (68%)]	Loss: 13.7218	Cost: 5.77s
Train Epoch: 606 [81920/90000 (91%)]	Loss: 13.5824	Cost: 5.63s
Train Epoch: 606 	Average Loss: 13.8203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1829

Learning rate: 0.00019819323004199868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: 16.9608	Cost: 20.44s
Train Epoch: 607 [20480/90000 (23%)]	Loss: 13.6203	Cost: 6.00s
Train Epoch: 607 [40960/90000 (45%)]	Loss: 13.4945	Cost: 6.04s
Train Epoch: 607 [61440/90000 (68%)]	Loss: 13.4073	Cost: 5.85s
Train Epoch: 607 [81920/90000 (91%)]	Loss: 13.5646	Cost: 5.61s
Train Epoch: 607 	Average Loss: 13.8065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0882

Learning rate: 0.0001981872802806146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: 16.8984	Cost: 20.74s
Train Epoch: 608 [20480/90000 (23%)]	Loss: 13.4386	Cost: 5.98s
Train Epoch: 608 [40960/90000 (45%)]	Loss: 13.6915	Cost: 6.74s
Train Epoch: 608 [61440/90000 (68%)]	Loss: 13.4198	Cost: 5.79s
Train Epoch: 608 [81920/90000 (91%)]	Loss: 13.5492	Cost: 5.64s
Train Epoch: 608 	Average Loss: 13.7917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1374

Learning rate: 0.0001981813208285345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: 16.8349	Cost: 19.63s
Train Epoch: 609 [20480/90000 (23%)]	Loss: 13.4522	Cost: 6.03s
Train Epoch: 609 [40960/90000 (45%)]	Loss: 13.6993	Cost: 5.98s
Train Epoch: 609 [61440/90000 (68%)]	Loss: 13.4333	Cost: 5.82s
Train Epoch: 609 [81920/90000 (91%)]	Loss: 13.6136	Cost: 5.65s
Train Epoch: 609 	Average Loss: 13.7867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0463

Learning rate: 0.00019817535168634647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: 16.7120	Cost: 20.97s
Train Epoch: 610 [20480/90000 (23%)]	Loss: 13.6150	Cost: 5.99s
Train Epoch: 610 [40960/90000 (45%)]	Loss: 13.4463	Cost: 6.24s
Train Epoch: 610 [61440/90000 (68%)]	Loss: 13.4280	Cost: 5.85s
Train Epoch: 610 [81920/90000 (91%)]	Loss: 13.5307	Cost: 5.76s
Train Epoch: 610 	Average Loss: 13.7784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0514

Learning rate: 0.0001981693728546397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: 16.7732	Cost: 19.90s
Train Epoch: 611 [20480/90000 (23%)]	Loss: 13.4194	Cost: 5.96s
Train Epoch: 611 [40960/90000 (45%)]	Loss: 13.6247	Cost: 6.50s
Train Epoch: 611 [61440/90000 (68%)]	Loss: 13.2760	Cost: 5.82s
Train Epoch: 611 [81920/90000 (91%)]	Loss: 13.7295	Cost: 5.66s
Train Epoch: 611 	Average Loss: 13.7701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1478

Learning rate: 0.00019816338433400427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: 16.9091	Cost: 20.94s
Train Epoch: 612 [20480/90000 (23%)]	Loss: 13.5586	Cost: 6.01s
Train Epoch: 612 [40960/90000 (45%)]	Loss: 13.6195	Cost: 6.41s
Train Epoch: 612 [61440/90000 (68%)]	Loss: 13.3125	Cost: 5.90s
Train Epoch: 612 [81920/90000 (91%)]	Loss: 13.4837	Cost: 6.24s
Train Epoch: 612 	Average Loss: 13.7535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1758

Learning rate: 0.00019815738612503125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: 16.8738	Cost: 19.92s
Train Epoch: 613 [20480/90000 (23%)]	Loss: 13.6848	Cost: 6.17s
Train Epoch: 613 [40960/90000 (45%)]	Loss: 13.5570	Cost: 6.82s
Train Epoch: 613 [61440/90000 (68%)]	Loss: 13.4763	Cost: 6.48s
Train Epoch: 613 [81920/90000 (91%)]	Loss: 13.6797	Cost: 6.34s
Train Epoch: 613 	Average Loss: 13.7560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1660

Learning rate: 0.00019815137822831258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: 16.6348	Cost: 21.74s
Train Epoch: 614 [20480/90000 (23%)]	Loss: 13.5115	Cost: 5.93s
Train Epoch: 614 [40960/90000 (45%)]	Loss: 13.6692	Cost: 6.85s
Train Epoch: 614 [61440/90000 (68%)]	Loss: 13.4639	Cost: 5.89s
Train Epoch: 614 [81920/90000 (91%)]	Loss: 13.5919	Cost: 5.91s
Train Epoch: 614 	Average Loss: 13.7759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1632

Learning rate: 0.00019814536064444125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: 16.8293	Cost: 21.59s
Train Epoch: 615 [20480/90000 (23%)]	Loss: 13.1922	Cost: 5.98s
Train Epoch: 615 [40960/90000 (45%)]	Loss: 13.6441	Cost: 6.09s
Train Epoch: 615 [61440/90000 (68%)]	Loss: 13.3575	Cost: 5.82s
Train Epoch: 615 [81920/90000 (91%)]	Loss: 13.6273	Cost: 5.70s
Train Epoch: 615 	Average Loss: 13.7592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1432

Learning rate: 0.00019813933337401116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: 16.9090	Cost: 22.04s
Train Epoch: 616 [20480/90000 (23%)]	Loss: 13.5167	Cost: 5.95s
Train Epoch: 616 [40960/90000 (45%)]	Loss: 13.5964	Cost: 6.31s
Train Epoch: 616 [61440/90000 (68%)]	Loss: 13.3469	Cost: 5.84s
Train Epoch: 616 [81920/90000 (91%)]	Loss: 13.6480	Cost: 5.71s
Train Epoch: 616 	Average Loss: 13.7936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0676

Learning rate: 0.0001981332964176172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: 16.8497	Cost: 20.27s
Train Epoch: 617 [20480/90000 (23%)]	Loss: 13.6902	Cost: 5.98s
Train Epoch: 617 [40960/90000 (45%)]	Loss: 13.4654	Cost: 6.55s
Train Epoch: 617 [61440/90000 (68%)]	Loss: 13.5302	Cost: 5.79s
Train Epoch: 617 [81920/90000 (91%)]	Loss: 13.5927	Cost: 6.01s
Train Epoch: 617 	Average Loss: 13.7569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2348

Learning rate: 0.00019812724977585515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: 16.8706	Cost: 19.65s
Train Epoch: 618 [20480/90000 (23%)]	Loss: 13.3288	Cost: 5.96s
Train Epoch: 618 [40960/90000 (45%)]	Loss: 13.7765	Cost: 6.29s
Train Epoch: 618 [61440/90000 (68%)]	Loss: 13.5412	Cost: 5.84s
Train Epoch: 618 [81920/90000 (91%)]	Loss: 13.4770	Cost: 5.74s
Train Epoch: 618 	Average Loss: 13.7436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1876

Learning rate: 0.00019812119344932182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: 16.7623	Cost: 21.92s
Train Epoch: 619 [20480/90000 (23%)]	Loss: 13.3870	Cost: 5.95s
Train Epoch: 619 [40960/90000 (45%)]	Loss: 13.5608	Cost: 6.43s
Train Epoch: 619 [61440/90000 (68%)]	Loss: 13.4281	Cost: 5.96s
Train Epoch: 619 [81920/90000 (91%)]	Loss: 13.6763	Cost: 6.36s
Train Epoch: 619 	Average Loss: 13.6945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1620

Learning rate: 0.00019811512743861495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: 17.0208	Cost: 19.95s
Train Epoch: 620 [20480/90000 (23%)]	Loss: 13.4605	Cost: 5.92s
Train Epoch: 620 [40960/90000 (45%)]	Loss: 13.4699	Cost: 5.97s
Train Epoch: 620 [61440/90000 (68%)]	Loss: 13.3957	Cost: 5.86s
Train Epoch: 620 [81920/90000 (91%)]	Loss: 13.2097	Cost: 5.68s
Train Epoch: 620 	Average Loss: 13.6982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0869

Learning rate: 0.00019810905174433323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: 16.9231	Cost: 19.77s
Train Epoch: 621 [20480/90000 (23%)]	Loss: 13.3797	Cost: 5.96s
Train Epoch: 621 [40960/90000 (45%)]	Loss: 13.2511	Cost: 5.99s
Train Epoch: 621 [61440/90000 (68%)]	Loss: 13.4602	Cost: 5.86s
Train Epoch: 621 [81920/90000 (91%)]	Loss: 13.7006	Cost: 5.66s
Train Epoch: 621 	Average Loss: 13.6819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2044

Learning rate: 0.0001981029663670763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: 17.0487	Cost: 20.54s
Train Epoch: 622 [20480/90000 (23%)]	Loss: 13.1855	Cost: 6.76s
Train Epoch: 622 [40960/90000 (45%)]	Loss: 13.4208	Cost: 6.69s
Train Epoch: 622 [61440/90000 (68%)]	Loss: 13.5882	Cost: 5.96s
Train Epoch: 622 [81920/90000 (91%)]	Loss: 13.2285	Cost: 5.75s
Train Epoch: 622 	Average Loss: 13.6854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2270

Learning rate: 0.00019809687130744477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: 16.9813	Cost: 20.21s
Train Epoch: 623 [20480/90000 (23%)]	Loss: 13.4558	Cost: 6.00s
Train Epoch: 623 [40960/90000 (45%)]	Loss: 13.3816	Cost: 6.02s
Train Epoch: 623 [61440/90000 (68%)]	Loss: 13.2438	Cost: 6.00s
Train Epoch: 623 [81920/90000 (91%)]	Loss: 13.4565	Cost: 5.67s
Train Epoch: 623 	Average Loss: 13.6516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1847

Learning rate: 0.00019809076656604016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: 16.9203	Cost: 20.74s
Train Epoch: 624 [20480/90000 (23%)]	Loss: 13.4267	Cost: 5.97s
Train Epoch: 624 [40960/90000 (45%)]	Loss: 13.4768	Cost: 6.60s
Train Epoch: 624 [61440/90000 (68%)]	Loss: 13.4737	Cost: 5.79s
Train Epoch: 624 [81920/90000 (91%)]	Loss: 13.6398	Cost: 6.08s
Train Epoch: 624 	Average Loss: 13.6766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1801

Learning rate: 0.00019808465214346508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: 16.6762	Cost: 19.56s
Train Epoch: 625 [20480/90000 (23%)]	Loss: 13.3054	Cost: 6.15s
Train Epoch: 625 [40960/90000 (45%)]	Loss: 13.2554	Cost: 6.04s
Train Epoch: 625 [61440/90000 (68%)]	Loss: 13.3451	Cost: 5.92s
Train Epoch: 625 [81920/90000 (91%)]	Loss: 13.3766	Cost: 5.73s
Train Epoch: 625 	Average Loss: 13.6274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1132

Learning rate: 0.00019807852804032286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: 16.9461	Cost: 20.83s
Train Epoch: 626 [20480/90000 (23%)]	Loss: 13.3031	Cost: 5.95s
Train Epoch: 626 [40960/90000 (45%)]	Loss: 13.3825	Cost: 6.38s
Train Epoch: 626 [61440/90000 (68%)]	Loss: 13.3460	Cost: 5.82s
Train Epoch: 626 [81920/90000 (91%)]	Loss: 13.3397	Cost: 5.67s
Train Epoch: 626 	Average Loss: 13.6269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1994

Learning rate: 0.00019807239425721806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: 16.9021	Cost: 20.13s
Train Epoch: 627 [20480/90000 (23%)]	Loss: 13.2086	Cost: 6.10s
Train Epoch: 627 [40960/90000 (45%)]	Loss: 13.2726	Cost: 7.75s
Train Epoch: 627 [61440/90000 (68%)]	Loss: 13.2484	Cost: 5.87s
Train Epoch: 627 [81920/90000 (91%)]	Loss: 13.3800	Cost: 6.33s
Train Epoch: 627 	Average Loss: 13.5775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2442

Learning rate: 0.00019806625079475595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: 16.9256	Cost: 20.32s
Train Epoch: 628 [20480/90000 (23%)]	Loss: 13.4304	Cost: 5.96s
Train Epoch: 628 [40960/90000 (45%)]	Loss: 13.4428	Cost: 6.60s
Train Epoch: 628 [61440/90000 (68%)]	Loss: 13.2849	Cost: 5.78s
Train Epoch: 628 [81920/90000 (91%)]	Loss: 13.3818	Cost: 5.78s
Train Epoch: 628 	Average Loss: 13.6072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2284

Learning rate: 0.00019806009765354292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: 16.8558	Cost: 20.76s
Train Epoch: 629 [20480/90000 (23%)]	Loss: 13.2624	Cost: 6.02s
Train Epoch: 629 [40960/90000 (45%)]	Loss: 13.4897	Cost: 7.10s
Train Epoch: 629 [61440/90000 (68%)]	Loss: 13.4247	Cost: 5.80s
Train Epoch: 629 [81920/90000 (91%)]	Loss: 13.3474	Cost: 5.67s
Train Epoch: 629 	Average Loss: 13.6103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2269

Learning rate: 0.00019805393483418628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: 16.7936	Cost: 21.07s
Train Epoch: 630 [20480/90000 (23%)]	Loss: 13.4465	Cost: 5.94s
Train Epoch: 630 [40960/90000 (45%)]	Loss: 13.3113	Cost: 6.56s
Train Epoch: 630 [61440/90000 (68%)]	Loss: 13.2157	Cost: 5.95s
Train Epoch: 630 [81920/90000 (91%)]	Loss: 13.3958	Cost: 5.75s
Train Epoch: 630 	Average Loss: 13.5645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2090

Learning rate: 0.00019804776233729425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: 16.9252	Cost: 20.01s
Train Epoch: 631 [20480/90000 (23%)]	Loss: 13.3606	Cost: 5.95s
Train Epoch: 631 [40960/90000 (45%)]	Loss: 13.3091	Cost: 5.99s
Train Epoch: 631 [61440/90000 (68%)]	Loss: 13.3605	Cost: 5.83s
Train Epoch: 631 [81920/90000 (91%)]	Loss: 13.2753	Cost: 5.67s
Train Epoch: 631 	Average Loss: 13.6050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2505

Learning rate: 0.00019804158016347603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: 17.0868	Cost: 20.23s
Train Epoch: 632 [20480/90000 (23%)]	Loss: 13.3137	Cost: 5.95s
Train Epoch: 632 [40960/90000 (45%)]	Loss: 13.2282	Cost: 5.98s
Train Epoch: 632 [61440/90000 (68%)]	Loss: 13.0837	Cost: 5.83s
Train Epoch: 632 [81920/90000 (91%)]	Loss: 13.2795	Cost: 5.64s
Train Epoch: 632 	Average Loss: 13.5755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2327

Learning rate: 0.0001980353883133418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: 16.8979	Cost: 20.80s
Train Epoch: 633 [20480/90000 (23%)]	Loss: 13.2663	Cost: 5.98s
Train Epoch: 633 [40960/90000 (45%)]	Loss: 13.3339	Cost: 6.58s
Train Epoch: 633 [61440/90000 (68%)]	Loss: 13.1744	Cost: 5.79s
Train Epoch: 633 [81920/90000 (91%)]	Loss: 13.4318	Cost: 5.69s
Train Epoch: 633 	Average Loss: 13.5575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2129

Learning rate: 0.0001980291867875026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: 17.1703	Cost: 20.68s
Train Epoch: 634 [20480/90000 (23%)]	Loss: 13.3509	Cost: 5.79s
Train Epoch: 634 [40960/90000 (45%)]	Loss: 13.3051	Cost: 6.27s
Train Epoch: 634 [61440/90000 (68%)]	Loss: 13.2704	Cost: 5.88s
Train Epoch: 634 [81920/90000 (91%)]	Loss: 13.5373	Cost: 5.71s
Train Epoch: 634 	Average Loss: 13.5996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2245

Learning rate: 0.00019802297558657058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: 17.0037	Cost: 20.31s
Train Epoch: 635 [20480/90000 (23%)]	Loss: 13.2491	Cost: 6.11s
Train Epoch: 635 [40960/90000 (45%)]	Loss: 13.3001	Cost: 6.68s
Train Epoch: 635 [61440/90000 (68%)]	Loss: 13.4343	Cost: 5.78s
Train Epoch: 635 [81920/90000 (91%)]	Loss: 13.5387	Cost: 6.17s
Train Epoch: 635 	Average Loss: 13.6672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2106

Learning rate: 0.00019801675471115872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: 16.8789	Cost: 20.03s
Train Epoch: 636 [20480/90000 (23%)]	Loss: 13.3622	Cost: 5.96s
Train Epoch: 636 [40960/90000 (45%)]	Loss: 13.3750	Cost: 5.98s
Train Epoch: 636 [61440/90000 (68%)]	Loss: 13.4485	Cost: 5.79s
Train Epoch: 636 [81920/90000 (91%)]	Loss: 13.6789	Cost: 5.65s
Train Epoch: 636 	Average Loss: 13.7231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2896

Learning rate: 0.000198010524161881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: 16.9662	Cost: 20.50s
Train Epoch: 637 [20480/90000 (23%)]	Loss: 13.3983	Cost: 6.01s
Train Epoch: 637 [40960/90000 (45%)]	Loss: 13.4809	Cost: 6.51s
Train Epoch: 637 [61440/90000 (68%)]	Loss: 13.1884	Cost: 5.84s
Train Epoch: 637 [81920/90000 (91%)]	Loss: 13.4804	Cost: 5.86s
Train Epoch: 637 	Average Loss: 13.6430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1826

Learning rate: 0.00019800428393935233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: 17.1445	Cost: 20.66s
Train Epoch: 638 [20480/90000 (23%)]	Loss: 13.3144	Cost: 5.97s
Train Epoch: 638 [40960/90000 (45%)]	Loss: 13.1448	Cost: 6.50s
Train Epoch: 638 [61440/90000 (68%)]	Loss: 13.1000	Cost: 5.83s
Train Epoch: 638 [81920/90000 (91%)]	Loss: 13.3369	Cost: 5.71s
Train Epoch: 638 	Average Loss: 13.5538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1767

Learning rate: 0.00019799803404418868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: 17.0990	Cost: 20.22s
Train Epoch: 639 [20480/90000 (23%)]	Loss: 13.1928	Cost: 6.05s
Train Epoch: 639 [40960/90000 (45%)]	Loss: 13.3694	Cost: 6.12s
Train Epoch: 639 [61440/90000 (68%)]	Loss: 13.1869	Cost: 5.83s
Train Epoch: 639 [81920/90000 (91%)]	Loss: 13.4232	Cost: 5.73s
Train Epoch: 639 	Average Loss: 13.5533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3136

Learning rate: 0.00019799177447700676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: 16.9274	Cost: 20.23s
Train Epoch: 640 [20480/90000 (23%)]	Loss: 13.1471	Cost: 6.11s
Train Epoch: 640 [40960/90000 (45%)]	Loss: 13.4047	Cost: 7.06s
Train Epoch: 640 [61440/90000 (68%)]	Loss: 13.3250	Cost: 5.86s
Train Epoch: 640 [81920/90000 (91%)]	Loss: 13.4178	Cost: 5.76s
Train Epoch: 640 	Average Loss: 13.5470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2542

Learning rate: 0.00019798550523842447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: 16.8666	Cost: 20.25s
Train Epoch: 641 [20480/90000 (23%)]	Loss: 13.3234	Cost: 5.99s
Train Epoch: 641 [40960/90000 (45%)]	Loss: 13.4025	Cost: 7.27s
Train Epoch: 641 [61440/90000 (68%)]	Loss: 13.1491	Cost: 5.96s
Train Epoch: 641 [81920/90000 (91%)]	Loss: 13.3472	Cost: 5.89s
Train Epoch: 641 	Average Loss: 13.5707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2684

Learning rate: 0.0001979792263290605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: 16.9293	Cost: 20.31s
Train Epoch: 642 [20480/90000 (23%)]	Loss: 13.3218	Cost: 6.05s
Train Epoch: 642 [40960/90000 (45%)]	Loss: 13.4256	Cost: 6.07s
Train Epoch: 642 [61440/90000 (68%)]	Loss: 12.9802	Cost: 5.95s
Train Epoch: 642 [81920/90000 (91%)]	Loss: 13.1891	Cost: 5.78s
Train Epoch: 642 	Average Loss: 13.5054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2715

Learning rate: 0.00019797293774953458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: 16.9310	Cost: 20.49s
Train Epoch: 643 [20480/90000 (23%)]	Loss: 13.2897	Cost: 6.04s
Train Epoch: 643 [40960/90000 (45%)]	Loss: 13.2987	Cost: 6.52s
Train Epoch: 643 [61440/90000 (68%)]	Loss: 13.0024	Cost: 5.93s
Train Epoch: 643 [81920/90000 (91%)]	Loss: 13.3500	Cost: 6.22s
Train Epoch: 643 	Average Loss: 13.4861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3136

Learning rate: 0.00019796663950046741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: 16.9102	Cost: 22.07s
Train Epoch: 644 [20480/90000 (23%)]	Loss: 13.1525	Cost: 5.96s
Train Epoch: 644 [40960/90000 (45%)]	Loss: 13.5855	Cost: 7.41s
Train Epoch: 644 [61440/90000 (68%)]	Loss: 13.3769	Cost: 5.80s
Train Epoch: 644 [81920/90000 (91%)]	Loss: 13.5166	Cost: 5.75s
Train Epoch: 644 	Average Loss: 13.7174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2067

Learning rate: 0.0001979603315824805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: 16.8968	Cost: 20.26s
Train Epoch: 645 [20480/90000 (23%)]	Loss: 13.5715	Cost: 5.99s
Train Epoch: 645 [40960/90000 (45%)]	Loss: 13.5508	Cost: 6.36s
Train Epoch: 645 [61440/90000 (68%)]	Loss: 13.1718	Cost: 6.55s
Train Epoch: 645 [81920/90000 (91%)]	Loss: 13.3158	Cost: 6.14s
Train Epoch: 645 	Average Loss: 13.6846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2113

Learning rate: 0.0001979540139961965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: 17.0223	Cost: 21.85s
Train Epoch: 646 [20480/90000 (23%)]	Loss: 13.4412	Cost: 5.93s
Train Epoch: 646 [40960/90000 (45%)]	Loss: 13.5098	Cost: 6.32s
Train Epoch: 646 [61440/90000 (68%)]	Loss: 13.0970	Cost: 5.84s
Train Epoch: 646 [81920/90000 (91%)]	Loss: 13.2115	Cost: 5.75s
Train Epoch: 646 	Average Loss: 13.5765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2689

Learning rate: 0.0001979476867422389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: 17.1337	Cost: 22.45s
Train Epoch: 647 [20480/90000 (23%)]	Loss: 13.1217	Cost: 5.90s
Train Epoch: 647 [40960/90000 (45%)]	Loss: 13.4429	Cost: 6.06s
Train Epoch: 647 [61440/90000 (68%)]	Loss: 13.0588	Cost: 5.83s
Train Epoch: 647 [81920/90000 (91%)]	Loss: 13.2127	Cost: 5.73s
Train Epoch: 647 	Average Loss: 13.5116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2327

Learning rate: 0.00019794134982123216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: 17.2031	Cost: 19.39s
Train Epoch: 648 [20480/90000 (23%)]	Loss: 12.9909	Cost: 6.11s
Train Epoch: 648 [40960/90000 (45%)]	Loss: 13.3047	Cost: 6.11s
Train Epoch: 648 [61440/90000 (68%)]	Loss: 12.9448	Cost: 5.91s
Train Epoch: 648 [81920/90000 (91%)]	Loss: 12.9411	Cost: 5.78s
Train Epoch: 648 	Average Loss: 13.4793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2894

Learning rate: 0.00019793500323380173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: 17.1043	Cost: 19.54s
Train Epoch: 649 [20480/90000 (23%)]	Loss: 12.9933	Cost: 6.13s
Train Epoch: 649 [40960/90000 (45%)]	Loss: 13.1534	Cost: 6.03s
Train Epoch: 649 [61440/90000 (68%)]	Loss: 12.9420	Cost: 5.88s
Train Epoch: 649 [81920/90000 (91%)]	Loss: 13.1661	Cost: 5.76s
Train Epoch: 649 	Average Loss: 13.4629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2436

Learning rate: 0.000197928646980574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: 16.8812	Cost: 20.96s
Train Epoch: 650 [20480/90000 (23%)]	Loss: 13.1347	Cost: 6.04s
Train Epoch: 650 [40960/90000 (45%)]	Loss: 13.1108	Cost: 6.57s
Train Epoch: 650 [61440/90000 (68%)]	Loss: 13.0722	Cost: 5.87s
Train Epoch: 650 [81920/90000 (91%)]	Loss: 13.3212	Cost: 6.09s
Train Epoch: 650 	Average Loss: 13.4566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3885

Learning rate: 0.00019792228106217628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: 16.9459	Cost: 20.80s
Train Epoch: 651 [20480/90000 (23%)]	Loss: 13.2505	Cost: 6.12s
Train Epoch: 651 [40960/90000 (45%)]	Loss: 13.3892	Cost: 6.66s
Train Epoch: 651 [61440/90000 (68%)]	Loss: 12.9628	Cost: 5.82s
Train Epoch: 651 [81920/90000 (91%)]	Loss: 13.3376	Cost: 5.75s
Train Epoch: 651 	Average Loss: 13.4799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3256

Learning rate: 0.00019791590547923692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: 17.0077	Cost: 20.73s
Train Epoch: 652 [20480/90000 (23%)]	Loss: 12.9487	Cost: 6.08s
Train Epoch: 652 [40960/90000 (45%)]	Loss: 13.1828	Cost: 6.38s
Train Epoch: 652 [61440/90000 (68%)]	Loss: 13.2170	Cost: 6.13s
Train Epoch: 652 [81920/90000 (91%)]	Loss: 13.3845	Cost: 5.96s
Train Epoch: 652 	Average Loss: 13.4823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3217

Learning rate: 0.00019790952023238508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: 16.9635	Cost: 20.49s
Train Epoch: 653 [20480/90000 (23%)]	Loss: 13.1545	Cost: 6.02s
Train Epoch: 653 [40960/90000 (45%)]	Loss: 13.2552	Cost: 6.65s
Train Epoch: 653 [61440/90000 (68%)]	Loss: 13.2230	Cost: 5.83s
Train Epoch: 653 [81920/90000 (91%)]	Loss: 13.1574	Cost: 5.74s
Train Epoch: 653 	Average Loss: 13.4603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4082

Learning rate: 0.000197903125322251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: 17.0403	Cost: 19.95s
Train Epoch: 654 [20480/90000 (23%)]	Loss: 13.0005	Cost: 6.16s
Train Epoch: 654 [40960/90000 (45%)]	Loss: 13.3973	Cost: 6.06s
Train Epoch: 654 [61440/90000 (68%)]	Loss: 13.0402	Cost: 5.87s
Train Epoch: 654 [81920/90000 (91%)]	Loss: 13.2483	Cost: 5.75s
Train Epoch: 654 	Average Loss: 13.4394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3912

Learning rate: 0.00019789672074946586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: 16.9843	Cost: 20.17s
Train Epoch: 655 [20480/90000 (23%)]	Loss: 12.9959	Cost: 6.21s
Train Epoch: 655 [40960/90000 (45%)]	Loss: 13.3435	Cost: 6.14s
Train Epoch: 655 [61440/90000 (68%)]	Loss: 13.0565	Cost: 6.20s
Train Epoch: 655 [81920/90000 (91%)]	Loss: 13.1213	Cost: 5.80s
Train Epoch: 655 	Average Loss: 13.4249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2719

Learning rate: 0.00019789030651466173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: 17.1692	Cost: 21.13s
Train Epoch: 656 [20480/90000 (23%)]	Loss: 12.8724	Cost: 6.10s
Train Epoch: 656 [40960/90000 (45%)]	Loss: 13.1400	Cost: 6.57s
Train Epoch: 656 [61440/90000 (68%)]	Loss: 12.9975	Cost: 5.86s
Train Epoch: 656 [81920/90000 (91%)]	Loss: 13.0223	Cost: 6.08s
Train Epoch: 656 	Average Loss: 13.3962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3140

Learning rate: 0.0001978838826184717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: 17.1254	Cost: 20.56s
Train Epoch: 657 [20480/90000 (23%)]	Loss: 12.9780	Cost: 6.12s
Train Epoch: 657 [40960/90000 (45%)]	Loss: 13.0712	Cost: 7.57s
Train Epoch: 657 [61440/90000 (68%)]	Loss: 12.9204	Cost: 6.01s
Train Epoch: 657 [81920/90000 (91%)]	Loss: 13.0307	Cost: 7.00s
Train Epoch: 657 	Average Loss: 13.4108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3431

Learning rate: 0.00019787744906152977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: 17.0070	Cost: 20.00s
Train Epoch: 658 [20480/90000 (23%)]	Loss: 13.0928	Cost: 6.07s
Train Epoch: 658 [40960/90000 (45%)]	Loss: 13.3175	Cost: 6.23s
Train Epoch: 658 [61440/90000 (68%)]	Loss: 13.0759	Cost: 5.87s
Train Epoch: 658 [81920/90000 (91%)]	Loss: 13.1505	Cost: 5.74s
Train Epoch: 658 	Average Loss: 13.4103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3895

Learning rate: 0.00019787100584447087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: 17.0191	Cost: 20.65s
Train Epoch: 659 [20480/90000 (23%)]	Loss: 12.9595	Cost: 6.04s
Train Epoch: 659 [40960/90000 (45%)]	Loss: 13.1623	Cost: 6.66s
Train Epoch: 659 [61440/90000 (68%)]	Loss: 13.0885	Cost: 5.94s
Train Epoch: 659 [81920/90000 (91%)]	Loss: 13.1485	Cost: 6.23s
Train Epoch: 659 	Average Loss: 13.3828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4062

Learning rate: 0.00019786455296793095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: 17.2431	Cost: 19.38s
Train Epoch: 660 [20480/90000 (23%)]	Loss: 13.0996	Cost: 6.07s
Train Epoch: 660 [40960/90000 (45%)]	Loss: 13.1011	Cost: 6.56s
Train Epoch: 660 [61440/90000 (68%)]	Loss: 13.0570	Cost: 5.85s
Train Epoch: 660 [81920/90000 (91%)]	Loss: 12.9201	Cost: 5.82s
Train Epoch: 660 	Average Loss: 13.3911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3948

Learning rate: 0.0001978580904325469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: 17.0959	Cost: 20.36s
Train Epoch: 661 [20480/90000 (23%)]	Loss: 13.0347	Cost: 6.01s
Train Epoch: 661 [40960/90000 (45%)]	Loss: 13.2131	Cost: 7.48s
Train Epoch: 661 [61440/90000 (68%)]	Loss: 12.8521	Cost: 6.56s
Train Epoch: 661 [81920/90000 (91%)]	Loss: 13.1371	Cost: 6.48s
Train Epoch: 661 	Average Loss: 13.3434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4617

Learning rate: 0.00019785161823895653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: 16.9321	Cost: 20.32s
Train Epoch: 662 [20480/90000 (23%)]	Loss: 12.9988	Cost: 6.06s
Train Epoch: 662 [40960/90000 (45%)]	Loss: 13.1531	Cost: 6.82s
Train Epoch: 662 [61440/90000 (68%)]	Loss: 12.8677	Cost: 5.81s
Train Epoch: 662 [81920/90000 (91%)]	Loss: 13.0559	Cost: 5.91s
Train Epoch: 662 	Average Loss: 13.3773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4810

Learning rate: 0.00019784513638779864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: 17.2236	Cost: 19.85s
Train Epoch: 663 [20480/90000 (23%)]	Loss: 13.0150	Cost: 6.02s
Train Epoch: 663 [40960/90000 (45%)]	Loss: 13.1241	Cost: 6.85s
Train Epoch: 663 [61440/90000 (68%)]	Loss: 13.0603	Cost: 5.98s
Train Epoch: 663 [81920/90000 (91%)]	Loss: 13.3643	Cost: 5.70s
Train Epoch: 663 	Average Loss: 13.3613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4192

Learning rate: 0.0001978386448797129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: 17.1958	Cost: 20.08s
Train Epoch: 664 [20480/90000 (23%)]	Loss: 12.9113	Cost: 5.99s
Train Epoch: 664 [40960/90000 (45%)]	Loss: 12.9522	Cost: 6.76s
Train Epoch: 664 [61440/90000 (68%)]	Loss: 12.9571	Cost: 5.86s
Train Epoch: 664 [81920/90000 (91%)]	Loss: 12.9960	Cost: 5.66s
Train Epoch: 664 	Average Loss: 13.3398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3581

Learning rate: 0.00019783214371534008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: 17.1416	Cost: 19.52s
Train Epoch: 665 [20480/90000 (23%)]	Loss: 13.1114	Cost: 6.22s
Train Epoch: 665 [40960/90000 (45%)]	Loss: 13.0362	Cost: 5.79s
Train Epoch: 665 [61440/90000 (68%)]	Loss: 13.0580	Cost: 5.63s
Train Epoch: 665 [81920/90000 (91%)]	Loss: 12.9678	Cost: 5.65s
Train Epoch: 665 	Average Loss: 13.3284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4290

Learning rate: 0.00019782563289532173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: 17.2309	Cost: 20.63s
Train Epoch: 666 [20480/90000 (23%)]	Loss: 12.9580	Cost: 5.98s
Train Epoch: 666 [40960/90000 (45%)]	Loss: 13.2731	Cost: 6.21s
Train Epoch: 666 [61440/90000 (68%)]	Loss: 12.8826	Cost: 5.84s
Train Epoch: 666 [81920/90000 (91%)]	Loss: 12.9488	Cost: 5.69s
Train Epoch: 666 	Average Loss: 13.3139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3505

Learning rate: 0.0001978191124203005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: 17.0361	Cost: 21.49s
Train Epoch: 667 [20480/90000 (23%)]	Loss: 12.8370	Cost: 5.92s
Train Epoch: 667 [40960/90000 (45%)]	Loss: 13.1881	Cost: 6.85s
Train Epoch: 667 [61440/90000 (68%)]	Loss: 12.9118	Cost: 5.78s
Train Epoch: 667 [81920/90000 (91%)]	Loss: 12.9599	Cost: 5.65s
Train Epoch: 667 	Average Loss: 13.3123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4582

Learning rate: 0.00019781258229091995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: 17.0755	Cost: 22.14s
Train Epoch: 668 [20480/90000 (23%)]	Loss: 12.8400	Cost: 6.03s
Train Epoch: 668 [40960/90000 (45%)]	Loss: 13.0285	Cost: 6.40s
Train Epoch: 668 [61440/90000 (68%)]	Loss: 12.8699	Cost: 5.83s
Train Epoch: 668 [81920/90000 (91%)]	Loss: 13.0319	Cost: 5.73s
Train Epoch: 668 	Average Loss: 13.2577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5352

Learning rate: 0.00019780604250782451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: 17.2619	Cost: 19.97s
Train Epoch: 669 [20480/90000 (23%)]	Loss: 12.9561	Cost: 6.04s
Train Epoch: 669 [40960/90000 (45%)]	Loss: 13.1041	Cost: 6.72s
Train Epoch: 669 [61440/90000 (68%)]	Loss: 12.9339	Cost: 5.83s
Train Epoch: 669 [81920/90000 (91%)]	Loss: 13.1206	Cost: 5.73s
Train Epoch: 669 	Average Loss: 13.3281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4520

Learning rate: 0.00019779949307165972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: 17.2886	Cost: 21.26s
Train Epoch: 670 [20480/90000 (23%)]	Loss: 12.9275	Cost: 5.99s
Train Epoch: 670 [40960/90000 (45%)]	Loss: 13.1229	Cost: 6.19s
Train Epoch: 670 [61440/90000 (68%)]	Loss: 12.8523	Cost: 5.87s
Train Epoch: 670 [81920/90000 (91%)]	Loss: 13.0832	Cost: 5.77s
Train Epoch: 670 	Average Loss: 13.2928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3780

Learning rate: 0.00019779293398307192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: 17.3347	Cost: 20.73s
Train Epoch: 671 [20480/90000 (23%)]	Loss: 13.0094	Cost: 5.99s
Train Epoch: 671 [40960/90000 (45%)]	Loss: 13.1299	Cost: 6.25s
Train Epoch: 671 [61440/90000 (68%)]	Loss: 12.6963	Cost: 5.82s
Train Epoch: 671 [81920/90000 (91%)]	Loss: 13.0824	Cost: 5.70s
Train Epoch: 671 	Average Loss: 13.2664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3737

Learning rate: 0.00019778636524270848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: 17.0929	Cost: 20.51s
Train Epoch: 672 [20480/90000 (23%)]	Loss: 12.7933	Cost: 6.02s
Train Epoch: 672 [40960/90000 (45%)]	Loss: 13.2335	Cost: 6.09s
Train Epoch: 672 [61440/90000 (68%)]	Loss: 12.9997	Cost: 5.85s
Train Epoch: 672 [81920/90000 (91%)]	Loss: 12.9364	Cost: 5.71s
Train Epoch: 672 	Average Loss: 13.2783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3963

Learning rate: 0.0001977797868512177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: 17.3064	Cost: 20.83s
Train Epoch: 673 [20480/90000 (23%)]	Loss: 12.7047	Cost: 6.01s
Train Epoch: 673 [40960/90000 (45%)]	Loss: 13.0149	Cost: 6.07s
Train Epoch: 673 [61440/90000 (68%)]	Loss: 12.6278	Cost: 6.00s
Train Epoch: 673 [81920/90000 (91%)]	Loss: 12.8542	Cost: 5.92s
Train Epoch: 673 	Average Loss: 13.2167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3708

Learning rate: 0.00019777319880924887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: 17.2539	Cost: 21.80s
Train Epoch: 674 [20480/90000 (23%)]	Loss: 12.8775	Cost: 5.96s
Train Epoch: 674 [40960/90000 (45%)]	Loss: 13.0381	Cost: 5.97s
Train Epoch: 674 [61440/90000 (68%)]	Loss: 12.8832	Cost: 5.79s
Train Epoch: 674 [81920/90000 (91%)]	Loss: 13.0614	Cost: 5.70s
Train Epoch: 674 	Average Loss: 13.2351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5075

Learning rate: 0.0001977666011174522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: 17.0885	Cost: 20.71s
Train Epoch: 675 [20480/90000 (23%)]	Loss: 12.7888	Cost: 6.06s
Train Epoch: 675 [40960/90000 (45%)]	Loss: 13.1028	Cost: 6.07s
Train Epoch: 675 [61440/90000 (68%)]	Loss: 12.9237	Cost: 5.89s
Train Epoch: 675 [81920/90000 (91%)]	Loss: 13.0059	Cost: 5.69s
Train Epoch: 675 	Average Loss: 13.2508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4408

Learning rate: 0.00019775999377647882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: 17.2530	Cost: 20.36s
Train Epoch: 676 [20480/90000 (23%)]	Loss: 12.6726	Cost: 6.34s
Train Epoch: 676 [40960/90000 (45%)]	Loss: 12.8418	Cost: 6.03s
Train Epoch: 676 [61440/90000 (68%)]	Loss: 12.7229	Cost: 5.83s
Train Epoch: 676 [81920/90000 (91%)]	Loss: 12.8842	Cost: 5.68s
Train Epoch: 676 	Average Loss: 13.2316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4397

Learning rate: 0.00019775337678698088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: 17.3087	Cost: 19.93s
Train Epoch: 677 [20480/90000 (23%)]	Loss: 12.8631	Cost: 6.06s
Train Epoch: 677 [40960/90000 (45%)]	Loss: 13.0914	Cost: 6.01s
Train Epoch: 677 [61440/90000 (68%)]	Loss: 12.7792	Cost: 5.97s
Train Epoch: 677 [81920/90000 (91%)]	Loss: 12.9852	Cost: 5.93s
Train Epoch: 677 	Average Loss: 13.1887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4557

Learning rate: 0.00019774675014961146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: 17.2463	Cost: 20.22s
Train Epoch: 678 [20480/90000 (23%)]	Loss: 12.9749	Cost: 5.98s
Train Epoch: 678 [40960/90000 (45%)]	Loss: 12.9830	Cost: 6.01s
Train Epoch: 678 [61440/90000 (68%)]	Loss: 12.8151	Cost: 5.85s
Train Epoch: 678 [81920/90000 (91%)]	Loss: 13.0330	Cost: 5.69s
Train Epoch: 678 	Average Loss: 13.2442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4365

Learning rate: 0.00019774011386502452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: 17.2969	Cost: 20.92s
Train Epoch: 679 [20480/90000 (23%)]	Loss: 12.6950	Cost: 5.96s
Train Epoch: 679 [40960/90000 (45%)]	Loss: 13.0119	Cost: 5.97s
Train Epoch: 679 [61440/90000 (68%)]	Loss: 12.8480	Cost: 5.87s
Train Epoch: 679 [81920/90000 (91%)]	Loss: 12.9320	Cost: 5.71s
Train Epoch: 679 	Average Loss: 13.2269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5118

Learning rate: 0.0001977334679338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: 17.0899	Cost: 20.98s
Train Epoch: 680 [20480/90000 (23%)]	Loss: 12.8327	Cost: 5.96s
Train Epoch: 680 [40960/90000 (45%)]	Loss: 12.9855	Cost: 6.05s
Train Epoch: 680 [61440/90000 (68%)]	Loss: 12.7617	Cost: 5.90s
Train Epoch: 680 [81920/90000 (91%)]	Loss: 12.8502	Cost: 5.93s
Train Epoch: 680 	Average Loss: 13.1791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4604

Learning rate: 0.0001977268123568191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: 17.1977	Cost: 23.00s
Train Epoch: 681 [20480/90000 (23%)]	Loss: 12.6604	Cost: 5.94s
Train Epoch: 681 [40960/90000 (45%)]	Loss: 12.8519	Cost: 6.04s
Train Epoch: 681 [61440/90000 (68%)]	Loss: 12.8124	Cost: 5.82s
Train Epoch: 681 [81920/90000 (91%)]	Loss: 13.0184	Cost: 5.72s
Train Epoch: 681 	Average Loss: 13.1490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5251

Learning rate: 0.00019772014713451342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: 17.3817	Cost: 22.80s
Train Epoch: 682 [20480/90000 (23%)]	Loss: 12.5902	Cost: 5.74s
Train Epoch: 682 [40960/90000 (45%)]	Loss: 12.9849	Cost: 6.44s
Train Epoch: 682 [61440/90000 (68%)]	Loss: 12.7567	Cost: 5.61s
Train Epoch: 682 [81920/90000 (91%)]	Loss: 13.0727	Cost: 6.14s
Train Epoch: 682 	Average Loss: 13.1493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5360

Learning rate: 0.00019771347226761588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: 17.2698	Cost: 23.81s
Train Epoch: 683 [20480/90000 (23%)]	Loss: 12.7103	Cost: 6.00s
Train Epoch: 683 [40960/90000 (45%)]	Loss: 12.8550	Cost: 6.06s
Train Epoch: 683 [61440/90000 (68%)]	Loss: 12.8279	Cost: 5.83s
Train Epoch: 683 [81920/90000 (91%)]	Loss: 13.0195	Cost: 5.72s
Train Epoch: 683 	Average Loss: 13.1701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5733

Learning rate: 0.00019770678775678525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: 17.4017	Cost: 25.55s
Train Epoch: 684 [20480/90000 (23%)]	Loss: 12.6919	Cost: 6.49s
Train Epoch: 684 [40960/90000 (45%)]	Loss: 12.7920	Cost: 6.03s
Train Epoch: 684 [61440/90000 (68%)]	Loss: 12.6779	Cost: 5.83s
Train Epoch: 684 [81920/90000 (91%)]	Loss: 12.7492	Cost: 5.75s
Train Epoch: 684 	Average Loss: 13.1694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5361

Learning rate: 0.00019770009360268128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: 17.2765	Cost: 23.13s
Train Epoch: 685 [20480/90000 (23%)]	Loss: 12.7548	Cost: 6.50s
Train Epoch: 685 [40960/90000 (45%)]	Loss: 12.9296	Cost: 6.03s
Train Epoch: 685 [61440/90000 (68%)]	Loss: 12.7860	Cost: 6.08s
Train Epoch: 685 [81920/90000 (91%)]	Loss: 13.0011	Cost: 5.74s
Train Epoch: 685 	Average Loss: 13.1584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5268

Learning rate: 0.00019769338980596464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: 17.1774	Cost: 23.89s
Train Epoch: 686 [20480/90000 (23%)]	Loss: 12.7266	Cost: 7.11s
Train Epoch: 686 [40960/90000 (45%)]	Loss: 12.6708	Cost: 5.99s
Train Epoch: 686 [61440/90000 (68%)]	Loss: 12.6161	Cost: 5.91s
Train Epoch: 686 [81920/90000 (91%)]	Loss: 12.7124	Cost: 5.78s
Train Epoch: 686 	Average Loss: 13.1049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4829

Learning rate: 0.00019768667636729697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: 17.1871	Cost: 21.84s
Train Epoch: 687 [20480/90000 (23%)]	Loss: 12.5231	Cost: 6.07s
Train Epoch: 687 [40960/90000 (45%)]	Loss: 12.9858	Cost: 6.21s
Train Epoch: 687 [61440/90000 (68%)]	Loss: 12.6271	Cost: 5.89s
Train Epoch: 687 [81920/90000 (91%)]	Loss: 12.8676	Cost: 6.35s
Train Epoch: 687 	Average Loss: 13.1332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5613

Learning rate: 0.0001976799532873409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: 17.3903	Cost: 20.49s
Train Epoch: 688 [20480/90000 (23%)]	Loss: 12.8315	Cost: 6.43s
Train Epoch: 688 [40960/90000 (45%)]	Loss: 12.8786	Cost: 6.02s
Train Epoch: 688 [61440/90000 (68%)]	Loss: 12.6412	Cost: 5.88s
Train Epoch: 688 [81920/90000 (91%)]	Loss: 12.6750	Cost: 5.77s
Train Epoch: 688 	Average Loss: 13.1333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5822

Learning rate: 0.00019767322056675991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: 17.3850	Cost: 19.99s
Train Epoch: 689 [20480/90000 (23%)]	Loss: 12.6571	Cost: 6.53s
Train Epoch: 689 [40960/90000 (45%)]	Loss: 12.9340	Cost: 6.30s
Train Epoch: 689 [61440/90000 (68%)]	Loss: 12.9686	Cost: 6.04s
Train Epoch: 689 [81920/90000 (91%)]	Loss: 13.0058	Cost: 6.33s
Train Epoch: 689 	Average Loss: 13.1126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5834

Learning rate: 0.00019766647820621853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: 17.1714	Cost: 19.75s
Train Epoch: 690 [20480/90000 (23%)]	Loss: 12.5190	Cost: 6.05s
Train Epoch: 690 [40960/90000 (45%)]	Loss: 12.9346	Cost: 6.07s
Train Epoch: 690 [61440/90000 (68%)]	Loss: 12.7173	Cost: 5.95s
Train Epoch: 690 [81920/90000 (91%)]	Loss: 12.6674	Cost: 6.09s
Train Epoch: 690 	Average Loss: 13.0860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5301

Learning rate: 0.0001976597262063822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: 17.0854	Cost: 19.95s
Train Epoch: 691 [20480/90000 (23%)]	Loss: 12.8982	Cost: 5.97s
Train Epoch: 691 [40960/90000 (45%)]	Loss: 12.8652	Cost: 6.02s
Train Epoch: 691 [61440/90000 (68%)]	Loss: 12.7082	Cost: 5.97s
Train Epoch: 691 [81920/90000 (91%)]	Loss: 12.8035	Cost: 5.97s
Train Epoch: 691 	Average Loss: 13.0804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4142

Learning rate: 0.00019765296456791733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: 17.2032	Cost: 21.03s
Train Epoch: 692 [20480/90000 (23%)]	Loss: 12.6560	Cost: 6.02s
Train Epoch: 692 [40960/90000 (45%)]	Loss: 12.7669	Cost: 6.51s
Train Epoch: 692 [61440/90000 (68%)]	Loss: 12.5327	Cost: 6.10s
Train Epoch: 692 [81920/90000 (91%)]	Loss: 12.8481	Cost: 7.00s
Train Epoch: 692 	Average Loss: 13.0372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6369

Learning rate: 0.00019764619329149126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: 17.1803	Cost: 20.66s
Train Epoch: 693 [20480/90000 (23%)]	Loss: 12.6695	Cost: 5.95s
Train Epoch: 693 [40960/90000 (45%)]	Loss: 12.9259	Cost: 6.12s
Train Epoch: 693 [61440/90000 (68%)]	Loss: 12.6505	Cost: 6.01s
Train Epoch: 693 [81920/90000 (91%)]	Loss: 12.8523	Cost: 6.65s
Train Epoch: 693 	Average Loss: 13.0656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5945

Learning rate: 0.00019763941237777225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: 17.3705	Cost: 20.61s
Train Epoch: 694 [20480/90000 (23%)]	Loss: 12.6646	Cost: 5.97s
Train Epoch: 694 [40960/90000 (45%)]	Loss: 12.8307	Cost: 6.82s
Train Epoch: 694 [61440/90000 (68%)]	Loss: 12.6353	Cost: 5.95s
Train Epoch: 694 [81920/90000 (91%)]	Loss: 12.9004	Cost: 6.73s
Train Epoch: 694 	Average Loss: 13.1025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6196

Learning rate: 0.0001976326218274296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: 17.2116	Cost: 20.76s
Train Epoch: 695 [20480/90000 (23%)]	Loss: 12.8788	Cost: 6.04s
Train Epoch: 695 [40960/90000 (45%)]	Loss: 12.7681	Cost: 6.20s
Train Epoch: 695 [61440/90000 (68%)]	Loss: 12.6075	Cost: 5.89s
Train Epoch: 695 [81920/90000 (91%)]	Loss: 12.8533	Cost: 6.63s
Train Epoch: 695 	Average Loss: 13.0790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5001

Learning rate: 0.00019762582164113346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: 17.3486	Cost: 21.24s
Train Epoch: 696 [20480/90000 (23%)]	Loss: 12.5292	Cost: 6.04s
Train Epoch: 696 [40960/90000 (45%)]	Loss: 12.8355	Cost: 6.16s
Train Epoch: 696 [61440/90000 (68%)]	Loss: 12.6625	Cost: 6.10s
Train Epoch: 696 [81920/90000 (91%)]	Loss: 12.8546	Cost: 6.02s
Train Epoch: 696 	Average Loss: 13.0163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6572

Learning rate: 0.00019761901181955505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: 17.3153	Cost: 20.89s
Train Epoch: 697 [20480/90000 (23%)]	Loss: 12.5750	Cost: 6.01s
Train Epoch: 697 [40960/90000 (45%)]	Loss: 12.7264	Cost: 6.36s
Train Epoch: 697 [61440/90000 (68%)]	Loss: 12.6696	Cost: 5.87s
Train Epoch: 697 [81920/90000 (91%)]	Loss: 12.7614	Cost: 5.82s
Train Epoch: 697 	Average Loss: 13.0211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6100

Learning rate: 0.0001976121923633664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: 17.3216	Cost: 21.19s
Train Epoch: 698 [20480/90000 (23%)]	Loss: 12.7333	Cost: 6.00s
Train Epoch: 698 [40960/90000 (45%)]	Loss: 12.6664	Cost: 6.54s
Train Epoch: 698 [61440/90000 (68%)]	Loss: 12.7047	Cost: 6.03s
Train Epoch: 698 [81920/90000 (91%)]	Loss: 12.7714	Cost: 5.91s
Train Epoch: 698 	Average Loss: 13.0083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6220

Learning rate: 0.0001976053632732406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: 17.2615	Cost: 21.56s
Train Epoch: 699 [20480/90000 (23%)]	Loss: 12.6471	Cost: 5.97s
Train Epoch: 699 [40960/90000 (45%)]	Loss: 12.7831	Cost: 6.81s
Train Epoch: 699 [61440/90000 (68%)]	Loss: 12.5713	Cost: 5.80s
Train Epoch: 699 [81920/90000 (91%)]	Loss: 12.6825	Cost: 6.10s
Train Epoch: 699 	Average Loss: 12.9856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5741

Learning rate: 0.00019759852454985166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: 17.2395	Cost: 20.74s
Train Epoch: 700 [20480/90000 (23%)]	Loss: 12.7410	Cost: 5.92s
Train Epoch: 700 [40960/90000 (45%)]	Loss: 12.6664	Cost: 6.47s
Train Epoch: 700 [61440/90000 (68%)]	Loss: 12.6463	Cost: 5.86s
Train Epoch: 700 [81920/90000 (91%)]	Loss: 12.5332	Cost: 6.01s
Train Epoch: 700 	Average Loss: 12.9568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6478

Learning rate: 0.0001975916761938745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: 17.4930	Cost: 20.61s
Train Epoch: 701 [20480/90000 (23%)]	Loss: 12.6689	Cost: 6.02s
Train Epoch: 701 [40960/90000 (45%)]	Loss: 12.8181	Cost: 6.58s
Train Epoch: 701 [61440/90000 (68%)]	Loss: 12.6685	Cost: 5.84s
Train Epoch: 701 [81920/90000 (91%)]	Loss: 12.6121	Cost: 5.72s
Train Epoch: 701 	Average Loss: 12.9768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6191

Learning rate: 0.00019758481820598506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: 17.2981	Cost: 19.57s
Train Epoch: 702 [20480/90000 (23%)]	Loss: 12.5487	Cost: 6.03s
Train Epoch: 702 [40960/90000 (45%)]	Loss: 12.8168	Cost: 5.99s
Train Epoch: 702 [61440/90000 (68%)]	Loss: 12.5538	Cost: 5.91s
Train Epoch: 702 [81920/90000 (91%)]	Loss: 12.6675	Cost: 5.74s
Train Epoch: 702 	Average Loss: 12.9885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6184

Learning rate: 0.0001975779505868602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: 17.4865	Cost: 21.02s
Train Epoch: 703 [20480/90000 (23%)]	Loss: 12.6141	Cost: 5.98s
Train Epoch: 703 [40960/90000 (45%)]	Loss: 12.8333	Cost: 6.11s
Train Epoch: 703 [61440/90000 (68%)]	Loss: 12.7525	Cost: 5.91s
Train Epoch: 703 [81920/90000 (91%)]	Loss: 12.6181	Cost: 5.87s
Train Epoch: 703 	Average Loss: 12.9895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6164

Learning rate: 0.0001975710733371777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: 17.1732	Cost: 19.61s
Train Epoch: 704 [20480/90000 (23%)]	Loss: 12.4541	Cost: 6.02s
Train Epoch: 704 [40960/90000 (45%)]	Loss: 12.6133	Cost: 6.04s
Train Epoch: 704 [61440/90000 (68%)]	Loss: 12.5170	Cost: 5.88s
Train Epoch: 704 [81920/90000 (91%)]	Loss: 12.5531	Cost: 5.69s
Train Epoch: 704 	Average Loss: 12.9439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6836

Learning rate: 0.00019756418645761634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: 17.5511	Cost: 20.73s
Train Epoch: 705 [20480/90000 (23%)]	Loss: 12.4343	Cost: 5.97s
Train Epoch: 705 [40960/90000 (45%)]	Loss: 12.7648	Cost: 5.99s
Train Epoch: 705 [61440/90000 (68%)]	Loss: 12.4885	Cost: 5.82s
Train Epoch: 705 [81920/90000 (91%)]	Loss: 12.6433	Cost: 6.14s
Train Epoch: 705 	Average Loss: 12.9394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7035

Learning rate: 0.0001975572899488558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: 17.2385	Cost: 20.68s
Train Epoch: 706 [20480/90000 (23%)]	Loss: 12.5675	Cost: 5.98s
Train Epoch: 706 [40960/90000 (45%)]	Loss: 12.5980	Cost: 7.21s
Train Epoch: 706 [61440/90000 (68%)]	Loss: 12.5362	Cost: 5.80s
Train Epoch: 706 [81920/90000 (91%)]	Loss: 12.6203	Cost: 5.73s
Train Epoch: 706 	Average Loss: 12.9570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6141

Learning rate: 0.0001975503838115768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: 17.3604	Cost: 20.07s
Train Epoch: 707 [20480/90000 (23%)]	Loss: 12.4383	Cost: 5.83s
Train Epoch: 707 [40960/90000 (45%)]	Loss: 12.6742	Cost: 7.67s
Train Epoch: 707 [61440/90000 (68%)]	Loss: 12.3452	Cost: 5.76s
Train Epoch: 707 [81920/90000 (91%)]	Loss: 12.7369	Cost: 5.45s
Train Epoch: 707 	Average Loss: 12.8896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6693

Learning rate: 0.00019754346804646088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: 17.2494	Cost: 19.96s
Train Epoch: 708 [20480/90000 (23%)]	Loss: 12.4886	Cost: 5.81s
Train Epoch: 708 [40960/90000 (45%)]	Loss: 12.4422	Cost: 6.30s
Train Epoch: 708 [61440/90000 (68%)]	Loss: 12.6495	Cost: 5.64s
Train Epoch: 708 [81920/90000 (91%)]	Loss: 12.5947	Cost: 5.51s
Train Epoch: 708 	Average Loss: 12.8966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7340

Learning rate: 0.00019753654265419063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: 17.4395	Cost: 21.20s
Train Epoch: 709 [20480/90000 (23%)]	Loss: 12.4825	Cost: 6.10s
Train Epoch: 709 [40960/90000 (45%)]	Loss: 12.6967	Cost: 6.06s
Train Epoch: 709 [61440/90000 (68%)]	Loss: 12.5643	Cost: 5.94s
Train Epoch: 709 [81920/90000 (91%)]	Loss: 12.7478	Cost: 5.98s
Train Epoch: 709 	Average Loss: 12.9246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6775

Learning rate: 0.00019752960763544955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: 17.5065	Cost: 20.33s
Train Epoch: 710 [20480/90000 (23%)]	Loss: 12.6184	Cost: 6.00s
Train Epoch: 710 [40960/90000 (45%)]	Loss: 12.4528	Cost: 6.54s
Train Epoch: 710 [61440/90000 (68%)]	Loss: 12.4912	Cost: 5.84s
Train Epoch: 710 [81920/90000 (91%)]	Loss: 12.7274	Cost: 5.92s
Train Epoch: 710 	Average Loss: 12.9293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6835

Learning rate: 0.0001975226629909221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: 17.4001	Cost: 21.96s
Train Epoch: 711 [20480/90000 (23%)]	Loss: 12.5441	Cost: 5.99s
Train Epoch: 711 [40960/90000 (45%)]	Loss: 12.6640	Cost: 6.29s
Train Epoch: 711 [61440/90000 (68%)]	Loss: 12.2953	Cost: 5.93s
Train Epoch: 711 [81920/90000 (91%)]	Loss: 12.4540	Cost: 5.77s
Train Epoch: 711 	Average Loss: 12.8837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6743

Learning rate: 0.00019751570872129367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: 17.2774	Cost: 20.52s
Train Epoch: 712 [20480/90000 (23%)]	Loss: 12.5806	Cost: 5.98s
Train Epoch: 712 [40960/90000 (45%)]	Loss: 12.7210	Cost: 6.01s
Train Epoch: 712 [61440/90000 (68%)]	Loss: 12.6376	Cost: 5.88s
Train Epoch: 712 [81920/90000 (91%)]	Loss: 12.5081	Cost: 5.66s
Train Epoch: 712 	Average Loss: 12.9502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7021

Learning rate: 0.00019750874482725065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: 17.5735	Cost: 20.50s
Train Epoch: 713 [20480/90000 (23%)]	Loss: 12.4401	Cost: 6.05s
Train Epoch: 713 [40960/90000 (45%)]	Loss: 12.5709	Cost: 6.70s
Train Epoch: 713 [61440/90000 (68%)]	Loss: 12.5691	Cost: 5.87s
Train Epoch: 713 [81920/90000 (91%)]	Loss: 12.6104	Cost: 6.14s
Train Epoch: 713 	Average Loss: 12.8855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7006

Learning rate: 0.00019750177130948036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: 17.3426	Cost: 19.91s
Train Epoch: 714 [20480/90000 (23%)]	Loss: 12.3343	Cost: 6.19s
Train Epoch: 714 [40960/90000 (45%)]	Loss: 12.6175	Cost: 6.28s
Train Epoch: 714 [61440/90000 (68%)]	Loss: 12.5483	Cost: 5.83s
Train Epoch: 714 [81920/90000 (91%)]	Loss: 12.6368	Cost: 5.69s
Train Epoch: 714 	Average Loss: 12.8476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7184

Learning rate: 0.00019749478816867102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: 17.6260	Cost: 20.10s
Train Epoch: 715 [20480/90000 (23%)]	Loss: 12.5835	Cost: 6.07s
Train Epoch: 715 [40960/90000 (45%)]	Loss: 12.6856	Cost: 6.09s
Train Epoch: 715 [61440/90000 (68%)]	Loss: 12.4701	Cost: 5.94s
Train Epoch: 715 [81920/90000 (91%)]	Loss: 12.6758	Cost: 5.75s
Train Epoch: 715 	Average Loss: 12.9178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7026

Learning rate: 0.0001974877954055119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: 17.3543	Cost: 20.78s
Train Epoch: 716 [20480/90000 (23%)]	Loss: 12.4501	Cost: 6.07s
Train Epoch: 716 [40960/90000 (45%)]	Loss: 12.4923	Cost: 7.15s
Train Epoch: 716 [61440/90000 (68%)]	Loss: 12.5751	Cost: 5.80s
Train Epoch: 716 [81920/90000 (91%)]	Loss: 12.6385	Cost: 5.97s
Train Epoch: 716 	Average Loss: 12.8420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7413

Learning rate: 0.00019748079302069307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: 17.4951	Cost: 19.99s
Train Epoch: 717 [20480/90000 (23%)]	Loss: 12.2723	Cost: 6.02s
Train Epoch: 717 [40960/90000 (45%)]	Loss: 12.3991	Cost: 6.89s
Train Epoch: 717 [61440/90000 (68%)]	Loss: 12.3757	Cost: 6.02s
Train Epoch: 717 [81920/90000 (91%)]	Loss: 12.5164	Cost: 5.99s
Train Epoch: 717 	Average Loss: 12.8247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6956

Learning rate: 0.00019747378101490567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: 17.5551	Cost: 20.23s
Train Epoch: 718 [20480/90000 (23%)]	Loss: 12.4451	Cost: 6.06s
Train Epoch: 718 [40960/90000 (45%)]	Loss: 12.6387	Cost: 6.20s
Train Epoch: 718 [61440/90000 (68%)]	Loss: 12.5105	Cost: 6.02s
Train Epoch: 718 [81920/90000 (91%)]	Loss: 12.4751	Cost: 5.68s
Train Epoch: 718 	Average Loss: 12.8253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7745

Learning rate: 0.00019746675938884178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: 17.5767	Cost: 20.04s
Train Epoch: 719 [20480/90000 (23%)]	Loss: 12.3762	Cost: 6.10s
Train Epoch: 719 [40960/90000 (45%)]	Loss: 12.3002	Cost: 6.11s
Train Epoch: 719 [61440/90000 (68%)]	Loss: 12.4541	Cost: 5.83s
Train Epoch: 719 [81920/90000 (91%)]	Loss: 12.4692	Cost: 5.72s
Train Epoch: 719 	Average Loss: 12.7731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7609

Learning rate: 0.0001974597281431944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: 17.3205	Cost: 20.17s
Train Epoch: 720 [20480/90000 (23%)]	Loss: 12.4810	Cost: 5.97s
Train Epoch: 720 [40960/90000 (45%)]	Loss: 12.5597	Cost: 6.52s
Train Epoch: 720 [61440/90000 (68%)]	Loss: 12.1265	Cost: 5.82s
Train Epoch: 720 [81920/90000 (91%)]	Loss: 12.4024	Cost: 5.67s
Train Epoch: 720 	Average Loss: 12.7916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7931

Learning rate: 0.0001974526872786575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: 17.4591	Cost: 19.47s
Train Epoch: 721 [20480/90000 (23%)]	Loss: 12.4018	Cost: 6.11s
Train Epoch: 721 [40960/90000 (45%)]	Loss: 12.3067	Cost: 6.09s
Train Epoch: 721 [61440/90000 (68%)]	Loss: 12.5954	Cost: 5.94s
Train Epoch: 721 [81920/90000 (91%)]	Loss: 12.5884	Cost: 5.78s
Train Epoch: 721 	Average Loss: 12.8129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8331

Learning rate: 0.00019744563679592594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: 17.3952	Cost: 21.18s
Train Epoch: 722 [20480/90000 (23%)]	Loss: 12.3449	Cost: 5.99s
Train Epoch: 722 [40960/90000 (45%)]	Loss: 12.5843	Cost: 6.07s
Train Epoch: 722 [61440/90000 (68%)]	Loss: 12.3721	Cost: 5.85s
Train Epoch: 722 [81920/90000 (91%)]	Loss: 12.5139	Cost: 5.63s
Train Epoch: 722 	Average Loss: 12.8147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8597

Learning rate: 0.0001974385766956956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: 17.5499	Cost: 20.14s
Train Epoch: 723 [20480/90000 (23%)]	Loss: 12.5013	Cost: 5.98s
Train Epoch: 723 [40960/90000 (45%)]	Loss: 12.2949	Cost: 6.00s
Train Epoch: 723 [61440/90000 (68%)]	Loss: 12.3885	Cost: 5.83s
Train Epoch: 723 [81920/90000 (91%)]	Loss: 12.6146	Cost: 5.66s
Train Epoch: 723 	Average Loss: 12.8289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7526

Learning rate: 0.0001974315069786633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: 17.4323	Cost: 20.36s
Train Epoch: 724 [20480/90000 (23%)]	Loss: 12.4437	Cost: 6.08s
Train Epoch: 724 [40960/90000 (45%)]	Loss: 12.5054	Cost: 6.37s
Train Epoch: 724 [61440/90000 (68%)]	Loss: 12.1001	Cost: 5.91s
Train Epoch: 724 [81920/90000 (91%)]	Loss: 12.5291	Cost: 5.77s
Train Epoch: 724 	Average Loss: 12.7662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7956

Learning rate: 0.00019742442764552676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: 17.4228	Cost: 20.02s
Train Epoch: 725 [20480/90000 (23%)]	Loss: 12.2714	Cost: 6.11s
Train Epoch: 725 [40960/90000 (45%)]	Loss: 12.4215	Cost: 6.04s
Train Epoch: 725 [61440/90000 (68%)]	Loss: 12.4667	Cost: 5.83s
Train Epoch: 725 [81920/90000 (91%)]	Loss: 12.3841	Cost: 5.68s
Train Epoch: 725 	Average Loss: 12.7314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7456

Learning rate: 0.0001974173386969847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: 17.5900	Cost: 19.99s
Train Epoch: 726 [20480/90000 (23%)]	Loss: 12.2686	Cost: 6.07s
Train Epoch: 726 [40960/90000 (45%)]	Loss: 12.4213	Cost: 6.06s
Train Epoch: 726 [61440/90000 (68%)]	Loss: 12.4330	Cost: 5.90s
Train Epoch: 726 [81920/90000 (91%)]	Loss: 12.3840	Cost: 5.73s
Train Epoch: 726 	Average Loss: 12.7702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7770

Learning rate: 0.00019741024013373678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: 17.5656	Cost: 21.39s
Train Epoch: 727 [20480/90000 (23%)]	Loss: 12.4403	Cost: 5.93s
Train Epoch: 727 [40960/90000 (45%)]	Loss: 12.6275	Cost: 6.15s
Train Epoch: 727 [61440/90000 (68%)]	Loss: 12.4456	Cost: 5.82s
Train Epoch: 727 [81920/90000 (91%)]	Loss: 12.3992	Cost: 5.68s
Train Epoch: 727 	Average Loss: 12.7840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8526

Learning rate: 0.00019740313195648358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: 17.6755	Cost: 20.43s
Train Epoch: 728 [20480/90000 (23%)]	Loss: 12.3157	Cost: 5.99s
Train Epoch: 728 [40960/90000 (45%)]	Loss: 12.4115	Cost: 6.52s
Train Epoch: 728 [61440/90000 (68%)]	Loss: 12.2697	Cost: 5.95s
Train Epoch: 728 [81920/90000 (91%)]	Loss: 12.3117	Cost: 5.86s
Train Epoch: 728 	Average Loss: 12.7363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8676

Learning rate: 0.00019739601416592667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: 17.6096	Cost: 20.19s
Train Epoch: 729 [20480/90000 (23%)]	Loss: 12.5356	Cost: 6.19s
Train Epoch: 729 [40960/90000 (45%)]	Loss: 12.5709	Cost: 6.07s
Train Epoch: 729 [61440/90000 (68%)]	Loss: 12.4394	Cost: 6.06s
Train Epoch: 729 [81920/90000 (91%)]	Loss: 12.3566	Cost: 5.69s
Train Epoch: 729 	Average Loss: 12.7844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8263

Learning rate: 0.00019738888676276855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: 17.7803	Cost: 20.02s
Train Epoch: 730 [20480/90000 (23%)]	Loss: 12.2400	Cost: 5.99s
Train Epoch: 730 [40960/90000 (45%)]	Loss: 12.5929	Cost: 6.01s
Train Epoch: 730 [61440/90000 (68%)]	Loss: 12.3834	Cost: 5.93s
Train Epoch: 730 [81920/90000 (91%)]	Loss: 12.3269	Cost: 5.72s
Train Epoch: 730 	Average Loss: 12.7540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8960

Learning rate: 0.00019738174974771262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: 17.5898	Cost: 20.91s
Train Epoch: 731 [20480/90000 (23%)]	Loss: 12.1337	Cost: 5.95s
Train Epoch: 731 [40960/90000 (45%)]	Loss: 12.3971	Cost: 6.63s
Train Epoch: 731 [61440/90000 (68%)]	Loss: 12.3692	Cost: 5.81s
Train Epoch: 731 [81920/90000 (91%)]	Loss: 12.3486	Cost: 5.93s
Train Epoch: 731 	Average Loss: 12.7025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8201

Learning rate: 0.00019737460312146333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: 17.4505	Cost: 20.25s
Train Epoch: 732 [20480/90000 (23%)]	Loss: 12.1501	Cost: 6.00s
Train Epoch: 732 [40960/90000 (45%)]	Loss: 12.2720	Cost: 6.01s
Train Epoch: 732 [61440/90000 (68%)]	Loss: 11.9883	Cost: 5.84s
Train Epoch: 732 [81920/90000 (91%)]	Loss: 12.2531	Cost: 5.65s
Train Epoch: 732 	Average Loss: 12.6611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9011

Learning rate: 0.000197367446884726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: 17.5816	Cost: 21.49s
Train Epoch: 733 [20480/90000 (23%)]	Loss: 12.0673	Cost: 6.11s
Train Epoch: 733 [40960/90000 (45%)]	Loss: 12.4315	Cost: 6.06s
Train Epoch: 733 [61440/90000 (68%)]	Loss: 12.3663	Cost: 5.91s
Train Epoch: 733 [81920/90000 (91%)]	Loss: 12.4001	Cost: 5.71s
Train Epoch: 733 	Average Loss: 12.7222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8307

Learning rate: 0.00019736028103820694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: 17.2606	Cost: 20.35s
Train Epoch: 734 [20480/90000 (23%)]	Loss: 12.2557	Cost: 6.13s
Train Epoch: 734 [40960/90000 (45%)]	Loss: 12.3031	Cost: 5.99s
Train Epoch: 734 [61440/90000 (68%)]	Loss: 12.3839	Cost: 5.86s
Train Epoch: 734 [81920/90000 (91%)]	Loss: 12.3902	Cost: 5.75s
Train Epoch: 734 	Average Loss: 12.7140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8113

Learning rate: 0.0001973531055826134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: 17.7727	Cost: 20.44s
Train Epoch: 735 [20480/90000 (23%)]	Loss: 12.3034	Cost: 6.06s
Train Epoch: 735 [40960/90000 (45%)]	Loss: 12.3292	Cost: 6.19s
Train Epoch: 735 [61440/90000 (68%)]	Loss: 12.2063	Cost: 6.11s
Train Epoch: 735 [81920/90000 (91%)]	Loss: 12.2292	Cost: 5.98s
Train Epoch: 735 	Average Loss: 12.6609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8507

Learning rate: 0.0001973459205186535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: 17.6527	Cost: 20.44s
Train Epoch: 736 [20480/90000 (23%)]	Loss: 12.1579	Cost: 6.15s
Train Epoch: 736 [40960/90000 (45%)]	Loss: 12.1889	Cost: 6.00s
Train Epoch: 736 [61440/90000 (68%)]	Loss: 12.4164	Cost: 5.86s
Train Epoch: 736 [81920/90000 (91%)]	Loss: 12.2719	Cost: 5.70s
Train Epoch: 736 	Average Loss: 12.6358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8422

Learning rate: 0.00019733872584703645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: 17.4989	Cost: 20.87s
Train Epoch: 737 [20480/90000 (23%)]	Loss: 12.1892	Cost: 6.04s
Train Epoch: 737 [40960/90000 (45%)]	Loss: 12.3223	Cost: 6.13s
Train Epoch: 737 [61440/90000 (68%)]	Loss: 12.1942	Cost: 5.94s
Train Epoch: 737 [81920/90000 (91%)]	Loss: 12.3538	Cost: 5.77s
Train Epoch: 737 	Average Loss: 12.6309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8571

Learning rate: 0.0001973315215684723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: 17.8240	Cost: 20.30s
Train Epoch: 738 [20480/90000 (23%)]	Loss: 12.1970	Cost: 6.02s
Train Epoch: 738 [40960/90000 (45%)]	Loss: 12.3131	Cost: 7.72s
Train Epoch: 738 [61440/90000 (68%)]	Loss: 12.3997	Cost: 5.82s
Train Epoch: 738 [81920/90000 (91%)]	Loss: 12.4469	Cost: 5.80s
Train Epoch: 738 	Average Loss: 12.6895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8950

Learning rate: 0.00019732430768367213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: 17.6653	Cost: 21.23s
Train Epoch: 739 [20480/90000 (23%)]	Loss: 12.3349	Cost: 6.01s
Train Epoch: 739 [40960/90000 (45%)]	Loss: 12.4140	Cost: 6.11s
Train Epoch: 739 [61440/90000 (68%)]	Loss: 12.2912	Cost: 5.84s
Train Epoch: 739 [81920/90000 (91%)]	Loss: 12.4413	Cost: 6.70s
Train Epoch: 739 	Average Loss: 12.6985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8228

Learning rate: 0.00019731708419334784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: 17.8669	Cost: 20.32s
Train Epoch: 740 [20480/90000 (23%)]	Loss: 12.1842	Cost: 6.08s
Train Epoch: 740 [40960/90000 (45%)]	Loss: 12.2070	Cost: 6.06s
Train Epoch: 740 [61440/90000 (68%)]	Loss: 12.1936	Cost: 6.64s
Train Epoch: 740 [81920/90000 (91%)]	Loss: 12.4271	Cost: 6.40s
Train Epoch: 740 	Average Loss: 12.6658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8764

Learning rate: 0.00019730985109821242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: 17.6435	Cost: 20.68s
Train Epoch: 741 [20480/90000 (23%)]	Loss: 12.0831	Cost: 6.02s
Train Epoch: 741 [40960/90000 (45%)]	Loss: 12.2451	Cost: 6.08s
Train Epoch: 741 [61440/90000 (68%)]	Loss: 12.1574	Cost: 5.97s
Train Epoch: 741 [81920/90000 (91%)]	Loss: 12.3097	Cost: 5.74s
Train Epoch: 741 	Average Loss: 12.6210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9363

Learning rate: 0.0001973026083989797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: 17.7650	Cost: 20.86s
Train Epoch: 742 [20480/90000 (23%)]	Loss: 12.2188	Cost: 6.17s
Train Epoch: 742 [40960/90000 (45%)]	Loss: 12.1626	Cost: 7.05s
Train Epoch: 742 [61440/90000 (68%)]	Loss: 12.2015	Cost: 5.79s
Train Epoch: 742 [81920/90000 (91%)]	Loss: 12.3708	Cost: 6.20s
Train Epoch: 742 	Average Loss: 12.5889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9239

Learning rate: 0.00019729535609636458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: 17.5988	Cost: 21.19s
Train Epoch: 743 [20480/90000 (23%)]	Loss: 12.1318	Cost: 5.95s
Train Epoch: 743 [40960/90000 (45%)]	Loss: 12.3029	Cost: 6.64s
Train Epoch: 743 [61440/90000 (68%)]	Loss: 12.2244	Cost: 5.82s
Train Epoch: 743 [81920/90000 (91%)]	Loss: 12.1985	Cost: 5.75s
Train Epoch: 743 	Average Loss: 12.5502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9127

Learning rate: 0.00019728809419108275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: 17.4996	Cost: 19.55s
Train Epoch: 744 [20480/90000 (23%)]	Loss: 12.1076	Cost: 5.99s
Train Epoch: 744 [40960/90000 (45%)]	Loss: 12.2169	Cost: 5.99s
Train Epoch: 744 [61440/90000 (68%)]	Loss: 12.1247	Cost: 5.87s
Train Epoch: 744 [81920/90000 (91%)]	Loss: 12.1723	Cost: 5.70s
Train Epoch: 744 	Average Loss: 12.5763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9296

Learning rate: 0.00019728082268385098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: 17.6184	Cost: 20.47s
Train Epoch: 745 [20480/90000 (23%)]	Loss: 12.2160	Cost: 5.98s
Train Epoch: 745 [40960/90000 (45%)]	Loss: 12.1898	Cost: 6.01s
Train Epoch: 745 [61440/90000 (68%)]	Loss: 12.0717	Cost: 5.85s
Train Epoch: 745 [81920/90000 (91%)]	Loss: 12.2590	Cost: 5.69s
Train Epoch: 745 	Average Loss: 12.5640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8971

Learning rate: 0.00019727354157538695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: 17.6424	Cost: 20.26s
Train Epoch: 746 [20480/90000 (23%)]	Loss: 12.1784	Cost: 6.05s
Train Epoch: 746 [40960/90000 (45%)]	Loss: 12.2012	Cost: 6.11s
Train Epoch: 746 [61440/90000 (68%)]	Loss: 12.1312	Cost: 5.84s
Train Epoch: 746 [81920/90000 (91%)]	Loss: 12.1495	Cost: 5.69s
Train Epoch: 746 	Average Loss: 12.5589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9490

Learning rate: 0.00019726625086640925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: 17.5055	Cost: 20.84s
Train Epoch: 747 [20480/90000 (23%)]	Loss: 11.9010	Cost: 6.14s
Train Epoch: 747 [40960/90000 (45%)]	Loss: 12.1934	Cost: 5.96s
Train Epoch: 747 [61440/90000 (68%)]	Loss: 12.2750	Cost: 5.79s
Train Epoch: 747 [81920/90000 (91%)]	Loss: 12.3658	Cost: 6.13s
Train Epoch: 747 	Average Loss: 12.5453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9889

Learning rate: 0.00019725895055763745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: 17.8370	Cost: 20.24s
Train Epoch: 748 [20480/90000 (23%)]	Loss: 11.9844	Cost: 5.99s
Train Epoch: 748 [40960/90000 (45%)]	Loss: 12.1681	Cost: 5.99s
Train Epoch: 748 [61440/90000 (68%)]	Loss: 12.0190	Cost: 5.86s
Train Epoch: 748 [81920/90000 (91%)]	Loss: 12.1296	Cost: 5.69s
Train Epoch: 748 	Average Loss: 12.5611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9782

Learning rate: 0.00019725164064979207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: 17.5787	Cost: 20.67s
Train Epoch: 749 [20480/90000 (23%)]	Loss: 12.0450	Cost: 5.97s
Train Epoch: 749 [40960/90000 (45%)]	Loss: 12.1507	Cost: 6.45s
Train Epoch: 749 [61440/90000 (68%)]	Loss: 12.1776	Cost: 5.81s
Train Epoch: 749 [81920/90000 (91%)]	Loss: 12.2563	Cost: 5.68s
Train Epoch: 749 	Average Loss: 12.5622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9732

Learning rate: 0.00019724432114359458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: 17.5867	Cost: 22.02s
Train Epoch: 750 [20480/90000 (23%)]	Loss: 11.9806	Cost: 5.96s
Train Epoch: 750 [40960/90000 (45%)]	Loss: 12.1597	Cost: 6.02s
Train Epoch: 750 [61440/90000 (68%)]	Loss: 12.1946	Cost: 5.85s
Train Epoch: 750 [81920/90000 (91%)]	Loss: 12.1893	Cost: 5.71s
Train Epoch: 750 	Average Loss: 12.5671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9518

Learning rate: 0.00019723699203976736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: 17.8289	Cost: 20.64s
Train Epoch: 751 [20480/90000 (23%)]	Loss: 12.1641	Cost: 5.98s
Train Epoch: 751 [40960/90000 (45%)]	Loss: 12.2013	Cost: 6.58s
Train Epoch: 751 [61440/90000 (68%)]	Loss: 12.0836	Cost: 5.98s
Train Epoch: 751 [81920/90000 (91%)]	Loss: 12.1738	Cost: 5.93s
Train Epoch: 751 	Average Loss: 12.5758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0267

Learning rate: 0.0001972296533390338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: 17.4965	Cost: 20.83s
Train Epoch: 752 [20480/90000 (23%)]	Loss: 11.9288	Cost: 6.00s
Train Epoch: 752 [40960/90000 (45%)]	Loss: 12.0532	Cost: 6.05s
Train Epoch: 752 [61440/90000 (68%)]	Loss: 11.9387	Cost: 5.85s
Train Epoch: 752 [81920/90000 (91%)]	Loss: 12.0354	Cost: 5.72s
Train Epoch: 752 	Average Loss: 12.5097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0693

Learning rate: 0.00019722230504211813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: 17.8306	Cost: 20.11s
Train Epoch: 753 [20480/90000 (23%)]	Loss: 12.2314	Cost: 5.99s
Train Epoch: 753 [40960/90000 (45%)]	Loss: 12.0557	Cost: 6.11s
Train Epoch: 753 [61440/90000 (68%)]	Loss: 12.1583	Cost: 5.87s
Train Epoch: 753 [81920/90000 (91%)]	Loss: 12.1422	Cost: 5.68s
Train Epoch: 753 	Average Loss: 12.5049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0749

Learning rate: 0.00019721494714974565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: 17.7188	Cost: 20.31s
Train Epoch: 754 [20480/90000 (23%)]	Loss: 12.1105	Cost: 5.98s
Train Epoch: 754 [40960/90000 (45%)]	Loss: 12.1009	Cost: 5.97s
Train Epoch: 754 [61440/90000 (68%)]	Loss: 12.0307	Cost: 5.83s
Train Epoch: 754 [81920/90000 (91%)]	Loss: 12.1748	Cost: 5.69s
Train Epoch: 754 	Average Loss: 12.4626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0344

Learning rate: 0.00019720757966264256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: 17.7499	Cost: 19.94s
Train Epoch: 755 [20480/90000 (23%)]	Loss: 11.9063	Cost: 6.02s
Train Epoch: 755 [40960/90000 (45%)]	Loss: 12.1873	Cost: 6.21s
Train Epoch: 755 [61440/90000 (68%)]	Loss: 12.0755	Cost: 5.85s
Train Epoch: 755 [81920/90000 (91%)]	Loss: 12.0552	Cost: 5.73s
Train Epoch: 755 	Average Loss: 12.4714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0540

Learning rate: 0.00019720020258153596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: 17.6998	Cost: 19.86s
Train Epoch: 756 [20480/90000 (23%)]	Loss: 12.1459	Cost: 6.05s
Train Epoch: 756 [40960/90000 (45%)]	Loss: 12.1647	Cost: 6.04s
Train Epoch: 756 [61440/90000 (68%)]	Loss: 12.2278	Cost: 5.89s
Train Epoch: 756 [81920/90000 (91%)]	Loss: 12.0566	Cost: 5.71s
Train Epoch: 756 	Average Loss: 12.4934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0448

Learning rate: 0.000197192815907154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: 17.8269	Cost: 20.49s
Train Epoch: 757 [20480/90000 (23%)]	Loss: 11.9777	Cost: 5.98s
Train Epoch: 757 [40960/90000 (45%)]	Loss: 12.1403	Cost: 6.26s
Train Epoch: 757 [61440/90000 (68%)]	Loss: 12.0322	Cost: 5.88s
Train Epoch: 757 [81920/90000 (91%)]	Loss: 12.1789	Cost: 6.22s
Train Epoch: 757 	Average Loss: 12.4610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9505

Learning rate: 0.00019718541964022568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: 17.5743	Cost: 20.31s
Train Epoch: 758 [20480/90000 (23%)]	Loss: 12.0007	Cost: 6.16s
Train Epoch: 758 [40960/90000 (45%)]	Loss: 11.9763	Cost: 6.41s
Train Epoch: 758 [61440/90000 (68%)]	Loss: 12.0240	Cost: 5.84s
Train Epoch: 758 [81920/90000 (91%)]	Loss: 11.9821	Cost: 5.95s
Train Epoch: 758 	Average Loss: 12.4158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0775

Learning rate: 0.00019717801378148098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: 17.6728	Cost: 20.09s
Train Epoch: 759 [20480/90000 (23%)]	Loss: 11.7822	Cost: 5.96s
Train Epoch: 759 [40960/90000 (45%)]	Loss: 12.1504	Cost: 5.96s
Train Epoch: 759 [61440/90000 (68%)]	Loss: 12.0758	Cost: 5.83s
Train Epoch: 759 [81920/90000 (91%)]	Loss: 12.0114	Cost: 5.68s
Train Epoch: 759 	Average Loss: 12.4059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0193

Learning rate: 0.0001971705983316508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: 17.4132	Cost: 21.40s
Train Epoch: 760 [20480/90000 (23%)]	Loss: 11.8574	Cost: 5.91s
Train Epoch: 760 [40960/90000 (45%)]	Loss: 12.2235	Cost: 5.98s
Train Epoch: 760 [61440/90000 (68%)]	Loss: 11.8972	Cost: 5.83s
Train Epoch: 760 [81920/90000 (91%)]	Loss: 12.0637	Cost: 6.00s
Train Epoch: 760 	Average Loss: 12.4476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9902

Learning rate: 0.0001971631732914671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: 17.6496	Cost: 21.05s
Train Epoch: 761 [20480/90000 (23%)]	Loss: 11.9706	Cost: 6.41s
Train Epoch: 761 [40960/90000 (45%)]	Loss: 12.3082	Cost: 6.00s
Train Epoch: 761 [61440/90000 (68%)]	Loss: 11.9984	Cost: 5.84s
Train Epoch: 761 [81920/90000 (91%)]	Loss: 12.3055	Cost: 5.75s
Train Epoch: 761 	Average Loss: 12.4823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0759

Learning rate: 0.00019715573866166262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: 17.7933	Cost: 21.56s
Train Epoch: 762 [20480/90000 (23%)]	Loss: 12.0541	Cost: 6.03s
Train Epoch: 762 [40960/90000 (45%)]	Loss: 12.0627	Cost: 6.11s
Train Epoch: 762 [61440/90000 (68%)]	Loss: 12.2627	Cost: 6.19s
Train Epoch: 762 [81920/90000 (91%)]	Loss: 12.1794	Cost: 5.78s
Train Epoch: 762 	Average Loss: 12.5372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0597

Learning rate: 0.0001971482944429712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: 17.7155	Cost: 21.01s
Train Epoch: 763 [20480/90000 (23%)]	Loss: 12.1418	Cost: 6.09s
Train Epoch: 763 [40960/90000 (45%)]	Loss: 12.1134	Cost: 6.06s
Train Epoch: 763 [61440/90000 (68%)]	Loss: 11.9147	Cost: 5.95s
Train Epoch: 763 [81920/90000 (91%)]	Loss: 12.1307	Cost: 5.78s
Train Epoch: 763 	Average Loss: 12.4906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0149

Learning rate: 0.00019714084063612747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: 17.9363	Cost: 22.63s
Train Epoch: 764 [20480/90000 (23%)]	Loss: 11.8908	Cost: 6.68s
Train Epoch: 764 [40960/90000 (45%)]	Loss: 12.1247	Cost: 6.73s
Train Epoch: 764 [61440/90000 (68%)]	Loss: 11.9760	Cost: 6.24s
Train Epoch: 764 [81920/90000 (91%)]	Loss: 12.1254	Cost: 5.83s
Train Epoch: 764 	Average Loss: 12.4355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0560

Learning rate: 0.00019713337724186716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: 17.7596	Cost: 20.94s
Train Epoch: 765 [20480/90000 (23%)]	Loss: 12.1023	Cost: 5.98s
Train Epoch: 765 [40960/90000 (45%)]	Loss: 12.1947	Cost: 6.39s
Train Epoch: 765 [61440/90000 (68%)]	Loss: 11.9291	Cost: 5.93s
Train Epoch: 765 [81920/90000 (91%)]	Loss: 12.0692	Cost: 6.00s
Train Epoch: 765 	Average Loss: 12.5078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0394

Learning rate: 0.00019712590426092686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: 17.6552	Cost: 21.00s
Train Epoch: 766 [20480/90000 (23%)]	Loss: 11.9209	Cost: 5.82s
Train Epoch: 766 [40960/90000 (45%)]	Loss: 12.1993	Cost: 6.70s
Train Epoch: 766 [61440/90000 (68%)]	Loss: 12.0645	Cost: 5.85s
Train Epoch: 766 [81920/90000 (91%)]	Loss: 12.0863	Cost: 6.06s
Train Epoch: 766 	Average Loss: 12.4470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0710

Learning rate: 0.0001971184216940441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: 18.0292	Cost: 21.27s
Train Epoch: 767 [20480/90000 (23%)]	Loss: 12.0401	Cost: 6.00s
Train Epoch: 767 [40960/90000 (45%)]	Loss: 12.0000	Cost: 5.99s
Train Epoch: 767 [61440/90000 (68%)]	Loss: 12.0194	Cost: 5.93s
Train Epoch: 767 [81920/90000 (91%)]	Loss: 11.9931	Cost: 5.75s
Train Epoch: 767 	Average Loss: 12.4221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0508

Learning rate: 0.0001971109295419574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: 17.7304	Cost: 22.03s
Train Epoch: 768 [20480/90000 (23%)]	Loss: 11.9511	Cost: 6.00s
Train Epoch: 768 [40960/90000 (45%)]	Loss: 11.9559	Cost: 5.99s
Train Epoch: 768 [61440/90000 (68%)]	Loss: 11.8361	Cost: 5.86s
Train Epoch: 768 [81920/90000 (91%)]	Loss: 11.7655	Cost: 5.75s
Train Epoch: 768 	Average Loss: 12.3505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0668

Learning rate: 0.0001971034278054062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: 17.8206	Cost: 22.83s
Train Epoch: 769 [20480/90000 (23%)]	Loss: 11.7491	Cost: 6.03s
Train Epoch: 769 [40960/90000 (45%)]	Loss: 11.9120	Cost: 6.82s
Train Epoch: 769 [61440/90000 (68%)]	Loss: 11.8430	Cost: 5.81s
Train Epoch: 769 [81920/90000 (91%)]	Loss: 11.8282	Cost: 5.74s
Train Epoch: 769 	Average Loss: 12.3523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1122

Learning rate: 0.00019709591648513092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: 17.6833	Cost: 23.28s
Train Epoch: 770 [20480/90000 (23%)]	Loss: 11.8553	Cost: 5.97s
Train Epoch: 770 [40960/90000 (45%)]	Loss: 11.7767	Cost: 5.98s
Train Epoch: 770 [61440/90000 (68%)]	Loss: 11.9958	Cost: 5.83s
Train Epoch: 770 [81920/90000 (91%)]	Loss: 11.9631	Cost: 5.62s
Train Epoch: 770 	Average Loss: 12.3188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1611

Learning rate: 0.00019708839558187284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: 17.8302	Cost: 21.51s
Train Epoch: 771 [20480/90000 (23%)]	Loss: 11.8989	Cost: 6.87s
Train Epoch: 771 [40960/90000 (45%)]	Loss: 12.0927	Cost: 6.11s
Train Epoch: 771 [61440/90000 (68%)]	Loss: 12.0525	Cost: 5.96s
Train Epoch: 771 [81920/90000 (91%)]	Loss: 12.3275	Cost: 5.93s
Train Epoch: 771 	Average Loss: 12.4147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1026

Learning rate: 0.0001970808650963743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: 17.7457	Cost: 20.51s
Train Epoch: 772 [20480/90000 (23%)]	Loss: 11.9302	Cost: 6.27s
Train Epoch: 772 [40960/90000 (45%)]	Loss: 12.1238	Cost: 6.00s
Train Epoch: 772 [61440/90000 (68%)]	Loss: 11.6754	Cost: 5.88s
Train Epoch: 772 [81920/90000 (91%)]	Loss: 12.0244	Cost: 5.89s
Train Epoch: 772 	Average Loss: 12.3566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1497

Learning rate: 0.00019707332502937847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: 18.1454	Cost: 21.19s
Train Epoch: 773 [20480/90000 (23%)]	Loss: 11.8821	Cost: 5.97s
Train Epoch: 773 [40960/90000 (45%)]	Loss: 12.0315	Cost: 6.37s
Train Epoch: 773 [61440/90000 (68%)]	Loss: 11.6793	Cost: 5.96s
Train Epoch: 773 [81920/90000 (91%)]	Loss: 12.2028	Cost: 6.48s
Train Epoch: 773 	Average Loss: 12.4035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1585

Learning rate: 0.00019706577538162957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: 18.0078	Cost: 20.98s
Train Epoch: 774 [20480/90000 (23%)]	Loss: 12.0906	Cost: 5.99s
Train Epoch: 774 [40960/90000 (45%)]	Loss: 12.1998	Cost: 6.29s
Train Epoch: 774 [61440/90000 (68%)]	Loss: 11.8865	Cost: 5.90s
Train Epoch: 774 [81920/90000 (91%)]	Loss: 11.9342	Cost: 5.90s
Train Epoch: 774 	Average Loss: 12.4861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1717

Learning rate: 0.00019705821615387272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: 17.6064	Cost: 19.87s
Train Epoch: 775 [20480/90000 (23%)]	Loss: 11.9758	Cost: 5.96s
Train Epoch: 775 [40960/90000 (45%)]	Loss: 11.8325	Cost: 6.54s
Train Epoch: 775 [61440/90000 (68%)]	Loss: 11.9816	Cost: 5.85s
Train Epoch: 775 [81920/90000 (91%)]	Loss: 11.8089	Cost: 5.82s
Train Epoch: 775 	Average Loss: 12.3865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1967

Learning rate: 0.000197050647346854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: 17.7540	Cost: 19.31s
Train Epoch: 776 [20480/90000 (23%)]	Loss: 11.9112	Cost: 6.02s
Train Epoch: 776 [40960/90000 (45%)]	Loss: 11.9491	Cost: 6.00s
Train Epoch: 776 [61440/90000 (68%)]	Loss: 11.6153	Cost: 5.98s
Train Epoch: 776 [81920/90000 (91%)]	Loss: 11.9097	Cost: 7.11s
Train Epoch: 776 	Average Loss: 12.3202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1881

Learning rate: 0.0001970430689613204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: 17.5397	Cost: 20.70s
Train Epoch: 777 [20480/90000 (23%)]	Loss: 11.8093	Cost: 5.96s
Train Epoch: 777 [40960/90000 (45%)]	Loss: 12.0939	Cost: 7.02s
Train Epoch: 777 [61440/90000 (68%)]	Loss: 12.0330	Cost: 5.88s
Train Epoch: 777 [81920/90000 (91%)]	Loss: 12.0065	Cost: 6.75s
Train Epoch: 777 	Average Loss: 12.3692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1142

Learning rate: 0.00019703548099801984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: 17.8049	Cost: 20.02s
Train Epoch: 778 [20480/90000 (23%)]	Loss: 11.7501	Cost: 6.07s
Train Epoch: 778 [40960/90000 (45%)]	Loss: 11.9205	Cost: 6.09s
Train Epoch: 778 [61440/90000 (68%)]	Loss: 11.8766	Cost: 5.83s
Train Epoch: 778 [81920/90000 (91%)]	Loss: 12.0230	Cost: 5.69s
Train Epoch: 778 	Average Loss: 12.3148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0721

Learning rate: 0.00019702788345770126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: 17.8546	Cost: 21.37s
Train Epoch: 779 [20480/90000 (23%)]	Loss: 11.8567	Cost: 5.92s
Train Epoch: 779 [40960/90000 (45%)]	Loss: 11.9145	Cost: 6.08s
Train Epoch: 779 [61440/90000 (68%)]	Loss: 11.6632	Cost: 5.82s
Train Epoch: 779 [81920/90000 (91%)]	Loss: 11.7469	Cost: 5.66s
Train Epoch: 779 	Average Loss: 12.2378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2363

Learning rate: 0.0001970202763411145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: 17.6544	Cost: 20.51s
Train Epoch: 780 [20480/90000 (23%)]	Loss: 11.8373	Cost: 5.92s
Train Epoch: 780 [40960/90000 (45%)]	Loss: 12.0990	Cost: 6.18s
Train Epoch: 780 [61440/90000 (68%)]	Loss: 11.8993	Cost: 5.82s
Train Epoch: 780 [81920/90000 (91%)]	Loss: 12.0071	Cost: 5.65s
Train Epoch: 780 	Average Loss: 12.3109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1162

Learning rate: 0.00019701265964901035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: 17.8263	Cost: 19.59s
Train Epoch: 781 [20480/90000 (23%)]	Loss: 11.8726	Cost: 5.96s
Train Epoch: 781 [40960/90000 (45%)]	Loss: 11.8050	Cost: 5.99s
Train Epoch: 781 [61440/90000 (68%)]	Loss: 11.8444	Cost: 5.83s
Train Epoch: 781 [81920/90000 (91%)]	Loss: 11.9905	Cost: 5.66s
Train Epoch: 781 	Average Loss: 12.2410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2648

Learning rate: 0.00019700503338214057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: 17.7217	Cost: 19.77s
Train Epoch: 782 [20480/90000 (23%)]	Loss: 11.4787	Cost: 5.80s
Train Epoch: 782 [40960/90000 (45%)]	Loss: 11.9148	Cost: 6.16s
Train Epoch: 782 [61440/90000 (68%)]	Loss: 11.8116	Cost: 5.62s
Train Epoch: 782 [81920/90000 (91%)]	Loss: 11.7275	Cost: 5.44s
Train Epoch: 782 	Average Loss: 12.1997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1686

Learning rate: 0.0001969973975412578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: 17.8360	Cost: 20.43s
Train Epoch: 783 [20480/90000 (23%)]	Loss: 11.9129	Cost: 6.00s
Train Epoch: 783 [40960/90000 (45%)]	Loss: 11.7380	Cost: 6.82s
Train Epoch: 783 [61440/90000 (68%)]	Loss: 11.6861	Cost: 5.78s
Train Epoch: 783 [81920/90000 (91%)]	Loss: 11.8115	Cost: 6.08s
Train Epoch: 783 	Average Loss: 12.1856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2859

Learning rate: 0.00019698975212711572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: 17.8990	Cost: 20.61s
Train Epoch: 784 [20480/90000 (23%)]	Loss: 11.8496	Cost: 5.98s
Train Epoch: 784 [40960/90000 (45%)]	Loss: 11.8686	Cost: 6.29s
Train Epoch: 784 [61440/90000 (68%)]	Loss: 11.5911	Cost: 5.82s
Train Epoch: 784 [81920/90000 (91%)]	Loss: 11.8114	Cost: 5.83s
Train Epoch: 784 	Average Loss: 12.2012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2020

Learning rate: 0.00019698209714046885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: 17.9552	Cost: 20.69s
Train Epoch: 785 [20480/90000 (23%)]	Loss: 11.7318	Cost: 6.03s
Train Epoch: 785 [40960/90000 (45%)]	Loss: 11.8782	Cost: 6.11s
Train Epoch: 785 [61440/90000 (68%)]	Loss: 11.7705	Cost: 5.81s
Train Epoch: 785 [81920/90000 (91%)]	Loss: 11.9448	Cost: 5.85s
Train Epoch: 785 	Average Loss: 12.2520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2323

Learning rate: 0.00019697443258207274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: 17.5931	Cost: 20.54s
Train Epoch: 786 [20480/90000 (23%)]	Loss: 11.8601	Cost: 6.00s
Train Epoch: 786 [40960/90000 (45%)]	Loss: 11.8130	Cost: 7.69s
Train Epoch: 786 [61440/90000 (68%)]	Loss: 11.5868	Cost: 5.61s
Train Epoch: 786 [81920/90000 (91%)]	Loss: 11.8694	Cost: 6.23s
Train Epoch: 786 	Average Loss: 12.2720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2500

Learning rate: 0.00019696675845268385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: 17.8818	Cost: 20.53s
Train Epoch: 787 [20480/90000 (23%)]	Loss: 11.7442	Cost: 5.99s
Train Epoch: 787 [40960/90000 (45%)]	Loss: 11.7448	Cost: 7.50s
Train Epoch: 787 [61440/90000 (68%)]	Loss: 11.6175	Cost: 5.92s
Train Epoch: 787 [81920/90000 (91%)]	Loss: 12.0215	Cost: 5.73s
Train Epoch: 787 	Average Loss: 12.2405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1347

Learning rate: 0.00019695907475305956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: 17.9498	Cost: 20.14s
Train Epoch: 788 [20480/90000 (23%)]	Loss: 11.7916	Cost: 6.19s
Train Epoch: 788 [40960/90000 (45%)]	Loss: 11.9514	Cost: 6.26s
Train Epoch: 788 [61440/90000 (68%)]	Loss: 11.5859	Cost: 5.86s
Train Epoch: 788 [81920/90000 (91%)]	Loss: 11.6884	Cost: 5.69s
Train Epoch: 788 	Average Loss: 12.1734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2282

Learning rate: 0.00019695138148395828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: 18.0048	Cost: 21.51s
Train Epoch: 789 [20480/90000 (23%)]	Loss: 11.7129	Cost: 5.99s
Train Epoch: 789 [40960/90000 (45%)]	Loss: 12.0774	Cost: 6.24s
Train Epoch: 789 [61440/90000 (68%)]	Loss: 11.7628	Cost: 5.87s
Train Epoch: 789 [81920/90000 (91%)]	Loss: 11.7037	Cost: 5.92s
Train Epoch: 789 	Average Loss: 12.1762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3015

Learning rate: 0.00019694367864613922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: 17.9786	Cost: 20.35s
Train Epoch: 790 [20480/90000 (23%)]	Loss: 11.6892	Cost: 6.01s
Train Epoch: 790 [40960/90000 (45%)]	Loss: 11.8280	Cost: 6.79s
Train Epoch: 790 [61440/90000 (68%)]	Loss: 11.4780	Cost: 5.83s
Train Epoch: 790 [81920/90000 (91%)]	Loss: 11.6853	Cost: 6.03s
Train Epoch: 790 	Average Loss: 12.1212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2386

Learning rate: 0.00019693596624036267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: 17.6361	Cost: 21.11s
Train Epoch: 791 [20480/90000 (23%)]	Loss: 11.6716	Cost: 6.00s
Train Epoch: 791 [40960/90000 (45%)]	Loss: 11.8163	Cost: 6.33s
Train Epoch: 791 [61440/90000 (68%)]	Loss: 11.5828	Cost: 5.89s
Train Epoch: 791 [81920/90000 (91%)]	Loss: 11.6119	Cost: 5.96s
Train Epoch: 791 	Average Loss: 12.1373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2510

Learning rate: 0.00019692824426738987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: 18.0688	Cost: 20.37s
Train Epoch: 792 [20480/90000 (23%)]	Loss: 11.6094	Cost: 6.10s
Train Epoch: 792 [40960/90000 (45%)]	Loss: 11.6274	Cost: 6.46s
Train Epoch: 792 [61440/90000 (68%)]	Loss: 11.6306	Cost: 5.81s
Train Epoch: 792 [81920/90000 (91%)]	Loss: 11.5138	Cost: 6.14s
Train Epoch: 792 	Average Loss: 12.0755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1636

Learning rate: 0.0001969205127279828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: 17.9918	Cost: 21.37s
Train Epoch: 793 [20480/90000 (23%)]	Loss: 11.5814	Cost: 6.00s
Train Epoch: 793 [40960/90000 (45%)]	Loss: 11.7318	Cost: 6.66s
Train Epoch: 793 [61440/90000 (68%)]	Loss: 11.4798	Cost: 5.95s
Train Epoch: 793 [81920/90000 (91%)]	Loss: 11.6997	Cost: 5.74s
Train Epoch: 793 	Average Loss: 12.0745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2057

Learning rate: 0.00019691277162290467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: 18.0217	Cost: 20.50s
Train Epoch: 794 [20480/90000 (23%)]	Loss: 11.5632	Cost: 5.96s
Train Epoch: 794 [40960/90000 (45%)]	Loss: 11.7651	Cost: 6.03s
Train Epoch: 794 [61440/90000 (68%)]	Loss: 11.4313	Cost: 5.82s
Train Epoch: 794 [81920/90000 (91%)]	Loss: 11.7681	Cost: 5.71s
Train Epoch: 794 	Average Loss: 12.0963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3734

Learning rate: 0.00019690502095291943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 795 [0/90000 (0%)]	Loss: 17.8693	Cost: 19.70s
Train Epoch: 795 [20480/90000 (23%)]	Loss: 11.7137	Cost: 6.09s
Train Epoch: 795 [40960/90000 (45%)]	Loss: 11.6266	Cost: 6.02s
Train Epoch: 795 [61440/90000 (68%)]	Loss: 11.6019	Cost: 5.91s
Train Epoch: 795 [81920/90000 (91%)]	Loss: 11.6316	Cost: 5.76s
Train Epoch: 795 	Average Loss: 12.0803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2924

Learning rate: 0.00019689726071879206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 796 [0/90000 (0%)]	Loss: 17.8348	Cost: 20.19s
Train Epoch: 796 [20480/90000 (23%)]	Loss: 11.5519	Cost: 6.13s
Train Epoch: 796 [40960/90000 (45%)]	Loss: 11.7281	Cost: 6.07s
Train Epoch: 796 [61440/90000 (68%)]	Loss: 11.6277	Cost: 5.83s
Train Epoch: 796 [81920/90000 (91%)]	Loss: 11.6939	Cost: 5.85s
Train Epoch: 796 	Average Loss: 12.0946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2554

Learning rate: 0.00019688949092128843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 797 [0/90000 (0%)]	Loss: 18.1336	Cost: 19.54s
Train Epoch: 797 [20480/90000 (23%)]	Loss: 11.4315	Cost: 6.21s
Train Epoch: 797 [40960/90000 (45%)]	Loss: 11.9252	Cost: 6.02s
Train Epoch: 797 [61440/90000 (68%)]	Loss: 11.6436	Cost: 5.91s
Train Epoch: 797 [81920/90000 (91%)]	Loss: 11.9128	Cost: 5.72s
Train Epoch: 797 	Average Loss: 12.1630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3196

Learning rate: 0.00019688171156117545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 798 [0/90000 (0%)]	Loss: 18.0045	Cost: 19.89s
Train Epoch: 798 [20480/90000 (23%)]	Loss: 11.5898	Cost: 6.00s
Train Epoch: 798 [40960/90000 (45%)]	Loss: 11.9261	Cost: 6.01s
Train Epoch: 798 [61440/90000 (68%)]	Loss: 11.6942	Cost: 5.87s
Train Epoch: 798 [81920/90000 (91%)]	Loss: 11.7303	Cost: 5.67s
Train Epoch: 798 	Average Loss: 12.1384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3043

Learning rate: 0.00019687392263922088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 799 [0/90000 (0%)]	Loss: 18.1020	Cost: 21.37s
Train Epoch: 799 [20480/90000 (23%)]	Loss: 11.6279	Cost: 5.96s
Train Epoch: 799 [40960/90000 (45%)]	Loss: 11.6925	Cost: 5.98s
Train Epoch: 799 [61440/90000 (68%)]	Loss: 11.6941	Cost: 5.81s
Train Epoch: 799 [81920/90000 (91%)]	Loss: 11.8095	Cost: 5.68s
Train Epoch: 799 	Average Loss: 12.1387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3377

Learning rate: 0.00019686612415619346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 800 [0/90000 (0%)]	Loss: 17.9123	Cost: 20.50s
Train Epoch: 800 [20480/90000 (23%)]	Loss: 11.5788	Cost: 6.00s
Train Epoch: 800 [40960/90000 (45%)]	Loss: 11.8625	Cost: 6.02s
Train Epoch: 800 [61440/90000 (68%)]	Loss: 11.6429	Cost: 5.86s
Train Epoch: 800 [81920/90000 (91%)]	Loss: 11.4997	Cost: 5.67s
Train Epoch: 800 	Average Loss: 12.0617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3304

Learning rate: 0.00019685831611286286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 801 [0/90000 (0%)]	Loss: 18.0718	Cost: 20.77s
Train Epoch: 801 [20480/90000 (23%)]	Loss: 11.4823	Cost: 5.97s
Train Epoch: 801 [40960/90000 (45%)]	Loss: 11.7405	Cost: 6.20s
Train Epoch: 801 [61440/90000 (68%)]	Loss: 11.4672	Cost: 5.88s
Train Epoch: 801 [81920/90000 (91%)]	Loss: 11.4954	Cost: 5.66s
Train Epoch: 801 	Average Loss: 12.0141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4411

Learning rate: 0.0001968504985099997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 802 [0/90000 (0%)]	Loss: 18.0866	Cost: 21.07s
Train Epoch: 802 [20480/90000 (23%)]	Loss: 11.3786	Cost: 6.02s
Train Epoch: 802 [40960/90000 (45%)]	Loss: 11.6796	Cost: 6.34s
Train Epoch: 802 [61440/90000 (68%)]	Loss: 11.3917	Cost: 5.84s
Train Epoch: 802 [81920/90000 (91%)]	Loss: 11.6743	Cost: 5.66s
Train Epoch: 802 	Average Loss: 12.0054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3104

Learning rate: 0.00019684267134837557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 803 [0/90000 (0%)]	Loss: 17.8805	Cost: 20.10s
Train Epoch: 803 [20480/90000 (23%)]	Loss: 11.7086	Cost: 5.98s
Train Epoch: 803 [40960/90000 (45%)]	Loss: 11.6933	Cost: 6.12s
Train Epoch: 803 [61440/90000 (68%)]	Loss: 11.5639	Cost: 5.83s
Train Epoch: 803 [81920/90000 (91%)]	Loss: 11.4866	Cost: 5.77s
Train Epoch: 803 	Average Loss: 12.0410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3819

Learning rate: 0.00019683483462876295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 804 [0/90000 (0%)]	Loss: 17.9859	Cost: 20.83s
Train Epoch: 804 [20480/90000 (23%)]	Loss: 11.4995	Cost: 6.08s
Train Epoch: 804 [40960/90000 (45%)]	Loss: 11.5234	Cost: 6.10s
Train Epoch: 804 [61440/90000 (68%)]	Loss: 11.4408	Cost: 5.90s
Train Epoch: 804 [81920/90000 (91%)]	Loss: 11.6497	Cost: 5.97s
Train Epoch: 804 	Average Loss: 12.0218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4423

Learning rate: 0.0001968269883519353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 805 [0/90000 (0%)]	Loss: 17.9899	Cost: 20.46s
Train Epoch: 805 [20480/90000 (23%)]	Loss: 11.4834	Cost: 6.08s
Train Epoch: 805 [40960/90000 (45%)]	Loss: 11.6555	Cost: 6.04s
Train Epoch: 805 [61440/90000 (68%)]	Loss: 11.4458	Cost: 5.89s
Train Epoch: 805 [81920/90000 (91%)]	Loss: 11.5289	Cost: 5.64s
Train Epoch: 805 	Average Loss: 12.0765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3640

Learning rate: 0.00019681913251866706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 806 [0/90000 (0%)]	Loss: 17.9641	Cost: 21.26s
Train Epoch: 806 [20480/90000 (23%)]	Loss: 11.4886	Cost: 5.97s
Train Epoch: 806 [40960/90000 (45%)]	Loss: 11.7536	Cost: 6.48s
Train Epoch: 806 [61440/90000 (68%)]	Loss: 11.5090	Cost: 5.84s
Train Epoch: 806 [81920/90000 (91%)]	Loss: 11.5316	Cost: 5.69s
Train Epoch: 806 	Average Loss: 12.0463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3372

Learning rate: 0.00019681126712973353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 807 [0/90000 (0%)]	Loss: 18.0881	Cost: 21.21s
Train Epoch: 807 [20480/90000 (23%)]	Loss: 11.4751	Cost: 5.96s
Train Epoch: 807 [40960/90000 (45%)]	Loss: 11.3934	Cost: 7.14s
Train Epoch: 807 [61440/90000 (68%)]	Loss: 11.3916	Cost: 5.79s
Train Epoch: 807 [81920/90000 (91%)]	Loss: 11.4888	Cost: 6.02s
Train Epoch: 807 	Average Loss: 11.9573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4679

Learning rate: 0.00019680339218591098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 808 [0/90000 (0%)]	Loss: 18.1384	Cost: 20.26s
Train Epoch: 808 [20480/90000 (23%)]	Loss: 11.6081	Cost: 5.97s
Train Epoch: 808 [40960/90000 (45%)]	Loss: 11.5921	Cost: 6.01s
Train Epoch: 808 [61440/90000 (68%)]	Loss: 11.4496	Cost: 5.83s
Train Epoch: 808 [81920/90000 (91%)]	Loss: 11.5430	Cost: 5.65s
Train Epoch: 808 	Average Loss: 11.9822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4504

Learning rate: 0.00019679550768797666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 809 [0/90000 (0%)]	Loss: 18.0657	Cost: 20.80s
Train Epoch: 809 [20480/90000 (23%)]	Loss: 11.5574	Cost: 6.11s
Train Epoch: 809 [40960/90000 (45%)]	Loss: 11.5458	Cost: 6.01s
Train Epoch: 809 [61440/90000 (68%)]	Loss: 11.3629	Cost: 5.87s
Train Epoch: 809 [81920/90000 (91%)]	Loss: 11.5770	Cost: 5.67s
Train Epoch: 809 	Average Loss: 11.9481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4249

Learning rate: 0.00019678761363670875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 810 [0/90000 (0%)]	Loss: 18.1504	Cost: 20.72s
Train Epoch: 810 [20480/90000 (23%)]	Loss: 11.4147	Cost: 5.96s
Train Epoch: 810 [40960/90000 (45%)]	Loss: 11.4904	Cost: 6.53s
Train Epoch: 810 [61440/90000 (68%)]	Loss: 11.3167	Cost: 5.81s
Train Epoch: 810 [81920/90000 (91%)]	Loss: 11.7172	Cost: 5.81s
Train Epoch: 810 	Average Loss: 11.9454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4529

Learning rate: 0.0001967797100328863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 811 [0/90000 (0%)]	Loss: 18.0711	Cost: 19.69s
Train Epoch: 811 [20480/90000 (23%)]	Loss: 11.6931	Cost: 5.98s
Train Epoch: 811 [40960/90000 (45%)]	Loss: 11.5764	Cost: 5.96s
Train Epoch: 811 [61440/90000 (68%)]	Loss: 11.4441	Cost: 5.83s
Train Epoch: 811 [81920/90000 (91%)]	Loss: 11.4809	Cost: 5.64s
Train Epoch: 811 	Average Loss: 11.9559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4113

Learning rate: 0.00019677179687728943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 812 [0/90000 (0%)]	Loss: 18.1958	Cost: 20.25s
Train Epoch: 812 [20480/90000 (23%)]	Loss: 11.4011	Cost: 5.95s
Train Epoch: 812 [40960/90000 (45%)]	Loss: 11.5247	Cost: 6.01s
Train Epoch: 812 [61440/90000 (68%)]	Loss: 11.3650	Cost: 5.84s
Train Epoch: 812 [81920/90000 (91%)]	Loss: 11.5546	Cost: 5.65s
Train Epoch: 812 	Average Loss: 11.9442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4336

Learning rate: 0.00019676387417069913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 813 [0/90000 (0%)]	Loss: 18.1348	Cost: 20.14s
Train Epoch: 813 [20480/90000 (23%)]	Loss: 11.3724	Cost: 5.94s
Train Epoch: 813 [40960/90000 (45%)]	Loss: 11.6310	Cost: 5.96s
Train Epoch: 813 [61440/90000 (68%)]	Loss: 11.4237	Cost: 5.91s
Train Epoch: 813 [81920/90000 (91%)]	Loss: 11.5758	Cost: 5.70s
Train Epoch: 813 	Average Loss: 11.9213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3926

Learning rate: 0.0001967559419138973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 814 [0/90000 (0%)]	Loss: 18.4123	Cost: 21.57s
Train Epoch: 814 [20480/90000 (23%)]	Loss: 11.3067	Cost: 5.98s
Train Epoch: 814 [40960/90000 (45%)]	Loss: 11.2930	Cost: 6.12s
Train Epoch: 814 [61440/90000 (68%)]	Loss: 11.1969	Cost: 5.83s
Train Epoch: 814 [81920/90000 (91%)]	Loss: 11.3269	Cost: 5.72s
Train Epoch: 814 	Average Loss: 11.8772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4528

Learning rate: 0.00019674800010766687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 815 [0/90000 (0%)]	Loss: 18.2350	Cost: 22.06s
Train Epoch: 815 [20480/90000 (23%)]	Loss: 11.4614	Cost: 6.01s
Train Epoch: 815 [40960/90000 (45%)]	Loss: 11.2844	Cost: 5.95s
Train Epoch: 815 [61440/90000 (68%)]	Loss: 11.3401	Cost: 5.83s
Train Epoch: 815 [81920/90000 (91%)]	Loss: 11.5064	Cost: 5.73s
Train Epoch: 815 	Average Loss: 11.9147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3866

Learning rate: 0.00019674004875279162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 816 [0/90000 (0%)]	Loss: 18.0943	Cost: 23.53s
Train Epoch: 816 [20480/90000 (23%)]	Loss: 11.3215	Cost: 5.96s
Train Epoch: 816 [40960/90000 (45%)]	Loss: 11.5066	Cost: 6.04s
Train Epoch: 816 [61440/90000 (68%)]	Loss: 11.1265	Cost: 5.82s
Train Epoch: 816 [81920/90000 (91%)]	Loss: 11.5675	Cost: 5.77s
Train Epoch: 816 	Average Loss: 11.8770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4329

Learning rate: 0.00019673208785005636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 817 [0/90000 (0%)]	Loss: 18.0490	Cost: 24.36s
Train Epoch: 817 [20480/90000 (23%)]	Loss: 11.3922	Cost: 5.92s
Train Epoch: 817 [40960/90000 (45%)]	Loss: 11.4621	Cost: 6.56s
Train Epoch: 817 [61440/90000 (68%)]	Loss: 11.3328	Cost: 5.84s
Train Epoch: 817 [81920/90000 (91%)]	Loss: 11.3534	Cost: 5.71s
Train Epoch: 817 	Average Loss: 11.8648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4313

Learning rate: 0.00019672411740024673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 818 [0/90000 (0%)]	Loss: 18.1255	Cost: 21.67s
Train Epoch: 818 [20480/90000 (23%)]	Loss: 11.4703	Cost: 6.28s
Train Epoch: 818 [40960/90000 (45%)]	Loss: 11.2646	Cost: 6.03s
Train Epoch: 818 [61440/90000 (68%)]	Loss: 11.4247	Cost: 5.86s
Train Epoch: 818 [81920/90000 (91%)]	Loss: 11.4533	Cost: 5.69s
Train Epoch: 818 	Average Loss: 11.8544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4501

Learning rate: 0.0001967161374041495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 819 [0/90000 (0%)]	Loss: 18.1473	Cost: 22.52s
Train Epoch: 819 [20480/90000 (23%)]	Loss: 11.3559	Cost: 6.02s
Train Epoch: 819 [40960/90000 (45%)]	Loss: 11.4721	Cost: 6.73s
Train Epoch: 819 [61440/90000 (68%)]	Loss: 11.2649	Cost: 5.91s
Train Epoch: 819 [81920/90000 (91%)]	Loss: 11.4169	Cost: 6.88s
Train Epoch: 819 	Average Loss: 11.8617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5036

Learning rate: 0.00019670814786255217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 820 [0/90000 (0%)]	Loss: 17.8442	Cost: 20.31s
Train Epoch: 820 [20480/90000 (23%)]	Loss: 11.2843	Cost: 6.20s
Train Epoch: 820 [40960/90000 (45%)]	Loss: 11.4567	Cost: 6.23s
Train Epoch: 820 [61440/90000 (68%)]	Loss: 11.2761	Cost: 5.97s
Train Epoch: 820 [81920/90000 (91%)]	Loss: 11.3796	Cost: 6.16s
Train Epoch: 820 	Average Loss: 11.8461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5005

Learning rate: 0.0001967001487762433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 821 [0/90000 (0%)]	Loss: 18.0108	Cost: 20.91s
Train Epoch: 821 [20480/90000 (23%)]	Loss: 11.3521	Cost: 6.33s
Train Epoch: 821 [40960/90000 (45%)]	Loss: 11.4800	Cost: 6.09s
Train Epoch: 821 [61440/90000 (68%)]	Loss: 11.1063	Cost: 5.91s
Train Epoch: 821 [81920/90000 (91%)]	Loss: 11.2955	Cost: 5.84s
Train Epoch: 821 	Average Loss: 11.8165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4571

Learning rate: 0.00019669214014601236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 822 [0/90000 (0%)]	Loss: 18.0139	Cost: 20.47s
Train Epoch: 822 [20480/90000 (23%)]	Loss: 11.2081	Cost: 6.04s
Train Epoch: 822 [40960/90000 (45%)]	Loss: 11.4956	Cost: 7.37s
Train Epoch: 822 [61440/90000 (68%)]	Loss: 11.3392	Cost: 5.86s
Train Epoch: 822 [81920/90000 (91%)]	Loss: 11.5558	Cost: 6.74s
Train Epoch: 822 	Average Loss: 11.8735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5180

Learning rate: 0.00019668412197264976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 823 [0/90000 (0%)]	Loss: 18.2495	Cost: 19.16s
Train Epoch: 823 [20480/90000 (23%)]	Loss: 11.4000	Cost: 5.99s
Train Epoch: 823 [40960/90000 (45%)]	Loss: 11.4355	Cost: 6.15s
Train Epoch: 823 [61440/90000 (68%)]	Loss: 11.2840	Cost: 5.90s
Train Epoch: 823 [81920/90000 (91%)]	Loss: 11.2025	Cost: 5.84s
Train Epoch: 823 	Average Loss: 11.8494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5182

Learning rate: 0.0001966760942569469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 824 [0/90000 (0%)]	Loss: 18.2715	Cost: 19.95s
Train Epoch: 824 [20480/90000 (23%)]	Loss: 11.1543	Cost: 6.03s
Train Epoch: 824 [40960/90000 (45%)]	Loss: 11.4006	Cost: 5.99s
Train Epoch: 824 [61440/90000 (68%)]	Loss: 11.1056	Cost: 5.97s
Train Epoch: 824 [81920/90000 (91%)]	Loss: 11.4474	Cost: 6.49s
Train Epoch: 824 	Average Loss: 11.7747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4907

Learning rate: 0.00019666805699969608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 825 [0/90000 (0%)]	Loss: 18.2233	Cost: 20.01s
Train Epoch: 825 [20480/90000 (23%)]	Loss: 11.2180	Cost: 5.94s
Train Epoch: 825 [40960/90000 (45%)]	Loss: 11.3923	Cost: 6.04s
Train Epoch: 825 [61440/90000 (68%)]	Loss: 11.1666	Cost: 5.82s
Train Epoch: 825 [81920/90000 (91%)]	Loss: 11.3968	Cost: 5.92s
Train Epoch: 825 	Average Loss: 11.7934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5456

Learning rate: 0.00019666001020169052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 826 [0/90000 (0%)]	Loss: 18.0420	Cost: 20.87s
Train Epoch: 826 [20480/90000 (23%)]	Loss: 11.1988	Cost: 5.94s
Train Epoch: 826 [40960/90000 (45%)]	Loss: 11.3160	Cost: 6.24s
Train Epoch: 826 [61440/90000 (68%)]	Loss: 11.0935	Cost: 5.83s
Train Epoch: 826 [81920/90000 (91%)]	Loss: 11.4443	Cost: 5.91s
Train Epoch: 826 	Average Loss: 11.7795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5676

Learning rate: 0.00019665195386372441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 827 [0/90000 (0%)]	Loss: 18.1510	Cost: 19.90s
Train Epoch: 827 [20480/90000 (23%)]	Loss: 11.2507	Cost: 5.98s
Train Epoch: 827 [40960/90000 (45%)]	Loss: 11.3946	Cost: 6.02s
Train Epoch: 827 [61440/90000 (68%)]	Loss: 11.1857	Cost: 5.94s
Train Epoch: 827 [81920/90000 (91%)]	Loss: 11.4784	Cost: 5.74s
Train Epoch: 827 	Average Loss: 11.8298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5760

Learning rate: 0.00019664388798659287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 828 [0/90000 (0%)]	Loss: 18.3137	Cost: 20.12s
Train Epoch: 828 [20480/90000 (23%)]	Loss: 11.3058	Cost: 6.00s
Train Epoch: 828 [40960/90000 (45%)]	Loss: 11.5084	Cost: 6.80s
Train Epoch: 828 [61440/90000 (68%)]	Loss: 11.2728	Cost: 5.83s
Train Epoch: 828 [81920/90000 (91%)]	Loss: 11.4207	Cost: 5.86s
Train Epoch: 828 	Average Loss: 11.8509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5241

Learning rate: 0.00019663581257109203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 829 [0/90000 (0%)]	Loss: 18.1007	Cost: 19.28s
Train Epoch: 829 [20480/90000 (23%)]	Loss: 11.4122	Cost: 6.06s
Train Epoch: 829 [40960/90000 (45%)]	Loss: 11.3730	Cost: 5.99s
Train Epoch: 829 [61440/90000 (68%)]	Loss: 11.4273	Cost: 5.84s
Train Epoch: 829 [81920/90000 (91%)]	Loss: 11.4021	Cost: 5.72s
Train Epoch: 829 	Average Loss: 11.8740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5152

Learning rate: 0.00019662772761801884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 830 [0/90000 (0%)]	Loss: 17.8763	Cost: 19.99s
Train Epoch: 830 [20480/90000 (23%)]	Loss: 11.2079	Cost: 5.98s
Train Epoch: 830 [40960/90000 (45%)]	Loss: 11.2610	Cost: 6.00s
Train Epoch: 830 [61440/90000 (68%)]	Loss: 11.0588	Cost: 5.79s
Train Epoch: 830 [81920/90000 (91%)]	Loss: 11.1951	Cost: 6.23s
Train Epoch: 830 	Average Loss: 11.8000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5386

Learning rate: 0.00019661963312817126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 831 [0/90000 (0%)]	Loss: 18.3218	Cost: 20.49s
Train Epoch: 831 [20480/90000 (23%)]	Loss: 11.2656	Cost: 6.03s
Train Epoch: 831 [40960/90000 (45%)]	Loss: 11.4396	Cost: 6.34s
Train Epoch: 831 [61440/90000 (68%)]	Loss: 11.2195	Cost: 5.83s
Train Epoch: 831 [81920/90000 (91%)]	Loss: 11.5142	Cost: 5.87s
Train Epoch: 831 	Average Loss: 11.8440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5131

Learning rate: 0.00019661152910234822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 832 [0/90000 (0%)]	Loss: 18.2686	Cost: 20.28s
Train Epoch: 832 [20480/90000 (23%)]	Loss: 11.2167	Cost: 6.20s
Train Epoch: 832 [40960/90000 (45%)]	Loss: 11.2773	Cost: 5.98s
Train Epoch: 832 [61440/90000 (68%)]	Loss: 11.0611	Cost: 5.82s
Train Epoch: 832 [81920/90000 (91%)]	Loss: 11.3137	Cost: 5.62s
Train Epoch: 832 	Average Loss: 11.7713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5535

Learning rate: 0.0001966034155413495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 833 [0/90000 (0%)]	Loss: 18.3271	Cost: 20.22s
Train Epoch: 833 [20480/90000 (23%)]	Loss: 11.1863	Cost: 5.95s
Train Epoch: 833 [40960/90000 (45%)]	Loss: 11.3621	Cost: 5.99s
Train Epoch: 833 [61440/90000 (68%)]	Loss: 11.2241	Cost: 5.81s
Train Epoch: 833 [81920/90000 (91%)]	Loss: 11.2617	Cost: 5.64s
Train Epoch: 833 	Average Loss: 11.7409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4964

Learning rate: 0.00019659529244597592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 834 [0/90000 (0%)]	Loss: 18.2647	Cost: 20.66s
Train Epoch: 834 [20480/90000 (23%)]	Loss: 11.1745	Cost: 6.06s
Train Epoch: 834 [40960/90000 (45%)]	Loss: 11.3143	Cost: 6.03s
Train Epoch: 834 [61440/90000 (68%)]	Loss: 11.1926	Cost: 5.86s
Train Epoch: 834 [81920/90000 (91%)]	Loss: 11.2840	Cost: 5.66s
Train Epoch: 834 	Average Loss: 11.6655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5005

Learning rate: 0.00019658715981702915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 835 [0/90000 (0%)]	Loss: 18.2014	Cost: 19.49s
Train Epoch: 835 [20480/90000 (23%)]	Loss: 11.2093	Cost: 6.46s
Train Epoch: 835 [40960/90000 (45%)]	Loss: 11.1957	Cost: 6.00s
Train Epoch: 835 [61440/90000 (68%)]	Loss: 11.1285	Cost: 5.84s
Train Epoch: 835 [81920/90000 (91%)]	Loss: 11.3605	Cost: 5.73s
Train Epoch: 835 	Average Loss: 11.7648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5203

Learning rate: 0.00019657901765531195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 836 [0/90000 (0%)]	Loss: 18.1406	Cost: 21.12s
Train Epoch: 836 [20480/90000 (23%)]	Loss: 11.1684	Cost: 6.00s
Train Epoch: 836 [40960/90000 (45%)]	Loss: 11.2120	Cost: 6.35s
Train Epoch: 836 [61440/90000 (68%)]	Loss: 11.3215	Cost: 5.81s
Train Epoch: 836 [81920/90000 (91%)]	Loss: 11.2561	Cost: 5.82s
Train Epoch: 836 	Average Loss: 11.7567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5332

Learning rate: 0.0001965708659616278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 837 [0/90000 (0%)]	Loss: 18.2071	Cost: 20.27s
Train Epoch: 837 [20480/90000 (23%)]	Loss: 11.2969	Cost: 5.95s
Train Epoch: 837 [40960/90000 (45%)]	Loss: 11.3046	Cost: 6.04s
Train Epoch: 837 [61440/90000 (68%)]	Loss: 11.1241	Cost: 5.91s
Train Epoch: 837 [81920/90000 (91%)]	Loss: 11.1606	Cost: 5.71s
Train Epoch: 837 	Average Loss: 11.6845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6445

Learning rate: 0.00019656270473678128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 838 [0/90000 (0%)]	Loss: 18.2052	Cost: 19.93s
Train Epoch: 838 [20480/90000 (23%)]	Loss: 11.1842	Cost: 6.19s
Train Epoch: 838 [40960/90000 (45%)]	Loss: 11.0235	Cost: 6.02s
Train Epoch: 838 [61440/90000 (68%)]	Loss: 11.1588	Cost: 6.01s
Train Epoch: 838 [81920/90000 (91%)]	Loss: 11.3702	Cost: 5.71s
Train Epoch: 838 	Average Loss: 11.6353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6209

Learning rate: 0.0001965545339815779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 839 [0/90000 (0%)]	Loss: 18.2534	Cost: 21.00s
Train Epoch: 839 [20480/90000 (23%)]	Loss: 11.1235	Cost: 6.00s
Train Epoch: 839 [40960/90000 (45%)]	Loss: 11.2110	Cost: 6.29s
Train Epoch: 839 [61440/90000 (68%)]	Loss: 11.2260	Cost: 5.97s
Train Epoch: 839 [81920/90000 (91%)]	Loss: 11.5423	Cost: 5.90s
Train Epoch: 839 	Average Loss: 11.7416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5692

Learning rate: 0.00019654635369682408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 840 [0/90000 (0%)]	Loss: 18.3299	Cost: 20.18s
Train Epoch: 840 [20480/90000 (23%)]	Loss: 11.2426	Cost: 6.13s
Train Epoch: 840 [40960/90000 (45%)]	Loss: 11.2737	Cost: 6.14s
Train Epoch: 840 [61440/90000 (68%)]	Loss: 10.8890	Cost: 5.90s
Train Epoch: 840 [81920/90000 (91%)]	Loss: 11.1273	Cost: 5.73s
Train Epoch: 840 	Average Loss: 11.7121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5195

Learning rate: 0.00019653816388332714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 841 [0/90000 (0%)]	Loss: 18.3941	Cost: 19.53s
Train Epoch: 841 [20480/90000 (23%)]	Loss: 11.5241	Cost: 6.06s
Train Epoch: 841 [40960/90000 (45%)]	Loss: 11.5082	Cost: 6.07s
Train Epoch: 841 [61440/90000 (68%)]	Loss: 11.3356	Cost: 5.91s
Train Epoch: 841 [81920/90000 (91%)]	Loss: 11.2468	Cost: 5.72s
Train Epoch: 841 	Average Loss: 11.8908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5409

Learning rate: 0.00019652996454189544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 842 [0/90000 (0%)]	Loss: 18.1522	Cost: 20.75s
Train Epoch: 842 [20480/90000 (23%)]	Loss: 11.4675	Cost: 6.06s
Train Epoch: 842 [40960/90000 (45%)]	Loss: 11.4725	Cost: 6.32s
Train Epoch: 842 [61440/90000 (68%)]	Loss: 11.3414	Cost: 5.83s
Train Epoch: 842 [81920/90000 (91%)]	Loss: 11.2586	Cost: 5.84s
Train Epoch: 842 	Average Loss: 11.7910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5653

Learning rate: 0.00019652175567333815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 843 [0/90000 (0%)]	Loss: 18.0339	Cost: 20.03s
Train Epoch: 843 [20480/90000 (23%)]	Loss: 11.1273	Cost: 5.98s
Train Epoch: 843 [40960/90000 (45%)]	Loss: 10.9984	Cost: 5.99s
Train Epoch: 843 [61440/90000 (68%)]	Loss: 10.9652	Cost: 5.89s
Train Epoch: 843 [81920/90000 (91%)]	Loss: 11.2939	Cost: 5.99s
Train Epoch: 843 	Average Loss: 11.5861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6359

Learning rate: 0.00019651353727846553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 844 [0/90000 (0%)]	Loss: 18.1511	Cost: 20.94s
Train Epoch: 844 [20480/90000 (23%)]	Loss: 11.0747	Cost: 6.52s
Train Epoch: 844 [40960/90000 (45%)]	Loss: 11.2680	Cost: 6.07s
Train Epoch: 844 [61440/90000 (68%)]	Loss: 11.0363	Cost: 5.82s
Train Epoch: 844 [81920/90000 (91%)]	Loss: 11.3073	Cost: 5.65s
Train Epoch: 844 	Average Loss: 11.6211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6852

Learning rate: 0.00019650530935808866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 845 [0/90000 (0%)]	Loss: 18.4759	Cost: 20.16s
Train Epoch: 845 [20480/90000 (23%)]	Loss: 11.2393	Cost: 6.07s
Train Epoch: 845 [40960/90000 (45%)]	Loss: 11.1794	Cost: 6.01s
Train Epoch: 845 [61440/90000 (68%)]	Loss: 11.2997	Cost: 5.91s
Train Epoch: 845 [81920/90000 (91%)]	Loss: 11.3676	Cost: 5.71s
Train Epoch: 845 	Average Loss: 11.7579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5165

Learning rate: 0.00019649707191301958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 846 [0/90000 (0%)]	Loss: 18.4039	Cost: 19.13s
Train Epoch: 846 [20480/90000 (23%)]	Loss: 11.1675	Cost: 6.07s
Train Epoch: 846 [40960/90000 (45%)]	Loss: 11.2486	Cost: 6.12s
Train Epoch: 846 [61440/90000 (68%)]	Loss: 11.1851	Cost: 5.88s
Train Epoch: 846 [81920/90000 (91%)]	Loss: 11.1540	Cost: 5.68s
Train Epoch: 846 	Average Loss: 11.6987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5511

Learning rate: 0.00019648882494407134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 847 [0/90000 (0%)]	Loss: 18.4237	Cost: 20.37s
Train Epoch: 847 [20480/90000 (23%)]	Loss: 11.1118	Cost: 5.96s
Train Epoch: 847 [40960/90000 (45%)]	Loss: 11.1919	Cost: 6.05s
Train Epoch: 847 [61440/90000 (68%)]	Loss: 11.0357	Cost: 5.82s
Train Epoch: 847 [81920/90000 (91%)]	Loss: 11.0932	Cost: 5.70s
Train Epoch: 847 	Average Loss: 11.5889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4862

Learning rate: 0.0001964805684520579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 848 [0/90000 (0%)]	Loss: 18.3575	Cost: 19.79s
Train Epoch: 848 [20480/90000 (23%)]	Loss: 10.8872	Cost: 6.07s
Train Epoch: 848 [40960/90000 (45%)]	Loss: 11.0468	Cost: 6.04s
Train Epoch: 848 [61440/90000 (68%)]	Loss: 10.9221	Cost: 5.88s
Train Epoch: 848 [81920/90000 (91%)]	Loss: 11.2258	Cost: 5.72s
Train Epoch: 848 	Average Loss: 11.5336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6312

Learning rate: 0.00019647230243779407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 849 [0/90000 (0%)]	Loss: 18.5217	Cost: 19.36s
Train Epoch: 849 [20480/90000 (23%)]	Loss: 10.8078	Cost: 6.07s
Train Epoch: 849 [40960/90000 (45%)]	Loss: 11.0324	Cost: 6.04s
Train Epoch: 849 [61440/90000 (68%)]	Loss: 10.7338	Cost: 6.08s
Train Epoch: 849 [81920/90000 (91%)]	Loss: 11.1954	Cost: 5.73s
Train Epoch: 849 	Average Loss: 11.5145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6449

Learning rate: 0.00019646402690209574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 850 [0/90000 (0%)]	Loss: 18.0841	Cost: 20.57s
Train Epoch: 850 [20480/90000 (23%)]	Loss: 10.9939	Cost: 5.99s
Train Epoch: 850 [40960/90000 (45%)]	Loss: 11.0562	Cost: 6.03s
Train Epoch: 850 [61440/90000 (68%)]	Loss: 10.8621	Cost: 5.91s
Train Epoch: 850 [81920/90000 (91%)]	Loss: 11.0797	Cost: 5.69s
Train Epoch: 850 	Average Loss: 11.5060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7308

Learning rate: 0.0001964557418457796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 851 [0/90000 (0%)]	Loss: 18.5260	Cost: 20.61s
Train Epoch: 851 [20480/90000 (23%)]	Loss: 11.0693	Cost: 6.18s
Train Epoch: 851 [40960/90000 (45%)]	Loss: 11.1465	Cost: 6.13s
Train Epoch: 851 [61440/90000 (68%)]	Loss: 11.0373	Cost: 5.84s
Train Epoch: 851 [81920/90000 (91%)]	Loss: 11.0326	Cost: 6.03s
Train Epoch: 851 	Average Loss: 11.5902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7017

Learning rate: 0.0001964474472696634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 852 [0/90000 (0%)]	Loss: 18.5489	Cost: 20.57s
Train Epoch: 852 [20480/90000 (23%)]	Loss: 10.8386	Cost: 6.17s
Train Epoch: 852 [40960/90000 (45%)]	Loss: 11.1930	Cost: 6.05s
Train Epoch: 852 [61440/90000 (68%)]	Loss: 10.9808	Cost: 5.92s
Train Epoch: 852 [81920/90000 (91%)]	Loss: 11.2599	Cost: 5.77s
Train Epoch: 852 	Average Loss: 11.5378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6230

Learning rate: 0.00019643914317456578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 853 [0/90000 (0%)]	Loss: 18.4152	Cost: 20.47s
Train Epoch: 853 [20480/90000 (23%)]	Loss: 10.8655	Cost: 6.14s
Train Epoch: 853 [40960/90000 (45%)]	Loss: 11.0553	Cost: 6.34s
Train Epoch: 853 [61440/90000 (68%)]	Loss: 10.8033	Cost: 5.85s
Train Epoch: 853 [81920/90000 (91%)]	Loss: 10.8947	Cost: 5.73s
Train Epoch: 853 	Average Loss: 11.5168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7492

Learning rate: 0.00019643082956130633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 854 [0/90000 (0%)]	Loss: 18.3131	Cost: 20.18s
Train Epoch: 854 [20480/90000 (23%)]	Loss: 10.9511	Cost: 6.04s
Train Epoch: 854 [40960/90000 (45%)]	Loss: 11.0508	Cost: 6.08s
Train Epoch: 854 [61440/90000 (68%)]	Loss: 11.0399	Cost: 5.93s
Train Epoch: 854 [81920/90000 (91%)]	Loss: 10.9369	Cost: 5.76s
Train Epoch: 854 	Average Loss: 11.5342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6424

Learning rate: 0.00019642250643070558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 855 [0/90000 (0%)]	Loss: 18.3272	Cost: 19.91s
Train Epoch: 855 [20480/90000 (23%)]	Loss: 10.8179	Cost: 6.02s
Train Epoch: 855 [40960/90000 (45%)]	Loss: 11.3815	Cost: 6.45s
Train Epoch: 855 [61440/90000 (68%)]	Loss: 11.0250	Cost: 5.85s
Train Epoch: 855 [81920/90000 (91%)]	Loss: 11.1204	Cost: 5.85s
Train Epoch: 855 	Average Loss: 11.5324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7319

Learning rate: 0.00019641417378358494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 856 [0/90000 (0%)]	Loss: 18.2936	Cost: 19.95s
Train Epoch: 856 [20480/90000 (23%)]	Loss: 11.1144	Cost: 5.78s
Train Epoch: 856 [40960/90000 (45%)]	Loss: 11.1085	Cost: 6.17s
Train Epoch: 856 [61440/90000 (68%)]	Loss: 10.9826	Cost: 5.74s
Train Epoch: 856 [81920/90000 (91%)]	Loss: 11.2095	Cost: 5.90s
Train Epoch: 856 	Average Loss: 11.5953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6648

Learning rate: 0.00019640583162076685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 857 [0/90000 (0%)]	Loss: 18.3146	Cost: 20.46s
Train Epoch: 857 [20480/90000 (23%)]	Loss: 11.0252	Cost: 6.00s
Train Epoch: 857 [40960/90000 (45%)]	Loss: 11.0688	Cost: 6.09s
Train Epoch: 857 [61440/90000 (68%)]	Loss: 11.0856	Cost: 5.86s
Train Epoch: 857 [81920/90000 (91%)]	Loss: 10.9275	Cost: 5.73s
Train Epoch: 857 	Average Loss: 11.5342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7073

Learning rate: 0.00019639747994307463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 858 [0/90000 (0%)]	Loss: 18.4385	Cost: 21.79s
Train Epoch: 858 [20480/90000 (23%)]	Loss: 10.9158	Cost: 6.02s
Train Epoch: 858 [40960/90000 (45%)]	Loss: 11.0191	Cost: 6.00s
Train Epoch: 858 [61440/90000 (68%)]	Loss: 10.9849	Cost: 5.86s
Train Epoch: 858 [81920/90000 (91%)]	Loss: 11.0898	Cost: 5.77s
Train Epoch: 858 	Average Loss: 11.5183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6547

Learning rate: 0.0001963891187513326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 859 [0/90000 (0%)]	Loss: 18.5472	Cost: 21.36s
Train Epoch: 859 [20480/90000 (23%)]	Loss: 10.9238	Cost: 6.02s
Train Epoch: 859 [40960/90000 (45%)]	Loss: 11.0922	Cost: 6.43s
Train Epoch: 859 [61440/90000 (68%)]	Loss: 10.9430	Cost: 5.86s
Train Epoch: 859 [81920/90000 (91%)]	Loss: 11.0798	Cost: 5.91s
Train Epoch: 859 	Average Loss: 11.5654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7398

Learning rate: 0.0001963807480463659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 860 [0/90000 (0%)]	Loss: 18.1449	Cost: 20.40s
Train Epoch: 860 [20480/90000 (23%)]	Loss: 10.8308	Cost: 6.03s
Train Epoch: 860 [40960/90000 (45%)]	Loss: 10.9907	Cost: 6.03s
Train Epoch: 860 [61440/90000 (68%)]	Loss: 10.7753	Cost: 5.99s
Train Epoch: 860 [81920/90000 (91%)]	Loss: 11.1103	Cost: 5.69s
Train Epoch: 860 	Average Loss: 11.4573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6938

Learning rate: 0.00019637236782900076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 861 [0/90000 (0%)]	Loss: 18.3255	Cost: 20.59s
Train Epoch: 861 [20480/90000 (23%)]	Loss: 10.7693	Cost: 6.22s
Train Epoch: 861 [40960/90000 (45%)]	Loss: 10.9824	Cost: 6.24s
Train Epoch: 861 [61440/90000 (68%)]	Loss: 10.9443	Cost: 5.83s
Train Epoch: 861 [81920/90000 (91%)]	Loss: 11.1121	Cost: 5.87s
Train Epoch: 861 	Average Loss: 11.4744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7094

Learning rate: 0.0001963639781000642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 862 [0/90000 (0%)]	Loss: 18.3862	Cost: 20.65s
Train Epoch: 862 [20480/90000 (23%)]	Loss: 10.7636	Cost: 5.99s
Train Epoch: 862 [40960/90000 (45%)]	Loss: 11.0446	Cost: 6.07s
Train Epoch: 862 [61440/90000 (68%)]	Loss: 11.0230	Cost: 5.91s
Train Epoch: 862 [81920/90000 (91%)]	Loss: 10.9024	Cost: 5.69s
Train Epoch: 862 	Average Loss: 11.4633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6790

Learning rate: 0.00019635557886038432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 863 [0/90000 (0%)]	Loss: 18.5025	Cost: 20.77s
Train Epoch: 863 [20480/90000 (23%)]	Loss: 10.9475	Cost: 6.01s
Train Epoch: 863 [40960/90000 (45%)]	Loss: 10.9591	Cost: 6.18s
Train Epoch: 863 [61440/90000 (68%)]	Loss: 10.7333	Cost: 6.51s
Train Epoch: 863 [81920/90000 (91%)]	Loss: 10.8711	Cost: 5.84s
Train Epoch: 863 	Average Loss: 11.4070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7387

Learning rate: 0.00019634717011079007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 864 [0/90000 (0%)]	Loss: 18.3618	Cost: 22.15s
Train Epoch: 864 [20480/90000 (23%)]	Loss: 10.7520	Cost: 5.99s
Train Epoch: 864 [40960/90000 (45%)]	Loss: 10.7098	Cost: 5.97s
Train Epoch: 864 [61440/90000 (68%)]	Loss: 10.7627	Cost: 5.86s
Train Epoch: 864 [81920/90000 (91%)]	Loss: 10.7823	Cost: 5.72s
Train Epoch: 864 	Average Loss: 11.3638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7540

Learning rate: 0.00019633875185211136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 865 [0/90000 (0%)]	Loss: 18.3216	Cost: 22.18s
Train Epoch: 865 [20480/90000 (23%)]	Loss: 10.8723	Cost: 6.03s
Train Epoch: 865 [40960/90000 (45%)]	Loss: 10.8162	Cost: 6.64s
Train Epoch: 865 [61440/90000 (68%)]	Loss: 10.7387	Cost: 5.94s
Train Epoch: 865 [81920/90000 (91%)]	Loss: 11.0282	Cost: 6.25s
Train Epoch: 865 	Average Loss: 11.3966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7544

Learning rate: 0.00019633032408517903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 866 [0/90000 (0%)]	Loss: 18.5249	Cost: 22.25s
Train Epoch: 866 [20480/90000 (23%)]	Loss: 10.8789	Cost: 6.01s
Train Epoch: 866 [40960/90000 (45%)]	Loss: 11.0317	Cost: 6.08s
Train Epoch: 866 [61440/90000 (68%)]	Loss: 10.7230	Cost: 5.84s
Train Epoch: 866 [81920/90000 (91%)]	Loss: 10.8135	Cost: 5.77s
Train Epoch: 866 	Average Loss: 11.4146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6672

Learning rate: 0.00019632188681082487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 867 [0/90000 (0%)]	Loss: 18.4396	Cost: 24.24s
Train Epoch: 867 [20480/90000 (23%)]	Loss: 10.7711	Cost: 6.00s
Train Epoch: 867 [40960/90000 (45%)]	Loss: 10.8840	Cost: 6.56s
Train Epoch: 867 [61440/90000 (68%)]	Loss: 10.9053	Cost: 5.90s
Train Epoch: 867 [81920/90000 (91%)]	Loss: 10.9134	Cost: 6.10s
Train Epoch: 867 	Average Loss: 11.4379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8444

Learning rate: 0.00019631344002988158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 868 [0/90000 (0%)]	Loss: 18.5569	Cost: 21.52s
Train Epoch: 868 [20480/90000 (23%)]	Loss: 10.6106	Cost: 6.05s
Train Epoch: 868 [40960/90000 (45%)]	Loss: 10.9289	Cost: 6.04s
Train Epoch: 868 [61440/90000 (68%)]	Loss: 10.8114	Cost: 5.83s
Train Epoch: 868 [81920/90000 (91%)]	Loss: 10.8903	Cost: 6.17s
Train Epoch: 868 	Average Loss: 11.4697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8057

Learning rate: 0.00019630498374318287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 869 [0/90000 (0%)]	Loss: 18.4391	Cost: 22.43s
Train Epoch: 869 [20480/90000 (23%)]	Loss: 10.7036	Cost: 6.01s
Train Epoch: 869 [40960/90000 (45%)]	Loss: 11.0360	Cost: 6.07s
Train Epoch: 869 [61440/90000 (68%)]	Loss: 10.7256	Cost: 5.91s
Train Epoch: 869 [81920/90000 (91%)]	Loss: 10.8646	Cost: 5.73s
Train Epoch: 869 	Average Loss: 11.4650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7836

Learning rate: 0.00019629651795156333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 870 [0/90000 (0%)]	Loss: 18.4753	Cost: 24.79s
Train Epoch: 870 [20480/90000 (23%)]	Loss: 10.6873	Cost: 5.99s
Train Epoch: 870 [40960/90000 (45%)]	Loss: 11.0187	Cost: 6.42s
Train Epoch: 870 [61440/90000 (68%)]	Loss: 10.6696	Cost: 5.90s
Train Epoch: 870 [81920/90000 (91%)]	Loss: 10.9195	Cost: 5.75s
Train Epoch: 870 	Average Loss: 11.3582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8179

Learning rate: 0.00019628804265585853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 871 [0/90000 (0%)]	Loss: 18.4322	Cost: 24.43s
Train Epoch: 871 [20480/90000 (23%)]	Loss: 10.7484	Cost: 6.00s
Train Epoch: 871 [40960/90000 (45%)]	Loss: 10.8265	Cost: 6.19s
Train Epoch: 871 [61440/90000 (68%)]	Loss: 10.8645	Cost: 6.08s
Train Epoch: 871 [81920/90000 (91%)]	Loss: 10.9559	Cost: 5.75s
Train Epoch: 871 	Average Loss: 11.4335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8408

Learning rate: 0.00019627955785690487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 872 [0/90000 (0%)]	Loss: 18.4437	Cost: 24.67s
Train Epoch: 872 [20480/90000 (23%)]	Loss: 10.6692	Cost: 5.99s
Train Epoch: 872 [40960/90000 (45%)]	Loss: 10.9715	Cost: 6.57s
Train Epoch: 872 [61440/90000 (68%)]	Loss: 10.6189	Cost: 5.82s
Train Epoch: 872 [81920/90000 (91%)]	Loss: 11.0239	Cost: 5.66s
Train Epoch: 872 	Average Loss: 11.3931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8594

Learning rate: 0.00019627106355553982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 873 [0/90000 (0%)]	Loss: 18.3173	Cost: 23.61s
Train Epoch: 873 [20480/90000 (23%)]	Loss: 10.6262	Cost: 5.96s
Train Epoch: 873 [40960/90000 (45%)]	Loss: 10.9597	Cost: 6.10s
Train Epoch: 873 [61440/90000 (68%)]	Loss: 10.6862	Cost: 5.96s
Train Epoch: 873 [81920/90000 (91%)]	Loss: 10.8941	Cost: 5.84s
Train Epoch: 873 	Average Loss: 11.3504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8120

Learning rate: 0.00019626255975260172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 874 [0/90000 (0%)]	Loss: 18.5821	Cost: 23.69s
Train Epoch: 874 [20480/90000 (23%)]	Loss: 10.6225	Cost: 6.00s
Train Epoch: 874 [40960/90000 (45%)]	Loss: 10.9291	Cost: 6.15s
Train Epoch: 874 [61440/90000 (68%)]	Loss: 10.9212	Cost: 5.93s
Train Epoch: 874 [81920/90000 (91%)]	Loss: 10.8275	Cost: 5.72s
Train Epoch: 874 	Average Loss: 11.3251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7562

Learning rate: 0.00019625404644892983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 875 [0/90000 (0%)]	Loss: 18.6029	Cost: 23.79s
Train Epoch: 875 [20480/90000 (23%)]	Loss: 10.6492	Cost: 6.92s
Train Epoch: 875 [40960/90000 (45%)]	Loss: 10.8283	Cost: 6.52s
Train Epoch: 875 [61440/90000 (68%)]	Loss: 10.6743	Cost: 5.95s
Train Epoch: 875 [81920/90000 (91%)]	Loss: 10.7557	Cost: 6.82s
Train Epoch: 875 	Average Loss: 11.3304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8367

Learning rate: 0.00019624552364536446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 876 [0/90000 (0%)]	Loss: 18.3605	Cost: 21.72s
Train Epoch: 876 [20480/90000 (23%)]	Loss: 10.7475	Cost: 6.61s
Train Epoch: 876 [40960/90000 (45%)]	Loss: 10.9194	Cost: 6.11s
Train Epoch: 876 [61440/90000 (68%)]	Loss: 10.8683	Cost: 5.93s
Train Epoch: 876 [81920/90000 (91%)]	Loss: 10.8243	Cost: 5.71s
Train Epoch: 876 	Average Loss: 11.3351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7731

Learning rate: 0.00019623699134274674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 877 [0/90000 (0%)]	Loss: 18.6507	Cost: 21.67s
Train Epoch: 877 [20480/90000 (23%)]	Loss: 10.7370	Cost: 6.04s
Train Epoch: 877 [40960/90000 (45%)]	Loss: 10.7831	Cost: 6.07s
Train Epoch: 877 [61440/90000 (68%)]	Loss: 10.7065	Cost: 6.02s
Train Epoch: 877 [81920/90000 (91%)]	Loss: 10.7549	Cost: 6.02s
Train Epoch: 877 	Average Loss: 11.3026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8418

Learning rate: 0.00019622844954191875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 878 [0/90000 (0%)]	Loss: 18.4226	Cost: 20.27s
Train Epoch: 878 [20480/90000 (23%)]	Loss: 10.5221	Cost: 6.11s
Train Epoch: 878 [40960/90000 (45%)]	Loss: 10.8305	Cost: 6.64s
Train Epoch: 878 [61440/90000 (68%)]	Loss: 10.7840	Cost: 5.95s
Train Epoch: 878 [81920/90000 (91%)]	Loss: 11.0717	Cost: 5.86s
Train Epoch: 878 	Average Loss: 11.3670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8040

Learning rate: 0.00019621989824372354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 879 [0/90000 (0%)]	Loss: 18.6791	Cost: 19.26s
Train Epoch: 879 [20480/90000 (23%)]	Loss: 10.7247	Cost: 6.18s
Train Epoch: 879 [40960/90000 (45%)]	Loss: 10.9676	Cost: 6.03s
Train Epoch: 879 [61440/90000 (68%)]	Loss: 10.7682	Cost: 5.88s
Train Epoch: 879 [81920/90000 (91%)]	Loss: 10.7558	Cost: 5.86s
Train Epoch: 879 	Average Loss: 11.3729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8423

Learning rate: 0.0001962113374490051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 880 [0/90000 (0%)]	Loss: 18.6562	Cost: 21.12s
Train Epoch: 880 [20480/90000 (23%)]	Loss: 10.7834	Cost: 5.98s
Train Epoch: 880 [40960/90000 (45%)]	Loss: 10.9043	Cost: 6.70s
Train Epoch: 880 [61440/90000 (68%)]	Loss: 10.8440	Cost: 5.86s
Train Epoch: 880 [81920/90000 (91%)]	Loss: 11.0831	Cost: 5.87s
Train Epoch: 880 	Average Loss: 11.4196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8778

Learning rate: 0.00019620276715860832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 881 [0/90000 (0%)]	Loss: 18.4108	Cost: 19.70s
Train Epoch: 881 [20480/90000 (23%)]	Loss: 10.5840	Cost: 6.04s
Train Epoch: 881 [40960/90000 (45%)]	Loss: 10.7006	Cost: 6.07s
Train Epoch: 881 [61440/90000 (68%)]	Loss: 10.7139	Cost: 5.95s
Train Epoch: 881 [81920/90000 (91%)]	Loss: 11.0225	Cost: 5.90s
Train Epoch: 881 	Average Loss: 11.3256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8905

Learning rate: 0.0001961941873733791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 882 [0/90000 (0%)]	Loss: 18.4825	Cost: 19.00s
Train Epoch: 882 [20480/90000 (23%)]	Loss: 10.5427	Cost: 6.08s
Train Epoch: 882 [40960/90000 (45%)]	Loss: 10.8311	Cost: 5.96s
Train Epoch: 882 [61440/90000 (68%)]	Loss: 10.7043	Cost: 6.09s
Train Epoch: 882 [81920/90000 (91%)]	Loss: 10.8907	Cost: 5.84s
Train Epoch: 882 	Average Loss: 11.3362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9599

Learning rate: 0.0001961855980941642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 883 [0/90000 (0%)]	Loss: 18.4505	Cost: 19.44s
Train Epoch: 883 [20480/90000 (23%)]	Loss: 10.5110	Cost: 6.04s
Train Epoch: 883 [40960/90000 (45%)]	Loss: 10.8536	Cost: 5.87s
Train Epoch: 883 [61440/90000 (68%)]	Loss: 10.6029	Cost: 5.63s
Train Epoch: 883 [81920/90000 (91%)]	Loss: 10.8321	Cost: 5.59s
Train Epoch: 883 	Average Loss: 11.3396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9516

Learning rate: 0.0001961769993218114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 884 [0/90000 (0%)]	Loss: 18.4543	Cost: 22.92s
Train Epoch: 884 [20480/90000 (23%)]	Loss: 10.8996	Cost: 5.92s
Train Epoch: 884 [40960/90000 (45%)]	Loss: 10.8726	Cost: 6.75s
Train Epoch: 884 [61440/90000 (68%)]	Loss: 10.7693	Cost: 5.87s
Train Epoch: 884 [81920/90000 (91%)]	Loss: 10.8030	Cost: 7.03s
Train Epoch: 884 	Average Loss: 11.3809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8169

Learning rate: 0.00019616839105716927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 885 [0/90000 (0%)]	Loss: 18.3631	Cost: 21.81s
Train Epoch: 885 [20480/90000 (23%)]	Loss: 10.6651	Cost: 5.96s
Train Epoch: 885 [40960/90000 (45%)]	Loss: 10.8361	Cost: 5.98s
Train Epoch: 885 [61440/90000 (68%)]	Loss: 10.8180	Cost: 5.83s
Train Epoch: 885 [81920/90000 (91%)]	Loss: 10.6309	Cost: 5.71s
Train Epoch: 885 	Average Loss: 11.2122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8812

Learning rate: 0.00019615977330108747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 886 [0/90000 (0%)]	Loss: 18.7332	Cost: 21.39s
Train Epoch: 886 [20480/90000 (23%)]	Loss: 10.7082	Cost: 5.99s
Train Epoch: 886 [40960/90000 (45%)]	Loss: 10.6911	Cost: 6.62s
Train Epoch: 886 [61440/90000 (68%)]	Loss: 10.8159	Cost: 5.92s
Train Epoch: 886 [81920/90000 (91%)]	Loss: 10.7610	Cost: 5.84s
Train Epoch: 886 	Average Loss: 11.3021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8163

Learning rate: 0.00019615114605441654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 887 [0/90000 (0%)]	Loss: 18.3515	Cost: 20.10s
Train Epoch: 887 [20480/90000 (23%)]	Loss: 10.5953	Cost: 6.28s
Train Epoch: 887 [40960/90000 (45%)]	Loss: 10.6228	Cost: 6.77s
Train Epoch: 887 [61440/90000 (68%)]	Loss: 10.5815	Cost: 5.80s
Train Epoch: 887 [81920/90000 (91%)]	Loss: 10.6928	Cost: 5.75s
Train Epoch: 887 	Average Loss: 11.2966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9130

Learning rate: 0.00019614250931800791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 888 [0/90000 (0%)]	Loss: 18.5754	Cost: 19.98s
Train Epoch: 888 [20480/90000 (23%)]	Loss: 10.7818	Cost: 6.07s
Train Epoch: 888 [40960/90000 (45%)]	Loss: 10.9608	Cost: 6.63s
Train Epoch: 888 [61440/90000 (68%)]	Loss: 10.7523	Cost: 5.86s
Train Epoch: 888 [81920/90000 (91%)]	Loss: 10.8155	Cost: 6.29s
Train Epoch: 888 	Average Loss: 11.2778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8095

Learning rate: 0.00019613386309271408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 889 [0/90000 (0%)]	Loss: 18.6103	Cost: 20.18s
Train Epoch: 889 [20480/90000 (23%)]	Loss: 10.6126	Cost: 6.08s
Train Epoch: 889 [40960/90000 (45%)]	Loss: 10.8685	Cost: 6.34s
Train Epoch: 889 [61440/90000 (68%)]	Loss: 10.5608	Cost: 5.83s
Train Epoch: 889 [81920/90000 (91%)]	Loss: 10.6291	Cost: 5.86s
Train Epoch: 889 	Average Loss: 11.2851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9093

Learning rate: 0.0001961252073793883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 890 [0/90000 (0%)]	Loss: 18.5633	Cost: 20.36s
Train Epoch: 890 [20480/90000 (23%)]	Loss: 10.6638	Cost: 6.02s
Train Epoch: 890 [40960/90000 (45%)]	Loss: 10.7149	Cost: 6.52s
Train Epoch: 890 [61440/90000 (68%)]	Loss: 10.7293	Cost: 5.87s
Train Epoch: 890 [81920/90000 (91%)]	Loss: 10.7000	Cost: 6.00s
Train Epoch: 890 	Average Loss: 11.2426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8506

Learning rate: 0.00019611654217888494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 891 [0/90000 (0%)]	Loss: 18.3993	Cost: 20.73s
Train Epoch: 891 [20480/90000 (23%)]	Loss: 10.6599	Cost: 5.96s
Train Epoch: 891 [40960/90000 (45%)]	Loss: 10.8003	Cost: 6.52s
Train Epoch: 891 [61440/90000 (68%)]	Loss: 10.4488	Cost: 5.82s
Train Epoch: 891 [81920/90000 (91%)]	Loss: 10.7130	Cost: 6.02s
Train Epoch: 891 	Average Loss: 11.2127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9763

Learning rate: 0.00019610786749205917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 892 [0/90000 (0%)]	Loss: 18.6784	Cost: 19.45s
Train Epoch: 892 [20480/90000 (23%)]	Loss: 10.4200	Cost: 6.01s
Train Epoch: 892 [40960/90000 (45%)]	Loss: 10.6964	Cost: 5.99s
Train Epoch: 892 [61440/90000 (68%)]	Loss: 10.4906	Cost: 5.87s
Train Epoch: 892 [81920/90000 (91%)]	Loss: 10.5815	Cost: 5.71s
Train Epoch: 892 	Average Loss: 11.1499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9995

Learning rate: 0.00019609918331976714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 893 [0/90000 (0%)]	Loss: 18.6484	Cost: 20.61s
Train Epoch: 893 [20480/90000 (23%)]	Loss: 10.3267	Cost: 6.04s
Train Epoch: 893 [40960/90000 (45%)]	Loss: 10.6862	Cost: 6.70s
Train Epoch: 893 [61440/90000 (68%)]	Loss: 10.5289	Cost: 5.97s
Train Epoch: 893 [81920/90000 (91%)]	Loss: 10.5808	Cost: 5.66s
Train Epoch: 893 	Average Loss: 11.1154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9330

Learning rate: 0.00019609048966286597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 894 [0/90000 (0%)]	Loss: 18.6622	Cost: 20.23s
Train Epoch: 894 [20480/90000 (23%)]	Loss: 10.7002	Cost: 5.95s
Train Epoch: 894 [40960/90000 (45%)]	Loss: 10.4611	Cost: 6.59s
Train Epoch: 894 [61440/90000 (68%)]	Loss: 10.9102	Cost: 5.80s
Train Epoch: 894 [81920/90000 (91%)]	Loss: 10.7683	Cost: 6.04s
Train Epoch: 894 	Average Loss: 11.2227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0733

Learning rate: 0.0001960817865222137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 895 [0/90000 (0%)]	Loss: 18.3710	Cost: 20.38s
Train Epoch: 895 [20480/90000 (23%)]	Loss: 10.5393	Cost: 5.97s
Train Epoch: 895 [40960/90000 (45%)]	Loss: 10.6629	Cost: 6.04s
Train Epoch: 895 [61440/90000 (68%)]	Loss: 10.6207	Cost: 5.84s
Train Epoch: 895 [81920/90000 (91%)]	Loss: 10.5218	Cost: 5.70s
Train Epoch: 895 	Average Loss: 11.1482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9582

Learning rate: 0.00019607307389866925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 896 [0/90000 (0%)]	Loss: 18.4762	Cost: 19.58s
Train Epoch: 896 [20480/90000 (23%)]	Loss: 10.4166	Cost: 6.07s
Train Epoch: 896 [40960/90000 (45%)]	Loss: 10.5523	Cost: 6.01s
Train Epoch: 896 [61440/90000 (68%)]	Loss: 10.6325	Cost: 5.84s
Train Epoch: 896 [81920/90000 (91%)]	Loss: 10.5978	Cost: 5.66s
Train Epoch: 896 	Average Loss: 11.1176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0295

Learning rate: 0.00019606435179309254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 897 [0/90000 (0%)]	Loss: 18.6050	Cost: 20.61s
Train Epoch: 897 [20480/90000 (23%)]	Loss: 10.4719	Cost: 5.98s
Train Epoch: 897 [40960/90000 (45%)]	Loss: 10.7417	Cost: 6.43s
Train Epoch: 897 [61440/90000 (68%)]	Loss: 10.7172	Cost: 5.95s
Train Epoch: 897 [81920/90000 (91%)]	Loss: 10.9792	Cost: 5.72s
Train Epoch: 897 	Average Loss: 11.2455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9543

Learning rate: 0.00019605562020634444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 898 [0/90000 (0%)]	Loss: 18.9774	Cost: 19.88s
Train Epoch: 898 [20480/90000 (23%)]	Loss: 10.7486	Cost: 5.97s
Train Epoch: 898 [40960/90000 (45%)]	Loss: 10.9301	Cost: 5.99s
Train Epoch: 898 [61440/90000 (68%)]	Loss: 10.6773	Cost: 5.80s
Train Epoch: 898 [81920/90000 (91%)]	Loss: 10.6097	Cost: 5.67s
Train Epoch: 898 	Average Loss: 11.3097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0297

Learning rate: 0.0001960468791392867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 899 [0/90000 (0%)]	Loss: 18.6444	Cost: 19.84s
Train Epoch: 899 [20480/90000 (23%)]	Loss: 10.3963	Cost: 6.01s
Train Epoch: 899 [40960/90000 (45%)]	Loss: 10.6218	Cost: 5.99s
Train Epoch: 899 [61440/90000 (68%)]	Loss: 10.6176	Cost: 5.89s
Train Epoch: 899 [81920/90000 (91%)]	Loss: 10.5647	Cost: 5.73s
Train Epoch: 899 	Average Loss: 11.1310
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8813

Learning rate: 0.000196038128592782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 900 [0/90000 (0%)]	Loss: 18.6568	Cost: 19.51s
Train Epoch: 900 [20480/90000 (23%)]	Loss: 10.3200	Cost: 5.97s
Train Epoch: 900 [40960/90000 (45%)]	Loss: 10.4534	Cost: 6.03s
Train Epoch: 900 [61440/90000 (68%)]	Loss: 10.4066	Cost: 5.85s
Train Epoch: 900 [81920/90000 (91%)]	Loss: 10.8726	Cost: 5.67s
Train Epoch: 900 	Average Loss: 11.1252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9558

Learning rate: 0.00019602936856769404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 901 [0/90000 (0%)]	Loss: 18.8515	Cost: 20.53s
Train Epoch: 901 [20480/90000 (23%)]	Loss: 10.4413	Cost: 5.97s
Train Epoch: 901 [40960/90000 (45%)]	Loss: 10.6559	Cost: 6.40s
Train Epoch: 901 [61440/90000 (68%)]	Loss: 10.6201	Cost: 6.50s
Train Epoch: 901 [81920/90000 (91%)]	Loss: 10.5449	Cost: 5.72s
Train Epoch: 901 	Average Loss: 11.2531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0583

Learning rate: 0.0001960205990648874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 902 [0/90000 (0%)]	Loss: 18.5489	Cost: 20.90s
Train Epoch: 902 [20480/90000 (23%)]	Loss: 10.6049	Cost: 6.10s
Train Epoch: 902 [40960/90000 (45%)]	Loss: 10.4997	Cost: 6.08s
Train Epoch: 902 [61440/90000 (68%)]	Loss: 10.6099	Cost: 5.91s
Train Epoch: 902 [81920/90000 (91%)]	Loss: 10.6021	Cost: 5.71s
Train Epoch: 902 	Average Loss: 11.1882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0254

Learning rate: 0.0001960118200852275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 903 [0/90000 (0%)]	Loss: 18.6501	Cost: 20.91s
Train Epoch: 903 [20480/90000 (23%)]	Loss: 10.4204	Cost: 6.14s
Train Epoch: 903 [40960/90000 (45%)]	Loss: 10.6561	Cost: 6.03s
Train Epoch: 903 [61440/90000 (68%)]	Loss: 10.4872	Cost: 5.94s
Train Epoch: 903 [81920/90000 (91%)]	Loss: 10.5009	Cost: 5.81s
Train Epoch: 903 	Average Loss: 11.1265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0238

Learning rate: 0.00019600303162958089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 904 [0/90000 (0%)]	Loss: 18.8240	Cost: 21.67s
Train Epoch: 904 [20480/90000 (23%)]	Loss: 10.3831	Cost: 5.96s
Train Epoch: 904 [40960/90000 (45%)]	Loss: 10.5672	Cost: 6.60s
Train Epoch: 904 [61440/90000 (68%)]	Loss: 10.4002	Cost: 5.98s
Train Epoch: 904 [81920/90000 (91%)]	Loss: 10.6953	Cost: 5.74s
Train Epoch: 904 	Average Loss: 11.1489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0161

Learning rate: 0.00019599423369881492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 905 [0/90000 (0%)]	Loss: 18.8703	Cost: 21.02s
Train Epoch: 905 [20480/90000 (23%)]	Loss: 10.4682	Cost: 6.05s
Train Epoch: 905 [40960/90000 (45%)]	Loss: 10.7389	Cost: 6.00s
Train Epoch: 905 [61440/90000 (68%)]	Loss: 10.6830	Cost: 5.90s
Train Epoch: 905 [81920/90000 (91%)]	Loss: 10.7987	Cost: 6.27s
Train Epoch: 905 	Average Loss: 11.2747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0482

Learning rate: 0.0001959854262937979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 906 [0/90000 (0%)]	Loss: 18.5868	Cost: 22.25s
Train Epoch: 906 [20480/90000 (23%)]	Loss: 10.7183	Cost: 5.97s
Train Epoch: 906 [40960/90000 (45%)]	Loss: 10.6751	Cost: 5.99s
Train Epoch: 906 [61440/90000 (68%)]	Loss: 10.6586	Cost: 5.82s
Train Epoch: 906 [81920/90000 (91%)]	Loss: 10.7685	Cost: 5.73s
Train Epoch: 906 	Average Loss: 11.2645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1189

Learning rate: 0.0001959766094153991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 907 [0/90000 (0%)]	Loss: 18.6887	Cost: 22.20s
Train Epoch: 907 [20480/90000 (23%)]	Loss: 10.4613	Cost: 6.26s
Train Epoch: 907 [40960/90000 (45%)]	Loss: 10.5298	Cost: 6.33s
Train Epoch: 907 [61440/90000 (68%)]	Loss: 10.4853	Cost: 6.02s
Train Epoch: 907 [81920/90000 (91%)]	Loss: 10.5998	Cost: 5.96s
Train Epoch: 907 	Average Loss: 11.1299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0643

Learning rate: 0.00019596778306448873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 908 [0/90000 (0%)]	Loss: 18.7813	Cost: 22.91s
Train Epoch: 908 [20480/90000 (23%)]	Loss: 10.3520	Cost: 5.97s
Train Epoch: 908 [40960/90000 (45%)]	Loss: 10.5623	Cost: 6.20s
Train Epoch: 908 [61440/90000 (68%)]	Loss: 10.3975	Cost: 5.89s
Train Epoch: 908 [81920/90000 (91%)]	Loss: 10.5512	Cost: 5.91s
Train Epoch: 908 	Average Loss: 11.0412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1283

Learning rate: 0.0001959589472419379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 909 [0/90000 (0%)]	Loss: 18.6177	Cost: 23.57s
Train Epoch: 909 [20480/90000 (23%)]	Loss: 10.3286	Cost: 6.01s
Train Epoch: 909 [40960/90000 (45%)]	Loss: 10.5494	Cost: 6.10s
Train Epoch: 909 [61440/90000 (68%)]	Loss: 10.2050	Cost: 5.96s
Train Epoch: 909 [81920/90000 (91%)]	Loss: 10.2078	Cost: 5.66s
Train Epoch: 909 	Average Loss: 11.0046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0644

Learning rate: 0.00019595010194861865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 910 [0/90000 (0%)]	Loss: 18.6855	Cost: 26.63s
Train Epoch: 910 [20480/90000 (23%)]	Loss: 10.3142	Cost: 5.94s
Train Epoch: 910 [40960/90000 (45%)]	Loss: 10.2540	Cost: 6.06s
Train Epoch: 910 [61440/90000 (68%)]	Loss: 10.6527	Cost: 5.87s
Train Epoch: 910 [81920/90000 (91%)]	Loss: 10.7340	Cost: 5.66s
Train Epoch: 910 	Average Loss: 11.0492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0864

Learning rate: 0.00019594124718540402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 911 [0/90000 (0%)]	Loss: 18.7479	Cost: 24.08s
Train Epoch: 911 [20480/90000 (23%)]	Loss: 10.6253	Cost: 6.16s
Train Epoch: 911 [40960/90000 (45%)]	Loss: 10.5494	Cost: 6.02s
Train Epoch: 911 [61440/90000 (68%)]	Loss: 10.6741	Cost: 5.84s
Train Epoch: 911 [81920/90000 (91%)]	Loss: 10.5749	Cost: 5.65s
Train Epoch: 911 	Average Loss: 11.1680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0642

Learning rate: 0.00019593238295316788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 912 [0/90000 (0%)]	Loss: 18.5892	Cost: 24.11s
Train Epoch: 912 [20480/90000 (23%)]	Loss: 10.2644	Cost: 7.07s
Train Epoch: 912 [40960/90000 (45%)]	Loss: 10.7026	Cost: 6.02s
Train Epoch: 912 [61440/90000 (68%)]	Loss: 10.5477	Cost: 5.94s
Train Epoch: 912 [81920/90000 (91%)]	Loss: 10.6744	Cost: 5.69s
Train Epoch: 912 	Average Loss: 11.1004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1297

Learning rate: 0.00019592350925278515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 913 [0/90000 (0%)]	Loss: 18.7125	Cost: 24.67s
Train Epoch: 913 [20480/90000 (23%)]	Loss: 10.5819	Cost: 6.00s
Train Epoch: 913 [40960/90000 (45%)]	Loss: 10.7508	Cost: 6.23s
Train Epoch: 913 [61440/90000 (68%)]	Loss: 10.3497	Cost: 5.98s
Train Epoch: 913 [81920/90000 (91%)]	Loss: 10.5617	Cost: 6.15s
Train Epoch: 913 	Average Loss: 11.1443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0624

Learning rate: 0.0001959146260851316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 914 [0/90000 (0%)]	Loss: 18.7446	Cost: 24.37s
Train Epoch: 914 [20480/90000 (23%)]	Loss: 10.4241	Cost: 5.98s
Train Epoch: 914 [40960/90000 (45%)]	Loss: 10.5568	Cost: 6.80s
Train Epoch: 914 [61440/90000 (68%)]	Loss: 10.4246	Cost: 5.84s
Train Epoch: 914 [81920/90000 (91%)]	Loss: 10.5012	Cost: 6.14s
Train Epoch: 914 	Average Loss: 11.0516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0719

Learning rate: 0.00019590573345108395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 915 [0/90000 (0%)]	Loss: 18.5690	Cost: 23.49s
Train Epoch: 915 [20480/90000 (23%)]	Loss: 10.4471	Cost: 6.18s
Train Epoch: 915 [40960/90000 (45%)]	Loss: 10.5500	Cost: 6.59s
Train Epoch: 915 [61440/90000 (68%)]	Loss: 10.3176	Cost: 6.03s
Train Epoch: 915 [81920/90000 (91%)]	Loss: 10.4533	Cost: 6.17s
Train Epoch: 915 	Average Loss: 10.9846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1541

Learning rate: 0.00019589683135151992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 916 [0/90000 (0%)]	Loss: 18.8071	Cost: 22.72s
Train Epoch: 916 [20480/90000 (23%)]	Loss: 10.1160	Cost: 6.26s
Train Epoch: 916 [40960/90000 (45%)]	Loss: 10.5357	Cost: 6.61s
Train Epoch: 916 [61440/90000 (68%)]	Loss: 10.2764	Cost: 5.85s
Train Epoch: 916 [81920/90000 (91%)]	Loss: 10.4789	Cost: 5.87s
Train Epoch: 916 	Average Loss: 10.9533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0711

Learning rate: 0.00019588791978731806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 917 [0/90000 (0%)]	Loss: 18.6882	Cost: 21.63s
Train Epoch: 917 [20480/90000 (23%)]	Loss: 10.1501	Cost: 6.13s
Train Epoch: 917 [40960/90000 (45%)]	Loss: 10.5391	Cost: 6.31s
Train Epoch: 917 [61440/90000 (68%)]	Loss: 10.3018	Cost: 5.92s
Train Epoch: 917 [81920/90000 (91%)]	Loss: 10.2042	Cost: 6.47s
Train Epoch: 917 	Average Loss: 10.9252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1479

Learning rate: 0.00019587899875935793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 918 [0/90000 (0%)]	Loss: 18.7762	Cost: 22.36s
Train Epoch: 918 [20480/90000 (23%)]	Loss: 10.2819	Cost: 6.05s
Train Epoch: 918 [40960/90000 (45%)]	Loss: 10.4187	Cost: 6.76s
Train Epoch: 918 [61440/90000 (68%)]	Loss: 10.0570	Cost: 5.94s
Train Epoch: 918 [81920/90000 (91%)]	Loss: 10.3613	Cost: 6.21s
Train Epoch: 918 	Average Loss: 10.8983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1734

Learning rate: 0.00019587006826851997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 919 [0/90000 (0%)]	Loss: 18.5878	Cost: 20.08s
Train Epoch: 919 [20480/90000 (23%)]	Loss: 10.2163	Cost: 6.10s
Train Epoch: 919 [40960/90000 (45%)]	Loss: 10.5397	Cost: 6.07s
Train Epoch: 919 [61440/90000 (68%)]	Loss: 10.2911	Cost: 5.92s
Train Epoch: 919 [81920/90000 (91%)]	Loss: 10.3901	Cost: 5.90s
Train Epoch: 919 	Average Loss: 10.9899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1359

Learning rate: 0.00019586112831568563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 920 [0/90000 (0%)]	Loss: 18.8634	Cost: 20.94s
Train Epoch: 920 [20480/90000 (23%)]	Loss: 10.3712	Cost: 6.41s
Train Epoch: 920 [40960/90000 (45%)]	Loss: 10.7042	Cost: 6.13s
Train Epoch: 920 [61440/90000 (68%)]	Loss: 10.3944	Cost: 5.97s
Train Epoch: 920 [81920/90000 (91%)]	Loss: 10.4614	Cost: 6.57s
Train Epoch: 920 	Average Loss: 11.0877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2131

Learning rate: 0.00019585217890173725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 921 [0/90000 (0%)]	Loss: 18.6152	Cost: 19.75s
Train Epoch: 921 [20480/90000 (23%)]	Loss: 10.3240	Cost: 6.17s
Train Epoch: 921 [40960/90000 (45%)]	Loss: 10.5650	Cost: 6.85s
Train Epoch: 921 [61440/90000 (68%)]	Loss: 10.2263	Cost: 5.83s
Train Epoch: 921 [81920/90000 (91%)]	Loss: 10.4107	Cost: 5.75s
Train Epoch: 921 	Average Loss: 10.9813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1009

Learning rate: 0.0001958432200275581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 922 [0/90000 (0%)]	Loss: 19.1132	Cost: 20.15s
Train Epoch: 922 [20480/90000 (23%)]	Loss: 10.2242	Cost: 6.02s
Train Epoch: 922 [40960/90000 (45%)]	Loss: 10.3245	Cost: 6.66s
Train Epoch: 922 [61440/90000 (68%)]	Loss: 10.4250	Cost: 5.92s
Train Epoch: 922 [81920/90000 (91%)]	Loss: 10.4338	Cost: 5.86s
Train Epoch: 922 	Average Loss: 10.9547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1949

Learning rate: 0.00019583425169403235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 923 [0/90000 (0%)]	Loss: 18.7422	Cost: 19.74s
Train Epoch: 923 [20480/90000 (23%)]	Loss: 10.1531	Cost: 5.95s
Train Epoch: 923 [40960/90000 (45%)]	Loss: 10.3891	Cost: 6.52s
Train Epoch: 923 [61440/90000 (68%)]	Loss: 10.2790	Cost: 5.86s
Train Epoch: 923 [81920/90000 (91%)]	Loss: 10.1830	Cost: 5.99s
Train Epoch: 923 	Average Loss: 10.8883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1360

Learning rate: 0.00019582527390204514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 924 [0/90000 (0%)]	Loss: 18.9640	Cost: 21.47s
Train Epoch: 924 [20480/90000 (23%)]	Loss: 10.1893	Cost: 5.97s
Train Epoch: 924 [40960/90000 (45%)]	Loss: 10.3519	Cost: 6.55s
Train Epoch: 924 [61440/90000 (68%)]	Loss: 9.9921	Cost: 5.98s
Train Epoch: 924 [81920/90000 (91%)]	Loss: 10.4423	Cost: 6.75s
Train Epoch: 924 	Average Loss: 10.8120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1578

Learning rate: 0.00019581628665248256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 925 [0/90000 (0%)]	Loss: 19.1220	Cost: 20.81s
Train Epoch: 925 [20480/90000 (23%)]	Loss: 10.1551	Cost: 5.90s
Train Epoch: 925 [40960/90000 (45%)]	Loss: 10.2207	Cost: 5.97s
Train Epoch: 925 [61440/90000 (68%)]	Loss: 10.1669	Cost: 5.87s
Train Epoch: 925 [81920/90000 (91%)]	Loss: 10.2480	Cost: 6.04s
Train Epoch: 925 	Average Loss: 10.8208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2165

Learning rate: 0.00019580728994623165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 926 [0/90000 (0%)]	Loss: 18.7025	Cost: 20.95s
Train Epoch: 926 [20480/90000 (23%)]	Loss: 10.1433	Cost: 5.97s
Train Epoch: 926 [40960/90000 (45%)]	Loss: 10.3312	Cost: 6.54s
Train Epoch: 926 [61440/90000 (68%)]	Loss: 10.4888	Cost: 6.02s
Train Epoch: 926 [81920/90000 (91%)]	Loss: 10.1764	Cost: 6.47s
Train Epoch: 926 	Average Loss: 10.8904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0943

Learning rate: 0.00019579828378418028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 927 [0/90000 (0%)]	Loss: 18.7387	Cost: 22.50s
Train Epoch: 927 [20480/90000 (23%)]	Loss: 10.1560	Cost: 5.84s
Train Epoch: 927 [40960/90000 (45%)]	Loss: 10.2769	Cost: 6.21s
Train Epoch: 927 [61440/90000 (68%)]	Loss: 10.1109	Cost: 5.82s
Train Epoch: 927 [81920/90000 (91%)]	Loss: 10.4012	Cost: 6.05s
Train Epoch: 927 	Average Loss: 10.8698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2383

Learning rate: 0.00019578926816721736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 928 [0/90000 (0%)]	Loss: 18.7053	Cost: 20.34s
Train Epoch: 928 [20480/90000 (23%)]	Loss: 10.3404	Cost: 6.01s
Train Epoch: 928 [40960/90000 (45%)]	Loss: 10.2880	Cost: 5.99s
Train Epoch: 928 [61440/90000 (68%)]	Loss: 10.1675	Cost: 5.90s
Train Epoch: 928 [81920/90000 (91%)]	Loss: 10.3393	Cost: 5.95s
Train Epoch: 928 	Average Loss: 10.9632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1498

Learning rate: 0.00019578024309623268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 929 [0/90000 (0%)]	Loss: 18.7271	Cost: 20.06s
Train Epoch: 929 [20480/90000 (23%)]	Loss: 10.1174	Cost: 6.08s
Train Epoch: 929 [40960/90000 (45%)]	Loss: 10.5537	Cost: 6.06s
Train Epoch: 929 [61440/90000 (68%)]	Loss: 10.2763	Cost: 5.87s
Train Epoch: 929 [81920/90000 (91%)]	Loss: 10.3145	Cost: 5.80s
Train Epoch: 929 	Average Loss: 10.9102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2554

Learning rate: 0.00019577120857211698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 930 [0/90000 (0%)]	Loss: 18.7651	Cost: 20.29s
Train Epoch: 930 [20480/90000 (23%)]	Loss: 10.3892	Cost: 6.31s
Train Epoch: 930 [40960/90000 (45%)]	Loss: 10.4958	Cost: 6.08s
Train Epoch: 930 [61440/90000 (68%)]	Loss: 10.4224	Cost: 5.84s
Train Epoch: 930 [81920/90000 (91%)]	Loss: 10.2818	Cost: 5.75s
Train Epoch: 930 	Average Loss: 10.9403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1929

Learning rate: 0.00019576216459576195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 931 [0/90000 (0%)]	Loss: 18.9481	Cost: 20.84s
Train Epoch: 931 [20480/90000 (23%)]	Loss: 10.2482	Cost: 6.18s
Train Epoch: 931 [40960/90000 (45%)]	Loss: 10.3534	Cost: 6.43s
Train Epoch: 931 [61440/90000 (68%)]	Loss: 10.2465	Cost: 5.89s
Train Epoch: 931 [81920/90000 (91%)]	Loss: 10.1571	Cost: 6.22s
Train Epoch: 931 	Average Loss: 10.8758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2981

Learning rate: 0.0001957531111680602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 932 [0/90000 (0%)]	Loss: 18.7479	Cost: 21.27s
Train Epoch: 932 [20480/90000 (23%)]	Loss: 10.0389	Cost: 6.00s
Train Epoch: 932 [40960/90000 (45%)]	Loss: 10.1325	Cost: 6.36s
Train Epoch: 932 [61440/90000 (68%)]	Loss: 10.2928	Cost: 5.86s
Train Epoch: 932 [81920/90000 (91%)]	Loss: 10.1388	Cost: 5.87s
Train Epoch: 932 	Average Loss: 10.7622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1744

Learning rate: 0.00019574404828990522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 933 [0/90000 (0%)]	Loss: 18.8168	Cost: 20.94s
Train Epoch: 933 [20480/90000 (23%)]	Loss: 9.9392	Cost: 5.94s
Train Epoch: 933 [40960/90000 (45%)]	Loss: 10.0513	Cost: 6.01s
Train Epoch: 933 [61440/90000 (68%)]	Loss: 10.2807	Cost: 5.86s
Train Epoch: 933 [81920/90000 (91%)]	Loss: 10.0752	Cost: 6.08s
Train Epoch: 933 	Average Loss: 10.7589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1674

Learning rate: 0.00019573497596219155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 934 [0/90000 (0%)]	Loss: 18.9087	Cost: 20.75s
Train Epoch: 934 [20480/90000 (23%)]	Loss: 9.9608	Cost: 6.10s
Train Epoch: 934 [40960/90000 (45%)]	Loss: 10.1594	Cost: 6.30s
Train Epoch: 934 [61440/90000 (68%)]	Loss: 10.1606	Cost: 5.94s
Train Epoch: 934 [81920/90000 (91%)]	Loss: 10.0044	Cost: 5.83s
Train Epoch: 934 	Average Loss: 10.7444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2575

Learning rate: 0.00019572589418581453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 935 [0/90000 (0%)]	Loss: 18.9382	Cost: 21.20s
Train Epoch: 935 [20480/90000 (23%)]	Loss: 10.0280	Cost: 6.09s
Train Epoch: 935 [40960/90000 (45%)]	Loss: 10.0848	Cost: 6.38s
Train Epoch: 935 [61440/90000 (68%)]	Loss: 9.9720	Cost: 5.87s
Train Epoch: 935 [81920/90000 (91%)]	Loss: 9.8984	Cost: 5.72s
Train Epoch: 935 	Average Loss: 10.6521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1759

Learning rate: 0.00019571680296167054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 936 [0/90000 (0%)]	Loss: 18.7739	Cost: 20.02s
Train Epoch: 936 [20480/90000 (23%)]	Loss: 9.9885	Cost: 6.12s
Train Epoch: 936 [40960/90000 (45%)]	Loss: 10.2658	Cost: 6.44s
Train Epoch: 936 [61440/90000 (68%)]	Loss: 10.1100	Cost: 5.86s
Train Epoch: 936 [81920/90000 (91%)]	Loss: 10.2562	Cost: 5.74s
Train Epoch: 936 	Average Loss: 10.7968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2635

Learning rate: 0.00019570770229065682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 937 [0/90000 (0%)]	Loss: 18.8526	Cost: 20.88s
Train Epoch: 937 [20480/90000 (23%)]	Loss: 10.0690	Cost: 6.02s
Train Epoch: 937 [40960/90000 (45%)]	Loss: 10.1520	Cost: 6.64s
Train Epoch: 937 [61440/90000 (68%)]	Loss: 10.0911	Cost: 6.04s
Train Epoch: 937 [81920/90000 (91%)]	Loss: 10.0201	Cost: 5.79s
Train Epoch: 937 	Average Loss: 10.7460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2536

Learning rate: 0.0001956985921736716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 938 [0/90000 (0%)]	Loss: 18.6697	Cost: 20.98s
Train Epoch: 938 [20480/90000 (23%)]	Loss: 10.0166	Cost: 6.04s
Train Epoch: 938 [40960/90000 (45%)]	Loss: 10.1404	Cost: 6.27s
Train Epoch: 938 [61440/90000 (68%)]	Loss: 10.0610	Cost: 5.92s
Train Epoch: 938 [81920/90000 (91%)]	Loss: 10.2925	Cost: 5.81s
Train Epoch: 938 	Average Loss: 10.7352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3035

Learning rate: 0.00019568947261161396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 939 [0/90000 (0%)]	Loss: 19.0232	Cost: 21.14s
Train Epoch: 939 [20480/90000 (23%)]	Loss: 10.2847	Cost: 5.97s
Train Epoch: 939 [40960/90000 (45%)]	Loss: 10.4356	Cost: 6.08s
Train Epoch: 939 [61440/90000 (68%)]	Loss: 10.3498	Cost: 5.89s
Train Epoch: 939 [81920/90000 (91%)]	Loss: 10.4775	Cost: 5.76s
Train Epoch: 939 	Average Loss: 10.9888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2354

Learning rate: 0.00019568034360538402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 940 [0/90000 (0%)]	Loss: 18.8609	Cost: 20.27s
Train Epoch: 940 [20480/90000 (23%)]	Loss: 10.2031	Cost: 5.99s
Train Epoch: 940 [40960/90000 (45%)]	Loss: 10.3798	Cost: 6.17s
Train Epoch: 940 [61440/90000 (68%)]	Loss: 10.0411	Cost: 5.88s
Train Epoch: 940 [81920/90000 (91%)]	Loss: 10.2263	Cost: 5.73s
Train Epoch: 940 	Average Loss: 10.8475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3099

Learning rate: 0.00019567120515588275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 941 [0/90000 (0%)]	Loss: 18.9366	Cost: 20.69s
Train Epoch: 941 [20480/90000 (23%)]	Loss: 10.1419	Cost: 6.04s
Train Epoch: 941 [40960/90000 (45%)]	Loss: 10.0862	Cost: 6.06s
Train Epoch: 941 [61440/90000 (68%)]	Loss: 10.2386	Cost: 5.92s
Train Epoch: 941 [81920/90000 (91%)]	Loss: 10.3207	Cost: 5.78s
Train Epoch: 941 	Average Loss: 10.7877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2381

Learning rate: 0.0001956620572640121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 942 [0/90000 (0%)]	Loss: 18.9238	Cost: 20.94s
Train Epoch: 942 [20480/90000 (23%)]	Loss: 10.1165	Cost: 6.05s
Train Epoch: 942 [40960/90000 (45%)]	Loss: 10.1655	Cost: 6.08s
Train Epoch: 942 [61440/90000 (68%)]	Loss: 10.1610	Cost: 5.94s
Train Epoch: 942 [81920/90000 (91%)]	Loss: 10.2429	Cost: 5.98s
Train Epoch: 942 	Average Loss: 10.8224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3529

Learning rate: 0.0001956528999306749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 943 [0/90000 (0%)]	Loss: 18.9073	Cost: 19.87s
Train Epoch: 943 [20480/90000 (23%)]	Loss: 10.0237	Cost: 6.03s
Train Epoch: 943 [40960/90000 (45%)]	Loss: 9.9587	Cost: 6.25s
Train Epoch: 943 [61440/90000 (68%)]	Loss: 10.0212	Cost: 5.93s
Train Epoch: 943 [81920/90000 (91%)]	Loss: 10.0653	Cost: 5.83s
Train Epoch: 943 	Average Loss: 10.6873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3124

Learning rate: 0.00019564373315677494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 944 [0/90000 (0%)]	Loss: 19.0649	Cost: 21.48s
Train Epoch: 944 [20480/90000 (23%)]	Loss: 9.9711	Cost: 6.09s
Train Epoch: 944 [40960/90000 (45%)]	Loss: 10.1058	Cost: 6.08s
Train Epoch: 944 [61440/90000 (68%)]	Loss: 10.0447	Cost: 5.86s
Train Epoch: 944 [81920/90000 (91%)]	Loss: 10.0770	Cost: 6.41s
Train Epoch: 944 	Average Loss: 10.6707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2710

Learning rate: 0.00019563455694321697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 945 [0/90000 (0%)]	Loss: 18.9401	Cost: 21.63s
Train Epoch: 945 [20480/90000 (23%)]	Loss: 9.8587	Cost: 5.92s
Train Epoch: 945 [40960/90000 (45%)]	Loss: 9.9518	Cost: 5.97s
Train Epoch: 945 [61440/90000 (68%)]	Loss: 9.8862	Cost: 5.89s
Train Epoch: 945 [81920/90000 (91%)]	Loss: 9.9334	Cost: 5.64s
Train Epoch: 945 	Average Loss: 10.5900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3904

Learning rate: 0.00019562537129090663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 946 [0/90000 (0%)]	Loss: 19.1723	Cost: 22.72s
Train Epoch: 946 [20480/90000 (23%)]	Loss: 9.9150	Cost: 6.03s
Train Epoch: 946 [40960/90000 (45%)]	Loss: 9.9512	Cost: 6.47s
Train Epoch: 946 [61440/90000 (68%)]	Loss: 9.9313	Cost: 6.00s
Train Epoch: 946 [81920/90000 (91%)]	Loss: 10.0511	Cost: 6.27s
Train Epoch: 946 	Average Loss: 10.6350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3203

Learning rate: 0.00019561617620075054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 947 [0/90000 (0%)]	Loss: 19.0403	Cost: 21.70s
Train Epoch: 947 [20480/90000 (23%)]	Loss: 9.7511	Cost: 6.06s
Train Epoch: 947 [40960/90000 (45%)]	Loss: 9.9583	Cost: 6.25s
Train Epoch: 947 [61440/90000 (68%)]	Loss: 9.5774	Cost: 5.94s
Train Epoch: 947 [81920/90000 (91%)]	Loss: 9.9246	Cost: 5.85s
Train Epoch: 947 	Average Loss: 10.6072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3417

Learning rate: 0.00019560697167365617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 948 [0/90000 (0%)]	Loss: 18.8750	Cost: 22.58s
Train Epoch: 948 [20480/90000 (23%)]	Loss: 9.6934	Cost: 6.33s
Train Epoch: 948 [40960/90000 (45%)]	Loss: 10.0113	Cost: 6.56s
Train Epoch: 948 [61440/90000 (68%)]	Loss: 9.9807	Cost: 6.06s
Train Epoch: 948 [81920/90000 (91%)]	Loss: 10.1567	Cost: 6.27s
Train Epoch: 948 	Average Loss: 10.6274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3720

Learning rate: 0.00019559775771053198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 949 [0/90000 (0%)]	Loss: 19.0449	Cost: 21.02s
Train Epoch: 949 [20480/90000 (23%)]	Loss: 9.8483	Cost: 6.11s
Train Epoch: 949 [40960/90000 (45%)]	Loss: 10.0768	Cost: 6.28s
Train Epoch: 949 [61440/90000 (68%)]	Loss: 9.9046	Cost: 5.87s
Train Epoch: 949 [81920/90000 (91%)]	Loss: 9.9942	Cost: 5.87s
Train Epoch: 949 	Average Loss: 10.6410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4579

Learning rate: 0.0001955885343122874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 950 [0/90000 (0%)]	Loss: 18.8321	Cost: 20.03s
Train Epoch: 950 [20480/90000 (23%)]	Loss: 10.5515	Cost: 6.02s
Train Epoch: 950 [40960/90000 (45%)]	Loss: 10.4762	Cost: 6.22s
Train Epoch: 950 [61440/90000 (68%)]	Loss: 10.3070	Cost: 5.93s
Train Epoch: 950 [81920/90000 (91%)]	Loss: 10.2478	Cost: 6.10s
Train Epoch: 950 	Average Loss: 10.9311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3940

Learning rate: 0.0001955793014798327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 951 [0/90000 (0%)]	Loss: 18.7642	Cost: 20.27s
Train Epoch: 951 [20480/90000 (23%)]	Loss: 10.1070	Cost: 6.09s
Train Epoch: 951 [40960/90000 (45%)]	Loss: 9.9660	Cost: 6.59s
Train Epoch: 951 [61440/90000 (68%)]	Loss: 10.0440	Cost: 5.91s
Train Epoch: 951 [81920/90000 (91%)]	Loss: 10.0577	Cost: 6.48s
Train Epoch: 951 	Average Loss: 10.7563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3028

Learning rate: 0.00019557005921407914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 952 [0/90000 (0%)]	Loss: 18.8964	Cost: 20.11s
Train Epoch: 952 [20480/90000 (23%)]	Loss: 9.8554	Cost: 6.05s
Train Epoch: 952 [40960/90000 (45%)]	Loss: 10.0419	Cost: 6.06s
Train Epoch: 952 [61440/90000 (68%)]	Loss: 9.9860	Cost: 5.90s
Train Epoch: 952 [81920/90000 (91%)]	Loss: 9.9721	Cost: 5.74s
Train Epoch: 952 	Average Loss: 10.6915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3676

Learning rate: 0.0001955608075159389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 953 [0/90000 (0%)]	Loss: 19.1828	Cost: 21.03s
Train Epoch: 953 [20480/90000 (23%)]	Loss: 9.8316	Cost: 5.98s
Train Epoch: 953 [40960/90000 (45%)]	Loss: 10.2611	Cost: 6.97s
Train Epoch: 953 [61440/90000 (68%)]	Loss: 9.7641	Cost: 5.82s
Train Epoch: 953 [81920/90000 (91%)]	Loss: 9.8884	Cost: 5.74s
Train Epoch: 953 	Average Loss: 10.7287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4202

Learning rate: 0.00019555154638632502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 954 [0/90000 (0%)]	Loss: 18.8467	Cost: 21.62s
Train Epoch: 954 [20480/90000 (23%)]	Loss: 10.0126	Cost: 5.94s
Train Epoch: 954 [40960/90000 (45%)]	Loss: 10.1035	Cost: 6.22s
Train Epoch: 954 [61440/90000 (68%)]	Loss: 9.9012	Cost: 5.87s
Train Epoch: 954 [81920/90000 (91%)]	Loss: 9.9794	Cost: 6.26s
Train Epoch: 954 	Average Loss: 10.6936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3629

Learning rate: 0.00019554227582615162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 955 [0/90000 (0%)]	Loss: 19.1304	Cost: 22.86s
Train Epoch: 955 [20480/90000 (23%)]	Loss: 9.7584	Cost: 5.67s
Train Epoch: 955 [40960/90000 (45%)]	Loss: 10.1320	Cost: 6.35s
Train Epoch: 955 [61440/90000 (68%)]	Loss: 9.9718	Cost: 5.86s
Train Epoch: 955 [81920/90000 (91%)]	Loss: 10.4074	Cost: 5.74s
Train Epoch: 955 	Average Loss: 10.7003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3649

Learning rate: 0.00019553299583633364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 956 [0/90000 (0%)]	Loss: 19.1965	Cost: 20.96s
Train Epoch: 956 [20480/90000 (23%)]	Loss: 10.0886	Cost: 5.97s
Train Epoch: 956 [40960/90000 (45%)]	Loss: 10.2830	Cost: 6.65s
Train Epoch: 956 [61440/90000 (68%)]	Loss: 10.1540	Cost: 5.82s
Train Epoch: 956 [81920/90000 (91%)]	Loss: 10.4027	Cost: 5.78s
Train Epoch: 956 	Average Loss: 10.8259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3713

Learning rate: 0.00019552370641778697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 957 [0/90000 (0%)]	Loss: 19.2849	Cost: 20.48s
Train Epoch: 957 [20480/90000 (23%)]	Loss: 10.1794	Cost: 6.02s
Train Epoch: 957 [40960/90000 (45%)]	Loss: 10.1188	Cost: 6.11s
Train Epoch: 957 [61440/90000 (68%)]	Loss: 10.0490	Cost: 5.84s
Train Epoch: 957 [81920/90000 (91%)]	Loss: 10.0042	Cost: 5.73s
Train Epoch: 957 	Average Loss: 10.7284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3608

Learning rate: 0.00019551440757142847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 958 [0/90000 (0%)]	Loss: 19.0124	Cost: 20.21s
Train Epoch: 958 [20480/90000 (23%)]	Loss: 9.8083	Cost: 6.67s
Train Epoch: 958 [40960/90000 (45%)]	Loss: 9.9357	Cost: 6.17s
Train Epoch: 958 [61440/90000 (68%)]	Loss: 9.8407	Cost: 5.86s
Train Epoch: 958 [81920/90000 (91%)]	Loss: 9.9990	Cost: 5.85s
Train Epoch: 958 	Average Loss: 10.6026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3813

Learning rate: 0.00019550509929817583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 959 [0/90000 (0%)]	Loss: 18.7097	Cost: 21.68s
Train Epoch: 959 [20480/90000 (23%)]	Loss: 9.7866	Cost: 6.02s
Train Epoch: 959 [40960/90000 (45%)]	Loss: 9.9708	Cost: 6.54s
Train Epoch: 959 [61440/90000 (68%)]	Loss: 10.0030	Cost: 5.98s
Train Epoch: 959 [81920/90000 (91%)]	Loss: 10.1170	Cost: 5.81s
Train Epoch: 959 	Average Loss: 10.6167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3258

Learning rate: 0.00019549578159894782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 960 [0/90000 (0%)]	Loss: 19.1293	Cost: 21.70s
Train Epoch: 960 [20480/90000 (23%)]	Loss: 9.9330	Cost: 5.99s
Train Epoch: 960 [40960/90000 (45%)]	Loss: 9.9558	Cost: 6.09s
Train Epoch: 960 [61440/90000 (68%)]	Loss: 10.0989	Cost: 5.85s
Train Epoch: 960 [81920/90000 (91%)]	Loss: 10.0497	Cost: 5.75s
Train Epoch: 960 	Average Loss: 10.6576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3504

Learning rate: 0.00019548645447466402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 961 [0/90000 (0%)]	Loss: 18.8754	Cost: 23.01s
Train Epoch: 961 [20480/90000 (23%)]	Loss: 9.8393	Cost: 5.92s
Train Epoch: 961 [40960/90000 (45%)]	Loss: 10.1093	Cost: 6.57s
Train Epoch: 961 [61440/90000 (68%)]	Loss: 9.9688	Cost: 5.82s
Train Epoch: 961 [81920/90000 (91%)]	Loss: 9.9125	Cost: 6.20s
Train Epoch: 961 	Average Loss: 10.6632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3279

Learning rate: 0.00019547711792624497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 962 [0/90000 (0%)]	Loss: 19.1047	Cost: 21.66s
Train Epoch: 962 [20480/90000 (23%)]	Loss: 9.9045	Cost: 5.91s
Train Epoch: 962 [40960/90000 (45%)]	Loss: 9.7917	Cost: 6.24s
Train Epoch: 962 [61440/90000 (68%)]	Loss: 9.7722	Cost: 5.81s
Train Epoch: 962 [81920/90000 (91%)]	Loss: 10.1208	Cost: 6.01s
Train Epoch: 962 	Average Loss: 10.5894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3312

Learning rate: 0.00019546777195461216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 963 [0/90000 (0%)]	Loss: 19.0645	Cost: 22.59s
Train Epoch: 963 [20480/90000 (23%)]	Loss: 9.8229	Cost: 6.89s
Train Epoch: 963 [40960/90000 (45%)]	Loss: 9.7545	Cost: 6.40s
Train Epoch: 963 [61440/90000 (68%)]	Loss: 9.7077	Cost: 5.92s
Train Epoch: 963 [81920/90000 (91%)]	Loss: 10.1251	Cost: 5.92s
Train Epoch: 963 	Average Loss: 10.5545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4315

Learning rate: 0.00019545841656068801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 964 [0/90000 (0%)]	Loss: 19.1749	Cost: 21.59s
Train Epoch: 964 [20480/90000 (23%)]	Loss: 9.8304	Cost: 5.99s
Train Epoch: 964 [40960/90000 (45%)]	Loss: 9.8286	Cost: 6.27s
Train Epoch: 964 [61440/90000 (68%)]	Loss: 9.7753	Cost: 5.84s
Train Epoch: 964 [81920/90000 (91%)]	Loss: 9.9501	Cost: 6.10s
Train Epoch: 964 	Average Loss: 10.4858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5193

Learning rate: 0.00019544905174539588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 965 [0/90000 (0%)]	Loss: 19.2064	Cost: 22.16s
Train Epoch: 965 [20480/90000 (23%)]	Loss: 9.8169	Cost: 5.99s
Train Epoch: 965 [40960/90000 (45%)]	Loss: 10.0619	Cost: 7.29s
Train Epoch: 965 [61440/90000 (68%)]	Loss: 9.8045	Cost: 5.84s
Train Epoch: 965 [81920/90000 (91%)]	Loss: 10.0702	Cost: 6.30s
Train Epoch: 965 	Average Loss: 10.5926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5043

Learning rate: 0.00019543967750965997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 966 [0/90000 (0%)]	Loss: 19.0449	Cost: 19.30s
Train Epoch: 966 [20480/90000 (23%)]	Loss: 10.0559	Cost: 6.01s
Train Epoch: 966 [40960/90000 (45%)]	Loss: 10.0558	Cost: 5.98s
Train Epoch: 966 [61440/90000 (68%)]	Loss: 9.7189	Cost: 5.84s
Train Epoch: 966 [81920/90000 (91%)]	Loss: 9.8921	Cost: 5.73s
Train Epoch: 966 	Average Loss: 10.5867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4109

Learning rate: 0.00019543029385440556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 967 [0/90000 (0%)]	Loss: 18.7261	Cost: 19.51s
Train Epoch: 967 [20480/90000 (23%)]	Loss: 9.7494	Cost: 6.00s
Train Epoch: 967 [40960/90000 (45%)]	Loss: 10.0650	Cost: 6.05s
Train Epoch: 967 [61440/90000 (68%)]	Loss: 9.7691	Cost: 5.90s
Train Epoch: 967 [81920/90000 (91%)]	Loss: 9.8894	Cost: 5.99s
Train Epoch: 967 	Average Loss: 10.5378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4236

Learning rate: 0.00019542090078055873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 968 [0/90000 (0%)]	Loss: 19.0767	Cost: 20.44s
Train Epoch: 968 [20480/90000 (23%)]	Loss: 10.0758	Cost: 5.98s
Train Epoch: 968 [40960/90000 (45%)]	Loss: 9.9173	Cost: 6.31s
Train Epoch: 968 [61440/90000 (68%)]	Loss: 9.9693	Cost: 5.83s
Train Epoch: 968 [81920/90000 (91%)]	Loss: 9.9948	Cost: 5.74s
Train Epoch: 968 	Average Loss: 10.5798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5094

Learning rate: 0.00019541149828904657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 969 [0/90000 (0%)]	Loss: 19.1372	Cost: 20.18s
Train Epoch: 969 [20480/90000 (23%)]	Loss: 9.7875	Cost: 5.99s
Train Epoch: 969 [40960/90000 (45%)]	Loss: 9.8514	Cost: 6.57s
Train Epoch: 969 [61440/90000 (68%)]	Loss: 9.7183	Cost: 5.87s
Train Epoch: 969 [81920/90000 (91%)]	Loss: 9.7051	Cost: 6.19s
Train Epoch: 969 	Average Loss: 10.4641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5506

Learning rate: 0.00019540208638079703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 970 [0/90000 (0%)]	Loss: 19.1168	Cost: 20.40s
Train Epoch: 970 [20480/90000 (23%)]	Loss: 9.6436	Cost: 6.08s
Train Epoch: 970 [40960/90000 (45%)]	Loss: 9.9221	Cost: 6.52s
Train Epoch: 970 [61440/90000 (68%)]	Loss: 9.8119	Cost: 6.01s
Train Epoch: 970 [81920/90000 (91%)]	Loss: 9.6662	Cost: 5.79s
Train Epoch: 970 	Average Loss: 10.4343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6626

Learning rate: 0.00019539266505673905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 971 [0/90000 (0%)]	Loss: 19.1737	Cost: 20.71s
Train Epoch: 971 [20480/90000 (23%)]	Loss: 9.4621	Cost: 6.16s
Train Epoch: 971 [40960/90000 (45%)]	Loss: 9.8021	Cost: 6.67s
Train Epoch: 971 [61440/90000 (68%)]	Loss: 9.5619	Cost: 5.84s
Train Epoch: 971 [81920/90000 (91%)]	Loss: 9.8957	Cost: 5.82s
Train Epoch: 971 	Average Loss: 10.4189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5379

Learning rate: 0.0001953832343178025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 972 [0/90000 (0%)]	Loss: 19.0675	Cost: 20.77s
Train Epoch: 972 [20480/90000 (23%)]	Loss: 9.7316	Cost: 6.07s
Train Epoch: 972 [40960/90000 (45%)]	Loss: 9.7787	Cost: 6.65s
Train Epoch: 972 [61440/90000 (68%)]	Loss: 9.7352	Cost: 5.82s
Train Epoch: 972 [81920/90000 (91%)]	Loss: 9.6844	Cost: 6.15s
Train Epoch: 972 	Average Loss: 10.4340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5532

Learning rate: 0.00019537379416491811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 973 [0/90000 (0%)]	Loss: 19.1186	Cost: 20.59s
Train Epoch: 973 [20480/90000 (23%)]	Loss: 9.6992	Cost: 5.85s
Train Epoch: 973 [40960/90000 (45%)]	Loss: 9.7000	Cost: 6.92s
Train Epoch: 973 [61440/90000 (68%)]	Loss: 9.5837	Cost: 5.82s
Train Epoch: 973 [81920/90000 (91%)]	Loss: 9.8253	Cost: 5.98s
Train Epoch: 973 	Average Loss: 10.3544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5460

Learning rate: 0.00019536434459901765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 974 [0/90000 (0%)]	Loss: 19.1298	Cost: 21.48s
Train Epoch: 974 [20480/90000 (23%)]	Loss: 9.5390	Cost: 6.00s
Train Epoch: 974 [40960/90000 (45%)]	Loss: 9.5656	Cost: 6.76s
Train Epoch: 974 [61440/90000 (68%)]	Loss: 9.6180	Cost: 5.83s
Train Epoch: 974 [81920/90000 (91%)]	Loss: 9.6447	Cost: 5.73s
Train Epoch: 974 	Average Loss: 10.3331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5978

Learning rate: 0.0001953548856210337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 975 [0/90000 (0%)]	Loss: 19.2911	Cost: 19.76s
Train Epoch: 975 [20480/90000 (23%)]	Loss: 9.6884	Cost: 6.01s
Train Epoch: 975 [40960/90000 (45%)]	Loss: 9.7483	Cost: 6.47s
Train Epoch: 975 [61440/90000 (68%)]	Loss: 9.5278	Cost: 5.89s
Train Epoch: 975 [81920/90000 (91%)]	Loss: 9.7310	Cost: 5.99s
Train Epoch: 975 	Average Loss: 10.3510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5416

Learning rate: 0.00019534541723189978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 976 [0/90000 (0%)]	Loss: 18.9858	Cost: 21.21s
Train Epoch: 976 [20480/90000 (23%)]	Loss: 9.8645	Cost: 6.16s
Train Epoch: 976 [40960/90000 (45%)]	Loss: 9.8484	Cost: 6.61s
Train Epoch: 976 [61440/90000 (68%)]	Loss: 9.5725	Cost: 5.90s
Train Epoch: 976 [81920/90000 (91%)]	Loss: 9.7927	Cost: 6.55s
Train Epoch: 976 	Average Loss: 10.4669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6633

Learning rate: 0.00019533593943255054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 977 [0/90000 (0%)]	Loss: 19.1264	Cost: 21.27s
Train Epoch: 977 [20480/90000 (23%)]	Loss: 9.6329	Cost: 5.99s
Train Epoch: 977 [40960/90000 (45%)]	Loss: 9.8964	Cost: 6.96s
Train Epoch: 977 [61440/90000 (68%)]	Loss: 9.7307	Cost: 5.85s
Train Epoch: 977 [81920/90000 (91%)]	Loss: 9.9988	Cost: 6.13s
Train Epoch: 977 	Average Loss: 10.4632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5377

Learning rate: 0.00019532645222392127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 978 [0/90000 (0%)]	Loss: 19.4861	Cost: 21.65s
Train Epoch: 978 [20480/90000 (23%)]	Loss: 9.4704	Cost: 5.98s
Train Epoch: 978 [40960/90000 (45%)]	Loss: 9.6991	Cost: 6.69s
Train Epoch: 978 [61440/90000 (68%)]	Loss: 9.5983	Cost: 5.93s
Train Epoch: 978 [81920/90000 (91%)]	Loss: 9.7480	Cost: 6.34s
Train Epoch: 978 	Average Loss: 10.4431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5414

Learning rate: 0.00019531695560694832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 979 [0/90000 (0%)]	Loss: 18.9948	Cost: 21.25s
Train Epoch: 979 [20480/90000 (23%)]	Loss: 9.7561	Cost: 6.02s
Train Epoch: 979 [40960/90000 (45%)]	Loss: 9.8764	Cost: 6.61s
Train Epoch: 979 [61440/90000 (68%)]	Loss: 9.6654	Cost: 5.98s
Train Epoch: 979 [81920/90000 (91%)]	Loss: 9.7861	Cost: 6.02s
Train Epoch: 979 	Average Loss: 10.4293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5423

Learning rate: 0.00019530744958256901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 980 [0/90000 (0%)]	Loss: 19.1759	Cost: 20.00s
Train Epoch: 980 [20480/90000 (23%)]	Loss: 9.6842	Cost: 6.20s
Train Epoch: 980 [40960/90000 (45%)]	Loss: 9.8038	Cost: 6.04s
Train Epoch: 980 [61440/90000 (68%)]	Loss: 9.6494	Cost: 5.96s
Train Epoch: 980 [81920/90000 (91%)]	Loss: 9.8188	Cost: 6.05s
Train Epoch: 980 	Average Loss: 10.4917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5431

Learning rate: 0.00019529793415172156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 981 [0/90000 (0%)]	Loss: 19.2370	Cost: 21.79s
Train Epoch: 981 [20480/90000 (23%)]	Loss: 9.7676	Cost: 6.02s
Train Epoch: 981 [40960/90000 (45%)]	Loss: 10.1198	Cost: 5.96s
Train Epoch: 981 [61440/90000 (68%)]	Loss: 10.1858	Cost: 5.96s
Train Epoch: 981 [81920/90000 (91%)]	Loss: 9.8910	Cost: 5.66s
Train Epoch: 981 	Average Loss: 10.6411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5914

Learning rate: 0.00019528840931534505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 982 [0/90000 (0%)]	Loss: 19.0001	Cost: 21.38s
Train Epoch: 982 [20480/90000 (23%)]	Loss: 9.8620	Cost: 5.99s
Train Epoch: 982 [40960/90000 (45%)]	Loss: 9.8386	Cost: 6.33s
Train Epoch: 982 [61440/90000 (68%)]	Loss: 9.7688	Cost: 5.85s
Train Epoch: 982 [81920/90000 (91%)]	Loss: 9.5736	Cost: 5.76s
Train Epoch: 982 	Average Loss: 10.4727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5565

Learning rate: 0.0001952788750743796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 983 [0/90000 (0%)]	Loss: 19.1018	Cost: 20.68s
Train Epoch: 983 [20480/90000 (23%)]	Loss: 9.7316	Cost: 5.98s
Train Epoch: 983 [40960/90000 (45%)]	Loss: 9.6647	Cost: 6.11s
Train Epoch: 983 [61440/90000 (68%)]	Loss: 9.6337	Cost: 5.84s
Train Epoch: 983 [81920/90000 (91%)]	Loss: 9.7640	Cost: 5.68s
Train Epoch: 983 	Average Loss: 10.4464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5898

Learning rate: 0.0001952693314297662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 984 [0/90000 (0%)]	Loss: 19.3835	Cost: 20.84s
Train Epoch: 984 [20480/90000 (23%)]	Loss: 9.8301	Cost: 5.95s
Train Epoch: 984 [40960/90000 (45%)]	Loss: 10.4830	Cost: 6.62s
Train Epoch: 984 [61440/90000 (68%)]	Loss: 10.3956	Cost: 5.90s
Train Epoch: 984 [81920/90000 (91%)]	Loss: 10.3062	Cost: 6.19s
Train Epoch: 984 	Average Loss: 10.8458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4995

Learning rate: 0.00019525977838244672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 985 [0/90000 (0%)]	Loss: 19.0838	Cost: 19.67s
Train Epoch: 985 [20480/90000 (23%)]	Loss: 10.2855	Cost: 6.06s
Train Epoch: 985 [40960/90000 (45%)]	Loss: 10.1784	Cost: 6.00s
Train Epoch: 985 [61440/90000 (68%)]	Loss: 9.8599	Cost: 5.85s
Train Epoch: 985 [81920/90000 (91%)]	Loss: 9.9117	Cost: 5.66s
Train Epoch: 985 	Average Loss: 10.7352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4534

Learning rate: 0.00019525021593336405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 986 [0/90000 (0%)]	Loss: 19.2334	Cost: 19.41s
Train Epoch: 986 [20480/90000 (23%)]	Loss: 9.8076	Cost: 6.10s
Train Epoch: 986 [40960/90000 (45%)]	Loss: 9.9427	Cost: 6.01s
Train Epoch: 986 [61440/90000 (68%)]	Loss: 9.7183	Cost: 5.83s
Train Epoch: 986 [81920/90000 (91%)]	Loss: 9.9356	Cost: 5.74s
Train Epoch: 986 	Average Loss: 10.4220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5145

Learning rate: 0.00019524064408346195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 987 [0/90000 (0%)]	Loss: 19.1001	Cost: 20.32s
Train Epoch: 987 [20480/90000 (23%)]	Loss: 9.6616	Cost: 6.05s
Train Epoch: 987 [40960/90000 (45%)]	Loss: 9.9681	Cost: 5.99s
Train Epoch: 987 [61440/90000 (68%)]	Loss: 9.7191	Cost: 5.83s
Train Epoch: 987 [81920/90000 (91%)]	Loss: 9.8958	Cost: 5.64s
Train Epoch: 987 	Average Loss: 10.4126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5663

Learning rate: 0.00019523106283368514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 988 [0/90000 (0%)]	Loss: 19.1919	Cost: 19.81s
Train Epoch: 988 [20480/90000 (23%)]	Loss: 9.5685	Cost: 6.00s
Train Epoch: 988 [40960/90000 (45%)]	Loss: 9.5990	Cost: 6.02s
Train Epoch: 988 [61440/90000 (68%)]	Loss: 9.4106	Cost: 5.85s
Train Epoch: 988 [81920/90000 (91%)]	Loss: 9.5957	Cost: 5.65s
Train Epoch: 988 	Average Loss: 10.2880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5634

Learning rate: 0.00019522147218497925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 989 [0/90000 (0%)]	Loss: 19.1373	Cost: 21.00s
Train Epoch: 989 [20480/90000 (23%)]	Loss: 9.7428	Cost: 6.00s
Train Epoch: 989 [40960/90000 (45%)]	Loss: 9.7977	Cost: 6.56s
Train Epoch: 989 [61440/90000 (68%)]	Loss: 9.5821	Cost: 5.81s
Train Epoch: 989 [81920/90000 (91%)]	Loss: 9.8020	Cost: 5.64s
Train Epoch: 989 	Average Loss: 10.2808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5974

Learning rate: 0.0001952118721382908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 990 [0/90000 (0%)]	Loss: 19.1974	Cost: 20.95s
Train Epoch: 990 [20480/90000 (23%)]	Loss: 9.4120	Cost: 6.02s
Train Epoch: 990 [40960/90000 (45%)]	Loss: 9.7549	Cost: 6.33s
Train Epoch: 990 [61440/90000 (68%)]	Loss: 9.5920	Cost: 5.80s
Train Epoch: 990 [81920/90000 (91%)]	Loss: 9.8763	Cost: 6.07s
Train Epoch: 990 	Average Loss: 10.2772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6149

Learning rate: 0.0001952022626945673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 991 [0/90000 (0%)]	Loss: 19.3012	Cost: 20.82s
Train Epoch: 991 [20480/90000 (23%)]	Loss: 9.5490	Cost: 6.17s
Train Epoch: 991 [40960/90000 (45%)]	Loss: 9.7245	Cost: 6.06s
Train Epoch: 991 [61440/90000 (68%)]	Loss: 9.6015	Cost: 5.90s
Train Epoch: 991 [81920/90000 (91%)]	Loss: 9.7925	Cost: 5.76s
Train Epoch: 991 	Average Loss: 10.3281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6762

Learning rate: 0.00019519264385475717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 992 [0/90000 (0%)]	Loss: 19.1004	Cost: 20.68s
Train Epoch: 992 [20480/90000 (23%)]	Loss: 9.4685	Cost: 6.70s
Train Epoch: 992 [40960/90000 (45%)]	Loss: 9.5930	Cost: 6.98s
Train Epoch: 992 [61440/90000 (68%)]	Loss: 9.5413	Cost: 6.37s
Train Epoch: 992 [81920/90000 (91%)]	Loss: 9.6898	Cost: 5.68s
Train Epoch: 992 	Average Loss: 10.2711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6524

Learning rate: 0.00019518301561980976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 993 [0/90000 (0%)]	Loss: 19.2346	Cost: 21.21s
Train Epoch: 993 [20480/90000 (23%)]	Loss: 9.3687	Cost: 5.99s
Train Epoch: 993 [40960/90000 (45%)]	Loss: 9.6297	Cost: 7.83s
Train Epoch: 993 [61440/90000 (68%)]	Loss: 9.3687	Cost: 5.86s
Train Epoch: 993 [81920/90000 (91%)]	Loss: 9.7372	Cost: 6.05s
Train Epoch: 993 	Average Loss: 10.1895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7380

Learning rate: 0.00019517337799067536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 994 [0/90000 (0%)]	Loss: 19.1221	Cost: 19.49s
Train Epoch: 994 [20480/90000 (23%)]	Loss: 9.6127	Cost: 6.10s
Train Epoch: 994 [40960/90000 (45%)]	Loss: 9.5851	Cost: 7.21s
Train Epoch: 994 [61440/90000 (68%)]	Loss: 9.6665	Cost: 5.81s
Train Epoch: 994 [81920/90000 (91%)]	Loss: 9.8088	Cost: 5.98s
Train Epoch: 994 	Average Loss: 10.3409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5850

Learning rate: 0.00019516373096830513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 995 [0/90000 (0%)]	Loss: 19.1266	Cost: 20.41s
Train Epoch: 995 [20480/90000 (23%)]	Loss: 9.4663	Cost: 5.97s
Train Epoch: 995 [40960/90000 (45%)]	Loss: 9.5975	Cost: 6.08s
Train Epoch: 995 [61440/90000 (68%)]	Loss: 9.5364	Cost: 5.89s
Train Epoch: 995 [81920/90000 (91%)]	Loss: 9.5543	Cost: 5.72s
Train Epoch: 995 	Average Loss: 10.2303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6059

Learning rate: 0.00019515407455365116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 996 [0/90000 (0%)]	Loss: 19.2789	Cost: 20.11s
Train Epoch: 996 [20480/90000 (23%)]	Loss: 9.2428	Cost: 6.63s
Train Epoch: 996 [40960/90000 (45%)]	Loss: 9.4937	Cost: 6.05s
Train Epoch: 996 [61440/90000 (68%)]	Loss: 9.3076	Cost: 5.86s
Train Epoch: 996 [81920/90000 (91%)]	Loss: 9.5199	Cost: 5.66s
Train Epoch: 996 	Average Loss: 10.1387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7978

Learning rate: 0.00019514440874766656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 997 [0/90000 (0%)]	Loss: 19.1669	Cost: 20.18s
Train Epoch: 997 [20480/90000 (23%)]	Loss: 9.2666	Cost: 6.06s
Train Epoch: 997 [40960/90000 (45%)]	Loss: 9.8304	Cost: 6.08s
Train Epoch: 997 [61440/90000 (68%)]	Loss: 9.5875	Cost: 5.91s
Train Epoch: 997 [81920/90000 (91%)]	Loss: 9.6131	Cost: 5.71s
Train Epoch: 997 	Average Loss: 10.2028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6580

Learning rate: 0.00019513473355130528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 998 [0/90000 (0%)]	Loss: 19.1828	Cost: 20.53s
Train Epoch: 998 [20480/90000 (23%)]	Loss: 9.3529	Cost: 5.97s
Train Epoch: 998 [40960/90000 (45%)]	Loss: 9.7502	Cost: 6.04s
Train Epoch: 998 [61440/90000 (68%)]	Loss: 9.5218	Cost: 5.84s
Train Epoch: 998 [81920/90000 (91%)]	Loss: 9.6572	Cost: 5.66s
Train Epoch: 998 	Average Loss: 10.2335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7595

Learning rate: 0.00019512504896552222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 999 [0/90000 (0%)]	Loss: 19.3444	Cost: 21.11s
Train Epoch: 999 [20480/90000 (23%)]	Loss: 9.3674	Cost: 5.98s
Train Epoch: 999 [40960/90000 (45%)]	Loss: 9.6856	Cost: 6.33s
Train Epoch: 999 [61440/90000 (68%)]	Loss: 9.3025	Cost: 5.88s
Train Epoch: 999 [81920/90000 (91%)]	Loss: 9.4770	Cost: 6.06s
Train Epoch: 999 	Average Loss: 10.1850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7350

Learning rate: 0.00019511535499127324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1000 [0/90000 (0%)]	Loss: 19.3424	Cost: 20.03s
Train Epoch: 1000 [20480/90000 (23%)]	Loss: 9.4234	Cost: 6.16s
Train Epoch: 1000 [40960/90000 (45%)]	Loss: 9.5178	Cost: 6.79s
Train Epoch: 1000 [61440/90000 (68%)]	Loss: 9.3765	Cost: 5.90s
Train Epoch: 1000 [81920/90000 (91%)]	Loss: 9.3482	Cost: 5.69s
Train Epoch: 1000 	Average Loss: 10.1031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7395

Learning rate: 0.00019510565162951505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1001 [0/90000 (0%)]	Loss: 19.2523	Cost: 20.14s
Train Epoch: 1001 [20480/90000 (23%)]	Loss: 9.3157	Cost: 5.99s
Train Epoch: 1001 [40960/90000 (45%)]	Loss: 9.5967	Cost: 6.00s
Train Epoch: 1001 [61440/90000 (68%)]	Loss: 9.0901	Cost: 5.95s
Train Epoch: 1001 [81920/90000 (91%)]	Loss: 9.5118	Cost: 5.70s
Train Epoch: 1001 	Average Loss: 10.0801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7462

Learning rate: 0.00019509593888120534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1002 [0/90000 (0%)]	Loss: 19.3917	Cost: 20.70s
Train Epoch: 1002 [20480/90000 (23%)]	Loss: 9.4091	Cost: 6.00s
Train Epoch: 1002 [40960/90000 (45%)]	Loss: 9.6853	Cost: 6.35s
Train Epoch: 1002 [61440/90000 (68%)]	Loss: 9.6232	Cost: 5.83s
Train Epoch: 1002 [81920/90000 (91%)]	Loss: 9.5542	Cost: 5.88s
Train Epoch: 1002 	Average Loss: 10.2821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6926

Learning rate: 0.00019508621674730277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1003 [0/90000 (0%)]	Loss: 19.2960	Cost: 20.65s
Train Epoch: 1003 [20480/90000 (23%)]	Loss: 9.4354	Cost: 5.99s
Train Epoch: 1003 [40960/90000 (45%)]	Loss: 9.5474	Cost: 6.38s
Train Epoch: 1003 [61440/90000 (68%)]	Loss: 9.3794	Cost: 5.84s
Train Epoch: 1003 [81920/90000 (91%)]	Loss: 9.6158	Cost: 5.91s
Train Epoch: 1003 	Average Loss: 10.2353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6775

Learning rate: 0.00019507648522876684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1004 [0/90000 (0%)]	Loss: 19.4377	Cost: 20.37s
Train Epoch: 1004 [20480/90000 (23%)]	Loss: 9.5243	Cost: 6.03s
Train Epoch: 1004 [40960/90000 (45%)]	Loss: 9.5902	Cost: 6.27s
Train Epoch: 1004 [61440/90000 (68%)]	Loss: 9.3684	Cost: 5.80s
Train Epoch: 1004 [81920/90000 (91%)]	Loss: 9.5965	Cost: 6.10s
Train Epoch: 1004 	Average Loss: 10.1999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7055

Learning rate: 0.00019506674432655802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1005 [0/90000 (0%)]	Loss: 19.4564	Cost: 20.51s
Train Epoch: 1005 [20480/90000 (23%)]	Loss: 9.4129	Cost: 5.99s
Train Epoch: 1005 [40960/90000 (45%)]	Loss: 9.5368	Cost: 6.66s
Train Epoch: 1005 [61440/90000 (68%)]	Loss: 9.4960	Cost: 5.81s
Train Epoch: 1005 [81920/90000 (91%)]	Loss: 9.6643	Cost: 6.15s
Train Epoch: 1005 	Average Loss: 10.1887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7931

Learning rate: 0.0001950569940416377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1006 [0/90000 (0%)]	Loss: 19.3612	Cost: 21.57s
Train Epoch: 1006 [20480/90000 (23%)]	Loss: 9.2974	Cost: 6.05s
Train Epoch: 1006 [40960/90000 (45%)]	Loss: 9.3543	Cost: 6.96s
Train Epoch: 1006 [61440/90000 (68%)]	Loss: 9.4430	Cost: 5.82s
Train Epoch: 1006 [81920/90000 (91%)]	Loss: 9.5225	Cost: 6.04s
Train Epoch: 1006 	Average Loss: 10.1161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8290

Learning rate: 0.00019504723437496817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1007 [0/90000 (0%)]	Loss: 19.2935	Cost: 19.92s
Train Epoch: 1007 [20480/90000 (23%)]	Loss: 9.2643	Cost: 6.12s
Train Epoch: 1007 [40960/90000 (45%)]	Loss: 9.3424	Cost: 6.09s
Train Epoch: 1007 [61440/90000 (68%)]	Loss: 9.1779	Cost: 5.84s
Train Epoch: 1007 [81920/90000 (91%)]	Loss: 9.3597	Cost: 5.72s
Train Epoch: 1007 	Average Loss: 10.0644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7694

Learning rate: 0.0001950374653275127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1008 [0/90000 (0%)]	Loss: 19.3951	Cost: 20.37s
Train Epoch: 1008 [20480/90000 (23%)]	Loss: 9.3075	Cost: 6.02s
Train Epoch: 1008 [40960/90000 (45%)]	Loss: 9.4615	Cost: 6.04s
Train Epoch: 1008 [61440/90000 (68%)]	Loss: 9.2360	Cost: 5.83s
Train Epoch: 1008 [81920/90000 (91%)]	Loss: 9.3530	Cost: 5.67s
Train Epoch: 1008 	Average Loss: 10.0331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7652

Learning rate: 0.00019502768690023544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1009 [0/90000 (0%)]	Loss: 19.3766	Cost: 20.50s
Train Epoch: 1009 [20480/90000 (23%)]	Loss: 9.1045	Cost: 5.93s
Train Epoch: 1009 [40960/90000 (45%)]	Loss: 9.4551	Cost: 5.99s
Train Epoch: 1009 [61440/90000 (68%)]	Loss: 9.2441	Cost: 5.78s
Train Epoch: 1009 [81920/90000 (91%)]	Loss: 9.5337	Cost: 6.08s
Train Epoch: 1009 	Average Loss: 10.0443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7830

Learning rate: 0.0001950178990941015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1010 [0/90000 (0%)]	Loss: 19.5501	Cost: 23.01s
Train Epoch: 1010 [20480/90000 (23%)]	Loss: 9.4356	Cost: 5.89s
Train Epoch: 1010 [40960/90000 (45%)]	Loss: 9.5214	Cost: 6.03s
Train Epoch: 1010 [61440/90000 (68%)]	Loss: 9.3345	Cost: 5.79s
Train Epoch: 1010 [81920/90000 (91%)]	Loss: 9.4402	Cost: 5.63s
Train Epoch: 1010 	Average Loss: 10.1218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7832

Learning rate: 0.00019500810191007685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1011 [0/90000 (0%)]	Loss: 19.3058	Cost: 19.99s
Train Epoch: 1011 [20480/90000 (23%)]	Loss: 9.3478	Cost: 5.98s
Train Epoch: 1011 [40960/90000 (45%)]	Loss: 9.3493	Cost: 5.99s
Train Epoch: 1011 [61440/90000 (68%)]	Loss: 9.3611	Cost: 5.81s
Train Epoch: 1011 [81920/90000 (91%)]	Loss: 9.2655	Cost: 5.65s
Train Epoch: 1011 	Average Loss: 10.0568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8129

Learning rate: 0.0001949982953491285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1012 [0/90000 (0%)]	Loss: 19.5759	Cost: 20.95s
Train Epoch: 1012 [20480/90000 (23%)]	Loss: 9.1137	Cost: 5.96s
Train Epoch: 1012 [40960/90000 (45%)]	Loss: 9.3162	Cost: 5.99s
Train Epoch: 1012 [61440/90000 (68%)]	Loss: 8.9925	Cost: 5.94s
Train Epoch: 1012 [81920/90000 (91%)]	Loss: 9.4105	Cost: 5.66s
Train Epoch: 1012 	Average Loss: 9.9568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7598

Learning rate: 0.0001949884794122243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1013 [0/90000 (0%)]	Loss: 19.3473	Cost: 20.33s
Train Epoch: 1013 [20480/90000 (23%)]	Loss: 9.0695	Cost: 6.71s
Train Epoch: 1013 [40960/90000 (45%)]	Loss: 9.5169	Cost: 6.09s
Train Epoch: 1013 [61440/90000 (68%)]	Loss: 9.4322	Cost: 5.83s
Train Epoch: 1013 [81920/90000 (91%)]	Loss: 9.3301	Cost: 5.66s
Train Epoch: 1013 	Average Loss: 10.0868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7341

Learning rate: 0.000194978654100333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1014 [0/90000 (0%)]	Loss: 19.3851	Cost: 20.11s
Train Epoch: 1014 [20480/90000 (23%)]	Loss: 9.3437	Cost: 6.02s
Train Epoch: 1014 [40960/90000 (45%)]	Loss: 9.5117	Cost: 6.03s
Train Epoch: 1014 [61440/90000 (68%)]	Loss: 9.3800	Cost: 5.80s
Train Epoch: 1014 [81920/90000 (91%)]	Loss: 9.3441	Cost: 5.68s
Train Epoch: 1014 	Average Loss: 10.0608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8117

Learning rate: 0.00019496881941442437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1015 [0/90000 (0%)]	Loss: 19.3048	Cost: 20.49s
Train Epoch: 1015 [20480/90000 (23%)]	Loss: 9.1651	Cost: 6.65s
Train Epoch: 1015 [40960/90000 (45%)]	Loss: 9.3099	Cost: 6.25s
Train Epoch: 1015 [61440/90000 (68%)]	Loss: 9.1093	Cost: 6.44s
Train Epoch: 1015 [81920/90000 (91%)]	Loss: 9.2718	Cost: 6.05s
Train Epoch: 1015 	Average Loss: 9.9770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9142

Learning rate: 0.00019495897535546904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1016 [0/90000 (0%)]	Loss: 19.1299	Cost: 19.84s
Train Epoch: 1016 [20480/90000 (23%)]	Loss: 9.3754	Cost: 5.93s
Train Epoch: 1016 [40960/90000 (45%)]	Loss: 9.2817	Cost: 6.01s
Train Epoch: 1016 [61440/90000 (68%)]	Loss: 9.1800	Cost: 5.81s
Train Epoch: 1016 [81920/90000 (91%)]	Loss: 9.2661	Cost: 5.71s
Train Epoch: 1016 	Average Loss: 9.9793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8677

Learning rate: 0.00019494912192443854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1017 [0/90000 (0%)]	Loss: 19.4912	Cost: 21.67s
Train Epoch: 1017 [20480/90000 (23%)]	Loss: 9.0550	Cost: 5.93s
Train Epoch: 1017 [40960/90000 (45%)]	Loss: 9.1426	Cost: 6.42s
Train Epoch: 1017 [61440/90000 (68%)]	Loss: 9.0665	Cost: 5.82s
Train Epoch: 1017 [81920/90000 (91%)]	Loss: 9.0235	Cost: 5.75s
Train Epoch: 1017 	Average Loss: 9.9268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8466

Learning rate: 0.00019493925912230544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1018 [0/90000 (0%)]	Loss: 19.2810	Cost: 19.73s
Train Epoch: 1018 [20480/90000 (23%)]	Loss: 9.1557	Cost: 5.98s
Train Epoch: 1018 [40960/90000 (45%)]	Loss: 9.4530	Cost: 5.98s
Train Epoch: 1018 [61440/90000 (68%)]	Loss: 9.5410	Cost: 5.85s
Train Epoch: 1018 [81920/90000 (91%)]	Loss: 9.5041	Cost: 5.66s
Train Epoch: 1018 	Average Loss: 10.0926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8696

Learning rate: 0.00019492938695004312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1019 [0/90000 (0%)]	Loss: 19.4573	Cost: 20.61s
Train Epoch: 1019 [20480/90000 (23%)]	Loss: 9.7546	Cost: 5.83s
Train Epoch: 1019 [40960/90000 (45%)]	Loss: 9.9437	Cost: 6.15s
Train Epoch: 1019 [61440/90000 (68%)]	Loss: 9.5507	Cost: 5.63s
Train Epoch: 1019 [81920/90000 (91%)]	Loss: 9.4958	Cost: 5.49s
Train Epoch: 1019 	Average Loss: 10.4127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8213

Learning rate: 0.00019491950540862592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1020 [0/90000 (0%)]	Loss: 19.1461	Cost: 20.33s
Train Epoch: 1020 [20480/90000 (23%)]	Loss: 9.4614	Cost: 6.03s
Train Epoch: 1020 [40960/90000 (45%)]	Loss: 9.4184	Cost: 5.99s
Train Epoch: 1020 [61440/90000 (68%)]	Loss: 9.2550	Cost: 5.81s
Train Epoch: 1020 [81920/90000 (91%)]	Loss: 9.4610	Cost: 5.66s
Train Epoch: 1020 	Average Loss: 10.1460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9003

Learning rate: 0.0001949096144990291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1021 [0/90000 (0%)]	Loss: 19.5593	Cost: 20.82s
Train Epoch: 1021 [20480/90000 (23%)]	Loss: 9.1006	Cost: 6.06s
Train Epoch: 1021 [40960/90000 (45%)]	Loss: 9.4697	Cost: 6.06s
Train Epoch: 1021 [61440/90000 (68%)]	Loss: 9.2771	Cost: 5.93s
Train Epoch: 1021 [81920/90000 (91%)]	Loss: 9.4992	Cost: 5.72s
Train Epoch: 1021 	Average Loss: 10.0603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9470

Learning rate: 0.0001948997142222289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1022 [0/90000 (0%)]	Loss: 19.2550	Cost: 20.94s
Train Epoch: 1022 [20480/90000 (23%)]	Loss: 9.2298	Cost: 5.92s
Train Epoch: 1022 [40960/90000 (45%)]	Loss: 9.2223	Cost: 6.57s
Train Epoch: 1022 [61440/90000 (68%)]	Loss: 9.0676	Cost: 5.82s
Train Epoch: 1022 [81920/90000 (91%)]	Loss: 9.2121	Cost: 5.94s
Train Epoch: 1022 	Average Loss: 9.9645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7829

Learning rate: 0.00019488980457920237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1023 [0/90000 (0%)]	Loss: 19.2930	Cost: 20.54s
Train Epoch: 1023 [20480/90000 (23%)]	Loss: 9.0270	Cost: 5.76s
Train Epoch: 1023 [40960/90000 (45%)]	Loss: 9.2876	Cost: 6.19s
Train Epoch: 1023 [61440/90000 (68%)]	Loss: 8.9939	Cost: 5.74s
Train Epoch: 1023 [81920/90000 (91%)]	Loss: 9.2700	Cost: 5.47s
Train Epoch: 1023 	Average Loss: 9.8761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9511

Learning rate: 0.00019487988557092759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1024 [0/90000 (0%)]	Loss: 19.4770	Cost: 20.36s
Train Epoch: 1024 [20480/90000 (23%)]	Loss: 9.2600	Cost: 6.09s
Train Epoch: 1024 [40960/90000 (45%)]	Loss: 9.2235	Cost: 6.52s
Train Epoch: 1024 [61440/90000 (68%)]	Loss: 9.0166	Cost: 5.81s
Train Epoch: 1024 [81920/90000 (91%)]	Loss: 9.3087	Cost: 5.92s
Train Epoch: 1024 	Average Loss: 9.9814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8638

Learning rate: 0.00019486995719838354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1025 [0/90000 (0%)]	Loss: 19.4405	Cost: 20.62s
Train Epoch: 1025 [20480/90000 (23%)]	Loss: 9.1830	Cost: 6.04s
Train Epoch: 1025 [40960/90000 (45%)]	Loss: 9.1608	Cost: 6.00s
Train Epoch: 1025 [61440/90000 (68%)]	Loss: 9.0878	Cost: 5.80s
Train Epoch: 1025 [81920/90000 (91%)]	Loss: 9.2106	Cost: 5.67s
Train Epoch: 1025 	Average Loss: 9.9525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9338

Learning rate: 0.00019486001946255008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1026 [0/90000 (0%)]	Loss: 19.3291	Cost: 20.09s
Train Epoch: 1026 [20480/90000 (23%)]	Loss: 9.2789	Cost: 6.10s
Train Epoch: 1026 [40960/90000 (45%)]	Loss: 9.4344	Cost: 6.01s
Train Epoch: 1026 [61440/90000 (68%)]	Loss: 9.0940	Cost: 5.96s
Train Epoch: 1026 [81920/90000 (91%)]	Loss: 9.2094	Cost: 5.68s
Train Epoch: 1026 	Average Loss: 9.9689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8388

Learning rate: 0.00019485007236440808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1027 [0/90000 (0%)]	Loss: 19.5752	Cost: 20.94s
Train Epoch: 1027 [20480/90000 (23%)]	Loss: 9.1755	Cost: 5.97s
Train Epoch: 1027 [40960/90000 (45%)]	Loss: 9.3769	Cost: 6.65s
Train Epoch: 1027 [61440/90000 (68%)]	Loss: 9.3323	Cost: 5.82s
Train Epoch: 1027 [81920/90000 (91%)]	Loss: 9.2037	Cost: 5.99s
Train Epoch: 1027 	Average Loss: 9.9987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9559

Learning rate: 0.00019484011590493924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1028 [0/90000 (0%)]	Loss: 19.3997	Cost: 22.21s
Train Epoch: 1028 [20480/90000 (23%)]	Loss: 9.1311	Cost: 5.94s
Train Epoch: 1028 [40960/90000 (45%)]	Loss: 9.4063	Cost: 6.20s
Train Epoch: 1028 [61440/90000 (68%)]	Loss: 9.1076	Cost: 5.85s
Train Epoch: 1028 [81920/90000 (91%)]	Loss: 9.2722	Cost: 5.87s
Train Epoch: 1028 	Average Loss: 10.0041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8751

Learning rate: 0.0001948301500851262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1029 [0/90000 (0%)]	Loss: 19.4957	Cost: 20.87s
Train Epoch: 1029 [20480/90000 (23%)]	Loss: 9.1981	Cost: 5.98s
Train Epoch: 1029 [40960/90000 (45%)]	Loss: 9.3517	Cost: 5.94s
Train Epoch: 1029 [61440/90000 (68%)]	Loss: 8.9847	Cost: 5.80s
Train Epoch: 1029 [81920/90000 (91%)]	Loss: 9.1646	Cost: 5.75s
Train Epoch: 1029 	Average Loss: 9.9063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9322

Learning rate: 0.00019482017490595255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1030 [0/90000 (0%)]	Loss: 19.6070	Cost: 23.01s
Train Epoch: 1030 [20480/90000 (23%)]	Loss: 9.0237	Cost: 6.26s
Train Epoch: 1030 [40960/90000 (45%)]	Loss: 9.3017	Cost: 6.10s
Train Epoch: 1030 [61440/90000 (68%)]	Loss: 9.0162	Cost: 5.80s
Train Epoch: 1030 [81920/90000 (91%)]	Loss: 9.3014	Cost: 5.88s
Train Epoch: 1030 	Average Loss: 9.9112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9031

Learning rate: 0.00019481019036840283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1031 [0/90000 (0%)]	Loss: 19.6385	Cost: 24.81s
Train Epoch: 1031 [20480/90000 (23%)]	Loss: 9.2077	Cost: 6.45s
Train Epoch: 1031 [40960/90000 (45%)]	Loss: 9.4040	Cost: 6.04s
Train Epoch: 1031 [61440/90000 (68%)]	Loss: 9.2722	Cost: 5.91s
Train Epoch: 1031 [81920/90000 (91%)]	Loss: 9.3146	Cost: 5.69s
Train Epoch: 1031 	Average Loss: 10.0491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8642

Learning rate: 0.0001948001964734625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1032 [0/90000 (0%)]	Loss: 19.5922	Cost: 23.82s
Train Epoch: 1032 [20480/90000 (23%)]	Loss: 9.3192	Cost: 6.25s
Train Epoch: 1032 [40960/90000 (45%)]	Loss: 9.4909	Cost: 6.09s
Train Epoch: 1032 [61440/90000 (68%)]	Loss: 9.2056	Cost: 5.92s
Train Epoch: 1032 [81920/90000 (91%)]	Loss: 9.3152	Cost: 6.17s
Train Epoch: 1032 	Average Loss: 10.0354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8036

Learning rate: 0.00019479019322211785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1033 [0/90000 (0%)]	Loss: 19.5347	Cost: 20.80s
Train Epoch: 1033 [20480/90000 (23%)]	Loss: 9.1541	Cost: 6.71s
Train Epoch: 1033 [40960/90000 (45%)]	Loss: 9.3067	Cost: 6.02s
Train Epoch: 1033 [61440/90000 (68%)]	Loss: 8.9873	Cost: 5.94s
Train Epoch: 1033 [81920/90000 (91%)]	Loss: 9.1294	Cost: 5.89s
Train Epoch: 1033 	Average Loss: 9.8908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8828

Learning rate: 0.00019478018061535622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1034 [0/90000 (0%)]	Loss: 19.4497	Cost: 20.73s
Train Epoch: 1034 [20480/90000 (23%)]	Loss: 8.9834	Cost: 6.12s
Train Epoch: 1034 [40960/90000 (45%)]	Loss: 9.2085	Cost: 6.51s
Train Epoch: 1034 [61440/90000 (68%)]	Loss: 9.2575	Cost: 6.20s
Train Epoch: 1034 [81920/90000 (91%)]	Loss: 9.4697	Cost: 6.49s
Train Epoch: 1034 	Average Loss: 9.9520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0620

Learning rate: 0.0001947701586541658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1035 [0/90000 (0%)]	Loss: 19.6675	Cost: 19.22s
Train Epoch: 1035 [20480/90000 (23%)]	Loss: 9.5219	Cost: 6.07s
Train Epoch: 1035 [40960/90000 (45%)]	Loss: 9.5484	Cost: 6.49s
Train Epoch: 1035 [61440/90000 (68%)]	Loss: 9.6192	Cost: 5.89s
Train Epoch: 1035 [81920/90000 (91%)]	Loss: 9.5371	Cost: 6.22s
Train Epoch: 1035 	Average Loss: 10.2738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8366

Learning rate: 0.00019476012733953566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1036 [0/90000 (0%)]	Loss: 19.8268	Cost: 20.93s
Train Epoch: 1036 [20480/90000 (23%)]	Loss: 9.2540	Cost: 6.06s
Train Epoch: 1036 [40960/90000 (45%)]	Loss: 9.3335	Cost: 6.19s
Train Epoch: 1036 [61440/90000 (68%)]	Loss: 9.1087	Cost: 6.02s
Train Epoch: 1036 [81920/90000 (91%)]	Loss: 9.3173	Cost: 7.14s
Train Epoch: 1036 	Average Loss: 10.0294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8715

Learning rate: 0.0001947500866724559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1037 [0/90000 (0%)]	Loss: 19.5233	Cost: 19.98s
Train Epoch: 1037 [20480/90000 (23%)]	Loss: 9.0173	Cost: 5.97s
Train Epoch: 1037 [40960/90000 (45%)]	Loss: 8.9275	Cost: 5.95s
Train Epoch: 1037 [61440/90000 (68%)]	Loss: 9.1010	Cost: 5.93s
Train Epoch: 1037 [81920/90000 (91%)]	Loss: 9.2939	Cost: 6.15s
Train Epoch: 1037 	Average Loss: 9.8223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9781

Learning rate: 0.00019474003665391753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1038 [0/90000 (0%)]	Loss: 19.6308	Cost: 20.52s
Train Epoch: 1038 [20480/90000 (23%)]	Loss: 8.9041	Cost: 6.02s
Train Epoch: 1038 [40960/90000 (45%)]	Loss: 9.2098	Cost: 6.06s
Train Epoch: 1038 [61440/90000 (68%)]	Loss: 8.9519	Cost: 5.85s
Train Epoch: 1038 [81920/90000 (91%)]	Loss: 9.0556	Cost: 6.40s
Train Epoch: 1038 	Average Loss: 9.7842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9537

Learning rate: 0.0001947299772849124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1039 [0/90000 (0%)]	Loss: 19.5452	Cost: 20.61s
Train Epoch: 1039 [20480/90000 (23%)]	Loss: 9.0546	Cost: 5.92s
Train Epoch: 1039 [40960/90000 (45%)]	Loss: 9.2401	Cost: 6.56s
Train Epoch: 1039 [61440/90000 (68%)]	Loss: 9.0070	Cost: 5.78s
Train Epoch: 1039 [81920/90000 (91%)]	Loss: 9.2292	Cost: 6.49s
Train Epoch: 1039 	Average Loss: 9.8210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9687

Learning rate: 0.00019471990856643334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1040 [0/90000 (0%)]	Loss: 19.5175	Cost: 19.47s
Train Epoch: 1040 [20480/90000 (23%)]	Loss: 8.8524	Cost: 6.02s
Train Epoch: 1040 [40960/90000 (45%)]	Loss: 9.1106	Cost: 6.03s
Train Epoch: 1040 [61440/90000 (68%)]	Loss: 8.9780	Cost: 5.80s
Train Epoch: 1040 [81920/90000 (91%)]	Loss: 9.0889	Cost: 5.80s
Train Epoch: 1040 	Average Loss: 9.7994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9035

Learning rate: 0.0001947098304994741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1041 [0/90000 (0%)]	Loss: 19.4863	Cost: 20.92s
Train Epoch: 1041 [20480/90000 (23%)]	Loss: 9.1456	Cost: 6.07s
Train Epoch: 1041 [40960/90000 (45%)]	Loss: 9.4112	Cost: 6.04s
Train Epoch: 1041 [61440/90000 (68%)]	Loss: 8.8895	Cost: 5.84s
Train Epoch: 1041 [81920/90000 (91%)]	Loss: 9.0913	Cost: 5.64s
Train Epoch: 1041 	Average Loss: 9.8528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9882

Learning rate: 0.0001946997430850293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1042 [0/90000 (0%)]	Loss: 19.4690	Cost: 21.64s
Train Epoch: 1042 [20480/90000 (23%)]	Loss: 8.9104	Cost: 6.02s
Train Epoch: 1042 [40960/90000 (45%)]	Loss: 9.2485	Cost: 6.50s
Train Epoch: 1042 [61440/90000 (68%)]	Loss: 9.2139	Cost: 5.86s
Train Epoch: 1042 [81920/90000 (91%)]	Loss: 9.1298	Cost: 6.14s
Train Epoch: 1042 	Average Loss: 9.8402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9145

Learning rate: 0.0001946896463240946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1043 [0/90000 (0%)]	Loss: 19.4464	Cost: 22.63s
Train Epoch: 1043 [20480/90000 (23%)]	Loss: 8.9723	Cost: 5.91s
Train Epoch: 1043 [40960/90000 (45%)]	Loss: 9.3035	Cost: 6.51s
Train Epoch: 1043 [61440/90000 (68%)]	Loss: 8.7708	Cost: 5.81s
Train Epoch: 1043 [81920/90000 (91%)]	Loss: 9.1259	Cost: 5.94s
Train Epoch: 1043 	Average Loss: 9.7868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0996

Learning rate: 0.00019467954021766648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1044 [0/90000 (0%)]	Loss: 19.4797	Cost: 21.40s
Train Epoch: 1044 [20480/90000 (23%)]	Loss: 8.6766	Cost: 6.66s
Train Epoch: 1044 [40960/90000 (45%)]	Loss: 9.2422	Cost: 6.67s
Train Epoch: 1044 [61440/90000 (68%)]	Loss: 9.0085	Cost: 6.11s
Train Epoch: 1044 [81920/90000 (91%)]	Loss: 8.9575	Cost: 5.91s
Train Epoch: 1044 	Average Loss: 9.6989
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0031

Learning rate: 0.00019466942476674236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1045 [0/90000 (0%)]	Loss: 19.4322	Cost: 22.47s
Train Epoch: 1045 [20480/90000 (23%)]	Loss: 8.8832	Cost: 5.93s
Train Epoch: 1045 [40960/90000 (45%)]	Loss: 9.0095	Cost: 6.52s
Train Epoch: 1045 [61440/90000 (68%)]	Loss: 9.0637	Cost: 5.84s
Train Epoch: 1045 [81920/90000 (91%)]	Loss: 8.8672	Cost: 6.49s
Train Epoch: 1045 	Average Loss: 9.7306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0042

Learning rate: 0.00019465929997232058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1046 [0/90000 (0%)]	Loss: 19.8125	Cost: 19.34s
Train Epoch: 1046 [20480/90000 (23%)]	Loss: 8.9667	Cost: 6.00s
Train Epoch: 1046 [40960/90000 (45%)]	Loss: 9.3171	Cost: 6.11s
Train Epoch: 1046 [61440/90000 (68%)]	Loss: 9.0519	Cost: 5.94s
Train Epoch: 1046 [81920/90000 (91%)]	Loss: 9.2171	Cost: 5.73s
Train Epoch: 1046 	Average Loss: 9.8469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0420

Learning rate: 0.00019464916583540045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1047 [0/90000 (0%)]	Loss: 19.6426	Cost: 21.26s
Train Epoch: 1047 [20480/90000 (23%)]	Loss: 8.7144	Cost: 6.01s
Train Epoch: 1047 [40960/90000 (45%)]	Loss: 9.2545	Cost: 6.12s
Train Epoch: 1047 [61440/90000 (68%)]	Loss: 8.8434	Cost: 5.88s
Train Epoch: 1047 [81920/90000 (91%)]	Loss: 9.2099	Cost: 5.73s
Train Epoch: 1047 	Average Loss: 9.7199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0395

Learning rate: 0.00019463902235698218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1048 [0/90000 (0%)]	Loss: 19.5656	Cost: 19.34s
Train Epoch: 1048 [20480/90000 (23%)]	Loss: 9.0247	Cost: 5.97s
Train Epoch: 1048 [40960/90000 (45%)]	Loss: 9.3605	Cost: 5.97s
Train Epoch: 1048 [61440/90000 (68%)]	Loss: 8.9036	Cost: 5.84s
Train Epoch: 1048 [81920/90000 (91%)]	Loss: 8.9967	Cost: 5.70s
Train Epoch: 1048 	Average Loss: 9.7685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1237

Learning rate: 0.00019462886953806687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1049 [0/90000 (0%)]	Loss: 19.6122	Cost: 19.50s
Train Epoch: 1049 [20480/90000 (23%)]	Loss: 8.8574	Cost: 6.16s
Train Epoch: 1049 [40960/90000 (45%)]	Loss: 9.0677	Cost: 6.09s
Train Epoch: 1049 [61440/90000 (68%)]	Loss: 8.8524	Cost: 5.84s
Train Epoch: 1049 [81920/90000 (91%)]	Loss: 9.1871	Cost: 5.70s
Train Epoch: 1049 	Average Loss: 9.7198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1758

Learning rate: 0.00019461870737965656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1050 [0/90000 (0%)]	Loss: 19.3364	Cost: 20.27s
Train Epoch: 1050 [20480/90000 (23%)]	Loss: 8.9575	Cost: 6.03s
Train Epoch: 1050 [40960/90000 (45%)]	Loss: 9.0846	Cost: 6.02s
Train Epoch: 1050 [61440/90000 (68%)]	Loss: 8.8193	Cost: 5.84s
Train Epoch: 1050 [81920/90000 (91%)]	Loss: 8.8197	Cost: 5.69s
Train Epoch: 1050 	Average Loss: 9.7742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0562

Learning rate: 0.00019460853588275422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1051 [0/90000 (0%)]	Loss: 19.7652	Cost: 19.62s
Train Epoch: 1051 [20480/90000 (23%)]	Loss: 8.8461	Cost: 5.75s
Train Epoch: 1051 [40960/90000 (45%)]	Loss: 9.0048	Cost: 6.25s
Train Epoch: 1051 [61440/90000 (68%)]	Loss: 8.6574	Cost: 5.58s
Train Epoch: 1051 [81920/90000 (91%)]	Loss: 9.3350	Cost: 5.70s
Train Epoch: 1051 	Average Loss: 9.6697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1337

Learning rate: 0.00019459835504836374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1052 [0/90000 (0%)]	Loss: 19.6926	Cost: 22.27s
Train Epoch: 1052 [20480/90000 (23%)]	Loss: 8.8672	Cost: 5.93s
Train Epoch: 1052 [40960/90000 (45%)]	Loss: 9.1322	Cost: 6.49s
Train Epoch: 1052 [61440/90000 (68%)]	Loss: 9.0807	Cost: 5.77s
Train Epoch: 1052 [81920/90000 (91%)]	Loss: 9.2218	Cost: 6.29s
Train Epoch: 1052 	Average Loss: 9.8736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0379

Learning rate: 0.0001945881648774899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1053 [0/90000 (0%)]	Loss: 19.6793	Cost: 19.86s
Train Epoch: 1053 [20480/90000 (23%)]	Loss: 9.3071	Cost: 6.05s
Train Epoch: 1053 [40960/90000 (45%)]	Loss: 9.3658	Cost: 6.05s
Train Epoch: 1053 [61440/90000 (68%)]	Loss: 9.2245	Cost: 5.81s
Train Epoch: 1053 [81920/90000 (91%)]	Loss: 9.3987	Cost: 5.66s
Train Epoch: 1053 	Average Loss: 10.0468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1430

Learning rate: 0.00019457796537113845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1054 [0/90000 (0%)]	Loss: 19.6630	Cost: 23.56s
Train Epoch: 1054 [20480/90000 (23%)]	Loss: 8.8769	Cost: 6.39s
Train Epoch: 1054 [40960/90000 (45%)]	Loss: 9.0946	Cost: 6.06s
Train Epoch: 1054 [61440/90000 (68%)]	Loss: 8.7353	Cost: 5.94s
Train Epoch: 1054 [81920/90000 (91%)]	Loss: 9.0080	Cost: 5.82s
Train Epoch: 1054 	Average Loss: 9.7467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0379

Learning rate: 0.00019456775653031605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1055 [0/90000 (0%)]	Loss: 19.4933	Cost: 20.29s
Train Epoch: 1055 [20480/90000 (23%)]	Loss: 8.7169	Cost: 6.14s
Train Epoch: 1055 [40960/90000 (45%)]	Loss: 9.2387	Cost: 6.04s
Train Epoch: 1055 [61440/90000 (68%)]	Loss: 8.9006	Cost: 5.94s
Train Epoch: 1055 [81920/90000 (91%)]	Loss: 9.1098	Cost: 5.99s
Train Epoch: 1055 	Average Loss: 9.7614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0547

Learning rate: 0.0001945575383560303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1056 [0/90000 (0%)]	Loss: 19.3912	Cost: 21.40s
Train Epoch: 1056 [20480/90000 (23%)]	Loss: 8.9871	Cost: 5.96s
Train Epoch: 1056 [40960/90000 (45%)]	Loss: 9.1414	Cost: 6.00s
Train Epoch: 1056 [61440/90000 (68%)]	Loss: 8.6003	Cost: 5.98s
Train Epoch: 1056 [81920/90000 (91%)]	Loss: 8.8573	Cost: 5.80s
Train Epoch: 1056 	Average Loss: 9.6678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1461

Learning rate: 0.00019454731084928963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1057 [0/90000 (0%)]	Loss: 19.9298	Cost: 20.80s
Train Epoch: 1057 [20480/90000 (23%)]	Loss: 8.6191	Cost: 6.05s
Train Epoch: 1057 [40960/90000 (45%)]	Loss: 8.9361	Cost: 6.56s
Train Epoch: 1057 [61440/90000 (68%)]	Loss: 8.5989	Cost: 5.90s
Train Epoch: 1057 [81920/90000 (91%)]	Loss: 8.9027	Cost: 5.85s
Train Epoch: 1057 	Average Loss: 9.5713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0650

Learning rate: 0.0001945370740111035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1058 [0/90000 (0%)]	Loss: 19.7644	Cost: 19.89s
Train Epoch: 1058 [20480/90000 (23%)]	Loss: 8.5896	Cost: 6.03s
Train Epoch: 1058 [40960/90000 (45%)]	Loss: 8.8945	Cost: 6.13s
Train Epoch: 1058 [61440/90000 (68%)]	Loss: 8.8769	Cost: 6.27s
Train Epoch: 1058 [81920/90000 (91%)]	Loss: 9.0331	Cost: 5.93s
Train Epoch: 1058 	Average Loss: 9.6362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1679

Learning rate: 0.00019452682784248221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1059 [0/90000 (0%)]	Loss: 19.5936	Cost: 22.38s
Train Epoch: 1059 [20480/90000 (23%)]	Loss: 9.1403	Cost: 5.98s
Train Epoch: 1059 [40960/90000 (45%)]	Loss: 9.5743	Cost: 6.05s
Train Epoch: 1059 [61440/90000 (68%)]	Loss: 9.1677	Cost: 6.12s
Train Epoch: 1059 [81920/90000 (91%)]	Loss: 9.3372	Cost: 6.14s
Train Epoch: 1059 	Average Loss: 10.0338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1164

Learning rate: 0.00019451657234443705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1060 [0/90000 (0%)]	Loss: 19.7269	Cost: 20.52s
Train Epoch: 1060 [20480/90000 (23%)]	Loss: 9.1929	Cost: 6.06s
Train Epoch: 1060 [40960/90000 (45%)]	Loss: 9.1202	Cost: 6.10s
Train Epoch: 1060 [61440/90000 (68%)]	Loss: 8.9038	Cost: 5.86s
Train Epoch: 1060 [81920/90000 (91%)]	Loss: 8.9130	Cost: 5.72s
Train Epoch: 1060 	Average Loss: 9.8256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0929

Learning rate: 0.00019450630751798018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1061 [0/90000 (0%)]	Loss: 19.4923	Cost: 20.99s
Train Epoch: 1061 [20480/90000 (23%)]	Loss: 8.6671	Cost: 5.98s
Train Epoch: 1061 [40960/90000 (45%)]	Loss: 8.8164	Cost: 6.40s
Train Epoch: 1061 [61440/90000 (68%)]	Loss: 8.6281	Cost: 5.81s
Train Epoch: 1061 [81920/90000 (91%)]	Loss: 8.8999	Cost: 5.70s
Train Epoch: 1061 	Average Loss: 9.5761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0584

Learning rate: 0.0001944960333641247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1062 [0/90000 (0%)]	Loss: 19.8968	Cost: 21.22s
Train Epoch: 1062 [20480/90000 (23%)]	Loss: 8.6470	Cost: 6.01s
Train Epoch: 1062 [40960/90000 (45%)]	Loss: 8.7231	Cost: 6.46s
Train Epoch: 1062 [61440/90000 (68%)]	Loss: 8.8491	Cost: 6.40s
Train Epoch: 1062 [81920/90000 (91%)]	Loss: 9.2110	Cost: 6.62s
Train Epoch: 1062 	Average Loss: 9.6076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1367

Learning rate: 0.0001944857498838846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1063 [0/90000 (0%)]	Loss: 19.7737	Cost: 20.66s
Train Epoch: 1063 [20480/90000 (23%)]	Loss: 8.8802	Cost: 6.05s
Train Epoch: 1063 [40960/90000 (45%)]	Loss: 8.9159	Cost: 6.33s
Train Epoch: 1063 [61440/90000 (68%)]	Loss: 8.7659	Cost: 5.77s
Train Epoch: 1063 [81920/90000 (91%)]	Loss: 8.8376	Cost: 6.01s
Train Epoch: 1063 	Average Loss: 9.5977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1576

Learning rate: 0.00019447545707827488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1064 [0/90000 (0%)]	Loss: 19.7963	Cost: 20.93s
Train Epoch: 1064 [20480/90000 (23%)]	Loss: 8.7082	Cost: 6.24s
Train Epoch: 1064 [40960/90000 (45%)]	Loss: 8.7954	Cost: 7.30s
Train Epoch: 1064 [61440/90000 (68%)]	Loss: 8.5073	Cost: 5.83s
Train Epoch: 1064 [81920/90000 (91%)]	Loss: 8.9443	Cost: 5.91s
Train Epoch: 1064 	Average Loss: 9.5459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1686

Learning rate: 0.00019446515494831135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1065 [0/90000 (0%)]	Loss: 19.6734	Cost: 21.73s
Train Epoch: 1065 [20480/90000 (23%)]	Loss: 8.7090	Cost: 5.96s
Train Epoch: 1065 [40960/90000 (45%)]	Loss: 8.6158	Cost: 6.78s
Train Epoch: 1065 [61440/90000 (68%)]	Loss: 8.6833	Cost: 5.82s
Train Epoch: 1065 [81920/90000 (91%)]	Loss: 8.6439	Cost: 5.86s
Train Epoch: 1065 	Average Loss: 9.4936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2356

Learning rate: 0.00019445484349501084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1066 [0/90000 (0%)]	Loss: 19.6913	Cost: 21.55s
Train Epoch: 1066 [20480/90000 (23%)]	Loss: 8.5035	Cost: 5.91s
Train Epoch: 1066 [40960/90000 (45%)]	Loss: 8.8624	Cost: 7.35s
Train Epoch: 1066 [61440/90000 (68%)]	Loss: 8.6261	Cost: 5.75s
Train Epoch: 1066 [81920/90000 (91%)]	Loss: 9.3463	Cost: 5.80s
Train Epoch: 1066 	Average Loss: 9.6098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1029

Learning rate: 0.00019444452271939096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1067 [0/90000 (0%)]	Loss: 19.4844	Cost: 20.76s
Train Epoch: 1067 [20480/90000 (23%)]	Loss: 8.9753	Cost: 6.01s
Train Epoch: 1067 [40960/90000 (45%)]	Loss: 9.2476	Cost: 7.09s
Train Epoch: 1067 [61440/90000 (68%)]	Loss: 8.8067	Cost: 6.04s
Train Epoch: 1067 [81920/90000 (91%)]	Loss: 8.9251	Cost: 5.68s
Train Epoch: 1067 	Average Loss: 9.7475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2566

Learning rate: 0.0001944341926224704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1068 [0/90000 (0%)]	Loss: 19.6915	Cost: 21.76s
Train Epoch: 1068 [20480/90000 (23%)]	Loss: 8.6985	Cost: 6.04s
Train Epoch: 1068 [40960/90000 (45%)]	Loss: 8.8291	Cost: 6.23s
Train Epoch: 1068 [61440/90000 (68%)]	Loss: 8.8224	Cost: 6.42s
Train Epoch: 1068 [81920/90000 (91%)]	Loss: 8.8723	Cost: 6.46s
Train Epoch: 1068 	Average Loss: 9.5580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2685

Learning rate: 0.00019442385320526872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1069 [0/90000 (0%)]	Loss: 19.5466	Cost: 22.29s
Train Epoch: 1069 [20480/90000 (23%)]	Loss: 8.5841	Cost: 5.95s
Train Epoch: 1069 [40960/90000 (45%)]	Loss: 8.7641	Cost: 6.47s
Train Epoch: 1069 [61440/90000 (68%)]	Loss: 8.8109	Cost: 5.84s
Train Epoch: 1069 [81920/90000 (91%)]	Loss: 8.9300	Cost: 5.80s
Train Epoch: 1069 	Average Loss: 9.5369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2920

Learning rate: 0.00019441350446880632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1070 [0/90000 (0%)]	Loss: 19.6938	Cost: 21.07s
Train Epoch: 1070 [20480/90000 (23%)]	Loss: 8.5657	Cost: 5.93s
Train Epoch: 1070 [40960/90000 (45%)]	Loss: 8.9302	Cost: 6.99s
Train Epoch: 1070 [61440/90000 (68%)]	Loss: 8.6707	Cost: 5.85s
Train Epoch: 1070 [81920/90000 (91%)]	Loss: 8.7443	Cost: 6.03s
Train Epoch: 1070 	Average Loss: 9.5420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3185

Learning rate: 0.00019440314641410464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1071 [0/90000 (0%)]	Loss: 19.6396	Cost: 20.64s
Train Epoch: 1071 [20480/90000 (23%)]	Loss: 8.4887	Cost: 5.96s
Train Epoch: 1071 [40960/90000 (45%)]	Loss: 8.6101	Cost: 6.13s
Train Epoch: 1071 [61440/90000 (68%)]	Loss: 8.4770	Cost: 5.82s
Train Epoch: 1071 [81920/90000 (91%)]	Loss: 8.6474	Cost: 5.68s
Train Epoch: 1071 	Average Loss: 9.4383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2141

Learning rate: 0.0001943927790421859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1072 [0/90000 (0%)]	Loss: 19.7306	Cost: 21.04s
Train Epoch: 1072 [20480/90000 (23%)]	Loss: 8.6261	Cost: 5.98s
Train Epoch: 1072 [40960/90000 (45%)]	Loss: 8.7822	Cost: 6.25s
Train Epoch: 1072 [61440/90000 (68%)]	Loss: 8.5049	Cost: 6.26s
Train Epoch: 1072 [81920/90000 (91%)]	Loss: 8.7081	Cost: 5.88s
Train Epoch: 1072 	Average Loss: 9.4826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2784

Learning rate: 0.00019438240235407337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1073 [0/90000 (0%)]	Loss: 19.7220	Cost: 22.70s
Train Epoch: 1073 [20480/90000 (23%)]	Loss: 8.4923	Cost: 5.92s
Train Epoch: 1073 [40960/90000 (45%)]	Loss: 8.6534	Cost: 6.05s
Train Epoch: 1073 [61440/90000 (68%)]	Loss: 8.6994	Cost: 5.86s
Train Epoch: 1073 [81920/90000 (91%)]	Loss: 8.7180	Cost: 6.34s
Train Epoch: 1073 	Average Loss: 9.3965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1714

Learning rate: 0.0001943720163507912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1074 [0/90000 (0%)]	Loss: 19.7008	Cost: 22.17s
Train Epoch: 1074 [20480/90000 (23%)]	Loss: 8.8057	Cost: 6.00s
Train Epoch: 1074 [40960/90000 (45%)]	Loss: 8.9038	Cost: 6.83s
Train Epoch: 1074 [61440/90000 (68%)]	Loss: 8.6196	Cost: 5.82s
Train Epoch: 1074 [81920/90000 (91%)]	Loss: 8.9340	Cost: 5.74s
Train Epoch: 1074 	Average Loss: 9.6022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2628

Learning rate: 0.0001943616210333644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1075 [0/90000 (0%)]	Loss: 19.8870	Cost: 21.12s
Train Epoch: 1075 [20480/90000 (23%)]	Loss: 8.9961	Cost: 6.15s
Train Epoch: 1075 [40960/90000 (45%)]	Loss: 8.9850	Cost: 6.42s
Train Epoch: 1075 [61440/90000 (68%)]	Loss: 8.7983	Cost: 5.84s
Train Epoch: 1075 [81920/90000 (91%)]	Loss: 8.7684	Cost: 5.70s
Train Epoch: 1075 	Average Loss: 9.7170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3007

Learning rate: 0.000194351216402819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1076 [0/90000 (0%)]	Loss: 19.8227	Cost: 22.19s
Train Epoch: 1076 [20480/90000 (23%)]	Loss: 8.5247	Cost: 5.90s
Train Epoch: 1076 [40960/90000 (45%)]	Loss: 8.8374	Cost: 6.12s
Train Epoch: 1076 [61440/90000 (68%)]	Loss: 8.4459	Cost: 5.81s
Train Epoch: 1076 [81920/90000 (91%)]	Loss: 8.7002	Cost: 5.70s
Train Epoch: 1076 	Average Loss: 9.4592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1510

Learning rate: 0.00019434080246018187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1077 [0/90000 (0%)]	Loss: 20.1112	Cost: 19.69s
Train Epoch: 1077 [20480/90000 (23%)]	Loss: 8.5675	Cost: 6.08s
Train Epoch: 1077 [40960/90000 (45%)]	Loss: 8.7996	Cost: 6.08s
Train Epoch: 1077 [61440/90000 (68%)]	Loss: 8.6100	Cost: 5.88s
Train Epoch: 1077 [81920/90000 (91%)]	Loss: 8.5327	Cost: 5.76s
Train Epoch: 1077 	Average Loss: 9.4590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1958

Learning rate: 0.00019433037920648082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1078 [0/90000 (0%)]	Loss: 19.7542	Cost: 21.18s
Train Epoch: 1078 [20480/90000 (23%)]	Loss: 8.5409	Cost: 6.10s
Train Epoch: 1078 [40960/90000 (45%)]	Loss: 8.6792	Cost: 5.98s
Train Epoch: 1078 [61440/90000 (68%)]	Loss: 8.6763	Cost: 6.02s
Train Epoch: 1078 [81920/90000 (91%)]	Loss: 8.5367	Cost: 5.84s
Train Epoch: 1078 	Average Loss: 9.3783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2433

Learning rate: 0.0001943199466427446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1079 [0/90000 (0%)]	Loss: 19.7898	Cost: 21.98s
Train Epoch: 1079 [20480/90000 (23%)]	Loss: 8.6174	Cost: 5.97s
Train Epoch: 1079 [40960/90000 (45%)]	Loss: 8.9562	Cost: 6.96s
Train Epoch: 1079 [61440/90000 (68%)]	Loss: 8.5801	Cost: 5.80s
Train Epoch: 1079 [81920/90000 (91%)]	Loss: 8.7211	Cost: 5.94s
Train Epoch: 1079 	Average Loss: 9.4009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3918

Learning rate: 0.0001943095047700028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1080 [0/90000 (0%)]	Loss: 20.0527	Cost: 19.09s
Train Epoch: 1080 [20480/90000 (23%)]	Loss: 8.5389	Cost: 6.23s
Train Epoch: 1080 [40960/90000 (45%)]	Loss: 8.3769	Cost: 6.65s
Train Epoch: 1080 [61440/90000 (68%)]	Loss: 8.3316	Cost: 5.82s
Train Epoch: 1080 [81920/90000 (91%)]	Loss: 8.4116	Cost: 6.06s
Train Epoch: 1080 	Average Loss: 9.3631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4077

Learning rate: 0.00019429905358928608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1081 [0/90000 (0%)]	Loss: 20.1124	Cost: 21.52s
Train Epoch: 1081 [20480/90000 (23%)]	Loss: 8.7403	Cost: 5.95s
Train Epoch: 1081 [40960/90000 (45%)]	Loss: 8.7311	Cost: 6.04s
Train Epoch: 1081 [61440/90000 (68%)]	Loss: 8.6009	Cost: 5.85s
Train Epoch: 1081 [81920/90000 (91%)]	Loss: 8.6056	Cost: 5.66s
Train Epoch: 1081 	Average Loss: 9.4483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3546

Learning rate: 0.0001942885931016259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1082 [0/90000 (0%)]	Loss: 19.7531	Cost: 20.35s
Train Epoch: 1082 [20480/90000 (23%)]	Loss: 8.6567	Cost: 6.05s
Train Epoch: 1082 [40960/90000 (45%)]	Loss: 8.7277	Cost: 6.51s
Train Epoch: 1082 [61440/90000 (68%)]	Loss: 8.4926	Cost: 5.84s
Train Epoch: 1082 [81920/90000 (91%)]	Loss: 8.6240	Cost: 5.78s
Train Epoch: 1082 	Average Loss: 9.3898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2997

Learning rate: 0.00019427812330805462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1083 [0/90000 (0%)]	Loss: 20.0764	Cost: 19.89s
Train Epoch: 1083 [20480/90000 (23%)]	Loss: 8.5969	Cost: 6.06s
Train Epoch: 1083 [40960/90000 (45%)]	Loss: 8.6917	Cost: 6.92s
Train Epoch: 1083 [61440/90000 (68%)]	Loss: 8.4511	Cost: 5.81s
Train Epoch: 1083 [81920/90000 (91%)]	Loss: 8.5551	Cost: 5.88s
Train Epoch: 1083 	Average Loss: 9.4306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4022

Learning rate: 0.00019426764420960564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1084 [0/90000 (0%)]	Loss: 19.9727	Cost: 20.75s
Train Epoch: 1084 [20480/90000 (23%)]	Loss: 10.2589	Cost: 6.69s
Train Epoch: 1084 [40960/90000 (45%)]	Loss: 10.2482	Cost: 6.69s
Train Epoch: 1084 [61440/90000 (68%)]	Loss: 9.7487	Cost: 6.46s
Train Epoch: 1084 [81920/90000 (91%)]	Loss: 9.4721	Cost: 6.36s
Train Epoch: 1084 	Average Loss: 10.7164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1430

Learning rate: 0.00019425715580731318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1085 [0/90000 (0%)]	Loss: 19.7858	Cost: 20.84s
Train Epoch: 1085 [20480/90000 (23%)]	Loss: 9.2801	Cost: 5.98s
Train Epoch: 1085 [40960/90000 (45%)]	Loss: 9.1994	Cost: 7.38s
Train Epoch: 1085 [61440/90000 (68%)]	Loss: 9.3437	Cost: 5.92s
Train Epoch: 1085 [81920/90000 (91%)]	Loss: 9.2137	Cost: 6.10s
Train Epoch: 1085 	Average Loss: 9.9711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2126

Learning rate: 0.00019424665810221242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1086 [0/90000 (0%)]	Loss: 19.9621	Cost: 19.63s
Train Epoch: 1086 [20480/90000 (23%)]	Loss: 9.7027	Cost: 6.02s
Train Epoch: 1086 [40960/90000 (45%)]	Loss: 9.8188	Cost: 6.46s
Train Epoch: 1086 [61440/90000 (68%)]	Loss: 9.3889	Cost: 5.87s
Train Epoch: 1086 [81920/90000 (91%)]	Loss: 9.3735	Cost: 5.71s
Train Epoch: 1086 	Average Loss: 10.3091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0286

Learning rate: 0.00019423615109533942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1087 [0/90000 (0%)]	Loss: 19.5515	Cost: 20.64s
Train Epoch: 1087 [20480/90000 (23%)]	Loss: 8.9467	Cost: 5.97s
Train Epoch: 1087 [40960/90000 (45%)]	Loss: 9.2902	Cost: 6.01s
Train Epoch: 1087 [61440/90000 (68%)]	Loss: 8.8286	Cost: 5.95s
Train Epoch: 1087 [81920/90000 (91%)]	Loss: 8.9323	Cost: 5.88s
Train Epoch: 1087 	Average Loss: 9.8093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1247

Learning rate: 0.00019422563478773116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1088 [0/90000 (0%)]	Loss: 19.6396	Cost: 20.31s
Train Epoch: 1088 [20480/90000 (23%)]	Loss: 9.0426	Cost: 6.05s
Train Epoch: 1088 [40960/90000 (45%)]	Loss: 8.8734	Cost: 6.88s
Train Epoch: 1088 [61440/90000 (68%)]	Loss: 8.7702	Cost: 5.82s
Train Epoch: 1088 [81920/90000 (91%)]	Loss: 8.8387	Cost: 5.69s
Train Epoch: 1088 	Average Loss: 9.6035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1592

Learning rate: 0.00019421510918042557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1089 [0/90000 (0%)]	Loss: 19.7919	Cost: 20.19s
Train Epoch: 1089 [20480/90000 (23%)]	Loss: 8.6699	Cost: 6.11s
Train Epoch: 1089 [40960/90000 (45%)]	Loss: 9.0517	Cost: 6.39s
Train Epoch: 1089 [61440/90000 (68%)]	Loss: 8.6816	Cost: 5.89s
Train Epoch: 1089 [81920/90000 (91%)]	Loss: 8.7848	Cost: 6.03s
Train Epoch: 1089 	Average Loss: 9.5955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2651

Learning rate: 0.0001942045742744615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1090 [0/90000 (0%)]	Loss: 19.8628	Cost: 20.54s
Train Epoch: 1090 [20480/90000 (23%)]	Loss: 8.7607	Cost: 6.04s
Train Epoch: 1090 [40960/90000 (45%)]	Loss: 8.8077	Cost: 7.86s
Train Epoch: 1090 [61440/90000 (68%)]	Loss: 8.5774	Cost: 6.03s
Train Epoch: 1090 [81920/90000 (91%)]	Loss: 8.4852	Cost: 6.51s
Train Epoch: 1090 	Average Loss: 9.4639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2390

Learning rate: 0.0001941940300708787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1091 [0/90000 (0%)]	Loss: 19.5648	Cost: 20.50s
Train Epoch: 1091 [20480/90000 (23%)]	Loss: 8.7006	Cost: 6.08s
Train Epoch: 1091 [40960/90000 (45%)]	Loss: 8.6956	Cost: 7.16s
Train Epoch: 1091 [61440/90000 (68%)]	Loss: 8.7095	Cost: 5.85s
Train Epoch: 1091 [81920/90000 (91%)]	Loss: 8.9277	Cost: 6.02s
Train Epoch: 1091 	Average Loss: 9.4930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2078

Learning rate: 0.00019418347657071785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1092 [0/90000 (0%)]	Loss: 19.6600	Cost: 19.79s
Train Epoch: 1092 [20480/90000 (23%)]	Loss: 8.5329	Cost: 5.92s
Train Epoch: 1092 [40960/90000 (45%)]	Loss: 8.6892	Cost: 6.40s
Train Epoch: 1092 [61440/90000 (68%)]	Loss: 8.4128	Cost: 5.66s
Train Epoch: 1092 [81920/90000 (91%)]	Loss: 8.3590	Cost: 6.20s
Train Epoch: 1092 	Average Loss: 9.3106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2952

Learning rate: 0.0001941729137750205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1093 [0/90000 (0%)]	Loss: 19.5902	Cost: 21.14s
Train Epoch: 1093 [20480/90000 (23%)]	Loss: 8.2749	Cost: 6.02s
Train Epoch: 1093 [40960/90000 (45%)]	Loss: 8.4825	Cost: 6.65s
Train Epoch: 1093 [61440/90000 (68%)]	Loss: 8.5657	Cost: 5.95s
Train Epoch: 1093 [81920/90000 (91%)]	Loss: 8.5915	Cost: 5.85s
Train Epoch: 1093 	Average Loss: 9.3097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2741

Learning rate: 0.0001941623416848292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1094 [0/90000 (0%)]	Loss: 19.9243	Cost: 20.89s
Train Epoch: 1094 [20480/90000 (23%)]	Loss: 8.9428	Cost: 6.25s
Train Epoch: 1094 [40960/90000 (45%)]	Loss: 8.6277	Cost: 7.34s
Train Epoch: 1094 [61440/90000 (68%)]	Loss: 8.5228	Cost: 6.11s
Train Epoch: 1094 [81920/90000 (91%)]	Loss: 8.7827	Cost: 5.79s
Train Epoch: 1094 	Average Loss: 9.4860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3086

Learning rate: 0.00019415176030118734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1095 [0/90000 (0%)]	Loss: 19.7729	Cost: 20.21s
Train Epoch: 1095 [20480/90000 (23%)]	Loss: 8.6321	Cost: 6.05s
Train Epoch: 1095 [40960/90000 (45%)]	Loss: 8.4641	Cost: 7.00s
Train Epoch: 1095 [61440/90000 (68%)]	Loss: 8.2946	Cost: 5.84s
Train Epoch: 1095 [81920/90000 (91%)]	Loss: 8.6264	Cost: 5.92s
Train Epoch: 1095 	Average Loss: 9.3444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2489

Learning rate: 0.00019414116962513932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1096 [0/90000 (0%)]	Loss: 19.8810	Cost: 20.10s
Train Epoch: 1096 [20480/90000 (23%)]	Loss: 8.4349	Cost: 6.08s
Train Epoch: 1096 [40960/90000 (45%)]	Loss: 8.5303	Cost: 6.11s
Train Epoch: 1096 [61440/90000 (68%)]	Loss: 8.3401	Cost: 6.02s
Train Epoch: 1096 [81920/90000 (91%)]	Loss: 8.2443	Cost: 5.75s
Train Epoch: 1096 	Average Loss: 9.2090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4244

Learning rate: 0.00019413056965773032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1097 [0/90000 (0%)]	Loss: 19.7650	Cost: 20.11s
Train Epoch: 1097 [20480/90000 (23%)]	Loss: 8.3822	Cost: 6.00s
Train Epoch: 1097 [40960/90000 (45%)]	Loss: 8.1663	Cost: 6.72s
Train Epoch: 1097 [61440/90000 (68%)]	Loss: 8.3093	Cost: 5.85s
Train Epoch: 1097 [81920/90000 (91%)]	Loss: 8.1070	Cost: 5.73s
Train Epoch: 1097 	Average Loss: 9.1151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4674

Learning rate: 0.00019411996040000657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1098 [0/90000 (0%)]	Loss: 19.9645	Cost: 20.57s
Train Epoch: 1098 [20480/90000 (23%)]	Loss: 8.4378	Cost: 6.15s
Train Epoch: 1098 [40960/90000 (45%)]	Loss: 8.3502	Cost: 6.25s
Train Epoch: 1098 [61440/90000 (68%)]	Loss: 8.1507	Cost: 5.85s
Train Epoch: 1098 [81920/90000 (91%)]	Loss: 8.1735	Cost: 6.44s
Train Epoch: 1098 	Average Loss: 9.1781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4043

Learning rate: 0.00019410934185301514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1099 [0/90000 (0%)]	Loss: 19.8013	Cost: 20.72s
Train Epoch: 1099 [20480/90000 (23%)]	Loss: 8.4390	Cost: 6.06s
Train Epoch: 1099 [40960/90000 (45%)]	Loss: 8.6296	Cost: 6.04s
Train Epoch: 1099 [61440/90000 (68%)]	Loss: 8.3827	Cost: 5.95s
Train Epoch: 1099 [81920/90000 (91%)]	Loss: 8.1767	Cost: 6.07s
Train Epoch: 1099 	Average Loss: 9.2214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3595

Learning rate: 0.00019409871401780405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1100 [0/90000 (0%)]	Loss: 19.6560	Cost: 20.85s
Train Epoch: 1100 [20480/90000 (23%)]	Loss: 8.1982	Cost: 6.00s
Train Epoch: 1100 [40960/90000 (45%)]	Loss: 8.3488	Cost: 6.90s
Train Epoch: 1100 [61440/90000 (68%)]	Loss: 8.1716	Cost: 5.88s
Train Epoch: 1100 [81920/90000 (91%)]	Loss: 8.1289	Cost: 6.13s
Train Epoch: 1100 	Average Loss: 9.1370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4403

Learning rate: 0.0001940880768954222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1101 [0/90000 (0%)]	Loss: 19.7101	Cost: 19.89s
Train Epoch: 1101 [20480/90000 (23%)]	Loss: 8.1491	Cost: 6.11s
Train Epoch: 1101 [40960/90000 (45%)]	Loss: 8.3385	Cost: 7.05s
Train Epoch: 1101 [61440/90000 (68%)]	Loss: 8.4723	Cost: 5.81s
Train Epoch: 1101 [81920/90000 (91%)]	Loss: 8.5268	Cost: 6.35s
Train Epoch: 1101 	Average Loss: 9.2146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3371

Learning rate: 0.00019407743048691943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1102 [0/90000 (0%)]	Loss: 19.8417	Cost: 19.99s
Train Epoch: 1102 [20480/90000 (23%)]	Loss: 8.5159	Cost: 6.01s
Train Epoch: 1102 [40960/90000 (45%)]	Loss: 8.6032	Cost: 6.75s
Train Epoch: 1102 [61440/90000 (68%)]	Loss: 8.2602	Cost: 5.84s
Train Epoch: 1102 [81920/90000 (91%)]	Loss: 8.2284	Cost: 5.94s
Train Epoch: 1102 	Average Loss: 9.2751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4726

Learning rate: 0.00019406677479334654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1103 [0/90000 (0%)]	Loss: 19.7991	Cost: 21.89s
Train Epoch: 1103 [20480/90000 (23%)]	Loss: 8.3289	Cost: 6.13s
Train Epoch: 1103 [40960/90000 (45%)]	Loss: 8.5708	Cost: 6.10s
Train Epoch: 1103 [61440/90000 (68%)]	Loss: 8.1626	Cost: 5.82s
Train Epoch: 1103 [81920/90000 (91%)]	Loss: 7.9782	Cost: 6.00s
Train Epoch: 1103 	Average Loss: 9.1029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4204

Learning rate: 0.0001940561098157552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1104 [0/90000 (0%)]	Loss: 19.7613	Cost: 20.38s
Train Epoch: 1104 [20480/90000 (23%)]	Loss: 8.1455	Cost: 6.04s
Train Epoch: 1104 [40960/90000 (45%)]	Loss: 8.2167	Cost: 6.39s
Train Epoch: 1104 [61440/90000 (68%)]	Loss: 9.0631	Cost: 5.93s
Train Epoch: 1104 [81920/90000 (91%)]	Loss: 8.9787	Cost: 5.81s
Train Epoch: 1104 	Average Loss: 9.3567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4998

Learning rate: 0.00019404543555519795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1105 [0/90000 (0%)]	Loss: 20.1082	Cost: 22.78s
Train Epoch: 1105 [20480/90000 (23%)]	Loss: 8.7320	Cost: 5.90s
Train Epoch: 1105 [40960/90000 (45%)]	Loss: 8.5764	Cost: 6.52s
Train Epoch: 1105 [61440/90000 (68%)]	Loss: 8.3532	Cost: 5.82s
Train Epoch: 1105 [81920/90000 (91%)]	Loss: 8.4878	Cost: 5.73s
Train Epoch: 1105 	Average Loss: 9.4017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3985

Learning rate: 0.00019403475201272834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1106 [0/90000 (0%)]	Loss: 19.9580	Cost: 21.52s
Train Epoch: 1106 [20480/90000 (23%)]	Loss: 8.4611	Cost: 6.33s
Train Epoch: 1106 [40960/90000 (45%)]	Loss: 8.6491	Cost: 6.04s
Train Epoch: 1106 [61440/90000 (68%)]	Loss: 8.3303	Cost: 5.83s
Train Epoch: 1106 [81920/90000 (91%)]	Loss: 8.4279	Cost: 5.72s
Train Epoch: 1106 	Average Loss: 9.2697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4351

Learning rate: 0.00019402405918940077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1107 [0/90000 (0%)]	Loss: 19.7797	Cost: 21.36s
Train Epoch: 1107 [20480/90000 (23%)]	Loss: 8.1458	Cost: 5.96s
Train Epoch: 1107 [40960/90000 (45%)]	Loss: 8.1506	Cost: 6.82s
Train Epoch: 1107 [61440/90000 (68%)]	Loss: 8.1382	Cost: 5.97s
Train Epoch: 1107 [81920/90000 (91%)]	Loss: 8.4533	Cost: 6.08s
Train Epoch: 1107 	Average Loss: 9.0426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5051

Learning rate: 0.00019401335708627064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1108 [0/90000 (0%)]	Loss: 19.8843	Cost: 19.97s
Train Epoch: 1108 [20480/90000 (23%)]	Loss: 8.4327	Cost: 5.86s
Train Epoch: 1108 [40960/90000 (45%)]	Loss: 8.3991	Cost: 5.96s
Train Epoch: 1108 [61440/90000 (68%)]	Loss: 8.2235	Cost: 5.83s
Train Epoch: 1108 [81920/90000 (91%)]	Loss: 8.3079	Cost: 5.68s
Train Epoch: 1108 	Average Loss: 9.1399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5409

Learning rate: 0.00019400264570439412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1109 [0/90000 (0%)]	Loss: 19.8793	Cost: 22.29s
Train Epoch: 1109 [20480/90000 (23%)]	Loss: 8.3142	Cost: 5.88s
Train Epoch: 1109 [40960/90000 (45%)]	Loss: 8.2896	Cost: 6.49s
Train Epoch: 1109 [61440/90000 (68%)]	Loss: 8.1516	Cost: 5.89s
Train Epoch: 1109 [81920/90000 (91%)]	Loss: 8.2333	Cost: 6.38s
Train Epoch: 1109 	Average Loss: 9.0368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3899

Learning rate: 0.0001939919250448284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1110 [0/90000 (0%)]	Loss: 20.0435	Cost: 19.75s
Train Epoch: 1110 [20480/90000 (23%)]	Loss: 8.0039	Cost: 5.97s
Train Epoch: 1110 [40960/90000 (45%)]	Loss: 8.3738	Cost: 6.00s
Train Epoch: 1110 [61440/90000 (68%)]	Loss: 8.3283	Cost: 5.83s
Train Epoch: 1110 [81920/90000 (91%)]	Loss: 8.3658	Cost: 5.76s
Train Epoch: 1110 	Average Loss: 9.0939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5361

Learning rate: 0.00019398119510863161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1111 [0/90000 (0%)]	Loss: 19.7377	Cost: 21.73s
Train Epoch: 1111 [20480/90000 (23%)]	Loss: 7.8807	Cost: 5.92s
Train Epoch: 1111 [40960/90000 (45%)]	Loss: 8.2571	Cost: 7.00s
Train Epoch: 1111 [61440/90000 (68%)]	Loss: 8.0111	Cost: 5.86s
Train Epoch: 1111 [81920/90000 (91%)]	Loss: 8.3456	Cost: 6.96s
Train Epoch: 1111 	Average Loss: 9.0044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4942

Learning rate: 0.00019397045589686273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1112 [0/90000 (0%)]	Loss: 19.7599	Cost: 21.49s
Train Epoch: 1112 [20480/90000 (23%)]	Loss: 8.2122	Cost: 5.97s
Train Epoch: 1112 [40960/90000 (45%)]	Loss: 8.3698	Cost: 6.16s
Train Epoch: 1112 [61440/90000 (68%)]	Loss: 8.6244	Cost: 5.86s
Train Epoch: 1112 [81920/90000 (91%)]	Loss: 8.4714	Cost: 5.91s
Train Epoch: 1112 	Average Loss: 9.1679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5169

Learning rate: 0.00019395970741058167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1113 [0/90000 (0%)]	Loss: 19.9843	Cost: 21.01s
Train Epoch: 1113 [20480/90000 (23%)]	Loss: 8.5186	Cost: 6.04s
Train Epoch: 1113 [40960/90000 (45%)]	Loss: 8.6621	Cost: 6.18s
Train Epoch: 1113 [61440/90000 (68%)]	Loss: 8.2983	Cost: 5.94s
Train Epoch: 1113 [81920/90000 (91%)]	Loss: 8.3357	Cost: 5.99s
Train Epoch: 1113 	Average Loss: 9.3443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5440

Learning rate: 0.00019394894965084927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1114 [0/90000 (0%)]	Loss: 19.9821	Cost: 21.02s
Train Epoch: 1114 [20480/90000 (23%)]	Loss: 8.1389	Cost: 6.26s
Train Epoch: 1114 [40960/90000 (45%)]	Loss: 8.3033	Cost: 6.00s
Train Epoch: 1114 [61440/90000 (68%)]	Loss: 8.1454	Cost: 5.86s
Train Epoch: 1114 [81920/90000 (91%)]	Loss: 8.2922	Cost: 5.81s
Train Epoch: 1114 	Average Loss: 9.0998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4907

Learning rate: 0.00019393818261872732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1115 [0/90000 (0%)]	Loss: 20.2241	Cost: 20.27s
Train Epoch: 1115 [20480/90000 (23%)]	Loss: 8.0646	Cost: 5.98s
Train Epoch: 1115 [40960/90000 (45%)]	Loss: 8.3359	Cost: 5.99s
Train Epoch: 1115 [61440/90000 (68%)]	Loss: 8.0239	Cost: 5.87s
Train Epoch: 1115 [81920/90000 (91%)]	Loss: 8.1607	Cost: 5.75s
Train Epoch: 1115 	Average Loss: 9.0248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5804

Learning rate: 0.0001939274063152784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1116 [0/90000 (0%)]	Loss: 20.3127	Cost: 21.20s
Train Epoch: 1116 [20480/90000 (23%)]	Loss: 8.2740	Cost: 5.99s
Train Epoch: 1116 [40960/90000 (45%)]	Loss: 8.1475	Cost: 6.06s
Train Epoch: 1116 [61440/90000 (68%)]	Loss: 7.9778	Cost: 5.87s
Train Epoch: 1116 [81920/90000 (91%)]	Loss: 8.0559	Cost: 5.75s
Train Epoch: 1116 	Average Loss: 8.9511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5708

Learning rate: 0.00019391662074156612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1117 [0/90000 (0%)]	Loss: 20.1553	Cost: 19.73s
Train Epoch: 1117 [20480/90000 (23%)]	Loss: 7.9034	Cost: 5.89s
Train Epoch: 1117 [40960/90000 (45%)]	Loss: 7.9324	Cost: 6.07s
Train Epoch: 1117 [61440/90000 (68%)]	Loss: 7.8904	Cost: 5.73s
Train Epoch: 1117 [81920/90000 (91%)]	Loss: 7.9607	Cost: 6.01s
Train Epoch: 1117 	Average Loss: 8.8293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6992

Learning rate: 0.00019390582589865496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1118 [0/90000 (0%)]	Loss: 20.1342	Cost: 21.00s
Train Epoch: 1118 [20480/90000 (23%)]	Loss: 8.1105	Cost: 5.95s
Train Epoch: 1118 [40960/90000 (45%)]	Loss: 8.0982	Cost: 6.51s
Train Epoch: 1118 [61440/90000 (68%)]	Loss: 7.9066	Cost: 5.99s
Train Epoch: 1118 [81920/90000 (91%)]	Loss: 8.0188	Cost: 5.85s
Train Epoch: 1118 	Average Loss: 8.8656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7184

Learning rate: 0.0001938950217876104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1119 [0/90000 (0%)]	Loss: 19.9320	Cost: 20.49s
Train Epoch: 1119 [20480/90000 (23%)]	Loss: 8.0254	Cost: 6.05s
Train Epoch: 1119 [40960/90000 (45%)]	Loss: 8.2272	Cost: 6.25s
Train Epoch: 1119 [61440/90000 (68%)]	Loss: 8.3519	Cost: 5.89s
Train Epoch: 1119 [81920/90000 (91%)]	Loss: 8.5105	Cost: 5.82s
Train Epoch: 1119 	Average Loss: 9.0772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6148

Learning rate: 0.00019388420840949869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1120 [0/90000 (0%)]	Loss: 20.2389	Cost: 20.16s
Train Epoch: 1120 [20480/90000 (23%)]	Loss: 8.3834	Cost: 6.12s
Train Epoch: 1120 [40960/90000 (45%)]	Loss: 8.4949	Cost: 5.91s
Train Epoch: 1120 [61440/90000 (68%)]	Loss: 8.2200	Cost: 5.68s
Train Epoch: 1120 [81920/90000 (91%)]	Loss: 8.1246	Cost: 5.67s
Train Epoch: 1120 	Average Loss: 9.1484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5523

Learning rate: 0.00019387338576538711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1121 [0/90000 (0%)]	Loss: 20.0761	Cost: 19.26s
Train Epoch: 1121 [20480/90000 (23%)]	Loss: 7.8565	Cost: 6.06s
Train Epoch: 1121 [40960/90000 (45%)]	Loss: 8.0297	Cost: 6.05s
Train Epoch: 1121 [61440/90000 (68%)]	Loss: 8.0832	Cost: 5.85s
Train Epoch: 1121 [81920/90000 (91%)]	Loss: 8.0382	Cost: 5.75s
Train Epoch: 1121 	Average Loss: 8.9327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5611

Learning rate: 0.00019386255385634376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1122 [0/90000 (0%)]	Loss: 20.2529	Cost: 20.16s
Train Epoch: 1122 [20480/90000 (23%)]	Loss: 8.1185	Cost: 6.17s
Train Epoch: 1122 [40960/90000 (45%)]	Loss: 8.2187	Cost: 6.14s
Train Epoch: 1122 [61440/90000 (68%)]	Loss: 7.8828	Cost: 5.95s
Train Epoch: 1122 [81920/90000 (91%)]	Loss: 7.9684	Cost: 5.78s
Train Epoch: 1122 	Average Loss: 8.9315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6205

Learning rate: 0.00019385171268343775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1123 [0/90000 (0%)]	Loss: 20.1392	Cost: 19.90s
Train Epoch: 1123 [20480/90000 (23%)]	Loss: 7.8499	Cost: 6.02s
Train Epoch: 1123 [40960/90000 (45%)]	Loss: 8.0955	Cost: 6.37s
Train Epoch: 1123 [61440/90000 (68%)]	Loss: 8.4030	Cost: 5.88s
Train Epoch: 1123 [81920/90000 (91%)]	Loss: 8.3678	Cost: 5.75s
Train Epoch: 1123 	Average Loss: 8.9623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5393

Learning rate: 0.00019384086224773903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1124 [0/90000 (0%)]	Loss: 20.0692	Cost: 19.84s
Train Epoch: 1124 [20480/90000 (23%)]	Loss: 8.0098	Cost: 6.07s
Train Epoch: 1124 [40960/90000 (45%)]	Loss: 8.0073	Cost: 6.05s
Train Epoch: 1124 [61440/90000 (68%)]	Loss: 8.1285	Cost: 5.90s
Train Epoch: 1124 [81920/90000 (91%)]	Loss: 8.6712	Cost: 5.80s
Train Epoch: 1124 	Average Loss: 9.1017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6650

Learning rate: 0.00019383000255031852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1125 [0/90000 (0%)]	Loss: 20.2215	Cost: 19.62s
Train Epoch: 1125 [20480/90000 (23%)]	Loss: 8.4438	Cost: 6.03s
Train Epoch: 1125 [40960/90000 (45%)]	Loss: 8.5213	Cost: 6.56s
Train Epoch: 1125 [61440/90000 (68%)]	Loss: 8.4132	Cost: 5.87s
Train Epoch: 1125 [81920/90000 (91%)]	Loss: 8.3053	Cost: 5.82s
Train Epoch: 1125 	Average Loss: 9.2865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5180

Learning rate: 0.00019381913359224807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1126 [0/90000 (0%)]	Loss: 20.0803	Cost: 20.21s
Train Epoch: 1126 [20480/90000 (23%)]	Loss: 8.1572	Cost: 6.05s
Train Epoch: 1126 [40960/90000 (45%)]	Loss: 8.3602	Cost: 7.81s
Train Epoch: 1126 [61440/90000 (68%)]	Loss: 8.2794	Cost: 5.94s
Train Epoch: 1126 [81920/90000 (91%)]	Loss: 8.4455	Cost: 6.57s
Train Epoch: 1126 	Average Loss: 9.2119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4942

Learning rate: 0.00019380825537460033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1127 [0/90000 (0%)]	Loss: 20.2135	Cost: 20.78s
Train Epoch: 1127 [20480/90000 (23%)]	Loss: 8.1246	Cost: 6.18s
Train Epoch: 1127 [40960/90000 (45%)]	Loss: 8.3197	Cost: 6.87s
Train Epoch: 1127 [61440/90000 (68%)]	Loss: 8.1376	Cost: 6.55s
Train Epoch: 1127 [81920/90000 (91%)]	Loss: 8.2077	Cost: 6.49s
Train Epoch: 1127 	Average Loss: 9.0589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5753

Learning rate: 0.00019379736789844898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1128 [0/90000 (0%)]	Loss: 20.1998	Cost: 21.10s
Train Epoch: 1128 [20480/90000 (23%)]	Loss: 7.9363	Cost: 6.03s
Train Epoch: 1128 [40960/90000 (45%)]	Loss: 8.1615	Cost: 6.35s
Train Epoch: 1128 [61440/90000 (68%)]	Loss: 7.6843	Cost: 5.91s
Train Epoch: 1128 [81920/90000 (91%)]	Loss: 7.9753	Cost: 6.59s
Train Epoch: 1128 	Average Loss: 8.8888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4954

Learning rate: 0.00019378647116486856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1129 [0/90000 (0%)]	Loss: 20.1461	Cost: 21.65s
Train Epoch: 1129 [20480/90000 (23%)]	Loss: 7.9344	Cost: 6.60s
Train Epoch: 1129 [40960/90000 (45%)]	Loss: 8.0975	Cost: 6.41s
Train Epoch: 1129 [61440/90000 (68%)]	Loss: 7.9782	Cost: 6.00s
Train Epoch: 1129 [81920/90000 (91%)]	Loss: 8.2690	Cost: 5.85s
Train Epoch: 1129 	Average Loss: 8.9098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6560

Learning rate: 0.0001937755651749345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1130 [0/90000 (0%)]	Loss: 20.0699	Cost: 21.43s
Train Epoch: 1130 [20480/90000 (23%)]	Loss: 7.9535	Cost: 5.94s
Train Epoch: 1130 [40960/90000 (45%)]	Loss: 8.2724	Cost: 6.06s
Train Epoch: 1130 [61440/90000 (68%)]	Loss: 8.1021	Cost: 5.89s
Train Epoch: 1130 [81920/90000 (91%)]	Loss: 8.2213	Cost: 6.22s
Train Epoch: 1130 	Average Loss: 9.0580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6703

Learning rate: 0.0001937646499297232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1131 [0/90000 (0%)]	Loss: 19.8534	Cost: 21.59s
Train Epoch: 1131 [20480/90000 (23%)]	Loss: 8.1154	Cost: 5.93s
Train Epoch: 1131 [40960/90000 (45%)]	Loss: 8.3202	Cost: 6.54s
Train Epoch: 1131 [61440/90000 (68%)]	Loss: 8.4071	Cost: 5.86s
Train Epoch: 1131 [81920/90000 (91%)]	Loss: 8.7395	Cost: 6.10s
Train Epoch: 1131 	Average Loss: 9.1716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6055

Learning rate: 0.000193753725430312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1132 [0/90000 (0%)]	Loss: 20.1119	Cost: 20.19s
Train Epoch: 1132 [20480/90000 (23%)]	Loss: 8.2291	Cost: 6.09s
Train Epoch: 1132 [40960/90000 (45%)]	Loss: 8.4073	Cost: 6.50s
Train Epoch: 1132 [61440/90000 (68%)]	Loss: 8.2210	Cost: 5.92s
Train Epoch: 1132 [81920/90000 (91%)]	Loss: 8.1259	Cost: 5.95s
Train Epoch: 1132 	Average Loss: 9.1031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6652

Learning rate: 0.00019374279167777905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1133 [0/90000 (0%)]	Loss: 19.9907	Cost: 21.66s
Train Epoch: 1133 [20480/90000 (23%)]	Loss: 7.8400	Cost: 6.07s
Train Epoch: 1133 [40960/90000 (45%)]	Loss: 8.0297	Cost: 6.27s
Train Epoch: 1133 [61440/90000 (68%)]	Loss: 7.9159	Cost: 5.93s
Train Epoch: 1133 [81920/90000 (91%)]	Loss: 8.1434	Cost: 6.02s
Train Epoch: 1133 	Average Loss: 8.9437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5769

Learning rate: 0.00019373184867320348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1134 [0/90000 (0%)]	Loss: 20.3545	Cost: 21.12s
Train Epoch: 1134 [20480/90000 (23%)]	Loss: 7.8000	Cost: 6.08s
Train Epoch: 1134 [40960/90000 (45%)]	Loss: 8.0479	Cost: 6.50s
Train Epoch: 1134 [61440/90000 (68%)]	Loss: 7.9531	Cost: 5.92s
Train Epoch: 1134 [81920/90000 (91%)]	Loss: 7.9622	Cost: 6.01s
Train Epoch: 1134 	Average Loss: 8.8678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7499

Learning rate: 0.00019372089641766534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1135 [0/90000 (0%)]	Loss: 20.3274	Cost: 20.76s
Train Epoch: 1135 [20480/90000 (23%)]	Loss: 7.8421	Cost: 6.55s
Train Epoch: 1135 [40960/90000 (45%)]	Loss: 8.1813	Cost: 6.22s
Train Epoch: 1135 [61440/90000 (68%)]	Loss: 8.1758	Cost: 5.87s
Train Epoch: 1135 [81920/90000 (91%)]	Loss: 8.1591	Cost: 6.02s
Train Epoch: 1135 	Average Loss: 8.9681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6713

Learning rate: 0.00019370993491224555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1136 [0/90000 (0%)]	Loss: 19.9759	Cost: 20.45s
Train Epoch: 1136 [20480/90000 (23%)]	Loss: 7.8449	Cost: 6.00s
Train Epoch: 1136 [40960/90000 (45%)]	Loss: 8.0616	Cost: 5.99s
Train Epoch: 1136 [61440/90000 (68%)]	Loss: 7.6198	Cost: 5.81s
Train Epoch: 1136 [81920/90000 (91%)]	Loss: 7.9500	Cost: 5.77s
Train Epoch: 1136 	Average Loss: 8.7765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6489

Learning rate: 0.00019369896415802597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1137 [0/90000 (0%)]	Loss: 20.3274	Cost: 20.19s
Train Epoch: 1137 [20480/90000 (23%)]	Loss: 7.8029	Cost: 6.08s
Train Epoch: 1137 [40960/90000 (45%)]	Loss: 8.1695	Cost: 6.48s
Train Epoch: 1137 [61440/90000 (68%)]	Loss: 7.6402	Cost: 5.85s
Train Epoch: 1137 [81920/90000 (91%)]	Loss: 8.0341	Cost: 5.77s
Train Epoch: 1137 	Average Loss: 8.8362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6903

Learning rate: 0.0001936879841560894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1138 [0/90000 (0%)]	Loss: 20.2402	Cost: 21.59s
Train Epoch: 1138 [20480/90000 (23%)]	Loss: 8.0123	Cost: 6.11s
Train Epoch: 1138 [40960/90000 (45%)]	Loss: 8.2691	Cost: 6.59s
Train Epoch: 1138 [61440/90000 (68%)]	Loss: 8.0434	Cost: 5.90s
Train Epoch: 1138 [81920/90000 (91%)]	Loss: 8.2388	Cost: 6.16s
Train Epoch: 1138 	Average Loss: 8.9833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6788

Learning rate: 0.00019367699490751948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1139 [0/90000 (0%)]	Loss: 20.3329	Cost: 21.24s
Train Epoch: 1139 [20480/90000 (23%)]	Loss: 8.0112	Cost: 6.04s
Train Epoch: 1139 [40960/90000 (45%)]	Loss: 8.1353	Cost: 7.14s
Train Epoch: 1139 [61440/90000 (68%)]	Loss: 8.1026	Cost: 5.85s
Train Epoch: 1139 [81920/90000 (91%)]	Loss: 7.7033	Cost: 6.20s
Train Epoch: 1139 	Average Loss: 8.8985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6966

Learning rate: 0.0001936659964134008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1140 [0/90000 (0%)]	Loss: 20.6524	Cost: 19.76s
Train Epoch: 1140 [20480/90000 (23%)]	Loss: 7.7825	Cost: 6.05s
Train Epoch: 1140 [40960/90000 (45%)]	Loss: 8.2103	Cost: 6.12s
Train Epoch: 1140 [61440/90000 (68%)]	Loss: 7.7501	Cost: 6.02s
Train Epoch: 1140 [81920/90000 (91%)]	Loss: 7.8588	Cost: 5.82s
Train Epoch: 1140 	Average Loss: 8.7492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7955

Learning rate: 0.0001936549886748189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1141 [0/90000 (0%)]	Loss: 20.2964	Cost: 21.94s
Train Epoch: 1141 [20480/90000 (23%)]	Loss: 7.7482	Cost: 5.99s
Train Epoch: 1141 [40960/90000 (45%)]	Loss: 7.8257	Cost: 6.66s
Train Epoch: 1141 [61440/90000 (68%)]	Loss: 7.6326	Cost: 5.84s
Train Epoch: 1141 [81920/90000 (91%)]	Loss: 7.8848	Cost: 5.93s
Train Epoch: 1141 	Average Loss: 8.6863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8506

Learning rate: 0.00019364397169286022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1142 [0/90000 (0%)]	Loss: 20.3516	Cost: 20.95s
Train Epoch: 1142 [20480/90000 (23%)]	Loss: 7.4449	Cost: 6.04s
Train Epoch: 1142 [40960/90000 (45%)]	Loss: 7.9830	Cost: 6.05s
Train Epoch: 1142 [61440/90000 (68%)]	Loss: 7.6723	Cost: 5.90s
Train Epoch: 1142 [81920/90000 (91%)]	Loss: 7.6610	Cost: 5.88s
Train Epoch: 1142 	Average Loss: 8.6751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6617

Learning rate: 0.00019363294546861204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1143 [0/90000 (0%)]	Loss: 20.4357	Cost: 19.72s
Train Epoch: 1143 [20480/90000 (23%)]	Loss: 7.7440	Cost: 6.05s
Train Epoch: 1143 [40960/90000 (45%)]	Loss: 8.4938	Cost: 6.08s
Train Epoch: 1143 [61440/90000 (68%)]	Loss: 7.9643	Cost: 5.90s
Train Epoch: 1143 [81920/90000 (91%)]	Loss: 8.1668	Cost: 5.75s
Train Epoch: 1143 	Average Loss: 8.9556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7395

Learning rate: 0.00019362191000316264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1144 [0/90000 (0%)]	Loss: 20.2063	Cost: 22.25s
Train Epoch: 1144 [20480/90000 (23%)]	Loss: 8.0213	Cost: 5.92s
Train Epoch: 1144 [40960/90000 (45%)]	Loss: 8.1501	Cost: 6.40s
Train Epoch: 1144 [61440/90000 (68%)]	Loss: 7.9403	Cost: 6.13s
Train Epoch: 1144 [81920/90000 (91%)]	Loss: 8.0728	Cost: 5.81s
Train Epoch: 1144 	Average Loss: 8.9502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9035

Learning rate: 0.0001936108652976012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1145 [0/90000 (0%)]	Loss: 20.3733	Cost: 20.85s
Train Epoch: 1145 [20480/90000 (23%)]	Loss: 7.8718	Cost: 5.98s
Train Epoch: 1145 [40960/90000 (45%)]	Loss: 8.1965	Cost: 6.24s
Train Epoch: 1145 [61440/90000 (68%)]	Loss: 7.7237	Cost: 5.85s
Train Epoch: 1145 [81920/90000 (91%)]	Loss: 7.8550	Cost: 6.49s
Train Epoch: 1145 	Average Loss: 8.8413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7018

Learning rate: 0.0001935998113530177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1146 [0/90000 (0%)]	Loss: 20.2703	Cost: 22.04s
Train Epoch: 1146 [20480/90000 (23%)]	Loss: 7.8108	Cost: 5.98s
Train Epoch: 1146 [40960/90000 (45%)]	Loss: 7.8712	Cost: 6.14s
Train Epoch: 1146 [61440/90000 (68%)]	Loss: 8.0444	Cost: 5.88s
Train Epoch: 1146 [81920/90000 (91%)]	Loss: 8.4304	Cost: 5.88s
Train Epoch: 1146 	Average Loss: 8.8377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8154

Learning rate: 0.0001935887481705032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1147 [0/90000 (0%)]	Loss: 20.3582	Cost: 20.05s
Train Epoch: 1147 [20480/90000 (23%)]	Loss: 8.0233	Cost: 6.02s
Train Epoch: 1147 [40960/90000 (45%)]	Loss: 8.0240	Cost: 6.33s
Train Epoch: 1147 [61440/90000 (68%)]	Loss: 7.7050	Cost: 6.30s
Train Epoch: 1147 [81920/90000 (91%)]	Loss: 7.7948	Cost: 5.98s
Train Epoch: 1147 	Average Loss: 8.8373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8499

Learning rate: 0.00019357767575114954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1148 [0/90000 (0%)]	Loss: 20.1465	Cost: 19.62s
Train Epoch: 1148 [20480/90000 (23%)]	Loss: 8.1058	Cost: 6.05s
Train Epoch: 1148 [40960/90000 (45%)]	Loss: 8.0925	Cost: 6.19s
Train Epoch: 1148 [61440/90000 (68%)]	Loss: 8.0663	Cost: 5.89s
Train Epoch: 1148 [81920/90000 (91%)]	Loss: 8.1698	Cost: 5.90s
Train Epoch: 1148 	Average Loss: 8.8846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7457

Learning rate: 0.0001935665940960496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1149 [0/90000 (0%)]	Loss: 20.4977	Cost: 21.95s
Train Epoch: 1149 [20480/90000 (23%)]	Loss: 7.8659	Cost: 6.09s
Train Epoch: 1149 [40960/90000 (45%)]	Loss: 7.9578	Cost: 6.46s
Train Epoch: 1149 [61440/90000 (68%)]	Loss: 7.8089	Cost: 5.92s
Train Epoch: 1149 [81920/90000 (91%)]	Loss: 7.8672	Cost: 6.37s
Train Epoch: 1149 	Average Loss: 8.8192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8458

Learning rate: 0.000193555503206297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1150 [0/90000 (0%)]	Loss: 20.0599	Cost: 20.51s
Train Epoch: 1150 [20480/90000 (23%)]	Loss: 7.7616	Cost: 6.06s
Train Epoch: 1150 [40960/90000 (45%)]	Loss: 8.0430	Cost: 6.24s
Train Epoch: 1150 [61440/90000 (68%)]	Loss: 8.1926	Cost: 5.90s
Train Epoch: 1150 [81920/90000 (91%)]	Loss: 8.2580	Cost: 6.21s
Train Epoch: 1150 	Average Loss: 8.8987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8551

Learning rate: 0.00019354440308298645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1151 [0/90000 (0%)]	Loss: 20.4322	Cost: 22.51s
Train Epoch: 1151 [20480/90000 (23%)]	Loss: 8.0380	Cost: 6.01s
Train Epoch: 1151 [40960/90000 (45%)]	Loss: 8.1328	Cost: 6.40s
Train Epoch: 1151 [61440/90000 (68%)]	Loss: 7.8034	Cost: 6.10s
Train Epoch: 1151 [81920/90000 (91%)]	Loss: 7.9013	Cost: 5.94s
Train Epoch: 1151 	Average Loss: 8.8666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7615

Learning rate: 0.00019353329372721341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1152 [0/90000 (0%)]	Loss: 20.1740	Cost: 20.95s
Train Epoch: 1152 [20480/90000 (23%)]	Loss: 7.6086	Cost: 6.23s
Train Epoch: 1152 [40960/90000 (45%)]	Loss: 7.8875	Cost: 6.57s
Train Epoch: 1152 [61440/90000 (68%)]	Loss: 7.7659	Cost: 5.89s
Train Epoch: 1152 [81920/90000 (91%)]	Loss: 7.6077	Cost: 6.53s
Train Epoch: 1152 	Average Loss: 8.6715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8433

Learning rate: 0.0001935221751400744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1153 [0/90000 (0%)]	Loss: 20.4160	Cost: 20.47s
Train Epoch: 1153 [20480/90000 (23%)]	Loss: 7.7556	Cost: 6.53s
Train Epoch: 1153 [40960/90000 (45%)]	Loss: 7.7978	Cost: 6.71s
Train Epoch: 1153 [61440/90000 (68%)]	Loss: 7.7601	Cost: 5.97s
Train Epoch: 1153 [81920/90000 (91%)]	Loss: 7.8459	Cost: 5.87s
Train Epoch: 1153 	Average Loss: 8.6782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7764

Learning rate: 0.00019351104732266675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1154 [0/90000 (0%)]	Loss: 20.3949	Cost: 21.68s
Train Epoch: 1154 [20480/90000 (23%)]	Loss: 7.7435	Cost: 6.04s
Train Epoch: 1154 [40960/90000 (45%)]	Loss: 7.8060	Cost: 6.38s
Train Epoch: 1154 [61440/90000 (68%)]	Loss: 7.6690	Cost: 5.90s
Train Epoch: 1154 [81920/90000 (91%)]	Loss: 7.5537	Cost: 6.01s
Train Epoch: 1154 	Average Loss: 8.6325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8675

Learning rate: 0.00019349991027608872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1155 [0/90000 (0%)]	Loss: 20.2655	Cost: 21.13s
Train Epoch: 1155 [20480/90000 (23%)]	Loss: 7.9947	Cost: 6.39s
Train Epoch: 1155 [40960/90000 (45%)]	Loss: 7.9842	Cost: 6.72s
Train Epoch: 1155 [61440/90000 (68%)]	Loss: 7.8525	Cost: 6.30s
Train Epoch: 1155 [81920/90000 (91%)]	Loss: 7.7223	Cost: 5.93s
Train Epoch: 1155 	Average Loss: 8.7094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8534

Learning rate: 0.0001934887640014395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1156 [0/90000 (0%)]	Loss: 20.5145	Cost: 21.26s
Train Epoch: 1156 [20480/90000 (23%)]	Loss: 7.8645	Cost: 6.01s
Train Epoch: 1156 [40960/90000 (45%)]	Loss: 8.0344	Cost: 6.66s
Train Epoch: 1156 [61440/90000 (68%)]	Loss: 8.0463	Cost: 5.84s
Train Epoch: 1156 [81920/90000 (91%)]	Loss: 8.3358	Cost: 6.05s
Train Epoch: 1156 	Average Loss: 8.8916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7777

Learning rate: 0.00019347760849981922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1157 [0/90000 (0%)]	Loss: 20.3496	Cost: 21.16s
Train Epoch: 1157 [20480/90000 (23%)]	Loss: 8.1606	Cost: 6.01s
Train Epoch: 1157 [40960/90000 (45%)]	Loss: 8.6751	Cost: 6.18s
Train Epoch: 1157 [61440/90000 (68%)]	Loss: 8.1446	Cost: 5.88s
Train Epoch: 1157 [81920/90000 (91%)]	Loss: 7.9712	Cost: 5.88s
Train Epoch: 1157 	Average Loss: 9.1456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7538

Learning rate: 0.00019346644377232883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1158 [0/90000 (0%)]	Loss: 20.1972	Cost: 19.99s
Train Epoch: 1158 [20480/90000 (23%)]	Loss: 7.6636	Cost: 6.04s
Train Epoch: 1158 [40960/90000 (45%)]	Loss: 7.8571	Cost: 6.35s
Train Epoch: 1158 [61440/90000 (68%)]	Loss: 7.6180	Cost: 5.96s
Train Epoch: 1158 [81920/90000 (91%)]	Loss: 7.8243	Cost: 6.21s
Train Epoch: 1158 	Average Loss: 8.7455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7249

Learning rate: 0.0001934552698200703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1159 [0/90000 (0%)]	Loss: 20.3960	Cost: 21.66s
Train Epoch: 1159 [20480/90000 (23%)]	Loss: 7.8525	Cost: 5.97s
Train Epoch: 1159 [40960/90000 (45%)]	Loss: 8.0340	Cost: 6.33s
Train Epoch: 1159 [61440/90000 (68%)]	Loss: 7.6373	Cost: 5.83s
Train Epoch: 1159 [81920/90000 (91%)]	Loss: 7.8418	Cost: 5.88s
Train Epoch: 1159 	Average Loss: 8.6669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8413

Learning rate: 0.0001934440866441464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1160 [0/90000 (0%)]	Loss: 20.4092	Cost: 22.00s
Train Epoch: 1160 [20480/90000 (23%)]	Loss: 7.8572	Cost: 6.19s
Train Epoch: 1160 [40960/90000 (45%)]	Loss: 7.8338	Cost: 6.25s
Train Epoch: 1160 [61440/90000 (68%)]	Loss: 7.5847	Cost: 6.08s
Train Epoch: 1160 [81920/90000 (91%)]	Loss: 7.7042	Cost: 6.04s
Train Epoch: 1160 	Average Loss: 8.6026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7437

Learning rate: 0.0001934328942456609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1161 [0/90000 (0%)]	Loss: 20.2886	Cost: 20.94s
Train Epoch: 1161 [20480/90000 (23%)]	Loss: 7.7714	Cost: 5.96s
Train Epoch: 1161 [40960/90000 (45%)]	Loss: 7.9824	Cost: 6.30s
Train Epoch: 1161 [61440/90000 (68%)]	Loss: 7.5535	Cost: 5.77s
Train Epoch: 1161 [81920/90000 (91%)]	Loss: 7.6573	Cost: 6.04s
Train Epoch: 1161 	Average Loss: 8.6441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9354

Learning rate: 0.0001934216926257184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1162 [0/90000 (0%)]	Loss: 20.1126	Cost: 21.08s
Train Epoch: 1162 [20480/90000 (23%)]	Loss: 7.7471	Cost: 6.06s
Train Epoch: 1162 [40960/90000 (45%)]	Loss: 7.8283	Cost: 6.05s
Train Epoch: 1162 [61440/90000 (68%)]	Loss: 7.6358	Cost: 6.11s
Train Epoch: 1162 [81920/90000 (91%)]	Loss: 7.5695	Cost: 5.91s
Train Epoch: 1162 	Average Loss: 8.6059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9587

Learning rate: 0.0001934104817854245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1163 [0/90000 (0%)]	Loss: 20.4687	Cost: 20.63s
Train Epoch: 1163 [20480/90000 (23%)]	Loss: 7.4281	Cost: 6.16s
Train Epoch: 1163 [40960/90000 (45%)]	Loss: 7.7526	Cost: 6.65s
Train Epoch: 1163 [61440/90000 (68%)]	Loss: 7.3807	Cost: 6.59s
Train Epoch: 1163 [81920/90000 (91%)]	Loss: 7.5691	Cost: 6.63s
Train Epoch: 1163 	Average Loss: 8.5072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9518

Learning rate: 0.00019339926172588564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1164 [0/90000 (0%)]	Loss: 20.5257	Cost: 20.36s
Train Epoch: 1164 [20480/90000 (23%)]	Loss: 7.6952	Cost: 6.13s
Train Epoch: 1164 [40960/90000 (45%)]	Loss: 7.5987	Cost: 6.30s
Train Epoch: 1164 [61440/90000 (68%)]	Loss: 7.5096	Cost: 5.90s
Train Epoch: 1164 [81920/90000 (91%)]	Loss: 7.8401	Cost: 5.87s
Train Epoch: 1164 	Average Loss: 8.5608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8738

Learning rate: 0.00019338803244820925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1165 [0/90000 (0%)]	Loss: 20.2011	Cost: 20.42s
Train Epoch: 1165 [20480/90000 (23%)]	Loss: 7.6813	Cost: 6.03s
Train Epoch: 1165 [40960/90000 (45%)]	Loss: 7.6912	Cost: 6.07s
Train Epoch: 1165 [61440/90000 (68%)]	Loss: 7.6656	Cost: 5.89s
Train Epoch: 1165 [81920/90000 (91%)]	Loss: 7.5247	Cost: 5.84s
Train Epoch: 1165 	Average Loss: 8.5271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9000

Learning rate: 0.00019337679395350357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1166 [0/90000 (0%)]	Loss: 20.4869	Cost: 21.98s
Train Epoch: 1166 [20480/90000 (23%)]	Loss: 7.8991	Cost: 5.92s
Train Epoch: 1166 [40960/90000 (45%)]	Loss: 8.2401	Cost: 6.82s
Train Epoch: 1166 [61440/90000 (68%)]	Loss: 7.9508	Cost: 5.85s
Train Epoch: 1166 [81920/90000 (91%)]	Loss: 7.8629	Cost: 6.05s
Train Epoch: 1166 	Average Loss: 8.8042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9224

Learning rate: 0.00019336554624287778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1167 [0/90000 (0%)]	Loss: 20.7321	Cost: 20.34s
Train Epoch: 1167 [20480/90000 (23%)]	Loss: 7.9162	Cost: 6.03s
Train Epoch: 1167 [40960/90000 (45%)]	Loss: 7.7936	Cost: 6.03s
Train Epoch: 1167 [61440/90000 (68%)]	Loss: 7.7885	Cost: 5.89s
Train Epoch: 1167 [81920/90000 (91%)]	Loss: 8.0656	Cost: 5.81s
Train Epoch: 1167 	Average Loss: 8.7428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8322

Learning rate: 0.00019335428931744204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1168 [0/90000 (0%)]	Loss: 20.5473	Cost: 21.34s
Train Epoch: 1168 [20480/90000 (23%)]	Loss: 7.6549	Cost: 6.10s
Train Epoch: 1168 [40960/90000 (45%)]	Loss: 7.8589	Cost: 6.35s
Train Epoch: 1168 [61440/90000 (68%)]	Loss: 7.6246	Cost: 5.85s
Train Epoch: 1168 [81920/90000 (91%)]	Loss: 7.7458	Cost: 6.14s
Train Epoch: 1168 	Average Loss: 8.6579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8649

Learning rate: 0.0001933430231783073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1169 [0/90000 (0%)]	Loss: 20.5455	Cost: 21.90s
Train Epoch: 1169 [20480/90000 (23%)]	Loss: 7.5997	Cost: 6.07s
Train Epoch: 1169 [40960/90000 (45%)]	Loss: 7.8755	Cost: 6.65s
Train Epoch: 1169 [61440/90000 (68%)]	Loss: 7.4408	Cost: 5.88s
Train Epoch: 1169 [81920/90000 (91%)]	Loss: 7.7920	Cost: 6.41s
Train Epoch: 1169 	Average Loss: 8.5762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9723

Learning rate: 0.00019333174782658552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1170 [0/90000 (0%)]	Loss: 20.4183	Cost: 20.11s
Train Epoch: 1170 [20480/90000 (23%)]	Loss: 7.9308	Cost: 6.16s
Train Epoch: 1170 [40960/90000 (45%)]	Loss: 7.7365	Cost: 6.21s
Train Epoch: 1170 [61440/90000 (68%)]	Loss: 7.6290	Cost: 5.86s
Train Epoch: 1170 [81920/90000 (91%)]	Loss: 7.7166	Cost: 5.78s
Train Epoch: 1170 	Average Loss: 8.6077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9554

Learning rate: 0.0001933204632633895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1171 [0/90000 (0%)]	Loss: 20.4289	Cost: 21.22s
Train Epoch: 1171 [20480/90000 (23%)]	Loss: 7.5979	Cost: 5.98s
Train Epoch: 1171 [40960/90000 (45%)]	Loss: 7.4935	Cost: 6.69s
Train Epoch: 1171 [61440/90000 (68%)]	Loss: 7.5717	Cost: 5.86s
Train Epoch: 1171 [81920/90000 (91%)]	Loss: 7.5829	Cost: 6.31s
Train Epoch: 1171 	Average Loss: 8.4554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9234

Learning rate: 0.00019330916948983305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1172 [0/90000 (0%)]	Loss: 20.3901	Cost: 20.98s
Train Epoch: 1172 [20480/90000 (23%)]	Loss: 7.3884	Cost: 6.11s
Train Epoch: 1172 [40960/90000 (45%)]	Loss: 7.4901	Cost: 6.21s
Train Epoch: 1172 [61440/90000 (68%)]	Loss: 7.3507	Cost: 5.86s
Train Epoch: 1172 [81920/90000 (91%)]	Loss: 7.2411	Cost: 5.90s
Train Epoch: 1172 	Average Loss: 8.3549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9350

Learning rate: 0.00019329786650703075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1173 [0/90000 (0%)]	Loss: 20.4929	Cost: 20.59s
Train Epoch: 1173 [20480/90000 (23%)]	Loss: 7.5949	Cost: 6.11s
Train Epoch: 1173 [40960/90000 (45%)]	Loss: 7.6721	Cost: 6.45s
Train Epoch: 1173 [61440/90000 (68%)]	Loss: 7.4882	Cost: 6.12s
Train Epoch: 1173 [81920/90000 (91%)]	Loss: 7.4735	Cost: 5.82s
Train Epoch: 1173 	Average Loss: 8.4209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9975

Learning rate: 0.00019328655431609818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1174 [0/90000 (0%)]	Loss: 20.5117	Cost: 19.66s
Train Epoch: 1174 [20480/90000 (23%)]	Loss: 7.4406	Cost: 6.08s
Train Epoch: 1174 [40960/90000 (45%)]	Loss: 7.6560	Cost: 5.96s
Train Epoch: 1174 [61440/90000 (68%)]	Loss: 7.3595	Cost: 5.89s
Train Epoch: 1174 [81920/90000 (91%)]	Loss: 7.5651	Cost: 6.03s
Train Epoch: 1174 	Average Loss: 8.4603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8888

Learning rate: 0.00019327523291815183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1175 [0/90000 (0%)]	Loss: 20.5171	Cost: 19.94s
Train Epoch: 1175 [20480/90000 (23%)]	Loss: 7.6165	Cost: 6.13s
Train Epoch: 1175 [40960/90000 (45%)]	Loss: 7.5831	Cost: 6.64s
Train Epoch: 1175 [61440/90000 (68%)]	Loss: 7.3416	Cost: 5.96s
Train Epoch: 1175 [81920/90000 (91%)]	Loss: 7.6575	Cost: 6.30s
Train Epoch: 1175 	Average Loss: 8.4623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9704

Learning rate: 0.00019326390231430904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1176 [0/90000 (0%)]	Loss: 20.4064	Cost: 22.08s
Train Epoch: 1176 [20480/90000 (23%)]	Loss: 7.3644	Cost: 5.93s
Train Epoch: 1176 [40960/90000 (45%)]	Loss: 7.5416	Cost: 6.53s
Train Epoch: 1176 [61440/90000 (68%)]	Loss: 7.6513	Cost: 5.97s
Train Epoch: 1176 [81920/90000 (91%)]	Loss: 8.0067	Cost: 5.78s
Train Epoch: 1176 	Average Loss: 8.4862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0045

Learning rate: 0.00019325256250568812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1177 [0/90000 (0%)]	Loss: 20.5784	Cost: 21.97s
Train Epoch: 1177 [20480/90000 (23%)]	Loss: 7.8383	Cost: 5.99s
Train Epoch: 1177 [40960/90000 (45%)]	Loss: 8.2072	Cost: 6.31s
Train Epoch: 1177 [61440/90000 (68%)]	Loss: 8.0151	Cost: 5.93s
Train Epoch: 1177 [81920/90000 (91%)]	Loss: 8.0013	Cost: 6.10s
Train Epoch: 1177 	Average Loss: 8.8781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9596

Learning rate: 0.00019324121349340828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1178 [0/90000 (0%)]	Loss: 20.4181	Cost: 19.94s
Train Epoch: 1178 [20480/90000 (23%)]	Loss: 7.7515	Cost: 6.04s
Train Epoch: 1178 [40960/90000 (45%)]	Loss: 7.8184	Cost: 6.40s
Train Epoch: 1178 [61440/90000 (68%)]	Loss: 7.7266	Cost: 5.85s
Train Epoch: 1178 [81920/90000 (91%)]	Loss: 7.5528	Cost: 5.79s
Train Epoch: 1178 	Average Loss: 8.6151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0202

Learning rate: 0.0001932298552785896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1179 [0/90000 (0%)]	Loss: 20.6051	Cost: 22.58s
Train Epoch: 1179 [20480/90000 (23%)]	Loss: 7.4126	Cost: 6.08s
Train Epoch: 1179 [40960/90000 (45%)]	Loss: 7.4422	Cost: 6.05s
Train Epoch: 1179 [61440/90000 (68%)]	Loss: 7.6409	Cost: 5.96s
Train Epoch: 1179 [81920/90000 (91%)]	Loss: 7.5631	Cost: 5.92s
Train Epoch: 1179 	Average Loss: 8.4408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9550

Learning rate: 0.00019321848786235313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1180 [0/90000 (0%)]	Loss: 20.3249	Cost: 22.53s
Train Epoch: 1180 [20480/90000 (23%)]	Loss: 7.5757	Cost: 5.98s
Train Epoch: 1180 [40960/90000 (45%)]	Loss: 7.6739	Cost: 6.13s
Train Epoch: 1180 [61440/90000 (68%)]	Loss: 7.4869	Cost: 5.87s
Train Epoch: 1180 [81920/90000 (91%)]	Loss: 7.6423	Cost: 6.04s
Train Epoch: 1180 	Average Loss: 8.4902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0019

Learning rate: 0.0001932071112458207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1181 [0/90000 (0%)]	Loss: 20.6774	Cost: 22.19s
Train Epoch: 1181 [20480/90000 (23%)]	Loss: 7.3175	Cost: 5.91s
Train Epoch: 1181 [40960/90000 (45%)]	Loss: 7.8576	Cost: 6.19s
Train Epoch: 1181 [61440/90000 (68%)]	Loss: 7.5787	Cost: 5.94s
Train Epoch: 1181 [81920/90000 (91%)]	Loss: 7.4811	Cost: 5.99s
Train Epoch: 1181 	Average Loss: 8.4323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0180

Learning rate: 0.00019319572543011524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1182 [0/90000 (0%)]	Loss: 20.4689	Cost: 21.43s
Train Epoch: 1182 [20480/90000 (23%)]	Loss: 7.3281	Cost: 6.00s
Train Epoch: 1182 [40960/90000 (45%)]	Loss: 7.5275	Cost: 6.50s
Train Epoch: 1182 [61440/90000 (68%)]	Loss: 7.3756	Cost: 6.05s
Train Epoch: 1182 [81920/90000 (91%)]	Loss: 7.4695	Cost: 6.00s
Train Epoch: 1182 	Average Loss: 8.4002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0878

Learning rate: 0.0001931843304163604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1183 [0/90000 (0%)]	Loss: 20.4298	Cost: 21.07s
Train Epoch: 1183 [20480/90000 (23%)]	Loss: 7.4607	Cost: 6.17s
Train Epoch: 1183 [40960/90000 (45%)]	Loss: 7.7883	Cost: 6.15s
Train Epoch: 1183 [61440/90000 (68%)]	Loss: 7.6997	Cost: 6.14s
Train Epoch: 1183 [81920/90000 (91%)]	Loss: 7.5490	Cost: 5.86s
Train Epoch: 1183 	Average Loss: 8.5663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0064

Learning rate: 0.0001931729262056809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1184 [0/90000 (0%)]	Loss: 20.6859	Cost: 20.67s
Train Epoch: 1184 [20480/90000 (23%)]	Loss: 7.3665	Cost: 6.01s
Train Epoch: 1184 [40960/90000 (45%)]	Loss: 7.5407	Cost: 6.08s
Train Epoch: 1184 [61440/90000 (68%)]	Loss: 7.4482	Cost: 6.04s
Train Epoch: 1184 [81920/90000 (91%)]	Loss: 7.6063	Cost: 5.79s
Train Epoch: 1184 	Average Loss: 8.4363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0497

Learning rate: 0.0001931615127992022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1185 [0/90000 (0%)]	Loss: 20.6181	Cost: 21.96s
Train Epoch: 1185 [20480/90000 (23%)]	Loss: 7.1450	Cost: 5.96s
Train Epoch: 1185 [40960/90000 (45%)]	Loss: 7.4533	Cost: 6.49s
Train Epoch: 1185 [61440/90000 (68%)]	Loss: 7.1830	Cost: 5.90s
Train Epoch: 1185 [81920/90000 (91%)]	Loss: 7.3173	Cost: 5.79s
Train Epoch: 1185 	Average Loss: 8.2650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0923

Learning rate: 0.00019315009019805086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1186 [0/90000 (0%)]	Loss: 20.6832	Cost: 21.89s
Train Epoch: 1186 [20480/90000 (23%)]	Loss: 7.3458	Cost: 6.08s
Train Epoch: 1186 [40960/90000 (45%)]	Loss: 7.5290	Cost: 6.38s
Train Epoch: 1186 [61440/90000 (68%)]	Loss: 7.2847	Cost: 5.93s
Train Epoch: 1186 [81920/90000 (91%)]	Loss: 7.4659	Cost: 6.59s
Train Epoch: 1186 	Average Loss: 8.3468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0185

Learning rate: 0.00019313865840335417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1187 [0/90000 (0%)]	Loss: 20.3292	Cost: 20.74s
Train Epoch: 1187 [20480/90000 (23%)]	Loss: 7.2263	Cost: 6.31s
Train Epoch: 1187 [40960/90000 (45%)]	Loss: 7.5737	Cost: 6.33s
Train Epoch: 1187 [61440/90000 (68%)]	Loss: 7.2515	Cost: 5.89s
Train Epoch: 1187 [81920/90000 (91%)]	Loss: 7.4863	Cost: 5.85s
Train Epoch: 1187 	Average Loss: 8.2802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0792

Learning rate: 0.00019312721741624044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1188 [0/90000 (0%)]	Loss: 20.6182	Cost: 21.28s
Train Epoch: 1188 [20480/90000 (23%)]	Loss: 7.5887	Cost: 6.00s
Train Epoch: 1188 [40960/90000 (45%)]	Loss: 7.7023	Cost: 6.61s
Train Epoch: 1188 [61440/90000 (68%)]	Loss: 7.4380	Cost: 6.34s
Train Epoch: 1188 [81920/90000 (91%)]	Loss: 7.7373	Cost: 6.69s
Train Epoch: 1188 	Average Loss: 8.5620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0827

Learning rate: 0.00019311576723783885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1189 [0/90000 (0%)]	Loss: 20.4628	Cost: 20.99s
Train Epoch: 1189 [20480/90000 (23%)]	Loss: 7.5628	Cost: 5.96s
Train Epoch: 1189 [40960/90000 (45%)]	Loss: 7.5310	Cost: 6.05s
Train Epoch: 1189 [61440/90000 (68%)]	Loss: 7.3168	Cost: 5.90s
Train Epoch: 1189 [81920/90000 (91%)]	Loss: 7.2264	Cost: 5.87s
Train Epoch: 1189 	Average Loss: 8.3624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1279

Learning rate: 0.00019310430786927943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1190 [0/90000 (0%)]	Loss: 20.7158	Cost: 20.77s
Train Epoch: 1190 [20480/90000 (23%)]	Loss: 7.0963	Cost: 5.96s
Train Epoch: 1190 [40960/90000 (45%)]	Loss: 7.3365	Cost: 6.45s
Train Epoch: 1190 [61440/90000 (68%)]	Loss: 7.5690	Cost: 5.92s
Train Epoch: 1190 [81920/90000 (91%)]	Loss: 7.4834	Cost: 6.27s
Train Epoch: 1190 	Average Loss: 8.3163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0461

Learning rate: 0.0001930928393116932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1191 [0/90000 (0%)]	Loss: 20.5368	Cost: 20.03s
Train Epoch: 1191 [20480/90000 (23%)]	Loss: 7.5168	Cost: 5.99s
Train Epoch: 1191 [40960/90000 (45%)]	Loss: 7.4925	Cost: 6.01s
Train Epoch: 1191 [61440/90000 (68%)]	Loss: 7.3934	Cost: 5.98s
Train Epoch: 1191 [81920/90000 (91%)]	Loss: 7.5032	Cost: 6.02s
Train Epoch: 1191 	Average Loss: 8.4003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0765

Learning rate: 0.00019308136156621214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1192 [0/90000 (0%)]	Loss: 20.6141	Cost: 20.55s
Train Epoch: 1192 [20480/90000 (23%)]	Loss: 7.4696	Cost: 6.09s
Train Epoch: 1192 [40960/90000 (45%)]	Loss: 7.5931	Cost: 6.01s
Train Epoch: 1192 [61440/90000 (68%)]	Loss: 7.1879	Cost: 5.92s
Train Epoch: 1192 [81920/90000 (91%)]	Loss: 7.4487	Cost: 5.80s
Train Epoch: 1192 	Average Loss: 8.3176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0675

Learning rate: 0.00019306987463396896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1193 [0/90000 (0%)]	Loss: 20.8323	Cost: 22.22s
Train Epoch: 1193 [20480/90000 (23%)]	Loss: 7.2327	Cost: 5.92s
Train Epoch: 1193 [40960/90000 (45%)]	Loss: 7.4851	Cost: 6.33s
Train Epoch: 1193 [61440/90000 (68%)]	Loss: 6.9821	Cost: 5.88s
Train Epoch: 1193 [81920/90000 (91%)]	Loss: 7.2585	Cost: 5.89s
Train Epoch: 1193 	Average Loss: 8.2773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0470

Learning rate: 0.00019305837851609745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1194 [0/90000 (0%)]	Loss: 20.9331	Cost: 21.72s
Train Epoch: 1194 [20480/90000 (23%)]	Loss: 7.2020	Cost: 5.94s
Train Epoch: 1194 [40960/90000 (45%)]	Loss: 7.2815	Cost: 6.96s
Train Epoch: 1194 [61440/90000 (68%)]	Loss: 7.4546	Cost: 5.88s
Train Epoch: 1194 [81920/90000 (91%)]	Loss: 7.1076	Cost: 6.41s
Train Epoch: 1194 	Average Loss: 8.2667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1597

Learning rate: 0.00019304687321373217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1195 [0/90000 (0%)]	Loss: 20.5619	Cost: 20.64s
Train Epoch: 1195 [20480/90000 (23%)]	Loss: 7.0632	Cost: 6.05s
Train Epoch: 1195 [40960/90000 (45%)]	Loss: 7.2529	Cost: 6.44s
Train Epoch: 1195 [61440/90000 (68%)]	Loss: 7.1507	Cost: 6.05s
Train Epoch: 1195 [81920/90000 (91%)]	Loss: 7.0586	Cost: 5.81s
Train Epoch: 1195 	Average Loss: 8.1542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1322

Learning rate: 0.00019303535872800865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1196 [0/90000 (0%)]	Loss: 20.8983	Cost: 20.67s
Train Epoch: 1196 [20480/90000 (23%)]	Loss: 7.0005	Cost: 6.09s
Train Epoch: 1196 [40960/90000 (45%)]	Loss: 7.1947	Cost: 6.07s
Train Epoch: 1196 [61440/90000 (68%)]	Loss: 7.0065	Cost: 6.32s
Train Epoch: 1196 [81920/90000 (91%)]	Loss: 7.4083	Cost: 5.82s
Train Epoch: 1196 	Average Loss: 8.1311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1841

Learning rate: 0.00019302383506006335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1197 [0/90000 (0%)]	Loss: 20.7242	Cost: 21.98s
Train Epoch: 1197 [20480/90000 (23%)]	Loss: 7.3561	Cost: 6.00s
Train Epoch: 1197 [40960/90000 (45%)]	Loss: 7.3719	Cost: 6.35s
Train Epoch: 1197 [61440/90000 (68%)]	Loss: 7.3219	Cost: 5.87s
Train Epoch: 1197 [81920/90000 (91%)]	Loss: 7.2514	Cost: 6.40s
Train Epoch: 1197 	Average Loss: 8.3249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1813

Learning rate: 0.00019301230221103362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1198 [0/90000 (0%)]	Loss: 20.6341	Cost: 21.47s
Train Epoch: 1198 [20480/90000 (23%)]	Loss: 7.2913	Cost: 6.00s
Train Epoch: 1198 [40960/90000 (45%)]	Loss: 7.2917	Cost: 6.03s
Train Epoch: 1198 [61440/90000 (68%)]	Loss: 7.1819	Cost: 5.94s
Train Epoch: 1198 [81920/90000 (91%)]	Loss: 7.2896	Cost: 5.91s
Train Epoch: 1198 	Average Loss: 8.2136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1808

Learning rate: 0.0001930007601820577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1199 [0/90000 (0%)]	Loss: 20.6032	Cost: 21.45s
Train Epoch: 1199 [20480/90000 (23%)]	Loss: 7.1759	Cost: 6.05s
Train Epoch: 1199 [40960/90000 (45%)]	Loss: 7.3303	Cost: 6.10s
Train Epoch: 1199 [61440/90000 (68%)]	Loss: 7.1210	Cost: 5.88s
Train Epoch: 1199 [81920/90000 (91%)]	Loss: 6.9797	Cost: 5.84s
Train Epoch: 1199 	Average Loss: 8.1740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0894

Learning rate: 0.00019298920897427473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1200 [0/90000 (0%)]	Loss: 20.8901	Cost: 21.04s
Train Epoch: 1200 [20480/90000 (23%)]	Loss: 7.1095	Cost: 5.97s
Train Epoch: 1200 [40960/90000 (45%)]	Loss: 7.7185	Cost: 6.57s
Train Epoch: 1200 [61440/90000 (68%)]	Loss: 7.4654	Cost: 5.85s
Train Epoch: 1200 [81920/90000 (91%)]	Loss: 7.4385	Cost: 5.91s
Train Epoch: 1200 	Average Loss: 8.3136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2750

Learning rate: 0.00019297764858882476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1201 [0/90000 (0%)]	Loss: 20.6328	Cost: 20.19s
Train Epoch: 1201 [20480/90000 (23%)]	Loss: 7.3891	Cost: 6.02s
Train Epoch: 1201 [40960/90000 (45%)]	Loss: 7.3645	Cost: 6.40s
Train Epoch: 1201 [61440/90000 (68%)]	Loss: 6.9217	Cost: 5.89s
Train Epoch: 1201 [81920/90000 (91%)]	Loss: 7.1287	Cost: 5.89s
Train Epoch: 1201 	Average Loss: 8.2239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2348

Learning rate: 0.0001929660790268488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1202 [0/90000 (0%)]	Loss: 20.5089	Cost: 20.85s
Train Epoch: 1202 [20480/90000 (23%)]	Loss: 6.9171	Cost: 5.98s
Train Epoch: 1202 [40960/90000 (45%)]	Loss: 7.4295	Cost: 6.33s
Train Epoch: 1202 [61440/90000 (68%)]	Loss: 7.2748	Cost: 5.84s
Train Epoch: 1202 [81920/90000 (91%)]	Loss: 7.3892	Cost: 5.85s
Train Epoch: 1202 	Average Loss: 8.1750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1249

Learning rate: 0.00019295450028948867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1203 [0/90000 (0%)]	Loss: 20.5293	Cost: 22.30s
Train Epoch: 1203 [20480/90000 (23%)]	Loss: 7.1261	Cost: 6.01s
Train Epoch: 1203 [40960/90000 (45%)]	Loss: 7.2698	Cost: 6.17s
Train Epoch: 1203 [61440/90000 (68%)]	Loss: 7.3276	Cost: 5.69s
Train Epoch: 1203 [81920/90000 (91%)]	Loss: 7.3142	Cost: 5.88s
Train Epoch: 1203 	Average Loss: 8.2974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2426

Learning rate: 0.00019294291237788717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1204 [0/90000 (0%)]	Loss: 20.6685	Cost: 22.02s
Train Epoch: 1204 [20480/90000 (23%)]	Loss: 7.0919	Cost: 5.97s
Train Epoch: 1204 [40960/90000 (45%)]	Loss: 7.4652	Cost: 6.49s
Train Epoch: 1204 [61440/90000 (68%)]	Loss: 7.2197	Cost: 5.88s
Train Epoch: 1204 [81920/90000 (91%)]	Loss: 7.1140	Cost: 5.81s
Train Epoch: 1204 	Average Loss: 8.2957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1858

Learning rate: 0.00019293131529318796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1205 [0/90000 (0%)]	Loss: 20.6404	Cost: 22.69s
Train Epoch: 1205 [20480/90000 (23%)]	Loss: 7.1840	Cost: 5.91s
Train Epoch: 1205 [40960/90000 (45%)]	Loss: 7.5291	Cost: 6.37s
Train Epoch: 1205 [61440/90000 (68%)]	Loss: 7.3482	Cost: 5.89s
Train Epoch: 1205 [81920/90000 (91%)]	Loss: 7.1946	Cost: 6.41s
Train Epoch: 1205 	Average Loss: 8.1965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2373

Learning rate: 0.00019291970903653568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1206 [0/90000 (0%)]	Loss: 20.9466	Cost: 21.13s
Train Epoch: 1206 [20480/90000 (23%)]	Loss: 7.0608	Cost: 5.99s
Train Epoch: 1206 [40960/90000 (45%)]	Loss: 7.4878	Cost: 6.37s
Train Epoch: 1206 [61440/90000 (68%)]	Loss: 7.3423	Cost: 6.02s
Train Epoch: 1206 [81920/90000 (91%)]	Loss: 7.5131	Cost: 5.75s
Train Epoch: 1206 	Average Loss: 8.2534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2262

Learning rate: 0.00019290809360907572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1207 [0/90000 (0%)]	Loss: 20.9203	Cost: 20.22s
Train Epoch: 1207 [20480/90000 (23%)]	Loss: 7.4380	Cost: 6.05s
Train Epoch: 1207 [40960/90000 (45%)]	Loss: 7.3600	Cost: 7.40s
Train Epoch: 1207 [61440/90000 (68%)]	Loss: 7.1061	Cost: 5.87s
Train Epoch: 1207 [81920/90000 (91%)]	Loss: 7.5610	Cost: 6.30s
Train Epoch: 1207 	Average Loss: 8.3067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1176

Learning rate: 0.0001928964690119546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1208 [0/90000 (0%)]	Loss: 20.7154	Cost: 19.30s
Train Epoch: 1208 [20480/90000 (23%)]	Loss: 7.3340	Cost: 6.04s
Train Epoch: 1208 [40960/90000 (45%)]	Loss: 7.3600	Cost: 7.25s
Train Epoch: 1208 [61440/90000 (68%)]	Loss: 7.1428	Cost: 5.83s
Train Epoch: 1208 [81920/90000 (91%)]	Loss: 7.5518	Cost: 5.90s
Train Epoch: 1208 	Average Loss: 8.2661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2849

Learning rate: 0.00019288483524631953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1209 [0/90000 (0%)]	Loss: 20.7503	Cost: 20.26s
Train Epoch: 1209 [20480/90000 (23%)]	Loss: 7.1617	Cost: 6.00s
Train Epoch: 1209 [40960/90000 (45%)]	Loss: 7.1277	Cost: 7.43s
Train Epoch: 1209 [61440/90000 (68%)]	Loss: 7.0010	Cost: 5.83s
Train Epoch: 1209 [81920/90000 (91%)]	Loss: 7.2319	Cost: 6.77s
Train Epoch: 1209 	Average Loss: 8.1275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1951

Learning rate: 0.00019287319231331873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1210 [0/90000 (0%)]	Loss: 20.7578	Cost: 19.53s
Train Epoch: 1210 [20480/90000 (23%)]	Loss: 7.0890	Cost: 6.21s
Train Epoch: 1210 [40960/90000 (45%)]	Loss: 7.2373	Cost: 6.49s
Train Epoch: 1210 [61440/90000 (68%)]	Loss: 6.9832	Cost: 5.91s
Train Epoch: 1210 [81920/90000 (91%)]	Loss: 6.9711	Cost: 6.31s
Train Epoch: 1210 	Average Loss: 8.0568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2383

Learning rate: 0.00019286154021410135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1211 [0/90000 (0%)]	Loss: 20.7106	Cost: 20.66s
Train Epoch: 1211 [20480/90000 (23%)]	Loss: 7.1957	Cost: 6.21s
Train Epoch: 1211 [40960/90000 (45%)]	Loss: 7.5404	Cost: 6.85s
Train Epoch: 1211 [61440/90000 (68%)]	Loss: 7.6519	Cost: 5.98s
Train Epoch: 1211 [81920/90000 (91%)]	Loss: 7.5048	Cost: 6.34s
Train Epoch: 1211 	Average Loss: 8.3890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2435

Learning rate: 0.0001928498789498174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1212 [0/90000 (0%)]	Loss: 20.8151	Cost: 20.27s
Train Epoch: 1212 [20480/90000 (23%)]	Loss: 7.2363	Cost: 6.05s
Train Epoch: 1212 [40960/90000 (45%)]	Loss: 7.2588	Cost: 7.04s
Train Epoch: 1212 [61440/90000 (68%)]	Loss: 7.2333	Cost: 5.88s
Train Epoch: 1212 [81920/90000 (91%)]	Loss: 7.2268	Cost: 5.76s
Train Epoch: 1212 	Average Loss: 8.2794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2395

Learning rate: 0.00019283820852161778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1213 [0/90000 (0%)]	Loss: 20.7561	Cost: 19.60s
Train Epoch: 1213 [20480/90000 (23%)]	Loss: 7.1792	Cost: 6.06s
Train Epoch: 1213 [40960/90000 (45%)]	Loss: 7.1065	Cost: 6.48s
Train Epoch: 1213 [61440/90000 (68%)]	Loss: 6.8901	Cost: 5.89s
Train Epoch: 1213 [81920/90000 (91%)]	Loss: 7.1131	Cost: 5.84s
Train Epoch: 1213 	Average Loss: 8.0313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1957

Learning rate: 0.00019282652893065432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1214 [0/90000 (0%)]	Loss: 20.8315	Cost: 20.05s
Train Epoch: 1214 [20480/90000 (23%)]	Loss: 6.9584	Cost: 5.99s
Train Epoch: 1214 [40960/90000 (45%)]	Loss: 6.9402	Cost: 7.09s
Train Epoch: 1214 [61440/90000 (68%)]	Loss: 6.8947	Cost: 5.83s
Train Epoch: 1214 [81920/90000 (91%)]	Loss: 6.9382	Cost: 6.16s
Train Epoch: 1214 	Average Loss: 8.0090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2512

Learning rate: 0.00019281484017807975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1215 [0/90000 (0%)]	Loss: 20.7513	Cost: 20.05s
Train Epoch: 1215 [20480/90000 (23%)]	Loss: 7.0041	Cost: 5.96s
Train Epoch: 1215 [40960/90000 (45%)]	Loss: 6.7680	Cost: 8.12s
Train Epoch: 1215 [61440/90000 (68%)]	Loss: 6.8085	Cost: 5.77s
Train Epoch: 1215 [81920/90000 (91%)]	Loss: 6.9166	Cost: 6.19s
Train Epoch: 1215 	Average Loss: 7.9732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3805

Learning rate: 0.00019280314226504771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1216 [0/90000 (0%)]	Loss: 20.8118	Cost: 22.09s
Train Epoch: 1216 [20480/90000 (23%)]	Loss: 7.0930	Cost: 5.95s
Train Epoch: 1216 [40960/90000 (45%)]	Loss: 7.0388	Cost: 6.66s
Train Epoch: 1216 [61440/90000 (68%)]	Loss: 7.0108	Cost: 5.88s
Train Epoch: 1216 [81920/90000 (91%)]	Loss: 6.8317	Cost: 6.12s
Train Epoch: 1216 	Average Loss: 7.8980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3750

Learning rate: 0.00019279143519271272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1217 [0/90000 (0%)]	Loss: 20.7322	Cost: 20.27s
Train Epoch: 1217 [20480/90000 (23%)]	Loss: 6.9182	Cost: 6.09s
Train Epoch: 1217 [40960/90000 (45%)]	Loss: 7.3578	Cost: 6.67s
Train Epoch: 1217 [61440/90000 (68%)]	Loss: 7.6843	Cost: 6.06s
Train Epoch: 1217 [81920/90000 (91%)]	Loss: 7.7495	Cost: 5.75s
Train Epoch: 1217 	Average Loss: 8.3240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2935

Learning rate: 0.00019277971896223024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1218 [0/90000 (0%)]	Loss: 20.6354	Cost: 21.60s
Train Epoch: 1218 [20480/90000 (23%)]	Loss: 7.8584	Cost: 5.95s
Train Epoch: 1218 [40960/90000 (45%)]	Loss: 7.5576	Cost: 6.83s
Train Epoch: 1218 [61440/90000 (68%)]	Loss: 7.4658	Cost: 5.87s
Train Epoch: 1218 [81920/90000 (91%)]	Loss: 7.3307	Cost: 6.17s
Train Epoch: 1218 	Average Loss: 8.5157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2640

Learning rate: 0.00019276799357475661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1219 [0/90000 (0%)]	Loss: 20.3791	Cost: 22.35s
Train Epoch: 1219 [20480/90000 (23%)]	Loss: 6.9807	Cost: 6.07s
Train Epoch: 1219 [40960/90000 (45%)]	Loss: 7.2037	Cost: 6.46s
Train Epoch: 1219 [61440/90000 (68%)]	Loss: 7.1158	Cost: 5.93s
Train Epoch: 1219 [81920/90000 (91%)]	Loss: 7.0192	Cost: 6.10s
Train Epoch: 1219 	Average Loss: 8.0682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3140

Learning rate: 0.00019275625903144908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1220 [0/90000 (0%)]	Loss: 20.8329	Cost: 22.66s
Train Epoch: 1220 [20480/90000 (23%)]	Loss: 6.9947	Cost: 5.92s
Train Epoch: 1220 [40960/90000 (45%)]	Loss: 7.0991	Cost: 6.61s
Train Epoch: 1220 [61440/90000 (68%)]	Loss: 6.9269	Cost: 5.90s
Train Epoch: 1220 [81920/90000 (91%)]	Loss: 7.1858	Cost: 6.61s
Train Epoch: 1220 	Average Loss: 7.9777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3623

Learning rate: 0.0001927445153334658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1221 [0/90000 (0%)]	Loss: 21.0800	Cost: 21.32s
Train Epoch: 1221 [20480/90000 (23%)]	Loss: 7.1780	Cost: 5.97s
Train Epoch: 1221 [40960/90000 (45%)]	Loss: 7.0273	Cost: 6.36s
Train Epoch: 1221 [61440/90000 (68%)]	Loss: 6.9601	Cost: 5.95s
Train Epoch: 1221 [81920/90000 (91%)]	Loss: 7.1847	Cost: 5.97s
Train Epoch: 1221 	Average Loss: 7.9757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3562

Learning rate: 0.00019273276248196581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1222 [0/90000 (0%)]	Loss: 20.8438	Cost: 21.58s
Train Epoch: 1222 [20480/90000 (23%)]	Loss: 6.8153	Cost: 6.47s
Train Epoch: 1222 [40960/90000 (45%)]	Loss: 6.9748	Cost: 6.09s
Train Epoch: 1222 [61440/90000 (68%)]	Loss: 6.9722	Cost: 5.92s
Train Epoch: 1222 [81920/90000 (91%)]	Loss: 7.0886	Cost: 6.39s
Train Epoch: 1222 	Average Loss: 7.9266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3859

Learning rate: 0.0001927210004781091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1223 [0/90000 (0%)]	Loss: 20.8529	Cost: 21.50s
Train Epoch: 1223 [20480/90000 (23%)]	Loss: 6.9723	Cost: 6.04s
Train Epoch: 1223 [40960/90000 (45%)]	Loss: 7.0403	Cost: 6.20s
Train Epoch: 1223 [61440/90000 (68%)]	Loss: 7.0342	Cost: 5.89s
Train Epoch: 1223 [81920/90000 (91%)]	Loss: 6.9212	Cost: 5.84s
Train Epoch: 1223 	Average Loss: 8.0483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3629

Learning rate: 0.0001927092293230565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1224 [0/90000 (0%)]	Loss: 20.6839	Cost: 20.61s
Train Epoch: 1224 [20480/90000 (23%)]	Loss: 7.0551	Cost: 6.03s
Train Epoch: 1224 [40960/90000 (45%)]	Loss: 7.1737	Cost: 6.08s
Train Epoch: 1224 [61440/90000 (68%)]	Loss: 7.0086	Cost: 6.14s
Train Epoch: 1224 [81920/90000 (91%)]	Loss: 6.9890	Cost: 6.11s
Train Epoch: 1224 	Average Loss: 8.0365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3759

Learning rate: 0.00019269744901796983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1225 [0/90000 (0%)]	Loss: 20.7224	Cost: 21.47s
Train Epoch: 1225 [20480/90000 (23%)]	Loss: 6.8853	Cost: 6.07s
Train Epoch: 1225 [40960/90000 (45%)]	Loss: 6.9705	Cost: 6.18s
Train Epoch: 1225 [61440/90000 (68%)]	Loss: 7.2771	Cost: 5.88s
Train Epoch: 1225 [81920/90000 (91%)]	Loss: 7.3288	Cost: 5.88s
Train Epoch: 1225 	Average Loss: 8.0520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4596

Learning rate: 0.0001926856595640117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1226 [0/90000 (0%)]	Loss: 20.7338	Cost: 21.24s
Train Epoch: 1226 [20480/90000 (23%)]	Loss: 7.1603	Cost: 5.98s
Train Epoch: 1226 [40960/90000 (45%)]	Loss: 7.2369	Cost: 6.71s
Train Epoch: 1226 [61440/90000 (68%)]	Loss: 7.1806	Cost: 5.93s
Train Epoch: 1226 [81920/90000 (91%)]	Loss: 7.3021	Cost: 7.24s
Train Epoch: 1226 	Average Loss: 8.1899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4102

Learning rate: 0.00019267386096234575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1227 [0/90000 (0%)]	Loss: 20.6328	Cost: 21.55s
Train Epoch: 1227 [20480/90000 (23%)]	Loss: 7.4157	Cost: 5.72s
Train Epoch: 1227 [40960/90000 (45%)]	Loss: 7.4414	Cost: 6.24s
Train Epoch: 1227 [61440/90000 (68%)]	Loss: 7.3788	Cost: 5.68s
Train Epoch: 1227 [81920/90000 (91%)]	Loss: 7.3987	Cost: 5.92s
Train Epoch: 1227 	Average Loss: 8.3531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3470

Learning rate: 0.0001926620532141364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1228 [0/90000 (0%)]	Loss: 20.6221	Cost: 21.89s
Train Epoch: 1228 [20480/90000 (23%)]	Loss: 6.9643	Cost: 5.98s
Train Epoch: 1228 [40960/90000 (45%)]	Loss: 6.9166	Cost: 6.55s
Train Epoch: 1228 [61440/90000 (68%)]	Loss: 6.8575	Cost: 6.07s
Train Epoch: 1228 [81920/90000 (91%)]	Loss: 7.0226	Cost: 6.79s
Train Epoch: 1228 	Average Loss: 7.9386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2708

Learning rate: 0.00019265023632054903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1229 [0/90000 (0%)]	Loss: 20.8234	Cost: 21.26s
Train Epoch: 1229 [20480/90000 (23%)]	Loss: 6.7107	Cost: 5.98s
Train Epoch: 1229 [40960/90000 (45%)]	Loss: 6.7864	Cost: 7.23s
Train Epoch: 1229 [61440/90000 (68%)]	Loss: 6.8809	Cost: 6.04s
Train Epoch: 1229 [81920/90000 (91%)]	Loss: 6.8041	Cost: 6.28s
Train Epoch: 1229 	Average Loss: 7.7992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4383

Learning rate: 0.00019263841028274996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1230 [0/90000 (0%)]	Loss: 21.1063	Cost: 20.34s
Train Epoch: 1230 [20480/90000 (23%)]	Loss: 7.2127	Cost: 6.08s
Train Epoch: 1230 [40960/90000 (45%)]	Loss: 7.3497	Cost: 6.16s
Train Epoch: 1230 [61440/90000 (68%)]	Loss: 7.1448	Cost: 5.91s
Train Epoch: 1230 [81920/90000 (91%)]	Loss: 7.1583	Cost: 6.26s
Train Epoch: 1230 	Average Loss: 8.2057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3788

Learning rate: 0.0001926265751019063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1231 [0/90000 (0%)]	Loss: 20.8876	Cost: 21.61s
Train Epoch: 1231 [20480/90000 (23%)]	Loss: 7.4269	Cost: 6.01s
Train Epoch: 1231 [40960/90000 (45%)]	Loss: 7.4889	Cost: 6.46s
Train Epoch: 1231 [61440/90000 (68%)]	Loss: 7.0385	Cost: 6.10s
Train Epoch: 1231 [81920/90000 (91%)]	Loss: 7.4408	Cost: 6.50s
Train Epoch: 1231 	Average Loss: 8.1937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3462

Learning rate: 0.00019261473077918618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1232 [0/90000 (0%)]	Loss: 20.8173	Cost: 21.07s
Train Epoch: 1232 [20480/90000 (23%)]	Loss: 7.1537	Cost: 6.01s
Train Epoch: 1232 [40960/90000 (45%)]	Loss: 7.1298	Cost: 6.05s
Train Epoch: 1232 [61440/90000 (68%)]	Loss: 7.0571	Cost: 6.03s
Train Epoch: 1232 [81920/90000 (91%)]	Loss: 6.9818	Cost: 6.44s
Train Epoch: 1232 	Average Loss: 8.0613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3139

Learning rate: 0.00019260287731575864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1233 [0/90000 (0%)]	Loss: 21.1571	Cost: 20.34s
Train Epoch: 1233 [20480/90000 (23%)]	Loss: 7.0089	Cost: 6.14s
Train Epoch: 1233 [40960/90000 (45%)]	Loss: 7.1169	Cost: 6.67s
Train Epoch: 1233 [61440/90000 (68%)]	Loss: 6.9462	Cost: 5.91s
Train Epoch: 1233 [81920/90000 (91%)]	Loss: 6.9918	Cost: 6.11s
Train Epoch: 1233 	Average Loss: 7.9361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3913

Learning rate: 0.0001925910147127935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1234 [0/90000 (0%)]	Loss: 20.7331	Cost: 20.86s
Train Epoch: 1234 [20480/90000 (23%)]	Loss: 6.8240	Cost: 6.07s
Train Epoch: 1234 [40960/90000 (45%)]	Loss: 6.8545	Cost: 6.25s
Train Epoch: 1234 [61440/90000 (68%)]	Loss: 6.8120	Cost: 5.91s
Train Epoch: 1234 [81920/90000 (91%)]	Loss: 6.9155	Cost: 5.90s
Train Epoch: 1234 	Average Loss: 7.8624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3900

Learning rate: 0.00019257914297146156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1235 [0/90000 (0%)]	Loss: 20.9402	Cost: 22.44s
Train Epoch: 1235 [20480/90000 (23%)]	Loss: 6.6154	Cost: 6.09s
Train Epoch: 1235 [40960/90000 (45%)]	Loss: 6.7306	Cost: 6.58s
Train Epoch: 1235 [61440/90000 (68%)]	Loss: 6.6188	Cost: 5.85s
Train Epoch: 1235 [81920/90000 (91%)]	Loss: 6.7351	Cost: 6.50s
Train Epoch: 1235 	Average Loss: 7.7268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4753

Learning rate: 0.00019256726209293456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1236 [0/90000 (0%)]	Loss: 21.2993	Cost: 20.92s
Train Epoch: 1236 [20480/90000 (23%)]	Loss: 6.6484	Cost: 6.13s
Train Epoch: 1236 [40960/90000 (45%)]	Loss: 6.8389	Cost: 6.02s
Train Epoch: 1236 [61440/90000 (68%)]	Loss: 6.5133	Cost: 5.97s
Train Epoch: 1236 [81920/90000 (91%)]	Loss: 6.6450	Cost: 5.92s
Train Epoch: 1236 	Average Loss: 7.6820
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5051

Learning rate: 0.00019255537207838502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1237 [0/90000 (0%)]	Loss: 21.1541	Cost: 22.59s
Train Epoch: 1237 [20480/90000 (23%)]	Loss: 6.8438	Cost: 5.96s
Train Epoch: 1237 [40960/90000 (45%)]	Loss: 7.0724	Cost: 7.03s
Train Epoch: 1237 [61440/90000 (68%)]	Loss: 6.9629	Cost: 6.07s
Train Epoch: 1237 [81920/90000 (91%)]	Loss: 7.0491	Cost: 6.35s
Train Epoch: 1237 	Average Loss: 7.8940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4603

Learning rate: 0.0001925434729289865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1238 [0/90000 (0%)]	Loss: 20.9472	Cost: 21.57s
Train Epoch: 1238 [20480/90000 (23%)]	Loss: 6.7994	Cost: 5.98s
Train Epoch: 1238 [40960/90000 (45%)]	Loss: 6.9615	Cost: 6.64s
Train Epoch: 1238 [61440/90000 (68%)]	Loss: 6.6990	Cost: 5.88s
Train Epoch: 1238 [81920/90000 (91%)]	Loss: 6.6350	Cost: 6.07s
Train Epoch: 1238 	Average Loss: 7.7461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5448

Learning rate: 0.00019253156464591338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1239 [0/90000 (0%)]	Loss: 21.0325	Cost: 21.95s
Train Epoch: 1239 [20480/90000 (23%)]	Loss: 6.7794	Cost: 6.02s
Train Epoch: 1239 [40960/90000 (45%)]	Loss: 6.9609	Cost: 6.98s
Train Epoch: 1239 [61440/90000 (68%)]	Loss: 6.7378	Cost: 6.37s
Train Epoch: 1239 [81920/90000 (91%)]	Loss: 6.8748	Cost: 5.84s
Train Epoch: 1239 	Average Loss: 7.8421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5231

Learning rate: 0.00019251964723034095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1240 [0/90000 (0%)]	Loss: 20.8107	Cost: 21.94s
Train Epoch: 1240 [20480/90000 (23%)]	Loss: 6.8765	Cost: 6.33s
Train Epoch: 1240 [40960/90000 (45%)]	Loss: 6.7049	Cost: 6.01s
Train Epoch: 1240 [61440/90000 (68%)]	Loss: 6.6006	Cost: 5.89s
Train Epoch: 1240 [81920/90000 (91%)]	Loss: 7.3413	Cost: 6.11s
Train Epoch: 1240 	Average Loss: 7.8312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4458

Learning rate: 0.00019250772068344542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1241 [0/90000 (0%)]	Loss: 21.1033	Cost: 21.28s
Train Epoch: 1241 [20480/90000 (23%)]	Loss: 7.4683	Cost: 6.16s
Train Epoch: 1241 [40960/90000 (45%)]	Loss: 7.4942	Cost: 6.88s
Train Epoch: 1241 [61440/90000 (68%)]	Loss: 7.1308	Cost: 5.89s
Train Epoch: 1241 [81920/90000 (91%)]	Loss: 7.1958	Cost: 7.03s
Train Epoch: 1241 	Average Loss: 8.3690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4499

Learning rate: 0.0001924957850064039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1242 [0/90000 (0%)]	Loss: 20.9368	Cost: 21.27s
Train Epoch: 1242 [20480/90000 (23%)]	Loss: 7.1797	Cost: 6.09s
Train Epoch: 1242 [40960/90000 (45%)]	Loss: 7.1091	Cost: 6.45s
Train Epoch: 1242 [61440/90000 (68%)]	Loss: 6.9199	Cost: 5.95s
Train Epoch: 1242 [81920/90000 (91%)]	Loss: 6.9737	Cost: 5.95s
Train Epoch: 1242 	Average Loss: 7.9917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3962

Learning rate: 0.0001924838402003944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1243 [0/90000 (0%)]	Loss: 21.1179	Cost: 21.62s
Train Epoch: 1243 [20480/90000 (23%)]	Loss: 6.8223	Cost: 6.08s
Train Epoch: 1243 [40960/90000 (45%)]	Loss: 7.0464	Cost: 6.59s
Train Epoch: 1243 [61440/90000 (68%)]	Loss: 6.8559	Cost: 6.05s
Train Epoch: 1243 [81920/90000 (91%)]	Loss: 6.8338	Cost: 5.83s
Train Epoch: 1243 	Average Loss: 7.8437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4557

Learning rate: 0.0001924718862665958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1244 [0/90000 (0%)]	Loss: 21.0244	Cost: 21.11s
Train Epoch: 1244 [20480/90000 (23%)]	Loss: 6.7823	Cost: 6.03s
Train Epoch: 1244 [40960/90000 (45%)]	Loss: 6.8190	Cost: 6.26s
Train Epoch: 1244 [61440/90000 (68%)]	Loss: 6.5674	Cost: 5.83s
Train Epoch: 1244 [81920/90000 (91%)]	Loss: 6.8774	Cost: 6.41s
Train Epoch: 1244 	Average Loss: 7.7299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5427

Learning rate: 0.0001924599232061879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1245 [0/90000 (0%)]	Loss: 21.1717	Cost: 20.45s
Train Epoch: 1245 [20480/90000 (23%)]	Loss: 6.6398	Cost: 6.30s
Train Epoch: 1245 [40960/90000 (45%)]	Loss: 6.8858	Cost: 6.31s
Train Epoch: 1245 [61440/90000 (68%)]	Loss: 6.5557	Cost: 6.09s
Train Epoch: 1245 [81920/90000 (91%)]	Loss: 6.5802	Cost: 6.04s
Train Epoch: 1245 	Average Loss: 7.6648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4187

Learning rate: 0.00019244795102035147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1246 [0/90000 (0%)]	Loss: 21.2282	Cost: 21.84s
Train Epoch: 1246 [20480/90000 (23%)]	Loss: 6.7416	Cost: 6.65s
Train Epoch: 1246 [40960/90000 (45%)]	Loss: 6.8928	Cost: 6.69s
Train Epoch: 1246 [61440/90000 (68%)]	Loss: 6.5785	Cost: 5.89s
Train Epoch: 1246 [81920/90000 (91%)]	Loss: 6.8459	Cost: 5.93s
Train Epoch: 1246 	Average Loss: 7.6687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5379

Learning rate: 0.00019243596971026803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1247 [0/90000 (0%)]	Loss: 21.0199	Cost: 21.27s
Train Epoch: 1247 [20480/90000 (23%)]	Loss: 6.6302	Cost: 5.97s
Train Epoch: 1247 [40960/90000 (45%)]	Loss: 7.4788	Cost: 6.11s
Train Epoch: 1247 [61440/90000 (68%)]	Loss: 7.1336	Cost: 5.87s
Train Epoch: 1247 [81920/90000 (91%)]	Loss: 7.0990	Cost: 6.10s
Train Epoch: 1247 	Average Loss: 8.0441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4526

Learning rate: 0.00019242397927712014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1248 [0/90000 (0%)]	Loss: 20.8321	Cost: 21.50s
Train Epoch: 1248 [20480/90000 (23%)]	Loss: 6.9502	Cost: 5.98s
Train Epoch: 1248 [40960/90000 (45%)]	Loss: 6.9917	Cost: 6.44s
Train Epoch: 1248 [61440/90000 (68%)]	Loss: 6.7766	Cost: 5.89s
Train Epoch: 1248 [81920/90000 (91%)]	Loss: 7.2191	Cost: 6.16s
Train Epoch: 1248 	Average Loss: 8.0482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4460

Learning rate: 0.00019241197972209119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1249 [0/90000 (0%)]	Loss: 20.9099	Cost: 20.12s
Train Epoch: 1249 [20480/90000 (23%)]	Loss: 6.8183	Cost: 6.01s
Train Epoch: 1249 [40960/90000 (45%)]	Loss: 6.8572	Cost: 6.68s
Train Epoch: 1249 [61440/90000 (68%)]	Loss: 6.6508	Cost: 5.88s
Train Epoch: 1249 [81920/90000 (91%)]	Loss: 6.9404	Cost: 6.13s
Train Epoch: 1249 	Average Loss: 7.9107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4836

Learning rate: 0.0001923999710463655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1250 [0/90000 (0%)]	Loss: 20.8907	Cost: 22.44s
Train Epoch: 1250 [20480/90000 (23%)]	Loss: 6.6333	Cost: 5.98s
Train Epoch: 1250 [40960/90000 (45%)]	Loss: 6.9625	Cost: 6.05s
Train Epoch: 1250 [61440/90000 (68%)]	Loss: 7.0174	Cost: 5.99s
Train Epoch: 1250 [81920/90000 (91%)]	Loss: 6.9232	Cost: 5.82s
Train Epoch: 1250 	Average Loss: 7.8428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5431

Learning rate: 0.0001923879532511283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1251 [0/90000 (0%)]	Loss: 20.9581	Cost: 21.57s
Train Epoch: 1251 [20480/90000 (23%)]	Loss: 6.5482	Cost: 5.97s
Train Epoch: 1251 [40960/90000 (45%)]	Loss: 6.8256	Cost: 6.05s
Train Epoch: 1251 [61440/90000 (68%)]	Loss: 6.6307	Cost: 5.83s
Train Epoch: 1251 [81920/90000 (91%)]	Loss: 6.4880	Cost: 5.78s
Train Epoch: 1251 	Average Loss: 7.7081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5136

Learning rate: 0.00019237592633756566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1252 [0/90000 (0%)]	Loss: 20.9921	Cost: 22.83s
Train Epoch: 1252 [20480/90000 (23%)]	Loss: 6.5773	Cost: 6.07s
Train Epoch: 1252 [40960/90000 (45%)]	Loss: 6.8575	Cost: 6.07s
Train Epoch: 1252 [61440/90000 (68%)]	Loss: 6.3846	Cost: 5.93s
Train Epoch: 1252 [81920/90000 (91%)]	Loss: 6.7684	Cost: 7.20s
Train Epoch: 1252 	Average Loss: 7.6100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5671

Learning rate: 0.00019236389030686458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1253 [0/90000 (0%)]	Loss: 21.1405	Cost: 22.01s
Train Epoch: 1253 [20480/90000 (23%)]	Loss: 6.6645	Cost: 6.18s
Train Epoch: 1253 [40960/90000 (45%)]	Loss: 6.7418	Cost: 6.45s
Train Epoch: 1253 [61440/90000 (68%)]	Loss: 6.4917	Cost: 6.04s
Train Epoch: 1253 [81920/90000 (91%)]	Loss: 6.5929	Cost: 5.83s
Train Epoch: 1253 	Average Loss: 7.5664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5392

Learning rate: 0.000192351845160213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1254 [0/90000 (0%)]	Loss: 21.2344	Cost: 21.00s
Train Epoch: 1254 [20480/90000 (23%)]	Loss: 6.4258	Cost: 6.05s
Train Epoch: 1254 [40960/90000 (45%)]	Loss: 6.8573	Cost: 6.17s
Train Epoch: 1254 [61440/90000 (68%)]	Loss: 6.8153	Cost: 6.02s
Train Epoch: 1254 [81920/90000 (91%)]	Loss: 6.8214	Cost: 5.79s
Train Epoch: 1254 	Average Loss: 7.6959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6394

Learning rate: 0.00019233979089879974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1255 [0/90000 (0%)]	Loss: 21.1450	Cost: 21.56s
Train Epoch: 1255 [20480/90000 (23%)]	Loss: 6.5181	Cost: 5.93s
Train Epoch: 1255 [40960/90000 (45%)]	Loss: 6.7428	Cost: 6.52s
Train Epoch: 1255 [61440/90000 (68%)]	Loss: 6.4315	Cost: 5.83s
Train Epoch: 1255 [81920/90000 (91%)]	Loss: 6.4620	Cost: 6.04s
Train Epoch: 1255 	Average Loss: 7.5673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5646

Learning rate: 0.00019232772752381447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1256 [0/90000 (0%)]	Loss: 21.1338	Cost: 20.23s
Train Epoch: 1256 [20480/90000 (23%)]	Loss: 6.2959	Cost: 6.01s
Train Epoch: 1256 [40960/90000 (45%)]	Loss: 6.6680	Cost: 6.33s
Train Epoch: 1256 [61440/90000 (68%)]	Loss: 6.3722	Cost: 6.07s
Train Epoch: 1256 [81920/90000 (91%)]	Loss: 6.4956	Cost: 5.77s
Train Epoch: 1256 	Average Loss: 7.4635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4660

Learning rate: 0.00019231565503644783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1257 [0/90000 (0%)]	Loss: 21.2282	Cost: 19.57s
Train Epoch: 1257 [20480/90000 (23%)]	Loss: 6.6295	Cost: 6.11s
Train Epoch: 1257 [40960/90000 (45%)]	Loss: 6.6718	Cost: 6.17s
Train Epoch: 1257 [61440/90000 (68%)]	Loss: 6.4596	Cost: 5.98s
Train Epoch: 1257 [81920/90000 (91%)]	Loss: 6.7316	Cost: 5.77s
Train Epoch: 1257 	Average Loss: 7.6394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6846

Learning rate: 0.0001923035734378913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1258 [0/90000 (0%)]	Loss: 21.1383	Cost: 20.35s
Train Epoch: 1258 [20480/90000 (23%)]	Loss: 6.4495	Cost: 6.67s
Train Epoch: 1258 [40960/90000 (45%)]	Loss: 6.8789	Cost: 6.67s
Train Epoch: 1258 [61440/90000 (68%)]	Loss: 7.0479	Cost: 6.58s
Train Epoch: 1258 [81920/90000 (91%)]	Loss: 7.3526	Cost: 6.43s
Train Epoch: 1258 	Average Loss: 7.9364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6486

Learning rate: 0.00019229148272933733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1259 [0/90000 (0%)]	Loss: 20.9449	Cost: 21.43s
Train Epoch: 1259 [20480/90000 (23%)]	Loss: 7.2352	Cost: 5.97s
Train Epoch: 1259 [40960/90000 (45%)]	Loss: 7.4262	Cost: 6.11s
Train Epoch: 1259 [61440/90000 (68%)]	Loss: 7.2786	Cost: 5.84s
Train Epoch: 1259 [81920/90000 (91%)]	Loss: 7.3607	Cost: 5.71s
Train Epoch: 1259 	Average Loss: 8.2702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4662

Learning rate: 0.00019227938291197918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1260 [0/90000 (0%)]	Loss: 21.2169	Cost: 19.48s
Train Epoch: 1260 [20480/90000 (23%)]	Loss: 7.0499	Cost: 6.02s
Train Epoch: 1260 [40960/90000 (45%)]	Loss: 7.2035	Cost: 5.98s
Train Epoch: 1260 [61440/90000 (68%)]	Loss: 7.3017	Cost: 5.87s
Train Epoch: 1260 [81920/90000 (91%)]	Loss: 7.1089	Cost: 5.75s
Train Epoch: 1260 	Average Loss: 8.1923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5070

Learning rate: 0.00019226727398701107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1261 [0/90000 (0%)]	Loss: 21.0461	Cost: 20.90s
Train Epoch: 1261 [20480/90000 (23%)]	Loss: 7.0855	Cost: 6.00s
Train Epoch: 1261 [40960/90000 (45%)]	Loss: 7.3546	Cost: 6.12s
Train Epoch: 1261 [61440/90000 (68%)]	Loss: 6.8121	Cost: 6.01s
Train Epoch: 1261 [81920/90000 (91%)]	Loss: 6.7909	Cost: 5.73s
Train Epoch: 1261 	Average Loss: 8.0397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5206

Learning rate: 0.00019225515595562809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1262 [0/90000 (0%)]	Loss: 21.0931	Cost: 20.79s
Train Epoch: 1262 [20480/90000 (23%)]	Loss: 6.7827	Cost: 5.75s
Train Epoch: 1262 [40960/90000 (45%)]	Loss: 7.0334	Cost: 6.15s
Train Epoch: 1262 [61440/90000 (68%)]	Loss: 6.6360	Cost: 5.62s
Train Epoch: 1262 [81920/90000 (91%)]	Loss: 6.7758	Cost: 5.58s
Train Epoch: 1262 	Average Loss: 7.7396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5591

Learning rate: 0.00019224302881902622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1263 [0/90000 (0%)]	Loss: 21.1967	Cost: 21.84s
Train Epoch: 1263 [20480/90000 (23%)]	Loss: 6.7287	Cost: 5.92s
Train Epoch: 1263 [40960/90000 (45%)]	Loss: 7.0524	Cost: 6.31s
Train Epoch: 1263 [61440/90000 (68%)]	Loss: 6.6245	Cost: 5.78s
Train Epoch: 1263 [81920/90000 (91%)]	Loss: 6.5658	Cost: 5.94s
Train Epoch: 1263 	Average Loss: 7.6855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5172

Learning rate: 0.00019223089257840243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1264 [0/90000 (0%)]	Loss: 21.0366	Cost: 21.41s
Train Epoch: 1264 [20480/90000 (23%)]	Loss: 6.4764	Cost: 6.00s
Train Epoch: 1264 [40960/90000 (45%)]	Loss: 6.8194	Cost: 6.16s
Train Epoch: 1264 [61440/90000 (68%)]	Loss: 6.3883	Cost: 5.81s
Train Epoch: 1264 [81920/90000 (91%)]	Loss: 7.0028	Cost: 5.75s
Train Epoch: 1264 	Average Loss: 7.6808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6329

Learning rate: 0.0001922187472349545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1265 [0/90000 (0%)]	Loss: 21.0822	Cost: 20.58s
Train Epoch: 1265 [20480/90000 (23%)]	Loss: 6.4612	Cost: 6.00s
Train Epoch: 1265 [40960/90000 (45%)]	Loss: 6.8523	Cost: 6.47s
Train Epoch: 1265 [61440/90000 (68%)]	Loss: 7.4530	Cost: 5.79s
Train Epoch: 1265 [81920/90000 (91%)]	Loss: 7.3528	Cost: 5.91s
Train Epoch: 1265 	Average Loss: 8.0067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5518

Learning rate: 0.0001922065927898811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1266 [0/90000 (0%)]	Loss: 21.1769	Cost: 21.09s
Train Epoch: 1266 [20480/90000 (23%)]	Loss: 6.9171	Cost: 5.99s
Train Epoch: 1266 [40960/90000 (45%)]	Loss: 7.2601	Cost: 6.10s
Train Epoch: 1266 [61440/90000 (68%)]	Loss: 6.9748	Cost: 5.79s
Train Epoch: 1266 [81920/90000 (91%)]	Loss: 7.0998	Cost: 5.67s
Train Epoch: 1266 	Average Loss: 8.0879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5634

Learning rate: 0.0001921944292443818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1267 [0/90000 (0%)]	Loss: 21.0275	Cost: 21.74s
Train Epoch: 1267 [20480/90000 (23%)]	Loss: 6.8657	Cost: 5.93s
Train Epoch: 1267 [40960/90000 (45%)]	Loss: 7.2929	Cost: 6.23s
Train Epoch: 1267 [61440/90000 (68%)]	Loss: 6.9962	Cost: 5.80s
Train Epoch: 1267 [81920/90000 (91%)]	Loss: 6.7094	Cost: 5.87s
Train Epoch: 1267 	Average Loss: 7.9615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4797

Learning rate: 0.00019218225659965716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1268 [0/90000 (0%)]	Loss: 21.1811	Cost: 21.45s
Train Epoch: 1268 [20480/90000 (23%)]	Loss: 6.6814	Cost: 5.96s
Train Epoch: 1268 [40960/90000 (45%)]	Loss: 6.8018	Cost: 6.39s
Train Epoch: 1268 [61440/90000 (68%)]	Loss: 6.6415	Cost: 5.92s
Train Epoch: 1268 [81920/90000 (91%)]	Loss: 6.7419	Cost: 5.86s
Train Epoch: 1268 	Average Loss: 7.7239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5310

Learning rate: 0.00019217007485690854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1269 [0/90000 (0%)]	Loss: 21.2387	Cost: 21.97s
Train Epoch: 1269 [20480/90000 (23%)]	Loss: 6.9837	Cost: 5.93s
Train Epoch: 1269 [40960/90000 (45%)]	Loss: 7.0557	Cost: 6.08s
Train Epoch: 1269 [61440/90000 (68%)]	Loss: 7.0524	Cost: 5.95s
Train Epoch: 1269 [81920/90000 (91%)]	Loss: 6.7267	Cost: 5.90s
Train Epoch: 1269 	Average Loss: 7.9413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5019

Learning rate: 0.00019215788401733824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1270 [0/90000 (0%)]	Loss: 21.0162	Cost: 22.01s
Train Epoch: 1270 [20480/90000 (23%)]	Loss: 6.8544	Cost: 5.89s
Train Epoch: 1270 [40960/90000 (45%)]	Loss: 7.0169	Cost: 6.63s
Train Epoch: 1270 [61440/90000 (68%)]	Loss: 6.7004	Cost: 5.80s
Train Epoch: 1270 [81920/90000 (91%)]	Loss: 6.7900	Cost: 5.98s
Train Epoch: 1270 	Average Loss: 7.8221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5492

Learning rate: 0.00019214568408214942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1271 [0/90000 (0%)]	Loss: 20.9493	Cost: 20.80s
Train Epoch: 1271 [20480/90000 (23%)]	Loss: 6.5158	Cost: 6.13s
Train Epoch: 1271 [40960/90000 (45%)]	Loss: 6.6258	Cost: 6.13s
Train Epoch: 1271 [61440/90000 (68%)]	Loss: 6.3609	Cost: 5.80s
Train Epoch: 1271 [81920/90000 (91%)]	Loss: 6.6251	Cost: 5.93s
Train Epoch: 1271 	Average Loss: 7.5376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6328

Learning rate: 0.00019213347505254617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1272 [0/90000 (0%)]	Loss: 21.1476	Cost: 21.92s
Train Epoch: 1272 [20480/90000 (23%)]	Loss: 6.5640	Cost: 6.12s
Train Epoch: 1272 [40960/90000 (45%)]	Loss: 6.8108	Cost: 6.55s
Train Epoch: 1272 [61440/90000 (68%)]	Loss: 6.5774	Cost: 5.96s
Train Epoch: 1272 [81920/90000 (91%)]	Loss: 6.4123	Cost: 5.70s
Train Epoch: 1272 	Average Loss: 7.6322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6300

Learning rate: 0.0001921212569297335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1273 [0/90000 (0%)]	Loss: 21.2257	Cost: 21.68s
Train Epoch: 1273 [20480/90000 (23%)]	Loss: 6.7414	Cost: 6.00s
Train Epoch: 1273 [40960/90000 (45%)]	Loss: 6.5963	Cost: 6.59s
Train Epoch: 1273 [61440/90000 (68%)]	Loss: 6.3524	Cost: 6.44s
Train Epoch: 1273 [81920/90000 (91%)]	Loss: 6.5421	Cost: 6.41s
Train Epoch: 1273 	Average Loss: 7.5327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6085

Learning rate: 0.00019210902971491728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1274 [0/90000 (0%)]	Loss: 21.0254	Cost: 21.43s
Train Epoch: 1274 [20480/90000 (23%)]	Loss: 6.4542	Cost: 6.05s
Train Epoch: 1274 [40960/90000 (45%)]	Loss: 6.3611	Cost: 6.50s
Train Epoch: 1274 [61440/90000 (68%)]	Loss: 6.1824	Cost: 5.82s
Train Epoch: 1274 [81920/90000 (91%)]	Loss: 6.4798	Cost: 5.70s
Train Epoch: 1274 	Average Loss: 7.4091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6699

Learning rate: 0.0001920967934093043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1275 [0/90000 (0%)]	Loss: 21.0471	Cost: 21.94s
Train Epoch: 1275 [20480/90000 (23%)]	Loss: 6.3260	Cost: 5.91s
Train Epoch: 1275 [40960/90000 (45%)]	Loss: 6.4578	Cost: 6.41s
Train Epoch: 1275 [61440/90000 (68%)]	Loss: 6.5771	Cost: 5.78s
Train Epoch: 1275 [81920/90000 (91%)]	Loss: 6.5379	Cost: 6.19s
Train Epoch: 1275 	Average Loss: 7.4995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7231

Learning rate: 0.00019208454801410222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1276 [0/90000 (0%)]	Loss: 21.3960	Cost: 21.20s
Train Epoch: 1276 [20480/90000 (23%)]	Loss: 6.3256	Cost: 5.94s
Train Epoch: 1276 [40960/90000 (45%)]	Loss: 7.5765	Cost: 6.32s
Train Epoch: 1276 [61440/90000 (68%)]	Loss: 7.2469	Cost: 5.81s
Train Epoch: 1276 [81920/90000 (91%)]	Loss: 6.9730	Cost: 5.75s
Train Epoch: 1276 	Average Loss: 7.9404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6115

Learning rate: 0.00019207229353051958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1277 [0/90000 (0%)]	Loss: 21.1554	Cost: 21.94s
Train Epoch: 1277 [20480/90000 (23%)]	Loss: 6.9433	Cost: 5.90s
Train Epoch: 1277 [40960/90000 (45%)]	Loss: 6.9769	Cost: 6.05s
Train Epoch: 1277 [61440/90000 (68%)]	Loss: 6.7954	Cost: 5.81s
Train Epoch: 1277 [81920/90000 (91%)]	Loss: 6.7741	Cost: 5.72s
Train Epoch: 1277 	Average Loss: 7.8697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6566

Learning rate: 0.00019206002995976587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1278 [0/90000 (0%)]	Loss: 20.9531	Cost: 21.15s
Train Epoch: 1278 [20480/90000 (23%)]	Loss: 6.5051	Cost: 5.76s
Train Epoch: 1278 [40960/90000 (45%)]	Loss: 6.7522	Cost: 6.23s
Train Epoch: 1278 [61440/90000 (68%)]	Loss: 6.3636	Cost: 5.64s
Train Epoch: 1278 [81920/90000 (91%)]	Loss: 6.7693	Cost: 5.53s
Train Epoch: 1278 	Average Loss: 7.5686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5898

Learning rate: 0.00019204775730305153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1279 [0/90000 (0%)]	Loss: 21.3349	Cost: 20.32s
Train Epoch: 1279 [20480/90000 (23%)]	Loss: 6.5971	Cost: 6.02s
Train Epoch: 1279 [40960/90000 (45%)]	Loss: 6.5396	Cost: 6.03s
Train Epoch: 1279 [61440/90000 (68%)]	Loss: 6.3309	Cost: 5.83s
Train Epoch: 1279 [81920/90000 (91%)]	Loss: 6.2920	Cost: 5.67s
Train Epoch: 1279 	Average Loss: 7.5180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6954

Learning rate: 0.00019203547556158768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1280 [0/90000 (0%)]	Loss: 21.2595	Cost: 20.59s
Train Epoch: 1280 [20480/90000 (23%)]	Loss: 6.3363	Cost: 5.98s
Train Epoch: 1280 [40960/90000 (45%)]	Loss: 6.6383	Cost: 6.37s
Train Epoch: 1280 [61440/90000 (68%)]	Loss: 6.3523	Cost: 5.79s
Train Epoch: 1280 [81920/90000 (91%)]	Loss: 6.4877	Cost: 5.70s
Train Epoch: 1280 	Average Loss: 7.4453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6929

Learning rate: 0.0001920231847365866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1281 [0/90000 (0%)]	Loss: 21.0735	Cost: 20.53s
Train Epoch: 1281 [20480/90000 (23%)]	Loss: 6.4913	Cost: 5.99s
Train Epoch: 1281 [40960/90000 (45%)]	Loss: 6.6189	Cost: 6.68s
Train Epoch: 1281 [61440/90000 (68%)]	Loss: 6.1208	Cost: 5.83s
Train Epoch: 1281 [81920/90000 (91%)]	Loss: 6.7038	Cost: 6.03s
Train Epoch: 1281 	Average Loss: 7.4435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7397

Learning rate: 0.00019201088482926132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1282 [0/90000 (0%)]	Loss: 21.3635	Cost: 21.08s
Train Epoch: 1282 [20480/90000 (23%)]	Loss: 6.2993	Cost: 5.92s
Train Epoch: 1282 [40960/90000 (45%)]	Loss: 6.4820	Cost: 6.17s
Train Epoch: 1282 [61440/90000 (68%)]	Loss: 6.2078	Cost: 5.81s
Train Epoch: 1282 [81920/90000 (91%)]	Loss: 6.5799	Cost: 5.80s
Train Epoch: 1282 	Average Loss: 7.4351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7172

Learning rate: 0.00019199857584082573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1283 [0/90000 (0%)]	Loss: 21.2980	Cost: 21.68s
Train Epoch: 1283 [20480/90000 (23%)]	Loss: 6.3252	Cost: 6.07s
Train Epoch: 1283 [40960/90000 (45%)]	Loss: 6.4887	Cost: 6.63s
Train Epoch: 1283 [61440/90000 (68%)]	Loss: 6.6265	Cost: 5.93s
Train Epoch: 1283 [81920/90000 (91%)]	Loss: 6.6688	Cost: 5.95s
Train Epoch: 1283 	Average Loss: 7.5112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8362

Learning rate: 0.00019198625777249478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1284 [0/90000 (0%)]	Loss: 21.3605	Cost: 21.75s
Train Epoch: 1284 [20480/90000 (23%)]	Loss: 6.7209	Cost: 5.90s
Train Epoch: 1284 [40960/90000 (45%)]	Loss: 6.5434	Cost: 5.97s
Train Epoch: 1284 [61440/90000 (68%)]	Loss: 6.2597	Cost: 5.82s
Train Epoch: 1284 [81920/90000 (91%)]	Loss: 6.3509	Cost: 5.85s
Train Epoch: 1284 	Average Loss: 7.4431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6978

Learning rate: 0.00019197393062548413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1285 [0/90000 (0%)]	Loss: 21.1964	Cost: 19.92s
Train Epoch: 1285 [20480/90000 (23%)]	Loss: 6.3191	Cost: 5.88s
Train Epoch: 1285 [40960/90000 (45%)]	Loss: 6.4601	Cost: 5.98s
Train Epoch: 1285 [61440/90000 (68%)]	Loss: 5.8782	Cost: 5.85s
Train Epoch: 1285 [81920/90000 (91%)]	Loss: 6.3066	Cost: 5.79s
Train Epoch: 1285 	Average Loss: 7.2181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8040

Learning rate: 0.00019196159440101047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1286 [0/90000 (0%)]	Loss: 21.2486	Cost: 20.65s
Train Epoch: 1286 [20480/90000 (23%)]	Loss: 6.1610	Cost: 5.95s
Train Epoch: 1286 [40960/90000 (45%)]	Loss: 6.1395	Cost: 6.57s
Train Epoch: 1286 [61440/90000 (68%)]	Loss: 6.1056	Cost: 5.81s
Train Epoch: 1286 [81920/90000 (91%)]	Loss: 6.2303	Cost: 5.84s
Train Epoch: 1286 	Average Loss: 7.2295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8177

Learning rate: 0.0001919492491002913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1287 [0/90000 (0%)]	Loss: 21.2165	Cost: 20.44s
Train Epoch: 1287 [20480/90000 (23%)]	Loss: 6.2944	Cost: 5.99s
Train Epoch: 1287 [40960/90000 (45%)]	Loss: 6.5632	Cost: 6.36s
Train Epoch: 1287 [61440/90000 (68%)]	Loss: 6.2894	Cost: 5.88s
Train Epoch: 1287 [81920/90000 (91%)]	Loss: 6.2153	Cost: 5.89s
Train Epoch: 1287 	Average Loss: 7.3180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8750

Learning rate: 0.00019193689472454505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1288 [0/90000 (0%)]	Loss: 21.2992	Cost: 20.75s
Train Epoch: 1288 [20480/90000 (23%)]	Loss: 6.1905	Cost: 6.05s
Train Epoch: 1288 [40960/90000 (45%)]	Loss: 6.1177	Cost: 6.01s
Train Epoch: 1288 [61440/90000 (68%)]	Loss: 5.9027	Cost: 5.83s
Train Epoch: 1288 [81920/90000 (91%)]	Loss: 6.1324	Cost: 5.75s
Train Epoch: 1288 	Average Loss: 7.1928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7948

Learning rate: 0.0001919245312749911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1289 [0/90000 (0%)]	Loss: 21.4477	Cost: 20.15s
Train Epoch: 1289 [20480/90000 (23%)]	Loss: 5.8881	Cost: 5.98s
Train Epoch: 1289 [40960/90000 (45%)]	Loss: 6.2356	Cost: 6.08s
Train Epoch: 1289 [61440/90000 (68%)]	Loss: 6.0605	Cost: 5.82s
Train Epoch: 1289 [81920/90000 (91%)]	Loss: 6.1040	Cost: 5.74s
Train Epoch: 1289 	Average Loss: 7.1449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8682

Learning rate: 0.00019191215875284963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1290 [0/90000 (0%)]	Loss: 21.1199	Cost: 20.35s
Train Epoch: 1290 [20480/90000 (23%)]	Loss: 6.1616	Cost: 6.30s
Train Epoch: 1290 [40960/90000 (45%)]	Loss: 6.1065	Cost: 6.67s
Train Epoch: 1290 [61440/90000 (68%)]	Loss: 6.1783	Cost: 6.52s
Train Epoch: 1290 [81920/90000 (91%)]	Loss: 6.2670	Cost: 6.58s
Train Epoch: 1290 	Average Loss: 7.2220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8113

Learning rate: 0.00019189977715934172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1291 [0/90000 (0%)]	Loss: 21.5534	Cost: 20.26s
Train Epoch: 1291 [20480/90000 (23%)]	Loss: 6.1882	Cost: 5.95s
Train Epoch: 1291 [40960/90000 (45%)]	Loss: 6.3396	Cost: 5.98s
Train Epoch: 1291 [61440/90000 (68%)]	Loss: 6.0461	Cost: 5.83s
Train Epoch: 1291 [81920/90000 (91%)]	Loss: 6.2748	Cost: 5.95s
Train Epoch: 1291 	Average Loss: 7.3065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8166

Learning rate: 0.0001918873864956895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1292 [0/90000 (0%)]	Loss: 21.5016	Cost: 21.81s
Train Epoch: 1292 [20480/90000 (23%)]	Loss: 5.8966	Cost: 5.87s
Train Epoch: 1292 [40960/90000 (45%)]	Loss: 5.9708	Cost: 6.32s
Train Epoch: 1292 [61440/90000 (68%)]	Loss: 5.8607	Cost: 5.62s
Train Epoch: 1292 [81920/90000 (91%)]	Loss: 6.1248	Cost: 5.65s
Train Epoch: 1292 	Average Loss: 7.0658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8672

Learning rate: 0.00019187498676311577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1293 [0/90000 (0%)]	Loss: 21.1989	Cost: 20.62s
Train Epoch: 1293 [20480/90000 (23%)]	Loss: 5.9188	Cost: 5.93s
Train Epoch: 1293 [40960/90000 (45%)]	Loss: 6.1865	Cost: 6.28s
Train Epoch: 1293 [61440/90000 (68%)]	Loss: 5.8907	Cost: 5.80s
Train Epoch: 1293 [81920/90000 (91%)]	Loss: 6.1405	Cost: 6.14s
Train Epoch: 1293 	Average Loss: 7.0973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9722

Learning rate: 0.0001918625779628444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1294 [0/90000 (0%)]	Loss: 21.2516	Cost: 22.66s
Train Epoch: 1294 [20480/90000 (23%)]	Loss: 6.0609	Cost: 5.96s
Train Epoch: 1294 [40960/90000 (45%)]	Loss: 6.5474	Cost: 6.18s
Train Epoch: 1294 [61440/90000 (68%)]	Loss: 6.2454	Cost: 6.02s
Train Epoch: 1294 [81920/90000 (91%)]	Loss: 6.3009	Cost: 5.73s
Train Epoch: 1294 	Average Loss: 7.3110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8750

Learning rate: 0.00019185016009610006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1295 [0/90000 (0%)]	Loss: 21.2792	Cost: 19.58s
Train Epoch: 1295 [20480/90000 (23%)]	Loss: 6.1289	Cost: 6.15s
Train Epoch: 1295 [40960/90000 (45%)]	Loss: 6.4260	Cost: 6.33s
Train Epoch: 1295 [61440/90000 (68%)]	Loss: 6.0809	Cost: 5.82s
Train Epoch: 1295 [81920/90000 (91%)]	Loss: 6.3103	Cost: 5.70s
Train Epoch: 1295 	Average Loss: 7.2850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8070

Learning rate: 0.00019183773316410835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1296 [0/90000 (0%)]	Loss: 21.4663	Cost: 20.59s
Train Epoch: 1296 [20480/90000 (23%)]	Loss: 6.0749	Cost: 6.19s
Train Epoch: 1296 [40960/90000 (45%)]	Loss: 6.3009	Cost: 6.55s
Train Epoch: 1296 [61440/90000 (68%)]	Loss: 6.5406	Cost: 5.80s
Train Epoch: 1296 [81920/90000 (91%)]	Loss: 6.9127	Cost: 5.70s
Train Epoch: 1296 	Average Loss: 7.4570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7633

Learning rate: 0.00019182529716809578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1297 [0/90000 (0%)]	Loss: 21.2378	Cost: 19.93s
Train Epoch: 1297 [20480/90000 (23%)]	Loss: 6.6612	Cost: 6.07s
Train Epoch: 1297 [40960/90000 (45%)]	Loss: 6.6687	Cost: 6.16s
Train Epoch: 1297 [61440/90000 (68%)]	Loss: 6.5265	Cost: 5.92s
Train Epoch: 1297 [81920/90000 (91%)]	Loss: 6.4333	Cost: 5.68s
Train Epoch: 1297 	Average Loss: 7.6361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8726

Learning rate: 0.0001918128521092897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1298 [0/90000 (0%)]	Loss: 21.3282	Cost: 20.18s
Train Epoch: 1298 [20480/90000 (23%)]	Loss: 6.2109	Cost: 6.20s
Train Epoch: 1298 [40960/90000 (45%)]	Loss: 6.5197	Cost: 6.33s
Train Epoch: 1298 [61440/90000 (68%)]	Loss: 6.3298	Cost: 5.89s
Train Epoch: 1298 [81920/90000 (91%)]	Loss: 6.3167	Cost: 5.72s
Train Epoch: 1298 	Average Loss: 7.4306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8765

Learning rate: 0.0001918003979889184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1299 [0/90000 (0%)]	Loss: 21.2416	Cost: 19.94s
Train Epoch: 1299 [20480/90000 (23%)]	Loss: 6.4949	Cost: 6.07s
Train Epoch: 1299 [40960/90000 (45%)]	Loss: 6.7097	Cost: 6.11s
Train Epoch: 1299 [61440/90000 (68%)]	Loss: 6.4017	Cost: 5.90s
Train Epoch: 1299 [81920/90000 (91%)]	Loss: 6.5066	Cost: 5.71s
Train Epoch: 1299 	Average Loss: 7.4115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8144

Learning rate: 0.00019178793480821105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1300 [0/90000 (0%)]	Loss: 21.6037	Cost: 20.32s
Train Epoch: 1300 [20480/90000 (23%)]	Loss: 6.0706	Cost: 6.11s
Train Epoch: 1300 [40960/90000 (45%)]	Loss: 6.2632	Cost: 7.03s
Train Epoch: 1300 [61440/90000 (68%)]	Loss: 5.8277	Cost: 5.88s
Train Epoch: 1300 [81920/90000 (91%)]	Loss: 6.2908	Cost: 5.92s
Train Epoch: 1300 	Average Loss: 7.1633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8987

Learning rate: 0.00019177546256839772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1301 [0/90000 (0%)]	Loss: 21.5412	Cost: 19.81s
Train Epoch: 1301 [20480/90000 (23%)]	Loss: 6.0204	Cost: 6.45s
Train Epoch: 1301 [40960/90000 (45%)]	Loss: 6.4151	Cost: 6.07s
Train Epoch: 1301 [61440/90000 (68%)]	Loss: 6.2571	Cost: 6.28s
Train Epoch: 1301 [81920/90000 (91%)]	Loss: 6.3142	Cost: 6.46s
Train Epoch: 1301 	Average Loss: 7.2719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8532

Learning rate: 0.00019176298127070938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1302 [0/90000 (0%)]	Loss: 21.1289	Cost: 19.37s
Train Epoch: 1302 [20480/90000 (23%)]	Loss: 6.2198	Cost: 6.06s
Train Epoch: 1302 [40960/90000 (45%)]	Loss: 6.3521	Cost: 6.03s
Train Epoch: 1302 [61440/90000 (68%)]	Loss: 6.0941	Cost: 5.88s
Train Epoch: 1302 [81920/90000 (91%)]	Loss: 6.2413	Cost: 5.75s
Train Epoch: 1302 	Average Loss: 7.3216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9078

Learning rate: 0.00019175049091637786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1303 [0/90000 (0%)]	Loss: 20.9368	Cost: 20.69s
Train Epoch: 1303 [20480/90000 (23%)]	Loss: 6.0532	Cost: 6.19s
Train Epoch: 1303 [40960/90000 (45%)]	Loss: 6.3045	Cost: 6.07s
Train Epoch: 1303 [61440/90000 (68%)]	Loss: 6.0981	Cost: 5.84s
Train Epoch: 1303 [81920/90000 (91%)]	Loss: 6.1521	Cost: 5.73s
Train Epoch: 1303 	Average Loss: 7.1768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9506

Learning rate: 0.00019173799150663595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1304 [0/90000 (0%)]	Loss: 21.4111	Cost: 20.17s
Train Epoch: 1304 [20480/90000 (23%)]	Loss: 6.3363	Cost: 6.01s
Train Epoch: 1304 [40960/90000 (45%)]	Loss: 6.4118	Cost: 6.02s
Train Epoch: 1304 [61440/90000 (68%)]	Loss: 6.0683	Cost: 5.82s
Train Epoch: 1304 [81920/90000 (91%)]	Loss: 6.2790	Cost: 5.72s
Train Epoch: 1304 	Average Loss: 7.2492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8400

Learning rate: 0.00019172548304271725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1305 [0/90000 (0%)]	Loss: 21.5794	Cost: 19.65s
Train Epoch: 1305 [20480/90000 (23%)]	Loss: 6.1050	Cost: 6.01s
Train Epoch: 1305 [40960/90000 (45%)]	Loss: 6.2965	Cost: 6.66s
Train Epoch: 1305 [61440/90000 (68%)]	Loss: 6.1035	Cost: 5.98s
Train Epoch: 1305 [81920/90000 (91%)]	Loss: 6.2203	Cost: 6.30s
Train Epoch: 1305 	Average Loss: 7.1743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9782

Learning rate: 0.00019171296552585629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1306 [0/90000 (0%)]	Loss: 21.4156	Cost: 20.28s
Train Epoch: 1306 [20480/90000 (23%)]	Loss: 5.9668	Cost: 5.79s
Train Epoch: 1306 [40960/90000 (45%)]	Loss: 6.0519	Cost: 6.78s
Train Epoch: 1306 [61440/90000 (68%)]	Loss: 5.9404	Cost: 5.89s
Train Epoch: 1306 [81920/90000 (91%)]	Loss: 6.3370	Cost: 5.88s
Train Epoch: 1306 	Average Loss: 7.1381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0487

Learning rate: 0.00019170043895728857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1307 [0/90000 (0%)]	Loss: 21.4414	Cost: 20.10s
Train Epoch: 1307 [20480/90000 (23%)]	Loss: 5.8861	Cost: 6.00s
Train Epoch: 1307 [40960/90000 (45%)]	Loss: 6.0412	Cost: 6.01s
Train Epoch: 1307 [61440/90000 (68%)]	Loss: 5.9207	Cost: 5.83s
Train Epoch: 1307 [81920/90000 (91%)]	Loss: 6.2488	Cost: 5.73s
Train Epoch: 1307 	Average Loss: 7.1110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9980

Learning rate: 0.00019168790333825032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1308 [0/90000 (0%)]	Loss: 21.5612	Cost: 20.15s
Train Epoch: 1308 [20480/90000 (23%)]	Loss: 6.0665	Cost: 5.86s
Train Epoch: 1308 [40960/90000 (45%)]	Loss: 6.1886	Cost: 5.85s
Train Epoch: 1308 [61440/90000 (68%)]	Loss: 5.6595	Cost: 5.65s
Train Epoch: 1308 [81920/90000 (91%)]	Loss: 6.2354	Cost: 5.55s
Train Epoch: 1308 	Average Loss: 7.1033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9574

Learning rate: 0.00019167535866997882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1309 [0/90000 (0%)]	Loss: 21.6704	Cost: 19.85s
Train Epoch: 1309 [20480/90000 (23%)]	Loss: 5.9896	Cost: 6.06s
Train Epoch: 1309 [40960/90000 (45%)]	Loss: 6.1537	Cost: 6.09s
Train Epoch: 1309 [61440/90000 (68%)]	Loss: 5.9366	Cost: 5.84s
Train Epoch: 1309 [81920/90000 (91%)]	Loss: 6.2577	Cost: 5.75s
Train Epoch: 1309 	Average Loss: 7.1703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9905

Learning rate: 0.0001916628049537122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1310 [0/90000 (0%)]	Loss: 21.4344	Cost: 20.01s
Train Epoch: 1310 [20480/90000 (23%)]	Loss: 5.8283	Cost: 6.01s
Train Epoch: 1310 [40960/90000 (45%)]	Loss: 6.2628	Cost: 5.98s
Train Epoch: 1310 [61440/90000 (68%)]	Loss: 5.9575	Cost: 5.84s
Train Epoch: 1310 [81920/90000 (91%)]	Loss: 6.2055	Cost: 5.71s
Train Epoch: 1310 	Average Loss: 7.1513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9581

Learning rate: 0.00019165024219068937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1311 [0/90000 (0%)]	Loss: 21.4602	Cost: 20.21s
Train Epoch: 1311 [20480/90000 (23%)]	Loss: 5.7555	Cost: 6.07s
Train Epoch: 1311 [40960/90000 (45%)]	Loss: 6.0544	Cost: 6.28s
Train Epoch: 1311 [61440/90000 (68%)]	Loss: 5.6206	Cost: 5.83s
Train Epoch: 1311 [81920/90000 (91%)]	Loss: 6.0894	Cost: 5.92s
Train Epoch: 1311 	Average Loss: 7.0019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9758

Learning rate: 0.0001916376703821503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1312 [0/90000 (0%)]	Loss: 21.2028	Cost: 21.02s
Train Epoch: 1312 [20480/90000 (23%)]	Loss: 5.9063	Cost: 6.07s
Train Epoch: 1312 [40960/90000 (45%)]	Loss: 6.2144	Cost: 5.97s
Train Epoch: 1312 [61440/90000 (68%)]	Loss: 5.9539	Cost: 5.81s
Train Epoch: 1312 [81920/90000 (91%)]	Loss: 6.1644	Cost: 5.70s
Train Epoch: 1312 	Average Loss: 7.1201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9801

Learning rate: 0.00019162508952933575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1313 [0/90000 (0%)]	Loss: 21.7904	Cost: 21.38s
Train Epoch: 1313 [20480/90000 (23%)]	Loss: 6.3359	Cost: 5.95s
Train Epoch: 1313 [40960/90000 (45%)]	Loss: 6.3689	Cost: 6.46s
Train Epoch: 1313 [61440/90000 (68%)]	Loss: 6.0519	Cost: 5.82s
Train Epoch: 1313 [81920/90000 (91%)]	Loss: 6.3727	Cost: 5.73s
Train Epoch: 1313 	Average Loss: 7.2567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9265

Learning rate: 0.0001916124996334874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1314 [0/90000 (0%)]	Loss: 21.6073	Cost: 21.39s
Train Epoch: 1314 [20480/90000 (23%)]	Loss: 5.9425	Cost: 5.76s
Train Epoch: 1314 [40960/90000 (45%)]	Loss: 6.3304	Cost: 6.59s
Train Epoch: 1314 [61440/90000 (68%)]	Loss: 6.1253	Cost: 5.64s
Train Epoch: 1314 [81920/90000 (91%)]	Loss: 6.1902	Cost: 5.65s
Train Epoch: 1314 	Average Loss: 7.0998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1349

Learning rate: 0.00019159990069584783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1315 [0/90000 (0%)]	Loss: 21.5655	Cost: 21.15s
Train Epoch: 1315 [20480/90000 (23%)]	Loss: 5.8763	Cost: 6.05s
Train Epoch: 1315 [40960/90000 (45%)]	Loss: 6.3344	Cost: 6.15s
Train Epoch: 1315 [61440/90000 (68%)]	Loss: 5.8482	Cost: 5.84s
Train Epoch: 1315 [81920/90000 (91%)]	Loss: 6.2042	Cost: 5.76s
Train Epoch: 1315 	Average Loss: 7.1341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0972

Learning rate: 0.0001915872927176605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1316 [0/90000 (0%)]	Loss: 21.6733	Cost: 21.35s
Train Epoch: 1316 [20480/90000 (23%)]	Loss: 5.7002	Cost: 6.01s
Train Epoch: 1316 [40960/90000 (45%)]	Loss: 6.1731	Cost: 6.01s
Train Epoch: 1316 [61440/90000 (68%)]	Loss: 6.0148	Cost: 6.01s
Train Epoch: 1316 [81920/90000 (91%)]	Loss: 6.4097	Cost: 5.76s
Train Epoch: 1316 	Average Loss: 7.1464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0752

Learning rate: 0.0001915746757001698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1317 [0/90000 (0%)]	Loss: 21.7741	Cost: 21.21s
Train Epoch: 1317 [20480/90000 (23%)]	Loss: 5.9383	Cost: 5.99s
Train Epoch: 1317 [40960/90000 (45%)]	Loss: 6.1912	Cost: 6.27s
Train Epoch: 1317 [61440/90000 (68%)]	Loss: 5.9556	Cost: 5.82s
Train Epoch: 1317 [81920/90000 (91%)]	Loss: 6.1765	Cost: 5.98s
Train Epoch: 1317 	Average Loss: 7.1213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0537

Learning rate: 0.00019156204964462093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1318 [0/90000 (0%)]	Loss: 21.4283	Cost: 20.14s
Train Epoch: 1318 [20480/90000 (23%)]	Loss: 5.7811	Cost: 6.02s
Train Epoch: 1318 [40960/90000 (45%)]	Loss: 6.0126	Cost: 7.50s
Train Epoch: 1318 [61440/90000 (68%)]	Loss: 5.8480	Cost: 5.81s
Train Epoch: 1318 [81920/90000 (91%)]	Loss: 6.0953	Cost: 5.96s
Train Epoch: 1318 	Average Loss: 7.0197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0105

Learning rate: 0.00019154941455226007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1319 [0/90000 (0%)]	Loss: 21.5539	Cost: 22.08s
Train Epoch: 1319 [20480/90000 (23%)]	Loss: 5.9270	Cost: 5.90s
Train Epoch: 1319 [40960/90000 (45%)]	Loss: 6.2909	Cost: 6.47s
Train Epoch: 1319 [61440/90000 (68%)]	Loss: 5.9785	Cost: 5.76s
Train Epoch: 1319 [81920/90000 (91%)]	Loss: 6.6045	Cost: 5.74s
Train Epoch: 1319 	Average Loss: 7.1943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0182

Learning rate: 0.00019153677042433424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1320 [0/90000 (0%)]	Loss: 21.3033	Cost: 20.61s
Train Epoch: 1320 [20480/90000 (23%)]	Loss: 6.0052	Cost: 6.08s
Train Epoch: 1320 [40960/90000 (45%)]	Loss: 6.3265	Cost: 6.32s
Train Epoch: 1320 [61440/90000 (68%)]	Loss: 5.9124	Cost: 5.85s
Train Epoch: 1320 [81920/90000 (91%)]	Loss: 6.2129	Cost: 5.77s
Train Epoch: 1320 	Average Loss: 7.2060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0679

Learning rate: 0.00019152411726209133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1321 [0/90000 (0%)]	Loss: 21.6925	Cost: 22.47s
Train Epoch: 1321 [20480/90000 (23%)]	Loss: 6.0014	Cost: 6.05s
Train Epoch: 1321 [40960/90000 (45%)]	Loss: 6.2263	Cost: 6.04s
Train Epoch: 1321 [61440/90000 (68%)]	Loss: 5.9633	Cost: 5.86s
Train Epoch: 1321 [81920/90000 (91%)]	Loss: 6.1977	Cost: 6.09s
Train Epoch: 1321 	Average Loss: 7.1806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0263

Learning rate: 0.00019151145506678021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1322 [0/90000 (0%)]	Loss: 21.7684	Cost: 19.10s
Train Epoch: 1322 [20480/90000 (23%)]	Loss: 5.9545	Cost: 6.09s
Train Epoch: 1322 [40960/90000 (45%)]	Loss: 5.9171	Cost: 6.03s
Train Epoch: 1322 [61440/90000 (68%)]	Loss: 5.8516	Cost: 5.97s
Train Epoch: 1322 [81920/90000 (91%)]	Loss: 6.0361	Cost: 5.80s
Train Epoch: 1322 	Average Loss: 7.0070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0251

Learning rate: 0.00019149878383965054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1323 [0/90000 (0%)]	Loss: 21.7734	Cost: 20.53s
Train Epoch: 1323 [20480/90000 (23%)]	Loss: 5.6832	Cost: 6.08s
Train Epoch: 1323 [40960/90000 (45%)]	Loss: 6.1395	Cost: 6.06s
Train Epoch: 1323 [61440/90000 (68%)]	Loss: 6.1387	Cost: 5.88s
Train Epoch: 1323 [81920/90000 (91%)]	Loss: 5.9355	Cost: 5.77s
Train Epoch: 1323 	Average Loss: 6.9691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1289

Learning rate: 0.00019148610358195298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1324 [0/90000 (0%)]	Loss: 21.3347	Cost: 19.93s
Train Epoch: 1324 [20480/90000 (23%)]	Loss: 5.6412	Cost: 6.01s
Train Epoch: 1324 [40960/90000 (45%)]	Loss: 5.7351	Cost: 6.41s
Train Epoch: 1324 [61440/90000 (68%)]	Loss: 5.6977	Cost: 5.84s
Train Epoch: 1324 [81920/90000 (91%)]	Loss: 5.9814	Cost: 6.06s
Train Epoch: 1324 	Average Loss: 6.8700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0539

Learning rate: 0.00019147341429493896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1325 [0/90000 (0%)]	Loss: 21.5961	Cost: 20.53s
Train Epoch: 1325 [20480/90000 (23%)]	Loss: 5.8424	Cost: 5.98s
Train Epoch: 1325 [40960/90000 (45%)]	Loss: 6.0486	Cost: 6.01s
Train Epoch: 1325 [61440/90000 (68%)]	Loss: 5.6498	Cost: 5.87s
Train Epoch: 1325 [81920/90000 (91%)]	Loss: 6.1071	Cost: 5.76s
Train Epoch: 1325 	Average Loss: 6.9642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0848

Learning rate: 0.00019146071597986092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1326 [0/90000 (0%)]	Loss: 21.4589	Cost: 21.69s
Train Epoch: 1326 [20480/90000 (23%)]	Loss: 5.8219	Cost: 5.94s
Train Epoch: 1326 [40960/90000 (45%)]	Loss: 6.0934	Cost: 6.29s
Train Epoch: 1326 [61440/90000 (68%)]	Loss: 5.8599	Cost: 5.85s
Train Epoch: 1326 [81920/90000 (91%)]	Loss: 5.7383	Cost: 5.75s
Train Epoch: 1326 	Average Loss: 6.9100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2831

Learning rate: 0.00019144800863797208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1327 [0/90000 (0%)]	Loss: 21.6478	Cost: 21.41s
Train Epoch: 1327 [20480/90000 (23%)]	Loss: 5.4497	Cost: 5.97s
Train Epoch: 1327 [40960/90000 (45%)]	Loss: 6.3913	Cost: 6.70s
Train Epoch: 1327 [61440/90000 (68%)]	Loss: 6.2185	Cost: 6.02s
Train Epoch: 1327 [81920/90000 (91%)]	Loss: 6.2660	Cost: 5.82s
Train Epoch: 1327 	Average Loss: 7.1106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1160

Learning rate: 0.00019143529227052663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1328 [0/90000 (0%)]	Loss: 21.5093	Cost: 20.80s
Train Epoch: 1328 [20480/90000 (23%)]	Loss: 5.9759	Cost: 5.96s
Train Epoch: 1328 [40960/90000 (45%)]	Loss: 6.1623	Cost: 6.57s
Train Epoch: 1328 [61440/90000 (68%)]	Loss: 6.0352	Cost: 5.91s
Train Epoch: 1328 [81920/90000 (91%)]	Loss: 6.1296	Cost: 6.53s
Train Epoch: 1328 	Average Loss: 7.1493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0244

Learning rate: 0.00019142256687877963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1329 [0/90000 (0%)]	Loss: 21.5099	Cost: 20.27s
Train Epoch: 1329 [20480/90000 (23%)]	Loss: 5.6829	Cost: 5.99s
Train Epoch: 1329 [40960/90000 (45%)]	Loss: 5.9219	Cost: 6.67s
Train Epoch: 1329 [61440/90000 (68%)]	Loss: 5.5930	Cost: 5.95s
Train Epoch: 1329 [81920/90000 (91%)]	Loss: 5.8729	Cost: 7.43s
Train Epoch: 1329 	Average Loss: 6.9211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0395

Learning rate: 0.00019140983246398704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1330 [0/90000 (0%)]	Loss: 21.5390	Cost: 20.69s
Train Epoch: 1330 [20480/90000 (23%)]	Loss: 5.4207	Cost: 5.96s
Train Epoch: 1330 [40960/90000 (45%)]	Loss: 5.8516	Cost: 6.07s
Train Epoch: 1330 [61440/90000 (68%)]	Loss: 5.5854	Cost: 5.93s
Train Epoch: 1330 [81920/90000 (91%)]	Loss: 5.6608	Cost: 6.30s
Train Epoch: 1330 	Average Loss: 6.7461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1468

Learning rate: 0.00019139708902740564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1331 [0/90000 (0%)]	Loss: 21.6517	Cost: 20.99s
Train Epoch: 1331 [20480/90000 (23%)]	Loss: 5.5167	Cost: 5.97s
Train Epoch: 1331 [40960/90000 (45%)]	Loss: 6.2470	Cost: 6.10s
Train Epoch: 1331 [61440/90000 (68%)]	Loss: 6.8703	Cost: 6.00s
Train Epoch: 1331 [81920/90000 (91%)]	Loss: 7.1386	Cost: 6.48s
Train Epoch: 1331 	Average Loss: 7.3188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1441

Learning rate: 0.00019138433657029324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1332 [0/90000 (0%)]	Loss: 21.6477	Cost: 19.58s
Train Epoch: 1332 [20480/90000 (23%)]	Loss: 6.4983	Cost: 5.94s
Train Epoch: 1332 [40960/90000 (45%)]	Loss: 6.7451	Cost: 6.43s
Train Epoch: 1332 [61440/90000 (68%)]	Loss: 6.4043	Cost: 5.87s
Train Epoch: 1332 [81920/90000 (91%)]	Loss: 6.4282	Cost: 6.65s
Train Epoch: 1332 	Average Loss: 7.6058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1089

Learning rate: 0.0001913715750939084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1333 [0/90000 (0%)]	Loss: 21.6254	Cost: 20.81s
Train Epoch: 1333 [20480/90000 (23%)]	Loss: 6.0482	Cost: 5.95s
Train Epoch: 1333 [40960/90000 (45%)]	Loss: 6.0434	Cost: 6.54s
Train Epoch: 1333 [61440/90000 (68%)]	Loss: 5.9465	Cost: 6.15s
Train Epoch: 1333 [81920/90000 (91%)]	Loss: 6.1528	Cost: 5.91s
Train Epoch: 1333 	Average Loss: 7.1095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0754

Learning rate: 0.00019135880459951061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1334 [0/90000 (0%)]	Loss: 21.7686	Cost: 20.87s
Train Epoch: 1334 [20480/90000 (23%)]	Loss: 5.9969	Cost: 5.91s
Train Epoch: 1334 [40960/90000 (45%)]	Loss: 6.2459	Cost: 6.60s
Train Epoch: 1334 [61440/90000 (68%)]	Loss: 5.8071	Cost: 5.80s
Train Epoch: 1334 [81920/90000 (91%)]	Loss: 5.7239	Cost: 5.92s
Train Epoch: 1334 	Average Loss: 7.0628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1239

Learning rate: 0.00019134602508836032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1335 [0/90000 (0%)]	Loss: 21.8468	Cost: 20.52s
Train Epoch: 1335 [20480/90000 (23%)]	Loss: 5.6107	Cost: 5.93s
Train Epoch: 1335 [40960/90000 (45%)]	Loss: 5.7590	Cost: 6.00s
Train Epoch: 1335 [61440/90000 (68%)]	Loss: 5.7621	Cost: 5.84s
Train Epoch: 1335 [81920/90000 (91%)]	Loss: 5.8759	Cost: 5.63s
Train Epoch: 1335 	Average Loss: 6.7952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3084

Learning rate: 0.00019133323656171877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1336 [0/90000 (0%)]	Loss: 21.6192	Cost: 20.90s
Train Epoch: 1336 [20480/90000 (23%)]	Loss: 5.7211	Cost: 5.97s
Train Epoch: 1336 [40960/90000 (45%)]	Loss: 6.1440	Cost: 6.29s
Train Epoch: 1336 [61440/90000 (68%)]	Loss: 5.7659	Cost: 5.77s
Train Epoch: 1336 [81920/90000 (91%)]	Loss: 6.1600	Cost: 6.02s
Train Epoch: 1336 	Average Loss: 6.9796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1376

Learning rate: 0.0001913204390208482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1337 [0/90000 (0%)]	Loss: 21.5237	Cost: 20.63s
Train Epoch: 1337 [20480/90000 (23%)]	Loss: 5.8141	Cost: 5.88s
Train Epoch: 1337 [40960/90000 (45%)]	Loss: 5.9785	Cost: 6.91s
Train Epoch: 1337 [61440/90000 (68%)]	Loss: 5.8742	Cost: 5.80s
Train Epoch: 1337 [81920/90000 (91%)]	Loss: 5.9058	Cost: 6.12s
Train Epoch: 1337 	Average Loss: 6.9183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2141

Learning rate: 0.0001913076324670116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1338 [0/90000 (0%)]	Loss: 21.8522	Cost: 19.53s
Train Epoch: 1338 [20480/90000 (23%)]	Loss: 5.6057	Cost: 6.02s
Train Epoch: 1338 [40960/90000 (45%)]	Loss: 5.9786	Cost: 6.17s
Train Epoch: 1338 [61440/90000 (68%)]	Loss: 5.7480	Cost: 5.80s
Train Epoch: 1338 [81920/90000 (91%)]	Loss: 5.6707	Cost: 5.62s
Train Epoch: 1338 	Average Loss: 6.8170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2287

Learning rate: 0.00019129481690147293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1339 [0/90000 (0%)]	Loss: 21.5436	Cost: 19.76s
Train Epoch: 1339 [20480/90000 (23%)]	Loss: 5.4903	Cost: 5.94s
Train Epoch: 1339 [40960/90000 (45%)]	Loss: 5.8253	Cost: 5.93s
Train Epoch: 1339 [61440/90000 (68%)]	Loss: 5.7595	Cost: 5.80s
Train Epoch: 1339 [81920/90000 (91%)]	Loss: 5.7302	Cost: 5.62s
Train Epoch: 1339 	Average Loss: 6.7657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2369

Learning rate: 0.0001912819923254971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1340 [0/90000 (0%)]	Loss: 21.4987	Cost: 19.70s
Train Epoch: 1340 [20480/90000 (23%)]	Loss: 5.4717	Cost: 5.93s
Train Epoch: 1340 [40960/90000 (45%)]	Loss: 6.1470	Cost: 5.95s
Train Epoch: 1340 [61440/90000 (68%)]	Loss: 5.7848	Cost: 5.79s
Train Epoch: 1340 [81920/90000 (91%)]	Loss: 5.8373	Cost: 5.76s
Train Epoch: 1340 	Average Loss: 6.8034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2429

Learning rate: 0.00019126915874034982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1341 [0/90000 (0%)]	Loss: 21.7260	Cost: 19.60s
Train Epoch: 1341 [20480/90000 (23%)]	Loss: 5.4919	Cost: 6.08s
Train Epoch: 1341 [40960/90000 (45%)]	Loss: 5.8650	Cost: 6.08s
Train Epoch: 1341 [61440/90000 (68%)]	Loss: 5.7106	Cost: 5.84s
Train Epoch: 1341 [81920/90000 (91%)]	Loss: 5.5598	Cost: 5.61s
Train Epoch: 1341 	Average Loss: 6.7248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3017

Learning rate: 0.00019125631614729769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1342 [0/90000 (0%)]	Loss: 21.6653	Cost: 19.69s
Train Epoch: 1342 [20480/90000 (23%)]	Loss: 5.6185	Cost: 6.30s
Train Epoch: 1342 [40960/90000 (45%)]	Loss: 5.4861	Cost: 5.97s
Train Epoch: 1342 [61440/90000 (68%)]	Loss: 5.3946	Cost: 5.80s
Train Epoch: 1342 [81920/90000 (91%)]	Loss: 5.5147	Cost: 5.65s
Train Epoch: 1342 	Average Loss: 6.6187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2949

Learning rate: 0.00019124346454760824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1343 [0/90000 (0%)]	Loss: 21.7291	Cost: 19.37s
Train Epoch: 1343 [20480/90000 (23%)]	Loss: 5.3877	Cost: 5.96s
Train Epoch: 1343 [40960/90000 (45%)]	Loss: 5.5221	Cost: 6.00s
Train Epoch: 1343 [61440/90000 (68%)]	Loss: 5.7187	Cost: 5.81s
Train Epoch: 1343 [81920/90000 (91%)]	Loss: 5.4490	Cost: 5.61s
Train Epoch: 1343 	Average Loss: 6.5933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3134

Learning rate: 0.00019123060394254988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1344 [0/90000 (0%)]	Loss: 22.0538	Cost: 19.75s
Train Epoch: 1344 [20480/90000 (23%)]	Loss: 5.4031	Cost: 5.98s
Train Epoch: 1344 [40960/90000 (45%)]	Loss: 5.6513	Cost: 6.02s
Train Epoch: 1344 [61440/90000 (68%)]	Loss: 5.6738	Cost: 5.79s
Train Epoch: 1344 [81920/90000 (91%)]	Loss: 5.9236	Cost: 5.63s
Train Epoch: 1344 	Average Loss: 6.7784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3495

Learning rate: 0.00019121773433339187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1345 [0/90000 (0%)]	Loss: 21.9501	Cost: 20.61s
Train Epoch: 1345 [20480/90000 (23%)]	Loss: 5.7025	Cost: 5.94s
Train Epoch: 1345 [40960/90000 (45%)]	Loss: 5.9930	Cost: 6.55s
Train Epoch: 1345 [61440/90000 (68%)]	Loss: 5.6500	Cost: 5.80s
Train Epoch: 1345 [81920/90000 (91%)]	Loss: 5.7987	Cost: 6.00s
Train Epoch: 1345 	Average Loss: 6.9044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3580

Learning rate: 0.00019120485572140446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1346 [0/90000 (0%)]	Loss: 22.1443	Cost: 19.93s
Train Epoch: 1346 [20480/90000 (23%)]	Loss: 5.8039	Cost: 5.97s
Train Epoch: 1346 [40960/90000 (45%)]	Loss: 5.7448	Cost: 7.50s
Train Epoch: 1346 [61440/90000 (68%)]	Loss: 5.6932	Cost: 5.74s
Train Epoch: 1346 [81920/90000 (91%)]	Loss: 5.4920	Cost: 5.62s
Train Epoch: 1346 	Average Loss: 6.7101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1711

Learning rate: 0.00019119196810785867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1347 [0/90000 (0%)]	Loss: 21.8426	Cost: 20.83s
Train Epoch: 1347 [20480/90000 (23%)]	Loss: 5.3046	Cost: 5.98s
Train Epoch: 1347 [40960/90000 (45%)]	Loss: 5.4471	Cost: 6.02s
Train Epoch: 1347 [61440/90000 (68%)]	Loss: 5.4409	Cost: 5.83s
Train Epoch: 1347 [81920/90000 (91%)]	Loss: 5.6896	Cost: 5.61s
Train Epoch: 1347 	Average Loss: 6.5516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3571

Learning rate: 0.0001911790714940264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1348 [0/90000 (0%)]	Loss: 22.1443	Cost: 19.97s
Train Epoch: 1348 [20480/90000 (23%)]	Loss: 5.4983	Cost: 6.01s
Train Epoch: 1348 [40960/90000 (45%)]	Loss: 5.6179	Cost: 6.02s
Train Epoch: 1348 [61440/90000 (68%)]	Loss: 5.3151	Cost: 5.77s
Train Epoch: 1348 [81920/90000 (91%)]	Loss: 5.5631	Cost: 5.61s
Train Epoch: 1348 	Average Loss: 6.5942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4709

Learning rate: 0.0001911661658811806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1349 [0/90000 (0%)]	Loss: 21.8799	Cost: 20.55s
Train Epoch: 1349 [20480/90000 (23%)]	Loss: 5.2767	Cost: 5.93s
Train Epoch: 1349 [40960/90000 (45%)]	Loss: 5.6211	Cost: 6.16s
Train Epoch: 1349 [61440/90000 (68%)]	Loss: 5.3948	Cost: 5.79s
Train Epoch: 1349 [81920/90000 (91%)]	Loss: 5.5571	Cost: 5.62s
Train Epoch: 1349 	Average Loss: 6.6021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3426

Learning rate: 0.00019115325127059494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1350 [0/90000 (0%)]	Loss: 21.8032	Cost: 19.94s
Train Epoch: 1350 [20480/90000 (23%)]	Loss: 5.3421	Cost: 5.98s
Train Epoch: 1350 [40960/90000 (45%)]	Loss: 5.8739	Cost: 6.23s
Train Epoch: 1350 [61440/90000 (68%)]	Loss: 5.3311	Cost: 5.82s
Train Epoch: 1350 [81920/90000 (91%)]	Loss: 5.4295	Cost: 5.62s
Train Epoch: 1350 	Average Loss: 6.7082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3084

Learning rate: 0.00019114032766354405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1351 [0/90000 (0%)]	Loss: 22.0618	Cost: 20.06s
Train Epoch: 1351 [20480/90000 (23%)]	Loss: 5.8439	Cost: 5.96s
Train Epoch: 1351 [40960/90000 (45%)]	Loss: 5.7954	Cost: 8.76s
Train Epoch: 1351 [61440/90000 (68%)]	Loss: 5.9571	Cost: 5.72s
Train Epoch: 1351 [81920/90000 (91%)]	Loss: 6.1625	Cost: 5.94s
Train Epoch: 1351 	Average Loss: 7.0280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3471

Learning rate: 0.00019112739506130344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1352 [0/90000 (0%)]	Loss: 21.9134	Cost: 20.02s
Train Epoch: 1352 [20480/90000 (23%)]	Loss: 5.9205	Cost: 6.09s
Train Epoch: 1352 [40960/90000 (45%)]	Loss: 5.9983	Cost: 6.74s
Train Epoch: 1352 [61440/90000 (68%)]	Loss: 5.6802	Cost: 6.50s
Train Epoch: 1352 [81920/90000 (91%)]	Loss: 5.6509	Cost: 6.24s
Train Epoch: 1352 	Average Loss: 6.9386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2168

Learning rate: 0.0001911144534651495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1353 [0/90000 (0%)]	Loss: 21.7938	Cost: 20.47s
Train Epoch: 1353 [20480/90000 (23%)]	Loss: 5.1763	Cost: 5.94s
Train Epoch: 1353 [40960/90000 (45%)]	Loss: 5.4689	Cost: 6.22s
Train Epoch: 1353 [61440/90000 (68%)]	Loss: 6.2404	Cost: 5.79s
Train Epoch: 1353 [81920/90000 (91%)]	Loss: 6.2919	Cost: 5.80s
Train Epoch: 1353 	Average Loss: 6.9614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3050

Learning rate: 0.00019110150287635953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1354 [0/90000 (0%)]	Loss: 21.8045	Cost: 19.97s
Train Epoch: 1354 [20480/90000 (23%)]	Loss: 6.0536	Cost: 5.96s
Train Epoch: 1354 [40960/90000 (45%)]	Loss: 6.0930	Cost: 5.93s
Train Epoch: 1354 [61440/90000 (68%)]	Loss: 5.9596	Cost: 5.81s
Train Epoch: 1354 [81920/90000 (91%)]	Loss: 5.8304	Cost: 5.76s
Train Epoch: 1354 	Average Loss: 7.1803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2802

Learning rate: 0.00019108854329621171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1355 [0/90000 (0%)]	Loss: 21.7346	Cost: 19.40s
Train Epoch: 1355 [20480/90000 (23%)]	Loss: 5.8161	Cost: 5.80s
Train Epoch: 1355 [40960/90000 (45%)]	Loss: 6.1371	Cost: 5.93s
Train Epoch: 1355 [61440/90000 (68%)]	Loss: 5.9541	Cost: 5.64s
Train Epoch: 1355 [81920/90000 (91%)]	Loss: 6.0506	Cost: 5.43s
Train Epoch: 1355 	Average Loss: 7.0943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2959

Learning rate: 0.0001910755747259851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1356 [0/90000 (0%)]	Loss: 21.7745	Cost: 20.51s
Train Epoch: 1356 [20480/90000 (23%)]	Loss: 5.9733	Cost: 5.82s
Train Epoch: 1356 [40960/90000 (45%)]	Loss: 6.1948	Cost: 6.77s
Train Epoch: 1356 [61440/90000 (68%)]	Loss: 5.8141	Cost: 5.58s
Train Epoch: 1356 [81920/90000 (91%)]	Loss: 5.9263	Cost: 5.86s
Train Epoch: 1356 	Average Loss: 6.9488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3310

Learning rate: 0.0001910625971669596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1357 [0/90000 (0%)]	Loss: 21.5590	Cost: 20.31s
Train Epoch: 1357 [20480/90000 (23%)]	Loss: 5.4357	Cost: 5.95s
Train Epoch: 1357 [40960/90000 (45%)]	Loss: 6.0837	Cost: 5.99s
Train Epoch: 1357 [61440/90000 (68%)]	Loss: 6.1061	Cost: 5.79s
Train Epoch: 1357 [81920/90000 (91%)]	Loss: 6.4463	Cost: 5.60s
Train Epoch: 1357 	Average Loss: 7.1162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2853

Learning rate: 0.00019104961062041612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1358 [0/90000 (0%)]	Loss: 21.8080	Cost: 20.35s
Train Epoch: 1358 [20480/90000 (23%)]	Loss: 5.8030	Cost: 6.02s
Train Epoch: 1358 [40960/90000 (45%)]	Loss: 6.1628	Cost: 6.23s
Train Epoch: 1358 [61440/90000 (68%)]	Loss: 5.6197	Cost: 6.02s
Train Epoch: 1358 [81920/90000 (91%)]	Loss: 5.8084	Cost: 5.84s
Train Epoch: 1358 	Average Loss: 7.0090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2707

Learning rate: 0.0001910366150876363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1359 [0/90000 (0%)]	Loss: 21.5754	Cost: 20.90s
Train Epoch: 1359 [20480/90000 (23%)]	Loss: 5.4624	Cost: 6.05s
Train Epoch: 1359 [40960/90000 (45%)]	Loss: 5.6233	Cost: 6.69s
Train Epoch: 1359 [61440/90000 (68%)]	Loss: 5.5358	Cost: 5.79s
Train Epoch: 1359 [81920/90000 (91%)]	Loss: 5.6323	Cost: 5.61s
Train Epoch: 1359 	Average Loss: 6.6754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2818

Learning rate: 0.0001910236105699028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1360 [0/90000 (0%)]	Loss: 21.8680	Cost: 21.20s
Train Epoch: 1360 [20480/90000 (23%)]	Loss: 5.1868	Cost: 5.92s
Train Epoch: 1360 [40960/90000 (45%)]	Loss: 5.4312	Cost: 6.87s
Train Epoch: 1360 [61440/90000 (68%)]	Loss: 5.1037	Cost: 5.77s
Train Epoch: 1360 [81920/90000 (91%)]	Loss: 5.2354	Cost: 5.69s
Train Epoch: 1360 	Average Loss: 6.4563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4093

Learning rate: 0.00019101059706849906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1361 [0/90000 (0%)]	Loss: 21.7685	Cost: 19.15s
Train Epoch: 1361 [20480/90000 (23%)]	Loss: 5.1381	Cost: 6.38s
Train Epoch: 1361 [40960/90000 (45%)]	Loss: 5.4362	Cost: 6.73s
Train Epoch: 1361 [61440/90000 (68%)]	Loss: 5.1686	Cost: 6.44s
Train Epoch: 1361 [81920/90000 (91%)]	Loss: 5.4194	Cost: 6.27s
Train Epoch: 1361 	Average Loss: 6.3582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5006

Learning rate: 0.00019099757458470952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1362 [0/90000 (0%)]	Loss: 21.8768	Cost: 20.84s
Train Epoch: 1362 [20480/90000 (23%)]	Loss: 5.1450	Cost: 6.12s
Train Epoch: 1362 [40960/90000 (45%)]	Loss: 5.4317	Cost: 6.70s
Train Epoch: 1362 [61440/90000 (68%)]	Loss: 5.1153	Cost: 5.94s
Train Epoch: 1362 [81920/90000 (91%)]	Loss: 5.1882	Cost: 5.94s
Train Epoch: 1362 	Average Loss: 6.3661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4961

Learning rate: 0.00019098454311981946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1363 [0/90000 (0%)]	Loss: 21.7880	Cost: 19.81s
Train Epoch: 1363 [20480/90000 (23%)]	Loss: 5.0723	Cost: 6.40s
Train Epoch: 1363 [40960/90000 (45%)]	Loss: 5.3714	Cost: 5.98s
Train Epoch: 1363 [61440/90000 (68%)]	Loss: 5.4038	Cost: 5.79s
Train Epoch: 1363 [81920/90000 (91%)]	Loss: 5.7573	Cost: 5.72s
Train Epoch: 1363 	Average Loss: 6.4764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5158

Learning rate: 0.000190971502675115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1364 [0/90000 (0%)]	Loss: 21.9193	Cost: 20.34s
Train Epoch: 1364 [20480/90000 (23%)]	Loss: 5.6966	Cost: 5.94s
Train Epoch: 1364 [40960/90000 (45%)]	Loss: 5.7977	Cost: 6.85s
Train Epoch: 1364 [61440/90000 (68%)]	Loss: 5.6593	Cost: 5.88s
Train Epoch: 1364 [81920/90000 (91%)]	Loss: 5.7491	Cost: 6.02s
Train Epoch: 1364 	Average Loss: 6.7937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4328

Learning rate: 0.00019095845325188318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1365 [0/90000 (0%)]	Loss: 21.7852	Cost: 20.72s
Train Epoch: 1365 [20480/90000 (23%)]	Loss: 5.3576	Cost: 5.99s
Train Epoch: 1365 [40960/90000 (45%)]	Loss: 5.8435	Cost: 6.03s
Train Epoch: 1365 [61440/90000 (68%)]	Loss: 5.6181	Cost: 5.77s
Train Epoch: 1365 [81920/90000 (91%)]	Loss: 5.5661	Cost: 5.61s
Train Epoch: 1365 	Average Loss: 6.6964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4332

Learning rate: 0.0001909453948514119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1366 [0/90000 (0%)]	Loss: 21.6359	Cost: 20.17s
Train Epoch: 1366 [20480/90000 (23%)]	Loss: 5.3346	Cost: 5.94s
Train Epoch: 1366 [40960/90000 (45%)]	Loss: 5.4620	Cost: 6.68s
Train Epoch: 1366 [61440/90000 (68%)]	Loss: 5.4056	Cost: 5.78s
Train Epoch: 1366 [81920/90000 (91%)]	Loss: 5.5071	Cost: 5.98s
Train Epoch: 1366 	Average Loss: 6.5638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4444

Learning rate: 0.00019093232747499004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1367 [0/90000 (0%)]	Loss: 21.8433	Cost: 20.06s
Train Epoch: 1367 [20480/90000 (23%)]	Loss: 5.4376	Cost: 5.93s
Train Epoch: 1367 [40960/90000 (45%)]	Loss: 5.5818	Cost: 6.27s
Train Epoch: 1367 [61440/90000 (68%)]	Loss: 5.6531	Cost: 5.80s
Train Epoch: 1367 [81920/90000 (91%)]	Loss: 5.7377	Cost: 5.61s
Train Epoch: 1367 	Average Loss: 6.7009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4754

Learning rate: 0.00019091925112390724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1368 [0/90000 (0%)]	Loss: 22.0094	Cost: 20.74s
Train Epoch: 1368 [20480/90000 (23%)]	Loss: 5.7713	Cost: 5.96s
Train Epoch: 1368 [40960/90000 (45%)]	Loss: 5.6748	Cost: 6.00s
Train Epoch: 1368 [61440/90000 (68%)]	Loss: 5.4691	Cost: 5.79s
Train Epoch: 1368 [81920/90000 (91%)]	Loss: 5.6786	Cost: 5.64s
Train Epoch: 1368 	Average Loss: 6.7527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3477

Learning rate: 0.0001909061657994541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1369 [0/90000 (0%)]	Loss: 21.7134	Cost: 20.24s
Train Epoch: 1369 [20480/90000 (23%)]	Loss: 5.1551	Cost: 5.91s
Train Epoch: 1369 [40960/90000 (45%)]	Loss: 5.2408	Cost: 6.40s
Train Epoch: 1369 [61440/90000 (68%)]	Loss: 5.2368	Cost: 5.81s
Train Epoch: 1369 [81920/90000 (91%)]	Loss: 5.0891	Cost: 5.87s
Train Epoch: 1369 	Average Loss: 6.4226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5597

Learning rate: 0.0001908930715029221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1370 [0/90000 (0%)]	Loss: 21.7465	Cost: 21.52s
Train Epoch: 1370 [20480/90000 (23%)]	Loss: 5.1887	Cost: 6.14s
Train Epoch: 1370 [40960/90000 (45%)]	Loss: 5.5370	Cost: 5.98s
Train Epoch: 1370 [61440/90000 (68%)]	Loss: 5.4039	Cost: 5.83s
Train Epoch: 1370 [81920/90000 (91%)]	Loss: 5.5209	Cost: 5.62s
Train Epoch: 1370 	Average Loss: 6.5116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5438

Learning rate: 0.0001908799682356036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1371 [0/90000 (0%)]	Loss: 21.6771	Cost: 20.51s
Train Epoch: 1371 [20480/90000 (23%)]	Loss: 5.2179	Cost: 5.95s
Train Epoch: 1371 [40960/90000 (45%)]	Loss: 5.5831	Cost: 6.48s
Train Epoch: 1371 [61440/90000 (68%)]	Loss: 5.3619	Cost: 5.82s
Train Epoch: 1371 [81920/90000 (91%)]	Loss: 5.5311	Cost: 5.67s
Train Epoch: 1371 	Average Loss: 6.6026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5382

Learning rate: 0.0001908668559987918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1372 [0/90000 (0%)]	Loss: 21.9460	Cost: 20.29s
Train Epoch: 1372 [20480/90000 (23%)]	Loss: 5.2968	Cost: 5.95s
Train Epoch: 1372 [40960/90000 (45%)]	Loss: 5.4922	Cost: 6.93s
Train Epoch: 1372 [61440/90000 (68%)]	Loss: 5.1882	Cost: 5.79s
Train Epoch: 1372 [81920/90000 (91%)]	Loss: 5.3812	Cost: 5.66s
Train Epoch: 1372 	Average Loss: 6.5007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5076

Learning rate: 0.00019085373479378083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1373 [0/90000 (0%)]	Loss: 21.9472	Cost: 19.96s
Train Epoch: 1373 [20480/90000 (23%)]	Loss: 5.0803	Cost: 5.95s
Train Epoch: 1373 [40960/90000 (45%)]	Loss: 5.3634	Cost: 6.01s
Train Epoch: 1373 [61440/90000 (68%)]	Loss: 5.2618	Cost: 5.78s
Train Epoch: 1373 [81920/90000 (91%)]	Loss: 5.1604	Cost: 5.77s
Train Epoch: 1373 	Average Loss: 6.4195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4877

Learning rate: 0.00019084060462186577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1374 [0/90000 (0%)]	Loss: 22.0443	Cost: 20.15s
Train Epoch: 1374 [20480/90000 (23%)]	Loss: 4.8447	Cost: 6.01s
Train Epoch: 1374 [40960/90000 (45%)]	Loss: 5.1142	Cost: 6.30s
Train Epoch: 1374 [61440/90000 (68%)]	Loss: 4.9318	Cost: 5.84s
Train Epoch: 1374 [81920/90000 (91%)]	Loss: 5.1845	Cost: 5.70s
Train Epoch: 1374 	Average Loss: 6.2488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5517

Learning rate: 0.00019082746548434244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1375 [0/90000 (0%)]	Loss: 21.9283	Cost: 20.50s
Train Epoch: 1375 [20480/90000 (23%)]	Loss: 4.9396	Cost: 5.97s
Train Epoch: 1375 [40960/90000 (45%)]	Loss: 5.2422	Cost: 6.47s
Train Epoch: 1375 [61440/90000 (68%)]	Loss: 5.2154	Cost: 5.79s
Train Epoch: 1375 [81920/90000 (91%)]	Loss: 5.1015	Cost: 5.99s
Train Epoch: 1375 	Average Loss: 6.2989
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5012

Learning rate: 0.0001908143173825077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1376 [0/90000 (0%)]	Loss: 21.8280	Cost: 19.61s
Train Epoch: 1376 [20480/90000 (23%)]	Loss: 5.1447	Cost: 6.00s
Train Epoch: 1376 [40960/90000 (45%)]	Loss: 5.7770	Cost: 6.01s
Train Epoch: 1376 [61440/90000 (68%)]	Loss: 5.2835	Cost: 5.80s
Train Epoch: 1376 [81920/90000 (91%)]	Loss: 5.3433	Cost: 5.61s
Train Epoch: 1376 	Average Loss: 6.4016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5708

Learning rate: 0.00019080116031765912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1377 [0/90000 (0%)]	Loss: 21.6669	Cost: 20.17s
Train Epoch: 1377 [20480/90000 (23%)]	Loss: 4.9383	Cost: 5.94s
Train Epoch: 1377 [40960/90000 (45%)]	Loss: 5.4549	Cost: 7.19s
Train Epoch: 1377 [61440/90000 (68%)]	Loss: 5.2212	Cost: 5.78s
Train Epoch: 1377 [81920/90000 (91%)]	Loss: 5.2343	Cost: 6.05s
Train Epoch: 1377 	Average Loss: 6.3571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5516

Learning rate: 0.00019078799429109533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1378 [0/90000 (0%)]	Loss: 22.0392	Cost: 20.32s
Train Epoch: 1378 [20480/90000 (23%)]	Loss: 5.0525	Cost: 5.97s
Train Epoch: 1378 [40960/90000 (45%)]	Loss: 5.2810	Cost: 6.77s
Train Epoch: 1378 [61440/90000 (68%)]	Loss: 5.0141	Cost: 5.83s
Train Epoch: 1378 [81920/90000 (91%)]	Loss: 5.0751	Cost: 5.88s
Train Epoch: 1378 	Average Loss: 6.3104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6334

Learning rate: 0.0001907748193041157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1379 [0/90000 (0%)]	Loss: 22.3660	Cost: 20.20s
Train Epoch: 1379 [20480/90000 (23%)]	Loss: 5.1381	Cost: 5.98s
Train Epoch: 1379 [40960/90000 (45%)]	Loss: 5.4717	Cost: 6.65s
Train Epoch: 1379 [61440/90000 (68%)]	Loss: 5.2119	Cost: 5.77s
Train Epoch: 1379 [81920/90000 (91%)]	Loss: 5.3364	Cost: 5.63s
Train Epoch: 1379 	Average Loss: 6.4701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6350

Learning rate: 0.00019076163535802063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1380 [0/90000 (0%)]	Loss: 22.1020	Cost: 20.63s
Train Epoch: 1380 [20480/90000 (23%)]	Loss: 5.1357	Cost: 5.95s
Train Epoch: 1380 [40960/90000 (45%)]	Loss: 5.4971	Cost: 6.07s
Train Epoch: 1380 [61440/90000 (68%)]	Loss: 5.6625	Cost: 5.82s
Train Epoch: 1380 [81920/90000 (91%)]	Loss: 5.5760	Cost: 5.70s
Train Epoch: 1380 	Average Loss: 6.6442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5166

Learning rate: 0.00019074844245411124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1381 [0/90000 (0%)]	Loss: 21.9709	Cost: 20.28s
Train Epoch: 1381 [20480/90000 (23%)]	Loss: 5.4919	Cost: 6.21s
Train Epoch: 1381 [40960/90000 (45%)]	Loss: 5.5181	Cost: 6.25s
Train Epoch: 1381 [61440/90000 (68%)]	Loss: 5.3630	Cost: 6.04s
Train Epoch: 1381 [81920/90000 (91%)]	Loss: 5.3853	Cost: 5.89s
Train Epoch: 1381 	Average Loss: 6.5469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5703

Learning rate: 0.00019073524059368967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1382 [0/90000 (0%)]	Loss: 22.0731	Cost: 20.71s
Train Epoch: 1382 [20480/90000 (23%)]	Loss: 5.0509	Cost: 5.96s
Train Epoch: 1382 [40960/90000 (45%)]	Loss: 5.2094	Cost: 6.00s
Train Epoch: 1382 [61440/90000 (68%)]	Loss: 5.2089	Cost: 6.01s
Train Epoch: 1382 [81920/90000 (91%)]	Loss: 5.4260	Cost: 5.76s
Train Epoch: 1382 	Average Loss: 6.3894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6510

Learning rate: 0.00019072202977805887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1383 [0/90000 (0%)]	Loss: 22.2862	Cost: 19.96s
Train Epoch: 1383 [20480/90000 (23%)]	Loss: 5.0746	Cost: 6.00s
Train Epoch: 1383 [40960/90000 (45%)]	Loss: 5.5652	Cost: 6.54s
Train Epoch: 1383 [61440/90000 (68%)]	Loss: 5.3652	Cost: 5.81s
Train Epoch: 1383 [81920/90000 (91%)]	Loss: 5.5021	Cost: 5.68s
Train Epoch: 1383 	Average Loss: 6.5146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5768

Learning rate: 0.0001907088100085227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1384 [0/90000 (0%)]	Loss: 21.9691	Cost: 19.83s
Train Epoch: 1384 [20480/90000 (23%)]	Loss: 5.0846	Cost: 5.97s
Train Epoch: 1384 [40960/90000 (45%)]	Loss: 5.4127	Cost: 6.47s
Train Epoch: 1384 [61440/90000 (68%)]	Loss: 5.2413	Cost: 5.82s
Train Epoch: 1384 [81920/90000 (91%)]	Loss: 5.3713	Cost: 6.05s
Train Epoch: 1384 	Average Loss: 6.4752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4644

Learning rate: 0.00019069558128638592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1385 [0/90000 (0%)]	Loss: 21.7441	Cost: 20.03s
Train Epoch: 1385 [20480/90000 (23%)]	Loss: 5.2936	Cost: 5.96s
Train Epoch: 1385 [40960/90000 (45%)]	Loss: 5.5054	Cost: 6.62s
Train Epoch: 1385 [61440/90000 (68%)]	Loss: 5.4340	Cost: 5.81s
Train Epoch: 1385 [81920/90000 (91%)]	Loss: 5.5478	Cost: 5.89s
Train Epoch: 1385 	Average Loss: 6.5114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5776

Learning rate: 0.0001906823436129541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1386 [0/90000 (0%)]	Loss: 21.9982	Cost: 19.34s
Train Epoch: 1386 [20480/90000 (23%)]	Loss: 5.4580	Cost: 6.15s
Train Epoch: 1386 [40960/90000 (45%)]	Loss: 5.5416	Cost: 7.83s
Train Epoch: 1386 [61440/90000 (68%)]	Loss: 5.8941	Cost: 5.80s
Train Epoch: 1386 [81920/90000 (91%)]	Loss: 5.9308	Cost: 5.70s
Train Epoch: 1386 	Average Loss: 6.7663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5360

Learning rate: 0.00019066909698953378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1387 [0/90000 (0%)]	Loss: 21.8381	Cost: 21.24s
Train Epoch: 1387 [20480/90000 (23%)]	Loss: 5.7782	Cost: 5.93s
Train Epoch: 1387 [40960/90000 (45%)]	Loss: 6.4422	Cost: 6.80s
Train Epoch: 1387 [61440/90000 (68%)]	Loss: 6.0509	Cost: 5.80s
Train Epoch: 1387 [81920/90000 (91%)]	Loss: 6.0502	Cost: 5.70s
Train Epoch: 1387 	Average Loss: 7.0528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5361

Learning rate: 0.0001906558414174324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1388 [0/90000 (0%)]	Loss: 21.7295	Cost: 19.41s
Train Epoch: 1388 [20480/90000 (23%)]	Loss: 5.6620	Cost: 6.12s
Train Epoch: 1388 [40960/90000 (45%)]	Loss: 6.1247	Cost: 6.07s
Train Epoch: 1388 [61440/90000 (68%)]	Loss: 5.6318	Cost: 6.48s
Train Epoch: 1388 [81920/90000 (91%)]	Loss: 5.8051	Cost: 6.46s
Train Epoch: 1388 	Average Loss: 6.8057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4332

Learning rate: 0.0001906425768979581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1389 [0/90000 (0%)]	Loss: 22.0254	Cost: 19.37s
Train Epoch: 1389 [20480/90000 (23%)]	Loss: 5.5449	Cost: 6.20s
Train Epoch: 1389 [40960/90000 (45%)]	Loss: 5.8895	Cost: 5.95s
Train Epoch: 1389 [61440/90000 (68%)]	Loss: 5.5221	Cost: 5.87s
Train Epoch: 1389 [81920/90000 (91%)]	Loss: 5.7371	Cost: 5.72s
Train Epoch: 1389 	Average Loss: 6.7267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4248

Learning rate: 0.00019062930343242013
