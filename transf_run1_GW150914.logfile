Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=4096, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=1.0, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_mixed_prior_transfered/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=500, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_mixed_prior_transfered/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Now, transfer learning from alpha=1.0!
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.3152	Cost: 33.43s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.6771	Cost: 9.51s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.6550	Cost: 12.02s
Train Epoch: 1 	Average Loss: 22.0305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9439

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.6365	Cost: 33.20s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 20.2908	Cost: 9.51s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 19.8380	Cost: 12.90s
Train Epoch: 2 	Average Loss: 20.2590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7958

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999998026079186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 19.8187	Cost: 32.90s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 19.2414	Cost: 9.68s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 18.8992	Cost: 12.32s
Train Epoch: 3 	Average Loss: 19.3109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9297

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019999995558678347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 18.8051	Cost: 32.95s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 18.3920	Cost: 9.68s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 18.1621	Cost: 11.75s
Train Epoch: 4 	Average Loss: 18.3852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1746

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.0001999999210431752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 18.1353	Cost: 33.97s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.7188	Cost: 9.80s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 17.3446	Cost: 12.53s
Train Epoch: 5 	Average Loss: 17.6486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7524

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019999987662997035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 17.2012	Cost: 33.60s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 16.9853	Cost: 9.62s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 16.6910	Cost: 12.04s
Train Epoch: 6 	Average Loss: 16.9348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1641

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019999982234717337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 16.7236	Cost: 33.20s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 16.3382	Cost: 10.42s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 16.0851	Cost: 11.62s
Train Epoch: 7 	Average Loss: 16.4024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6057

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 16.2259	Cost: 33.44s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 16.0658	Cost: 10.10s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 15.7534	Cost: 12.37s
Train Epoch: 8 	Average Loss: 16.0067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9053

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.0001999996841728254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 15.8049	Cost: 33.03s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 15.6043	Cost: 9.42s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 15.5014	Cost: 12.54s
Train Epoch: 9 	Average Loss: 15.6522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7628

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 15.4788	Cost: 33.53s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 15.4234	Cost: 9.64s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 15.2648	Cost: 11.63s
Train Epoch: 10 	Average Loss: 15.3100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4839

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019999950652018584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 15.1846	Cost: 33.54s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 15.1864	Cost: 9.80s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 15.0668	Cost: 11.78s
Train Epoch: 11 	Average Loss: 15.1716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1566

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019999940288952797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 15.0039	Cost: 33.01s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 14.8162	Cost: 9.64s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 14.9305	Cost: 11.83s
Train Epoch: 12 	Average Loss: 14.9045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8920

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019999928938932473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 14.8440	Cost: 32.76s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 14.6353	Cost: 9.59s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 14.5055	Cost: 12.59s
Train Epoch: 13 	Average Loss: 14.6910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6182

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.0001999991660195873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 14.5818	Cost: 33.66s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 14.6036	Cost: 9.62s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 14.3909	Cost: 12.21s
Train Epoch: 14 	Average Loss: 14.5530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6243

Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 14.5485	Cost: 32.82s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 14.4008	Cost: 9.44s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 14.3305	Cost: 12.29s
Train Epoch: 15 	Average Loss: 14.3853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5370

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019999888967155963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 14.4764	Cost: 33.82s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 14.1177	Cost: 9.45s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 14.0303	Cost: 12.26s
Train Epoch: 16 	Average Loss: 14.1923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0771

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001999987366932966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 13.9965	Cost: 33.37s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 13.9508	Cost: 10.10s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 13.8840	Cost: 11.12s
Train Epoch: 17 	Average Loss: 13.9988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0938

Learning rate: 0.00019999857384555393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 13.9086	Cost: 33.45s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 13.7765	Cost: 9.36s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 13.6042	Cost: 12.15s
Train Epoch: 18 	Average Loss: 13.7808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8159

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.0001999984011283477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 13.6732	Cost: 33.08s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 13.7178	Cost: 10.10s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 13.5436	Cost: 11.43s
Train Epoch: 19 	Average Loss: 13.5957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5877

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019999821854169497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 13.5342	Cost: 33.77s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 13.3834	Cost: 9.80s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 13.4386	Cost: 11.51s
Train Epoch: 20 	Average Loss: 13.4162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4919

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 13.3614	Cost: 33.57s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 13.3251	Cost: 10.08s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 13.2665	Cost: 11.99s
Train Epoch: 21 	Average Loss: 13.2906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3973

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 13.3288	Cost: 33.10s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 13.3444	Cost: 9.64s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 13.1750	Cost: 11.95s
Train Epoch: 22 	Average Loss: 13.2181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1894

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.00019999761156524272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 13.0671	Cost: 32.86s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 13.0898	Cost: 9.62s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 12.9283	Cost: 11.84s
Train Epoch: 23 	Average Loss: 13.0220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0417

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 13.0212	Cost: 33.44s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 13.0933	Cost: 9.75s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 12.7677	Cost: 11.92s
Train Epoch: 24 	Average Loss: 12.9528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0108

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.00019999715756739833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 12.9112	Cost: 33.60s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 12.7364	Cost: 9.67s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 12.7472	Cost: 12.33s
Train Epoch: 25 	Average Loss: 12.7639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8357

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.000199996915764479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 12.8410	Cost: 33.40s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 12.7957	Cost: 9.64s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 12.8692	Cost: 12.04s
Train Epoch: 26 	Average Loss: 12.7931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7695

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019999666409225975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 12.7466	Cost: 32.65s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 12.5638	Cost: 9.62s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 12.5493	Cost: 12.31s
Train Epoch: 27 	Average Loss: 12.5823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4462

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019999640255076543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 12.3788	Cost: 34.10s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 12.5562	Cost: 9.80s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 12.3539	Cost: 12.54s
Train Epoch: 28 	Average Loss: 12.4884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4515

Learning rate: 0.00019999613114002186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 12.5939	Cost: 33.52s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 12.3346	Cost: 9.64s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 12.3729	Cost: 12.60s
Train Epoch: 29 	Average Loss: 12.3648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4748

Learning rate: 0.0001999958498600558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 12.3619	Cost: 33.70s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 12.3055	Cost: 9.64s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 12.1461	Cost: 12.06s
Train Epoch: 30 	Average Loss: 12.3060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3626

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.000199995558710895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 12.3602	Cost: 33.82s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 12.2754	Cost: 10.12s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 12.4369	Cost: 12.47s
Train Epoch: 31 	Average Loss: 12.2695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3653

Learning rate: 0.00019999525769256825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 12.3792	Cost: 33.60s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 12.1678	Cost: 9.64s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 12.1205	Cost: 12.42s
Train Epoch: 32 	Average Loss: 12.1518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2192

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.00019999494680510518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 12.1249	Cost: 33.55s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 12.2000	Cost: 9.43s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 12.0194	Cost: 12.45s
Train Epoch: 33 	Average Loss: 12.0744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9847

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019999462604853658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 11.9636	Cost: 34.15s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 11.9628	Cost: 9.60s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 11.9481	Cost: 13.05s
Train Epoch: 34 	Average Loss: 11.9551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9459

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019999429542289402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 11.9010	Cost: 33.48s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 11.8727	Cost: 9.52s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 11.8669	Cost: 12.32s
Train Epoch: 35 	Average Loss: 11.8651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9396

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.00019999395492821016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 11.8907	Cost: 33.13s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 11.7757	Cost: 9.49s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 11.6988	Cost: 13.27s
Train Epoch: 36 	Average Loss: 11.7836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9102

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.0001999936045645186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 11.7243	Cost: 33.14s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 11.8640	Cost: 9.49s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 11.6737	Cost: 12.02s
Train Epoch: 37 	Average Loss: 11.7309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7908

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.00019999324433185394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 11.7197	Cost: 33.39s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 11.6649	Cost: 9.49s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 11.8207	Cost: 13.06s
Train Epoch: 38 	Average Loss: 11.7130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7410

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.0001999928742302517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 11.6262	Cost: 33.23s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 11.5985	Cost: 9.60s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 11.5866	Cost: 11.35s
Train Epoch: 39 	Average Loss: 11.6071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6033

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019999249425974844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 11.4974	Cost: 33.05s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 11.5470	Cost: 9.46s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 11.4563	Cost: 11.76s
Train Epoch: 40 	Average Loss: 11.5001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6683

Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 11.5472	Cost: 33.58s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 11.3957	Cost: 9.48s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 11.4722	Cost: 13.14s
Train Epoch: 41 	Average Loss: 11.4147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5053

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019999170471218976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 11.3203	Cost: 33.69s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 11.4619	Cost: 9.48s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 11.4461	Cost: 12.45s
Train Epoch: 42 	Average Loss: 11.3560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4888

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.0001999912951352123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 11.5414	Cost: 33.88s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 11.3150	Cost: 9.48s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 11.4680	Cost: 13.49s
Train Epoch: 43 	Average Loss: 11.2962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3860

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.00019999087568948966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 11.2995	Cost: 33.60s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 11.2154	Cost: 9.48s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 11.2045	Cost: 12.44s
Train Epoch: 44 	Average Loss: 11.2587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2051

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 0.0001999904463750632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 11.2301	Cost: 33.40s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 11.2643	Cost: 9.46s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 11.2312	Cost: 11.78s
Train Epoch: 45 	Average Loss: 11.1901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1657

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019999000719197536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 11.1094	Cost: 33.52s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 11.1206	Cost: 9.46s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 11.1210	Cost: 11.48s
Train Epoch: 46 	Average Loss: 11.1303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2524

Learning rate: 0.00019998955814026943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 11.1220	Cost: 33.06s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 11.0677	Cost: 9.47s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 11.0473	Cost: 11.61s
Train Epoch: 47 	Average Loss: 11.0538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0778

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 0.00019998909921998973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 10.9962	Cost: 32.89s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 11.0906	Cost: 9.63s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 10.9402	Cost: 12.98s
Train Epoch: 48 	Average Loss: 11.0164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0134

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 0.0001999886304311816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 10.9191	Cost: 34.02s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 11.0253	Cost: 9.47s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 10.9862	Cost: 11.78s
Train Epoch: 49 	Average Loss: 10.9246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9354

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019998815177389132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 10.9214	Cost: 33.33s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 10.8246	Cost: 9.47s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 10.8207	Cost: 12.24s
Train Epoch: 50 	Average Loss: 10.9089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9069

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 10.8438	Cost: 33.90s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 10.8672	Cost: 9.47s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 10.7613	Cost: 12.62s
Train Epoch: 51 	Average Loss: 10.7983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8692

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019998716485405404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 10.8123	Cost: 33.26s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 10.7606	Cost: 9.47s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 10.7874	Cost: 11.93s
Train Epoch: 52 	Average Loss: 10.7823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7334

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 0.0001999866565916045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 10.8369	Cost: 33.22s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 10.7465	Cost: 9.47s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 10.6858	Cost: 13.18s
Train Epoch: 53 	Average Loss: 10.7399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7941

Learning rate: 0.0001999861384608676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 10.7435	Cost: 33.38s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 10.7457	Cost: 9.46s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 10.6937	Cost: 11.71s
Train Epoch: 54 	Average Loss: 10.7039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7023

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 0.00019998561046189446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 10.6843	Cost: 33.67s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 10.7128	Cost: 9.48s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 10.5693	Cost: 13.52s
Train Epoch: 55 	Average Loss: 10.6693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7380

Learning rate: 0.00019998507259473718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 10.6583	Cost: 33.30s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 10.7237	Cost: 9.49s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 10.5673	Cost: 12.24s
Train Epoch: 56 	Average Loss: 10.5955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6691

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019998452485944885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 10.6832	Cost: 33.38s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 10.6065	Cost: 9.47s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 10.3981	Cost: 12.14s
Train Epoch: 57 	Average Loss: 10.5311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6233

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 0.00019998396725608354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 10.3986	Cost: 33.10s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 10.4897	Cost: 9.47s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 10.5162	Cost: 13.45s
Train Epoch: 58 	Average Loss: 10.5320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5920

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 10.6193	Cost: 33.37s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 10.5929	Cost: 9.48s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 10.4728	Cost: 11.73s
Train Epoch: 59 	Average Loss: 10.4868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6262

Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 10.6053	Cost: 33.55s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 10.4014	Cost: 9.48s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 10.3361	Cost: 12.86s
Train Epoch: 60 	Average Loss: 10.4691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3905

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 10.4936	Cost: 33.03s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 10.4297	Cost: 9.47s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 10.3572	Cost: 12.95s
Train Epoch: 61 	Average Loss: 10.3547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5595

Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 10.5589	Cost: 33.69s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 10.4005	Cost: 9.45s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 10.3960	Cost: 12.08s
Train Epoch: 62 	Average Loss: 10.3838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5587

Learning rate: 0.00019998103122006246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 10.4348	Cost: 33.75s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 10.3368	Cost: 9.47s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 10.2634	Cost: 13.48s
Train Epoch: 63 	Average Loss: 10.3407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3149

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 0.00019998041440942506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 10.2377	Cost: 33.40s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 10.2747	Cost: 9.47s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 10.2769	Cost: 12.33s
Train Epoch: 64 	Average Loss: 10.2692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3768

Learning rate: 0.00019997978773111632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 10.3529	Cost: 33.46s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 10.3057	Cost: 9.47s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 10.1478	Cost: 12.21s
Train Epoch: 65 	Average Loss: 10.2132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2379

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 0.00019997915118519813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 10.2449	Cost: 33.21s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 10.2803	Cost: 9.48s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 10.0929	Cost: 13.19s
Train Epoch: 66 	Average Loss: 10.2006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2320

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.0001999785047717333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 10.3527	Cost: 33.24s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 10.1627	Cost: 9.50s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 10.1334	Cost: 12.37s
Train Epoch: 67 	Average Loss: 10.1928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3841

Learning rate: 0.00019997784849078566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 10.2032	Cost: 33.99s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 10.1384	Cost: 9.48s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 10.1330	Cost: 12.71s
Train Epoch: 68 	Average Loss: 10.1528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2326

Learning rate: 0.00019997718234242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 10.0479	Cost: 33.14s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 10.1345	Cost: 9.46s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 10.1237	Cost: 11.96s
Train Epoch: 69 	Average Loss: 10.1095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1283

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Learning rate: 0.00019997650632670199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 10.1060	Cost: 33.50s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 10.2367	Cost: 9.50s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 9.9861	Cost: 11.95s
Train Epoch: 70 	Average Loss: 10.0812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1275

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Learning rate: 0.0001999758204436984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 10.0566	Cost: 33.19s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 10.1061	Cost: 9.47s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 10.2019	Cost: 11.71s
Train Epoch: 71 	Average Loss: 10.0333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0417

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00019997512469347695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 10.0811	Cost: 33.40s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 9.9129	Cost: 9.48s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 9.8750	Cost: 11.93s
Train Epoch: 72 	Average Loss: 9.9531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0966

Learning rate: 0.00019997441907610624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 10.0349	Cost: 33.69s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 10.0006	Cost: 9.49s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 9.9032	Cost: 12.45s
Train Epoch: 73 	Average Loss: 9.9683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0268

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Learning rate: 0.00019997370359165596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 9.9733	Cost: 33.78s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 9.8904	Cost: 9.51s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 9.8671	Cost: 12.28s
Train Epoch: 74 	Average Loss: 9.8890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0221

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.0001999729782401967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 9.9488	Cost: 33.80s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 9.9086	Cost: 9.52s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 9.8883	Cost: 12.66s
Train Epoch: 75 	Average Loss: 9.8878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9931

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 10.1217	Cost: 33.67s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 9.9123	Cost: 9.49s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 9.7346	Cost: 12.76s
Train Epoch: 76 	Average Loss: 9.8582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8557

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00019997149793653861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 9.8888	Cost: 34.06s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 9.9460	Cost: 9.49s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 9.7713	Cost: 13.21s
Train Epoch: 77 	Average Loss: 9.8080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8116

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Learning rate: 0.00019997074298448586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 9.7572	Cost: 33.87s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 9.8285	Cost: 9.46s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 9.8009	Cost: 12.65s
Train Epoch: 78 	Average Loss: 9.8103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8835

Learning rate: 0.00019996997816571638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 9.8807	Cost: 33.46s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 9.8152	Cost: 9.47s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 9.6622	Cost: 11.73s
Train Epoch: 79 	Average Loss: 9.7382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8151

Learning rate: 0.00019996920348030559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 9.7668	Cost: 33.34s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 9.6665	Cost: 9.48s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 9.8731	Cost: 12.21s
Train Epoch: 80 	Average Loss: 9.7088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7346

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892832998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 9.7410	Cost: 32.89s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 9.7865	Cost: 9.49s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 9.7161	Cost: 13.14s
Train Epoch: 81 	Average Loss: 9.7009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7429

Learning rate: 0.00019996762450986697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 9.8519	Cost: 34.20s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 9.7467	Cost: 9.48s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 9.7402	Cost: 13.02s
Train Epoch: 82 	Average Loss: 9.7279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6998

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Learning rate: 0.00019996682022499498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 9.6606	Cost: 33.42s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 9.7995	Cost: 9.49s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 9.6344	Cost: 12.85s
Train Epoch: 83 	Average Loss: 9.6415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7480

Learning rate: 0.0001999660060737934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 9.7205	Cost: 33.02s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 9.6444	Cost: 9.47s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 9.6117	Cost: 11.93s
Train Epoch: 84 	Average Loss: 9.6401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6686

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 0.00019996518205634255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 9.6744	Cost: 33.13s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 9.7054	Cost: 9.46s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 9.5220	Cost: 11.65s
Train Epoch: 85 	Average Loss: 9.5764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5979

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Learning rate: 0.0001999643481727238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 9.6152	Cost: 33.32s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 9.5742	Cost: 9.46s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 9.5533	Cost: 12.56s
Train Epoch: 86 	Average Loss: 9.5692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6828

Learning rate: 0.0001999635044230194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 9.5633	Cost: 33.29s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 9.5731	Cost: 9.47s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 9.5607	Cost: 11.91s
Train Epoch: 87 	Average Loss: 9.5523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5670

Saving model as e87_model.pt & e87_waveforms_supplementary.hdf5
Learning rate: 0.00019996265080731267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 9.5986	Cost: 33.54s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 9.4345	Cost: 9.45s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 9.4656	Cost: 11.65s
Train Epoch: 88 	Average Loss: 9.5120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5024

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 0.00019996178732568782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 9.5670	Cost: 33.18s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 9.4886	Cost: 9.47s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 9.4862	Cost: 11.94s
Train Epoch: 89 	Average Loss: 9.4768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5962

Learning rate: 0.00019996091397823007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 9.5236	Cost: 34.24s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 9.4783	Cost: 9.47s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 9.4970	Cost: 11.95s
Train Epoch: 90 	Average Loss: 9.4609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5217

Learning rate: 0.00019996003076502562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 9.4481	Cost: 33.36s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 9.4266	Cost: 9.52s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 9.3971	Cost: 13.29s
Train Epoch: 91 	Average Loss: 9.4432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5774

Learning rate: 0.0001999591376861617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 9.5180	Cost: 34.15s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 9.4579	Cost: 9.47s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 9.3049	Cost: 12.79s
Train Epoch: 92 	Average Loss: 9.4157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5154

Learning rate: 0.0001999582347417264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 9.4673	Cost: 33.85s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 9.4326	Cost: 9.48s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 9.3483	Cost: 12.36s
Train Epoch: 93 	Average Loss: 9.3866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4718

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 0.00019995732193180883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 9.4885	Cost: 33.81s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 9.5199	Cost: 9.47s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 9.3440	Cost: 12.64s
Train Epoch: 94 	Average Loss: 9.3690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4545

Saving model as e94_model.pt & e94_waveforms_supplementary.hdf5
Learning rate: 0.00019995639925649909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 9.4832	Cost: 33.37s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 9.2911	Cost: 9.45s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 9.2891	Cost: 12.46s
Train Epoch: 95 	Average Loss: 9.3422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4641

Learning rate: 0.00019995546671588827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 9.4877	Cost: 34.62s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 9.4314	Cost: 9.49s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 9.4458	Cost: 11.74s
Train Epoch: 96 	Average Loss: 9.3620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4729

Learning rate: 0.0001999545243100684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 9.4212	Cost: 33.67s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 9.3418	Cost: 9.50s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 9.2627	Cost: 12.66s
Train Epoch: 97 	Average Loss: 9.3306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4069

Saving model as e97_model.pt & e97_waveforms_supplementary.hdf5
Learning rate: 0.00019995357203913245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 9.3769	Cost: 33.30s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 9.3257	Cost: 9.47s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 9.3214	Cost: 11.70s
Train Epoch: 98 	Average Loss: 9.2919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3933

Saving model as e98_model.pt & e98_waveforms_supplementary.hdf5
Learning rate: 0.00019995260990317447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 9.3737	Cost: 33.78s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 9.1753	Cost: 9.46s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 9.1322	Cost: 12.70s
Train Epoch: 99 	Average Loss: 9.2507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3593

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Learning rate: 0.00019995163790228936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 9.2403	Cost: 33.64s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 9.1908	Cost: 9.47s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 9.1899	Cost: 13.11s
Train Epoch: 100 	Average Loss: 9.2052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2470

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 0.0001999506560365731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 9.1922	Cost: 33.27s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 9.3448	Cost: 9.49s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 9.1591	Cost: 13.39s
Train Epoch: 101 	Average Loss: 9.2103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3359

Learning rate: 0.00019994966430612258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 9.3459	Cost: 33.44s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 9.1743	Cost: 9.48s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 9.3077	Cost: 13.22s
Train Epoch: 102 	Average Loss: 9.2493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4331

Learning rate: 0.00019994866271103568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 9.3833	Cost: 33.73s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 9.2348	Cost: 9.48s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 9.1606	Cost: 13.42s
Train Epoch: 103 	Average Loss: 9.2340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2815

Learning rate: 0.0001999476512514112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 9.2191	Cost: 33.36s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 9.0363	Cost: 9.49s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 9.0877	Cost: 12.00s
Train Epoch: 104 	Average Loss: 9.1410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2409

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Learning rate: 0.00019994662992734905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 9.1642	Cost: 33.00s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 9.1359	Cost: 9.49s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 9.1347	Cost: 12.80s
Train Epoch: 105 	Average Loss: 9.1151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1648

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00019994559873894998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 9.1901	Cost: 33.43s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 8.9749	Cost: 9.47s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 9.1827	Cost: 13.05s
Train Epoch: 106 	Average Loss: 9.1331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1925

Learning rate: 0.00019994455768631577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 9.2064	Cost: 33.55s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 9.0430	Cost: 9.49s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 8.9976	Cost: 12.01s
Train Epoch: 107 	Average Loss: 9.0977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1728

Learning rate: 0.00019994350676954918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 9.2294	Cost: 33.43s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 9.0136	Cost: 9.48s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 9.0019	Cost: 12.29s
Train Epoch: 108 	Average Loss: 9.0548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1389

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Learning rate: 0.00019994244598875392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 9.1922	Cost: 33.53s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 9.0325	Cost: 9.51s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 8.9932	Cost: 13.41s
Train Epoch: 109 	Average Loss: 9.0435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1960

Learning rate: 0.00019994137534403472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 9.1910	Cost: 33.60s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 9.0851	Cost: 9.47s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 9.0258	Cost: 12.61s
Train Epoch: 110 	Average Loss: 9.0546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1487

Learning rate: 0.00019994029483549723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 9.1840	Cost: 33.34s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 9.0902	Cost: 9.49s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 9.0260	Cost: 12.14s
Train Epoch: 111 	Average Loss: 9.0148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1685

Learning rate: 0.00019993920446324803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 9.0966	Cost: 33.41s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 8.9764	Cost: 9.48s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 8.9210	Cost: 12.12s
Train Epoch: 112 	Average Loss: 8.9751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1232

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Learning rate: 0.00019993810422739487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 9.0155	Cost: 33.91s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 9.0390	Cost: 9.46s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 9.0247	Cost: 12.06s
Train Epoch: 113 	Average Loss: 8.9903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1511

Learning rate: 0.00019993699412804622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 9.1152	Cost: 33.15s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 8.9912	Cost: 9.48s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 8.9290	Cost: 11.64s
Train Epoch: 114 	Average Loss: 8.9665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1580

Learning rate: 0.00019993587416531166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 9.0767	Cost: 33.78s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 8.9108	Cost: 9.48s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 8.8763	Cost: 12.74s
Train Epoch: 115 	Average Loss: 8.9220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0687

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Learning rate: 0.00019993474433930176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 9.1664	Cost: 34.10s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 8.9288	Cost: 9.48s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 8.8661	Cost: 13.01s
Train Epoch: 116 	Average Loss: 8.9339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0029

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Learning rate: 0.000199933604650128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 9.0388	Cost: 33.78s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 8.8193	Cost: 9.46s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 8.8710	Cost: 13.10s
Train Epoch: 117 	Average Loss: 8.8833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9763

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 0.0001999324550979029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 8.9985	Cost: 34.38s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 8.8223	Cost: 9.49s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 8.9262	Cost: 13.38s
Train Epoch: 118 	Average Loss: 8.8506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0188

Learning rate: 0.00019993129568273988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 9.0571	Cost: 33.74s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 8.9185	Cost: 9.50s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 8.8732	Cost: 12.94s
Train Epoch: 119 	Average Loss: 8.8534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1198

Learning rate: 0.0001999301264047534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 9.0728	Cost: 32.73s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 8.8462	Cost: 9.46s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 8.8908	Cost: 12.20s
Train Epoch: 120 	Average Loss: 8.8539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9174

Saving model as e120_model.pt & e120_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 8.8791	Cost: 33.39s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 8.8156	Cost: 9.47s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 8.7683	Cost: 12.04s
Train Epoch: 121 	Average Loss: 8.8166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9385

Learning rate: 0.00019992775826077256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 8.8488	Cost: 33.14s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 8.8187	Cost: 9.51s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 8.7508	Cost: 11.65s
Train Epoch: 122 	Average Loss: 8.7754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8896

Saving model as e122_model.pt & e122_waveforms_supplementary.hdf5
Learning rate: 0.00019992655939501196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 8.9385	Cost: 33.45s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 8.7660	Cost: 9.47s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 8.7643	Cost: 12.21s
Train Epoch: 123 	Average Loss: 8.8143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0097

Learning rate: 0.00019992535066689534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 8.9542	Cost: 33.84s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 8.7840	Cost: 9.50s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 8.7034	Cost: 12.59s
Train Epoch: 124 	Average Loss: 8.7564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9038

Learning rate: 0.00019992413207654198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 8.8898	Cost: 33.60s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 8.6025	Cost: 9.47s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 8.6982	Cost: 12.16s
Train Epoch: 125 	Average Loss: 8.7492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9081

Learning rate: 0.0001999229036240722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 8.8709	Cost: 33.15s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 8.7052	Cost: 9.47s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 8.7136	Cost: 13.19s
Train Epoch: 126 	Average Loss: 8.7020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8624

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Learning rate: 0.0001999216653096072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 8.8322	Cost: 33.09s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 8.6382	Cost: 9.48s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 8.7346	Cost: 13.04s
Train Epoch: 127 	Average Loss: 8.7121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8512

Saving model as e127_model.pt & e127_waveforms_supplementary.hdf5
Learning rate: 0.00019992041713326917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 8.7266	Cost: 33.50s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 8.6783	Cost: 9.48s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 8.6820	Cost: 11.87s
Train Epoch: 128 	Average Loss: 8.7060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9031

Learning rate: 0.00019991915909518135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 8.9086	Cost: 33.21s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 8.5867	Cost: 9.46s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 8.5966	Cost: 13.29s
Train Epoch: 129 	Average Loss: 8.6559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7694

Saving model as e129_model.pt & e129_waveforms_supplementary.hdf5
Learning rate: 0.0001999178911954679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 8.7761	Cost: 33.31s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 8.6926	Cost: 9.48s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 8.5941	Cost: 11.77s
Train Epoch: 130 	Average Loss: 8.6764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7821

Learning rate: 0.0001999166134342539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 8.8155	Cost: 33.13s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 8.6733	Cost: 9.48s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 8.6791	Cost: 13.51s
Train Epoch: 131 	Average Loss: 8.6299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8548

Learning rate: 0.00019991532581166554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 8.7964	Cost: 33.83s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 8.6151	Cost: 9.79s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 8.5481	Cost: 11.59s
Train Epoch: 132 	Average Loss: 8.6392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7592

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Learning rate: 0.00019991402832782987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 8.7723	Cost: 33.66s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 8.6055	Cost: 9.46s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 8.5491	Cost: 13.17s
Train Epoch: 133 	Average Loss: 8.5811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8143

Learning rate: 0.00019991272098287494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 8.7079	Cost: 34.01s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 8.5838	Cost: 9.48s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 8.6205	Cost: 11.92s
Train Epoch: 134 	Average Loss: 8.5990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6991

Saving model as e134_model.pt & e134_waveforms_supplementary.hdf5
Learning rate: 0.00019991140377692977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 8.6828	Cost: 33.08s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 8.5748	Cost: 9.47s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 8.5711	Cost: 13.29s
Train Epoch: 135 	Average Loss: 8.5945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7948

Learning rate: 0.0001999100767101244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 8.7111	Cost: 33.87s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 8.5133	Cost: 9.50s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 8.5886	Cost: 13.07s
Train Epoch: 136 	Average Loss: 8.5725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7696

Learning rate: 0.00019990873978258976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 8.6862	Cost: 33.63s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 8.5944	Cost: 9.42s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 8.5840	Cost: 12.27s
Train Epoch: 137 	Average Loss: 8.5621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7025

Learning rate: 0.0001999073929944578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 8.7155	Cost: 33.32s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 8.4134	Cost: 9.47s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 8.5051	Cost: 11.71s
Train Epoch: 138 	Average Loss: 8.5000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6436

Saving model as e138_model.pt & e138_waveforms_supplementary.hdf5
Learning rate: 0.00019990603634586154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 8.7570	Cost: 33.18s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 8.5204	Cost: 9.48s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 8.4716	Cost: 13.18s
Train Epoch: 139 	Average Loss: 8.5431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6581

Learning rate: 0.00019990466983693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 8.6305	Cost: 34.58s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 8.4480	Cost: 9.46s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 8.4616	Cost: 12.07s
Train Epoch: 140 	Average Loss: 8.4921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6303

Saving model as e140_model.pt & e140_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 8.6766	Cost: 33.65s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 8.4783	Cost: 9.47s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 8.4676	Cost: 13.51s
Train Epoch: 141 	Average Loss: 8.5120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6666

Learning rate: 0.00019990190723863022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 8.6044	Cost: 33.27s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 8.5053	Cost: 9.46s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 8.4699	Cost: 12.03s
Train Epoch: 142 	Average Loss: 8.4664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7116

Learning rate: 0.00019990051114952508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 8.6123	Cost: 33.00s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 8.5431	Cost: 9.43s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 8.4021	Cost: 13.09s
Train Epoch: 143 	Average Loss: 8.4781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5836

Saving model as e143_model.pt & e143_waveforms_supplementary.hdf5
Learning rate: 0.0001998991052006348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 8.5822	Cost: 33.16s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 8.3759	Cost: 9.49s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 8.3756	Cost: 11.85s
Train Epoch: 144 	Average Loss: 8.4294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5421

Saving model as e144_model.pt & e144_waveforms_supplementary.hdf5
Learning rate: 0.0001998976893920981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 8.4790	Cost: 32.82s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 8.3275	Cost: 9.48s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 8.3504	Cost: 11.79s
Train Epoch: 145 	Average Loss: 8.3831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6098

Learning rate: 0.00019989626372405477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 8.4722	Cost: 33.55s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 8.4643	Cost: 9.46s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 8.4198	Cost: 12.12s
Train Epoch: 146 	Average Loss: 8.4022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6370

Learning rate: 0.00019989482819664545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 8.5567	Cost: 32.84s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 8.3668	Cost: 9.47s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 8.3935	Cost: 13.33s
Train Epoch: 147 	Average Loss: 8.3806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5541

Learning rate: 0.00019989338281001189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 8.6000	Cost: 33.58s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 8.3446	Cost: 9.46s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 8.3106	Cost: 12.42s
Train Epoch: 148 	Average Loss: 8.3607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5383

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 0.00019989192756429667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 8.4463	Cost: 33.06s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 8.3224	Cost: 9.48s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 8.3683	Cost: 13.41s
Train Epoch: 149 	Average Loss: 8.3648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6075

Learning rate: 0.00019989046245964345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 8.5392	Cost: 33.68s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 8.3429	Cost: 9.50s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 8.4056	Cost: 12.31s
Train Epoch: 150 	Average Loss: 8.3777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5483

Learning rate: 0.00019988898749619688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 8.5996	Cost: 33.43s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 8.4568	Cost: 9.49s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 8.3399	Cost: 12.51s
Train Epoch: 151 	Average Loss: 8.3785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5286

Saving model as e151_model.pt & e151_waveforms_supplementary.hdf5
Learning rate: 0.00019988750267410245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 8.4575	Cost: 33.51s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 8.2968	Cost: 9.46s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 8.3419	Cost: 13.26s
Train Epoch: 152 	Average Loss: 8.3199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5667

Learning rate: 0.0001998860079935067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 8.5053	Cost: 33.70s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 8.3520	Cost: 9.51s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 8.3839	Cost: 11.97s
Train Epoch: 153 	Average Loss: 8.3289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5690

Learning rate: 0.00019988450345455726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 8.5313	Cost: 33.66s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 8.1692	Cost: 9.47s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 8.2816	Cost: 12.09s
Train Epoch: 154 	Average Loss: 8.2948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4593

Saving model as e154_model.pt & e154_waveforms_supplementary.hdf5
Learning rate: 0.00019988298905740252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 8.4771	Cost: 33.85s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 8.2211	Cost: 9.48s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 8.2178	Cost: 12.67s
Train Epoch: 155 	Average Loss: 8.2601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4242

Saving model as e155_model.pt & e155_waveforms_supplementary.hdf5
Learning rate: 0.000199881464802192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 8.4833	Cost: 33.37s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 8.1688	Cost: 9.52s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 8.1964	Cost: 12.53s
Train Epoch: 156 	Average Loss: 8.2472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4305

Learning rate: 0.0001998799306890761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 8.4622	Cost: 33.78s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 8.1743	Cost: 9.47s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 8.2409	Cost: 13.41s
Train Epoch: 157 	Average Loss: 8.2449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4691

Learning rate: 0.00019987838671820622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 8.3833	Cost: 33.78s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 8.2076	Cost: 9.47s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 8.2708	Cost: 12.97s
Train Epoch: 158 	Average Loss: 8.2403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4456

Learning rate: 0.00019987683288973478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 8.4606	Cost: 33.99s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 8.2224	Cost: 9.47s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 8.2097	Cost: 11.95s
Train Epoch: 159 	Average Loss: 8.2253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4382

Learning rate: 0.00019987526920381513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 8.3613	Cost: 33.41s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 8.1913	Cost: 9.46s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 8.1922	Cost: 13.27s
Train Epoch: 160 	Average Loss: 8.2250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5010

Learning rate: 0.00019987369566060162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 8.5306	Cost: 33.49s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 8.1323	Cost: 9.48s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 8.1961	Cost: 12.67s
Train Epoch: 161 	Average Loss: 8.1997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3474

Saving model as e161_model.pt & e161_waveforms_supplementary.hdf5
Learning rate: 0.0001998721122602495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 8.4165	Cost: 33.29s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 8.0558	Cost: 9.47s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 8.1821	Cost: 11.92s
Train Epoch: 162 	Average Loss: 8.1688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4386

Learning rate: 0.00019987051900291508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 8.3633	Cost: 33.26s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 8.1618	Cost: 9.49s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 8.1173	Cost: 13.39s
Train Epoch: 163 	Average Loss: 8.1842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4550

Learning rate: 0.00019986891588875562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 8.3999	Cost: 34.04s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 8.0528	Cost: 9.48s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 8.0510	Cost: 12.10s
Train Epoch: 164 	Average Loss: 8.1251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3240

Saving model as e164_model.pt & e164_waveforms_supplementary.hdf5
Learning rate: 0.0001998673029179293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 8.2913	Cost: 33.42s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 8.1815	Cost: 9.48s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 8.0876	Cost: 12.23s
Train Epoch: 165 	Average Loss: 8.0968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3760

Learning rate: 0.00019986568009059536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 8.2710	Cost: 33.91s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 8.1169	Cost: 9.47s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 8.1943	Cost: 11.81s
Train Epoch: 166 	Average Loss: 8.1289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4532

Learning rate: 0.00019986404740691393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 8.3518	Cost: 33.30s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 8.1108	Cost: 9.51s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 8.0567	Cost: 12.65s
Train Epoch: 167 	Average Loss: 8.1036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3768

Learning rate: 0.00019986240486704617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 8.4911	Cost: 33.13s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 7.9840	Cost: 9.51s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 8.0158	Cost: 13.27s
Train Epoch: 168 	Average Loss: 8.0741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4164

Learning rate: 0.00019986075247115415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 8.3226	Cost: 33.34s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 8.0537	Cost: 9.48s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 8.0755	Cost: 12.32s
Train Epoch: 169 	Average Loss: 8.0696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3311

Learning rate: 0.00019985909021940103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 8.3318	Cost: 34.09s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 7.9863	Cost: 9.47s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 7.9755	Cost: 12.86s
Train Epoch: 170 	Average Loss: 8.0347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2131

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 0.0001998574181119508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 8.3042	Cost: 33.99s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 8.0620	Cost: 9.47s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 8.0912	Cost: 12.38s
Train Epoch: 171 	Average Loss: 8.0407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3847

Learning rate: 0.00019985573614896853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 8.2963	Cost: 34.21s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 7.9289	Cost: 9.47s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 8.1319	Cost: 12.15s
Train Epoch: 172 	Average Loss: 7.9980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2427

Learning rate: 0.00019985404433062024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 8.2346	Cost: 34.00s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 7.8988	Cost: 9.47s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 7.9946	Cost: 13.34s
Train Epoch: 173 	Average Loss: 8.0079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2058

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 0.00019985234265707287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 8.2650	Cost: 33.57s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 7.9539	Cost: 9.48s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 8.0493	Cost: 12.07s
Train Epoch: 174 	Average Loss: 8.0015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2265

Learning rate: 0.00019985063112849436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 8.1912	Cost: 33.72s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 7.9469	Cost: 9.48s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 7.8769	Cost: 12.99s
Train Epoch: 175 	Average Loss: 7.9662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2765

Learning rate: 0.00019984890974505368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 8.1755	Cost: 34.03s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 7.8929	Cost: 9.46s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 7.9581	Cost: 13.13s
Train Epoch: 176 	Average Loss: 7.9654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2261

Learning rate: 0.00019984717850692066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 8.2282	Cost: 35.18s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 8.0427	Cost: 9.48s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 8.0096	Cost: 12.36s
Train Epoch: 177 	Average Loss: 8.0305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3185

Learning rate: 0.00019984543741426617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 8.2648	Cost: 33.13s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 7.9899	Cost: 9.49s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 7.9995	Cost: 11.95s
Train Epoch: 178 	Average Loss: 7.9791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1773

Saving model as e178_model.pt & e178_waveforms_supplementary.hdf5
Learning rate: 0.0001998436864672621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 8.1960	Cost: 33.82s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 7.9691	Cost: 9.46s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 7.9305	Cost: 12.02s
Train Epoch: 179 	Average Loss: 7.9320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1388

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Learning rate: 0.00019984192566608125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 8.2479	Cost: 33.30s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 7.7756	Cost: 9.47s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 7.9384	Cost: 11.87s
Train Epoch: 180 	Average Loss: 7.8995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1832

Learning rate: 0.00019984015501089739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 8.0838	Cost: 33.43s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 7.8599	Cost: 9.47s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 7.8172	Cost: 11.96s
Train Epoch: 181 	Average Loss: 7.8625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2294

Learning rate: 0.00019983837450188524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 8.1702	Cost: 33.88s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 7.9116	Cost: 9.49s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 7.8465	Cost: 12.94s
Train Epoch: 182 	Average Loss: 7.8850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1396

Learning rate: 0.0001998365841392206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 8.1651	Cost: 33.93s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 7.8179	Cost: 9.44s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 7.8305	Cost: 11.98s
Train Epoch: 183 	Average Loss: 7.8304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0832

Saving model as e183_model.pt & e183_waveforms_supplementary.hdf5
Learning rate: 0.00019983478392308012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 8.1832	Cost: 34.03s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 7.8264	Cost: 9.51s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 7.8049	Cost: 13.44s
Train Epoch: 184 	Average Loss: 7.8393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1513

Learning rate: 0.0001998329738536415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 8.1033	Cost: 34.51s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 7.7850	Cost: 9.46s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 7.8529	Cost: 13.13s
Train Epoch: 185 	Average Loss: 7.8220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1930

Learning rate: 0.00019983115393108338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 8.0440	Cost: 33.63s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 7.7608	Cost: 9.51s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 7.7493	Cost: 12.64s
Train Epoch: 186 	Average Loss: 7.8355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0747

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Learning rate: 0.0001998293241555854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 8.0627	Cost: 33.98s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 7.7782	Cost: 9.48s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 7.7355	Cost: 12.45s
Train Epoch: 187 	Average Loss: 7.8046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0544

Saving model as e187_model.pt & e187_waveforms_supplementary.hdf5
Learning rate: 0.0001998274845273281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 8.1095	Cost: 33.74s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 7.7253	Cost: 9.45s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 7.7900	Cost: 12.06s
Train Epoch: 188 	Average Loss: 7.7844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1064

Learning rate: 0.00019982563504649309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 8.1325	Cost: 33.33s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 7.7507	Cost: 9.47s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 7.8558	Cost: 11.82s
Train Epoch: 189 	Average Loss: 7.7919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1511

Learning rate: 0.00019982377571326284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 8.0485	Cost: 33.64s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 7.6444	Cost: 9.46s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 7.8008	Cost: 13.49s
Train Epoch: 190 	Average Loss: 7.7678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1167

Learning rate: 0.00019982190652782097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 8.1467	Cost: 34.06s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 7.6502	Cost: 9.47s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 7.7644	Cost: 11.97s
Train Epoch: 191 	Average Loss: 7.7476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0347

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Learning rate: 0.0001998200274903519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 8.0397	Cost: 33.72s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 7.5840	Cost: 9.48s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 7.6457	Cost: 13.07s
Train Epoch: 192 	Average Loss: 7.6982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0055

Saving model as e192_model.pt & e192_waveforms_supplementary.hdf5
Learning rate: 0.00019981813860104106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 8.0224	Cost: 33.33s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 7.6154	Cost: 9.47s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 7.6507	Cost: 11.66s
Train Epoch: 193 	Average Loss: 7.7016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0366

Learning rate: 0.0001998162398600749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 8.0881	Cost: 33.30s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 7.6795	Cost: 9.48s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 7.6868	Cost: 13.31s
Train Epoch: 194 	Average Loss: 7.6802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0502

Learning rate: 0.00019981433126764085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 7.9571	Cost: 33.41s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 7.7215	Cost: 9.46s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 7.6077	Cost: 12.06s
Train Epoch: 195 	Average Loss: 7.6758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0364

Learning rate: 0.00019981241282392723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 8.0100	Cost: 33.37s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 7.5629	Cost: 9.48s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 7.5557	Cost: 12.07s
Train Epoch: 196 	Average Loss: 7.6359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9795

Saving model as e196_model.pt & e196_waveforms_supplementary.hdf5
Learning rate: 0.0001998104845291234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 7.9641	Cost: 33.16s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 7.5309	Cost: 9.48s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 7.6679	Cost: 11.81s
Train Epoch: 197 	Average Loss: 7.6396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9196

Saving model as e197_model.pt & e197_waveforms_supplementary.hdf5
Learning rate: 0.00019980854638341968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 7.9198	Cost: 33.36s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 7.5917	Cost: 9.47s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 7.6175	Cost: 12.33s
Train Epoch: 198 	Average Loss: 7.6392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0291

Learning rate: 0.00019980659838700736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 7.9609	Cost: 33.72s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 7.5196	Cost: 9.47s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 7.5987	Cost: 12.55s
Train Epoch: 199 	Average Loss: 7.6151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9765

Learning rate: 0.0001998046405400787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 7.8616	Cost: 33.86s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 7.5990	Cost: 9.45s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 7.4837	Cost: 13.31s
Train Epoch: 200 	Average Loss: 7.5840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9533

Learning rate: 0.00019980267284282693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 8.0194	Cost: 33.40s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 7.7013	Cost: 9.47s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 7.5430	Cost: 12.24s
Train Epoch: 201 	Average Loss: 7.5968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9569

Learning rate: 0.00019980069529544622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 7.9124	Cost: 33.99s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 7.5501	Cost: 9.47s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 7.5498	Cost: 13.23s
Train Epoch: 202 	Average Loss: 7.5572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8881

Saving model as e202_model.pt & e202_waveforms_supplementary.hdf5
Learning rate: 0.0001997987078981318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 7.8594	Cost: 33.34s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 7.4756	Cost: 9.50s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 7.4343	Cost: 11.91s
Train Epoch: 203 	Average Loss: 7.5407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8685

Saving model as e203_model.pt & e203_waveforms_supplementary.hdf5
Learning rate: 0.00019979671065107978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 7.8869	Cost: 33.74s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 7.4092	Cost: 9.48s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 7.5262	Cost: 12.55s
Train Epoch: 204 	Average Loss: 7.5178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8384

Saving model as e204_model.pt & e204_waveforms_supplementary.hdf5
Learning rate: 0.0001997947035544873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 7.8918	Cost: 33.99s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 7.3993	Cost: 9.49s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 7.4430	Cost: 13.27s
Train Epoch: 205 	Average Loss: 7.4815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8516

Learning rate: 0.00019979268660855247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 7.9004	Cost: 34.20s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 7.4073	Cost: 9.47s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 7.4715	Cost: 12.27s
Train Epoch: 206 	Average Loss: 7.5060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8776

Learning rate: 0.00019979065981347432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 7.9076	Cost: 33.35s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 7.3348	Cost: 9.50s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 7.4546	Cost: 13.33s
Train Epoch: 207 	Average Loss: 7.4695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8512

Learning rate: 0.0001997886231694529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 7.8869	Cost: 33.80s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 7.4156	Cost: 9.50s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 7.5075	Cost: 13.37s
Train Epoch: 208 	Average Loss: 7.4920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8870

Learning rate: 0.0001997865766766892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 7.8778	Cost: 33.06s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 7.4234	Cost: 9.45s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 7.4610	Cost: 11.99s
Train Epoch: 209 	Average Loss: 7.4859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8810

Learning rate: 0.00019978452033538524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 7.9075	Cost: 33.62s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 7.3509	Cost: 9.45s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 7.3338	Cost: 12.01s
Train Epoch: 210 	Average Loss: 7.4733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8649

Learning rate: 0.00019978245414574395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 7.7951	Cost: 33.36s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 7.3249	Cost: 9.48s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 7.4667	Cost: 11.87s
Train Epoch: 211 	Average Loss: 7.4501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9174

Learning rate: 0.00019978037810796924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 7.8981	Cost: 33.58s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 7.2827	Cost: 9.43s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 7.3999	Cost: 12.61s
Train Epoch: 212 	Average Loss: 7.4430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8971

Learning rate: 0.000199778292222266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 7.8680	Cost: 33.34s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 7.3540	Cost: 9.48s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 7.4170	Cost: 13.14s
Train Epoch: 213 	Average Loss: 7.4305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8129

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Learning rate: 0.00019977619648884015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 7.8752	Cost: 33.66s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 7.4244	Cost: 9.46s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 7.4044	Cost: 12.79s
Train Epoch: 214 	Average Loss: 7.4524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8922

Learning rate: 0.0001997740909078985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 7.9107	Cost: 32.96s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 7.1914	Cost: 9.46s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 7.3107	Cost: 12.82s
Train Epoch: 215 	Average Loss: 7.3727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8180

Learning rate: 0.0001997719754796489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 7.7846	Cost: 33.71s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 7.2176	Cost: 9.51s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 7.3226	Cost: 12.98s
Train Epoch: 216 	Average Loss: 7.3555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7559

Saving model as e216_model.pt & e216_waveforms_supplementary.hdf5
Learning rate: 0.00019976985020430003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 7.7510	Cost: 33.79s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 7.2192	Cost: 9.47s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 7.2916	Cost: 12.89s
Train Epoch: 217 	Average Loss: 7.3381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7222

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 0.00019976771508206176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 7.5849	Cost: 34.15s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 7.2199	Cost: 9.48s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 7.2014	Cost: 13.56s
Train Epoch: 218 	Average Loss: 7.2845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7108

Saving model as e218_model.pt & e218_waveforms_supplementary.hdf5
Learning rate: 0.00019976557011314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 7.8062	Cost: 32.74s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 7.2045	Cost: 9.47s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 7.2773	Cost: 12.02s
Train Epoch: 219 	Average Loss: 7.3023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7868

Learning rate: 0.00019976341529776072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 7.7563	Cost: 33.41s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 7.1872	Cost: 9.47s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 7.2051	Cost: 12.04s
Train Epoch: 220 	Average Loss: 7.2843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7623

Learning rate: 0.00019976125063612233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 7.7014	Cost: 34.00s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 7.1209	Cost: 9.47s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 7.1789	Cost: 12.95s
Train Epoch: 221 	Average Loss: 7.2398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7564

Learning rate: 0.00019975907612844327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 7.6398	Cost: 33.57s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 7.1846	Cost: 9.47s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 7.1913	Cost: 12.60s
Train Epoch: 222 	Average Loss: 7.2512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6490

Saving model as e222_model.pt & e222_waveforms_supplementary.hdf5
Learning rate: 0.00019975689177493812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 7.5914	Cost: 33.79s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 7.1696	Cost: 9.48s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 7.1746	Cost: 12.77s
Train Epoch: 223 	Average Loss: 7.1976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6493

Learning rate: 0.00019975469757582245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 7.5711	Cost: 33.94s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 7.0985	Cost: 9.47s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 7.1734	Cost: 13.28s
Train Epoch: 224 	Average Loss: 7.1909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7043

Learning rate: 0.00019975249353131286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 7.5906	Cost: 33.29s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 7.0483	Cost: 9.48s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 7.1735	Cost: 11.99s
Train Epoch: 225 	Average Loss: 7.1730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6063

Saving model as e225_model.pt & e225_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 7.6094	Cost: 33.37s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 7.0929	Cost: 9.47s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 7.1347	Cost: 13.17s
Train Epoch: 226 	Average Loss: 7.1748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6940

Learning rate: 0.0001997480559069829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 7.6723	Cost: 33.41s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 6.9897	Cost: 9.49s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 7.0642	Cost: 13.39s
Train Epoch: 227 	Average Loss: 7.1254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5971

Saving model as e227_model.pt & e227_waveforms_supplementary.hdf5
Learning rate: 0.00019974582232760058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 7.4681	Cost: 33.25s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 7.0518	Cost: 9.47s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 7.0786	Cost: 12.49s
Train Epoch: 228 	Average Loss: 7.0945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5855

Saving model as e228_model.pt & e228_waveforms_supplementary.hdf5
Learning rate: 0.0001997435789037002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 7.5398	Cost: 33.38s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 6.9870	Cost: 9.47s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 7.0855	Cost: 12.14s
Train Epoch: 229 	Average Loss: 7.0774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6670

Learning rate: 0.0001997413256355033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 7.5845	Cost: 33.69s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 6.9349	Cost: 9.48s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 7.0648	Cost: 11.93s
Train Epoch: 230 	Average Loss: 7.0728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5217

Saving model as e230_model.pt & e230_waveforms_supplementary.hdf5
Learning rate: 0.0001997390625232322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 7.5935	Cost: 33.21s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 6.9682	Cost: 9.48s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 7.0389	Cost: 12.95s
Train Epoch: 231 	Average Loss: 7.0686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5823

Learning rate: 0.00019973678956711026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 7.6372	Cost: 33.43s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 6.9395	Cost: 9.45s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 7.1296	Cost: 13.31s
Train Epoch: 232 	Average Loss: 7.0437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5290

Learning rate: 0.00019973450676736185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 7.4944	Cost: 33.24s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 6.9145	Cost: 9.48s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 6.9619	Cost: 12.26s
Train Epoch: 233 	Average Loss: 7.0244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5493

Learning rate: 0.00019973221412421225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 7.4977	Cost: 33.54s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 6.9018	Cost: 9.47s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 6.8924	Cost: 13.13s
Train Epoch: 234 	Average Loss: 7.0211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5218

Learning rate: 0.0001997299116378877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 7.4609	Cost: 34.26s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 6.8740	Cost: 9.48s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 6.9592	Cost: 13.37s
Train Epoch: 235 	Average Loss: 6.9949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5918

Learning rate: 0.0001997275993086155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 7.5960	Cost: 33.45s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 6.9597	Cost: 9.47s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 6.9914	Cost: 12.52s
Train Epoch: 236 	Average Loss: 6.9969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5108

Saving model as e236_model.pt & e236_waveforms_supplementary.hdf5
Learning rate: 0.0001997252771366239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 7.5012	Cost: 33.73s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 6.7884	Cost: 9.51s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 6.9525	Cost: 12.42s
Train Epoch: 237 	Average Loss: 6.9513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5376

Learning rate: 0.000199722945122142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 7.4372	Cost: 32.90s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 6.9152	Cost: 9.48s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 6.8793	Cost: 12.08s
Train Epoch: 238 	Average Loss: 6.9368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4317

Saving model as e238_model.pt & e238_waveforms_supplementary.hdf5
Learning rate: 0.0001997206032654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 7.4545	Cost: 33.63s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 6.7414	Cost: 9.50s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 6.8879	Cost: 13.42s
Train Epoch: 239 	Average Loss: 6.9141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4611

Learning rate: 0.00019971825156662903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 7.4767	Cost: 33.33s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 6.7973	Cost: 9.48s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 6.8606	Cost: 12.19s
Train Epoch: 240 	Average Loss: 6.9051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4367

Learning rate: 0.00019971589002606117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 7.4527	Cost: 33.73s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 6.8859	Cost: 9.49s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 6.8668	Cost: 13.29s
Train Epoch: 241 	Average Loss: 6.9256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4201

Saving model as e241_model.pt & e241_waveforms_supplementary.hdf5
Learning rate: 0.00019971351864392958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 7.4171	Cost: 32.84s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 6.7068	Cost: 9.50s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 6.8734	Cost: 11.91s
Train Epoch: 242 	Average Loss: 6.8795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5029

Learning rate: 0.00019971113742046817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 7.4754	Cost: 33.54s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 6.7268	Cost: 9.48s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 6.7689	Cost: 12.68s
Train Epoch: 243 	Average Loss: 6.8400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3732

Saving model as e243_model.pt & e243_waveforms_supplementary.hdf5
Learning rate: 0.00019970874635591207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 7.4113	Cost: 34.18s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 6.6468	Cost: 9.45s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 6.7038	Cost: 12.24s
Train Epoch: 244 	Average Loss: 6.8097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3893

Learning rate: 0.00019970634545049727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 7.3632	Cost: 34.94s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 6.6771	Cost: 9.47s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 6.8736	Cost: 12.41s
Train Epoch: 245 	Average Loss: 6.8135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3623

Saving model as e245_model.pt & e245_waveforms_supplementary.hdf5
Learning rate: 0.0001997039347044607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 7.4053	Cost: 33.28s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 6.7284	Cost: 9.48s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 6.7136	Cost: 12.14s
Train Epoch: 246 	Average Loss: 6.8176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4355

Learning rate: 0.00019970151411804023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 7.4323	Cost: 33.42s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 6.7174	Cost: 9.48s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 6.8205	Cost: 12.99s
Train Epoch: 247 	Average Loss: 6.8096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3962

Learning rate: 0.00019969908369147485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 7.4268	Cost: 33.22s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 6.7060	Cost: 9.48s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 6.7869	Cost: 12.98s
Train Epoch: 248 	Average Loss: 6.7974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4302

Learning rate: 0.00019969664342500438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 7.3137	Cost: 33.38s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 6.6687	Cost: 9.48s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 6.7038	Cost: 13.14s
Train Epoch: 249 	Average Loss: 6.7536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4562

Learning rate: 0.00019969419331886966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 7.3404	Cost: 33.26s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 6.6104	Cost: 9.52s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 6.6903	Cost: 12.79s
Train Epoch: 250 	Average Loss: 6.7428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4253

Learning rate: 0.0001996917333733126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 7.4384	Cost: 33.53s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 6.5801	Cost: 9.48s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 6.6736	Cost: 13.84s
Train Epoch: 251 	Average Loss: 6.7129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3846

Learning rate: 0.00019968926358857587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 7.3268	Cost: 34.11s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 6.5985	Cost: 9.46s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 6.6851	Cost: 11.79s
Train Epoch: 252 	Average Loss: 6.6735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3125

Saving model as e252_model.pt & e252_waveforms_supplementary.hdf5
Learning rate: 0.00019968678396490325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 7.2934	Cost: 33.35s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 6.4639	Cost: 9.50s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 6.6052	Cost: 11.67s
Train Epoch: 253 	Average Loss: 6.6383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3337

Learning rate: 0.00019968429450253954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 7.2214	Cost: 33.86s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 6.5724	Cost: 9.48s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 6.5333	Cost: 12.76s
Train Epoch: 254 	Average Loss: 6.6056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2203

Saving model as e254_model.pt & e254_waveforms_supplementary.hdf5
Learning rate: 0.0001996817952017304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 7.2261	Cost: 33.29s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 6.4774	Cost: 9.46s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 6.5480	Cost: 11.90s
Train Epoch: 255 	Average Loss: 6.6073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2562

Learning rate: 0.00019967928606272244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 7.1604	Cost: 33.93s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 6.5384	Cost: 9.47s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 6.5891	Cost: 12.70s
Train Epoch: 256 	Average Loss: 6.5986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2666

Learning rate: 0.0001996767670857634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 7.2761	Cost: 33.91s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 6.3894	Cost: 9.48s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 6.5635	Cost: 11.91s
Train Epoch: 257 	Average Loss: 6.5897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2554

Learning rate: 0.00019967423827110182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 7.3127	Cost: 33.73s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 6.4528	Cost: 9.48s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 6.6907	Cost: 11.82s
Train Epoch: 258 	Average Loss: 6.6094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3322

Learning rate: 0.00019967169961898734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 7.1622	Cost: 33.22s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 6.5181	Cost: 9.46s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 6.5190	Cost: 12.21s
Train Epoch: 259 	Average Loss: 6.5799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1532

Saving model as e259_model.pt & e259_waveforms_supplementary.hdf5
Learning rate: 0.00019966915112967047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 7.2337	Cost: 33.23s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 6.3915	Cost: 9.49s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 6.5239	Cost: 12.86s
Train Epoch: 260 	Average Loss: 6.5404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1990

Learning rate: 0.00019966659280340273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 7.2898	Cost: 33.05s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 6.3511	Cost: 9.50s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 6.4358	Cost: 12.34s
Train Epoch: 261 	Average Loss: 6.4901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2282

Learning rate: 0.00019966402464043667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 7.1844	Cost: 33.52s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 6.4080	Cost: 9.47s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 6.4283	Cost: 12.73s
Train Epoch: 262 	Average Loss: 6.4738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1607

Learning rate: 0.00019966144664102572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 7.1114	Cost: 33.74s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 6.3080	Cost: 9.47s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 6.4255	Cost: 13.40s
Train Epoch: 263 	Average Loss: 6.4667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2253

Learning rate: 0.00019965885880542434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 7.0483	Cost: 33.19s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 6.3334	Cost: 9.47s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 6.3957	Cost: 13.48s
Train Epoch: 264 	Average Loss: 6.4636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2201

Learning rate: 0.00019965626113388794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 7.1012	Cost: 33.91s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 6.3697	Cost: 9.47s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 6.3758	Cost: 13.04s
Train Epoch: 265 	Average Loss: 6.4332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2415

Learning rate: 0.00019965365362667288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 7.1823	Cost: 33.21s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 6.2723	Cost: 9.45s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 6.3197	Cost: 13.46s
Train Epoch: 266 	Average Loss: 6.4117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1314

Saving model as e266_model.pt & e266_waveforms_supplementary.hdf5
Learning rate: 0.0001996510362840365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 7.1899	Cost: 33.48s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 6.3177	Cost: 9.46s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 6.4326	Cost: 12.99s
Train Epoch: 267 	Average Loss: 6.4148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1101

Saving model as e267_model.pt & e267_waveforms_supplementary.hdf5
Learning rate: 0.00019964840910623716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 7.0775	Cost: 33.54s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 6.2139	Cost: 9.50s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 6.3308	Cost: 12.08s
Train Epoch: 268 	Average Loss: 6.3836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1513

Learning rate: 0.00019964577209353413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 7.1844	Cost: 33.68s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 6.2501	Cost: 9.48s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 6.3255	Cost: 11.89s
Train Epoch: 269 	Average Loss: 6.3681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0788

Saving model as e269_model.pt & e269_waveforms_supplementary.hdf5
Learning rate: 0.00019964312524618766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 7.0521	Cost: 33.79s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 6.2741	Cost: 9.48s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 6.2855	Cost: 12.59s
Train Epoch: 270 	Average Loss: 6.3535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2159

Learning rate: 0.000199640468564459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 7.1013	Cost: 33.74s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 6.1996	Cost: 9.48s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 6.1581	Cost: 13.17s
Train Epoch: 271 	Average Loss: 6.3727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0709

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 0.00019963780204861037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 6.9581	Cost: 32.99s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 6.1823	Cost: 9.52s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 6.2446	Cost: 12.48s
Train Epoch: 272 	Average Loss: 6.2737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9868

Saving model as e272_model.pt & e272_waveforms_supplementary.hdf5
Learning rate: 0.0001996351256989049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 7.0301	Cost: 33.31s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 6.1490	Cost: 9.48s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 6.1334	Cost: 12.68s
Train Epoch: 273 	Average Loss: 6.2260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9504

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 0.0001996324395156068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 7.0095	Cost: 32.95s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 6.0543	Cost: 9.47s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 6.0598	Cost: 11.70s
Train Epoch: 274 	Average Loss: 6.2096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9845

Learning rate: 0.00019962974349898107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 6.9611	Cost: 33.78s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 6.0697	Cost: 9.46s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 6.0986	Cost: 12.41s
Train Epoch: 275 	Average Loss: 6.2190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1052

Learning rate: 0.0001996270376492939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 7.0687	Cost: 33.57s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 5.9700	Cost: 9.47s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 6.1761	Cost: 12.39s
Train Epoch: 276 	Average Loss: 6.1954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9047

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Learning rate: 0.00019962432196681234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 6.9138	Cost: 32.74s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 6.0580	Cost: 9.47s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 6.0749	Cost: 11.75s
Train Epoch: 277 	Average Loss: 6.1507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9339

Learning rate: 0.00019962159645180437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 6.9490	Cost: 33.67s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 5.9773	Cost: 9.49s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 6.1110	Cost: 12.99s
Train Epoch: 278 	Average Loss: 6.1819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9257

Learning rate: 0.00019961886110453903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 6.9841	Cost: 33.50s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 5.9687	Cost: 9.48s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 6.0568	Cost: 12.08s
Train Epoch: 279 	Average Loss: 6.1627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9889

Learning rate: 0.00019961611592528625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 7.0004	Cost: 34.26s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 5.9307	Cost: 9.48s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 5.9570	Cost: 12.45s
Train Epoch: 280 	Average Loss: 6.1117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8777

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Learning rate: 0.000199613360914317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 6.9354	Cost: 33.59s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 5.9819	Cost: 9.47s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 6.0135	Cost: 12.77s
Train Epoch: 281 	Average Loss: 6.0920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9352

Learning rate: 0.00019961059607190318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 6.8519	Cost: 33.94s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 5.9964	Cost: 9.45s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 6.0578	Cost: 12.09s
Train Epoch: 282 	Average Loss: 6.1062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9143

Learning rate: 0.00019960782139831766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 6.8815	Cost: 33.88s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 5.9623	Cost: 9.46s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 5.9196	Cost: 13.51s
Train Epoch: 283 	Average Loss: 6.0585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8453

Saving model as e283_model.pt & e283_waveforms_supplementary.hdf5
Learning rate: 0.00019960503689383428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 6.8037	Cost: 33.89s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 5.9025	Cost: 9.45s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 5.8734	Cost: 12.75s
Train Epoch: 284 	Average Loss: 5.9944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8850

Learning rate: 0.0001996022425587279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 6.8771	Cost: 33.99s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 5.9515	Cost: 9.47s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 6.0233	Cost: 13.37s
Train Epoch: 285 	Average Loss: 6.1051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9157

Learning rate: 0.0001995994383932743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 6.7832	Cost: 33.92s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 6.0153	Cost: 9.46s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 5.9732	Cost: 12.96s
Train Epoch: 286 	Average Loss: 6.0482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8842

Learning rate: 0.0001995966243977502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 6.8161	Cost: 33.93s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 5.8583	Cost: 9.42s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 5.8536	Cost: 13.39s
Train Epoch: 287 	Average Loss: 5.9707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7614

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Learning rate: 0.0001995938005724334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 6.7089	Cost: 33.12s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 5.7920	Cost: 9.47s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 5.9391	Cost: 12.64s
Train Epoch: 288 	Average Loss: 5.9430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7936

Learning rate: 0.00019959096691760252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 6.7243	Cost: 33.26s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 5.8267	Cost: 9.48s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 5.7790	Cost: 11.82s
Train Epoch: 289 	Average Loss: 5.9263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8151

Learning rate: 0.00019958812343353726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 6.6489	Cost: 33.70s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 5.7615	Cost: 9.44s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 5.7719	Cost: 12.07s
Train Epoch: 290 	Average Loss: 5.8664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6887

Saving model as e290_model.pt & e290_waveforms_supplementary.hdf5
Learning rate: 0.0001995852701205183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 6.7667	Cost: 33.74s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 5.7330	Cost: 9.45s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 5.8221	Cost: 12.02s
Train Epoch: 291 	Average Loss: 5.8706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7430

Learning rate: 0.0001995824069788272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 6.8628	Cost: 33.46s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 5.6709	Cost: 9.47s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 5.7897	Cost: 12.11s
Train Epoch: 292 	Average Loss: 5.8372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7132

Learning rate: 0.00019957953400874656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 6.7967	Cost: 33.90s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 5.6685	Cost: 9.47s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 5.6954	Cost: 13.76s
Train Epoch: 293 	Average Loss: 5.8189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6856

Saving model as e293_model.pt & e293_waveforms_supplementary.hdf5
Learning rate: 0.00019957665121055995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 6.7121	Cost: 34.05s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 5.6665	Cost: 9.46s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 5.6350	Cost: 11.86s
Train Epoch: 294 	Average Loss: 5.8252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7132

Learning rate: 0.00019957375858455185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 6.7765	Cost: 33.11s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 5.6964	Cost: 9.46s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 5.7273	Cost: 11.86s
Train Epoch: 295 	Average Loss: 5.8097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7458

Learning rate: 0.00019957085613100776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 6.6408	Cost: 33.43s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 5.6606	Cost: 9.47s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 5.6711	Cost: 13.90s
Train Epoch: 296 	Average Loss: 5.7624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6715

Saving model as e296_model.pt & e296_waveforms_supplementary.hdf5
Learning rate: 0.00019956794385021415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 6.5779	Cost: 33.50s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 5.5402	Cost: 9.49s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 5.7362	Cost: 12.85s
Train Epoch: 297 	Average Loss: 5.7481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6632

Saving model as e297_model.pt & e297_waveforms_supplementary.hdf5
Learning rate: 0.00019956502174245846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 6.8745	Cost: 33.03s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 5.5385	Cost: 9.44s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 5.6598	Cost: 12.03s
Train Epoch: 298 	Average Loss: 5.7550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6784

Learning rate: 0.0001995620898080291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 6.6546	Cost: 33.54s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 5.9855	Cost: 9.46s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 5.7621	Cost: 12.56s
Train Epoch: 299 	Average Loss: 5.9359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8136

Learning rate: 0.00019955914804721542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 6.7449	Cost: 33.82s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 5.6663	Cost: 9.48s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 5.7601	Cost: 12.25s
Train Epoch: 300 	Average Loss: 5.8310
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6977

Learning rate: 0.00019955619646030775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 6.6541	Cost: 33.39s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 5.7334	Cost: 9.48s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 5.8041	Cost: 11.92s
Train Epoch: 301 	Average Loss: 5.8617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7354

Learning rate: 0.0001995532350475974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 6.7423	Cost: 33.70s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 5.6864	Cost: 9.46s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 5.6543	Cost: 13.05s
Train Epoch: 302 	Average Loss: 5.8373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6946

Learning rate: 0.00019955026380937669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 6.7079	Cost: 33.89s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 5.5436	Cost: 9.47s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 5.6155	Cost: 12.00s
Train Epoch: 303 	Average Loss: 5.7387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6632

Learning rate: 0.00019954728274593884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 6.7340	Cost: 33.41s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 5.5040	Cost: 9.49s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 5.6272	Cost: 12.82s
Train Epoch: 304 	Average Loss: 5.6993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7283

Learning rate: 0.00019954429185757805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 6.6498	Cost: 34.10s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 5.4992	Cost: 9.47s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 5.4747	Cost: 12.75s
Train Epoch: 305 	Average Loss: 5.6512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5870

Saving model as e305_model.pt & e305_waveforms_supplementary.hdf5
Learning rate: 0.00019954129114458955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 6.6573	Cost: 34.04s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 5.3886	Cost: 9.46s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 5.4681	Cost: 13.13s
Train Epoch: 306 	Average Loss: 5.6014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5326

Saving model as e306_model.pt & e306_waveforms_supplementary.hdf5
Learning rate: 0.00019953828060726943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 6.5587	Cost: 32.79s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 5.4908	Cost: 9.47s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 5.4479	Cost: 12.45s
Train Epoch: 307 	Average Loss: 5.5951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6331

Learning rate: 0.00019953526024591494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 6.6573	Cost: 33.30s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 5.3169	Cost: 9.46s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 5.4206	Cost: 13.53s
Train Epoch: 308 	Average Loss: 5.5553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4829

Saving model as e308_model.pt & e308_waveforms_supplementary.hdf5
Learning rate: 0.00019953223006082406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 6.5189	Cost: 33.70s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 5.3363	Cost: 9.47s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 5.4024	Cost: 12.50s
Train Epoch: 309 	Average Loss: 5.4706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4858

Learning rate: 0.00019952919005229592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 6.4049	Cost: 33.58s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 5.2938	Cost: 9.48s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 5.3728	Cost: 12.31s
Train Epoch: 310 	Average Loss: 5.5094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4813

Saving model as e310_model.pt & e310_waveforms_supplementary.hdf5
Learning rate: 0.00019952614022063054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 6.5322	Cost: 33.15s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 5.3382	Cost: 9.46s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 5.2951	Cost: 12.08s
Train Epoch: 311 	Average Loss: 5.4473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4709

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Learning rate: 0.00019952308056612892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 6.4854	Cost: 32.84s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 5.2739	Cost: 9.46s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 5.3434	Cost: 11.68s
Train Epoch: 312 	Average Loss: 5.4301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4750

Learning rate: 0.00019952001108909304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 6.3350	Cost: 33.66s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 5.1491	Cost: 9.50s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 5.3013	Cost: 13.08s
Train Epoch: 313 	Average Loss: 5.4053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4566

Saving model as e313_model.pt & e313_waveforms_supplementary.hdf5
Learning rate: 0.00019951693178982586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 6.3688	Cost: 33.22s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 5.1983	Cost: 9.45s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 5.1918	Cost: 12.78s
Train Epoch: 314 	Average Loss: 5.3837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4260

Saving model as e314_model.pt & e314_waveforms_supplementary.hdf5
Learning rate: 0.00019951384266863126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 6.2518	Cost: 33.13s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 5.1922	Cost: 9.48s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 5.3058	Cost: 11.86s
Train Epoch: 315 	Average Loss: 5.3722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3538

Saving model as e315_model.pt & e315_waveforms_supplementary.hdf5
Learning rate: 0.00019951074372581416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 6.3325	Cost: 33.57s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 5.1942	Cost: 9.49s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 5.2554	Cost: 13.26s
Train Epoch: 316 	Average Loss: 5.3421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3028

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 0.00019950763496168037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 6.3447	Cost: 33.14s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 5.1674	Cost: 9.47s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 5.2299	Cost: 12.08s
Train Epoch: 317 	Average Loss: 5.3252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4224

Learning rate: 0.00019950451637653678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 6.2988	Cost: 33.38s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 5.1223	Cost: 9.48s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 5.1396	Cost: 12.45s
Train Epoch: 318 	Average Loss: 5.2969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3369

Learning rate: 0.00019950138797069118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 6.4253	Cost: 33.47s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 5.1470	Cost: 9.45s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 5.1391	Cost: 12.53s
Train Epoch: 319 	Average Loss: 5.2851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2538

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Learning rate: 0.00019949824974445222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 6.2741	Cost: 33.30s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 5.1827	Cost: 9.48s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 5.2777	Cost: 11.71s
Train Epoch: 320 	Average Loss: 5.3292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4083

Learning rate: 0.00019949510169812976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 6.4520	Cost: 33.17s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 5.1250	Cost: 9.48s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 5.1088	Cost: 11.83s
Train Epoch: 321 	Average Loss: 5.2907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3079

Learning rate: 0.00019949194383203438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 6.2204	Cost: 33.41s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 5.0135	Cost: 9.49s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 5.1265	Cost: 11.76s
Train Epoch: 322 	Average Loss: 5.1933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3147

Learning rate: 0.00019948877614647787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 6.3732	Cost: 33.42s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 5.1864	Cost: 9.47s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 5.0889	Cost: 12.00s
Train Epoch: 323 	Average Loss: 5.2895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3419

Learning rate: 0.0001994855986417728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 6.3502	Cost: 33.51s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 5.0212	Cost: 9.46s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 5.1221	Cost: 12.23s
Train Epoch: 324 	Average Loss: 5.2556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3109

Learning rate: 0.0001994824113182328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 6.3314	Cost: 33.81s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 4.9949	Cost: 9.48s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 5.0075	Cost: 12.12s
Train Epoch: 325 	Average Loss: 5.2054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2232

Saving model as e325_model.pt & e325_waveforms_supplementary.hdf5
Learning rate: 0.00019947921417617242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 6.2229	Cost: 33.34s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 4.9889	Cost: 9.46s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 5.0241	Cost: 12.82s
Train Epoch: 326 	Average Loss: 5.1240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3071

Learning rate: 0.0001994760072159072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 6.2623	Cost: 34.62s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 5.0917	Cost: 9.48s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 5.1136	Cost: 12.45s
Train Epoch: 327 	Average Loss: 5.1895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2744

Learning rate: 0.00019947279043775368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 6.1909	Cost: 33.30s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 4.8838	Cost: 9.51s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 4.9628	Cost: 12.47s
Train Epoch: 328 	Average Loss: 5.1346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1794

Saving model as e328_model.pt & e328_waveforms_supplementary.hdf5
Learning rate: 0.00019946956384202932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 6.2177	Cost: 33.81s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 4.8851	Cost: 9.50s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 4.9022	Cost: 12.40s
Train Epoch: 329 	Average Loss: 5.0778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1456

Saving model as e329_model.pt & e329_waveforms_supplementary.hdf5
Learning rate: 0.00019946632742905265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 6.1141	Cost: 33.83s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 4.8052	Cost: 9.54s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 4.8843	Cost: 12.36s
Train Epoch: 330 	Average Loss: 5.0259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2530

Learning rate: 0.000199463081199143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 6.1283	Cost: 33.47s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 4.9096	Cost: 9.44s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 4.9234	Cost: 12.53s
Train Epoch: 331 	Average Loss: 5.0404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1926

Learning rate: 0.0001994598251526208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 6.1969	Cost: 33.52s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 4.8699	Cost: 9.48s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 4.9346	Cost: 13.30s
Train Epoch: 332 	Average Loss: 5.0609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1368

Saving model as e332_model.pt & e332_waveforms_supplementary.hdf5
Learning rate: 0.00019945655928980737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 6.0706	Cost: 32.93s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 4.8168	Cost: 9.47s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 4.8531	Cost: 13.00s
Train Epoch: 333 	Average Loss: 4.9814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1567

Learning rate: 0.0001994532836110251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 6.1589	Cost: 33.58s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 4.7836	Cost: 9.48s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 4.9088	Cost: 12.41s
Train Epoch: 334 	Average Loss: 4.9510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0983

Saving model as e334_model.pt & e334_waveforms_supplementary.hdf5
Learning rate: 0.00019944999811659725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 6.0949	Cost: 33.21s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 4.7026	Cost: 9.50s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 4.7709	Cost: 11.97s
Train Epoch: 335 	Average Loss: 4.8912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9734

Saving model as e335_model.pt & e335_waveforms_supplementary.hdf5
Learning rate: 0.00019944670280684805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 6.0929	Cost: 33.65s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 4.7022	Cost: 9.52s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 4.7426	Cost: 12.63s
Train Epoch: 336 	Average Loss: 4.8878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1010

Learning rate: 0.00019944339768210285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 6.2311	Cost: 33.66s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 4.6991	Cost: 9.50s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 4.7791	Cost: 12.07s
Train Epoch: 337 	Average Loss: 4.8872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0640

Learning rate: 0.0001994400827426877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 6.1684	Cost: 34.39s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 4.7188	Cost: 9.48s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 4.7083	Cost: 12.86s
Train Epoch: 338 	Average Loss: 4.8767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0220

Learning rate: 0.0001994367579889299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 6.0538	Cost: 33.46s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 4.5466	Cost: 9.47s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 4.6920	Cost: 11.89s
Train Epoch: 339 	Average Loss: 4.8197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1009

Learning rate: 0.0001994334234211575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 5.9999	Cost: 33.07s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 4.6466	Cost: 9.47s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 4.6713	Cost: 13.05s
Train Epoch: 340 	Average Loss: 4.8366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0492

Learning rate: 0.00019943007903969968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 5.9352	Cost: 34.11s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 4.6688	Cost: 9.48s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 4.7822	Cost: 11.77s
Train Epoch: 341 	Average Loss: 4.8386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0205

Learning rate: 0.00019942672484488645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 6.0887	Cost: 33.44s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 4.5902	Cost: 9.47s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 4.7260	Cost: 12.14s
Train Epoch: 342 	Average Loss: 4.8276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0556

Learning rate: 0.0001994233608370489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 6.0310	Cost: 33.86s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 4.6519	Cost: 9.47s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 4.7263	Cost: 12.94s
Train Epoch: 343 	Average Loss: 4.7847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0122

Learning rate: 0.00019941998701651908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 6.0525	Cost: 33.79s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 4.5452	Cost: 9.46s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 4.8073	Cost: 13.20s
Train Epoch: 344 	Average Loss: 4.8221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0928

Learning rate: 0.00019941660338362987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 6.1004	Cost: 33.04s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 4.5972	Cost: 9.48s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 4.7532	Cost: 13.16s
Train Epoch: 345 	Average Loss: 4.8179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8749

Saving model as e345_model.pt & e345_waveforms_supplementary.hdf5
Learning rate: 0.0001994132099387153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 6.0673	Cost: 33.95s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 4.5814	Cost: 9.47s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 4.7085	Cost: 12.76s
Train Epoch: 346 	Average Loss: 4.7621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9828

Learning rate: 0.00019940980668211027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 5.8735	Cost: 33.12s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 4.4622	Cost: 9.52s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 4.5492	Cost: 12.38s
Train Epoch: 347 	Average Loss: 4.7374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9066

Learning rate: 0.00019940639361415064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 5.8781	Cost: 33.87s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 4.4997	Cost: 9.51s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 4.4645	Cost: 12.29s
Train Epoch: 348 	Average Loss: 4.7099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8232

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Learning rate: 0.00019940297073517331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 5.7956	Cost: 33.32s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 4.4552	Cost: 9.52s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 4.4988	Cost: 11.93s
Train Epoch: 349 	Average Loss: 4.6773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9204

Learning rate: 0.00019939953804551608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 5.8898	Cost: 33.55s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 4.3554	Cost: 9.48s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 4.5955	Cost: 11.80s
Train Epoch: 350 	Average Loss: 4.6493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9428

Learning rate: 0.00019939609554551777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 6.0277	Cost: 33.59s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 4.3897	Cost: 9.47s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 4.5689	Cost: 13.28s
Train Epoch: 351 	Average Loss: 4.6452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9573

Learning rate: 0.0001993926432355181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 5.9395	Cost: 33.11s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 4.5151	Cost: 9.48s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 4.5034	Cost: 12.46s
Train Epoch: 352 	Average Loss: 4.6717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9600

Learning rate: 0.00019938918111585784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 5.8794	Cost: 34.58s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 4.3644	Cost: 9.49s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 4.3957	Cost: 13.01s
Train Epoch: 353 	Average Loss: 4.6035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8256

Learning rate: 0.00019938570918687863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 5.8152	Cost: 33.87s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 4.3199	Cost: 9.49s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 4.4223	Cost: 13.13s
Train Epoch: 354 	Average Loss: 4.5218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7949

Saving model as e354_model.pt & e354_waveforms_supplementary.hdf5
Learning rate: 0.0001993822274489232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 5.9131	Cost: 33.83s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 4.2469	Cost: 9.49s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 4.4189	Cost: 11.92s
Train Epoch: 355 	Average Loss: 4.4993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8530

Learning rate: 0.00019937873590233516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 5.8478	Cost: 33.45s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 4.2828	Cost: 9.48s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 4.3482	Cost: 12.11s
Train Epoch: 356 	Average Loss: 4.5056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6940

Saving model as e356_model.pt & e356_waveforms_supplementary.hdf5
Learning rate: 0.0001993752345474591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 5.7905	Cost: 33.67s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 4.2341	Cost: 9.48s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 4.3066	Cost: 11.85s
Train Epoch: 357 	Average Loss: 4.4097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6337

Saving model as e357_model.pt & e357_waveforms_supplementary.hdf5
Learning rate: 0.0001993717233846406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 5.7503	Cost: 33.47s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 4.4041	Cost: 9.48s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 4.4465	Cost: 11.75s
Train Epoch: 358 	Average Loss: 4.6394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8947

Learning rate: 0.0001993682024142262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 5.7535	Cost: 33.86s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 4.2256	Cost: 9.50s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 4.3083	Cost: 13.65s
Train Epoch: 359 	Average Loss: 4.4592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7866

Learning rate: 0.00019936467163656337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 5.7440	Cost: 32.96s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 4.3480	Cost: 9.49s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 4.3959	Cost: 13.93s
Train Epoch: 360 	Average Loss: 4.5456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8648

Learning rate: 0.00019936113105200064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 5.8917	Cost: 33.85s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 4.2881	Cost: 9.51s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 4.3926	Cost: 12.57s
Train Epoch: 361 	Average Loss: 4.4984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8028

Learning rate: 0.00019935758066088742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 5.7022	Cost: 33.81s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 4.1749	Cost: 9.49s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 4.2821	Cost: 12.54s
Train Epoch: 362 	Average Loss: 4.4057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8427

Learning rate: 0.00019935402046357414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 5.8690	Cost: 33.55s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 4.3288	Cost: 9.46s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 4.1516	Cost: 13.01s
Train Epoch: 363 	Average Loss: 4.4529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6848

Learning rate: 0.00019935045046041218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 5.8829	Cost: 33.12s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 4.1570	Cost: 9.46s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 4.2763	Cost: 12.24s
Train Epoch: 364 	Average Loss: 4.3801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7458

Learning rate: 0.00019934687065175386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 5.6152	Cost: 32.81s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 4.1604	Cost: 9.49s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 4.4098	Cost: 13.51s
Train Epoch: 365 	Average Loss: 4.4071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8504

Learning rate: 0.00019934328103795248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 5.7019	Cost: 33.61s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 4.1144	Cost: 9.50s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 4.1936	Cost: 13.12s
Train Epoch: 366 	Average Loss: 4.3299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5973

Saving model as e366_model.pt & e366_waveforms_supplementary.hdf5
Learning rate: 0.00019933968161936236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 5.6834	Cost: 32.97s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 4.0073	Cost: 9.48s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 4.1910	Cost: 11.80s
Train Epoch: 367 	Average Loss: 4.2768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5629

Saving model as e367_model.pt & e367_waveforms_supplementary.hdf5
Learning rate: 0.00019933607239633875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 5.5059	Cost: 32.96s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 3.9729	Cost: 9.46s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 4.1195	Cost: 12.69s
Train Epoch: 368 	Average Loss: 4.2254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6344

Learning rate: 0.00019933245336923783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 5.6580	Cost: 33.53s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 4.0010	Cost: 9.48s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 4.1451	Cost: 12.34s
Train Epoch: 369 	Average Loss: 4.2457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5468

Saving model as e369_model.pt & e369_waveforms_supplementary.hdf5
Learning rate: 0.0001993288245384168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 5.6153	Cost: 33.23s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 3.9337	Cost: 9.49s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 3.9809	Cost: 13.32s
Train Epoch: 370 	Average Loss: 4.1771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5924

Learning rate: 0.00019932518590423377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 5.5640	Cost: 33.80s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 3.9806	Cost: 9.46s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 4.0709	Cost: 12.59s
Train Epoch: 371 	Average Loss: 4.1757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6273

Learning rate: 0.00019932153746704794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 5.6097	Cost: 34.24s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 4.0380	Cost: 9.70s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 4.0675	Cost: 13.40s
Train Epoch: 372 	Average Loss: 4.2115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6247

Learning rate: 0.00019931787922721937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 5.6831	Cost: 34.47s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 3.9307	Cost: 9.49s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 4.0272	Cost: 13.31s
Train Epoch: 373 	Average Loss: 4.1798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5860

Learning rate: 0.00019931421118510906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 5.5697	Cost: 33.74s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 3.9724	Cost: 9.47s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 3.9325	Cost: 12.92s
Train Epoch: 374 	Average Loss: 4.1078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4831

Saving model as e374_model.pt & e374_waveforms_supplementary.hdf5
Learning rate: 0.0001993105333410791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 5.4400	Cost: 33.68s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 3.9173	Cost: 9.46s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 3.9900	Cost: 12.57s
Train Epoch: 375 	Average Loss: 4.0705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6342

Learning rate: 0.00019930684569549248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 5.5506	Cost: 33.84s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 3.9040	Cost: 9.47s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 3.9856	Cost: 12.60s
Train Epoch: 376 	Average Loss: 4.1465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5137

Learning rate: 0.0001993031482487131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 5.5000	Cost: 33.03s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 3.8607	Cost: 9.46s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 3.8542	Cost: 12.93s
Train Epoch: 377 	Average Loss: 4.0261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5483

Learning rate: 0.0001992994410011059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 5.5219	Cost: 34.14s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 3.8204	Cost: 9.47s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 3.9409	Cost: 13.57s
Train Epoch: 378 	Average Loss: 4.0716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3773

Saving model as e378_model.pt & e378_waveforms_supplementary.hdf5
Learning rate: 0.00019929572395303678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 5.5249	Cost: 33.14s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 3.7505	Cost: 9.46s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 3.9773	Cost: 13.59s
Train Epoch: 379 	Average Loss: 4.0503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4926

Learning rate: 0.0001992919971048726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 5.4806	Cost: 34.08s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 3.7579	Cost: 9.46s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 3.8762	Cost: 11.65s
Train Epoch: 380 	Average Loss: 3.9701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3953

Learning rate: 0.0001992882604569812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 5.5120	Cost: 33.39s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 3.7297	Cost: 9.50s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 3.8138	Cost: 12.01s
Train Epoch: 381 	Average Loss: 3.9656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3788

Learning rate: 0.00019928451400973133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 5.4510	Cost: 33.26s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 3.6026	Cost: 9.49s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 3.6433	Cost: 12.34s
Train Epoch: 382 	Average Loss: 3.8861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3700

Saving model as e382_model.pt & e382_waveforms_supplementary.hdf5
Learning rate: 0.0001992807577634928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 5.3348	Cost: 33.40s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 3.6855	Cost: 9.49s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 3.7406	Cost: 11.99s
Train Epoch: 383 	Average Loss: 3.9013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4521

Learning rate: 0.00019927699171863632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 5.4524	Cost: 33.56s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 3.6985	Cost: 9.45s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 3.8014	Cost: 13.18s
Train Epoch: 384 	Average Loss: 3.9140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3209

Saving model as e384_model.pt & e384_waveforms_supplementary.hdf5
Learning rate: 0.00019927321587553357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 5.3868	Cost: 33.58s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 3.6210	Cost: 9.46s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 3.6147	Cost: 12.17s
Train Epoch: 385 	Average Loss: 3.8133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2250

Saving model as e385_model.pt & e385_waveforms_supplementary.hdf5
Learning rate: 0.00019926943023455717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 5.2081	Cost: 33.34s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 3.4808	Cost: 9.46s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 3.7285	Cost: 12.81s
Train Epoch: 386 	Average Loss: 3.7804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4050

Learning rate: 0.00019926563479608086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 5.1858	Cost: 33.37s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 3.5784	Cost: 9.48s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 3.6728	Cost: 12.53s
Train Epoch: 387 	Average Loss: 3.8015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3944

Learning rate: 0.00019926182956047912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 5.2792	Cost: 34.00s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 3.5512	Cost: 9.49s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 3.7607	Cost: 12.05s
Train Epoch: 388 	Average Loss: 3.8237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4265

Learning rate: 0.00019925801452812757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 5.3528	Cost: 33.40s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 3.5493	Cost: 9.46s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 3.6974	Cost: 13.35s
Train Epoch: 389 	Average Loss: 3.7914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2520

Learning rate: 0.00019925418969940278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 5.0717	Cost: 33.62s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 3.4724	Cost: 9.47s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 3.5845	Cost: 13.88s
Train Epoch: 390 	Average Loss: 3.7384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2730

Learning rate: 0.00019925035507468219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 5.3280	Cost: 33.25s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 3.4041	Cost: 9.48s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 3.6987	Cost: 13.31s
Train Epoch: 391 	Average Loss: 3.7415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3054

Learning rate: 0.00019924651065434423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 5.4329	Cost: 33.24s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 3.6552	Cost: 9.45s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 3.7043	Cost: 13.46s
Train Epoch: 392 	Average Loss: 3.8016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3239

Learning rate: 0.0001992426564387684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 5.1857	Cost: 33.98s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 3.5970	Cost: 9.46s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 3.5754	Cost: 11.84s
Train Epoch: 393 	Average Loss: 3.7669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2508

Learning rate: 0.00019923879242833502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 5.0925	Cost: 34.35s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 3.4757	Cost: 9.45s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 3.5446	Cost: 13.56s
Train Epoch: 394 	Average Loss: 3.7062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1796

Saving model as e394_model.pt & e394_waveforms_supplementary.hdf5
Learning rate: 0.00019923491862342552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 5.1399	Cost: 33.40s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 3.3015	Cost: 9.45s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 3.6223	Cost: 11.99s
Train Epoch: 395 	Average Loss: 3.6614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3758

Learning rate: 0.0001992310350244222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 5.3735	Cost: 33.14s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 3.4813	Cost: 9.47s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 3.7026	Cost: 11.75s
Train Epoch: 396 	Average Loss: 3.7532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3180

Learning rate: 0.0001992271416317084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 5.1814	Cost: 34.04s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 3.4200	Cost: 9.47s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 3.6045	Cost: 12.92s
Train Epoch: 397 	Average Loss: 3.7171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2309

Learning rate: 0.0001992232384456683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 5.3192	Cost: 34.13s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 3.3971	Cost: 9.47s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 3.5383	Cost: 12.97s
Train Epoch: 398 	Average Loss: 3.7597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2799

Learning rate: 0.00019921932546668718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 5.4364	Cost: 33.03s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 3.4612	Cost: 9.46s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 3.5356	Cost: 12.10s
Train Epoch: 399 	Average Loss: 3.6998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1953

Learning rate: 0.00019921540269515121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 5.2140	Cost: 33.20s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 3.3707	Cost: 9.48s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 3.5584	Cost: 11.86s
Train Epoch: 400 	Average Loss: 3.6685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3693

Learning rate: 0.0001992114701314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 5.1636	Cost: 33.99s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 3.3723	Cost: 9.46s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 3.4691	Cost: 12.77s
Train Epoch: 401 	Average Loss: 3.6852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2208

Learning rate: 0.00019920752777596444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 5.0241	Cost: 33.35s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 3.4093	Cost: 9.46s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 3.3989	Cost: 11.83s
Train Epoch: 402 	Average Loss: 3.5974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1292

Saving model as e402_model.pt & e402_waveforms_supplementary.hdf5
Learning rate: 0.00019920357562909082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 5.3013	Cost: 33.03s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 3.1696	Cost: 9.48s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 3.2959	Cost: 11.78s
Train Epoch: 403 	Average Loss: 3.5152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1755

Learning rate: 0.00019919961369121682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 4.9437	Cost: 33.53s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 3.2454	Cost: 9.49s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 3.2404	Cost: 11.96s
Train Epoch: 404 	Average Loss: 3.4846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1165

Saving model as e404_model.pt & e404_waveforms_supplementary.hdf5
Learning rate: 0.00019919564196273348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 5.1270	Cost: 33.99s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 3.2342	Cost: 9.47s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 3.4582	Cost: 12.66s
Train Epoch: 405 	Average Loss: 3.4786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0924

Saving model as e405_model.pt & e405_waveforms_supplementary.hdf5
Learning rate: 0.00019919166044403278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 5.1883	Cost: 32.95s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 3.3572	Cost: 9.48s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 3.4792	Cost: 13.07s
Train Epoch: 406 	Average Loss: 3.5895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0967

Learning rate: 0.00019918766913550764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 5.1778	Cost: 33.15s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 3.2122	Cost: 9.47s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 3.3699	Cost: 11.95s
Train Epoch: 407 	Average Loss: 3.5038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9104

Saving model as e407_model.pt & e407_waveforms_supplementary.hdf5
Learning rate: 0.00019918366803755205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 4.9825	Cost: 33.15s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 3.1567	Cost: 9.47s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 3.2827	Cost: 11.86s
Train Epoch: 408 	Average Loss: 3.4071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0098

Learning rate: 0.00019917965715056087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 5.0133	Cost: 33.76s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 3.0555	Cost: 9.47s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 3.2774	Cost: 12.17s
Train Epoch: 409 	Average Loss: 3.3872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0224

Learning rate: 0.00019917563647492995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 4.9146	Cost: 34.38s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 3.1274	Cost: 9.65s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 3.1505	Cost: 12.88s
Train Epoch: 410 	Average Loss: 3.3847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9344

Learning rate: 0.00019917160601105614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 4.8890	Cost: 33.98s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 3.1912	Cost: 9.50s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 3.2318	Cost: 12.60s
Train Epoch: 411 	Average Loss: 3.3823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0573

Learning rate: 0.0001991675657593372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 5.0962	Cost: 33.70s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 3.1058	Cost: 9.49s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 3.1170	Cost: 13.05s
Train Epoch: 412 	Average Loss: 3.3701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9248

Learning rate: 0.00019916351572017192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 4.7286	Cost: 33.93s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 3.0102	Cost: 9.48s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 3.1821	Cost: 12.75s
Train Epoch: 413 	Average Loss: 3.2966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0123

Learning rate: 0.00019915945589396003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 5.1647	Cost: 33.54s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 3.1348	Cost: 9.47s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 3.2727	Cost: 13.32s
Train Epoch: 414 	Average Loss: 3.4139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0304

Learning rate: 0.00019915538628110217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 5.0242	Cost: 33.57s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 3.1659	Cost: 9.50s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 3.1318	Cost: 12.45s
Train Epoch: 415 	Average Loss: 3.3226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0311

Learning rate: 0.00019915130688200001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 4.8004	Cost: 33.32s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 3.0804	Cost: 9.48s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 3.0804	Cost: 11.71s
Train Epoch: 416 	Average Loss: 3.2833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9715

Learning rate: 0.0001991472176970562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 4.9378	Cost: 33.64s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 2.9811	Cost: 9.48s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 3.1388	Cost: 13.39s
Train Epoch: 417 	Average Loss: 3.2073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8588

Saving model as e417_model.pt & e417_waveforms_supplementary.hdf5
Learning rate: 0.00019914311872667434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 4.8805	Cost: 33.39s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 2.9409	Cost: 9.48s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 2.9660	Cost: 12.03s
Train Epoch: 418 	Average Loss: 3.1950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9509

Learning rate: 0.0001991390099712589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 5.0901	Cost: 33.01s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 2.8909	Cost: 9.44s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 3.0445	Cost: 12.00s
Train Epoch: 419 	Average Loss: 3.1638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8559

Saving model as e419_model.pt & e419_waveforms_supplementary.hdf5
Learning rate: 0.00019913489143121547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 4.8596	Cost: 33.10s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 3.3307	Cost: 9.47s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 3.4506	Cost: 11.82s
Train Epoch: 420 	Average Loss: 3.4901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0932

Learning rate: 0.0001991307631069505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 5.0968	Cost: 33.58s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 3.1695	Cost: 9.48s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 3.2341	Cost: 13.35s
Train Epoch: 421 	Average Loss: 3.4386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0588

Learning rate: 0.0001991266249988715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 5.0827	Cost: 33.60s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 2.9690	Cost: 9.44s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 3.0721	Cost: 13.05s
Train Epoch: 422 	Average Loss: 3.2787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8852

Learning rate: 0.00019912247710738676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 5.0821	Cost: 33.99s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 2.9834	Cost: 9.50s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 3.0807	Cost: 13.04s
Train Epoch: 423 	Average Loss: 3.2078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8992

Learning rate: 0.0001991183194329058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 4.9243	Cost: 33.34s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 2.7928	Cost: 9.48s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 2.9323	Cost: 13.65s
Train Epoch: 424 	Average Loss: 3.0986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7636

Saving model as e424_model.pt & e424_waveforms_supplementary.hdf5
Learning rate: 0.00019911415197583891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 4.8217	Cost: 33.75s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 2.8881	Cost: 9.48s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 2.8566	Cost: 13.37s
Train Epoch: 425 	Average Loss: 3.1080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8724

Learning rate: 0.00019910997473659734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 4.9070	Cost: 33.81s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 2.9472	Cost: 9.43s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 2.9476	Cost: 12.12s
Train Epoch: 426 	Average Loss: 3.0962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7769

Learning rate: 0.00019910578771559345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 4.6941	Cost: 33.45s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 2.5780	Cost: 9.49s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 2.8962	Cost: 12.77s
Train Epoch: 427 	Average Loss: 3.0309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8112

Learning rate: 0.00019910159091324043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 4.7813	Cost: 34.19s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 2.7237	Cost: 9.51s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 2.9216	Cost: 12.95s
Train Epoch: 428 	Average Loss: 3.0123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7427

Saving model as e428_model.pt & e428_waveforms_supplementary.hdf5
Learning rate: 0.00019909738432995254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 4.7223	Cost: 33.50s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 2.7539	Cost: 9.44s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 2.8380	Cost: 12.38s
Train Epoch: 429 	Average Loss: 3.0073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7132

Saving model as e429_model.pt & e429_waveforms_supplementary.hdf5
Learning rate: 0.00019909316796614494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 4.6935	Cost: 33.08s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 2.7106	Cost: 9.47s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 2.6771	Cost: 11.78s
Train Epoch: 430 	Average Loss: 2.9597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6871

Saving model as e430_model.pt & e430_waveforms_supplementary.hdf5
Learning rate: 0.00019908894182223372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 4.8174	Cost: 34.21s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 2.6660	Cost: 9.64s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 3.1327	Cost: 12.91s
Train Epoch: 431 	Average Loss: 3.0606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9193

Learning rate: 0.00019908470589863605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 4.8143	Cost: 33.56s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 2.9756	Cost: 9.46s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 2.9864	Cost: 12.20s
Train Epoch: 432 	Average Loss: 3.1689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9003

Learning rate: 0.00019908046019576994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 4.8756	Cost: 33.86s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 2.9377	Cost: 9.47s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 2.9425	Cost: 12.83s
Train Epoch: 433 	Average Loss: 3.1066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7816

Learning rate: 0.00019907620471405445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 4.6676	Cost: 34.00s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 2.8823	Cost: 9.46s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 2.9011	Cost: 11.89s
Train Epoch: 434 	Average Loss: 3.1106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7628

Learning rate: 0.0001990719394539096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 4.8143	Cost: 34.00s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 2.6976	Cost: 9.49s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 2.8929	Cost: 13.00s
Train Epoch: 435 	Average Loss: 3.0360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7354

Learning rate: 0.0001990676644157563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 4.8142	Cost: 33.47s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 2.6530	Cost: 9.48s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 2.9170	Cost: 12.19s
Train Epoch: 436 	Average Loss: 2.9138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5363

Saving model as e436_model.pt & e436_waveforms_supplementary.hdf5
Learning rate: 0.00019906337960001657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 4.7697	Cost: 33.99s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 2.7665	Cost: 9.49s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 2.6914	Cost: 13.00s
Train Epoch: 437 	Average Loss: 2.9835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6656

Learning rate: 0.0001990590850071132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 4.7609	Cost: 34.77s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 2.6303	Cost: 9.46s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 2.7614	Cost: 12.52s
Train Epoch: 438 	Average Loss: 2.8739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7620

Learning rate: 0.0001990547806374701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 4.6010	Cost: 33.41s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 2.5305	Cost: 9.46s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 2.6802	Cost: 13.09s
Train Epoch: 439 	Average Loss: 2.8725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6284

Learning rate: 0.00019905046649151213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 4.5868	Cost: 33.63s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 2.4031	Cost: 9.47s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 2.7451	Cost: 12.24s
Train Epoch: 440 	Average Loss: 2.7942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7087

Learning rate: 0.00019904614256966498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 4.5084	Cost: 33.57s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 2.5444	Cost: 9.47s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 2.7835	Cost: 13.08s
Train Epoch: 441 	Average Loss: 2.8181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6290

Learning rate: 0.00019904180887235552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 4.5484	Cost: 33.44s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 2.4669	Cost: 9.46s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 2.5203	Cost: 12.44s
Train Epoch: 442 	Average Loss: 2.7630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6938

Learning rate: 0.0001990374654000114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 4.5860	Cost: 33.88s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 2.4957	Cost: 9.47s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 2.5879	Cost: 12.46s
Train Epoch: 443 	Average Loss: 2.7251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5643

Learning rate: 0.0001990331121530613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 4.6168	Cost: 33.67s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 2.5167	Cost: 9.47s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 2.6360	Cost: 13.01s
Train Epoch: 444 	Average Loss: 2.8241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5838

Learning rate: 0.0001990287491319349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 4.5062	Cost: 34.11s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 2.4490	Cost: 9.48s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 2.5911	Cost: 13.35s
Train Epoch: 445 	Average Loss: 2.7267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4345

Saving model as e445_model.pt & e445_waveforms_supplementary.hdf5
Learning rate: 0.00019902437633706276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 4.5611	Cost: 32.99s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 2.7027	Cost: 9.43s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 2.6495	Cost: 13.73s
Train Epoch: 446 	Average Loss: 2.8131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5587

Learning rate: 0.0001990199937688765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 4.4861	Cost: 33.05s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 2.4924	Cost: 9.48s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 2.6117	Cost: 12.79s
Train Epoch: 447 	Average Loss: 2.7373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4872

Learning rate: 0.00019901560142780868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 4.5099	Cost: 33.37s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 2.4572	Cost: 9.47s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 2.6175	Cost: 11.94s
Train Epoch: 448 	Average Loss: 2.7328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3903

Saving model as e448_model.pt & e448_waveforms_supplementary.hdf5
Learning rate: 0.0001990111993142928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 4.3677	Cost: 33.93s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 2.2090	Cost: 9.46s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 2.4295	Cost: 13.35s
Train Epoch: 449 	Average Loss: 2.5481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4536

Learning rate: 0.0001990067874287633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 4.1679	Cost: 33.82s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 2.2933	Cost: 9.46s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 2.4734	Cost: 13.10s
Train Epoch: 450 	Average Loss: 2.5116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3256

Saving model as e450_model.pt & e450_waveforms_supplementary.hdf5
Learning rate: 0.00019900236577165563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 4.3356	Cost: 33.92s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 2.3125	Cost: 9.49s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 2.5335	Cost: 11.66s
Train Epoch: 451 	Average Loss: 2.5806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4713

Learning rate: 0.00019899793434340619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 4.3441	Cost: 33.62s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 2.2366	Cost: 9.49s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 2.4576	Cost: 13.68s
Train Epoch: 452 	Average Loss: 2.5770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4765

Learning rate: 0.00019899349314445237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 4.4880	Cost: 33.31s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 2.2839	Cost: 9.49s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 2.3395	Cost: 12.42s
Train Epoch: 453 	Average Loss: 2.5470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3140

Saving model as e453_model.pt & e453_waveforms_supplementary.hdf5
Learning rate: 0.00019898904217523244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 4.3047	Cost: 33.57s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 2.2259	Cost: 9.47s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 2.2692	Cost: 12.94s
Train Epoch: 454 	Average Loss: 2.4940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3775

Learning rate: 0.00019898458143618574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 4.4123	Cost: 33.26s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 2.1777	Cost: 9.46s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 2.3664	Cost: 12.35s
Train Epoch: 455 	Average Loss: 2.5051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3492

Learning rate: 0.0001989801109277525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 4.3472	Cost: 33.89s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 2.2792	Cost: 9.48s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 2.3062	Cost: 12.90s
Train Epoch: 456 	Average Loss: 2.5209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4274

Learning rate: 0.000198975630650374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 4.3967	Cost: 33.39s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 2.1160	Cost: 9.47s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 2.1651	Cost: 13.74s
Train Epoch: 457 	Average Loss: 2.4333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2295

Saving model as e457_model.pt & e457_waveforms_supplementary.hdf5
Learning rate: 0.0001989711406044923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 4.1824	Cost: 33.28s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 2.0960	Cost: 9.50s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 2.2309	Cost: 11.84s
Train Epoch: 458 	Average Loss: 2.3508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1918

Saving model as e458_model.pt & e458_waveforms_supplementary.hdf5
Learning rate: 0.0001989666407905507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 4.3615	Cost: 33.01s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 2.0322	Cost: 9.48s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 2.2333	Cost: 12.64s
Train Epoch: 459 	Average Loss: 2.3801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2441

Learning rate: 0.00019896213120899325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 4.1320	Cost: 33.53s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 2.1423	Cost: 9.49s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 2.2470	Cost: 11.92s
Train Epoch: 460 	Average Loss: 2.3785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2360

Learning rate: 0.00019895761186026497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 4.2754	Cost: 34.14s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 1.9667	Cost: 9.49s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 2.1688	Cost: 13.01s
Train Epoch: 461 	Average Loss: 2.3080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1820

Saving model as e461_model.pt & e461_waveforms_supplementary.hdf5
Learning rate: 0.000198953082744812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 4.3576	Cost: 33.93s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 2.1134	Cost: 9.52s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 2.3347	Cost: 12.51s
Train Epoch: 462 	Average Loss: 2.3991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3896

Learning rate: 0.0001989485438630813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 4.3669	Cost: 33.86s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 2.1659	Cost: 9.47s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 2.2458	Cost: 13.05s
Train Epoch: 463 	Average Loss: 2.4712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3318

Learning rate: 0.00019894399521552084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 4.1710	Cost: 33.68s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 2.1462	Cost: 9.46s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 3.4400	Cost: 12.22s
Train Epoch: 464 	Average Loss: 2.6602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2893

Learning rate: 0.0001989394368025795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 5.1433	Cost: 33.26s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 3.0301	Cost: 9.50s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 2.8530	Cost: 13.73s
Train Epoch: 465 	Average Loss: 3.2946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7047

Learning rate: 0.0001989348686247073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 4.6894	Cost: 33.40s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 2.4970	Cost: 9.45s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 2.5206	Cost: 11.91s
Train Epoch: 466 	Average Loss: 2.7795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4164

Learning rate: 0.000198930290682355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 4.4219	Cost: 33.27s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 2.2642	Cost: 9.51s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 2.4719	Cost: 12.97s
Train Epoch: 467 	Average Loss: 2.6385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3867

Learning rate: 0.00019892570297597447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 4.4439	Cost: 33.78s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 2.2700	Cost: 9.50s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 2.3616	Cost: 13.11s
Train Epoch: 468 	Average Loss: 2.5091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3737

Learning rate: 0.00019892110550601846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 4.4514	Cost: 32.96s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 2.3221	Cost: 9.49s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 2.3149	Cost: 12.49s
Train Epoch: 469 	Average Loss: 2.5543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4001

Learning rate: 0.00019891649827294077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 4.4161	Cost: 33.49s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 2.1526	Cost: 9.49s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 2.1432	Cost: 13.62s
Train Epoch: 470 	Average Loss: 2.4020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1674

Saving model as e470_model.pt & e470_waveforms_supplementary.hdf5
Learning rate: 0.00019891188127719607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 4.1505	Cost: 33.60s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 2.0726	Cost: 9.48s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 2.2951	Cost: 12.99s
Train Epoch: 471 	Average Loss: 2.3397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2585

Learning rate: 0.00019890725451924011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 4.2132	Cost: 34.66s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 1.9427	Cost: 9.48s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 2.1358	Cost: 12.49s
Train Epoch: 472 	Average Loss: 2.2591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1649

Saving model as e472_model.pt & e472_waveforms_supplementary.hdf5
Learning rate: 0.00019890261799952944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 3.9244	Cost: 33.44s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 2.0461	Cost: 9.48s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 2.1366	Cost: 12.73s
Train Epoch: 473 	Average Loss: 2.2317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0590

Saving model as e473_model.pt & e473_waveforms_supplementary.hdf5
Learning rate: 0.00019889797171852172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 4.0584	Cost: 33.13s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 2.4074	Cost: 9.47s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 2.2849	Cost: 12.16s
Train Epoch: 474 	Average Loss: 2.4688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4172

Learning rate: 0.0001988933156766755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 4.3133	Cost: 33.08s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 2.1785	Cost: 9.45s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 2.0642	Cost: 12.42s
Train Epoch: 475 	Average Loss: 2.3777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1321

Learning rate: 0.00019888864987445035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 3.9552	Cost: 34.57s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 1.9399	Cost: 9.43s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 1.8818	Cost: 13.16s
Train Epoch: 476 	Average Loss: 2.1789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0689

Learning rate: 0.00019888397431230674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 3.8834	Cost: 33.67s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 1.8124	Cost: 9.50s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 2.1682	Cost: 13.50s
Train Epoch: 477 	Average Loss: 2.1351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1998

Learning rate: 0.00019887928899070613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 4.1512	Cost: 34.00s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 1.8998	Cost: 9.51s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 2.0025	Cost: 13.70s
Train Epoch: 478 	Average Loss: 2.1992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0247

Saving model as e478_model.pt & e478_waveforms_supplementary.hdf5
Learning rate: 0.00019887459391011093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 4.1584	Cost: 33.44s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 1.7900	Cost: 9.49s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 1.8313	Cost: 12.46s
Train Epoch: 479 	Average Loss: 2.0571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0225

Saving model as e479_model.pt & e479_waveforms_supplementary.hdf5
Learning rate: 0.0001988698890709845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 3.9996	Cost: 33.35s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 1.6861	Cost: 9.48s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 1.9483	Cost: 11.94s
Train Epoch: 480 	Average Loss: 2.0075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0759

Learning rate: 0.0001988651744737913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 3.9631	Cost: 33.52s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 1.8123	Cost: 9.52s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 1.7906	Cost: 13.35s
Train Epoch: 481 	Average Loss: 2.0420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9174

Saving model as e481_model.pt & e481_waveforms_supplementary.hdf5
Learning rate: 0.00019886045011899655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 3.8739	Cost: 34.09s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 1.7865	Cost: 9.47s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 1.8006	Cost: 13.09s
Train Epoch: 482 	Average Loss: 2.0186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9256

Learning rate: 0.00019885571600706652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 4.0454	Cost: 33.80s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 1.6101	Cost: 9.52s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 1.8914	Cost: 12.30s
Train Epoch: 483 	Average Loss: 1.9747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0536

Learning rate: 0.00019885097213846847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 3.8277	Cost: 33.83s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 1.6965	Cost: 9.48s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 1.8413	Cost: 13.23s
Train Epoch: 484 	Average Loss: 1.9927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9958

Learning rate: 0.00019884621851367065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 3.9513	Cost: 34.42s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 1.6587	Cost: 9.49s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 1.7843	Cost: 12.58s
Train Epoch: 485 	Average Loss: 1.9760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8933

Saving model as e485_model.pt & e485_waveforms_supplementary.hdf5
Learning rate: 0.00019884145513314214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 3.9267	Cost: 33.23s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 1.7281	Cost: 9.46s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 1.7045	Cost: 12.09s
Train Epoch: 486 	Average Loss: 1.8924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8425

Saving model as e486_model.pt & e486_waveforms_supplementary.hdf5
Learning rate: 0.00019883668199735307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 3.7150	Cost: 33.51s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 1.5838	Cost: 9.46s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 1.6576	Cost: 11.60s
Train Epoch: 487 	Average Loss: 1.8349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7494

Saving model as e487_model.pt & e487_waveforms_supplementary.hdf5
Learning rate: 0.00019883189910677464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 3.8752	Cost: 32.87s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 1.5904	Cost: 9.50s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 1.8875	Cost: 12.06s
Train Epoch: 488 	Average Loss: 1.9236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7750

Learning rate: 0.00019882710646187875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 4.0568	Cost: 33.81s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 1.5499	Cost: 9.48s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 1.7043	Cost: 13.28s
Train Epoch: 489 	Average Loss: 1.8583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7953

Learning rate: 0.00019882230406313855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 3.8443	Cost: 33.53s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 1.4633	Cost: 9.47s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 1.7302	Cost: 12.20s
Train Epoch: 490 	Average Loss: 1.7646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7389

Saving model as e490_model.pt & e490_waveforms_supplementary.hdf5
Learning rate: 0.00019881749191102795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 3.7690	Cost: 33.07s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 1.6299	Cost: 9.47s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 1.5371	Cost: 11.90s
Train Epoch: 491 	Average Loss: 1.8247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8010

Learning rate: 0.00019881267000602186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 3.7531	Cost: 33.10s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 1.4629	Cost: 9.48s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 1.5501	Cost: 11.98s
Train Epoch: 492 	Average Loss: 1.7302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7240

Saving model as e492_model.pt & e492_waveforms_supplementary.hdf5
Learning rate: 0.00019880783834859626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 3.7554	Cost: 33.06s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 1.4958	Cost: 9.49s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 1.6145	Cost: 12.07s
Train Epoch: 493 	Average Loss: 1.7155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8466

Learning rate: 0.000198802996939228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 3.8327	Cost: 33.68s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 1.3985	Cost: 9.51s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 1.6105	Cost: 12.51s
Train Epoch: 494 	Average Loss: 1.7327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8635

Learning rate: 0.0001987981457783948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 3.9423	Cost: 33.41s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 1.4039	Cost: 9.48s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 1.7225	Cost: 13.37s
Train Epoch: 495 	Average Loss: 1.8126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8050

Learning rate: 0.00019879328486657562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 3.8023	Cost: 33.47s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 1.6187	Cost: 9.46s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 1.6650	Cost: 11.79s
Train Epoch: 496 	Average Loss: 1.8234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8140

Learning rate: 0.0001987884142042501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 3.8044	Cost: 33.27s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 1.4977	Cost: 9.47s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 1.6668	Cost: 13.12s
Train Epoch: 497 	Average Loss: 1.7659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7716

Learning rate: 0.00019878353379189899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 3.5766	Cost: 33.15s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 1.3280	Cost: 9.46s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 1.3543	Cost: 12.12s
Train Epoch: 498 	Average Loss: 1.5957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6193

Saving model as e498_model.pt & e498_waveforms_supplementary.hdf5
Learning rate: 0.00019877864363000396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 3.6725	Cost: 33.54s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 1.6815	Cost: 9.48s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 1.8272	Cost: 12.02s
Train Epoch: 499 	Average Loss: 1.8548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9829

Learning rate: 0.00019877374371904765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 4.1458	Cost: 33.69s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 1.8155	Cost: 9.48s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 1.9402	Cost: 12.20s
Train Epoch: 500 	Average Loss: 2.0697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0458

Stopping timer.
Training time (including validation): 49441.922541856766 seconds
Saving model
Transfer learning by starting with alpha=0.9!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 46.0409	Cost: 32.55s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 25.2443	Cost: 9.51s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 18.5027	Cost: 12.04s
Train Epoch: 1 	Average Loss: 25.2089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9828

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.0001999980260856137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 17.3451	Cost: 33.31s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 14.3876	Cost: 9.85s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 13.2261	Cost: 12.26s
Train Epoch: 2 	Average Loss: 14.6714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0052

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 12.4006	Cost: 30.87s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 10.8855	Cost: 9.43s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 10.8825	Cost: 12.67s
Train Epoch: 3 	Average Loss: 11.3422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4794

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 10.2492	Cost: 31.80s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 9.6967	Cost: 9.42s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 9.5865	Cost: 11.81s
Train Epoch: 4 	Average Loss: 9.6354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7616

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892833004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 8.8045	Cost: 30.60s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 7.9280	Cost: 9.40s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 7.5359	Cost: 12.10s
Train Epoch: 5 	Average Loss: 8.2607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0251

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 8.1436	Cost: 32.61s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 7.3765	Cost: 9.42s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 7.3194	Cost: 11.87s
Train Epoch: 6 	Average Loss: 7.5322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2157

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 7.3070	Cost: 31.03s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 7.2677	Cost: 9.36s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 6.4477	Cost: 11.88s
Train Epoch: 7 	Average Loss: 6.8915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6894

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 6.7309	Cost: 31.76s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 6.6277	Cost: 9.42s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 6.1967	Cost: 11.90s
Train Epoch: 8 	Average Loss: 6.3651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9240

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019987369566060184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 6.1314	Cost: 30.86s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 6.4870	Cost: 9.62s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 5.6888	Cost: 12.67s
Train Epoch: 9 	Average Loss: 5.8860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7131

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019984015501089758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 5.7784	Cost: 30.56s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 5.6401	Cost: 9.40s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 5.4430	Cost: 12.56s
Train Epoch: 10 	Average Loss: 5.4733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3520

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 5.8675	Cost: 31.13s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 5.5997	Cost: 9.43s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 5.2555	Cost: 11.82s
Train Epoch: 11 	Average Loss: 5.2956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1841

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019976125063612257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 5.3515	Cost: 31.33s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 4.8820	Cost: 9.41s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 4.6997	Cost: 12.70s
Train Epoch: 12 	Average Loss: 4.9283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0171

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019971589002606144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 5.0264	Cost: 31.34s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 4.6751	Cost: 9.40s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 4.9729	Cost: 12.33s
Train Epoch: 13 	Average Loss: 4.8044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6470

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.00019966659280340303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 4.7404	Cost: 31.36s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 4.3694	Cost: 9.39s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 4.5731	Cost: 12.68s
Train Epoch: 14 	Average Loss: 4.5335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4546

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001996133609143173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 5.0219	Cost: 30.78s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 4.3513	Cost: 9.38s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 4.3675	Cost: 12.42s
Train Epoch: 15 	Average Loss: 4.4143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3589

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 4.5249	Cost: 31.58s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 4.0761	Cost: 9.41s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 4.0527	Cost: 12.79s
Train Epoch: 16 	Average Loss: 4.1120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0164

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.00019949510169813006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 4.4145	Cost: 31.13s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 3.9995	Cost: 9.39s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 3.9543	Cost: 12.76s
Train Epoch: 17 	Average Loss: 3.9512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0114

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019943007903969992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 4.3590	Cost: 30.93s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 3.8842	Cost: 9.40s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 3.8501	Cost: 13.00s
Train Epoch: 18 	Average Loss: 3.8795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8429

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.00019936113105200088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 4.2454	Cost: 31.21s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 3.8510	Cost: 9.42s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 3.6226	Cost: 11.84s
Train Epoch: 19 	Average Loss: 3.7306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6099

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.0001992882604569814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 4.1532	Cost: 30.91s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 3.4295	Cost: 9.43s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 3.4644	Cost: 13.05s
Train Epoch: 20 	Average Loss: 3.5488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5084

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019921147013144782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 3.9289	Cost: 31.36s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 3.5676	Cost: 9.42s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 3.6268	Cost: 12.33s
Train Epoch: 21 	Average Loss: 3.4248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3537

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.00019913076310695068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 3.6865	Cost: 31.38s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 3.2073	Cost: 9.40s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 3.2788	Cost: 12.00s
Train Epoch: 22 	Average Loss: 3.2929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4238

Learning rate: 0.00019904614256966512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 3.6734	Cost: 31.23s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 3.4682	Cost: 9.40s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 3.1506	Cost: 11.82s
Train Epoch: 23 	Average Loss: 3.1906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2490

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.0001989576118602651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 3.6041	Cost: 32.17s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 3.1784	Cost: 9.39s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 3.2115	Cost: 12.61s
Train Epoch: 24 	Average Loss: 3.1065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2679

Learning rate: 0.0001988651744737914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 3.4759	Cost: 31.28s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 2.8706	Cost: 9.60s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 2.9647	Cost: 12.87s
Train Epoch: 25 	Average Loss: 2.9463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9414

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.0001987688340595138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 3.5605	Cost: 31.14s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 2.9732	Cost: 9.41s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 3.0448	Cost: 11.82s
Train Epoch: 26 	Average Loss: 2.8761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0731

Learning rate: 0.00019866859442078683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 3.5433	Cost: 31.35s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 2.7714	Cost: 9.41s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 2.8217	Cost: 12.20s
Train Epoch: 27 	Average Loss: 2.7755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1247

Learning rate: 0.00019856445951489985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 3.4439	Cost: 30.77s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 2.6240	Cost: 10.10s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 2.9014	Cost: 11.17s
Train Epoch: 28 	Average Loss: 2.7292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8303

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.0001984564334529206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 3.4138	Cost: 32.15s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 2.5033	Cost: 9.39s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 2.5528	Cost: 12.34s
Train Epoch: 29 	Average Loss: 2.5616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8443

Learning rate: 0.00019834452049953302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 3.1374	Cost: 32.75s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 2.7670	Cost: 9.39s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 2.5814	Cost: 13.14s
Train Epoch: 30 	Average Loss: 2.5733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7616

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.00019822872507286893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 3.1182	Cost: 31.54s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 2.4874	Cost: 9.41s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 2.2599	Cost: 13.00s
Train Epoch: 31 	Average Loss: 2.4438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5575

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 0.00019810905174433345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 2.8755	Cost: 31.90s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 2.4996	Cost: 9.39s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 2.4918	Cost: 11.86s
Train Epoch: 32 	Average Loss: 2.3532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6748

Learning rate: 0.00019798550523842474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 2.9734	Cost: 31.98s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 2.4050	Cost: 9.42s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 2.3130	Cost: 13.53s
Train Epoch: 33 	Average Loss: 2.3274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5974

Learning rate: 0.00019785809043254728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 3.0677	Cost: 32.56s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 2.0241	Cost: 9.40s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 2.2175	Cost: 12.41s
Train Epoch: 34 	Average Loss: 2.2174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4808

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019772681235681944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 2.7285	Cost: 32.21s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 1.9654	Cost: 9.41s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 2.3200	Cost: 12.80s
Train Epoch: 35 	Average Loss: 2.1409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4939

Learning rate: 0.00019759167619387482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 2.9317	Cost: 32.58s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 2.1254	Cost: 9.35s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 2.0606	Cost: 12.70s
Train Epoch: 36 	Average Loss: 2.0693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3684

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.0001974526872786578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 2.6446	Cost: 31.75s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 1.9760	Cost: 9.44s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 1.9572	Cost: 12.46s
Train Epoch: 37 	Average Loss: 1.9810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4657

Learning rate: 0.00019730985109821272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 3.0387	Cost: 32.06s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 1.9086	Cost: 9.42s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 2.0468	Cost: 12.18s
Train Epoch: 38 	Average Loss: 1.9959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2794

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.00019716317329146745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 2.6146	Cost: 31.90s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 1.8365	Cost: 9.40s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 1.7442	Cost: 11.74s
Train Epoch: 39 	Average Loss: 1.8931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3667

Learning rate: 0.00019701265964901062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 2.4175	Cost: 32.05s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 1.7928	Cost: 9.40s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 1.7295	Cost: 12.06s
Train Epoch: 40 	Average Loss: 1.8342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2581

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 2.6386	Cost: 32.62s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 1.6206	Cost: 9.61s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 1.6337	Cost: 12.37s
Train Epoch: 41 	Average Loss: 1.7791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1672

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019670014877624353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 2.2220	Cost: 31.27s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 1.6219	Cost: 9.62s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 1.4786	Cost: 12.70s
Train Epoch: 42 	Average Loss: 1.7010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0692

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.0001965381638833274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 2.5014	Cost: 31.81s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 1.5403	Cost: 9.61s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 1.6008	Cost: 12.23s
Train Epoch: 43 	Average Loss: 1.6546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1949

Learning rate: 0.000196372367829001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 2.6956	Cost: 34.09s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 1.6594	Cost: 9.60s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 1.3894	Cost: 13.14s
Train Epoch: 44 	Average Loss: 1.6048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0882

Learning rate: 0.00019620276715860861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 2.6025	Cost: 35.45s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 1.3853	Cost: 9.61s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 1.3573	Cost: 14.05s
Train Epoch: 45 	Average Loss: 1.5233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1238

Learning rate: 0.00019602936856769434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 2.4157	Cost: 35.32s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 1.6170	Cost: 9.70s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 1.1909	Cost: 14.29s
Train Epoch: 46 	Average Loss: 1.4554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7931

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 0.00019585217890173763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 2.4056	Cost: 34.42s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 1.3103	Cost: 9.61s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 1.1358	Cost: 13.63s
Train Epoch: 47 	Average Loss: 1.3717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0732

Learning rate: 0.0001956712051558831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 2.1497	Cost: 37.06s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 1.2539	Cost: 9.59s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 1.2846	Cost: 13.72s
Train Epoch: 48 	Average Loss: 1.4008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0805

Learning rate: 0.00019548645447466434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 2.2335	Cost: 34.81s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 1.3164	Cost: 10.09s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 1.1828	Cost: 17.25s
Train Epoch: 49 	Average Loss: 1.2903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8526

Learning rate: 0.00019529793415172192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 2.1811	Cost: 35.11s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 1.1396	Cost: 9.69s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 1.1738	Cost: 17.19s
Train Epoch: 50 	Average Loss: 1.2412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8576

Learning rate: 0.0001951056516295154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 2.4253	Cost: 37.33s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 0.9517	Cost: 9.76s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 1.1667	Cost: 13.26s
Train Epoch: 51 	Average Loss: 1.1861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7627

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.0001949096144990295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 2.1872	Cost: 38.27s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 1.1953	Cost: 9.91s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 1.2262	Cost: 12.60s
Train Epoch: 52 	Average Loss: 1.1874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8021

Learning rate: 0.00019470983049947442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 2.1461	Cost: 35.70s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 1.0192	Cost: 9.75s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 1.1791	Cost: 14.50s
Train Epoch: 53 	Average Loss: 1.1631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7196

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 0.00019450630751798048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 1.9869	Cost: 33.65s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 0.9909	Cost: 9.95s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 1.0629	Cost: 17.63s
Train Epoch: 54 	Average Loss: 1.0949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7886

Learning rate: 0.00019429905358928646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 2.2148	Cost: 36.34s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 1.0786	Cost: 9.70s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 0.9470	Cost: 19.51s
Train Epoch: 55 	Average Loss: 1.0312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5433

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.00019408807689542257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 1.8166	Cost: 38.11s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 0.8573	Cost: 9.67s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 1.0499	Cost: 14.91s
Train Epoch: 56 	Average Loss: 0.9788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5569

Learning rate: 0.00019387338576538744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 1.9855	Cost: 34.63s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 1.0186	Cost: 9.66s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 1.0848	Cost: 14.39s
Train Epoch: 57 	Average Loss: 0.9899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6883

Learning rate: 0.00019365498867481926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 1.8877	Cost: 35.79s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 1.0283	Cost: 9.63s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 0.9456	Cost: 15.69s
Train Epoch: 58 	Average Loss: 0.9071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6919

Learning rate: 0.00019343289424566122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 1.8888	Cost: 33.14s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 0.7772	Cost: 9.72s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 0.6834	Cost: 19.05s
Train Epoch: 59 	Average Loss: 0.8389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6125

Learning rate: 0.00019320711124582108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 1.6698	Cost: 37.15s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 0.7566	Cost: 9.68s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 0.7070	Cost: 15.02s
Train Epoch: 60 	Average Loss: 0.7745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5150

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00019297764858882514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 2.0548	Cost: 34.82s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 0.5388	Cost: 9.68s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 0.6090	Cost: 13.91s
Train Epoch: 61 	Average Loss: 0.7901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5065

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 0.00019274451533346612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 1.8872	Cost: 37.37s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 0.6720	Cost: 9.59s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 0.5560	Cost: 13.46s
Train Epoch: 62 	Average Loss: 0.7009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3088

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019250772068344577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 1.6257	Cost: 33.54s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 0.8464	Cost: 9.78s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 0.5869	Cost: 17.78s
Train Epoch: 63 	Average Loss: 0.6810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5235

Learning rate: 0.00019226727398701147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 1.8704	Cost: 36.20s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 0.5762	Cost: 9.71s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 0.5155	Cost: 17.49s
Train Epoch: 64 	Average Loss: 0.6678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3993

Learning rate: 0.00019202318473658702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 1.6982	Cost: 36.60s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 0.5123	Cost: 9.71s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 0.5284	Cost: 13.32s
Train Epoch: 65 	Average Loss: 0.6086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3355

Learning rate: 0.0001917754625683981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 1.6539	Cost: 35.31s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 0.6665	Cost: 9.69s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 0.3223	Cost: 13.68s
Train Epoch: 66 	Average Loss: 0.5842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4045

Learning rate: 0.00019152411726209174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 1.5543	Cost: 35.62s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 0.2324	Cost: 10.01s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 0.4196	Cost: 13.38s
Train Epoch: 67 	Average Loss: 0.5084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2190

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Learning rate: 0.00019126915874035028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 1.6483	Cost: 33.59s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 0.2709	Cost: 9.94s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 0.4164	Cost: 18.21s
Train Epoch: 68 	Average Loss: 0.4794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2784

Learning rate: 0.00019101059706849957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 1.9614	Cost: 36.74s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 0.4407	Cost: 9.72s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 0.4165	Cost: 19.48s
Train Epoch: 69 	Average Loss: 0.4510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3034

Learning rate: 0.0001907484424541117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 1.6288	Cost: 36.44s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 0.3171	Cost: 9.69s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 0.3644	Cost: 14.29s
Train Epoch: 70 	Average Loss: 0.4346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2023

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Learning rate: 0.00019048270524660196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 1.7115	Cost: 38.05s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 0.1589	Cost: 9.77s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 0.1190	Cost: 13.33s
Train Epoch: 71 	Average Loss: 0.3360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1162

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00019021339593682028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 1.4343	Cost: 35.78s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 0.1823	Cost: 10.12s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 0.0668	Cost: 17.15s
Train Epoch: 72 	Average Loss: 0.2902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1514

Learning rate: 0.0001899405251566371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 1.2887	Cost: 36.07s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 0.0831	Cost: 9.66s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 0.2926	Cost: 19.26s
Train Epoch: 73 	Average Loss: 0.2506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2439

Learning rate: 0.0001896641036785236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 1.6031	Cost: 36.67s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 0.1833	Cost: 9.66s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 0.0515	Cost: 15.13s
Train Epoch: 74 	Average Loss: 0.2234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1971

Learning rate: 0.00018938414241512636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 1.5883	Cost: 37.54s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 0.2674	Cost: 9.57s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 0.1070	Cost: 14.38s
Train Epoch: 75 	Average Loss: 0.2918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2208

Learning rate: 0.00018910065241883677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 1.5748	Cost: 35.28s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 0.1061	Cost: 10.12s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 0.1504	Cost: 12.76s
Train Epoch: 76 	Average Loss: 0.1678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1518

Learning rate: 0.00018881364488135445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 1.5399	Cost: 32.42s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 0.1307	Cost: 9.96s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 0.1918	Cost: 19.69s
Train Epoch: 77 	Average Loss: 0.2249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0700

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Learning rate: 0.00018852313113324552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 1.4833	Cost: 37.22s
Train Epoch: 78 [40960/90000 (45%)]	Loss: -0.0706	Cost: 9.74s
Train Epoch: 78 [81920/90000 (91%)]	Loss: -0.0177	Cost: 15.83s
Train Epoch: 78 	Average Loss: 0.1560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0868

Learning rate: 0.00018822912264349534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 1.2791	Cost: 37.39s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 0.0093	Cost: 9.60s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 0.0039	Cost: 14.78s
Train Epoch: 79 	Average Loss: 0.0742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9431

Saving model as e79_model.pt & e79_waveforms_supplementary.hdf5
Learning rate: 0.00018793163101905563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 1.2549	Cost: 33.73s
Train Epoch: 80 [40960/90000 (45%)]	Loss: -0.0772	Cost: 9.62s
Train Epoch: 80 [81920/90000 (91%)]	Loss: -0.0549	Cost: 12.77s
Train Epoch: 80 	Average Loss: 0.0515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0262

Learning rate: 0.00018763066800438636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 1.5282	Cost: 35.34s
Train Epoch: 81 [40960/90000 (45%)]	Loss: -0.0260	Cost: 10.01s
Train Epoch: 81 [81920/90000 (91%)]	Loss: -0.2491	Cost: 13.70s
Train Epoch: 81 	Average Loss: 0.0346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9194

Saving model as e81_model.pt & e81_waveforms_supplementary.hdf5
Learning rate: 0.000187326245480992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 1.5276	Cost: 33.66s
Train Epoch: 82 [40960/90000 (45%)]	Loss: -0.0770	Cost: 9.75s
Train Epoch: 82 [81920/90000 (91%)]	Loss: -0.1704	Cost: 18.15s
Train Epoch: 82 	Average Loss: -0.0151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9256

Learning rate: 0.00018701837546695256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 1.2808	Cost: 36.59s
Train Epoch: 83 [40960/90000 (45%)]	Loss: -0.2374	Cost: 9.75s
Train Epoch: 83 [81920/90000 (91%)]	Loss: -0.2765	Cost: 16.98s
Train Epoch: 83 	Average Loss: -0.1252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8975

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Learning rate: 0.00018670707011644898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 1.4069	Cost: 35.99s
Train Epoch: 84 [40960/90000 (45%)]	Loss: -0.4057	Cost: 9.69s
Train Epoch: 84 [81920/90000 (91%)]	Loss: -0.1676	Cost: 15.09s
Train Epoch: 84 	Average Loss: -0.1499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8932

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 0.0001863923417192835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 1.3849	Cost: 36.66s
Train Epoch: 85 [40960/90000 (45%)]	Loss: -0.0853	Cost: 9.75s
Train Epoch: 85 [81920/90000 (91%)]	Loss: -0.3309	Cost: 13.73s
Train Epoch: 85 	Average Loss: -0.1184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0073

Learning rate: 0.00018607420270039436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 1.2250	Cost: 34.61s
Train Epoch: 86 [40960/90000 (45%)]	Loss: -0.3074	Cost: 9.67s
Train Epoch: 86 [81920/90000 (91%)]	Loss: -0.4853	Cost: 18.03s
Train Epoch: 86 	Average Loss: -0.2038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9337

Learning rate: 0.00018575266561936523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 1.1382	Cost: 35.94s
Train Epoch: 87 [40960/90000 (45%)]	Loss: -0.3965	Cost: 9.98s
Train Epoch: 87 [81920/90000 (91%)]	Loss: -0.3801	Cost: 18.19s
Train Epoch: 87 	Average Loss: -0.2324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8951

Learning rate: 0.0001854277431699295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 1.3804	Cost: 37.87s
Train Epoch: 88 [40960/90000 (45%)]	Loss: -0.3909	Cost: 9.73s
Train Epoch: 88 [81920/90000 (91%)]	Loss: -0.1014	Cost: 14.61s
Train Epoch: 88 	Average Loss: -0.2769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9696

Learning rate: 0.0001850994481794692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 1.2592	Cost: 37.49s
Train Epoch: 89 [40960/90000 (45%)]	Loss: -0.5084	Cost: 9.79s
Train Epoch: 89 [81920/90000 (91%)]	Loss: -0.2482	Cost: 13.08s
Train Epoch: 89 	Average Loss: -0.3012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6882

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 0.0001847677936085083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 0.9590	Cost: 33.61s
Train Epoch: 90 [40960/90000 (45%)]	Loss: -0.4552	Cost: 10.15s
Train Epoch: 90 [81920/90000 (91%)]	Loss: -0.4756	Cost: 12.83s
Train Epoch: 90 	Average Loss: -0.3260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7581

Learning rate: 0.00018443279255020146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 1.0770	Cost: 34.00s
Train Epoch: 91 [40960/90000 (45%)]	Loss: -0.5237	Cost: 10.09s
Train Epoch: 91 [81920/90000 (91%)]	Loss: -0.5171	Cost: 18.33s
Train Epoch: 91 	Average Loss: -0.3466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7200

Learning rate: 0.00018409445822981687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 1.3748	Cost: 36.23s
Train Epoch: 92 [40960/90000 (45%)]	Loss: -0.6047	Cost: 9.85s
Train Epoch: 92 [81920/90000 (91%)]	Loss: -0.4968	Cost: 16.28s
Train Epoch: 92 	Average Loss: -0.4017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8355

Learning rate: 0.00018375280400421414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 1.2963	Cost: 37.78s
Train Epoch: 93 [40960/90000 (45%)]	Loss: -0.6402	Cost: 9.62s
Train Epoch: 93 [81920/90000 (91%)]	Loss: -0.5524	Cost: 13.05s
Train Epoch: 93 	Average Loss: -0.4434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5595

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 0.00018340784336131708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 1.1633	Cost: 36.07s
Train Epoch: 94 [40960/90000 (45%)]	Loss: -0.5600	Cost: 9.56s
Train Epoch: 94 [81920/90000 (91%)]	Loss: -0.6220	Cost: 16.69s
Train Epoch: 94 	Average Loss: -0.4658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6005

Learning rate: 0.00018305958991958124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 0.9532	Cost: 36.01s
Train Epoch: 95 [40960/90000 (45%)]	Loss: -0.5397	Cost: 9.53s
Train Epoch: 95 [81920/90000 (91%)]	Loss: -0.6475	Cost: 15.90s
Train Epoch: 95 	Average Loss: -0.4984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5497

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 1.0884	Cost: 35.36s
Train Epoch: 96 [40960/90000 (45%)]	Loss: -0.6811	Cost: 9.69s
Train Epoch: 96 [81920/90000 (91%)]	Loss: -0.5868	Cost: 18.13s
Train Epoch: 96 	Average Loss: -0.4648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5944

Learning rate: 0.0001823532597628427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 0.7623	Cost: 37.76s
Train Epoch: 97 [40960/90000 (45%)]	Loss: -0.8801	Cost: 9.68s
Train Epoch: 97 [81920/90000 (91%)]	Loss: -0.4938	Cost: 15.33s
Train Epoch: 97 	Average Loss: -0.5729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5097

Saving model as e97_model.pt & e97_waveforms_supplementary.hdf5
Learning rate: 0.0001819952109325452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 0.6702	Cost: 38.96s
Train Epoch: 98 [40960/90000 (45%)]	Loss: -0.6671	Cost: 9.63s
Train Epoch: 98 [81920/90000 (91%)]	Loss: -0.6133	Cost: 13.49s
Train Epoch: 98 	Average Loss: -0.6048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6175

Learning rate: 0.00018163392507171837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 0.8399	Cost: 33.74s
Train Epoch: 99 [40960/90000 (45%)]	Loss: -0.4882	Cost: 9.54s
Train Epoch: 99 [81920/90000 (91%)]	Loss: -0.6691	Cost: 12.41s
Train Epoch: 99 	Average Loss: -0.5219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6005

Learning rate: 0.00018126941644330935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 0.8706	Cost: 35.41s
Train Epoch: 100 [40960/90000 (45%)]	Loss: -0.5904	Cost: 9.56s
Train Epoch: 100 [81920/90000 (91%)]	Loss: -0.6328	Cost: 27.95s
Train Epoch: 100 	Average Loss: -0.5697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6031

Learning rate: 0.0001809016994374947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 0.9941	Cost: 59.86s
Train Epoch: 101 [40960/90000 (45%)]	Loss: -0.6411	Cost: 10.79s
Train Epoch: 101 [81920/90000 (91%)]	Loss: -0.7072	Cost: 29.25s
Train Epoch: 101 	Average Loss: -0.6189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6006

Learning rate: 0.00018053078857111214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 1.0727	Cost: 61.01s
Train Epoch: 102 [40960/90000 (45%)]	Loss: -0.9297	Cost: 9.65s
Train Epoch: 102 [81920/90000 (91%)]	Loss: -0.7257	Cost: 20.17s
Train Epoch: 102 	Average Loss: -0.7193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5124

Learning rate: 0.00018015669848708761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 1.0003	Cost: 96.38s
Train Epoch: 103 [40960/90000 (45%)]	Loss: -0.6715	Cost: 13.02s
Train Epoch: 103 [81920/90000 (91%)]	Loss: -0.8759	Cost: 53.08s
Train Epoch: 103 	Average Loss: -0.7253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5862

Learning rate: 0.00017977944395385705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 0.8440	Cost: 38.58s
Train Epoch: 104 [40960/90000 (45%)]	Loss: -1.0065	Cost: 9.64s
Train Epoch: 104 [81920/90000 (91%)]	Loss: -0.9776	Cost: 20.61s
Train Epoch: 104 	Average Loss: -0.7477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4113

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Learning rate: 0.00017939903986478347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 0.7775	Cost: 36.95s
Train Epoch: 105 [40960/90000 (45%)]	Loss: -1.1233	Cost: 9.59s
Train Epoch: 105 [81920/90000 (91%)]	Loss: -0.9144	Cost: 19.55s
Train Epoch: 105 	Average Loss: -0.8613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2406

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00017901550123756898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 0.7314	Cost: 42.15s
Train Epoch: 106 [40960/90000 (45%)]	Loss: -1.0791	Cost: 9.47s
Train Epoch: 106 [81920/90000 (91%)]	Loss: -0.7046	Cost: 16.93s
Train Epoch: 106 	Average Loss: -0.7933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5384

Learning rate: 0.00017862884321366183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 1.0848	Cost: 40.81s
Train Epoch: 107 [40960/90000 (45%)]	Loss: -1.0812	Cost: 9.54s
Train Epoch: 107 [81920/90000 (91%)]	Loss: -1.0219	Cost: 14.86s
Train Epoch: 107 	Average Loss: -0.7913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2968

Learning rate: 0.00017823908105765875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 0.8356	Cost: 73.96s
Train Epoch: 108 [40960/90000 (45%)]	Loss: -0.8540	Cost: 13.46s
Train Epoch: 108 [81920/90000 (91%)]	Loss: -0.8366	Cost: 41.78s
Train Epoch: 108 	Average Loss: -0.7710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3596

Learning rate: 0.00017784623015670232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 1.0000	Cost: 97.87s
Train Epoch: 109 [40960/90000 (45%)]	Loss: -1.2085	Cost: 13.94s
Train Epoch: 109 [81920/90000 (91%)]	Loss: -0.9950	Cost: 47.85s
Train Epoch: 109 	Average Loss: -0.8933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3706

Learning rate: 0.00017745030601987337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 0.9340	Cost: 96.54s
Train Epoch: 110 [40960/90000 (45%)]	Loss: -1.2028	Cost: 12.07s
Train Epoch: 110 [81920/90000 (91%)]	Loss: -1.1534	Cost: 49.89s
Train Epoch: 110 	Average Loss: -1.0235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2828

Learning rate: 0.0001770513242775789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 0.7652	Cost: 78.82s
Train Epoch: 111 [40960/90000 (45%)]	Loss: -1.2874	Cost: 11.71s
Train Epoch: 111 [81920/90000 (91%)]	Loss: -1.2622	Cost: 43.27s
Train Epoch: 111 	Average Loss: -1.0171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2130

Saving model as e111_model.pt & e111_waveforms_supplementary.hdf5
Learning rate: 0.00017664930068093498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 0.4560	Cost: 76.89s
Train Epoch: 112 [40960/90000 (45%)]	Loss: -0.9712	Cost: 12.61s
Train Epoch: 112 [81920/90000 (91%)]	Loss: -1.0055	Cost: 37.80s
Train Epoch: 112 	Average Loss: -0.9001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2391

Learning rate: 0.0001762442511011448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 0.5425	Cost: 105.94s
Train Epoch: 113 [40960/90000 (45%)]	Loss: -1.1218	Cost: 11.66s
Train Epoch: 113 [81920/90000 (91%)]	Loss: -0.9291	Cost: 52.75s
Train Epoch: 113 	Average Loss: -0.9046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1624

Saving model as e113_model.pt & e113_waveforms_supplementary.hdf5
Learning rate: 0.0001758361915288722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 0.6544	Cost: 77.69s
Train Epoch: 114 [40960/90000 (45%)]	Loss: -1.1406	Cost: 11.73s
Train Epoch: 114 [81920/90000 (91%)]	Loss: -1.1962	Cost: 47.30s
Train Epoch: 114 	Average Loss: -1.0665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2231

Learning rate: 0.0001754251380736104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 0.5693	Cost: 81.51s
Train Epoch: 115 [40960/90000 (45%)]	Loss: -1.1790	Cost: 13.09s
Train Epoch: 115 [81920/90000 (91%)]	Loss: -1.2246	Cost: 47.21s
Train Epoch: 115 	Average Loss: -1.1261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0323

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 0.5160	Cost: 84.49s
Train Epoch: 116 [40960/90000 (45%)]	Loss: -1.3205	Cost: 11.63s
Train Epoch: 116 [81920/90000 (91%)]	Loss: -1.1753	Cost: 47.59s
Train Epoch: 116 	Average Loss: -1.1007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2736

Learning rate: 0.00017459411454241822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 0.6089	Cost: 80.53s
Train Epoch: 117 [40960/90000 (45%)]	Loss: -1.2194	Cost: 11.72s
Train Epoch: 117 [81920/90000 (91%)]	Loss: -1.1808	Cost: 49.18s
Train Epoch: 117 	Average Loss: -1.0870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3495

Learning rate: 0.00017417417727387391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 0.7956	Cost: 73.23s
Train Epoch: 118 [40960/90000 (45%)]	Loss: -1.2335	Cost: 14.24s
Train Epoch: 118 [81920/90000 (91%)]	Loss: -1.0537	Cost: 42.33s
Train Epoch: 118 	Average Loss: -1.1092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1475

Learning rate: 0.00017375131173581737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 0.6356	Cost: 88.08s
Train Epoch: 119 [40960/90000 (45%)]	Loss: -1.3460	Cost: 13.43s
Train Epoch: 119 [81920/90000 (91%)]	Loss: -1.1606	Cost: 47.69s
Train Epoch: 119 	Average Loss: -1.1183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2283

Learning rate: 0.000173325534622256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 0.6241	Cost: 79.33s
Train Epoch: 120 [40960/90000 (45%)]	Loss: -1.3029	Cost: 11.35s
Train Epoch: 120 [81920/90000 (91%)]	Loss: -1.3700	Cost: 39.57s
Train Epoch: 120 	Average Loss: -1.2138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0363

Learning rate: 0.00017289686274214115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 0.6406	Cost: 82.97s
Train Epoch: 121 [40960/90000 (45%)]	Loss: -1.2804	Cost: 11.40s
Train Epoch: 121 [81920/90000 (91%)]	Loss: -1.4221	Cost: 47.61s
Train Epoch: 121 	Average Loss: -1.2093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1458

Learning rate: 0.00017246531301870466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 0.3379	Cost: 91.59s
Train Epoch: 122 [40960/90000 (45%)]	Loss: -1.3445	Cost: 12.36s
Train Epoch: 122 [81920/90000 (91%)]	Loss: -1.2540	Cost: 47.46s
Train Epoch: 122 	Average Loss: -1.1793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3508

Learning rate: 0.00017203090248879067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 0.5849	Cost: 77.39s
Train Epoch: 123 [40960/90000 (45%)]	Loss: -1.1939	Cost: 12.56s
Train Epoch: 123 [81920/90000 (91%)]	Loss: -1.4354	Cost: 48.14s
Train Epoch: 123 	Average Loss: -1.2357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0694

Learning rate: 0.00017159364830218312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 0.6377	Cost: 97.75s
Train Epoch: 124 [40960/90000 (45%)]	Loss: -1.5823	Cost: 13.03s
Train Epoch: 124 [81920/90000 (91%)]	Loss: -1.7382	Cost: 50.26s
Train Epoch: 124 	Average Loss: -1.3663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8813

Saving model as e124_model.pt & e124_waveforms_supplementary.hdf5
Learning rate: 0.00017115356772092854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 0.2932	Cost: 83.83s
Train Epoch: 125 [40960/90000 (45%)]	Loss: -1.5237	Cost: 11.81s
Train Epoch: 125 [81920/90000 (91%)]	Loss: -1.5947	Cost: 48.30s
Train Epoch: 125 	Average Loss: -1.4564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0200

Learning rate: 0.00017071067811865473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 0.5039	Cost: 80.66s
Train Epoch: 126 [40960/90000 (45%)]	Loss: -1.5844	Cost: 13.96s
Train Epoch: 126 [81920/90000 (91%)]	Loss: -1.4379	Cost: 42.51s
Train Epoch: 126 	Average Loss: -1.4197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9449

Learning rate: 0.00017026499697988493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 0.4926	Cost: 76.54s
Train Epoch: 127 [40960/90000 (45%)]	Loss: -1.3512	Cost: 13.91s
Train Epoch: 127 [81920/90000 (91%)]	Loss: -1.7106	Cost: 44.07s
Train Epoch: 127 	Average Loss: -1.3940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1286

Learning rate: 0.00016981654189934727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 0.4212	Cost: 81.49s
Train Epoch: 128 [40960/90000 (45%)]	Loss: -1.4581	Cost: 12.38s
Train Epoch: 128 [81920/90000 (91%)]	Loss: -1.5843	Cost: 46.42s
Train Epoch: 128 	Average Loss: -1.4398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0158

Learning rate: 0.0001693653305812805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 0.5453	Cost: 87.39s
Train Epoch: 129 [40960/90000 (45%)]	Loss: -1.7077	Cost: 11.78s
Train Epoch: 129 [81920/90000 (91%)]	Loss: -1.6025	Cost: 47.72s
Train Epoch: 129 	Average Loss: -1.4916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8174

Saving model as e129_model.pt & e129_waveforms_supplementary.hdf5
Learning rate: 0.00016891138083873484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: -0.0490	Cost: 79.16s
Train Epoch: 130 [40960/90000 (45%)]	Loss: -1.7106	Cost: 11.58s
Train Epoch: 130 [81920/90000 (91%)]	Loss: -1.5710	Cost: 47.00s
Train Epoch: 130 	Average Loss: -1.5656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0037

Learning rate: 0.00016845471059286887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 0.3050	Cost: 80.60s
Train Epoch: 131 [40960/90000 (45%)]	Loss: -1.6756	Cost: 11.63s
Train Epoch: 131 [81920/90000 (91%)]	Loss: -1.6063	Cost: 47.42s
Train Epoch: 131 	Average Loss: -1.4845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0265

Learning rate: 0.0001679953378722419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 0.3232	Cost: 84.38s
Train Epoch: 132 [40960/90000 (45%)]	Loss: -1.7778	Cost: 11.62s
Train Epoch: 132 [81920/90000 (91%)]	Loss: -1.7224	Cost: 41.30s
Train Epoch: 132 	Average Loss: -1.6043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7416

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Learning rate: 0.00016753328081210242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 0.1400	Cost: 99.11s
Train Epoch: 133 [40960/90000 (45%)]	Loss: -1.8174	Cost: 11.70s
Train Epoch: 133 [81920/90000 (91%)]	Loss: -1.9136	Cost: 43.59s
Train Epoch: 133 	Average Loss: -1.7058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8275

Learning rate: 0.000167068557653672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 0.3949	Cost: 83.95s
Train Epoch: 134 [40960/90000 (45%)]	Loss: -1.7514	Cost: 12.89s
Train Epoch: 134 [81920/90000 (91%)]	Loss: -1.8065	Cost: 47.38s
Train Epoch: 134 	Average Loss: -1.7351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7827

Learning rate: 0.00016660118674342514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 0.1448	Cost: 77.79s
Train Epoch: 135 [40960/90000 (45%)]	Loss: -1.9188	Cost: 11.58s
Train Epoch: 135 [81920/90000 (91%)]	Loss: -2.1115	Cost: 40.26s
Train Epoch: 135 	Average Loss: -1.7875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7772

Learning rate: 0.00016613118653236516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 0.1464	Cost: 82.33s
Train Epoch: 136 [40960/90000 (45%)]	Loss: -1.9447	Cost: 13.56s
Train Epoch: 136 [81920/90000 (91%)]	Loss: -2.0342	Cost: 46.05s
Train Epoch: 136 	Average Loss: -1.7861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7015

Saving model as e136_model.pt & e136_waveforms_supplementary.hdf5
Learning rate: 0.0001656585755752956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 0.0160	Cost: 93.48s
Train Epoch: 137 [40960/90000 (45%)]	Loss: -2.0408	Cost: 13.32s
Train Epoch: 137 [81920/90000 (91%)]	Loss: -1.8604	Cost: 46.58s
Train Epoch: 137 	Average Loss: -1.8112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8444

Learning rate: 0.00016518337253008784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 0.2922	Cost: 84.76s
Train Epoch: 138 [40960/90000 (45%)]	Loss: -2.0093	Cost: 12.06s
Train Epoch: 138 [81920/90000 (91%)]	Loss: -1.9912	Cost: 47.61s
Train Epoch: 138 	Average Loss: -1.7903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8127

Learning rate: 0.0001647055961569444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 0.1696	Cost: 83.13s
Train Epoch: 139 [40960/90000 (45%)]	Loss: -2.1482	Cost: 11.29s
Train Epoch: 139 [81920/90000 (91%)]	Loss: -1.9903	Cost: 48.20s
Train Epoch: 139 	Average Loss: -1.7996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7131

Learning rate: 0.0001642252653176584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 0.1579	Cost: 85.85s
Train Epoch: 140 [40960/90000 (45%)]	Loss: -1.9378	Cost: 13.39s
Train Epoch: 140 [81920/90000 (91%)]	Loss: -1.6428	Cost: 46.44s
Train Epoch: 140 	Average Loss: -1.6464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9935

Learning rate: 0.00016374239897486894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 0.4999	Cost: 92.23s
Train Epoch: 141 [40960/90000 (45%)]	Loss: -2.0068	Cost: 11.79s
Train Epoch: 141 [81920/90000 (91%)]	Loss: -1.7641	Cost: 49.29s
Train Epoch: 141 	Average Loss: -1.7029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8011

Learning rate: 0.0001632570161913124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 0.1719	Cost: 83.03s
Train Epoch: 142 [40960/90000 (45%)]	Loss: -1.9246	Cost: 11.68s
Train Epoch: 142 [81920/90000 (91%)]	Loss: -2.0165	Cost: 49.62s
Train Epoch: 142 	Average Loss: -1.8138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8262

Learning rate: 0.00016276913612907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 0.1537	Cost: 87.95s
Train Epoch: 143 [40960/90000 (45%)]	Loss: -2.1205	Cost: 13.61s
Train Epoch: 143 [81920/90000 (91%)]	Loss: -2.0103	Cost: 47.70s
Train Epoch: 143 	Average Loss: -1.8743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7995

Learning rate: 0.00016227877804881122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 0.2045	Cost: 88.89s
Train Epoch: 144 [40960/90000 (45%)]	Loss: -2.1840	Cost: 14.51s
Train Epoch: 144 [81920/90000 (91%)]	Loss: -2.1658	Cost: 30.77s
Train Epoch: 144 	Average Loss: -1.9597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5517

Saving model as e144_model.pt & e144_waveforms_supplementary.hdf5
Learning rate: 0.0001617859613090334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 0.1252	Cost: 84.47s
Train Epoch: 145 [40960/90000 (45%)]	Loss: -2.0144	Cost: 12.70s
Train Epoch: 145 [81920/90000 (91%)]	Loss: -2.0644	Cost: 44.84s
Train Epoch: 145 	Average Loss: -1.8803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7101

Learning rate: 0.00016129070536529763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: -0.2001	Cost: 79.94s
Train Epoch: 146 [40960/90000 (45%)]	Loss: -2.1454	Cost: 11.76s
Train Epoch: 146 [81920/90000 (91%)]	Loss: -2.1789	Cost: 43.98s
Train Epoch: 146 	Average Loss: -2.0261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5318

Saving model as e146_model.pt & e146_waveforms_supplementary.hdf5
Learning rate: 0.00016079302976946053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 0.2032	Cost: 80.22s
Train Epoch: 147 [40960/90000 (45%)]	Loss: -2.2294	Cost: 14.91s
Train Epoch: 147 [81920/90000 (91%)]	Loss: -2.0349	Cost: 44.79s
Train Epoch: 147 	Average Loss: -2.0010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7923

Learning rate: 0.00016029295416890245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: -0.0898	Cost: 82.04s
Train Epoch: 148 [40960/90000 (45%)]	Loss: -2.2909	Cost: 12.78s
Train Epoch: 148 [81920/90000 (91%)]	Loss: -2.0302	Cost: 47.13s
Train Epoch: 148 	Average Loss: -1.9819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6939

Learning rate: 0.00015979049830575187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: -0.0556	Cost: 77.54s
Train Epoch: 149 [40960/90000 (45%)]	Loss: -2.3079	Cost: 11.60s
Train Epoch: 149 [81920/90000 (91%)]	Loss: -2.4027	Cost: 39.15s
Train Epoch: 149 	Average Loss: -2.1083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3561

Saving model as e149_model.pt & e149_waveforms_supplementary.hdf5
Learning rate: 0.00015928568201610592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: -0.0711	Cost: 74.83s
Train Epoch: 150 [40960/90000 (45%)]	Loss: -2.1572	Cost: 9.54s
Train Epoch: 150 [81920/90000 (91%)]	Loss: -2.3794	Cost: 13.20s
Train Epoch: 150 	Average Loss: -2.1286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5669

Learning rate: 0.00015877852522924732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: -0.0869	Cost: 34.56s
Train Epoch: 151 [40960/90000 (45%)]	Loss: -2.2921	Cost: 9.39s
Train Epoch: 151 [81920/90000 (91%)]	Loss: -2.2655	Cost: 18.00s
Train Epoch: 151 	Average Loss: -2.1139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6694

Learning rate: 0.00015826904796685762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: -0.0917	Cost: 34.62s
Train Epoch: 152 [40960/90000 (45%)]	Loss: -2.5326	Cost: 9.82s
Train Epoch: 152 [81920/90000 (91%)]	Loss: -2.4224	Cost: 18.24s
Train Epoch: 152 	Average Loss: -2.1610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4408

Learning rate: 0.00015775727034222675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: -0.0487	Cost: 38.02s
Train Epoch: 153 [40960/90000 (45%)]	Loss: -2.3309	Cost: 9.68s
Train Epoch: 153 [81920/90000 (91%)]	Loss: -2.3429	Cost: 14.21s
Train Epoch: 153 	Average Loss: -2.1943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3761

Learning rate: 0.00015724321255945907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: -0.2922	Cost: 34.48s
Train Epoch: 154 [40960/90000 (45%)]	Loss: -1.5777	Cost: 10.02s
Train Epoch: 154 [81920/90000 (91%)]	Loss: -1.9549	Cost: 12.58s
Train Epoch: 154 	Average Loss: -1.7148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7257

Learning rate: 0.00015672689491267567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 0.4709	Cost: 34.24s
Train Epoch: 155 [40960/90000 (45%)]	Loss: -2.1256	Cost: 10.14s
Train Epoch: 155 [81920/90000 (91%)]	Loss: -2.3294	Cost: 12.25s
Train Epoch: 155 	Average Loss: -1.9672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6823

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 0.0112	Cost: 35.38s
Train Epoch: 156 [40960/90000 (45%)]	Loss: -2.2536	Cost: 10.06s
Train Epoch: 156 [81920/90000 (91%)]	Loss: -2.2474	Cost: 16.15s
Train Epoch: 156 	Average Loss: -2.1346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5593

Learning rate: 0.00015568756164881882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 0.1123	Cost: 35.17s
Train Epoch: 157 [40960/90000 (45%)]	Loss: -2.5039	Cost: 9.76s
Train Epoch: 157 [81920/90000 (91%)]	Loss: -2.3357	Cost: 18.15s
Train Epoch: 157 	Average Loss: -2.2578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4635

Learning rate: 0.00015516458706284303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: -0.1050	Cost: 38.83s
Train Epoch: 158 [40960/90000 (45%)]	Loss: -2.6453	Cost: 9.72s
Train Epoch: 158 [81920/90000 (91%)]	Loss: -2.6661	Cost: 14.32s
Train Epoch: 158 	Average Loss: -2.3699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4141

Learning rate: 0.0001546394346734269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: -0.4026	Cost: 38.53s
Train Epoch: 159 [40960/90000 (45%)]	Loss: -2.5801	Cost: 9.81s
Train Epoch: 159 [81920/90000 (91%)]	Loss: -2.5288	Cost: 15.18s
Train Epoch: 159 	Average Loss: -2.4030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3386

Saving model as e159_model.pt & e159_waveforms_supplementary.hdf5
Learning rate: 0.00015411212521268755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: -0.0195	Cost: 34.69s
Train Epoch: 160 [40960/90000 (45%)]	Loss: -2.5302	Cost: 9.98s
Train Epoch: 160 [81920/90000 (91%)]	Loss: -2.4077	Cost: 12.13s
Train Epoch: 160 	Average Loss: -2.3507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3519

Learning rate: 0.00015358267949789963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: -0.2273	Cost: 35.24s
Train Epoch: 161 [40960/90000 (45%)]	Loss: -2.6062	Cost: 9.66s
Train Epoch: 161 [81920/90000 (91%)]	Loss: -2.6102	Cost: 16.49s
Train Epoch: 161 	Average Loss: -2.4814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3452

Learning rate: 0.00015305111843067339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: -0.0651	Cost: 35.38s
Train Epoch: 162 [40960/90000 (45%)]	Loss: -2.6001	Cost: 9.73s
Train Epoch: 162 [81920/90000 (91%)]	Loss: -2.7538	Cost: 17.50s
Train Epoch: 162 	Average Loss: -2.5342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4207

Learning rate: 0.00015251746299612957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: -0.2472	Cost: 37.65s
Train Epoch: 163 [40960/90000 (45%)]	Loss: -2.5901	Cost: 9.77s
Train Epoch: 163 [81920/90000 (91%)]	Loss: -2.7450	Cost: 13.72s
Train Epoch: 163 	Average Loss: -2.5332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2775

Saving model as e163_model.pt & e163_waveforms_supplementary.hdf5
Learning rate: 0.00015198173426207094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: -0.2967	Cost: 38.06s
Train Epoch: 164 [40960/90000 (45%)]	Loss: -2.5156	Cost: 9.77s
Train Epoch: 164 [81920/90000 (91%)]	Loss: -2.4262	Cost: 12.57s
Train Epoch: 164 	Average Loss: -2.3584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4320

Learning rate: 0.00015144395337815067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: -0.2152	Cost: 35.56s
Train Epoch: 165 [40960/90000 (45%)]	Loss: -2.6151	Cost: 9.59s
Train Epoch: 165 [81920/90000 (91%)]	Loss: -2.4667	Cost: 12.95s
Train Epoch: 165 	Average Loss: -2.3815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5120

Learning rate: 0.00015090414157503714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: -0.0164	Cost: 34.11s
Train Epoch: 166 [40960/90000 (45%)]	Loss: -2.5298	Cost: 9.90s
Train Epoch: 166 [81920/90000 (91%)]	Loss: -2.6090	Cost: 19.13s
Train Epoch: 166 	Average Loss: -2.4139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2458

Saving model as e166_model.pt & e166_waveforms_supplementary.hdf5
Learning rate: 0.00015036232016357607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: -0.1925	Cost: 37.28s
Train Epoch: 167 [40960/90000 (45%)]	Loss: -2.7414	Cost: 9.72s
Train Epoch: 167 [81920/90000 (91%)]	Loss: -2.6790	Cost: 14.92s
Train Epoch: 167 	Average Loss: -2.4758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2587

Learning rate: 0.00014981851053394907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: -0.1712	Cost: 35.85s
Train Epoch: 168 [40960/90000 (45%)]	Loss: -2.9179	Cost: 9.69s
Train Epoch: 168 [81920/90000 (91%)]	Loss: -2.7798	Cost: 14.85s
Train Epoch: 168 	Average Loss: -2.4940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2838

Learning rate: 0.00014927273415482915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: -0.4592	Cost: 38.75s
Train Epoch: 169 [40960/90000 (45%)]	Loss: -2.6610	Cost: 9.61s
Train Epoch: 169 [81920/90000 (91%)]	Loss: -2.9030	Cost: 13.76s
Train Epoch: 169 	Average Loss: -2.5445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2251

Saving model as e169_model.pt & e169_waveforms_supplementary.hdf5
Learning rate: 0.00014872501257253323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: -0.4338	Cost: 33.99s
Train Epoch: 170 [40960/90000 (45%)]	Loss: -2.7395	Cost: 9.72s
Train Epoch: 170 [81920/90000 (91%)]	Loss: -2.7303	Cost: 18.46s
Train Epoch: 170 	Average Loss: -2.6090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1981

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 0.00014817536741017152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: -0.3277	Cost: 36.82s
Train Epoch: 171 [40960/90000 (45%)]	Loss: -2.8495	Cost: 9.72s
Train Epoch: 171 [81920/90000 (91%)]	Loss: -2.8633	Cost: 17.36s
Train Epoch: 171 	Average Loss: -2.6515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1463

Saving model as e171_model.pt & e171_waveforms_supplementary.hdf5
Learning rate: 0.0001476238203667939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: -0.4535	Cost: 35.43s
Train Epoch: 172 [40960/90000 (45%)]	Loss: -2.9238	Cost: 9.91s
Train Epoch: 172 [81920/90000 (91%)]	Loss: -2.8425	Cost: 14.02s
Train Epoch: 172 	Average Loss: -2.6952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1551

Learning rate: 0.00014707039321653327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: -0.5223	Cost: 36.91s
Train Epoch: 173 [40960/90000 (45%)]	Loss: -2.8991	Cost: 9.66s
Train Epoch: 173 [81920/90000 (91%)]	Loss: -2.9388	Cost: 13.64s
Train Epoch: 173 	Average Loss: -2.7656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1988

Learning rate: 0.00014651510780774586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: -0.5533	Cost: 35.03s
Train Epoch: 174 [40960/90000 (45%)]	Loss: -3.0653	Cost: 10.10s
Train Epoch: 174 [81920/90000 (91%)]	Loss: -3.0641	Cost: 18.62s
Train Epoch: 174 	Average Loss: -2.8398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1239

Saving model as e174_model.pt & e174_waveforms_supplementary.hdf5
Learning rate: 0.00014595798606214882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: -0.5794	Cost: 36.25s
Train Epoch: 175 [40960/90000 (45%)]	Loss: -3.0763	Cost: 10.15s
Train Epoch: 175 [81920/90000 (91%)]	Loss: -2.8285	Cost: 16.63s
Train Epoch: 175 	Average Loss: -2.8115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0613

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Learning rate: 0.00014539904997395468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: -0.4998	Cost: 36.86s
Train Epoch: 176 [40960/90000 (45%)]	Loss: -3.1687	Cost: 9.59s
Train Epoch: 176 [81920/90000 (91%)]	Loss: -3.1690	Cost: 13.31s
Train Epoch: 176 	Average Loss: -2.8793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0278

Learning rate: 0.00014483832160900326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: -0.4527	Cost: 33.86s
Train Epoch: 177 [40960/90000 (45%)]	Loss: -3.0724	Cost: 10.02s
Train Epoch: 177 [81920/90000 (91%)]	Loss: -3.0971	Cost: 12.97s
Train Epoch: 177 	Average Loss: -2.8893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0805

Saving model as e177_model.pt & e177_waveforms_supplementary.hdf5
Learning rate: 0.00014427582310389016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: -0.3499	Cost: 34.03s
Train Epoch: 178 [40960/90000 (45%)]	Loss: -3.2085	Cost: 10.00s
Train Epoch: 178 [81920/90000 (91%)]	Loss: -3.0334	Cost: 17.95s
Train Epoch: 178 	Average Loss: -2.8927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0289

Learning rate: 0.0001437115766650933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: -0.6992	Cost: 36.07s
Train Epoch: 179 [40960/90000 (45%)]	Loss: -3.0524	Cost: 9.80s
Train Epoch: 179 [81920/90000 (91%)]	Loss: -3.1455	Cost: 18.04s
Train Epoch: 179 	Average Loss: -2.9450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1323

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Learning rate: 0.0001431456045680959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: -0.8024	Cost: 36.67s
Train Epoch: 180 [40960/90000 (45%)]	Loss: -2.9125	Cost: 9.73s
Train Epoch: 180 [81920/90000 (91%)]	Loss: -2.9423	Cost: 13.71s
Train Epoch: 180 	Average Loss: -2.7889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1756

Learning rate: 0.00014257792915650726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: -0.2352	Cost: 34.34s
Train Epoch: 181 [40960/90000 (45%)]	Loss: -2.9132	Cost: 9.63s
Train Epoch: 181 [81920/90000 (91%)]	Loss: -2.9694	Cost: 12.29s
Train Epoch: 181 	Average Loss: -2.7690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1453

Learning rate: 0.0001420085728411806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: -0.1660	Cost: 35.35s
Train Epoch: 182 [40960/90000 (45%)]	Loss: -3.0800	Cost: 9.81s
Train Epoch: 182 [81920/90000 (91%)]	Loss: -3.0173	Cost: 14.03s
Train Epoch: 182 	Average Loss: -2.8559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1946

Learning rate: 0.0001414375580993284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: -0.6059	Cost: 33.31s
Train Epoch: 183 [40960/90000 (45%)]	Loss: -3.2366	Cost: 9.77s
Train Epoch: 183 [81920/90000 (91%)]	Loss: -3.1469	Cost: 18.90s
Train Epoch: 183 	Average Loss: -2.9945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0662

Learning rate: 0.00014086490747363488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: -0.4766	Cost: 35.69s
Train Epoch: 184 [40960/90000 (45%)]	Loss: -3.0493	Cost: 9.67s
Train Epoch: 184 [81920/90000 (91%)]	Loss: -2.8301	Cost: 15.74s
Train Epoch: 184 	Average Loss: -2.8939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1547

Learning rate: 0.00014029064357136623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: -0.4321	Cost: 35.73s
Train Epoch: 185 [40960/90000 (45%)]	Loss: -3.1877	Cost: 9.75s
Train Epoch: 185 [81920/90000 (91%)]	Loss: -3.1285	Cost: 13.15s
Train Epoch: 185 	Average Loss: -2.8840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0123

Learning rate: 0.00013971478906347803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: -0.4123	Cost: 37.82s
Train Epoch: 186 [40960/90000 (45%)]	Loss: -3.1614	Cost: 9.60s
Train Epoch: 186 [81920/90000 (91%)]	Loss: -3.2380	Cost: 14.69s
Train Epoch: 186 	Average Loss: -2.9294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0376

Learning rate: 0.0001391373666837202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: -0.5854	Cost: 35.40s
Train Epoch: 187 [40960/90000 (45%)]	Loss: -3.2733	Cost: 9.60s
Train Epoch: 187 [81920/90000 (91%)]	Loss: -3.2854	Cost: 13.47s
Train Epoch: 187 	Average Loss: -3.0005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0914

Learning rate: 0.0001385583992277396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: -0.8647	Cost: 32.90s
Train Epoch: 188 [40960/90000 (45%)]	Loss: -3.4266	Cost: 9.85s
Train Epoch: 188 [81920/90000 (91%)]	Loss: -3.3711	Cost: 19.34s
Train Epoch: 188 	Average Loss: -3.1436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0904

Learning rate: 0.00013797790955218008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: -0.5135	Cost: 37.00s
Train Epoch: 189 [40960/90000 (45%)]	Loss: -3.3802	Cost: 9.72s
Train Epoch: 189 [81920/90000 (91%)]	Loss: -3.2171	Cost: 18.60s
Train Epoch: 189 	Average Loss: -3.0597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0773

Learning rate: 0.00013739592057378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: -0.7479	Cost: 37.55s
Train Epoch: 190 [40960/90000 (45%)]	Loss: -3.4071	Cost: 9.70s
Train Epoch: 190 [81920/90000 (91%)]	Loss: -3.4071	Cost: 14.56s
Train Epoch: 190 	Average Loss: -3.1650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1189

Learning rate: 0.00013681245526846775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: -0.6423	Cost: 35.21s
Train Epoch: 191 [40960/90000 (45%)]	Loss: -3.4385	Cost: 9.72s
Train Epoch: 191 [81920/90000 (91%)]	Loss: -3.2517	Cost: 12.88s
Train Epoch: 191 	Average Loss: -3.1883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0115

Learning rate: 0.00013622753667045454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: -0.4902	Cost: 35.56s
Train Epoch: 192 [40960/90000 (45%)]	Loss: -3.2800	Cost: 9.79s
Train Epoch: 192 [81920/90000 (91%)]	Loss: -3.3883	Cost: 13.45s
Train Epoch: 192 	Average Loss: -3.1016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2311

Saving model as e192_model.pt & e192_waveforms_supplementary.hdf5
Learning rate: 0.00013564118787132503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: -0.6116	Cost: 33.33s
Train Epoch: 193 [40960/90000 (45%)]	Loss: -3.5618	Cost: 9.81s
Train Epoch: 193 [81920/90000 (91%)]	Loss: -3.4254	Cost: 18.57s
Train Epoch: 193 	Average Loss: -3.1119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3709

Saving model as e193_model.pt & e193_waveforms_supplementary.hdf5
Learning rate: 0.00013505343201912587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: -1.0029	Cost: 36.63s
Train Epoch: 194 [40960/90000 (45%)]	Loss: -3.6891	Cost: 9.82s
Train Epoch: 194 [81920/90000 (91%)]	Loss: -3.4838	Cost: 16.45s
Train Epoch: 194 	Average Loss: -3.3011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1829

Learning rate: 0.0001344642923174517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: -0.7355	Cost: 37.08s
Train Epoch: 195 [40960/90000 (45%)]	Loss: -3.5875	Cost: 9.66s
Train Epoch: 195 [81920/90000 (91%)]	Loss: -3.5702	Cost: 15.24s
Train Epoch: 195 	Average Loss: -3.2915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2224

Learning rate: 0.00013387379202452914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: -0.9232	Cost: 36.16s
Train Epoch: 196 [40960/90000 (45%)]	Loss: -3.3566	Cost: 9.63s
Train Epoch: 196 [81920/90000 (91%)]	Loss: -3.1843	Cost: 14.08s
Train Epoch: 196 	Average Loss: -3.1299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1234

Learning rate: 0.00013328195445229865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: -0.9262	Cost: 35.17s
Train Epoch: 197 [40960/90000 (45%)]	Loss: -3.5222	Cost: 9.91s
Train Epoch: 197 [81920/90000 (91%)]	Loss: -3.5017	Cost: 17.80s
Train Epoch: 197 	Average Loss: -3.1756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1563

Learning rate: 0.00013268880296549425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: -0.6791	Cost: 36.21s
Train Epoch: 198 [40960/90000 (45%)]	Loss: -3.5612	Cost: 9.67s
Train Epoch: 198 [81920/90000 (91%)]	Loss: -3.5892	Cost: 16.87s
Train Epoch: 198 	Average Loss: -3.2625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2905

Learning rate: 0.00013209436098072093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: -0.9579	Cost: 37.69s
Train Epoch: 199 [40960/90000 (45%)]	Loss: -3.7267	Cost: 9.77s
Train Epoch: 199 [81920/90000 (91%)]	Loss: -3.6291	Cost: 14.63s
Train Epoch: 199 	Average Loss: -3.3838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4011

Saving model as e199_model.pt & e199_waveforms_supplementary.hdf5
Learning rate: 0.00013149865196553047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: -0.8332	Cost: 35.19s
Train Epoch: 200 [40960/90000 (45%)]	Loss: -3.8708	Cost: 9.67s
Train Epoch: 200 [81920/90000 (91%)]	Loss: -3.7517	Cost: 12.63s
Train Epoch: 200 	Average Loss: -3.4451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2747

Learning rate: 0.00013090169943749474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: -1.0282	Cost: 34.94s
Train Epoch: 201 [40960/90000 (45%)]	Loss: -3.7775	Cost: 9.71s
Train Epoch: 201 [81920/90000 (91%)]	Loss: -3.6953	Cost: 17.53s
Train Epoch: 201 	Average Loss: -3.4302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3827

Learning rate: 0.0001303035269632774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: -0.9383	Cost: 34.87s
Train Epoch: 202 [40960/90000 (45%)]	Loss: -3.6861	Cost: 9.72s
Train Epoch: 202 [81920/90000 (91%)]	Loss: -3.6036	Cost: 18.51s
Train Epoch: 202 	Average Loss: -3.4327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4111

Saving model as e202_model.pt & e202_waveforms_supplementary.hdf5
Learning rate: 0.00012970415815770348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: -1.2171	Cost: 37.88s
Train Epoch: 203 [40960/90000 (45%)]	Loss: -3.8028	Cost: 9.68s
Train Epoch: 203 [81920/90000 (91%)]	Loss: -3.7572	Cost: 14.72s
Train Epoch: 203 	Average Loss: -3.5292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5987

Saving model as e203_model.pt & e203_waveforms_supplementary.hdf5
Learning rate: 0.00012910361668282719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: -1.1547	Cost: 38.16s
Train Epoch: 204 [40960/90000 (45%)]	Loss: -3.9305	Cost: 9.57s
Train Epoch: 204 [81920/90000 (91%)]	Loss: -3.6742	Cost: 13.18s
Train Epoch: 204 	Average Loss: -3.5667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3511

Learning rate: 0.0001285019262469976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: -1.1406	Cost: 36.60s
Train Epoch: 205 [40960/90000 (45%)]	Loss: -3.8969	Cost: 9.63s
Train Epoch: 205 [81920/90000 (91%)]	Loss: -3.7013	Cost: 16.93s
Train Epoch: 205 	Average Loss: -3.5573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4436

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: -0.9392	Cost: 34.96s
Train Epoch: 206 [40960/90000 (45%)]	Loss: -3.8036	Cost: 9.72s
Train Epoch: 206 [81920/90000 (91%)]	Loss: -3.6251	Cost: 17.99s
Train Epoch: 206 	Average Loss: -3.5183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3629

Learning rate: 0.00012729519355173254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: -1.2917	Cost: 35.68s
Train Epoch: 207 [40960/90000 (45%)]	Loss: -3.9406	Cost: 9.71s
Train Epoch: 207 [81920/90000 (91%)]	Loss: -3.8085	Cost: 14.61s
Train Epoch: 207 	Average Loss: -3.5574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5398

Learning rate: 0.00012669019893203759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: -1.0033	Cost: 38.72s
Train Epoch: 208 [40960/90000 (45%)]	Loss: -3.8622	Cost: 9.86s
Train Epoch: 208 [81920/90000 (91%)]	Loss: -3.9438	Cost: 13.71s
Train Epoch: 208 	Average Loss: -3.5580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4151

Learning rate: 0.0001260841506289897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: -1.0346	Cost: 35.42s
Train Epoch: 209 [40960/90000 (45%)]	Loss: -3.8096	Cost: 9.62s
Train Epoch: 209 [81920/90000 (91%)]	Loss: -3.7968	Cost: 12.49s
Train Epoch: 209 	Average Loss: -3.6212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4103

Learning rate: 0.00012547707256833825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: -1.1773	Cost: 35.04s
Train Epoch: 210 [40960/90000 (45%)]	Loss: -3.8321	Cost: 10.07s
Train Epoch: 210 [81920/90000 (91%)]	Loss: -3.6990	Cost: 18.17s
Train Epoch: 210 	Average Loss: -3.5877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2895

Learning rate: 0.00012486898871648549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: -1.0064	Cost: 35.32s
Train Epoch: 211 [40960/90000 (45%)]	Loss: -3.9128	Cost: 10.10s
Train Epoch: 211 [81920/90000 (91%)]	Loss: -3.9891	Cost: 17.94s
Train Epoch: 211 	Average Loss: -3.7271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3582

Learning rate: 0.00012425992307954077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: -0.7662	Cost: 37.23s
Train Epoch: 212 [40960/90000 (45%)]	Loss: -3.8262	Cost: 9.81s
Train Epoch: 212 [81920/90000 (91%)]	Loss: -4.0392	Cost: 12.76s
Train Epoch: 212 	Average Loss: -3.6726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4841

Learning rate: 0.0001236498997023725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: -1.1948	Cost: 37.84s
Train Epoch: 213 [40960/90000 (45%)]	Loss: -4.1841	Cost: 9.64s
Train Epoch: 213 [81920/90000 (91%)]	Loss: -4.0267	Cost: 15.09s
Train Epoch: 213 	Average Loss: -3.8142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5162

Learning rate: 0.00012303894266765908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: -1.1644	Cost: 35.55s
Train Epoch: 214 [40960/90000 (45%)]	Loss: -4.0200	Cost: 9.65s
Train Epoch: 214 [81920/90000 (91%)]	Loss: -4.0532	Cost: 14.83s
Train Epoch: 214 	Average Loss: -3.7551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6193

Saving model as e214_model.pt & e214_waveforms_supplementary.hdf5
Learning rate: 0.00012242707609493814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: -1.0603	Cost: 35.16s
Train Epoch: 215 [40960/90000 (45%)]	Loss: -4.2296	Cost: 9.76s
Train Epoch: 215 [81920/90000 (91%)]	Loss: -4.0229	Cost: 17.40s
Train Epoch: 215 	Average Loss: -3.8185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5606

Learning rate: 0.0001218143241396543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: -1.2666	Cost: 35.89s
Train Epoch: 216 [40960/90000 (45%)]	Loss: -4.1808	Cost: 9.75s
Train Epoch: 216 [81920/90000 (91%)]	Loss: -3.9540	Cost: 13.73s
Train Epoch: 216 	Average Loss: -3.8595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7512

Saving model as e216_model.pt & e216_waveforms_supplementary.hdf5
Learning rate: 0.0001212007109922055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: -1.2976	Cost: 38.39s
Train Epoch: 217 [40960/90000 (45%)]	Loss: -4.1150	Cost: 9.56s
Train Epoch: 217 [81920/90000 (91%)]	Loss: -4.1951	Cost: 15.50s
Train Epoch: 217 	Average Loss: -3.8756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6844

Learning rate: 0.00012058626087698816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: -1.2261	Cost: 36.07s
Train Epoch: 218 [40960/90000 (45%)]	Loss: -4.1841	Cost: 9.52s
Train Epoch: 218 [81920/90000 (91%)]	Loss: -4.0067	Cost: 17.47s
Train Epoch: 218 	Average Loss: -3.9446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6995

Learning rate: 0.00011997099805144073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: -1.3928	Cost: 35.62s
Train Epoch: 219 [40960/90000 (45%)]	Loss: -4.2901	Cost: 9.68s
Train Epoch: 219 [81920/90000 (91%)]	Loss: -3.9623	Cost: 19.64s
Train Epoch: 219 	Average Loss: -3.9738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7634

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 0.00011935494680508606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: -1.1846	Cost: 36.51s
Train Epoch: 220 [40960/90000 (45%)]	Loss: -4.2349	Cost: 9.66s
Train Epoch: 220 [81920/90000 (91%)]	Loss: -4.2688	Cost: 13.11s
Train Epoch: 220 	Average Loss: -3.9619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6640

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: -1.4211	Cost: 37.06s
Train Epoch: 221 [40960/90000 (45%)]	Loss: -4.3849	Cost: 9.61s
Train Epoch: 221 [81920/90000 (91%)]	Loss: -4.0084	Cost: 13.42s
Train Epoch: 221 	Average Loss: -3.9743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7850

Saving model as e221_model.pt & e221_waveforms_supplementary.hdf5
Learning rate: 0.00011812057636271377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: -1.4624	Cost: 35.78s
Train Epoch: 222 [40960/90000 (45%)]	Loss: -4.1403	Cost: 9.62s
Train Epoch: 222 [81920/90000 (91%)]	Loss: -4.2828	Cost: 15.05s
Train Epoch: 222 	Average Loss: -3.9788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7661

Learning rate: 0.00011750230589752765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: -1.6212	Cost: 33.20s
Train Epoch: 223 [40960/90000 (45%)]	Loss: -4.3548	Cost: 9.81s
Train Epoch: 223 [81920/90000 (91%)]	Loss: -4.2126	Cost: 19.15s
Train Epoch: 223 	Average Loss: -4.0615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6499

Learning rate: 0.0001168833444712734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: -1.6068	Cost: 36.89s
Train Epoch: 224 [40960/90000 (45%)]	Loss: -3.8362	Cost: 9.79s
Train Epoch: 224 [81920/90000 (91%)]	Loss: -4.1483	Cost: 14.49s
Train Epoch: 224 	Average Loss: -3.8992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7233

Learning rate: 0.00011626371651948839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: -1.4334	Cost: 38.16s
Train Epoch: 225 [40960/90000 (45%)]	Loss: -4.4325	Cost: 9.65s
Train Epoch: 225 [81920/90000 (91%)]	Loss: -4.2405	Cost: 14.49s
Train Epoch: 225 	Average Loss: -4.0339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8568

Saving model as e225_model.pt & e225_waveforms_supplementary.hdf5
Learning rate: 0.00011564344650402312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: -1.4222	Cost: 33.94s
Train Epoch: 226 [40960/90000 (45%)]	Loss: -4.5032	Cost: 9.68s
Train Epoch: 226 [81920/90000 (91%)]	Loss: -4.5150	Cost: 12.77s
Train Epoch: 226 	Average Loss: -4.1565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7632

Learning rate: 0.00011502255891207573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: -1.1889	Cost: 33.59s
Train Epoch: 227 [40960/90000 (45%)]	Loss: -4.4338	Cost: 9.83s
Train Epoch: 227 [81920/90000 (91%)]	Loss: -4.4107	Cost: 18.42s
Train Epoch: 227 	Average Loss: -4.1330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6891

Learning rate: 0.00011440107825522525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: -1.2475	Cost: 37.18s
Train Epoch: 228 [40960/90000 (45%)]	Loss: -4.3444	Cost: 9.88s
Train Epoch: 228 [81920/90000 (91%)]	Loss: -4.3098	Cost: 16.68s
Train Epoch: 228 	Average Loss: -4.0669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6163

Learning rate: 0.00011377902906846383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: -1.3314	Cost: 36.68s
Train Epoch: 229 [40960/90000 (45%)]	Loss: -4.2854	Cost: 9.93s
Train Epoch: 229 [81920/90000 (91%)]	Loss: -4.4420	Cost: 15.52s
Train Epoch: 229 	Average Loss: -4.1011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7532

Learning rate: 0.00011315643590922827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: -1.4034	Cost: 34.94s
Train Epoch: 230 [40960/90000 (45%)]	Loss: -4.0200	Cost: 10.16s
Train Epoch: 230 [81920/90000 (91%)]	Loss: -4.2127	Cost: 13.52s
Train Epoch: 230 	Average Loss: -3.9109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5437

Learning rate: 0.00011253332335643043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: -1.1653	Cost: 34.45s
Train Epoch: 231 [40960/90000 (45%)]	Loss: -4.1925	Cost: 9.83s
Train Epoch: 231 [81920/90000 (91%)]	Loss: -4.2212	Cost: 19.26s
Train Epoch: 231 	Average Loss: -3.9799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7628

Learning rate: 0.00011190971600948699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: -1.5659	Cost: 37.24s
Train Epoch: 232 [40960/90000 (45%)]	Loss: -4.4414	Cost: 9.76s
Train Epoch: 232 [81920/90000 (91%)]	Loss: -4.3661	Cost: 18.44s
Train Epoch: 232 	Average Loss: -4.0842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8717

Saving model as e232_model.pt & e232_waveforms_supplementary.hdf5
Learning rate: 0.00011128563848734816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: -1.5532	Cost: 39.40s
Train Epoch: 233 [40960/90000 (45%)]	Loss: -4.6330	Cost: 10.23s
Train Epoch: 233 [81920/90000 (91%)]	Loss: -4.3640	Cost: 13.84s
Train Epoch: 233 	Average Loss: -4.2659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7945

Learning rate: 0.000110661115427526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: -1.6670	Cost: 33.71s
Train Epoch: 234 [40960/90000 (45%)]	Loss: -4.5101	Cost: 9.68s
Train Epoch: 234 [81920/90000 (91%)]	Loss: -4.4610	Cost: 12.37s
Train Epoch: 234 	Average Loss: -4.1850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9997

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 0.00011003617148512149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: -1.7108	Cost: 34.34s
Train Epoch: 235 [40960/90000 (45%)]	Loss: -4.6685	Cost: 10.16s
Train Epoch: 235 [81920/90000 (91%)]	Loss: -4.6138	Cost: 17.86s
Train Epoch: 235 	Average Loss: -4.2854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9293

Learning rate: 0.00010941083133185143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: -1.7698	Cost: 35.52s
Train Epoch: 236 [40960/90000 (45%)]	Loss: -4.6377	Cost: 9.68s
Train Epoch: 236 [81920/90000 (91%)]	Loss: -4.6066	Cost: 18.28s
Train Epoch: 236 	Average Loss: -4.3250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0146

Saving model as e236_model.pt & e236_waveforms_supplementary.hdf5
Learning rate: 0.00010878511965507434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: -1.3800	Cost: 36.39s
Train Epoch: 237 [40960/90000 (45%)]	Loss: -4.5160	Cost: 9.68s
Train Epoch: 237 [81920/90000 (91%)]	Loss: -4.4628	Cost: 13.27s
Train Epoch: 237 	Average Loss: -4.2780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9244

Learning rate: 0.00010815906115681577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: -1.3679	Cost: 37.40s
Train Epoch: 238 [40960/90000 (45%)]	Loss: -4.6013	Cost: 9.59s
Train Epoch: 238 [81920/90000 (91%)]	Loss: -4.2454	Cost: 14.89s
Train Epoch: 238 	Average Loss: -4.2572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8693

Learning rate: 0.00010753268055279328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: -1.3961	Cost: 35.14s
Train Epoch: 239 [40960/90000 (45%)]	Loss: -4.5966	Cost: 9.67s
Train Epoch: 239 [81920/90000 (91%)]	Loss: -4.5590	Cost: 14.24s
Train Epoch: 239 	Average Loss: -4.2562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9165

Learning rate: 0.0001069060025714406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: -1.3730	Cost: 33.01s
Train Epoch: 240 [40960/90000 (45%)]	Loss: -4.6327	Cost: 9.74s
Train Epoch: 240 [81920/90000 (91%)]	Loss: -4.7744	Cost: 18.62s
Train Epoch: 240 	Average Loss: -4.4026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8601

Learning rate: 0.00010627905195293134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: -1.6368	Cost: 38.90s
Train Epoch: 241 [40960/90000 (45%)]	Loss: -4.6771	Cost: 9.74s
Train Epoch: 241 [81920/90000 (91%)]	Loss: -4.9244	Cost: 14.47s
Train Epoch: 241 	Average Loss: -4.5093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0085

Learning rate: 0.00010565185344820243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: -1.5567	Cost: 35.53s
Train Epoch: 242 [40960/90000 (45%)]	Loss: -4.7833	Cost: 9.72s
Train Epoch: 242 [81920/90000 (91%)]	Loss: -4.7520	Cost: 14.41s
Train Epoch: 242 	Average Loss: -4.5171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0799

Saving model as e242_model.pt & e242_waveforms_supplementary.hdf5
Learning rate: 0.00010502443181797694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: -1.6574	Cost: 35.41s
Train Epoch: 243 [40960/90000 (45%)]	Loss: -4.6793	Cost: 9.68s
Train Epoch: 243 [81920/90000 (91%)]	Loss: -4.9395	Cost: 13.07s
Train Epoch: 243 	Average Loss: -4.5360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2064

Saving model as e243_model.pt & e243_waveforms_supplementary.hdf5
Learning rate: 0.00010439681183178646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: -1.5338	Cost: 34.21s
Train Epoch: 244 [40960/90000 (45%)]	Loss: -4.6182	Cost: 9.79s
Train Epoch: 244 [81920/90000 (91%)]	Loss: -4.5940	Cost: 19.36s
Train Epoch: 244 	Average Loss: -4.4707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0619

Learning rate: 0.00010376901826699342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: -1.3529	Cost: 37.68s
Train Epoch: 245 [40960/90000 (45%)]	Loss: -4.5408	Cost: 9.73s
Train Epoch: 245 [81920/90000 (91%)]	Loss: -4.7183	Cost: 14.47s
Train Epoch: 245 	Average Loss: -4.3815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8808

Learning rate: 0.0001031410759078128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: -1.5030	Cost: 38.32s
Train Epoch: 246 [40960/90000 (45%)]	Loss: -4.6215	Cost: 9.67s
Train Epoch: 246 [81920/90000 (91%)]	Loss: -4.5535	Cost: 14.52s
Train Epoch: 246 	Average Loss: -4.3993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0283

Learning rate: 0.00010251300954433372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: -1.6285	Cost: 37.19s
Train Epoch: 247 [40960/90000 (45%)]	Loss: -4.7783	Cost: 9.67s
Train Epoch: 247 [81920/90000 (91%)]	Loss: -4.8664	Cost: 13.16s
Train Epoch: 247 	Average Loss: -4.5291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1162

Learning rate: 0.0001018848439715408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: -1.9354	Cost: 33.29s
Train Epoch: 248 [40960/90000 (45%)]	Loss: -4.7534	Cost: 9.80s
Train Epoch: 248 [81920/90000 (91%)]	Loss: -4.6591	Cost: 18.25s
Train Epoch: 248 	Average Loss: -4.5894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1430

Learning rate: 0.00010125660398833524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: -1.5654	Cost: 34.99s
Train Epoch: 249 [40960/90000 (45%)]	Loss: -4.6157	Cost: 9.76s
Train Epoch: 249 [81920/90000 (91%)]	Loss: -4.8876	Cost: 17.32s
Train Epoch: 249 	Average Loss: -4.5282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9344

Learning rate: 0.00010062831439655587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: -2.0454	Cost: 36.00s
Train Epoch: 250 [40960/90000 (45%)]	Loss: -4.7336	Cost: 9.90s
Train Epoch: 250 [81920/90000 (91%)]	Loss: -4.8329	Cost: 14.07s
Train Epoch: 250 	Average Loss: -4.5876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0473

Learning rate: 9.999999999999996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: -1.8214	Cost: 37.42s
Train Epoch: 251 [40960/90000 (45%)]	Loss: -4.7640	Cost: 9.71s
Train Epoch: 251 [81920/90000 (91%)]	Loss: -4.7007	Cost: 14.01s
Train Epoch: 251 	Average Loss: -4.5296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0446

Learning rate: 9.937168560344407e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: -1.2630	Cost: 34.98s
Train Epoch: 252 [40960/90000 (45%)]	Loss: -4.6824	Cost: 9.75s
Train Epoch: 252 [81920/90000 (91%)]	Loss: -4.9364	Cost: 13.70s
Train Epoch: 252 	Average Loss: -4.4970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9621

Learning rate: 9.87433960116647e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: -1.2358	Cost: 33.61s
Train Epoch: 253 [40960/90000 (45%)]	Loss: -4.6381	Cost: 9.68s
Train Epoch: 253 [81920/90000 (91%)]	Loss: -4.7435	Cost: 19.88s
Train Epoch: 253 	Average Loss: -4.5021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0783

Learning rate: 9.811515602845915e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: -1.6654	Cost: 39.31s
Train Epoch: 254 [40960/90000 (45%)]	Loss: -4.8184	Cost: 9.66s
Train Epoch: 254 [81920/90000 (91%)]	Loss: -4.9386	Cost: 14.83s
Train Epoch: 254 	Average Loss: -4.5613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0311

Learning rate: 9.748699045566624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: -1.2477	Cost: 38.10s
Train Epoch: 255 [40960/90000 (45%)]	Loss: -4.9529	Cost: 9.79s
Train Epoch: 255 [81920/90000 (91%)]	Loss: -4.8288	Cost: 13.61s
Train Epoch: 255 	Average Loss: -4.5598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9039

Learning rate: 9.685892409218716e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: -1.6941	Cost: 35.26s
Train Epoch: 256 [40960/90000 (45%)]	Loss: -5.0534	Cost: 9.62s
Train Epoch: 256 [81920/90000 (91%)]	Loss: -5.0722	Cost: 12.34s
Train Epoch: 256 	Average Loss: -4.6661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2426

Saving model as e256_model.pt & e256_waveforms_supplementary.hdf5
Learning rate: 9.623098173300653e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: -1.7450	Cost: 33.36s
Train Epoch: 257 [40960/90000 (45%)]	Loss: -4.9454	Cost: 10.02s
Train Epoch: 257 [81920/90000 (91%)]	Loss: -4.9852	Cost: 18.28s
Train Epoch: 257 	Average Loss: -4.7191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1930

Learning rate: 9.560318816821353e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: -1.7279	Cost: 37.88s
Train Epoch: 258 [40960/90000 (45%)]	Loss: -5.0476	Cost: 9.64s
Train Epoch: 258 [81920/90000 (91%)]	Loss: -5.0604	Cost: 19.04s
Train Epoch: 258 	Average Loss: -4.7758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2370

Learning rate: 9.497556818202306e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: -1.7784	Cost: 42.21s
Train Epoch: 259 [40960/90000 (45%)]	Loss: -4.9752	Cost: 9.51s
Train Epoch: 259 [81920/90000 (91%)]	Loss: -5.2941	Cost: 14.39s
Train Epoch: 259 	Average Loss: -4.8753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3890

Saving model as e259_model.pt & e259_waveforms_supplementary.hdf5
Learning rate: 9.434814655179755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: -2.3540	Cost: 37.43s
Train Epoch: 260 [40960/90000 (45%)]	Loss: -5.4172	Cost: 9.86s
Train Epoch: 260 [81920/90000 (91%)]	Loss: -5.1840	Cost: 13.09s
Train Epoch: 260 	Average Loss: -4.9481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1355

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: -1.6856	Cost: 34.39s
Train Epoch: 261 [40960/90000 (45%)]	Loss: -4.6303	Cost: 9.86s
Train Epoch: 261 [81920/90000 (91%)]	Loss: -4.9282	Cost: 19.24s
Train Epoch: 261 	Average Loss: -4.5781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1650

Learning rate: 9.309399742855944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: -1.6557	Cost: 36.49s
Train Epoch: 262 [40960/90000 (45%)]	Loss: -5.0302	Cost: 9.86s
Train Epoch: 262 [81920/90000 (91%)]	Loss: -4.9031	Cost: 16.94s
Train Epoch: 262 	Average Loss: -4.7246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2503

Learning rate: 9.246731944720672e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: -1.5867	Cost: 39.03s
Train Epoch: 263 [40960/90000 (45%)]	Loss: -4.9933	Cost: 9.60s
Train Epoch: 263 [81920/90000 (91%)]	Loss: -5.0670	Cost: 14.18s
Train Epoch: 263 	Average Loss: -4.8016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2159

Learning rate: 9.184093884318424e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: -1.8047	Cost: 34.06s
Train Epoch: 264 [40960/90000 (45%)]	Loss: -4.9122	Cost: 9.81s
Train Epoch: 264 [81920/90000 (91%)]	Loss: -4.9597	Cost: 12.58s
Train Epoch: 264 	Average Loss: -4.7765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0560

Learning rate: 9.121488034492569e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: -1.4641	Cost: 35.20s
Train Epoch: 265 [40960/90000 (45%)]	Loss: -5.1129	Cost: 10.02s
Train Epoch: 265 [81920/90000 (91%)]	Loss: -5.1816	Cost: 17.61s
Train Epoch: 265 	Average Loss: -4.8278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0724

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: -1.8657	Cost: 34.79s
Train Epoch: 266 [40960/90000 (45%)]	Loss: -5.3437	Cost: 9.71s
Train Epoch: 266 [81920/90000 (91%)]	Loss: -5.1848	Cost: 18.19s
Train Epoch: 266 	Average Loss: -4.9511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3859

Learning rate: 8.996382851487852e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: -1.7188	Cost: 35.82s
Train Epoch: 267 [40960/90000 (45%)]	Loss: -5.4417	Cost: 9.79s
Train Epoch: 267 [81920/90000 (91%)]	Loss: -5.4241	Cost: 13.95s
Train Epoch: 267 	Average Loss: -5.0003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3105

Learning rate: 8.9338884572474e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: -2.0682	Cost: 34.44s
Train Epoch: 268 [40960/90000 (45%)]	Loss: -5.3167	Cost: 9.59s
Train Epoch: 268 [81920/90000 (91%)]	Loss: -5.5332	Cost: 13.61s
Train Epoch: 268 	Average Loss: -5.0942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1971

Learning rate: 8.871436151265182e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: -1.9407	Cost: 34.09s
Train Epoch: 269 [40960/90000 (45%)]	Loss: -5.4206	Cost: 9.64s
Train Epoch: 269 [81920/90000 (91%)]	Loss: -5.4594	Cost: 15.38s
Train Epoch: 269 	Average Loss: -5.1248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3485

Learning rate: 8.809028399051304e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: -1.7028	Cost: 33.71s
Train Epoch: 270 [40960/90000 (45%)]	Loss: -5.3735	Cost: 9.70s
Train Epoch: 270 [81920/90000 (91%)]	Loss: -5.5209	Cost: 18.16s
Train Epoch: 270 	Average Loss: -5.1076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2987

Learning rate: 8.746667664356958e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: -2.2591	Cost: 35.08s
Train Epoch: 271 [40960/90000 (45%)]	Loss: -5.5827	Cost: 9.71s
Train Epoch: 271 [81920/90000 (91%)]	Loss: -5.6083	Cost: 18.58s
Train Epoch: 271 	Average Loss: -5.1644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4522

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 8.684356409077174e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: -2.0331	Cost: 37.86s
Train Epoch: 272 [40960/90000 (45%)]	Loss: -5.3995	Cost: 9.77s
Train Epoch: 272 [81920/90000 (91%)]	Loss: -5.5794	Cost: 14.80s
Train Epoch: 272 	Average Loss: -5.1685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4847

Saving model as e272_model.pt & e272_waveforms_supplementary.hdf5
Learning rate: 8.622097093153619e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: -2.5150	Cost: 37.72s
Train Epoch: 273 [40960/90000 (45%)]	Loss: -5.6259	Cost: 9.58s
Train Epoch: 273 [81920/90000 (91%)]	Loss: -5.4853	Cost: 13.58s
Train Epoch: 273 	Average Loss: -5.1921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4751

Learning rate: 8.559892174477476e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: -2.2075	Cost: 35.54s
Train Epoch: 274 [40960/90000 (45%)]	Loss: -5.4742	Cost: 9.65s
Train Epoch: 274 [81920/90000 (91%)]	Loss: -5.3935	Cost: 17.69s
Train Epoch: 274 	Average Loss: -5.2239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3838

Learning rate: 8.497744108792427e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: -2.0709	Cost: 35.52s
Train Epoch: 275 [40960/90000 (45%)]	Loss: -5.3931	Cost: 9.69s
Train Epoch: 275 [81920/90000 (91%)]	Loss: -5.5711	Cost: 18.05s
Train Epoch: 275 	Average Loss: -5.2633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5904

Saving model as e275_model.pt & e275_waveforms_supplementary.hdf5
Learning rate: 8.435655349597689e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: -2.1482	Cost: 39.15s
Train Epoch: 276 [40960/90000 (45%)]	Loss: -5.6841	Cost: 9.71s
Train Epoch: 276 [81920/90000 (91%)]	Loss: -5.5556	Cost: 13.56s
Train Epoch: 276 	Average Loss: -5.3498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6009

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Learning rate: 8.373628348051162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: -2.6073	Cost: 37.55s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -5.8101	Cost: 9.58s
Train Epoch: 277 [81920/90000 (91%)]	Loss: -5.6902	Cost: 14.17s
Train Epoch: 277 	Average Loss: -5.3970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5269

Learning rate: 8.311665552872659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: -2.1210	Cost: 37.02s
Train Epoch: 278 [40960/90000 (45%)]	Loss: -5.7727	Cost: 9.49s
Train Epoch: 278 [81920/90000 (91%)]	Loss: -5.6687	Cost: 14.83s
Train Epoch: 278 	Average Loss: -5.3508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3332

Learning rate: 8.249769410247239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: -2.2477	Cost: 33.56s
Train Epoch: 279 [40960/90000 (45%)]	Loss: -5.7069	Cost: 9.66s
Train Epoch: 279 [81920/90000 (91%)]	Loss: -5.4746	Cost: 19.04s
Train Epoch: 279 	Average Loss: -5.3770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5104

Learning rate: 8.187942363728625e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: -1.7099	Cost: 36.63s
Train Epoch: 280 [40960/90000 (45%)]	Loss: -5.7039	Cost: 9.70s
Train Epoch: 280 [81920/90000 (91%)]	Loss: -5.6942	Cost: 17.50s
Train Epoch: 280 	Average Loss: -5.3689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6294

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Learning rate: 8.126186854142752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: -2.1798	Cost: 38.46s
Train Epoch: 281 [40960/90000 (45%)]	Loss: -5.7946	Cost: 9.70s
Train Epoch: 281 [81920/90000 (91%)]	Loss: -5.7803	Cost: 15.18s
Train Epoch: 281 	Average Loss: -5.3992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5365

Learning rate: 8.064505319491398e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: -2.0869	Cost: 35.94s
Train Epoch: 282 [40960/90000 (45%)]	Loss: -5.7864	Cost: 9.92s
Train Epoch: 282 [81920/90000 (91%)]	Loss: -5.7108	Cost: 12.14s
Train Epoch: 282 	Average Loss: -5.4024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5642

Learning rate: 8.002900194855929e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: -2.1949	Cost: 35.43s
Train Epoch: 283 [40960/90000 (45%)]	Loss: -5.8732	Cost: 10.14s
Train Epoch: 283 [81920/90000 (91%)]	Loss: -5.5927	Cost: 16.75s
Train Epoch: 283 	Average Loss: -5.4256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5745

Learning rate: 7.941373912301183e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: -2.2455	Cost: 34.66s
Train Epoch: 284 [40960/90000 (45%)]	Loss: -5.6689	Cost: 9.81s
Train Epoch: 284 [81920/90000 (91%)]	Loss: -5.6682	Cost: 18.19s
Train Epoch: 284 	Average Loss: -5.4325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6880

Saving model as e284_model.pt & e284_waveforms_supplementary.hdf5
Learning rate: 7.879928900779452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: -2.2855	Cost: 36.48s
Train Epoch: 285 [40960/90000 (45%)]	Loss: -5.7423	Cost: 9.86s
Train Epoch: 285 [81920/90000 (91%)]	Loss: -5.6428	Cost: 13.40s
Train Epoch: 285 	Average Loss: -5.4178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7272

Saving model as e285_model.pt & e285_waveforms_supplementary.hdf5
Learning rate: 7.818567586034573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: -2.3656	Cost: 34.95s
Train Epoch: 286 [40960/90000 (45%)]	Loss: -5.9511	Cost: 9.70s
Train Epoch: 286 [81920/90000 (91%)]	Loss: -5.7121	Cost: 13.31s
Train Epoch: 286 	Average Loss: -5.5038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6164

Learning rate: 7.757292390506185e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: -2.6179	Cost: 33.23s
Train Epoch: 287 [40960/90000 (45%)]	Loss: -5.9846	Cost: 9.50s
Train Epoch: 287 [81920/90000 (91%)]	Loss: -5.8287	Cost: 13.60s
Train Epoch: 287 	Average Loss: -5.5165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5784

Learning rate: 7.696105733234094e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: -2.4739	Cost: 33.32s
Train Epoch: 288 [40960/90000 (45%)]	Loss: -5.8325	Cost: 9.63s
Train Epoch: 288 [81920/90000 (91%)]	Loss: -5.8324	Cost: 17.85s
Train Epoch: 288 	Average Loss: -5.4849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5503

Learning rate: 7.635010029762752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: -2.2742	Cost: 35.81s
Train Epoch: 289 [40960/90000 (45%)]	Loss: -5.6781	Cost: 9.68s
Train Epoch: 289 [81920/90000 (91%)]	Loss: -5.7928	Cost: 17.74s
Train Epoch: 289 	Average Loss: -5.4025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6611

Learning rate: 7.574007692045924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: -2.1219	Cost: 36.87s
Train Epoch: 290 [40960/90000 (45%)]	Loss: -5.8782	Cost: 9.69s
Train Epoch: 290 [81920/90000 (91%)]	Loss: -5.8110	Cost: 13.77s
Train Epoch: 290 	Average Loss: -5.5141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6901

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: -2.1873	Cost: 37.68s
Train Epoch: 291 [40960/90000 (45%)]	Loss: -5.8492	Cost: 9.71s
Train Epoch: 291 [81920/90000 (91%)]	Loss: -5.8405	Cost: 14.25s
Train Epoch: 291 	Average Loss: -5.5257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5700

Learning rate: 7.452292743166178e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: -2.5084	Cost: 35.78s
Train Epoch: 292 [40960/90000 (45%)]	Loss: -5.8064	Cost: 10.08s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -5.7578	Cost: 13.03s
Train Epoch: 292 	Average Loss: -5.4865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7355

Saving model as e292_model.pt & e292_waveforms_supplementary.hdf5
Learning rate: 7.391584937101029e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: -2.3003	Cost: 32.84s
Train Epoch: 293 [40960/90000 (45%)]	Loss: -5.9358	Cost: 9.68s
Train Epoch: 293 [81920/90000 (91%)]	Loss: -6.0811	Cost: 19.47s
Train Epoch: 293 	Average Loss: -5.6013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8101

Saving model as e293_model.pt & e293_waveforms_supplementary.hdf5
Learning rate: 7.330980106796245e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: -2.3364	Cost: 38.52s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -6.0140	Cost: 9.74s
Train Epoch: 294 [81920/90000 (91%)]	Loss: -6.0429	Cost: 13.45s
Train Epoch: 294 	Average Loss: -5.6904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7020

Learning rate: 7.270480644826745e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: -2.2607	Cost: 38.96s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -6.1146	Cost: 9.53s
Train Epoch: 295 [81920/90000 (91%)]	Loss: -6.1740	Cost: 13.12s
Train Epoch: 295 	Average Loss: -5.7369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8756

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 7.210088939607704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: -2.2710	Cost: 33.85s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -6.0413	Cost: 9.65s
Train Epoch: 296 [81920/90000 (91%)]	Loss: -6.0395	Cost: 14.07s
Train Epoch: 296 	Average Loss: -5.7453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0209

Saving model as e296_model.pt & e296_waveforms_supplementary.hdf5
Learning rate: 7.149807375300236e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: -2.5090	Cost: 34.21s
Train Epoch: 297 [40960/90000 (45%)]	Loss: -6.0597	Cost: 9.66s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -6.2294	Cost: 18.21s
Train Epoch: 297 	Average Loss: -5.8229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8360

Learning rate: 7.08963833171728e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: -2.6902	Cost: 37.28s
Train Epoch: 298 [40960/90000 (45%)]	Loss: -6.2297	Cost: 9.70s
Train Epoch: 298 [81920/90000 (91%)]	Loss: -6.1126	Cost: 15.30s
Train Epoch: 298 	Average Loss: -5.8368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9438

Learning rate: 7.029584184229648e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: -2.6919	Cost: 36.81s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -6.2477	Cost: 9.64s
Train Epoch: 299 [81920/90000 (91%)]	Loss: -6.1207	Cost: 13.31s
Train Epoch: 299 	Average Loss: -5.8643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9455

Learning rate: 6.969647303672259e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: -2.5691	Cost: 38.57s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -6.2902	Cost: 9.69s
Train Epoch: 300 [81920/90000 (91%)]	Loss: -6.2068	Cost: 13.76s
Train Epoch: 300 	Average Loss: -5.8182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9152

Learning rate: 6.909830056250523e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: -2.5672	Cost: 35.71s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -6.1666	Cost: 9.55s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -6.0755	Cost: 17.58s
Train Epoch: 301 	Average Loss: -5.8155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9437

Learning rate: 6.850134803446949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: -2.6662	Cost: 35.20s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -6.2212	Cost: 9.65s
Train Epoch: 302 [81920/90000 (91%)]	Loss: -6.2920	Cost: 17.98s
Train Epoch: 302 	Average Loss: -5.8330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8897

Learning rate: 6.790563901927903e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: -2.4991	Cost: 35.35s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -6.2444	Cost: 9.69s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -6.2740	Cost: 13.72s
Train Epoch: 303 	Average Loss: -5.8524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9107

Learning rate: 6.731119703450573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: -2.6961	Cost: 37.88s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -6.3818	Cost: 9.79s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -6.0786	Cost: 13.34s
Train Epoch: 304 	Average Loss: -5.8731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9681

Learning rate: 6.67180455477013e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: -2.7215	Cost: 33.22s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -6.2828	Cost: 9.63s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -6.0594	Cost: 13.28s
Train Epoch: 305 	Average Loss: -5.9683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9844

Learning rate: 6.612620797547083e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: -2.4430	Cost: 33.71s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -6.3227	Cost: 9.74s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -6.2549	Cost: 18.88s
Train Epoch: 306 	Average Loss: -5.9176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1165

Saving model as e306_model.pt & e306_waveforms_supplementary.hdf5
Learning rate: 6.553570768254825e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: -2.8068	Cost: 38.07s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -6.3642	Cost: 9.85s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -6.4382	Cost: 15.61s
Train Epoch: 307 	Average Loss: -6.0053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0869

Learning rate: 6.494656798087406e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: -2.2988	Cost: 39.27s
Train Epoch: 308 [40960/90000 (45%)]	Loss: -6.4008	Cost: 9.66s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -6.3325	Cost: 13.17s
Train Epoch: 308 	Average Loss: -5.9943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9720

Learning rate: 6.435881212867491e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: -2.8119	Cost: 36.28s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -6.2245	Cost: 9.63s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -6.4665	Cost: 13.66s
Train Epoch: 309 	Average Loss: -6.0313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0903

Learning rate: 6.377246332954541e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: -2.6613	Cost: 34.28s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -6.3296	Cost: 9.81s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -6.2861	Cost: 18.94s
Train Epoch: 310 	Average Loss: -6.0336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0279

Learning rate: 6.318754473153218e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: -2.7929	Cost: 37.14s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -6.2105	Cost: 9.86s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -6.3220	Cost: 17.27s
Train Epoch: 311 	Average Loss: -5.9569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8642

Learning rate: 6.260407942621994e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: -2.8615	Cost: 36.28s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -6.4079	Cost: 9.67s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -6.1608	Cost: 15.99s
Train Epoch: 312 	Average Loss: -6.0233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9436

Learning rate: 6.202209044781987e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: -2.6102	Cost: 33.61s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -6.3582	Cost: 9.69s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -6.1811	Cost: 12.84s
Train Epoch: 313 	Average Loss: -6.0477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9974

Learning rate: 6.144160077226032e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: -2.4035	Cost: 33.51s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -6.3279	Cost: 10.24s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -6.4328	Cost: 17.36s
Train Epoch: 314 	Average Loss: -6.0950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0187

Learning rate: 6.0862633316279744e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: -2.7491	Cost: 35.19s
Train Epoch: 315 [40960/90000 (45%)]	Loss: -6.7144	Cost: 9.70s
Train Epoch: 315 [81920/90000 (91%)]	Loss: -6.3005	Cost: 18.19s
Train Epoch: 315 	Average Loss: -6.1116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1173

Saving model as e315_model.pt & e315_waveforms_supplementary.hdf5
Learning rate: 6.028521093652189e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: -2.8999	Cost: 36.56s
Train Epoch: 316 [40960/90000 (45%)]	Loss: -6.6383	Cost: 9.71s
Train Epoch: 316 [81920/90000 (91%)]	Loss: -6.6295	Cost: 14.96s
Train Epoch: 316 	Average Loss: -6.2526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2155

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 5.970935642863369e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: -2.7595	Cost: 33.96s
Train Epoch: 317 [40960/90000 (45%)]	Loss: -6.5309	Cost: 9.64s
Train Epoch: 317 [81920/90000 (91%)]	Loss: -6.4805	Cost: 12.81s
Train Epoch: 317 	Average Loss: -6.1702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1186

Learning rate: 5.9135092526365064e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: -2.7207	Cost: 34.55s
Train Epoch: 318 [40960/90000 (45%)]	Loss: -6.4787	Cost: 9.85s
Train Epoch: 318 [81920/90000 (91%)]	Loss: -6.5630	Cost: 17.61s
Train Epoch: 318 	Average Loss: -6.1964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0774

Learning rate: 5.8562441900671545e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: -2.8720	Cost: 35.74s
Train Epoch: 319 [40960/90000 (45%)]	Loss: -6.6150	Cost: 9.64s
Train Epoch: 319 [81920/90000 (91%)]	Loss: -6.6491	Cost: 18.62s
Train Epoch: 319 	Average Loss: -6.2234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3771

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Learning rate: 5.799142715881933e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: -2.5069	Cost: 38.29s
Train Epoch: 320 [40960/90000 (45%)]	Loss: -6.6838	Cost: 9.93s
Train Epoch: 320 [81920/90000 (91%)]	Loss: -6.4294	Cost: 13.71s
Train Epoch: 320 	Average Loss: -6.2078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1378

Learning rate: 5.742207084349269e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: -2.4952	Cost: 36.05s
Train Epoch: 321 [40960/90000 (45%)]	Loss: -6.6899	Cost: 9.72s
Train Epoch: 321 [81920/90000 (91%)]	Loss: -6.6963	Cost: 14.09s
Train Epoch: 321 	Average Loss: -6.2319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2842

Learning rate: 5.68543954319041e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: -2.6940	Cost: 33.84s
Train Epoch: 322 [40960/90000 (45%)]	Loss: -6.7258	Cost: 9.87s
Train Epoch: 322 [81920/90000 (91%)]	Loss: -6.5518	Cost: 17.39s
Train Epoch: 322 	Average Loss: -6.2919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2094

Learning rate: 5.62884233349067e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: -2.8290	Cost: 36.66s
Train Epoch: 323 [40960/90000 (45%)]	Loss: -6.8616	Cost: 9.71s
Train Epoch: 323 [81920/90000 (91%)]	Loss: -6.7326	Cost: 18.08s
Train Epoch: 323 	Average Loss: -6.3545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3037

Learning rate: 5.572417689610984e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: -2.8577	Cost: 41.14s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -6.8005	Cost: 9.68s
Train Epoch: 324 [81920/90000 (91%)]	Loss: -6.7236	Cost: 13.24s
Train Epoch: 324 	Average Loss: -6.4078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2706

Learning rate: 5.516167839099677e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: -2.7540	Cost: 35.10s
Train Epoch: 325 [40960/90000 (45%)]	Loss: -6.9118	Cost: 9.66s
Train Epoch: 325 [81920/90000 (91%)]	Loss: -6.6155	Cost: 12.77s
Train Epoch: 325 	Average Loss: -6.4320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3528

Learning rate: 5.46009500260453e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: -2.8837	Cost: 35.58s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -6.9995	Cost: 9.58s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -6.7070	Cost: 14.30s
Train Epoch: 326 	Average Loss: -6.4578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3263

Learning rate: 5.4042013937851194e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: -2.7907	Cost: 33.50s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -6.8993	Cost: 9.93s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -6.6501	Cost: 18.37s
Train Epoch: 327 	Average Loss: -6.4350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2869

Learning rate: 5.3484892192254136e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: -2.8147	Cost: 38.89s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -6.7768	Cost: 9.78s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -6.6897	Cost: 14.02s
Train Epoch: 328 	Average Loss: -6.4185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2007

Learning rate: 5.292960678346675e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: -3.1269	Cost: 34.79s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -6.9164	Cost: 9.97s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -6.7393	Cost: 13.23s
Train Epoch: 329 	Average Loss: -6.4450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3497

Learning rate: 5.237617963320605e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: -3.2229	Cost: 37.97s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -6.8630	Cost: 9.59s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -6.8814	Cost: 13.08s
Train Epoch: 330 	Average Loss: -6.5030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4196

Saving model as e330_model.pt & e330_waveforms_supplementary.hdf5
Learning rate: 5.182463258982848e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: -2.6288	Cost: 34.25s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -6.7060	Cost: 9.91s
Train Epoch: 331 [81920/90000 (91%)]	Loss: -6.9628	Cost: 19.43s
Train Epoch: 331 	Average Loss: -6.5122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4565

Saving model as e331_model.pt & e331_waveforms_supplementary.hdf5
Learning rate: 5.127498742746677e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: -3.1974	Cost: 35.68s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -6.7531	Cost: 9.78s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -6.5348	Cost: 14.49s
Train Epoch: 332 	Average Loss: -6.4930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4091

Learning rate: 5.07272658451708e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: -2.9466	Cost: 38.63s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -6.9258	Cost: 9.69s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -6.7099	Cost: 13.77s
Train Epoch: 333 	Average Loss: -6.4703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3577

Learning rate: 5.01814894660509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: -2.9489	Cost: 36.19s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -6.8671	Cost: 9.67s
Train Epoch: 334 [81920/90000 (91%)]	Loss: -6.8213	Cost: 12.73s
Train Epoch: 334 	Average Loss: -6.5210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4001

Learning rate: 4.96376798364239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: -2.9443	Cost: 33.36s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -7.0315	Cost: 9.99s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -7.0351	Cost: 17.79s
Train Epoch: 335 	Average Loss: -6.6213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5645

Saving model as e335_model.pt & e335_waveforms_supplementary.hdf5
Learning rate: 4.9095858424962844e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: -3.0653	Cost: 35.12s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -6.8302	Cost: 9.88s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -6.9908	Cost: 16.05s
Train Epoch: 336 	Average Loss: -6.6254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5504

Learning rate: 4.855604662184932e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: -3.0485	Cost: 38.39s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -6.7811	Cost: 9.66s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -6.7099	Cost: 15.30s
Train Epoch: 337 	Average Loss: -6.5968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5835

Saving model as e337_model.pt & e337_waveforms_supplementary.hdf5
Learning rate: 4.801826573792905e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: -3.1886	Cost: 34.93s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -6.8491	Cost: 9.67s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -6.9288	Cost: 13.40s
Train Epoch: 338 	Average Loss: -6.6939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4791

Learning rate: 4.748253700387039e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: -2.8986	Cost: 33.48s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -7.0793	Cost: 10.01s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -6.9823	Cost: 18.04s
Train Epoch: 339 	Average Loss: -6.7379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4692

Learning rate: 4.694888156932659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: -3.2948	Cost: 36.14s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -7.0109	Cost: 9.94s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -7.0778	Cost: 17.61s
Train Epoch: 340 	Average Loss: -6.7032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5640

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: -3.3357	Cost: 36.78s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -7.2113	Cost: 9.62s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -7.0734	Cost: 14.12s
Train Epoch: 341 	Average Loss: -6.7734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6767

Saving model as e341_model.pt & e341_waveforms_supplementary.hdf5
Learning rate: 4.5887874787312395e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: -3.4719	Cost: 38.07s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -7.1075	Cost: 9.59s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -7.2076	Cost: 13.29s
Train Epoch: 342 	Average Loss: -6.8279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7971

Saving model as e342_model.pt & e342_waveforms_supplementary.hdf5
Learning rate: 4.536056532657307e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: -3.0375	Cost: 34.05s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -7.1663	Cost: 9.96s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -7.2463	Cost: 18.57s
Train Epoch: 343 	Average Loss: -6.8204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7186

Learning rate: 4.4835412937156955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: -3.1888	Cost: 35.51s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -7.1737	Cost: 10.15s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -7.1506	Cost: 15.00s
Train Epoch: 344 	Average Loss: -6.8486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5650

Learning rate: 4.431243835118117e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: -3.2254	Cost: 37.93s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -7.1241	Cost: 9.66s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -7.1387	Cost: 16.42s
Train Epoch: 345 	Average Loss: -6.7949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4760

Learning rate: 4.379166221478691e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: -3.3227	Cost: 35.21s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -7.1603	Cost: 9.72s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -7.2189	Cost: 12.75s
Train Epoch: 346 	Average Loss: -6.8012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5337

Learning rate: 4.327310508732435e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: -3.2094	Cost: 33.64s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -7.1002	Cost: 9.83s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -7.3822	Cost: 20.18s
Train Epoch: 347 	Average Loss: -6.8648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5656

Learning rate: 4.275678744054088e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: -3.2201	Cost: 36.06s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -7.2457	Cost: 9.74s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -7.2749	Cost: 17.19s
Train Epoch: 348 	Average Loss: -6.9162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8177

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Learning rate: 4.224272965777324e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: -3.4646	Cost: 39.07s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -7.3284	Cost: 9.70s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -7.1622	Cost: 13.35s
Train Epoch: 349 	Average Loss: -6.9282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6051

Learning rate: 4.173095203314239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: -2.9595	Cost: 33.88s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -7.2942	Cost: 9.63s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -7.2255	Cost: 13.42s
Train Epoch: 350 	Average Loss: -6.8315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6546

Learning rate: 4.1221474770752684e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: -3.2050	Cost: 32.94s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -7.2963	Cost: 9.87s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -7.2423	Cost: 18.93s
Train Epoch: 351 	Average Loss: -6.9397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7717

Learning rate: 4.071431798389406e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: -3.3609	Cost: 38.01s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -7.2284	Cost: 9.80s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -7.2069	Cost: 14.83s
Train Epoch: 352 	Average Loss: -6.9536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6618

Learning rate: 4.020950169424814e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: -3.1351	Cost: 34.84s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -7.2254	Cost: 9.64s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -7.2957	Cost: 13.01s
Train Epoch: 353 	Average Loss: -6.9198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7194

Learning rate: 3.970704583109751e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: -3.4727	Cost: 34.30s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -7.3373	Cost: 9.63s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -7.3152	Cost: 12.78s
Train Epoch: 354 	Average Loss: -7.0246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8022

Learning rate: 3.920697023053944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: -3.2625	Cost: 33.69s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -7.3801	Cost: 9.71s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -7.4128	Cost: 16.31s
Train Epoch: 355 	Average Loss: -7.0439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8108

Learning rate: 3.870929463470237e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: -3.2784	Cost: 35.33s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -7.5139	Cost: 9.70s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -7.4589	Cost: 17.89s
Train Epoch: 356 	Average Loss: -7.0566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7243

Learning rate: 3.821403869096654e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: -3.4799	Cost: 37.71s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -7.4809	Cost: 9.81s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -7.4370	Cost: 14.35s
Train Epoch: 357 	Average Loss: -7.0862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7514

Learning rate: 3.772122195118876e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: -3.6612	Cost: 35.25s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -7.4415	Cost: 9.73s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -7.2791	Cost: 13.32s
Train Epoch: 358 	Average Loss: -7.0612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6246

Learning rate: 3.723086387092996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: -3.2419	Cost: 33.63s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -7.1637	Cost: 9.66s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -7.4214	Cost: 12.54s
Train Epoch: 359 	Average Loss: -6.9649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6974

Learning rate: 3.674298380868755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: -3.3921	Cost: 33.90s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -7.3489	Cost: 9.69s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -7.3407	Cost: 16.84s
Train Epoch: 360 	Average Loss: -7.0391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8237

Saving model as e360_model.pt & e360_waveforms_supplementary.hdf5
Learning rate: 3.6257601025131026e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: -3.4586	Cost: 36.15s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -7.3655	Cost: 9.74s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -7.4897	Cost: 19.19s
Train Epoch: 361 	Average Loss: -7.1062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8008

Learning rate: 3.5774734682341595e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: -3.4623	Cost: 37.75s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -7.4007	Cost: 9.59s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -7.2831	Cost: 14.87s
Train Epoch: 362 	Average Loss: -6.9907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7831

Learning rate: 3.529440384305556e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: -3.0271	Cost: 34.92s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -7.4819	Cost: 9.73s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -7.5731	Cost: 13.86s
Train Epoch: 363 	Average Loss: -7.0871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9522

Saving model as e363_model.pt & e363_waveforms_supplementary.hdf5
Learning rate: 3.481662746991211e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: -3.6830	Cost: 34.70s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -7.6181	Cost: 10.37s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -7.5460	Cost: 15.78s
Train Epoch: 364 	Average Loss: -7.1978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8256

Learning rate: 3.434142442470437e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: -3.8279	Cost: 34.91s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -7.5914	Cost: 9.70s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -7.6198	Cost: 17.44s
Train Epoch: 365 	Average Loss: -7.2240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9658

Saving model as e365_model.pt & e365_waveforms_supplementary.hdf5
Learning rate: 3.3868813467634793e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: -3.6356	Cost: 37.35s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -7.5578	Cost: 9.67s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -7.6365	Cost: 13.95s
Train Epoch: 366 	Average Loss: -7.2546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8615

Learning rate: 3.339881325657484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: -3.1303	Cost: 37.81s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -7.6668	Cost: 9.77s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -7.6365	Cost: 14.40s
Train Epoch: 367 	Average Loss: -7.2743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8657

Learning rate: 3.2931442346328e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: -3.5194	Cost: 35.87s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -7.6439	Cost: 9.62s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -7.5841	Cost: 12.34s
Train Epoch: 368 	Average Loss: -7.3167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9571

Learning rate: 3.246671918789755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: -3.7655	Cost: 33.03s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -7.6336	Cost: 9.71s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -7.6418	Cost: 19.07s
Train Epoch: 369 	Average Loss: -7.3098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0702

Saving model as e369_model.pt & e369_waveforms_supplementary.hdf5
Learning rate: 3.200466212775808e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: -3.8174	Cost: 37.04s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -7.6673	Cost: 9.83s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -7.5993	Cost: 14.84s
Train Epoch: 370 	Average Loss: -7.3413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8930

Learning rate: 3.1545289407131164e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: -3.7162	Cost: 37.26s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -7.7428	Cost: 9.97s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -7.8302	Cost: 13.96s
Train Epoch: 371 	Average Loss: -7.3329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0428

Learning rate: 3.1088619161265144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: -3.2615	Cost: 33.88s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -7.5682	Cost: 9.67s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -7.7871	Cost: 13.44s
Train Epoch: 372 	Average Loss: -7.3544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9211

Learning rate: 3.0634669418719525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: -3.8519	Cost: 33.93s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -7.5684	Cost: 9.85s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -7.5898	Cost: 15.68s
Train Epoch: 373 	Average Loss: -7.3332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9885

Learning rate: 3.0183458100652757e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: -3.8060	Cost: 35.11s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -7.7442	Cost: 9.71s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -7.4460	Cost: 17.38s
Train Epoch: 374 	Average Loss: -7.3492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9727

Learning rate: 2.9735003020115068e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: -3.7297	Cost: 37.43s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -7.6593	Cost: 9.74s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -7.5720	Cost: 13.99s
Train Epoch: 375 	Average Loss: -7.3810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0165

Learning rate: 2.928932188134526e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: -3.7801	Cost: 34.39s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -7.7332	Cost: 9.91s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -7.7051	Cost: 12.76s
Train Epoch: 376 	Average Loss: -7.4199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0061

Learning rate: 2.8846432279071474e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: -3.5102	Cost: 33.65s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -7.7383	Cost: 9.63s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -7.9629	Cost: 12.59s
Train Epoch: 377 	Average Loss: -7.4046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9895

Learning rate: 2.8406351697816885e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: -3.9586	Cost: 33.87s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -7.9693	Cost: 10.27s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -7.7487	Cost: 18.06s
Train Epoch: 378 	Average Loss: -7.5051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0451

Learning rate: 2.796909751120931e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: -3.9305	Cost: 37.19s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -7.8670	Cost: 9.85s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -7.7237	Cost: 17.40s
Train Epoch: 379 	Average Loss: -7.5321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0736

Saving model as e379_model.pt & e379_waveforms_supplementary.hdf5
Learning rate: 2.7534686981295358e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: -3.8764	Cost: 41.06s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -7.8313	Cost: 9.67s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -7.9983	Cost: 14.25s
Train Epoch: 380 	Average Loss: -7.5015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0795

Saving model as e380_model.pt & e380_waveforms_supplementary.hdf5
Learning rate: 2.7103137257858838e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: -3.4424	Cost: 37.79s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -7.7789	Cost: 9.70s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -7.9348	Cost: 13.35s
Train Epoch: 381 	Average Loss: -7.5552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1831

Saving model as e381_model.pt & e381_waveforms_supplementary.hdf5
Learning rate: 2.667446537774402e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: -3.5186	Cost: 32.94s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -7.8734	Cost: 9.87s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -7.9282	Cost: 18.32s
Train Epoch: 382 	Average Loss: -7.5719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0796

Learning rate: 2.6248688264182623e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: -3.7833	Cost: 35.99s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -8.0322	Cost: 9.82s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -7.9142	Cost: 15.86s
Train Epoch: 383 	Average Loss: -7.5474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1384

Learning rate: 2.5825822726126095e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: -4.1506	Cost: 38.13s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -8.0814	Cost: 9.67s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -7.8822	Cost: 15.29s
Train Epoch: 384 	Average Loss: -7.6071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2343

Saving model as e384_model.pt & e384_waveforms_supplementary.hdf5
Learning rate: 2.5405885457581793e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: -3.7726	Cost: 36.04s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -7.9562	Cost: 9.54s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -7.9667	Cost: 13.48s
Train Epoch: 385 	Average Loss: -7.6007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0853

Learning rate: 2.4988893036954043e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: -3.8211	Cost: 34.20s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -7.9414	Cost: 9.89s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -7.9641	Cost: 18.51s
Train Epoch: 386 	Average Loss: -7.6214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1308

Learning rate: 2.4574861926389615e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: -3.8129	Cost: 35.26s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -8.1329	Cost: 9.77s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -8.1643	Cost: 19.51s
Train Epoch: 387 	Average Loss: -7.6750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1789

Learning rate: 2.4163808471127812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: -3.7868	Cost: 38.38s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -8.1385	Cost: 9.66s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -7.9700	Cost: 12.96s
Train Epoch: 388 	Average Loss: -7.6803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2315

Learning rate: 2.3755748898855234e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: -3.5071	Cost: 38.35s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -8.0726	Cost: 9.58s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -7.9323	Cost: 13.41s
Train Epoch: 389 	Average Loss: -7.6760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1991

Learning rate: 2.3350699319065006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: -4.0961	Cost: 36.13s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -8.0957	Cost: 9.64s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -8.0968	Cost: 14.47s
Train Epoch: 390 	Average Loss: -7.7214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0926

Learning rate: 2.2948675722421086e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: -3.8196	Cost: 32.96s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -7.9304	Cost: 9.68s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -8.0335	Cost: 18.32s
Train Epoch: 391 	Average Loss: -7.7017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1962

Learning rate: 2.2549693980126627e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: -3.4821	Cost: 35.82s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -8.1016	Cost: 9.84s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -8.0056	Cost: 17.03s
Train Epoch: 392 	Average Loss: -7.6742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0308

Learning rate: 2.2153769843297664e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: -3.9488	Cost: 38.71s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -8.3121	Cost: 9.72s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -7.9459	Cost: 14.39s
Train Epoch: 393 	Average Loss: -7.7247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0351

Learning rate: 2.1760918942341185e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: -3.9055	Cost: 33.73s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -8.3625	Cost: 9.65s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -7.9787	Cost: 12.79s
Train Epoch: 394 	Average Loss: -7.7538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2611

Saving model as e394_model.pt & e394_waveforms_supplementary.hdf5
Learning rate: 2.1371156786338137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: -3.8236	Cost: 33.40s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -8.3253	Cost: 9.82s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -8.1160	Cost: 18.41s
Train Epoch: 395 	Average Loss: -7.7173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2977

Saving model as e395_model.pt & e395_waveforms_supplementary.hdf5
Learning rate: 2.0984498762430954e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: -4.1874	Cost: 36.92s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -8.1292	Cost: 10.00s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -8.1498	Cost: 15.87s
Train Epoch: 396 	Average Loss: -7.7815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2256

Learning rate: 2.060096013521646e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: -4.1811	Cost: 37.21s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -8.3185	Cost: 9.62s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -8.1116	Cost: 13.58s
Train Epoch: 397 	Average Loss: -7.8560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3748

Saving model as e397_model.pt & e397_waveforms_supplementary.hdf5
Learning rate: 2.022055604614291e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: -4.0260	Cost: 35.69s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -8.2086	Cost: 9.70s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -8.1038	Cost: 12.10s
Train Epoch: 398 	Average Loss: -7.8691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3375

Learning rate: 1.9843301512912324e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: -3.8513	Cost: 32.94s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -8.4267	Cost: 9.55s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -8.0859	Cost: 16.17s
Train Epoch: 399 	Average Loss: -7.8261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4610

Saving model as e399_model.pt & e399_waveforms_supplementary.hdf5
Learning rate: 1.9469211428887808e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: -4.0933	Cost: 35.65s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -8.3372	Cost: 9.78s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -8.0919	Cost: 18.62s
Train Epoch: 400 	Average Loss: -7.8621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4330

Learning rate: 1.9098300562505263e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: -3.7736	Cost: 36.56s
Train Epoch: 401 [40960/90000 (45%)]	Loss: -8.3131	Cost: 9.70s
Train Epoch: 401 [81920/90000 (91%)]	Loss: -7.7178	Cost: 14.14s
Train Epoch: 401 	Average Loss: -7.7385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1758

Learning rate: 1.8730583556690602e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: -4.0514	Cost: 39.20s
Train Epoch: 402 [40960/90000 (45%)]	Loss: -8.2840	Cost: 9.89s
Train Epoch: 402 [81920/90000 (91%)]	Loss: -7.8862	Cost: 13.49s
Train Epoch: 402 	Average Loss: -7.7692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3810

Learning rate: 1.8366074928281604e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: -4.1505	Cost: 33.71s
Train Epoch: 403 [40960/90000 (45%)]	Loss: -8.3167	Cost: 10.17s
Train Epoch: 403 [81920/90000 (91%)]	Loss: -8.1856	Cost: 16.92s
Train Epoch: 403 	Average Loss: -7.8602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2419

Learning rate: 1.8004789067454784e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: -3.9498	Cost: 36.46s
Train Epoch: 404 [40960/90000 (45%)]	Loss: -8.3885	Cost: 9.62s
Train Epoch: 404 [81920/90000 (91%)]	Loss: -8.3323	Cost: 18.64s
Train Epoch: 404 	Average Loss: -7.8899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3597

Learning rate: 1.7646740237157253e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: -4.3741	Cost: 36.69s
Train Epoch: 405 [40960/90000 (45%)]	Loss: -8.2459	Cost: 9.71s
Train Epoch: 405 [81920/90000 (91%)]	Loss: -8.0997	Cost: 12.74s
Train Epoch: 405 	Average Loss: -7.8995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1521

Learning rate: 1.7291942572543828e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: -3.9932	Cost: 38.11s
Train Epoch: 406 [40960/90000 (45%)]	Loss: -8.4080	Cost: 9.73s
Train Epoch: 406 [81920/90000 (91%)]	Loss: -8.3774	Cost: 14.75s
Train Epoch: 406 	Average Loss: -7.9429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4750

Saving model as e406_model.pt & e406_waveforms_supplementary.hdf5
Learning rate: 1.6940410080418743e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: -3.4988	Cost: 33.79s
Train Epoch: 407 [40960/90000 (45%)]	Loss: -8.1686	Cost: 9.60s
Train Epoch: 407 [81920/90000 (91%)]	Loss: -8.2634	Cost: 14.69s
Train Epoch: 407 	Average Loss: -7.8664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3675

Learning rate: 1.6592156638682862e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: -4.1735	Cost: 32.37s
Train Epoch: 408 [40960/90000 (45%)]	Loss: -8.3803	Cost: 9.99s
Train Epoch: 408 [81920/90000 (91%)]	Loss: -8.4192	Cost: 18.34s
Train Epoch: 408 	Average Loss: -7.9213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2612

Learning rate: 1.6247195995785833e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: -4.0224	Cost: 35.77s
Train Epoch: 409 [40960/90000 (45%)]	Loss: -8.4289	Cost: 9.70s
Train Epoch: 409 [81920/90000 (91%)]	Loss: -8.3274	Cost: 16.59s
Train Epoch: 409 	Average Loss: -7.9359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4703

Learning rate: 1.5905541770183092e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: -4.1503	Cost: 41.20s
Train Epoch: 410 [40960/90000 (45%)]	Loss: -8.5371	Cost: 9.49s
Train Epoch: 410 [81920/90000 (91%)]	Loss: -8.3374	Cost: 14.73s
Train Epoch: 410 	Average Loss: -7.9454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4618

Learning rate: 1.5567207449798488e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: -4.6013	Cost: 35.51s
Train Epoch: 411 [40960/90000 (45%)]	Loss: -8.2652	Cost: 9.78s
Train Epoch: 411 [81920/90000 (91%)]	Loss: -8.2762	Cost: 14.19s
Train Epoch: 411 	Average Loss: -7.9460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3711

Learning rate: 1.5232206391491672e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: -3.9597	Cost: 35.90s
Train Epoch: 412 [40960/90000 (45%)]	Loss: -8.4697	Cost: 9.58s
Train Epoch: 412 [81920/90000 (91%)]	Loss: -8.3671	Cost: 17.29s
Train Epoch: 412 	Average Loss: -7.9964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4525

Learning rate: 1.4900551820530823e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: -4.1491	Cost: 35.99s
Train Epoch: 413 [40960/90000 (45%)]	Loss: -8.3325	Cost: 9.65s
Train Epoch: 413 [81920/90000 (91%)]	Loss: -8.2095	Cost: 17.47s
Train Epoch: 413 	Average Loss: -7.9668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3780

Learning rate: 1.457225683007047e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: -3.7945	Cost: 36.31s
Train Epoch: 414 [40960/90000 (45%)]	Loss: -8.6229	Cost: 9.73s
Train Epoch: 414 [81920/90000 (91%)]	Loss: -8.3128	Cost: 13.58s
Train Epoch: 414 	Average Loss: -7.9944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4660

Learning rate: 1.4247334380634787e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: -4.2932	Cost: 38.50s
Train Epoch: 415 [40960/90000 (45%)]	Loss: -8.3131	Cost: 9.57s
Train Epoch: 415 [81920/90000 (91%)]	Loss: -8.4967	Cost: 14.38s
Train Epoch: 415 	Average Loss: -8.0329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5035

Saving model as e415_model.pt & e415_waveforms_supplementary.hdf5
Learning rate: 1.3925797299605641e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: -4.0394	Cost: 35.34s
Train Epoch: 416 [40960/90000 (45%)]	Loss: -8.5281	Cost: 9.71s
Train Epoch: 416 [81920/90000 (91%)]	Loss: -8.3217	Cost: 15.89s
Train Epoch: 416 	Average Loss: -8.0341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4091

Learning rate: 1.3607658280716445e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: -3.9408	Cost: 34.78s
Train Epoch: 417 [40960/90000 (45%)]	Loss: -8.3646	Cost: 9.70s
Train Epoch: 417 [81920/90000 (91%)]	Loss: -8.4156	Cost: 18.43s
Train Epoch: 417 	Average Loss: -7.9967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4846

Learning rate: 1.3292929883550993e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: -4.3353	Cost: 38.92s
Train Epoch: 418 [40960/90000 (45%)]	Loss: -8.5134	Cost: 9.80s
Train Epoch: 418 [81920/90000 (91%)]	Loss: -8.4415	Cost: 13.81s
Train Epoch: 418 	Average Loss: -8.0468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5089

Saving model as e418_model.pt & e418_waveforms_supplementary.hdf5
Learning rate: 1.2981624533047427e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: -4.0199	Cost: 35.56s
Train Epoch: 419 [40960/90000 (45%)]	Loss: -8.2918	Cost: 9.66s
Train Epoch: 419 [81920/90000 (91%)]	Loss: -8.4370	Cost: 14.23s
Train Epoch: 419 	Average Loss: -8.0157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4224

Learning rate: 1.2673754519007981e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: -4.3605	Cost: 35.98s
Train Epoch: 420 [40960/90000 (45%)]	Loss: -8.4139	Cost: 9.73s
Train Epoch: 420 [81920/90000 (91%)]	Loss: -8.4422	Cost: 12.92s
Train Epoch: 420 	Average Loss: -8.0787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6185

Saving model as e420_model.pt & e420_waveforms_supplementary.hdf5
Learning rate: 1.2369331995613638e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: -3.8320	Cost: 33.36s
Train Epoch: 421 [40960/90000 (45%)]	Loss: -8.6236	Cost: 9.81s
Train Epoch: 421 [81920/90000 (91%)]	Loss: -8.5234	Cost: 18.27s
Train Epoch: 421 	Average Loss: -8.1255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5799

Learning rate: 1.2068368980944384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: -4.2529	Cost: 35.88s
Train Epoch: 422 [40960/90000 (45%)]	Loss: -8.5574	Cost: 9.77s
Train Epoch: 422 [81920/90000 (91%)]	Loss: -8.4462	Cost: 13.93s
Train Epoch: 422 	Average Loss: -8.1496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4777

Learning rate: 1.1770877356504656e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: -4.0301	Cost: 36.92s
Train Epoch: 423 [40960/90000 (45%)]	Loss: -8.5713	Cost: 9.70s
Train Epoch: 423 [81920/90000 (91%)]	Loss: -8.5323	Cost: 16.86s
Train Epoch: 423 	Average Loss: -8.1299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5611

Learning rate: 1.1476868866754482e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: -4.1313	Cost: 37.55s
Train Epoch: 424 [40960/90000 (45%)]	Loss: -8.5367	Cost: 9.67s
Train Epoch: 424 [81920/90000 (91%)]	Loss: -8.5900	Cost: 13.03s
Train Epoch: 424 	Average Loss: -8.1270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4893

Learning rate: 1.1186355118645549e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: -3.9376	Cost: 33.30s
Train Epoch: 425 [40960/90000 (45%)]	Loss: -8.5409	Cost: 9.65s
Train Epoch: 425 [81920/90000 (91%)]	Loss: -8.4596	Cost: 17.83s
Train Epoch: 425 	Average Loss: -8.1969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6121

Learning rate: 1.0899347581163218e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: -3.9416	Cost: 35.33s
Train Epoch: 426 [40960/90000 (45%)]	Loss: -8.4927	Cost: 9.76s
Train Epoch: 426 [81920/90000 (91%)]	Loss: -8.4344	Cost: 19.01s
Train Epoch: 426 	Average Loss: -8.1728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4752

Learning rate: 1.061585758487362e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: -4.1684	Cost: 37.71s
Train Epoch: 427 [40960/90000 (45%)]	Loss: -8.5113	Cost: 10.18s
Train Epoch: 427 [81920/90000 (91%)]	Loss: -8.5080	Cost: 14.43s
Train Epoch: 427 	Average Loss: -8.2144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6791

Saving model as e427_model.pt & e427_waveforms_supplementary.hdf5
Learning rate: 1.033589632147641e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: -4.3826	Cost: 39.26s
Train Epoch: 428 [40960/90000 (45%)]	Loss: -8.7353	Cost: 9.76s
Train Epoch: 428 [81920/90000 (91%)]	Loss: -8.5637	Cost: 13.56s
Train Epoch: 428 	Average Loss: -8.2309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5930

Learning rate: 1.005947484336289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: -4.0421	Cost: 33.24s
Train Epoch: 429 [40960/90000 (45%)]	Loss: -8.5668	Cost: 9.94s
Train Epoch: 429 [81920/90000 (91%)]	Loss: -8.5297	Cost: 17.61s
Train Epoch: 429 	Average Loss: -8.2109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5243

Learning rate: 9.786604063179713e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: -3.9295	Cost: 35.36s
Train Epoch: 430 [40960/90000 (45%)]	Loss: -8.6643	Cost: 9.79s
Train Epoch: 430 [81920/90000 (91%)]	Loss: -8.5210	Cost: 18.39s
Train Epoch: 430 	Average Loss: -8.2148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6253

Learning rate: 9.517294753398061e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: -4.1879	Cost: 36.69s
Train Epoch: 431 [40960/90000 (45%)]	Loss: -8.6382	Cost: 9.74s
Train Epoch: 431 [81920/90000 (91%)]	Loss: -8.6067	Cost: 14.09s
Train Epoch: 431 	Average Loss: -8.2420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5619

Learning rate: 9.251557545888296e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: -4.0614	Cost: 35.41s
Train Epoch: 432 [40960/90000 (45%)]	Loss: -8.4919	Cost: 9.77s
Train Epoch: 432 [81920/90000 (91%)]	Loss: -8.4938	Cost: 14.70s
Train Epoch: 432 	Average Loss: -8.2494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6229

Learning rate: 8.98940293150043e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: -4.4097	Cost: 36.54s
Train Epoch: 433 [40960/90000 (45%)]	Loss: -8.6797	Cost: 9.58s
Train Epoch: 433 [81920/90000 (91%)]	Loss: -8.8002	Cost: 14.76s
Train Epoch: 433 	Average Loss: -8.3053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6945

Saving model as e433_model.pt & e433_waveforms_supplementary.hdf5
Learning rate: 8.730841259649718e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: -4.1597	Cost: 35.43s
Train Epoch: 434 [40960/90000 (45%)]	Loss: -8.4883	Cost: 9.75s
Train Epoch: 434 [81920/90000 (91%)]	Loss: -8.6102	Cost: 18.24s
Train Epoch: 434 	Average Loss: -8.2613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7141

Saving model as e434_model.pt & e434_waveforms_supplementary.hdf5
Learning rate: 8.475882737908241e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: -4.5059	Cost: 37.47s
Train Epoch: 435 [40960/90000 (45%)]	Loss: -8.7080	Cost: 9.67s
Train Epoch: 435 [81920/90000 (91%)]	Loss: -8.7777	Cost: 13.45s
Train Epoch: 435 	Average Loss: -8.3222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6865

Learning rate: 8.224537431601881e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: -4.2949	Cost: 38.41s
Train Epoch: 436 [40960/90000 (45%)]	Loss: -8.7548	Cost: 9.55s
Train Epoch: 436 [81920/90000 (91%)]	Loss: -8.5711	Cost: 14.31s
Train Epoch: 436 	Average Loss: -8.3249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5605

Learning rate: 7.97681526341298e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: -4.0915	Cost: 32.80s
Train Epoch: 437 [40960/90000 (45%)]	Loss: -8.7682	Cost: 9.63s
Train Epoch: 437 [81920/90000 (91%)]	Loss: -8.8208	Cost: 13.29s
Train Epoch: 437 	Average Loss: -8.3092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7012

Learning rate: 7.732726012988507e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: -4.5122	Cost: 33.07s
Train Epoch: 438 [40960/90000 (45%)]	Loss: -8.6592	Cost: 9.97s
Train Epoch: 438 [81920/90000 (91%)]	Loss: -8.6981	Cost: 18.85s
Train Epoch: 438 	Average Loss: -8.3091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6938

Learning rate: 7.492279316554181e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: -4.3047	Cost: 36.54s
Train Epoch: 439 [40960/90000 (45%)]	Loss: -8.7109	Cost: 9.79s
Train Epoch: 439 [81920/90000 (91%)]	Loss: -8.5681	Cost: 15.78s
Train Epoch: 439 	Average Loss: -8.3244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6940

Learning rate: 7.25548466653387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: -4.1938	Cost: 38.79s
Train Epoch: 440 [40960/90000 (45%)]	Loss: -8.7241	Cost: 9.62s
Train Epoch: 440 [81920/90000 (91%)]	Loss: -8.7546	Cost: 14.39s
Train Epoch: 440 	Average Loss: -8.3579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6760

Learning rate: 7.02235141117485e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: -4.2692	Cost: 37.43s
Train Epoch: 441 [40960/90000 (45%)]	Loss: -8.8192	Cost: 9.62s
Train Epoch: 441 [81920/90000 (91%)]	Loss: -8.7479	Cost: 14.29s
Train Epoch: 441 	Average Loss: -8.3341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5774

Learning rate: 6.792888754178901e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: -4.4302	Cost: 34.96s
Train Epoch: 442 [40960/90000 (45%)]	Loss: -8.5912	Cost: 9.54s
Train Epoch: 442 [81920/90000 (91%)]	Loss: -8.6830	Cost: 19.01s
Train Epoch: 442 	Average Loss: -8.3076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8657

Saving model as e442_model.pt & e442_waveforms_supplementary.hdf5
Learning rate: 6.567105754338794e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: -4.2002	Cost: 35.38s
Train Epoch: 443 [40960/90000 (45%)]	Loss: -8.8237	Cost: 9.77s
Train Epoch: 443 [81920/90000 (91%)]	Loss: -8.6891	Cost: 18.10s
Train Epoch: 443 	Average Loss: -8.3846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5595

Learning rate: 6.3450113251807676e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: -3.9495	Cost: 39.88s
Train Epoch: 444 [40960/90000 (45%)]	Loss: -8.7984	Cost: 9.60s
Train Epoch: 444 [81920/90000 (91%)]	Loss: -8.7375	Cost: 15.60s
Train Epoch: 444 	Average Loss: -8.3658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8102

Learning rate: 6.126614234612589e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: -4.2720	Cost: 36.14s
Train Epoch: 445 [40960/90000 (45%)]	Loss: -8.7939	Cost: 9.62s
Train Epoch: 445 [81920/90000 (91%)]	Loss: -8.5987	Cost: 14.14s
Train Epoch: 445 	Average Loss: -8.3382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7006

Learning rate: 5.911923104577461e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: -4.5072	Cost: 34.35s
Train Epoch: 446 [40960/90000 (45%)]	Loss: -8.9216	Cost: 9.76s
Train Epoch: 446 [81920/90000 (91%)]	Loss: -8.6879	Cost: 18.37s
Train Epoch: 446 	Average Loss: -8.4103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7912

Learning rate: 5.7009464107135434e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: -4.3487	Cost: 36.28s
Train Epoch: 447 [40960/90000 (45%)]	Loss: -8.7987	Cost: 9.86s
Train Epoch: 447 [81920/90000 (91%)]	Loss: -8.7325	Cost: 16.15s
Train Epoch: 447 	Average Loss: -8.3741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8298

Learning rate: 5.493692482019526e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: -4.2112	Cost: 37.50s
Train Epoch: 448 [40960/90000 (45%)]	Loss: -8.9079	Cost: 9.72s
Train Epoch: 448 [81920/90000 (91%)]	Loss: -8.8695	Cost: 14.12s
Train Epoch: 448 	Average Loss: -8.4280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6918

Learning rate: 5.290169500525573e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: -4.3176	Cost: 35.69s
Train Epoch: 449 [40960/90000 (45%)]	Loss: -8.7061	Cost: 10.06s
Train Epoch: 449 [81920/90000 (91%)]	Loss: -8.5832	Cost: 13.29s
Train Epoch: 449 	Average Loss: -8.4151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7383

Learning rate: 5.090385500970525e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: -4.1539	Cost: 36.38s
Train Epoch: 450 [40960/90000 (45%)]	Loss: -8.9475	Cost: 9.78s
Train Epoch: 450 [81920/90000 (91%)]	Loss: -8.7879	Cost: 14.25s
Train Epoch: 450 	Average Loss: -8.4024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8381

Learning rate: 4.894348370484643e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: -3.8874	Cost: 33.13s
Train Epoch: 451 [40960/90000 (45%)]	Loss: -8.6941	Cost: 9.68s
Train Epoch: 451 [81920/90000 (91%)]	Loss: -8.7786	Cost: 19.24s
Train Epoch: 451 	Average Loss: -8.4032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5499

Learning rate: 4.702065848278122e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: -4.4641	Cost: 36.37s
Train Epoch: 452 [40960/90000 (45%)]	Loss: -8.8978	Cost: 9.80s
Train Epoch: 452 [81920/90000 (91%)]	Loss: -8.6726	Cost: 17.23s
Train Epoch: 452 	Average Loss: -8.4554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6871

Learning rate: 4.513545525335701e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: -3.9244	Cost: 37.03s
Train Epoch: 453 [40960/90000 (45%)]	Loss: -8.9011	Cost: 9.54s
Train Epoch: 453 [81920/90000 (91%)]	Loss: -8.7109	Cost: 14.34s
Train Epoch: 453 	Average Loss: -8.4333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5685

Learning rate: 4.328794844116942e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: -4.2211	Cost: 35.61s
Train Epoch: 454 [40960/90000 (45%)]	Loss: -8.7628	Cost: 9.64s
Train Epoch: 454 [81920/90000 (91%)]	Loss: -8.8204	Cost: 14.17s
Train Epoch: 454 	Average Loss: -8.4721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7039

Learning rate: 4.147821098262413e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: -4.4683	Cost: 33.51s
Train Epoch: 455 [40960/90000 (45%)]	Loss: -8.9384	Cost: 9.98s
Train Epoch: 455 [81920/90000 (91%)]	Loss: -8.8980	Cost: 17.76s
Train Epoch: 455 	Average Loss: -8.4795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8838

Saving model as e455_model.pt & e455_waveforms_supplementary.hdf5
Learning rate: 3.97063143230569e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: -4.3490	Cost: 35.33s
Train Epoch: 456 [40960/90000 (45%)]	Loss: -8.9135	Cost: 9.69s
Train Epoch: 456 [81920/90000 (91%)]	Loss: -8.7581	Cost: 17.43s
Train Epoch: 456 	Average Loss: -8.4948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8253

Learning rate: 3.797232841391415e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: -4.4227	Cost: 37.23s
Train Epoch: 457 [40960/90000 (45%)]	Loss: -8.8283	Cost: 9.66s
Train Epoch: 457 [81920/90000 (91%)]	Loss: -8.7153	Cost: 14.84s
Train Epoch: 457 	Average Loss: -8.4658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7528

Learning rate: 3.627632170999026e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: -4.3398	Cost: 37.10s
Train Epoch: 458 [40960/90000 (45%)]	Loss: -9.0893	Cost: 9.64s
Train Epoch: 458 [81920/90000 (91%)]	Loss: -8.8599	Cost: 14.91s
Train Epoch: 458 	Average Loss: -8.4895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7538

Learning rate: 3.461836116672609e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: -4.7003	Cost: 35.85s
Train Epoch: 459 [40960/90000 (45%)]	Loss: -8.9727	Cost: 9.98s
Train Epoch: 459 [81920/90000 (91%)]	Loss: -8.7044	Cost: 15.59s
Train Epoch: 459 	Average Loss: -8.4861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6469

Learning rate: 3.2998512237564976e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: -4.4874	Cost: 34.92s
Train Epoch: 460 [40960/90000 (45%)]	Loss: -9.0944	Cost: 9.70s
Train Epoch: 460 [81920/90000 (91%)]	Loss: -8.8898	Cost: 18.75s
Train Epoch: 460 	Average Loss: -8.5113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8039

Learning rate: 3.14168388713689e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: -4.3140	Cost: 38.08s
Train Epoch: 461 [40960/90000 (45%)]	Loss: -8.8630	Cost: 9.71s
Train Epoch: 461 [81920/90000 (91%)]	Loss: -8.8293	Cost: 14.21s
Train Epoch: 461 	Average Loss: -8.5090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8350

Learning rate: 2.9873403509894177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: -4.3468	Cost: 38.08s
Train Epoch: 462 [40960/90000 (45%)]	Loss: -8.7755	Cost: 9.71s
Train Epoch: 462 [81920/90000 (91%)]	Loss: -8.7533	Cost: 13.69s
Train Epoch: 462 	Average Loss: -8.4528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6671

Learning rate: 2.8368267085326003e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: -4.5766	Cost: 36.59s
Train Epoch: 463 [40960/90000 (45%)]	Loss: -9.0215	Cost: 9.94s
Train Epoch: 463 [81920/90000 (91%)]	Loss: -8.8912	Cost: 13.21s
Train Epoch: 463 	Average Loss: -8.5338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8010

Learning rate: 2.690148901787346e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: -4.5674	Cost: 33.64s
Train Epoch: 464 [40960/90000 (45%)]	Loss: -9.0077	Cost: 9.76s
Train Epoch: 464 [81920/90000 (91%)]	Loss: -8.8225	Cost: 19.19s
Train Epoch: 464 	Average Loss: -8.5120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7869

Learning rate: 2.547312721342274e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: -4.2087	Cost: 36.69s
Train Epoch: 465 [40960/90000 (45%)]	Loss: -8.8912	Cost: 9.90s
Train Epoch: 465 [81920/90000 (91%)]	Loss: -9.0049	Cost: 15.90s
Train Epoch: 465 	Average Loss: -8.4755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6459

Learning rate: 2.4083238061252656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: -3.6865	Cost: 39.02s
Train Epoch: 466 [40960/90000 (45%)]	Loss: -8.9378	Cost: 9.60s
Train Epoch: 466 [81920/90000 (91%)]	Loss: -8.7684	Cost: 14.45s
Train Epoch: 466 	Average Loss: -8.4824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8950

Saving model as e466_model.pt & e466_waveforms_supplementary.hdf5
Learning rate: 2.27318764318065e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: -3.9738	Cost: 36.27s
Train Epoch: 467 [40960/90000 (45%)]	Loss: -9.0225	Cost: 9.59s
Train Epoch: 467 [81920/90000 (91%)]	Loss: -8.9188	Cost: 13.80s
Train Epoch: 467 	Average Loss: -8.5183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7944

Learning rate: 2.1419095674527915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: -3.9677	Cost: 34.55s
Train Epoch: 468 [40960/90000 (45%)]	Loss: -8.8769	Cost: 9.92s
Train Epoch: 468 [81920/90000 (91%)]	Loss: -8.8741	Cost: 18.90s
Train Epoch: 468 	Average Loss: -8.5204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8228

Learning rate: 2.0144947615753123e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: -4.1597	Cost: 36.78s
Train Epoch: 469 [40960/90000 (45%)]	Loss: -8.9039	Cost: 9.72s
Train Epoch: 469 [81920/90000 (91%)]	Loss: -8.9040	Cost: 16.19s
Train Epoch: 469 	Average Loss: -8.5111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7547

Learning rate: 1.890948255666601e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: -4.4669	Cost: 38.73s
Train Epoch: 470 [40960/90000 (45%)]	Loss: -8.8973	Cost: 9.58s
Train Epoch: 470 [81920/90000 (91%)]	Loss: -8.7453	Cost: 14.42s
Train Epoch: 470 	Average Loss: -8.5152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8134

Learning rate: 1.7712749271311265e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: -4.4331	Cost: 33.15s
Train Epoch: 471 [40960/90000 (45%)]	Loss: -9.0100	Cost: 9.65s
Train Epoch: 471 [81920/90000 (91%)]	Loss: -9.0573	Cost: 12.23s
Train Epoch: 471 	Average Loss: -8.5059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9439

Saving model as e471_model.pt & e471_waveforms_supplementary.hdf5
Learning rate: 1.6554795004670263e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: -4.1510	Cost: 33.45s
Train Epoch: 472 [40960/90000 (45%)]	Loss: -8.8611	Cost: 9.75s
Train Epoch: 472 [81920/90000 (91%)]	Loss: -9.0228	Cost: 18.14s
Train Epoch: 472 	Average Loss: -8.5133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9246

Learning rate: 1.5435665470794655e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: -4.4746	Cost: 36.67s
Train Epoch: 473 [40960/90000 (45%)]	Loss: -8.8831	Cost: 9.62s
Train Epoch: 473 [81920/90000 (91%)]	Loss: -8.9543	Cost: 18.08s
Train Epoch: 473 	Average Loss: -8.5501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9079

Learning rate: 1.435540485100194e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: -4.6012	Cost: 38.98s
Train Epoch: 474 [40960/90000 (45%)]	Loss: -8.9234	Cost: 9.65s
Train Epoch: 474 [81920/90000 (91%)]	Loss: -8.8748	Cost: 15.98s
Train Epoch: 474 	Average Loss: -8.5354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7319

Learning rate: 1.3314055792131951e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: -4.5553	Cost: 35.12s
Train Epoch: 475 [40960/90000 (45%)]	Loss: -9.0420	Cost: 9.62s
Train Epoch: 475 [81920/90000 (91%)]	Loss: -8.9275	Cost: 11.93s
Train Epoch: 475 	Average Loss: -8.5630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8225

Learning rate: 1.231165940486233e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: -4.1866	Cost: 35.44s
Train Epoch: 476 [40960/90000 (45%)]	Loss: -9.0147	Cost: 9.90s
Train Epoch: 476 [81920/90000 (91%)]	Loss: -9.1346	Cost: 17.63s
Train Epoch: 476 	Average Loss: -8.5617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7322

Learning rate: 1.1348255262086039e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: -4.5866	Cost: 35.57s
Train Epoch: 477 [40960/90000 (45%)]	Loss: -8.9810	Cost: 9.68s
Train Epoch: 477 [81920/90000 (91%)]	Loss: -9.0039	Cost: 19.75s
Train Epoch: 477 	Average Loss: -8.5010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9610

Saving model as e477_model.pt & e477_waveforms_supplementary.hdf5
Learning rate: 1.0423881397349057e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: -4.8937	Cost: 36.41s
Train Epoch: 478 [40960/90000 (45%)]	Loss: -9.0707	Cost: 9.76s
Train Epoch: 478 [81920/90000 (91%)]	Loss: -8.9128	Cost: 13.92s
Train Epoch: 478 	Average Loss: -8.6166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9412

Learning rate: 9.538574303348804e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: -4.5263	Cost: 36.52s
Train Epoch: 479 [40960/90000 (45%)]	Loss: -8.8904	Cost: 9.65s
Train Epoch: 479 [81920/90000 (91%)]	Loss: -9.0532	Cost: 13.86s
Train Epoch: 479 	Average Loss: -8.5686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8050

Learning rate: 8.692368930493404e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: -4.4377	Cost: 34.18s
Train Epoch: 480 [40960/90000 (45%)]	Loss: -9.0488	Cost: 10.08s
Train Epoch: 480 [81920/90000 (91%)]	Loss: -8.9874	Cost: 18.70s
Train Epoch: 480 	Average Loss: -8.5773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7773

Learning rate: 7.885298685522229e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: -4.3594	Cost: 35.83s
Train Epoch: 481 [40960/90000 (45%)]	Loss: -9.0018	Cost: 9.94s
Train Epoch: 481 [81920/90000 (91%)]	Loss: -9.0075	Cost: 15.24s
Train Epoch: 481 	Average Loss: -8.5593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6821

Learning rate: 7.117395430186407e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: -4.2107	Cost: 36.51s
Train Epoch: 482 [40960/90000 (45%)]	Loss: -8.9902	Cost: 9.62s
Train Epoch: 482 [81920/90000 (91%)]	Loss: -8.8174	Cost: 13.41s
Train Epoch: 482 	Average Loss: -8.5497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6488

Learning rate: 6.3886894799916e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: -4.0684	Cost: 36.86s
Train Epoch: 483 [40960/90000 (45%)]	Loss: -9.0442	Cost: 10.15s
Train Epoch: 483 [81920/90000 (91%)]	Loss: -8.6798	Cost: 12.03s
Train Epoch: 483 	Average Loss: -8.5495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8861

Learning rate: 5.699209603001072e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: -4.3997	Cost: 35.46s
Train Epoch: 484 [40960/90000 (45%)]	Loss: -9.0228	Cost: 9.66s
Train Epoch: 484 [81920/90000 (91%)]	Loss: -8.8277	Cost: 15.87s
Train Epoch: 484 	Average Loss: -8.6080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8416

Learning rate: 5.048983018699823e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: -4.3629	Cost: 33.84s
Train Epoch: 485 [40960/90000 (45%)]	Loss: -9.0029	Cost: 9.71s
Train Epoch: 485 [81920/90000 (91%)]	Loss: -8.9079	Cost: 18.68s
Train Epoch: 485 	Average Loss: -8.5283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8188

Learning rate: 4.43803539692e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: -4.3997	Cost: 37.81s
Train Epoch: 486 [40960/90000 (45%)]	Loss: -8.8796	Cost: 9.81s
Train Epoch: 486 [81920/90000 (91%)]	Loss: -9.0337	Cost: 13.78s
Train Epoch: 486 	Average Loss: -8.5570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8551

Learning rate: 3.8663908568274915e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: -3.8885	Cost: 37.56s
Train Epoch: 487 [40960/90000 (45%)]	Loss: -8.8675	Cost: 9.61s
Train Epoch: 487 [81920/90000 (91%)]	Loss: -8.7941	Cost: 13.79s
Train Epoch: 487 	Average Loss: -8.5235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7372

Learning rate: 3.334071965970128e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: -4.4599	Cost: 33.36s
Train Epoch: 488 [40960/90000 (45%)]	Loss: -9.0896	Cost: 9.59s
Train Epoch: 488 [81920/90000 (91%)]	Loss: -8.8552	Cost: 12.41s
Train Epoch: 488 	Average Loss: -8.5714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8077

Learning rate: 2.8410997393860634e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: -4.4968	Cost: 34.79s
Train Epoch: 489 [40960/90000 (45%)]	Loss: -9.1689	Cost: 9.79s
Train Epoch: 489 [81920/90000 (91%)]	Loss: -8.8484	Cost: 18.33s
Train Epoch: 489 	Average Loss: -8.5948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7594

Learning rate: 2.3874936387747717e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: -4.2984	Cost: 35.70s
Train Epoch: 490 [40960/90000 (45%)]	Loss: -8.8108	Cost: 9.65s
Train Epoch: 490 [81920/90000 (91%)]	Loss: -8.9276	Cost: 16.60s
Train Epoch: 490 	Average Loss: -8.5613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7448

Learning rate: 1.9732715717284395e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: -4.2606	Cost: 37.30s
Train Epoch: 491 [40960/90000 (45%)]	Loss: -9.0427	Cost: 9.65s
Train Epoch: 491 [81920/90000 (91%)]	Loss: -8.9306	Cost: 14.85s
Train Epoch: 491 	Average Loss: -8.5968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8161

Learning rate: 1.5984498910249766e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: -4.2896	Cost: 38.41s
Train Epoch: 492 [40960/90000 (45%)]	Loss: -8.9721	Cost: 9.54s
Train Epoch: 492 [81920/90000 (91%)]	Loss: -8.8209	Cost: 14.44s
Train Epoch: 492 	Average Loss: -8.5777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8370

Learning rate: 1.2630433939825314e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: -4.0041	Cost: 36.23s
Train Epoch: 493 [40960/90000 (45%)]	Loss: -9.0908	Cost: 9.61s
Train Epoch: 493 [81920/90000 (91%)]	Loss: -8.9265	Cost: 15.84s
Train Epoch: 493 	Average Loss: -8.5793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7835

Learning rate: 9.670653218752925e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: -4.7039	Cost: 34.87s
Train Epoch: 494 [40960/90000 (45%)]	Loss: -8.9957	Cost: 9.70s
Train Epoch: 494 [81920/90000 (91%)]	Loss: -9.0343	Cost: 19.49s
Train Epoch: 494 	Average Loss: -8.6281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7476

Learning rate: 7.105273594107945e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: -4.1024	Cost: 35.94s
Train Epoch: 495 [40960/90000 (45%)]	Loss: -8.9418	Cost: 9.86s
Train Epoch: 495 [81920/90000 (91%)]	Loss: -9.0172	Cost: 14.08s
Train Epoch: 495 	Average Loss: -8.5909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7083

Learning rate: 4.9343963426839946e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: -4.4917	Cost: 38.54s
Train Epoch: 496 [40960/90000 (45%)]	Loss: -9.1158	Cost: 9.85s
Train Epoch: 496 [81920/90000 (91%)]	Loss: -9.0296	Cost: 13.88s
Train Epoch: 496 	Average Loss: -8.6214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7858

Learning rate: 3.158107167000598e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: -4.5077	Cost: 36.74s
Train Epoch: 497 [40960/90000 (45%)]	Loss: -8.9008	Cost: 9.66s
Train Epoch: 497 [81920/90000 (91%)]	Loss: -8.8097	Cost: 13.79s
Train Epoch: 497 	Average Loss: -8.5924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8000

Learning rate: 1.776476191910346e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: -4.6482	Cost: 32.48s
Train Epoch: 498 [40960/90000 (45%)]	Loss: -9.0023	Cost: 9.71s
Train Epoch: 498 [81920/90000 (91%)]	Loss: -9.0160	Cost: 19.76s
Train Epoch: 498 	Average Loss: -8.5644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7277

Learning rate: 7.895579618388819e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: -4.1034	Cost: 36.90s
Train Epoch: 499 [40960/90000 (45%)]	Loss: -9.0307	Cost: 9.71s
Train Epoch: 499 [81920/90000 (91%)]	Loss: -8.9850	Cost: 16.11s
Train Epoch: 499 	Average Loss: -8.5677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6958

Learning rate: 1.973914386288465e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: -4.3528	Cost: 35.41s
Train Epoch: 500 [40960/90000 (45%)]	Loss: -8.8311	Cost: 9.96s
Train Epoch: 500 [81920/90000 (91%)]	Loss: -8.8920	Cost: 13.49s
Train Epoch: 500 	Average Loss: -8.5670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9258

Stopping timer.
Training time (including validation): 111549.9510064125 seconds
Saving model
Transfer learning by starting with alpha=0.8!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 18.8557	Cost: 33.82s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 9.0804	Cost: 9.99s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 8.0297	Cost: 12.29s
Train Epoch: 1 	Average Loss: 9.6699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8813

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.0001999980260856137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 7.8020	Cost: 32.73s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 6.2867	Cost: 9.83s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 5.2844	Cost: 18.25s
Train Epoch: 2 	Average Loss: 6.3027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1682

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 5.3399	Cost: 35.49s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 4.2261	Cost: 10.22s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 3.5767	Cost: 17.20s
Train Epoch: 3 	Average Loss: 4.2882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4934

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 3.6572	Cost: 38.16s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 3.1521	Cost: 10.03s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 2.5355	Cost: 13.58s
Train Epoch: 4 	Average Loss: 3.0311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6738

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892833004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 2.6953	Cost: 36.83s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 1.9435	Cost: 9.64s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 1.7861	Cost: 13.25s
Train Epoch: 5 	Average Loss: 2.0173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9132

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 1.7833	Cost: 32.63s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 1.1782	Cost: 9.72s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 0.8901	Cost: 19.34s
Train Epoch: 6 	Average Loss: 1.2199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5020

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 1.4113	Cost: 36.96s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 0.6047	Cost: 9.92s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 0.3981	Cost: 14.74s
Train Epoch: 7 	Average Loss: 0.6905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0006

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 0.7687	Cost: 35.53s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 0.2796	Cost: 9.70s
Train Epoch: 8 [81920/90000 (91%)]	Loss: -0.1230	Cost: 13.57s
Train Epoch: 8 	Average Loss: 0.1992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7437

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019987369566060184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 0.4020	Cost: 36.78s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 0.3366	Cost: 9.53s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 0.1455	Cost: 13.30s
Train Epoch: 9 	Average Loss: 0.2797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8460

Learning rate: 0.00019984015501089758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 0.6760	Cost: 33.77s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 0.0461	Cost: 10.00s
Train Epoch: 10 [81920/90000 (91%)]	Loss: -0.0748	Cost: 19.63s
Train Epoch: 10 	Average Loss: 0.0698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6474

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 0.6804	Cost: 36.81s
Train Epoch: 11 [40960/90000 (45%)]	Loss: -0.2591	Cost: 9.77s
Train Epoch: 11 [81920/90000 (91%)]	Loss: -0.2012	Cost: 14.53s
Train Epoch: 11 	Average Loss: -0.1398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5337

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019976125063612257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 0.4795	Cost: 38.49s
Train Epoch: 12 [40960/90000 (45%)]	Loss: -0.3935	Cost: 9.70s
Train Epoch: 12 [81920/90000 (91%)]	Loss: -0.4343	Cost: 13.77s
Train Epoch: 12 	Average Loss: -0.3368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2662

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019971589002606144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 0.3667	Cost: 36.08s
Train Epoch: 13 [40960/90000 (45%)]	Loss: -0.2644	Cost: 9.70s
Train Epoch: 13 [81920/90000 (91%)]	Loss: -0.5253	Cost: 13.93s
Train Epoch: 13 	Average Loss: -0.3728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3074

Learning rate: 0.00019966659280340303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 0.2791	Cost: 33.36s
Train Epoch: 14 [40960/90000 (45%)]	Loss: -0.5326	Cost: 9.76s
Train Epoch: 14 [81920/90000 (91%)]	Loss: -0.8140	Cost: 19.61s
Train Epoch: 14 	Average Loss: -0.5302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1761

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001996133609143173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: -0.2133	Cost: 37.24s
Train Epoch: 15 [40960/90000 (45%)]	Loss: -0.5244	Cost: 9.76s
Train Epoch: 15 [81920/90000 (91%)]	Loss: -0.5824	Cost: 13.81s
Train Epoch: 15 	Average Loss: -0.5728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2422

Learning rate: 0.00019955619646030805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 0.1581	Cost: 34.57s
Train Epoch: 16 [40960/90000 (45%)]	Loss: -0.7602	Cost: 9.53s
Train Epoch: 16 [81920/90000 (91%)]	Loss: -0.7717	Cost: 13.88s
Train Epoch: 16 	Average Loss: -0.6851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1373

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.00019949510169813006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: -0.0507	Cost: 36.45s
Train Epoch: 17 [40960/90000 (45%)]	Loss: -0.6890	Cost: 9.70s
Train Epoch: 17 [81920/90000 (91%)]	Loss: -0.6819	Cost: 12.92s
Train Epoch: 17 	Average Loss: -0.7595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1745

Learning rate: 0.00019943007903969992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: -0.0229	Cost: 32.70s
Train Epoch: 18 [40960/90000 (45%)]	Loss: -0.7582	Cost: 9.89s
Train Epoch: 18 [81920/90000 (91%)]	Loss: -0.9764	Cost: 19.22s
Train Epoch: 18 	Average Loss: -0.8232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0382

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.00019936113105200088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 0.2978	Cost: 35.77s
Train Epoch: 19 [40960/90000 (45%)]	Loss: -0.5961	Cost: 9.73s
Train Epoch: 19 [81920/90000 (91%)]	Loss: -0.8158	Cost: 14.56s
Train Epoch: 19 	Average Loss: -0.7368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0469

Learning rate: 0.0001992882604569814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: -0.1882	Cost: 36.37s
Train Epoch: 20 [40960/90000 (45%)]	Loss: -0.9608	Cost: 9.70s
Train Epoch: 20 [81920/90000 (91%)]	Loss: -0.9021	Cost: 14.73s
Train Epoch: 20 	Average Loss: -0.9742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7926

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019921147013144782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: -0.4081	Cost: 36.42s
Train Epoch: 21 [40960/90000 (45%)]	Loss: -1.1329	Cost: 9.55s
Train Epoch: 21 [81920/90000 (91%)]	Loss: -1.0932	Cost: 13.68s
Train Epoch: 21 	Average Loss: -1.1021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8185

Learning rate: 0.00019913076310695068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: -0.1135	Cost: 33.59s
Train Epoch: 22 [40960/90000 (45%)]	Loss: -1.1192	Cost: 9.98s
Train Epoch: 22 [81920/90000 (91%)]	Loss: -1.0409	Cost: 18.66s
Train Epoch: 22 	Average Loss: -1.0460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8808

Learning rate: 0.00019904614256966512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: -0.5182	Cost: 35.94s
Train Epoch: 23 [40960/90000 (45%)]	Loss: -1.2128	Cost: 10.14s
Train Epoch: 23 [81920/90000 (91%)]	Loss: -1.0709	Cost: 16.17s
Train Epoch: 23 	Average Loss: -1.0608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8040

Learning rate: 0.0001989576118602651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: -0.1800	Cost: 38.42s
Train Epoch: 24 [40960/90000 (45%)]	Loss: -1.3842	Cost: 9.63s
Train Epoch: 24 [81920/90000 (91%)]	Loss: -1.4453	Cost: 15.44s
Train Epoch: 24 	Average Loss: -1.2028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6733

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.0001988651744737914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: -0.1574	Cost: 36.63s
Train Epoch: 25 [40960/90000 (45%)]	Loss: -1.3429	Cost: 9.57s
Train Epoch: 25 [81920/90000 (91%)]	Loss: -1.5470	Cost: 13.07s
Train Epoch: 25 	Average Loss: -1.3174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4476

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.0001987688340595138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: -0.4880	Cost: 33.90s
Train Epoch: 26 [40960/90000 (45%)]	Loss: -1.4173	Cost: 9.75s
Train Epoch: 26 [81920/90000 (91%)]	Loss: -1.4044	Cost: 18.39s
Train Epoch: 26 	Average Loss: -1.3795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8751

Learning rate: 0.00019866859442078683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: -0.3528	Cost: 39.59s
Train Epoch: 27 [40960/90000 (45%)]	Loss: -1.2375	Cost: 9.63s
Train Epoch: 27 [81920/90000 (91%)]	Loss: -1.2633	Cost: 14.29s
Train Epoch: 27 	Average Loss: -1.2228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9959

Learning rate: 0.00019856445951489985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: -0.2122	Cost: 37.18s
Train Epoch: 28 [40960/90000 (45%)]	Loss: -1.2719	Cost: 9.54s
Train Epoch: 28 [81920/90000 (91%)]	Loss: -1.1968	Cost: 13.05s
Train Epoch: 28 	Average Loss: -1.1798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0554

Learning rate: 0.0001984564334529206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 0.1269	Cost: 36.13s
Train Epoch: 29 [40960/90000 (45%)]	Loss: -1.3513	Cost: 9.50s
Train Epoch: 29 [81920/90000 (91%)]	Loss: -1.4061	Cost: 16.55s
Train Epoch: 29 	Average Loss: -1.1729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6169

Learning rate: 0.00019834452049953302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: -0.2994	Cost: 34.58s
Train Epoch: 30 [40960/90000 (45%)]	Loss: -1.5220	Cost: 9.68s
Train Epoch: 30 [81920/90000 (91%)]	Loss: -1.5746	Cost: 17.81s
Train Epoch: 30 	Average Loss: -1.4913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8069

Learning rate: 0.00019822872507286893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: -0.3389	Cost: 36.37s
Train Epoch: 31 [40960/90000 (45%)]	Loss: -1.7621	Cost: 9.64s
Train Epoch: 31 [81920/90000 (91%)]	Loss: -1.6165	Cost: 14.98s
Train Epoch: 31 	Average Loss: -1.6047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6464

Learning rate: 0.00019810905174433345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: -0.4943	Cost: 35.40s
Train Epoch: 32 [40960/90000 (45%)]	Loss: -1.6908	Cost: 9.86s
Train Epoch: 32 [81920/90000 (91%)]	Loss: -1.6048	Cost: 12.46s
Train Epoch: 32 	Average Loss: -1.5915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5036

Learning rate: 0.00019798550523842474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: -0.8690	Cost: 36.26s
Train Epoch: 33 [40960/90000 (45%)]	Loss: -1.6713	Cost: 9.62s
Train Epoch: 33 [81920/90000 (91%)]	Loss: -1.7590	Cost: 13.49s
Train Epoch: 33 	Average Loss: -1.6503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5271

Learning rate: 0.00019785809043254728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: -0.4456	Cost: 33.72s
Train Epoch: 34 [40960/90000 (45%)]	Loss: -1.9162	Cost: 9.89s
Train Epoch: 34 [81920/90000 (91%)]	Loss: -1.7253	Cost: 19.07s
Train Epoch: 34 	Average Loss: -1.6523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8368

Learning rate: 0.00019772681235681944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: -0.5874	Cost: 36.66s
Train Epoch: 35 [40960/90000 (45%)]	Loss: -1.7918	Cost: 9.78s
Train Epoch: 35 [81920/90000 (91%)]	Loss: -1.7785	Cost: 15.94s
Train Epoch: 35 	Average Loss: -1.6878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6691

Learning rate: 0.00019759167619387482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: -0.7558	Cost: 36.45s
Train Epoch: 36 [40960/90000 (45%)]	Loss: -1.8536	Cost: 9.63s
Train Epoch: 36 [81920/90000 (91%)]	Loss: -2.0071	Cost: 15.62s
Train Epoch: 36 	Average Loss: -1.6933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6006

Learning rate: 0.0001974526872786578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: -0.6908	Cost: 36.26s
Train Epoch: 37 [40960/90000 (45%)]	Loss: -1.9500	Cost: 9.55s
Train Epoch: 37 [81920/90000 (91%)]	Loss: -1.7292	Cost: 13.85s
Train Epoch: 37 	Average Loss: -1.7568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5871

Learning rate: 0.00019730985109821272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: -0.5152	Cost: 34.24s
Train Epoch: 38 [40960/90000 (45%)]	Loss: -1.8605	Cost: 10.20s
Train Epoch: 38 [81920/90000 (91%)]	Loss: -1.8206	Cost: 17.44s
Train Epoch: 38 	Average Loss: -1.7366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5319

Learning rate: 0.00019716317329146745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: -0.5615	Cost: 36.30s
Train Epoch: 39 [40960/90000 (45%)]	Loss: -1.7496	Cost: 9.66s
Train Epoch: 39 [81920/90000 (91%)]	Loss: -1.9484	Cost: 17.90s
Train Epoch: 39 	Average Loss: -1.7871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6787

Learning rate: 0.00019701265964901062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: -0.4154	Cost: 37.77s
Train Epoch: 40 [40960/90000 (45%)]	Loss: -1.8229	Cost: 9.64s
Train Epoch: 40 [81920/90000 (91%)]	Loss: -1.9020	Cost: 14.69s
Train Epoch: 40 	Average Loss: -1.7599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6169

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: -0.7941	Cost: 34.35s
Train Epoch: 41 [40960/90000 (45%)]	Loss: -2.0660	Cost: 9.60s
Train Epoch: 41 [81920/90000 (91%)]	Loss: -2.0970	Cost: 13.17s
Train Epoch: 41 	Average Loss: -1.9680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4283

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019670014877624353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: -1.0838	Cost: 34.73s
Train Epoch: 42 [40960/90000 (45%)]	Loss: -1.9155	Cost: 9.97s
Train Epoch: 42 [81920/90000 (91%)]	Loss: -2.0707	Cost: 18.47s
Train Epoch: 42 	Average Loss: -1.9759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4663

Learning rate: 0.0001965381638833274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: -0.8351	Cost: 35.59s
Train Epoch: 43 [40960/90000 (45%)]	Loss: -2.0347	Cost: 9.70s
Train Epoch: 43 [81920/90000 (91%)]	Loss: -2.1157	Cost: 17.02s
Train Epoch: 43 	Average Loss: -1.9599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6455

Learning rate: 0.000196372367829001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: -0.5710	Cost: 36.16s
Train Epoch: 44 [40960/90000 (45%)]	Loss: -2.1177	Cost: 9.71s
Train Epoch: 44 [81920/90000 (91%)]	Loss: -2.2040	Cost: 14.58s
Train Epoch: 44 	Average Loss: -1.8996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6003

Learning rate: 0.00019620276715860861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: -0.6067	Cost: 36.79s
Train Epoch: 45 [40960/90000 (45%)]	Loss: -2.2734	Cost: 9.65s
Train Epoch: 45 [81920/90000 (91%)]	Loss: -2.0402	Cost: 13.75s
Train Epoch: 45 	Average Loss: -2.0362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6784

Learning rate: 0.00019602936856769434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: -0.5816	Cost: 34.21s
Train Epoch: 46 [40960/90000 (45%)]	Loss: -1.9012	Cost: 9.54s
Train Epoch: 46 [81920/90000 (91%)]	Loss: -1.6359	Cost: 19.53s
Train Epoch: 46 	Average Loss: -1.7005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8900

Learning rate: 0.00019585217890173763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: -0.1039	Cost: 35.74s
Train Epoch: 47 [40960/90000 (45%)]	Loss: -1.9173	Cost: 9.71s
Train Epoch: 47 [81920/90000 (91%)]	Loss: -1.9299	Cost: 16.48s
Train Epoch: 47 	Average Loss: -1.6792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6573

Learning rate: 0.0001956712051558831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: -0.3952	Cost: 38.36s
Train Epoch: 48 [40960/90000 (45%)]	Loss: -2.0631	Cost: 9.67s
Train Epoch: 48 [81920/90000 (91%)]	Loss: -1.9965	Cost: 15.60s
Train Epoch: 48 	Average Loss: -1.9192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5719

Learning rate: 0.00019548645447466434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: -0.6571	Cost: 36.17s
Train Epoch: 49 [40960/90000 (45%)]	Loss: -2.3433	Cost: 9.60s
Train Epoch: 49 [81920/90000 (91%)]	Loss: -2.1259	Cost: 14.66s
Train Epoch: 49 	Average Loss: -2.0911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2394

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019529793415172192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: -0.9188	Cost: 34.56s
Train Epoch: 50 [40960/90000 (45%)]	Loss: -2.3332	Cost: 9.97s
Train Epoch: 50 [81920/90000 (91%)]	Loss: -1.9660	Cost: 16.99s
Train Epoch: 50 	Average Loss: -2.2106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3076

Learning rate: 0.0001951056516295154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: -0.7186	Cost: 36.04s
Train Epoch: 51 [40960/90000 (45%)]	Loss: -2.3193	Cost: 9.76s
Train Epoch: 51 [81920/90000 (91%)]	Loss: -2.4722	Cost: 18.14s
Train Epoch: 51 	Average Loss: -2.1945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4084

Learning rate: 0.0001949096144990295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: -0.9462	Cost: 36.49s
Train Epoch: 52 [40960/90000 (45%)]	Loss: -1.9030	Cost: 9.75s
Train Epoch: 52 [81920/90000 (91%)]	Loss: -2.1802	Cost: 13.20s
Train Epoch: 52 	Average Loss: -2.0183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3365

Learning rate: 0.00019470983049947442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: -0.9498	Cost: 38.10s
Train Epoch: 53 [40960/90000 (45%)]	Loss: -2.1655	Cost: 9.55s
Train Epoch: 53 [81920/90000 (91%)]	Loss: -2.3852	Cost: 13.26s
Train Epoch: 53 	Average Loss: -2.1922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2779

Learning rate: 0.00019450630751798048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: -0.7444	Cost: 36.73s
Train Epoch: 54 [40960/90000 (45%)]	Loss: -2.6176	Cost: 9.53s
Train Epoch: 54 [81920/90000 (91%)]	Loss: -2.6007	Cost: 16.14s
Train Epoch: 54 	Average Loss: -2.3067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3220

Learning rate: 0.00019429905358928646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: -1.1310	Cost: 35.11s
Train Epoch: 55 [40960/90000 (45%)]	Loss: -2.4768	Cost: 9.73s
Train Epoch: 55 [81920/90000 (91%)]	Loss: -2.4460	Cost: 17.97s
Train Epoch: 55 	Average Loss: -2.3765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3660

Learning rate: 0.00019408807689542257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: -0.6562	Cost: 37.37s
Train Epoch: 56 [40960/90000 (45%)]	Loss: -2.4836	Cost: 9.66s
Train Epoch: 56 [81920/90000 (91%)]	Loss: -2.5612	Cost: 14.90s
Train Epoch: 56 	Average Loss: -2.3867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3645

Learning rate: 0.00019387338576538744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: -0.7460	Cost: 35.29s
Train Epoch: 57 [40960/90000 (45%)]	Loss: -2.5255	Cost: 9.76s
Train Epoch: 57 [81920/90000 (91%)]	Loss: -2.5372	Cost: 14.11s
Train Epoch: 57 	Average Loss: -2.3368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2324

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 0.00019365498867481926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: -0.7761	Cost: 36.98s
Train Epoch: 58 [40960/90000 (45%)]	Loss: -2.4708	Cost: 9.58s
Train Epoch: 58 [81920/90000 (91%)]	Loss: -2.6602	Cost: 13.61s
Train Epoch: 58 	Average Loss: -2.3862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2616

Learning rate: 0.00019343289424566122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: -0.7719	Cost: 33.76s
Train Epoch: 59 [40960/90000 (45%)]	Loss: -2.4590	Cost: 9.69s
Train Epoch: 59 [81920/90000 (91%)]	Loss: -2.7240	Cost: 19.74s
Train Epoch: 59 	Average Loss: -2.4979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2059

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00019320711124582108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: -0.9651	Cost: 35.26s
Train Epoch: 60 [40960/90000 (45%)]	Loss: -2.6184	Cost: 9.84s
Train Epoch: 60 [81920/90000 (91%)]	Loss: -2.6266	Cost: 16.09s
Train Epoch: 60 	Average Loss: -2.5082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2690

Learning rate: 0.00019297764858882514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: -1.2334	Cost: 36.59s
Train Epoch: 61 [40960/90000 (45%)]	Loss: -2.7340	Cost: 9.64s
Train Epoch: 61 [81920/90000 (91%)]	Loss: -2.4776	Cost: 13.88s
Train Epoch: 61 	Average Loss: -2.5481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2983

Learning rate: 0.00019274451533346612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: -0.8192	Cost: 38.64s
Train Epoch: 62 [40960/90000 (45%)]	Loss: -2.6242	Cost: 9.55s
Train Epoch: 62 [81920/90000 (91%)]	Loss: -2.7641	Cost: 13.28s
Train Epoch: 62 	Average Loss: -2.4309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2638

Learning rate: 0.00019250772068344577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: -0.8924	Cost: 35.11s
Train Epoch: 63 [40960/90000 (45%)]	Loss: -2.6269	Cost: 9.71s
Train Epoch: 63 [81920/90000 (91%)]	Loss: -2.4476	Cost: 18.28s
Train Epoch: 63 	Average Loss: -2.4923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2254

Learning rate: 0.00019226727398701147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: -0.9511	Cost: 35.55s
Train Epoch: 64 [40960/90000 (45%)]	Loss: -2.5634	Cost: 9.79s
Train Epoch: 64 [81920/90000 (91%)]	Loss: -2.5678	Cost: 17.52s
Train Epoch: 64 	Average Loss: -2.4868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1962

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00019202318473658702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: -1.0123	Cost: 36.23s
Train Epoch: 65 [40960/90000 (45%)]	Loss: -2.5157	Cost: 9.69s
Train Epoch: 65 [81920/90000 (91%)]	Loss: -2.6641	Cost: 14.58s
Train Epoch: 65 	Average Loss: -2.5936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1417

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 0.0001917754625683981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: -0.9923	Cost: 36.01s
Train Epoch: 66 [40960/90000 (45%)]	Loss: -2.8331	Cost: 9.56s
Train Epoch: 66 [81920/90000 (91%)]	Loss: -2.7329	Cost: 13.32s
Train Epoch: 66 	Average Loss: -2.6015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1113

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.00019152411726209174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: -0.9020	Cost: 33.64s
Train Epoch: 67 [40960/90000 (45%)]	Loss: -2.7594	Cost: 9.82s
Train Epoch: 67 [81920/90000 (91%)]	Loss: -2.5660	Cost: 19.23s
Train Epoch: 67 	Average Loss: -2.6169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1373

Learning rate: 0.00019126915874035028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: -1.0918	Cost: 37.63s
Train Epoch: 68 [40960/90000 (45%)]	Loss: -2.6516	Cost: 9.71s
Train Epoch: 68 [81920/90000 (91%)]	Loss: -2.8576	Cost: 16.01s
Train Epoch: 68 	Average Loss: -2.5715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0975

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 0.00019101059706849957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: -1.1044	Cost: 35.57s
Train Epoch: 69 [40960/90000 (45%)]	Loss: -3.0139	Cost: 9.65s
Train Epoch: 69 [81920/90000 (91%)]	Loss: -2.9079	Cost: 14.82s
Train Epoch: 69 	Average Loss: -2.7519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0749

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Learning rate: 0.0001907484424541117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: -0.8296	Cost: 34.71s
Train Epoch: 70 [40960/90000 (45%)]	Loss: -2.9344	Cost: 9.89s
Train Epoch: 70 [81920/90000 (91%)]	Loss: -2.5747	Cost: 13.88s
Train Epoch: 70 	Average Loss: -2.6599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0788

Learning rate: 0.00019048270524660196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: -1.1444	Cost: 34.95s
Train Epoch: 71 [40960/90000 (45%)]	Loss: -2.8055	Cost: 10.14s
Train Epoch: 71 [81920/90000 (91%)]	Loss: -2.7558	Cost: 18.77s
Train Epoch: 71 	Average Loss: -2.7075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2258

Learning rate: 0.00019021339593682028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: -0.9559	Cost: 36.26s
Train Epoch: 72 [40960/90000 (45%)]	Loss: -3.0242	Cost: 9.79s
Train Epoch: 72 [81920/90000 (91%)]	Loss: -2.5146	Cost: 18.61s
Train Epoch: 72 	Average Loss: -2.6984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4437

Learning rate: 0.0001899405251566371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: -0.8628	Cost: 38.67s
Train Epoch: 73 [40960/90000 (45%)]	Loss: -2.6860	Cost: 9.51s
Train Epoch: 73 [81920/90000 (91%)]	Loss: -2.7683	Cost: 15.94s
Train Epoch: 73 	Average Loss: -2.5850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1724

Learning rate: 0.0001896641036785236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: -0.6476	Cost: 34.79s
Train Epoch: 74 [40960/90000 (45%)]	Loss: -2.8803	Cost: 10.21s
Train Epoch: 74 [81920/90000 (91%)]	Loss: -2.9959	Cost: 13.05s
Train Epoch: 74 	Average Loss: -2.7795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0613

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.00018938414241512636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: -1.1784	Cost: 33.94s
Train Epoch: 75 [40960/90000 (45%)]	Loss: -3.0989	Cost: 9.90s
Train Epoch: 75 [81920/90000 (91%)]	Loss: -3.0584	Cost: 19.58s
Train Epoch: 75 	Average Loss: -2.8885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0727

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 0.00018910065241883677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: -1.1412	Cost: 36.19s
Train Epoch: 76 [40960/90000 (45%)]	Loss: -2.8952	Cost: 9.85s
Train Epoch: 76 [81920/90000 (91%)]	Loss: -3.1163	Cost: 18.13s
Train Epoch: 76 	Average Loss: -2.7831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0906

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00018881364488135445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: -0.9957	Cost: 39.36s
Train Epoch: 77 [40960/90000 (45%)]	Loss: -3.1167	Cost: 9.64s
Train Epoch: 77 [81920/90000 (91%)]	Loss: -2.9476	Cost: 14.15s
Train Epoch: 77 	Average Loss: -2.8816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0580

Learning rate: 0.00018852313113324552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: -0.9868	Cost: 37.74s
Train Epoch: 78 [40960/90000 (45%)]	Loss: -2.9707	Cost: 9.67s
Train Epoch: 78 [81920/90000 (91%)]	Loss: -2.7661	Cost: 13.67s
Train Epoch: 78 	Average Loss: -2.8034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0220

Learning rate: 0.00018822912264349534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: -0.8850	Cost: 33.76s
Train Epoch: 79 [40960/90000 (45%)]	Loss: -3.0984	Cost: 9.74s
Train Epoch: 79 [81920/90000 (91%)]	Loss: -3.0470	Cost: 19.13s
Train Epoch: 79 	Average Loss: -2.7759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1104

Learning rate: 0.00018793163101905563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: -1.3698	Cost: 40.08s
Train Epoch: 80 [40960/90000 (45%)]	Loss: -2.9291	Cost: 9.64s
Train Epoch: 80 [81920/90000 (91%)]	Loss: -2.9228	Cost: 13.96s
Train Epoch: 80 	Average Loss: -2.6776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1995

Learning rate: 0.00018763066800438636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: -0.7925	Cost: 35.85s
Train Epoch: 81 [40960/90000 (45%)]	Loss: -2.8710	Cost: 9.56s
Train Epoch: 81 [81920/90000 (91%)]	Loss: -2.9797	Cost: 12.82s
Train Epoch: 81 	Average Loss: -2.7447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0856

Learning rate: 0.000187326245480992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: -1.1063	Cost: 34.42s
Train Epoch: 82 [40960/90000 (45%)]	Loss: -3.1852	Cost: 9.68s
Train Epoch: 82 [81920/90000 (91%)]	Loss: -3.1869	Cost: 14.94s
Train Epoch: 82 	Average Loss: -2.9862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0532

Learning rate: 0.00018701837546695256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: -1.0120	Cost: 35.27s
Train Epoch: 83 [40960/90000 (45%)]	Loss: -3.0319	Cost: 10.00s
Train Epoch: 83 [81920/90000 (91%)]	Loss: -2.9791	Cost: 18.75s
Train Epoch: 83 	Average Loss: -2.9984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0759

Learning rate: 0.00018670707011644898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: -0.9632	Cost: 38.53s
Train Epoch: 84 [40960/90000 (45%)]	Loss: -3.3174	Cost: 9.85s
Train Epoch: 84 [81920/90000 (91%)]	Loss: -3.3828	Cost: 17.60s
Train Epoch: 84 	Average Loss: -2.9983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1014

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 0.0001863923417192835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: -1.2147	Cost: 38.89s
Train Epoch: 85 [40960/90000 (45%)]	Loss: -3.4673	Cost: 9.65s
Train Epoch: 85 [81920/90000 (91%)]	Loss: -3.4377	Cost: 13.69s
Train Epoch: 85 	Average Loss: -3.1403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0158

Learning rate: 0.00018607420270039436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: -0.9062	Cost: 36.49s
Train Epoch: 86 [40960/90000 (45%)]	Loss: -3.3162	Cost: 9.74s
Train Epoch: 86 [81920/90000 (91%)]	Loss: -3.2097	Cost: 13.48s
Train Epoch: 86 	Average Loss: -3.0547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1051

Learning rate: 0.00018575266561936523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: -1.2314	Cost: 33.52s
Train Epoch: 87 [40960/90000 (45%)]	Loss: -3.1858	Cost: 9.70s
Train Epoch: 87 [81920/90000 (91%)]	Loss: -3.3071	Cost: 19.19s
Train Epoch: 87 	Average Loss: -3.0327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0545

Learning rate: 0.0001854277431699295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: -1.0563	Cost: 37.44s
Train Epoch: 88 [40960/90000 (45%)]	Loss: -3.4373	Cost: 9.70s
Train Epoch: 88 [81920/90000 (91%)]	Loss: -3.4261	Cost: 16.31s
Train Epoch: 88 	Average Loss: -3.1928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1734

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 0.0001850994481794692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: -1.3898	Cost: 39.43s
Train Epoch: 89 [40960/90000 (45%)]	Loss: -3.6554	Cost: 9.68s
Train Epoch: 89 [81920/90000 (91%)]	Loss: -3.3110	Cost: 13.91s
Train Epoch: 89 	Average Loss: -3.2279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0985

Learning rate: 0.0001847677936085083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: -1.1330	Cost: 38.22s
Train Epoch: 90 [40960/90000 (45%)]	Loss: -3.3562	Cost: 9.70s
Train Epoch: 90 [81920/90000 (91%)]	Loss: -3.5419	Cost: 13.49s
Train Epoch: 90 	Average Loss: -3.2107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0010

Learning rate: 0.00018443279255020146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: -1.3249	Cost: 33.42s
Train Epoch: 91 [40960/90000 (45%)]	Loss: -3.3942	Cost: 9.71s
Train Epoch: 91 [81920/90000 (91%)]	Loss: -3.4363	Cost: 19.68s
Train Epoch: 91 	Average Loss: -3.2665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2025

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Learning rate: 0.00018409445822981687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: -1.2003	Cost: 35.37s
Train Epoch: 92 [40960/90000 (45%)]	Loss: -3.4702	Cost: 9.72s
Train Epoch: 92 [81920/90000 (91%)]	Loss: -3.5916	Cost: 14.32s
Train Epoch: 92 	Average Loss: -3.2429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2563

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 0.00018375280400421414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: -1.3577	Cost: 35.89s
Train Epoch: 93 [40960/90000 (45%)]	Loss: -3.6785	Cost: 9.70s
Train Epoch: 93 [81920/90000 (91%)]	Loss: -3.5320	Cost: 13.88s
Train Epoch: 93 	Average Loss: -3.3134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2053

Learning rate: 0.00018340784336131708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: -1.6548	Cost: 35.89s
Train Epoch: 94 [40960/90000 (45%)]	Loss: -3.5708	Cost: 9.57s
Train Epoch: 94 [81920/90000 (91%)]	Loss: -3.5798	Cost: 13.32s
Train Epoch: 94 	Average Loss: -3.3583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1297

Learning rate: 0.00018305958991958124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: -1.1514	Cost: 34.75s
Train Epoch: 95 [40960/90000 (45%)]	Loss: -3.2748	Cost: 9.83s
Train Epoch: 95 [81920/90000 (91%)]	Loss: -3.2379	Cost: 19.31s
Train Epoch: 95 	Average Loss: -3.1754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0125

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: -1.1781	Cost: 38.56s
Train Epoch: 96 [40960/90000 (45%)]	Loss: -3.0883	Cost: 10.10s
Train Epoch: 96 [81920/90000 (91%)]	Loss: -3.1344	Cost: 17.78s
Train Epoch: 96 	Average Loss: -2.9547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1111

Learning rate: 0.0001823532597628427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: -0.8649	Cost: 36.08s
Train Epoch: 97 [40960/90000 (45%)]	Loss: -3.2419	Cost: 9.57s
Train Epoch: 97 [81920/90000 (91%)]	Loss: -3.2235	Cost: 15.97s
Train Epoch: 97 	Average Loss: -3.0368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1658

Learning rate: 0.0001819952109325452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: -1.2197	Cost: 37.36s
Train Epoch: 98 [40960/90000 (45%)]	Loss: -3.3199	Cost: 9.67s
Train Epoch: 98 [81920/90000 (91%)]	Loss: -3.4417	Cost: 13.56s
Train Epoch: 98 	Average Loss: -3.2535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1084

Learning rate: 0.00018163392507171837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: -1.5846	Cost: 35.11s
Train Epoch: 99 [40960/90000 (45%)]	Loss: -3.4464	Cost: 10.08s
Train Epoch: 99 [81920/90000 (91%)]	Loss: -3.6742	Cost: 18.03s
Train Epoch: 99 	Average Loss: -3.3331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1679

Learning rate: 0.00018126941644330935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: -1.6488	Cost: 37.97s
Train Epoch: 100 [40960/90000 (45%)]	Loss: -3.6401	Cost: 9.72s
Train Epoch: 100 [81920/90000 (91%)]	Loss: -3.6168	Cost: 19.48s
Train Epoch: 100 	Average Loss: -3.3213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0788

Learning rate: 0.0001809016994374947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: -1.0390	Cost: 39.35s
Train Epoch: 101 [40960/90000 (45%)]	Loss: -3.6475	Cost: 9.74s
Train Epoch: 101 [81920/90000 (91%)]	Loss: -3.5849	Cost: 15.04s
Train Epoch: 101 	Average Loss: -3.3188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3208

Saving model as e101_model.pt & e101_waveforms_supplementary.hdf5
Learning rate: 0.00018053078857111214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: -1.0611	Cost: 37.04s
Train Epoch: 102 [40960/90000 (45%)]	Loss: -3.4919	Cost: 9.62s
Train Epoch: 102 [81920/90000 (91%)]	Loss: -3.5673	Cost: 13.27s
Train Epoch: 102 	Average Loss: -3.4422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1995

Learning rate: 0.00018015669848708761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: -1.5571	Cost: 33.69s
Train Epoch: 103 [40960/90000 (45%)]	Loss: -3.7634	Cost: 9.72s
Train Epoch: 103 [81920/90000 (91%)]	Loss: -3.8037	Cost: 18.92s
Train Epoch: 103 	Average Loss: -3.5363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3037

Learning rate: 0.00017977944395385705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: -1.5285	Cost: 38.81s
Train Epoch: 104 [40960/90000 (45%)]	Loss: -3.8363	Cost: 9.66s
Train Epoch: 104 [81920/90000 (91%)]	Loss: -3.4671	Cost: 13.49s
Train Epoch: 104 	Average Loss: -3.4431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1925

Learning rate: 0.00017939903986478347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: -1.3915	Cost: 37.30s
Train Epoch: 105 [40960/90000 (45%)]	Loss: -3.7307	Cost: 9.58s
Train Epoch: 105 [81920/90000 (91%)]	Loss: -3.6277	Cost: 13.41s
Train Epoch: 105 	Average Loss: -3.5404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2934

Learning rate: 0.00017901550123756898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: -1.5369	Cost: 36.36s
Train Epoch: 106 [40960/90000 (45%)]	Loss: -3.8006	Cost: 9.61s
Train Epoch: 106 [81920/90000 (91%)]	Loss: -3.5610	Cost: 14.37s
Train Epoch: 106 	Average Loss: -3.5848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0396

Learning rate: 0.00017862884321366183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: -1.0222	Cost: 33.41s
Train Epoch: 107 [40960/90000 (45%)]	Loss: -3.4994	Cost: 9.79s
Train Epoch: 107 [81920/90000 (91%)]	Loss: -3.4897	Cost: 18.94s
Train Epoch: 107 	Average Loss: -3.2692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2054

Learning rate: 0.00017823908105765875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: -1.4296	Cost: 38.67s
Train Epoch: 108 [40960/90000 (45%)]	Loss: -3.6234	Cost: 9.71s
Train Epoch: 108 [81920/90000 (91%)]	Loss: -3.8628	Cost: 15.85s
Train Epoch: 108 	Average Loss: -3.5100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3165

Learning rate: 0.00017784623015670232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: -1.4674	Cost: 39.83s
Train Epoch: 109 [40960/90000 (45%)]	Loss: -3.8400	Cost: 9.83s
Train Epoch: 109 [81920/90000 (91%)]	Loss: -3.9242	Cost: 13.78s
Train Epoch: 109 	Average Loss: -3.5840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4950

Saving model as e109_model.pt & e109_waveforms_supplementary.hdf5
Learning rate: 0.00017745030601987337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: -1.4968	Cost: 35.11s
Train Epoch: 110 [40960/90000 (45%)]	Loss: -3.8087	Cost: 9.65s
Train Epoch: 110 [81920/90000 (91%)]	Loss: -3.9565	Cost: 13.61s
Train Epoch: 110 	Average Loss: -3.6897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4007

Learning rate: 0.0001770513242775789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: -1.4135	Cost: 33.59s
Train Epoch: 111 [40960/90000 (45%)]	Loss: -4.0157	Cost: 9.70s
Train Epoch: 111 [81920/90000 (91%)]	Loss: -4.0530	Cost: 19.01s
Train Epoch: 111 	Average Loss: -3.7418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5236

Saving model as e111_model.pt & e111_waveforms_supplementary.hdf5
Learning rate: 0.00017664930068093498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: -1.5372	Cost: 37.84s
Train Epoch: 112 [40960/90000 (45%)]	Loss: -3.8248	Cost: 9.78s
Train Epoch: 112 [81920/90000 (91%)]	Loss: -3.9657	Cost: 14.00s
Train Epoch: 112 	Average Loss: -3.6332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2485

Learning rate: 0.0001762442511011448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: -1.6700	Cost: 37.70s
Train Epoch: 113 [40960/90000 (45%)]	Loss: -3.8742	Cost: 9.73s
Train Epoch: 113 [81920/90000 (91%)]	Loss: -3.7776	Cost: 13.24s
Train Epoch: 113 	Average Loss: -3.6519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1334

Learning rate: 0.0001758361915288722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: -1.7920	Cost: 34.63s
Train Epoch: 114 [40960/90000 (45%)]	Loss: -3.7529	Cost: 9.63s
Train Epoch: 114 [81920/90000 (91%)]	Loss: -3.5754	Cost: 12.87s
Train Epoch: 114 	Average Loss: -3.6002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0392

Learning rate: 0.0001754251380736104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: -1.4391	Cost: 33.71s
Train Epoch: 115 [40960/90000 (45%)]	Loss: -3.8576	Cost: 9.72s
Train Epoch: 115 [81920/90000 (91%)]	Loss: -3.9112	Cost: 19.04s
Train Epoch: 115 	Average Loss: -3.5326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2462

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: -1.4088	Cost: 35.65s
Train Epoch: 116 [40960/90000 (45%)]	Loss: -3.9573	Cost: 9.87s
Train Epoch: 116 [81920/90000 (91%)]	Loss: -3.9557	Cost: 16.46s
Train Epoch: 116 	Average Loss: -3.7453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3044

Learning rate: 0.00017459411454241822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: -1.4424	Cost: 39.43s
Train Epoch: 117 [40960/90000 (45%)]	Loss: -4.0898	Cost: 9.99s
Train Epoch: 117 [81920/90000 (91%)]	Loss: -4.0034	Cost: 13.66s
Train Epoch: 117 	Average Loss: -3.7903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3949

Learning rate: 0.00017417417727387391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: -1.3393	Cost: 37.75s
Train Epoch: 118 [40960/90000 (45%)]	Loss: -3.8613	Cost: 9.92s
Train Epoch: 118 [81920/90000 (91%)]	Loss: -3.9609	Cost: 13.83s
Train Epoch: 118 	Average Loss: -3.6626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4246

Learning rate: 0.00017375131173581737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: -1.8297	Cost: 34.57s
Train Epoch: 119 [40960/90000 (45%)]	Loss: -4.3230	Cost: 9.74s
Train Epoch: 119 [81920/90000 (91%)]	Loss: -4.1502	Cost: 19.38s
Train Epoch: 119 	Average Loss: -3.8772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3847

Learning rate: 0.000173325534622256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: -1.5218	Cost: 35.60s
Train Epoch: 120 [40960/90000 (45%)]	Loss: -4.2524	Cost: 9.84s
Train Epoch: 120 [81920/90000 (91%)]	Loss: -4.1391	Cost: 15.84s
Train Epoch: 120 	Average Loss: -3.9409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4210

Learning rate: 0.00017289686274214115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: -1.8773	Cost: 40.85s
Train Epoch: 121 [40960/90000 (45%)]	Loss: -4.1585	Cost: 10.03s
Train Epoch: 121 [81920/90000 (91%)]	Loss: -4.0154	Cost: 14.88s
Train Epoch: 121 	Average Loss: -4.0400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5886

Saving model as e121_model.pt & e121_waveforms_supplementary.hdf5
Learning rate: 0.00017246531301870466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: -1.7737	Cost: 36.66s
Train Epoch: 122 [40960/90000 (45%)]	Loss: -3.9327	Cost: 9.68s
Train Epoch: 122 [81920/90000 (91%)]	Loss: -4.2033	Cost: 13.61s
Train Epoch: 122 	Average Loss: -3.8199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3757

Learning rate: 0.00017203090248879067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: -1.5491	Cost: 33.17s
Train Epoch: 123 [40960/90000 (45%)]	Loss: -4.1852	Cost: 9.93s
Train Epoch: 123 [81920/90000 (91%)]	Loss: -4.0411	Cost: 18.72s
Train Epoch: 123 	Average Loss: -3.9091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4274

Learning rate: 0.00017159364830218312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: -1.6749	Cost: 35.92s
Train Epoch: 124 [40960/90000 (45%)]	Loss: -4.0704	Cost: 9.79s
Train Epoch: 124 [81920/90000 (91%)]	Loss: -3.9247	Cost: 17.37s
Train Epoch: 124 	Average Loss: -3.8423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4280

Learning rate: 0.00017115356772092854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: -1.3350	Cost: 38.17s
Train Epoch: 125 [40960/90000 (45%)]	Loss: -4.0575	Cost: 9.69s
Train Epoch: 125 [81920/90000 (91%)]	Loss: -3.8482	Cost: 15.52s
Train Epoch: 125 	Average Loss: -3.7748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0060

Learning rate: 0.00017071067811865473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: -1.4435	Cost: 34.41s
Train Epoch: 126 [40960/90000 (45%)]	Loss: -3.9535	Cost: 9.64s
Train Epoch: 126 [81920/90000 (91%)]	Loss: -3.9492	Cost: 12.61s
Train Epoch: 126 	Average Loss: -3.6967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2221

Learning rate: 0.00017026499697988493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: -1.3875	Cost: 35.72s
Train Epoch: 127 [40960/90000 (45%)]	Loss: -4.1632	Cost: 9.61s
Train Epoch: 127 [81920/90000 (91%)]	Loss: -3.9264	Cost: 17.37s
Train Epoch: 127 	Average Loss: -3.9171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4465

Learning rate: 0.00016981654189934727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: -1.6000	Cost: 35.80s
Train Epoch: 128 [40960/90000 (45%)]	Loss: -4.3230	Cost: 9.71s
Train Epoch: 128 [81920/90000 (91%)]	Loss: -4.1831	Cost: 17.74s
Train Epoch: 128 	Average Loss: -4.0377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5374

Learning rate: 0.0001693653305812805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: -1.6348	Cost: 37.43s
Train Epoch: 129 [40960/90000 (45%)]	Loss: -4.2831	Cost: 9.65s
Train Epoch: 129 [81920/90000 (91%)]	Loss: -4.2093	Cost: 13.79s
Train Epoch: 129 	Average Loss: -3.9807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4018

Learning rate: 0.00016891138083873484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: -1.7438	Cost: 34.76s
Train Epoch: 130 [40960/90000 (45%)]	Loss: -4.0759	Cost: 9.61s
Train Epoch: 130 [81920/90000 (91%)]	Loss: -3.9996	Cost: 12.99s
Train Epoch: 130 	Average Loss: -3.9955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4685

Learning rate: 0.00016845471059286887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: -1.5505	Cost: 34.30s
Train Epoch: 131 [40960/90000 (45%)]	Loss: -4.2848	Cost: 9.58s
Train Epoch: 131 [81920/90000 (91%)]	Loss: -4.4519	Cost: 15.29s
Train Epoch: 131 	Average Loss: -4.1182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6123

Saving model as e131_model.pt & e131_waveforms_supplementary.hdf5
Learning rate: 0.0001679953378722419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: -1.5166	Cost: 35.46s
Train Epoch: 132 [40960/90000 (45%)]	Loss: -4.3952	Cost: 9.78s
Train Epoch: 132 [81920/90000 (91%)]	Loss: -4.4301	Cost: 18.70s
Train Epoch: 132 	Average Loss: -4.2362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6996

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Learning rate: 0.00016753328081210242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: -1.6930	Cost: 36.42s
Train Epoch: 133 [40960/90000 (45%)]	Loss: -4.2535	Cost: 9.61s
Train Epoch: 133 [81920/90000 (91%)]	Loss: -4.3507	Cost: 13.56s
Train Epoch: 133 	Average Loss: -4.1668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4707

Learning rate: 0.000167068557653672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: -1.6352	Cost: 36.67s
Train Epoch: 134 [40960/90000 (45%)]	Loss: -4.4748	Cost: 9.65s
Train Epoch: 134 [81920/90000 (91%)]	Loss: -4.2106	Cost: 12.96s
Train Epoch: 134 	Average Loss: -4.2878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6467

Learning rate: 0.00016660118674342514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: -2.0876	Cost: 36.77s
Train Epoch: 135 [40960/90000 (45%)]	Loss: -4.4968	Cost: 9.50s
Train Epoch: 135 [81920/90000 (91%)]	Loss: -4.4898	Cost: 16.36s
Train Epoch: 135 	Average Loss: -4.2633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7341

Saving model as e135_model.pt & e135_waveforms_supplementary.hdf5
Learning rate: 0.00016613118653236516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: -1.7917	Cost: 34.46s
Train Epoch: 136 [40960/90000 (45%)]	Loss: -4.4539	Cost: 9.69s
Train Epoch: 136 [81920/90000 (91%)]	Loss: -4.3822	Cost: 17.46s
Train Epoch: 136 	Average Loss: -4.2183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5903

Learning rate: 0.0001656585755752956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: -1.8342	Cost: 37.57s
Train Epoch: 137 [40960/90000 (45%)]	Loss: -4.4464	Cost: 9.79s
Train Epoch: 137 [81920/90000 (91%)]	Loss: -4.4176	Cost: 14.00s
Train Epoch: 137 	Average Loss: -4.2233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5053

Learning rate: 0.00016518337253008784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: -2.1395	Cost: 35.22s
Train Epoch: 138 [40960/90000 (45%)]	Loss: -4.4252	Cost: 9.62s
Train Epoch: 138 [81920/90000 (91%)]	Loss: -4.3291	Cost: 14.59s
Train Epoch: 138 	Average Loss: -4.2647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5023

Learning rate: 0.0001647055961569444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: -1.7102	Cost: 36.89s
Train Epoch: 139 [40960/90000 (45%)]	Loss: -4.3583	Cost: 9.53s
Train Epoch: 139 [81920/90000 (91%)]	Loss: -4.2024	Cost: 13.68s
Train Epoch: 139 	Average Loss: -4.0971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3885

Learning rate: 0.0001642252653176584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: -1.6958	Cost: 33.90s
Train Epoch: 140 [40960/90000 (45%)]	Loss: -4.5643	Cost: 9.84s
Train Epoch: 140 [81920/90000 (91%)]	Loss: -4.0510	Cost: 19.34s
Train Epoch: 140 	Average Loss: -4.1195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2404

Learning rate: 0.00016374239897486894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: -1.8003	Cost: 36.38s
Train Epoch: 141 [40960/90000 (45%)]	Loss: -4.4889	Cost: 9.84s
Train Epoch: 141 [81920/90000 (91%)]	Loss: -4.6876	Cost: 17.43s
Train Epoch: 141 	Average Loss: -4.2357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5617

Learning rate: 0.0001632570161913124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: -1.9310	Cost: 40.09s
Train Epoch: 142 [40960/90000 (45%)]	Loss: -4.7622	Cost: 9.66s
Train Epoch: 142 [81920/90000 (91%)]	Loss: -4.5356	Cost: 14.61s
Train Epoch: 142 	Average Loss: -4.3848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6739

Learning rate: 0.00016276913612907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: -2.0752	Cost: 36.67s
Train Epoch: 143 [40960/90000 (45%)]	Loss: -4.7237	Cost: 9.59s
Train Epoch: 143 [81920/90000 (91%)]	Loss: -4.0404	Cost: 14.10s
Train Epoch: 143 	Average Loss: -4.3728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4777

Learning rate: 0.00016227877804881122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: -1.7974	Cost: 34.70s
Train Epoch: 144 [40960/90000 (45%)]	Loss: -4.3699	Cost: 9.86s
Train Epoch: 144 [81920/90000 (91%)]	Loss: -4.5661	Cost: 19.54s
Train Epoch: 144 	Average Loss: -4.1733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5843

Learning rate: 0.0001617859613090334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: -2.1631	Cost: 38.20s
Train Epoch: 145 [40960/90000 (45%)]	Loss: -4.8180	Cost: 10.01s
Train Epoch: 145 [81920/90000 (91%)]	Loss: -4.5705	Cost: 15.96s
Train Epoch: 145 	Average Loss: -4.4570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7622

Saving model as e145_model.pt & e145_waveforms_supplementary.hdf5
Learning rate: 0.00016129070536529763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: -2.1453	Cost: 39.68s
Train Epoch: 146 [40960/90000 (45%)]	Loss: -4.6606	Cost: 9.56s
Train Epoch: 146 [81920/90000 (91%)]	Loss: -4.4797	Cost: 14.38s
Train Epoch: 146 	Average Loss: -4.4555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6860

Learning rate: 0.00016079302976946053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: -1.9860	Cost: 37.36s
Train Epoch: 147 [40960/90000 (45%)]	Loss: -4.9373	Cost: 9.50s
Train Epoch: 147 [81920/90000 (91%)]	Loss: -4.8681	Cost: 16.37s
Train Epoch: 147 	Average Loss: -4.5572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5892

Learning rate: 0.00016029295416890245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: -1.7868	Cost: 34.41s
Train Epoch: 148 [40960/90000 (45%)]	Loss: -4.7964	Cost: 9.68s
Train Epoch: 148 [81920/90000 (91%)]	Loss: -4.8014	Cost: 18.37s
Train Epoch: 148 	Average Loss: -4.5913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8557

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 0.00015979049830575187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: -1.7826	Cost: 36.40s
Train Epoch: 149 [40960/90000 (45%)]	Loss: -4.6172	Cost: 9.62s
Train Epoch: 149 [81920/90000 (91%)]	Loss: -4.6329	Cost: 14.22s
Train Epoch: 149 	Average Loss: -4.4404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5638

Learning rate: 0.00015928568201610592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: -1.8807	Cost: 37.75s
Train Epoch: 150 [40960/90000 (45%)]	Loss: -4.6023	Cost: 9.55s
Train Epoch: 150 [81920/90000 (91%)]	Loss: -4.3982	Cost: 14.89s
Train Epoch: 150 	Average Loss: -4.4157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6662

Learning rate: 0.00015877852522924732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: -2.0742	Cost: 35.96s
Train Epoch: 151 [40960/90000 (45%)]	Loss: -4.8338	Cost: 9.48s
Train Epoch: 151 [81920/90000 (91%)]	Loss: -4.6839	Cost: 17.41s
Train Epoch: 151 	Average Loss: -4.4631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6362

Learning rate: 0.00015826904796685762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: -2.0340	Cost: 36.39s
Train Epoch: 152 [40960/90000 (45%)]	Loss: -4.6989	Cost: 9.69s
Train Epoch: 152 [81920/90000 (91%)]	Loss: -4.7294	Cost: 19.27s
Train Epoch: 152 	Average Loss: -4.5468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7571

Learning rate: 0.00015775727034222675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: -2.3027	Cost: 36.81s
Train Epoch: 153 [40960/90000 (45%)]	Loss: -4.9495	Cost: 9.65s
Train Epoch: 153 [81920/90000 (91%)]	Loss: -4.8995	Cost: 15.17s
Train Epoch: 153 	Average Loss: -4.7432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8346

Learning rate: 0.00015724321255945907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: -2.1871	Cost: 34.71s
Train Epoch: 154 [40960/90000 (45%)]	Loss: -4.9117	Cost: 9.57s
Train Epoch: 154 [81920/90000 (91%)]	Loss: -5.0407	Cost: 13.53s
Train Epoch: 154 	Average Loss: -4.7212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7477

Learning rate: 0.00015672689491267567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: -2.5098	Cost: 36.56s
Train Epoch: 155 [40960/90000 (45%)]	Loss: -5.1236	Cost: 9.65s
Train Epoch: 155 [81920/90000 (91%)]	Loss: -5.1183	Cost: 17.21s
Train Epoch: 155 	Average Loss: -4.7711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8711

Saving model as e155_model.pt & e155_waveforms_supplementary.hdf5
Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: -2.1795	Cost: 34.79s
Train Epoch: 156 [40960/90000 (45%)]	Loss: -4.9094	Cost: 9.73s
Train Epoch: 156 [81920/90000 (91%)]	Loss: -4.9942	Cost: 17.69s
Train Epoch: 156 	Average Loss: -4.8257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7955

Learning rate: 0.00015568756164881882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: -2.3577	Cost: 41.17s
Train Epoch: 157 [40960/90000 (45%)]	Loss: -4.8541	Cost: 10.09s
Train Epoch: 157 [81920/90000 (91%)]	Loss: -4.8503	Cost: 14.03s
Train Epoch: 157 	Average Loss: -4.5594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8660

Learning rate: 0.00015516458706284303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: -1.7073	Cost: 37.05s
Train Epoch: 158 [40960/90000 (45%)]	Loss: -4.8647	Cost: 9.69s
Train Epoch: 158 [81920/90000 (91%)]	Loss: -5.2183	Cost: 14.27s
Train Epoch: 158 	Average Loss: -4.7529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0516

Saving model as e158_model.pt & e158_waveforms_supplementary.hdf5
Learning rate: 0.0001546394346734269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: -2.0204	Cost: 35.17s
Train Epoch: 159 [40960/90000 (45%)]	Loss: -5.2421	Cost: 9.82s
Train Epoch: 159 [81920/90000 (91%)]	Loss: -4.9306	Cost: 19.41s
Train Epoch: 159 	Average Loss: -4.8857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9260

Learning rate: 0.00015411212521268755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: -2.2461	Cost: 37.65s
Train Epoch: 160 [40960/90000 (45%)]	Loss: -4.8958	Cost: 9.81s
Train Epoch: 160 [81920/90000 (91%)]	Loss: -5.0313	Cost: 17.12s
Train Epoch: 160 	Average Loss: -4.9171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0764

Saving model as e160_model.pt & e160_waveforms_supplementary.hdf5
Learning rate: 0.00015358267949789963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: -1.9669	Cost: 39.53s
Train Epoch: 161 [40960/90000 (45%)]	Loss: -5.2167	Cost: 9.68s
Train Epoch: 161 [81920/90000 (91%)]	Loss: -5.0352	Cost: 14.28s
Train Epoch: 161 	Average Loss: -4.9716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9964

Learning rate: 0.00015305111843067339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: -2.6247	Cost: 35.47s
Train Epoch: 162 [40960/90000 (45%)]	Loss: -5.2520	Cost: 9.55s
Train Epoch: 162 [81920/90000 (91%)]	Loss: -4.9317	Cost: 14.56s
Train Epoch: 162 	Average Loss: -4.9197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7269

Learning rate: 0.00015251746299612957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: -2.2907	Cost: 33.65s
Train Epoch: 163 [40960/90000 (45%)]	Loss: -4.9024	Cost: 9.69s
Train Epoch: 163 [81920/90000 (91%)]	Loss: -5.0117	Cost: 19.11s
Train Epoch: 163 	Average Loss: -4.7362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7882

Learning rate: 0.00015198173426207094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: -2.2983	Cost: 36.95s
Train Epoch: 164 [40960/90000 (45%)]	Loss: -5.0252	Cost: 9.76s
Train Epoch: 164 [81920/90000 (91%)]	Loss: -5.0473	Cost: 15.25s
Train Epoch: 164 	Average Loss: -4.7909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9357

Learning rate: 0.00015144395337815067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: -2.0987	Cost: 36.06s
Train Epoch: 165 [40960/90000 (45%)]	Loss: -5.1198	Cost: 10.04s
Train Epoch: 165 [81920/90000 (91%)]	Loss: -5.1358	Cost: 15.35s
Train Epoch: 165 	Average Loss: -4.9173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9089

Learning rate: 0.00015090414157503714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: -2.5179	Cost: 36.69s
Train Epoch: 166 [40960/90000 (45%)]	Loss: -5.2795	Cost: 9.69s
Train Epoch: 166 [81920/90000 (91%)]	Loss: -5.2353	Cost: 13.42s
Train Epoch: 166 	Average Loss: -5.0141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0115

Learning rate: 0.00015036232016357607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: -2.1584	Cost: 34.42s
Train Epoch: 167 [40960/90000 (45%)]	Loss: -5.4216	Cost: 9.76s
Train Epoch: 167 [81920/90000 (91%)]	Loss: -5.3976	Cost: 19.18s
Train Epoch: 167 	Average Loss: -5.0955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0809

Saving model as e167_model.pt & e167_waveforms_supplementary.hdf5
Learning rate: 0.00014981851053394907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: -2.5455	Cost: 37.38s
Train Epoch: 168 [40960/90000 (45%)]	Loss: -5.4468	Cost: 9.66s
Train Epoch: 168 [81920/90000 (91%)]	Loss: -5.4838	Cost: 18.03s
Train Epoch: 168 	Average Loss: -5.2139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0171

Learning rate: 0.00014927273415482915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: -2.2084	Cost: 36.12s
Train Epoch: 169 [40960/90000 (45%)]	Loss: -5.2929	Cost: 9.59s
Train Epoch: 169 [81920/90000 (91%)]	Loss: -5.3707	Cost: 15.30s
Train Epoch: 169 	Average Loss: -5.2052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2481

Saving model as e169_model.pt & e169_waveforms_supplementary.hdf5
Learning rate: 0.00014872501257253323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: -2.2436	Cost: 36.82s
Train Epoch: 170 [40960/90000 (45%)]	Loss: -5.6544	Cost: 9.79s
Train Epoch: 170 [81920/90000 (91%)]	Loss: -5.5327	Cost: 13.02s
Train Epoch: 170 	Average Loss: -5.2458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2635

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 0.00014817536741017152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: -2.7669	Cost: 33.90s
Train Epoch: 171 [40960/90000 (45%)]	Loss: -5.4052	Cost: 9.76s
Train Epoch: 171 [81920/90000 (91%)]	Loss: -5.3975	Cost: 18.32s
Train Epoch: 171 	Average Loss: -5.1689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1592

Learning rate: 0.0001476238203667939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: -2.2445	Cost: 37.17s
Train Epoch: 172 [40960/90000 (45%)]	Loss: -5.5184	Cost: 9.77s
Train Epoch: 172 [81920/90000 (91%)]	Loss: -5.6036	Cost: 14.82s
Train Epoch: 172 	Average Loss: -5.1987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1167

Learning rate: 0.00014707039321653327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: -2.5820	Cost: 39.90s
Train Epoch: 173 [40960/90000 (45%)]	Loss: -5.6292	Cost: 9.62s
Train Epoch: 173 [81920/90000 (91%)]	Loss: -5.6249	Cost: 14.63s
Train Epoch: 173 	Average Loss: -5.2553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0647

Learning rate: 0.00014651510780774586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: -2.2655	Cost: 36.91s
Train Epoch: 174 [40960/90000 (45%)]	Loss: -5.5412	Cost: 9.53s
Train Epoch: 174 [81920/90000 (91%)]	Loss: -5.4473	Cost: 14.07s
Train Epoch: 174 	Average Loss: -5.2228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1976

Learning rate: 0.00014595798606214882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: -2.4393	Cost: 33.26s
Train Epoch: 175 [40960/90000 (45%)]	Loss: -5.7331	Cost: 9.74s
Train Epoch: 175 [81920/90000 (91%)]	Loss: -5.8352	Cost: 18.65s
Train Epoch: 175 	Average Loss: -5.3497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1845

Learning rate: 0.00014539904997395468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: -2.4427	Cost: 36.66s
Train Epoch: 176 [40960/90000 (45%)]	Loss: -5.5889	Cost: 9.71s
Train Epoch: 176 [81920/90000 (91%)]	Loss: -5.6537	Cost: 15.87s
Train Epoch: 176 	Average Loss: -5.3776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2642

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Learning rate: 0.00014483832160900326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: -2.5082	Cost: 35.69s
Train Epoch: 177 [40960/90000 (45%)]	Loss: -5.7735	Cost: 9.69s
Train Epoch: 177 [81920/90000 (91%)]	Loss: -5.5115	Cost: 14.46s
Train Epoch: 177 	Average Loss: -5.3479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9948

Learning rate: 0.00014427582310389016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: -2.2677	Cost: 36.03s
Train Epoch: 178 [40960/90000 (45%)]	Loss: -5.5384	Cost: 9.74s
Train Epoch: 178 [81920/90000 (91%)]	Loss: -5.5939	Cost: 13.92s
Train Epoch: 178 	Average Loss: -5.2565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1269

Learning rate: 0.0001437115766650933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: -2.3774	Cost: 33.47s
Train Epoch: 179 [40960/90000 (45%)]	Loss: -5.7304	Cost: 9.96s
Train Epoch: 179 [81920/90000 (91%)]	Loss: -5.5671	Cost: 17.47s
Train Epoch: 179 	Average Loss: -5.2676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9956

Learning rate: 0.0001431456045680959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: -2.4417	Cost: 35.62s
Train Epoch: 180 [40960/90000 (45%)]	Loss: -5.5848	Cost: 9.73s
Train Epoch: 180 [81920/90000 (91%)]	Loss: -5.8940	Cost: 18.80s
Train Epoch: 180 	Average Loss: -5.3842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1882

Learning rate: 0.00014257792915650726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: -2.4828	Cost: 36.43s
Train Epoch: 181 [40960/90000 (45%)]	Loss: -5.9267	Cost: 9.83s
Train Epoch: 181 [81920/90000 (91%)]	Loss: -5.7290	Cost: 14.79s
Train Epoch: 181 	Average Loss: -5.4584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2083

Learning rate: 0.0001420085728411806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: -2.1756	Cost: 36.82s
Train Epoch: 182 [40960/90000 (45%)]	Loss: -5.9447	Cost: 10.20s
Train Epoch: 182 [81920/90000 (91%)]	Loss: -5.6868	Cost: 13.15s
Train Epoch: 182 	Average Loss: -5.4620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1796

Learning rate: 0.0001414375580993284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: -2.7264	Cost: 33.89s
Train Epoch: 183 [40960/90000 (45%)]	Loss: -5.6848	Cost: 9.78s
Train Epoch: 183 [81920/90000 (91%)]	Loss: -5.8050	Cost: 18.58s
Train Epoch: 183 	Average Loss: -5.4707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1815

Learning rate: 0.00014086490747363488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: -2.2409	Cost: 37.76s
Train Epoch: 184 [40960/90000 (45%)]	Loss: -5.7510	Cost: 9.84s
Train Epoch: 184 [81920/90000 (91%)]	Loss: -5.7075	Cost: 16.37s
Train Epoch: 184 	Average Loss: -5.4040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2359

Learning rate: 0.00014029064357136623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: -2.5161	Cost: 39.35s
Train Epoch: 185 [40960/90000 (45%)]	Loss: -5.9461	Cost: 9.59s
Train Epoch: 185 [81920/90000 (91%)]	Loss: -5.6134	Cost: 14.47s
Train Epoch: 185 	Average Loss: -5.5491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2169

Learning rate: 0.00013971478906347803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: -2.3867	Cost: 34.56s
Train Epoch: 186 [40960/90000 (45%)]	Loss: -5.6294	Cost: 9.78s
Train Epoch: 186 [81920/90000 (91%)]	Loss: -5.6613	Cost: 13.65s
Train Epoch: 186 	Average Loss: -5.4227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4765

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Learning rate: 0.0001391373666837202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: -2.6854	Cost: 33.36s
Train Epoch: 187 [40960/90000 (45%)]	Loss: -5.7511	Cost: 9.79s
Train Epoch: 187 [81920/90000 (91%)]	Loss: -5.7125	Cost: 20.14s
Train Epoch: 187 	Average Loss: -5.4978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3773

Learning rate: 0.0001385583992277396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: -2.1125	Cost: 35.64s
Train Epoch: 188 [40960/90000 (45%)]	Loss: -5.8163	Cost: 9.74s
Train Epoch: 188 [81920/90000 (91%)]	Loss: -5.7431	Cost: 16.04s
Train Epoch: 188 	Average Loss: -5.4244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1120

Learning rate: 0.00013797790955218008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: -2.3285	Cost: 38.52s
Train Epoch: 189 [40960/90000 (45%)]	Loss: -5.5011	Cost: 9.53s
Train Epoch: 189 [81920/90000 (91%)]	Loss: -5.4238	Cost: 14.55s
Train Epoch: 189 	Average Loss: -5.2984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0736

Learning rate: 0.00013739592057378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: -1.8721	Cost: 35.25s
Train Epoch: 190 [40960/90000 (45%)]	Loss: -5.5384	Cost: 9.67s
Train Epoch: 190 [81920/90000 (91%)]	Loss: -5.2010	Cost: 13.42s
Train Epoch: 190 	Average Loss: -5.1946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9251

Learning rate: 0.00013681245526846775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: -1.9655	Cost: 35.10s
Train Epoch: 191 [40960/90000 (45%)]	Loss: -5.6512	Cost: 10.29s
Train Epoch: 191 [81920/90000 (91%)]	Loss: -5.6851	Cost: 17.33s
Train Epoch: 191 	Average Loss: -5.3411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2174

Learning rate: 0.00013622753667045454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: -2.4356	Cost: 36.18s
Train Epoch: 192 [40960/90000 (45%)]	Loss: -5.9419	Cost: 9.65s
Train Epoch: 192 [81920/90000 (91%)]	Loss: -5.8930	Cost: 19.59s
Train Epoch: 192 	Average Loss: -5.6066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4487

Learning rate: 0.00013564118787132503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: -2.7466	Cost: 37.21s
Train Epoch: 193 [40960/90000 (45%)]	Loss: -6.1189	Cost: 9.61s
Train Epoch: 193 [81920/90000 (91%)]	Loss: -5.8515	Cost: 15.99s
Train Epoch: 193 	Average Loss: -5.7109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4999

Saving model as e193_model.pt & e193_waveforms_supplementary.hdf5
Learning rate: 0.00013505343201912587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: -2.6429	Cost: 37.76s
Train Epoch: 194 [40960/90000 (45%)]	Loss: -6.0030	Cost: 9.63s
Train Epoch: 194 [81920/90000 (91%)]	Loss: -5.7747	Cost: 13.87s
Train Epoch: 194 	Average Loss: -5.7269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4426

Learning rate: 0.0001344642923174517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: -2.8157	Cost: 34.97s
Train Epoch: 195 [40960/90000 (45%)]	Loss: -5.8731	Cost: 9.80s
Train Epoch: 195 [81920/90000 (91%)]	Loss: -5.8974	Cost: 19.14s
Train Epoch: 195 	Average Loss: -5.7526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1702

Learning rate: 0.00013387379202452914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: -3.0918	Cost: 35.60s
Train Epoch: 196 [40960/90000 (45%)]	Loss: -6.0263	Cost: 9.86s
Train Epoch: 196 [81920/90000 (91%)]	Loss: -5.8491	Cost: 17.23s
Train Epoch: 196 	Average Loss: -5.6902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2474

Learning rate: 0.00013328195445229865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: -2.4209	Cost: 37.80s
Train Epoch: 197 [40960/90000 (45%)]	Loss: -5.8431	Cost: 9.73s
Train Epoch: 197 [81920/90000 (91%)]	Loss: -5.8735	Cost: 14.84s
Train Epoch: 197 	Average Loss: -5.6226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2655

Learning rate: 0.00013268880296549425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: -3.1462	Cost: 39.07s
Train Epoch: 198 [40960/90000 (45%)]	Loss: -5.9291	Cost: 9.58s
Train Epoch: 198 [81920/90000 (91%)]	Loss: -5.8991	Cost: 14.49s
Train Epoch: 198 	Average Loss: -5.6944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4787

Learning rate: 0.00013209436098072093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: -2.3181	Cost: 35.82s
Train Epoch: 199 [40960/90000 (45%)]	Loss: -6.0797	Cost: 9.92s
Train Epoch: 199 [81920/90000 (91%)]	Loss: -5.8583	Cost: 20.35s
Train Epoch: 199 	Average Loss: -5.6038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3353

Learning rate: 0.00013149865196553047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: -2.7319	Cost: 35.69s
Train Epoch: 200 [40960/90000 (45%)]	Loss: -6.0371	Cost: 9.84s
Train Epoch: 200 [81920/90000 (91%)]	Loss: -5.9612	Cost: 17.27s
Train Epoch: 200 	Average Loss: -5.7458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2851

Learning rate: 0.00013090169943749474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: -2.5585	Cost: 38.26s
Train Epoch: 201 [40960/90000 (45%)]	Loss: -6.4799	Cost: 9.63s
Train Epoch: 201 [81920/90000 (91%)]	Loss: -6.0019	Cost: 15.94s
Train Epoch: 201 	Average Loss: -5.9066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4556

Learning rate: 0.0001303035269632774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: -2.8051	Cost: 39.03s
Train Epoch: 202 [40960/90000 (45%)]	Loss: -6.2174	Cost: 9.72s
Train Epoch: 202 [81920/90000 (91%)]	Loss: -6.0290	Cost: 13.40s
Train Epoch: 202 	Average Loss: -5.7883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4029

Learning rate: 0.00012970415815770348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: -2.2719	Cost: 35.15s
Train Epoch: 203 [40960/90000 (45%)]	Loss: -6.1466	Cost: 9.59s
Train Epoch: 203 [81920/90000 (91%)]	Loss: -5.9307	Cost: 18.20s
Train Epoch: 203 	Average Loss: -5.8095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4152

Learning rate: 0.00012910361668282719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: -2.6921	Cost: 36.56s
Train Epoch: 204 [40960/90000 (45%)]	Loss: -6.1093	Cost: 9.72s
Train Epoch: 204 [81920/90000 (91%)]	Loss: -6.2754	Cost: 19.16s
Train Epoch: 204 	Average Loss: -5.8132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4370

Learning rate: 0.0001285019262469976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: -2.4644	Cost: 36.18s
Train Epoch: 205 [40960/90000 (45%)]	Loss: -6.1632	Cost: 9.58s
Train Epoch: 205 [81920/90000 (91%)]	Loss: -6.2713	Cost: 15.21s
Train Epoch: 205 	Average Loss: -5.8836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3056

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: -2.9812	Cost: 37.62s
Train Epoch: 206 [40960/90000 (45%)]	Loss: -6.3081	Cost: 9.59s
Train Epoch: 206 [81920/90000 (91%)]	Loss: -6.4585	Cost: 14.20s
Train Epoch: 206 	Average Loss: -6.0397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6123

Saving model as e206_model.pt & e206_waveforms_supplementary.hdf5
Learning rate: 0.00012729519355173254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: -2.6475	Cost: 34.03s
Train Epoch: 207 [40960/90000 (45%)]	Loss: -6.4067	Cost: 9.66s
Train Epoch: 207 [81920/90000 (91%)]	Loss: -6.1683	Cost: 19.20s
Train Epoch: 207 	Average Loss: -6.0254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5607

Learning rate: 0.00012669019893203759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: -2.4385	Cost: 35.71s
Train Epoch: 208 [40960/90000 (45%)]	Loss: -6.0458	Cost: 9.70s
Train Epoch: 208 [81920/90000 (91%)]	Loss: -6.0525	Cost: 17.17s
Train Epoch: 208 	Average Loss: -5.8704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3350

Learning rate: 0.0001260841506289897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: -2.6251	Cost: 37.37s
Train Epoch: 209 [40960/90000 (45%)]	Loss: -6.4420	Cost: 9.59s
Train Epoch: 209 [81920/90000 (91%)]	Loss: -6.2351	Cost: 15.34s
Train Epoch: 209 	Average Loss: -5.9319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4545

Learning rate: 0.00012547707256833825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: -2.7903	Cost: 36.22s
Train Epoch: 210 [40960/90000 (45%)]	Loss: -6.4922	Cost: 9.58s
Train Epoch: 210 [81920/90000 (91%)]	Loss: -6.3536	Cost: 13.36s
Train Epoch: 210 	Average Loss: -6.0786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6894

Saving model as e210_model.pt & e210_waveforms_supplementary.hdf5
Learning rate: 0.00012486898871648549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: -3.1627	Cost: 34.10s
Train Epoch: 211 [40960/90000 (45%)]	Loss: -6.4799	Cost: 10.18s
Train Epoch: 211 [81920/90000 (91%)]	Loss: -6.3504	Cost: 18.25s
Train Epoch: 211 	Average Loss: -6.0754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4448

Learning rate: 0.00012425992307954077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: -2.8549	Cost: 36.97s
Train Epoch: 212 [40960/90000 (45%)]	Loss: -6.2780	Cost: 9.91s
Train Epoch: 212 [81920/90000 (91%)]	Loss: -6.1234	Cost: 15.53s
Train Epoch: 212 	Average Loss: -5.8602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3527

Learning rate: 0.0001236498997023725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: -2.6547	Cost: 39.00s
Train Epoch: 213 [40960/90000 (45%)]	Loss: -6.3710	Cost: 9.72s
Train Epoch: 213 [81920/90000 (91%)]	Loss: -6.3182	Cost: 14.98s
Train Epoch: 213 	Average Loss: -5.9699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2857

Learning rate: 0.00012303894266765908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: -2.4456	Cost: 33.79s
Train Epoch: 214 [40960/90000 (45%)]	Loss: -5.8534	Cost: 9.95s
Train Epoch: 214 [81920/90000 (91%)]	Loss: -6.0110	Cost: 12.09s
Train Epoch: 214 	Average Loss: -5.5916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2427

Learning rate: 0.00012242707609493814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: -2.8071	Cost: 33.57s
Train Epoch: 215 [40960/90000 (45%)]	Loss: -6.4600	Cost: 9.81s
Train Epoch: 215 [81920/90000 (91%)]	Loss: -6.2431	Cost: 18.94s
Train Epoch: 215 	Average Loss: -5.8908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4554

Learning rate: 0.0001218143241396543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: -2.3026	Cost: 37.18s
Train Epoch: 216 [40960/90000 (45%)]	Loss: -6.5169	Cost: 10.02s
Train Epoch: 216 [81920/90000 (91%)]	Loss: -6.3681	Cost: 16.51s
Train Epoch: 216 	Average Loss: -6.1103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4527

Learning rate: 0.0001212007109922055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: -3.2472	Cost: 36.11s
Train Epoch: 217 [40960/90000 (45%)]	Loss: -6.3331	Cost: 9.87s
Train Epoch: 217 [81920/90000 (91%)]	Loss: -6.3948	Cost: 15.42s
Train Epoch: 217 	Average Loss: -6.1598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7546

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 0.00012058626087698816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: -2.9006	Cost: 36.65s
Train Epoch: 218 [40960/90000 (45%)]	Loss: -6.5548	Cost: 9.64s
Train Epoch: 218 [81920/90000 (91%)]	Loss: -6.5678	Cost: 13.07s
Train Epoch: 218 	Average Loss: -6.1980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7669

Saving model as e218_model.pt & e218_waveforms_supplementary.hdf5
Learning rate: 0.00011997099805144073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: -3.1846	Cost: 33.68s
Train Epoch: 219 [40960/90000 (45%)]	Loss: -6.6248	Cost: 9.73s
Train Epoch: 219 [81920/90000 (91%)]	Loss: -6.6648	Cost: 19.26s
Train Epoch: 219 	Average Loss: -6.3377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5895

Learning rate: 0.00011935494680508606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: -3.2698	Cost: 37.41s
Train Epoch: 220 [40960/90000 (45%)]	Loss: -6.6675	Cost: 9.78s
Train Epoch: 220 [81920/90000 (91%)]	Loss: -6.7244	Cost: 15.52s
Train Epoch: 220 	Average Loss: -6.4305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9321

Saving model as e220_model.pt & e220_waveforms_supplementary.hdf5
Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: -3.1268	Cost: 39.32s
Train Epoch: 221 [40960/90000 (45%)]	Loss: -6.6762	Cost: 9.62s
Train Epoch: 221 [81920/90000 (91%)]	Loss: -6.5320	Cost: 13.16s
Train Epoch: 221 	Average Loss: -6.3372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6971

Learning rate: 0.00011812057636271377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: -3.1058	Cost: 37.05s
Train Epoch: 222 [40960/90000 (45%)]	Loss: -6.7506	Cost: 9.73s
Train Epoch: 222 [81920/90000 (91%)]	Loss: -6.4249	Cost: 13.51s
Train Epoch: 222 	Average Loss: -6.3042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7189

Learning rate: 0.00011750230589752765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: -3.0238	Cost: 33.14s
Train Epoch: 223 [40960/90000 (45%)]	Loss: -6.7226	Cost: 9.71s
Train Epoch: 223 [81920/90000 (91%)]	Loss: -6.5999	Cost: 19.36s
Train Epoch: 223 	Average Loss: -6.3007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7869

Learning rate: 0.0001168833444712734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: -3.1321	Cost: 36.58s
Train Epoch: 224 [40960/90000 (45%)]	Loss: -6.8527	Cost: 9.70s
Train Epoch: 224 [81920/90000 (91%)]	Loss: -6.6832	Cost: 15.70s
Train Epoch: 224 	Average Loss: -6.3573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6293

Learning rate: 0.00011626371651948839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: -3.3215	Cost: 38.14s
Train Epoch: 225 [40960/90000 (45%)]	Loss: -6.7933	Cost: 9.58s
Train Epoch: 225 [81920/90000 (91%)]	Loss: -6.7484	Cost: 15.09s
Train Epoch: 225 	Average Loss: -6.4039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6221

Learning rate: 0.00011564344650402312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: -2.8902	Cost: 35.47s
Train Epoch: 226 [40960/90000 (45%)]	Loss: -5.8668	Cost: 9.55s
Train Epoch: 226 [81920/90000 (91%)]	Loss: -5.7579	Cost: 13.29s
Train Epoch: 226 	Average Loss: -5.8466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4115

Learning rate: 0.00011502255891207573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: -2.3548	Cost: 34.35s
Train Epoch: 227 [40960/90000 (45%)]	Loss: -6.1870	Cost: 9.63s
Train Epoch: 227 [81920/90000 (91%)]	Loss: -6.1801	Cost: 19.35s
Train Epoch: 227 	Average Loss: -6.0120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6527

Learning rate: 0.00011440107825522525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: -3.1012	Cost: 35.87s
Train Epoch: 228 [40960/90000 (45%)]	Loss: -6.3054	Cost: 9.76s
Train Epoch: 228 [81920/90000 (91%)]	Loss: -6.3626	Cost: 17.71s
Train Epoch: 228 	Average Loss: -6.2395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6755

Learning rate: 0.00011377902906846383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: -3.0011	Cost: 36.66s
Train Epoch: 229 [40960/90000 (45%)]	Loss: -6.7837	Cost: 9.74s
Train Epoch: 229 [81920/90000 (91%)]	Loss: -6.6595	Cost: 14.50s
Train Epoch: 229 	Average Loss: -6.3992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7704

Learning rate: 0.00011315643590922827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: -2.7991	Cost: 38.79s
Train Epoch: 230 [40960/90000 (45%)]	Loss: -6.4164	Cost: 9.65s
Train Epoch: 230 [81920/90000 (91%)]	Loss: -6.5375	Cost: 13.07s
Train Epoch: 230 	Average Loss: -6.2419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7935

Learning rate: 0.00011253332335643043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: -2.9963	Cost: 34.29s
Train Epoch: 231 [40960/90000 (45%)]	Loss: -6.4358	Cost: 9.98s
Train Epoch: 231 [81920/90000 (91%)]	Loss: -6.5105	Cost: 17.50s
Train Epoch: 231 	Average Loss: -6.3505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7795

Learning rate: 0.00011190971600948699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: -3.3125	Cost: 35.01s
Train Epoch: 232 [40960/90000 (45%)]	Loss: -6.6449	Cost: 9.67s
Train Epoch: 232 [81920/90000 (91%)]	Loss: -6.7031	Cost: 18.80s
Train Epoch: 232 	Average Loss: -6.3869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6936

Learning rate: 0.00011128563848734816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: -3.0830	Cost: 35.73s
Train Epoch: 233 [40960/90000 (45%)]	Loss: -6.7634	Cost: 9.97s
Train Epoch: 233 [81920/90000 (91%)]	Loss: -6.7334	Cost: 13.67s
Train Epoch: 233 	Average Loss: -6.3971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6607

Learning rate: 0.000110661115427526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: -3.0398	Cost: 37.24s
Train Epoch: 234 [40960/90000 (45%)]	Loss: -6.9047	Cost: 9.61s
Train Epoch: 234 [81920/90000 (91%)]	Loss: -6.8206	Cost: 13.33s
Train Epoch: 234 	Average Loss: -6.4654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6282

Learning rate: 0.00011003617148512149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: -3.0774	Cost: 36.46s
Train Epoch: 235 [40960/90000 (45%)]	Loss: -6.8978	Cost: 9.51s
Train Epoch: 235 [81920/90000 (91%)]	Loss: -7.0504	Cost: 16.80s
Train Epoch: 235 	Average Loss: -6.4857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7731

Learning rate: 0.00010941083133185143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: -2.6919	Cost: 35.05s
Train Epoch: 236 [40960/90000 (45%)]	Loss: -6.7565	Cost: 9.73s
Train Epoch: 236 [81920/90000 (91%)]	Loss: -6.6453	Cost: 18.37s
Train Epoch: 236 	Average Loss: -6.3541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6628

Learning rate: 0.00010878511965507434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: -2.9268	Cost: 38.11s
Train Epoch: 237 [40960/90000 (45%)]	Loss: -7.0365	Cost: 9.77s
Train Epoch: 237 [81920/90000 (91%)]	Loss: -6.6483	Cost: 15.97s
Train Epoch: 237 	Average Loss: -6.4283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5786

Learning rate: 0.00010815906115681577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: -2.2787	Cost: 35.58s
Train Epoch: 238 [40960/90000 (45%)]	Loss: -6.5226	Cost: 9.66s
Train Epoch: 238 [81920/90000 (91%)]	Loss: -6.7507	Cost: 14.84s
Train Epoch: 238 	Average Loss: -6.2996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8509

Learning rate: 0.00010753268055279328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: -3.1099	Cost: 33.92s
Train Epoch: 239 [40960/90000 (45%)]	Loss: -7.0207	Cost: 9.60s
Train Epoch: 239 [81920/90000 (91%)]	Loss: -6.9280	Cost: 12.89s
Train Epoch: 239 	Average Loss: -6.5724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0222

Saving model as e239_model.pt & e239_waveforms_supplementary.hdf5
Learning rate: 0.0001069060025714406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: -2.9788	Cost: 34.98s
Train Epoch: 240 [40960/90000 (45%)]	Loss: -7.0596	Cost: 9.92s
Train Epoch: 240 [81920/90000 (91%)]	Loss: -7.0076	Cost: 18.45s
Train Epoch: 240 	Average Loss: -6.6380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9590

Learning rate: 0.00010627905195293134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: -3.2490	Cost: 36.09s
Train Epoch: 241 [40960/90000 (45%)]	Loss: -6.9608	Cost: 9.96s
Train Epoch: 241 [81920/90000 (91%)]	Loss: -6.9143	Cost: 17.62s
Train Epoch: 241 	Average Loss: -6.7054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8602

Learning rate: 0.00010565185344820243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: -3.0785	Cost: 36.40s
Train Epoch: 242 [40960/90000 (45%)]	Loss: -7.1943	Cost: 9.59s
Train Epoch: 242 [81920/90000 (91%)]	Loss: -6.9929	Cost: 13.93s
Train Epoch: 242 	Average Loss: -6.7682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7939

Learning rate: 0.00010502443181797694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: -2.8612	Cost: 38.86s
Train Epoch: 243 [40960/90000 (45%)]	Loss: -7.3210	Cost: 9.58s
Train Epoch: 243 [81920/90000 (91%)]	Loss: -7.0713	Cost: 14.52s
Train Epoch: 243 	Average Loss: -6.7168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0206

Learning rate: 0.00010439681183178646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: -3.4404	Cost: 34.89s
Train Epoch: 244 [40960/90000 (45%)]	Loss: -7.3172	Cost: 9.89s
Train Epoch: 244 [81920/90000 (91%)]	Loss: -7.3421	Cost: 17.52s
Train Epoch: 244 	Average Loss: -6.8943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9671

Learning rate: 0.00010376901826699342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: -3.4086	Cost: 35.96s
Train Epoch: 245 [40960/90000 (45%)]	Loss: -7.1418	Cost: 9.67s
Train Epoch: 245 [81920/90000 (91%)]	Loss: -7.2177	Cost: 18.22s
Train Epoch: 245 	Average Loss: -6.8880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9463

Learning rate: 0.0001031410759078128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: -3.2139	Cost: 40.13s
Train Epoch: 246 [40960/90000 (45%)]	Loss: -7.2039	Cost: 10.19s
Train Epoch: 246 [81920/90000 (91%)]	Loss: -7.3927	Cost: 15.32s
Train Epoch: 246 	Average Loss: -6.9037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1192

Saving model as e246_model.pt & e246_waveforms_supplementary.hdf5
Learning rate: 0.00010251300954433372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: -3.7131	Cost: 38.08s
Train Epoch: 247 [40960/90000 (45%)]	Loss: -7.4235	Cost: 9.59s
Train Epoch: 247 [81920/90000 (91%)]	Loss: -7.2179	Cost: 13.34s
Train Epoch: 247 	Average Loss: -7.0013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9938

Learning rate: 0.0001018848439715408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: -2.9033	Cost: 34.38s
Train Epoch: 248 [40960/90000 (45%)]	Loss: -7.2355	Cost: 9.78s
Train Epoch: 248 [81920/90000 (91%)]	Loss: -6.9855	Cost: 19.05s
Train Epoch: 248 	Average Loss: -6.7630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0609

Learning rate: 0.00010125660398833524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: -3.2865	Cost: 35.87s
Train Epoch: 249 [40960/90000 (45%)]	Loss: -7.3243	Cost: 9.80s
Train Epoch: 249 [81920/90000 (91%)]	Loss: -7.2127	Cost: 16.96s
Train Epoch: 249 	Average Loss: -6.9678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9917

Learning rate: 0.00010062831439655587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: -3.8988	Cost: 39.09s
Train Epoch: 250 [40960/90000 (45%)]	Loss: -7.3604	Cost: 9.66s
Train Epoch: 250 [81920/90000 (91%)]	Loss: -7.3292	Cost: 15.21s
Train Epoch: 250 	Average Loss: -6.9426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2620

Saving model as e250_model.pt & e250_waveforms_supplementary.hdf5
Learning rate: 9.999999999999996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: -3.8998	Cost: 35.48s
Train Epoch: 251 [40960/90000 (45%)]	Loss: -7.1778	Cost: 9.59s
Train Epoch: 251 [81920/90000 (91%)]	Loss: -7.4047	Cost: 13.56s
Train Epoch: 251 	Average Loss: -7.0303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1855

Learning rate: 9.937168560344407e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: -3.1435	Cost: 33.61s
Train Epoch: 252 [40960/90000 (45%)]	Loss: -7.3584	Cost: 9.78s
Train Epoch: 252 [81920/90000 (91%)]	Loss: -7.3523	Cost: 19.45s
Train Epoch: 252 	Average Loss: -7.0283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0826

Learning rate: 9.87433960116647e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: -3.2565	Cost: 39.96s
Train Epoch: 253 [40960/90000 (45%)]	Loss: -7.2857	Cost: 9.89s
Train Epoch: 253 [81920/90000 (91%)]	Loss: -7.2659	Cost: 14.66s
Train Epoch: 253 	Average Loss: -7.0068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1812

Learning rate: 9.811515602845915e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: -3.2170	Cost: 38.83s
Train Epoch: 254 [40960/90000 (45%)]	Loss: -7.4611	Cost: 9.68s
Train Epoch: 254 [81920/90000 (91%)]	Loss: -7.0325	Cost: 15.04s
Train Epoch: 254 	Average Loss: -7.0167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9832

Learning rate: 9.748699045566624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: -3.2472	Cost: 36.23s
Train Epoch: 255 [40960/90000 (45%)]	Loss: -7.3536	Cost: 9.50s
Train Epoch: 255 [81920/90000 (91%)]	Loss: -7.2867	Cost: 14.78s
Train Epoch: 255 	Average Loss: -6.9656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2220

Learning rate: 9.685892409218716e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: -3.5012	Cost: 33.03s
Train Epoch: 256 [40960/90000 (45%)]	Loss: -7.4951	Cost: 9.69s
Train Epoch: 256 [81920/90000 (91%)]	Loss: -7.3632	Cost: 18.90s
Train Epoch: 256 	Average Loss: -7.1311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3006

Saving model as e256_model.pt & e256_waveforms_supplementary.hdf5
Learning rate: 9.623098173300653e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: -3.6765	Cost: 36.67s
Train Epoch: 257 [40960/90000 (45%)]	Loss: -7.4460	Cost: 9.70s
Train Epoch: 257 [81920/90000 (91%)]	Loss: -7.4573	Cost: 14.90s
Train Epoch: 257 	Average Loss: -7.2231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3510

Saving model as e257_model.pt & e257_waveforms_supplementary.hdf5
Learning rate: 9.560318816821353e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: -3.9547	Cost: 38.80s
Train Epoch: 258 [40960/90000 (45%)]	Loss: -7.5134	Cost: 9.89s
Train Epoch: 258 [81920/90000 (91%)]	Loss: -7.5266	Cost: 13.30s
Train Epoch: 258 	Average Loss: -7.3398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2536

Learning rate: 9.497556818202306e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: -3.9440	Cost: 36.35s
Train Epoch: 259 [40960/90000 (45%)]	Loss: -7.5928	Cost: 10.21s
Train Epoch: 259 [81920/90000 (91%)]	Loss: -7.4344	Cost: 12.04s
Train Epoch: 259 	Average Loss: -7.2874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3648

Saving model as e259_model.pt & e259_waveforms_supplementary.hdf5
Learning rate: 9.434814655179755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: -3.3389	Cost: 32.95s
Train Epoch: 260 [40960/90000 (45%)]	Loss: -7.5520	Cost: 9.68s
Train Epoch: 260 [81920/90000 (91%)]	Loss: -7.5361	Cost: 18.46s
Train Epoch: 260 	Average Loss: -7.2839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3369

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: -3.6328	Cost: 41.31s
Train Epoch: 261 [40960/90000 (45%)]	Loss: -7.6508	Cost: 9.82s
Train Epoch: 261 [81920/90000 (91%)]	Loss: -7.6386	Cost: 14.70s
Train Epoch: 261 	Average Loss: -7.3773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1892

Learning rate: 9.309399742855944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: -3.4534	Cost: 38.62s
Train Epoch: 262 [40960/90000 (45%)]	Loss: -7.5972	Cost: 9.73s
Train Epoch: 262 [81920/90000 (91%)]	Loss: -7.5125	Cost: 15.52s
Train Epoch: 262 	Average Loss: -7.2649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1346

Learning rate: 9.246731944720672e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: -4.0431	Cost: 37.19s
Train Epoch: 263 [40960/90000 (45%)]	Loss: -7.6484	Cost: 9.56s
Train Epoch: 263 [81920/90000 (91%)]	Loss: -7.9090	Cost: 16.40s
Train Epoch: 263 	Average Loss: -7.3995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2516

Learning rate: 9.184093884318424e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: -4.0490	Cost: 34.94s
Train Epoch: 264 [40960/90000 (45%)]	Loss: -7.8810	Cost: 9.71s
Train Epoch: 264 [81920/90000 (91%)]	Loss: -7.7564	Cost: 17.50s
Train Epoch: 264 	Average Loss: -7.4477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2937

Learning rate: 9.121488034492569e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: -3.7284	Cost: 35.43s
Train Epoch: 265 [40960/90000 (45%)]	Loss: -7.7972	Cost: 9.78s
Train Epoch: 265 [81920/90000 (91%)]	Loss: -7.4502	Cost: 13.84s
Train Epoch: 265 	Average Loss: -7.2454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2812

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: -3.6781	Cost: 35.11s
Train Epoch: 266 [40960/90000 (45%)]	Loss: -7.5945	Cost: 9.87s
Train Epoch: 266 [81920/90000 (91%)]	Loss: -7.6624	Cost: 13.46s
Train Epoch: 266 	Average Loss: -7.3832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0902

Learning rate: 8.996382851487852e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: -3.4479	Cost: 38.19s
Train Epoch: 267 [40960/90000 (45%)]	Loss: -7.8452	Cost: 9.60s
Train Epoch: 267 [81920/90000 (91%)]	Loss: -7.9735	Cost: 13.61s
Train Epoch: 267 	Average Loss: -7.3877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5184

Saving model as e267_model.pt & e267_waveforms_supplementary.hdf5
Learning rate: 8.9338884572474e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: -3.8170	Cost: 32.88s
Train Epoch: 268 [40960/90000 (45%)]	Loss: -7.7545	Cost: 9.74s
Train Epoch: 268 [81920/90000 (91%)]	Loss: -7.7227	Cost: 19.55s
Train Epoch: 268 	Average Loss: -7.4477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2755

Learning rate: 8.871436151265182e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: -3.7176	Cost: 36.02s
Train Epoch: 269 [40960/90000 (45%)]	Loss: -8.0474	Cost: 9.88s
Train Epoch: 269 [81920/90000 (91%)]	Loss: -8.0196	Cost: 17.23s
Train Epoch: 269 	Average Loss: -7.5894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4179

Learning rate: 8.809028399051304e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: -3.5914	Cost: 38.89s
Train Epoch: 270 [40960/90000 (45%)]	Loss: -8.0810	Cost: 9.61s
Train Epoch: 270 [81920/90000 (91%)]	Loss: -7.6248	Cost: 17.06s
Train Epoch: 270 	Average Loss: -7.5675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2768

Learning rate: 8.746667664356958e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: -3.8833	Cost: 33.66s
Train Epoch: 271 [40960/90000 (45%)]	Loss: -7.8555	Cost: 9.59s
Train Epoch: 271 [81920/90000 (91%)]	Loss: -7.8322	Cost: 12.41s
Train Epoch: 271 	Average Loss: -7.5737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4303

Learning rate: 8.684356409077174e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: -3.8549	Cost: 34.68s
Train Epoch: 272 [40960/90000 (45%)]	Loss: -8.0703	Cost: 10.04s
Train Epoch: 272 [81920/90000 (91%)]	Loss: -8.1157	Cost: 18.03s
Train Epoch: 272 	Average Loss: -7.6081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5821

Saving model as e272_model.pt & e272_waveforms_supplementary.hdf5
Learning rate: 8.622097093153619e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: -3.6917	Cost: 36.68s
Train Epoch: 273 [40960/90000 (45%)]	Loss: -8.2605	Cost: 10.04s
Train Epoch: 273 [81920/90000 (91%)]	Loss: -8.1197	Cost: 18.59s
Train Epoch: 273 	Average Loss: -7.7113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4684

Learning rate: 8.559892174477476e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: -4.0785	Cost: 37.90s
Train Epoch: 274 [40960/90000 (45%)]	Loss: -8.0082	Cost: 9.72s
Train Epoch: 274 [81920/90000 (91%)]	Loss: -7.9389	Cost: 15.46s
Train Epoch: 274 	Average Loss: -7.7131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4242

Learning rate: 8.497744108792427e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: -3.7700	Cost: 39.46s
Train Epoch: 275 [40960/90000 (45%)]	Loss: -7.9972	Cost: 9.55s
Train Epoch: 275 [81920/90000 (91%)]	Loss: -8.0603	Cost: 14.47s
Train Epoch: 275 	Average Loss: -7.7374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4454

Learning rate: 8.435655349597689e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: -3.9548	Cost: 34.66s
Train Epoch: 276 [40960/90000 (45%)]	Loss: -7.9378	Cost: 9.64s
Train Epoch: 276 [81920/90000 (91%)]	Loss: -8.0049	Cost: 18.88s
Train Epoch: 276 	Average Loss: -7.6701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8077

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Learning rate: 8.373628348051162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: -4.1133	Cost: 37.16s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -8.2179	Cost: 9.88s
Train Epoch: 277 [81920/90000 (91%)]	Loss: -7.9466	Cost: 16.07s
Train Epoch: 277 	Average Loss: -7.7344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5659

Learning rate: 8.311665552872659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: -4.0071	Cost: 38.97s
Train Epoch: 278 [40960/90000 (45%)]	Loss: -8.1670	Cost: 9.76s
Train Epoch: 278 [81920/90000 (91%)]	Loss: -7.9454	Cost: 13.12s
Train Epoch: 278 	Average Loss: -7.7840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4397

Learning rate: 8.249769410247239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: -3.6535	Cost: 35.73s
Train Epoch: 279 [40960/90000 (45%)]	Loss: -8.1448	Cost: 9.66s
Train Epoch: 279 [81920/90000 (91%)]	Loss: -8.0454	Cost: 13.98s
Train Epoch: 279 	Average Loss: -7.6028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3342

Learning rate: 8.187942363728625e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: -3.6139	Cost: 34.94s
Train Epoch: 280 [40960/90000 (45%)]	Loss: -8.0056	Cost: 9.74s
Train Epoch: 280 [81920/90000 (91%)]	Loss: -8.2086	Cost: 21.49s
Train Epoch: 280 	Average Loss: -7.7530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5898

Learning rate: 8.126186854142752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: -4.2787	Cost: 36.92s
Train Epoch: 281 [40960/90000 (45%)]	Loss: -8.3292	Cost: 9.88s
Train Epoch: 281 [81920/90000 (91%)]	Loss: -8.0739	Cost: 15.65s
Train Epoch: 281 	Average Loss: -7.7612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6236

Learning rate: 8.064505319491398e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: -3.4036	Cost: 38.29s
Train Epoch: 282 [40960/90000 (45%)]	Loss: -8.2377	Cost: 9.63s
Train Epoch: 282 [81920/90000 (91%)]	Loss: -8.2561	Cost: 15.86s
Train Epoch: 282 	Average Loss: -7.7411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5434

Learning rate: 8.002900194855929e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: -3.8410	Cost: 37.29s
Train Epoch: 283 [40960/90000 (45%)]	Loss: -8.1828	Cost: 9.72s
Train Epoch: 283 [81920/90000 (91%)]	Loss: -8.3095	Cost: 13.08s
Train Epoch: 283 	Average Loss: -7.9128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6415

Learning rate: 7.941373912301183e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: -4.5316	Cost: 34.01s
Train Epoch: 284 [40960/90000 (45%)]	Loss: -8.3445	Cost: 9.74s
Train Epoch: 284 [81920/90000 (91%)]	Loss: -7.9257	Cost: 18.19s
Train Epoch: 284 	Average Loss: -7.8802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6242

Learning rate: 7.879928900779452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: -4.2121	Cost: 36.45s
Train Epoch: 285 [40960/90000 (45%)]	Loss: -8.3730	Cost: 9.94s
Train Epoch: 285 [81920/90000 (91%)]	Loss: -8.2352	Cost: 16.29s
Train Epoch: 285 	Average Loss: -7.8863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6411

Learning rate: 7.818567586034573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: -3.7064	Cost: 35.76s
Train Epoch: 286 [40960/90000 (45%)]	Loss: -8.2779	Cost: 9.65s
Train Epoch: 286 [81920/90000 (91%)]	Loss: -7.8927	Cost: 14.99s
Train Epoch: 286 	Average Loss: -7.8829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5655

Learning rate: 7.757292390506185e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: -3.6199	Cost: 36.85s
Train Epoch: 287 [40960/90000 (45%)]	Loss: -8.3002	Cost: 9.95s
Train Epoch: 287 [81920/90000 (91%)]	Loss: -8.1204	Cost: 13.27s
Train Epoch: 287 	Average Loss: -7.9095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6734

Learning rate: 7.696105733234094e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: -3.9683	Cost: 33.06s
Train Epoch: 288 [40960/90000 (45%)]	Loss: -8.4184	Cost: 9.90s
Train Epoch: 288 [81920/90000 (91%)]	Loss: -8.4271	Cost: 18.40s
Train Epoch: 288 	Average Loss: -8.0072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7743

Learning rate: 7.635010029762752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: -4.2134	Cost: 35.65s
Train Epoch: 289 [40960/90000 (45%)]	Loss: -8.4665	Cost: 10.00s
Train Epoch: 289 [81920/90000 (91%)]	Loss: -8.3872	Cost: 15.25s
Train Epoch: 289 	Average Loss: -8.0606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6619

Learning rate: 7.574007692045924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: -4.3019	Cost: 38.56s
Train Epoch: 290 [40960/90000 (45%)]	Loss: -8.5983	Cost: 9.52s
Train Epoch: 290 [81920/90000 (91%)]	Loss: -8.3648	Cost: 16.06s
Train Epoch: 290 	Average Loss: -8.0565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7387

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: -3.9306	Cost: 37.44s
Train Epoch: 291 [40960/90000 (45%)]	Loss: -8.5302	Cost: 9.64s
Train Epoch: 291 [81920/90000 (91%)]	Loss: -8.3307	Cost: 13.25s
Train Epoch: 291 	Average Loss: -8.0618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6962

Learning rate: 7.452292743166178e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: -3.7805	Cost: 34.19s
Train Epoch: 292 [40960/90000 (45%)]	Loss: -8.4411	Cost: 9.70s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -8.5540	Cost: 18.54s
Train Epoch: 292 	Average Loss: -8.0770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5975

Learning rate: 7.391584937101029e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: -3.8710	Cost: 35.82s
Train Epoch: 293 [40960/90000 (45%)]	Loss: -8.6029	Cost: 9.72s
Train Epoch: 293 [81920/90000 (91%)]	Loss: -8.3407	Cost: 20.00s
Train Epoch: 293 	Average Loss: -8.0781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7351

Learning rate: 7.330980106796245e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: -4.4215	Cost: 38.28s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -8.5158	Cost: 10.18s
Train Epoch: 294 [81920/90000 (91%)]	Loss: -8.4382	Cost: 14.94s
Train Epoch: 294 	Average Loss: -8.0560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5315

Learning rate: 7.270480644826745e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: -4.1720	Cost: 37.54s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -8.5080	Cost: 9.60s
Train Epoch: 295 [81920/90000 (91%)]	Loss: -8.4375	Cost: 13.50s
Train Epoch: 295 	Average Loss: -8.0594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7926

Learning rate: 7.210088939607704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: -4.0541	Cost: 35.29s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -8.3684	Cost: 9.56s
Train Epoch: 296 [81920/90000 (91%)]	Loss: -8.1222	Cost: 17.68s
Train Epoch: 296 	Average Loss: -8.0483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5846

Learning rate: 7.149807375300236e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: -3.5431	Cost: 36.07s
Train Epoch: 297 [40960/90000 (45%)]	Loss: -8.5129	Cost: 9.69s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -8.2686	Cost: 17.73s
Train Epoch: 297 	Average Loss: -7.9459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7659

Learning rate: 7.08963833171728e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: -3.8468	Cost: 38.48s
Train Epoch: 298 [40960/90000 (45%)]	Loss: -8.4977	Cost: 9.65s
Train Epoch: 298 [81920/90000 (91%)]	Loss: -8.2602	Cost: 14.37s
Train Epoch: 298 	Average Loss: -7.9027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6931

Learning rate: 7.029584184229648e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: -4.3137	Cost: 38.33s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -8.3505	Cost: 9.69s
Train Epoch: 299 [81920/90000 (91%)]	Loss: -8.3479	Cost: 13.50s
Train Epoch: 299 	Average Loss: -7.9897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8528

Saving model as e299_model.pt & e299_waveforms_supplementary.hdf5
Learning rate: 6.969647303672259e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: -3.6693	Cost: 34.24s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -8.6141	Cost: 9.60s
Train Epoch: 300 [81920/90000 (91%)]	Loss: -8.4583	Cost: 14.45s
Train Epoch: 300 	Average Loss: -8.1184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8887

Saving model as e300_model.pt & e300_waveforms_supplementary.hdf5
Learning rate: 6.909830056250523e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: -4.3703	Cost: 34.07s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -8.4686	Cost: 9.73s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -8.4467	Cost: 18.29s
Train Epoch: 301 	Average Loss: -8.1891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8640

Learning rate: 6.850134803446949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: -4.3254	Cost: 36.81s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -8.7198	Cost: 9.75s
Train Epoch: 302 [81920/90000 (91%)]	Loss: -8.5125	Cost: 14.93s
Train Epoch: 302 	Average Loss: -8.2425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8523

Learning rate: 6.790563901927903e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: -4.2211	Cost: 35.07s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -8.7824	Cost: 9.61s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -8.5001	Cost: 13.48s
Train Epoch: 303 	Average Loss: -8.2742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9826

Saving model as e303_model.pt & e303_waveforms_supplementary.hdf5
Learning rate: 6.731119703450573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: -4.3035	Cost: 33.51s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -8.6349	Cost: 9.57s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -8.6752	Cost: 12.39s
Train Epoch: 304 	Average Loss: -8.3671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9498

Learning rate: 6.67180455477013e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: -4.5350	Cost: 35.29s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -8.8930	Cost: 9.67s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -8.7880	Cost: 18.96s
Train Epoch: 305 	Average Loss: -8.4238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9802

Learning rate: 6.612620797547083e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: -4.4709	Cost: 36.09s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -9.0412	Cost: 9.74s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -8.4876	Cost: 18.71s
Train Epoch: 306 	Average Loss: -8.3807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6800

Learning rate: 6.553570768254825e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: -3.9005	Cost: 38.34s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -8.6387	Cost: 9.89s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -8.6434	Cost: 15.74s
Train Epoch: 307 	Average Loss: -8.2227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6572

Learning rate: 6.494656798087406e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: -3.9493	Cost: 35.17s
Train Epoch: 308 [40960/90000 (45%)]	Loss: -8.7332	Cost: 9.62s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -8.7068	Cost: 12.94s
Train Epoch: 308 	Average Loss: -8.3637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8965

Learning rate: 6.435881212867491e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: -4.4042	Cost: 33.45s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -8.7371	Cost: 9.70s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -8.3286	Cost: 17.76s
Train Epoch: 309 	Average Loss: -8.3903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8885

Learning rate: 6.377246332954541e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: -4.3610	Cost: 35.14s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -8.7139	Cost: 9.68s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -8.7292	Cost: 17.98s
Train Epoch: 310 	Average Loss: -8.2778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5999

Learning rate: 6.318754473153218e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: -4.3854	Cost: 36.85s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -8.7640	Cost: 9.78s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -8.8810	Cost: 13.61s
Train Epoch: 311 	Average Loss: -8.4459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0617

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Learning rate: 6.260407942621994e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: -4.5630	Cost: 37.76s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -8.8424	Cost: 9.73s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -8.9366	Cost: 13.94s
Train Epoch: 312 	Average Loss: -8.5879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9691

Learning rate: 6.202209044781987e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: -4.6620	Cost: 35.52s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -9.1844	Cost: 9.92s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -8.8593	Cost: 13.43s
Train Epoch: 313 	Average Loss: -8.6435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2695

Saving model as e313_model.pt & e313_waveforms_supplementary.hdf5
Learning rate: 6.144160077226032e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: -4.5307	Cost: 32.82s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -8.9483	Cost: 9.67s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -8.8467	Cost: 18.45s
Train Epoch: 314 	Average Loss: -8.6204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1106

Learning rate: 6.0862633316279744e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: -4.5272	Cost: 36.31s
Train Epoch: 315 [40960/90000 (45%)]	Loss: -9.0373	Cost: 9.81s
Train Epoch: 315 [81920/90000 (91%)]	Loss: -8.9345	Cost: 15.43s
Train Epoch: 315 	Average Loss: -8.6411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1227

Learning rate: 6.028521093652189e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: -4.4686	Cost: 36.65s
Train Epoch: 316 [40960/90000 (45%)]	Loss: -9.2534	Cost: 9.68s
Train Epoch: 316 [81920/90000 (91%)]	Loss: -9.0637	Cost: 15.17s
Train Epoch: 316 	Average Loss: -8.6834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0761

Learning rate: 5.970935642863369e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: -4.7642	Cost: 37.20s
Train Epoch: 317 [40960/90000 (45%)]	Loss: -9.1620	Cost: 9.60s
Train Epoch: 317 [81920/90000 (91%)]	Loss: -9.1006	Cost: 13.96s
Train Epoch: 317 	Average Loss: -8.7110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1449

Learning rate: 5.9135092526365064e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: -4.2832	Cost: 35.38s
Train Epoch: 318 [40960/90000 (45%)]	Loss: -9.0002	Cost: 9.89s
Train Epoch: 318 [81920/90000 (91%)]	Loss: -8.8957	Cost: 17.65s
Train Epoch: 318 	Average Loss: -8.5833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1843

Learning rate: 5.8562441900671545e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: -4.9525	Cost: 35.14s
Train Epoch: 319 [40960/90000 (45%)]	Loss: -9.0986	Cost: 9.68s
Train Epoch: 319 [81920/90000 (91%)]	Loss: -9.1420	Cost: 19.79s
Train Epoch: 319 	Average Loss: -8.7417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1471

Learning rate: 5.799142715881933e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: -4.5288	Cost: 36.36s
Train Epoch: 320 [40960/90000 (45%)]	Loss: -9.1551	Cost: 9.70s
Train Epoch: 320 [81920/90000 (91%)]	Loss: -9.2768	Cost: 13.24s
Train Epoch: 320 	Average Loss: -8.7406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1426

Learning rate: 5.742207084349269e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: -4.4054	Cost: 34.27s
Train Epoch: 321 [40960/90000 (45%)]	Loss: -9.4256	Cost: 9.65s
Train Epoch: 321 [81920/90000 (91%)]	Loss: -9.1477	Cost: 12.85s
Train Epoch: 321 	Average Loss: -8.8339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0880

Learning rate: 5.68543954319041e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: -4.7249	Cost: 36.45s
Train Epoch: 322 [40960/90000 (45%)]	Loss: -9.2655	Cost: 9.95s
Train Epoch: 322 [81920/90000 (91%)]	Loss: -9.3941	Cost: 15.40s
Train Epoch: 322 	Average Loss: -8.8196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3249

Saving model as e322_model.pt & e322_waveforms_supplementary.hdf5
Learning rate: 5.62884233349067e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: -4.9119	Cost: 35.95s
Train Epoch: 323 [40960/90000 (45%)]	Loss: -9.4534	Cost: 9.81s
Train Epoch: 323 [81920/90000 (91%)]	Loss: -9.1495	Cost: 18.20s
Train Epoch: 323 	Average Loss: -8.9637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2492

Learning rate: 5.572417689610984e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: -4.6820	Cost: 37.28s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -9.3069	Cost: 9.82s
Train Epoch: 324 [81920/90000 (91%)]	Loss: -9.2399	Cost: 14.57s
Train Epoch: 324 	Average Loss: -8.8639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2128

Learning rate: 5.516167839099677e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: -3.9958	Cost: 37.03s
Train Epoch: 325 [40960/90000 (45%)]	Loss: -9.4748	Cost: 9.66s
Train Epoch: 325 [81920/90000 (91%)]	Loss: -9.2216	Cost: 14.00s
Train Epoch: 325 	Average Loss: -8.8906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1778

Learning rate: 5.46009500260453e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: -4.8713	Cost: 35.22s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -9.2339	Cost: 10.22s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -9.3171	Cost: 17.23s
Train Epoch: 326 	Average Loss: -8.9651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5199

Saving model as e326_model.pt & e326_waveforms_supplementary.hdf5
Learning rate: 5.4042013937851194e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: -4.4691	Cost: 35.94s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -9.2925	Cost: 9.66s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -9.3627	Cost: 17.96s
Train Epoch: 327 	Average Loss: -8.8822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2602

Learning rate: 5.3484892192254136e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: -4.2423	Cost: 37.06s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -9.3116	Cost: 10.11s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -9.4443	Cost: 15.00s
Train Epoch: 328 	Average Loss: -8.9497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2316

Learning rate: 5.292960678346675e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: -3.9840	Cost: 35.31s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -9.2818	Cost: 9.68s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -9.3070	Cost: 12.28s
Train Epoch: 329 	Average Loss: -8.8597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2973

Learning rate: 5.237617963320605e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: -4.5639	Cost: 35.88s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -9.4300	Cost: 9.59s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -9.4870	Cost: 18.23s
Train Epoch: 330 	Average Loss: -8.9499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1884

Learning rate: 5.182463258982848e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: -5.1342	Cost: 36.99s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -9.5227	Cost: 9.62s
Train Epoch: 331 [81920/90000 (91%)]	Loss: -9.3545	Cost: 18.68s
Train Epoch: 331 	Average Loss: -9.0502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2823

Learning rate: 5.127498742746677e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: -4.8376	Cost: 37.48s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -9.4198	Cost: 9.73s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -9.1892	Cost: 14.96s
Train Epoch: 332 	Average Loss: -8.9947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3532

Learning rate: 5.07272658451708e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: -4.9077	Cost: 35.87s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -9.4175	Cost: 9.64s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -9.3568	Cost: 14.17s
Train Epoch: 333 	Average Loss: -9.0631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3847

Learning rate: 5.01814894660509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: -4.4389	Cost: 33.66s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -9.5955	Cost: 9.62s
Train Epoch: 334 [81920/90000 (91%)]	Loss: -9.3714	Cost: 17.09s
Train Epoch: 334 	Average Loss: -9.1288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2774

Learning rate: 4.96376798364239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: -4.5851	Cost: 35.90s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -9.6285	Cost: 9.68s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -9.5211	Cost: 18.14s
Train Epoch: 335 	Average Loss: -9.1236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3333

Learning rate: 4.9095858424962844e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: -4.9044	Cost: 38.72s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -9.7459	Cost: 9.66s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -9.4191	Cost: 15.65s
Train Epoch: 336 	Average Loss: -9.2337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3529

Learning rate: 4.855604662184932e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: -4.6868	Cost: 35.01s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -9.5213	Cost: 9.53s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -9.4711	Cost: 12.58s
Train Epoch: 337 	Average Loss: -9.1503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3872

Learning rate: 4.801826573792905e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: -4.7099	Cost: 35.67s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -9.6864	Cost: 9.74s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -9.6423	Cost: 18.68s
Train Epoch: 338 	Average Loss: -9.2286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4992

Learning rate: 4.748253700387039e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: -4.8822	Cost: 36.71s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -9.7717	Cost: 9.74s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -9.7160	Cost: 16.99s
Train Epoch: 339 	Average Loss: -9.2589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5770

Saving model as e339_model.pt & e339_waveforms_supplementary.hdf5
Learning rate: 4.694888156932659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: -4.3572	Cost: 37.40s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -9.6507	Cost: 9.62s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -9.6181	Cost: 14.48s
Train Epoch: 340 	Average Loss: -9.2526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3509

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: -4.7171	Cost: 36.80s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -9.8738	Cost: 9.59s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -9.5564	Cost: 14.26s
Train Epoch: 341 	Average Loss: -9.2967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5838

Saving model as e341_model.pt & e341_waveforms_supplementary.hdf5
Learning rate: 4.5887874787312395e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: -4.7667	Cost: 34.57s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -9.8951	Cost: 9.98s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -9.6042	Cost: 18.84s
Train Epoch: 342 	Average Loss: -9.3498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6327

Saving model as e342_model.pt & e342_waveforms_supplementary.hdf5
Learning rate: 4.536056532657307e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: -4.9028	Cost: 37.62s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -9.8253	Cost: 9.90s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -9.7445	Cost: 17.74s
Train Epoch: 343 	Average Loss: -9.4095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4459

Learning rate: 4.4835412937156955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: -5.1522	Cost: 36.00s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -9.7734	Cost: 9.68s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -9.8468	Cost: 15.03s
Train Epoch: 344 	Average Loss: -9.4101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5739

Learning rate: 4.431243835118117e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: -4.8566	Cost: 35.76s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -9.8872	Cost: 9.77s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -9.7774	Cost: 13.48s
Train Epoch: 345 	Average Loss: -9.3812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5050

Learning rate: 4.379166221478691e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: -4.8419	Cost: 34.71s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -9.7613	Cost: 9.78s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -9.7109	Cost: 18.84s
Train Epoch: 346 	Average Loss: -9.3412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5759

Learning rate: 4.327310508732435e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: -4.9421	Cost: 34.99s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -9.9631	Cost: 9.70s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -9.7079	Cost: 17.43s
Train Epoch: 347 	Average Loss: -9.3756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6400

Saving model as e347_model.pt & e347_waveforms_supplementary.hdf5
Learning rate: 4.275678744054088e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: -4.9526	Cost: 38.23s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -9.8352	Cost: 9.61s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -10.0171	Cost: 16.17s
Train Epoch: 348 	Average Loss: -9.4166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6969

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Learning rate: 4.224272965777324e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: -4.8013	Cost: 37.14s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -9.8729	Cost: 9.63s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -9.9648	Cost: 13.39s
Train Epoch: 349 	Average Loss: -9.4641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6503

Learning rate: 4.173095203314239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: -5.1225	Cost: 34.60s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -10.0485	Cost: 9.87s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -9.9521	Cost: 19.25s
Train Epoch: 350 	Average Loss: -9.5749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5858

Learning rate: 4.1221474770752684e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: -4.8266	Cost: 36.36s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -9.9926	Cost: 9.83s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -9.9837	Cost: 16.59s
Train Epoch: 351 	Average Loss: -9.5594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7044

Saving model as e351_model.pt & e351_waveforms_supplementary.hdf5
Learning rate: 4.071431798389406e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: -5.1158	Cost: 39.25s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -9.9938	Cost: 9.66s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -9.8282	Cost: 13.83s
Train Epoch: 352 	Average Loss: -9.5856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7738

Saving model as e352_model.pt & e352_waveforms_supplementary.hdf5
Learning rate: 4.020950169424814e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: -4.9592	Cost: 33.85s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -9.9893	Cost: 9.57s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -10.0514	Cost: 14.09s
Train Epoch: 353 	Average Loss: -9.5884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5466

Learning rate: 3.970704583109751e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: -4.6767	Cost: 33.19s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -9.9110	Cost: 9.77s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -9.8462	Cost: 19.48s
Train Epoch: 354 	Average Loss: -9.4870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6326

Learning rate: 3.920697023053944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: -4.2346	Cost: 35.68s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -10.0483	Cost: 9.82s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -9.8875	Cost: 16.32s
Train Epoch: 355 	Average Loss: -9.5084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6375

Learning rate: 3.870929463470237e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: -5.0596	Cost: 38.67s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -10.0671	Cost: 10.07s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -9.8331	Cost: 13.05s
Train Epoch: 356 	Average Loss: -9.5695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7670

Learning rate: 3.821403869096654e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: -5.3819	Cost: 35.97s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -9.8534	Cost: 9.61s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -9.8043	Cost: 13.14s
Train Epoch: 357 	Average Loss: -9.5854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7211

Learning rate: 3.772122195118876e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: -5.1497	Cost: 34.63s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -9.9920	Cost: 9.74s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -10.2517	Cost: 18.25s
Train Epoch: 358 	Average Loss: -9.7235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7839

Saving model as e358_model.pt & e358_waveforms_supplementary.hdf5
Learning rate: 3.723086387092996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: -5.0734	Cost: 36.03s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -10.0437	Cost: 9.76s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -9.9147	Cost: 16.40s
Train Epoch: 359 	Average Loss: -9.6961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6985

Learning rate: 3.674298380868755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: -5.0075	Cost: 37.65s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -10.2339	Cost: 10.01s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -9.8776	Cost: 15.57s
Train Epoch: 360 	Average Loss: -9.6682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6472

Learning rate: 3.6257601025131026e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: -5.5653	Cost: 37.90s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -10.0760	Cost: 9.84s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -10.0120	Cost: 13.65s
Train Epoch: 361 	Average Loss: -9.7074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8226

Saving model as e361_model.pt & e361_waveforms_supplementary.hdf5
Learning rate: 3.5774734682341595e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: -4.8013	Cost: 34.77s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -10.3825	Cost: 9.72s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -10.0843	Cost: 19.92s
Train Epoch: 362 	Average Loss: -9.7781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6345

Learning rate: 3.529440384305556e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: -5.5756	Cost: 36.07s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -10.1606	Cost: 9.80s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -10.1531	Cost: 17.17s
Train Epoch: 363 	Average Loss: -9.7769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7012

Learning rate: 3.481662746991211e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: -5.1246	Cost: 40.62s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -10.2337	Cost: 9.86s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -9.8389	Cost: 13.85s
Train Epoch: 364 	Average Loss: -9.6767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6537

Learning rate: 3.434142442470437e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: -5.0088	Cost: 34.24s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -10.2613	Cost: 9.60s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -10.2772	Cost: 12.93s
Train Epoch: 365 	Average Loss: -9.7655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8286

Saving model as e365_model.pt & e365_waveforms_supplementary.hdf5
Learning rate: 3.3868813467634793e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: -5.1648	Cost: 34.74s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -10.2840	Cost: 10.08s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -10.0425	Cost: 19.08s
Train Epoch: 366 	Average Loss: -9.7766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6845

Learning rate: 3.339881325657484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: -5.0843	Cost: 35.95s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -10.4761	Cost: 10.14s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -9.6972	Cost: 16.10s
Train Epoch: 367 	Average Loss: -9.7613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7969

Learning rate: 3.2931442346328e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: -5.2562	Cost: 37.77s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -10.3406	Cost: 9.65s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -10.2909	Cost: 15.19s
Train Epoch: 368 	Average Loss: -9.8951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9503

Saving model as e368_model.pt & e368_waveforms_supplementary.hdf5
Learning rate: 3.246671918789755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: -5.3468	Cost: 36.09s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -10.5243	Cost: 9.63s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -10.3072	Cost: 13.65s
Train Epoch: 369 	Average Loss: -9.9239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0219

Saving model as e369_model.pt & e369_waveforms_supplementary.hdf5
Learning rate: 3.200466212775808e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: -4.9751	Cost: 34.83s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -10.1675	Cost: 9.81s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -10.4111	Cost: 19.54s
Train Epoch: 370 	Average Loss: -9.9003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9291

Learning rate: 3.1545289407131164e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: -5.1575	Cost: 35.69s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -10.3841	Cost: 9.82s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -10.3386	Cost: 16.46s
Train Epoch: 371 	Average Loss: -9.9420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9901

Learning rate: 3.1088619161265144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: -4.7803	Cost: 40.08s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -10.3264	Cost: 9.56s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -10.3156	Cost: 14.30s
Train Epoch: 372 	Average Loss: -9.9350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7932

Learning rate: 3.0634669418719525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: -5.0912	Cost: 38.11s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -10.4460	Cost: 9.72s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -10.3810	Cost: 13.53s
Train Epoch: 373 	Average Loss: -9.9754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8791

Learning rate: 3.0183458100652757e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: -5.6997	Cost: 34.23s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -10.5105	Cost: 10.18s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -10.2779	Cost: 18.17s
Train Epoch: 374 	Average Loss: -10.0292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0223

Saving model as e374_model.pt & e374_waveforms_supplementary.hdf5
Learning rate: 2.9735003020115068e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: -5.7089	Cost: 35.78s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -10.3716	Cost: 9.99s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -10.6131	Cost: 17.99s
Train Epoch: 375 	Average Loss: -10.1238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0692

Saving model as e375_model.pt & e375_waveforms_supplementary.hdf5
Learning rate: 2.928932188134526e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: -4.9071	Cost: 39.75s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -10.6162	Cost: 9.46s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -10.4462	Cost: 15.41s
Train Epoch: 376 	Average Loss: -10.0483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9539

Learning rate: 2.8846432279071474e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: -5.2272	Cost: 35.88s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -10.5982	Cost: 10.19s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -10.5569	Cost: 12.55s
Train Epoch: 377 	Average Loss: -10.1015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9601

Learning rate: 2.8406351697816885e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: -5.3253	Cost: 33.74s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -10.6446	Cost: 9.87s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -10.2956	Cost: 19.36s
Train Epoch: 378 	Average Loss: -10.1260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0281

Learning rate: 2.796909751120931e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: -5.5855	Cost: 36.01s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -10.6447	Cost: 9.81s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -10.5652	Cost: 17.58s
Train Epoch: 379 	Average Loss: -10.2133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0894

Saving model as e379_model.pt & e379_waveforms_supplementary.hdf5
Learning rate: 2.7534686981295358e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: -5.1717	Cost: 40.06s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -10.4094	Cost: 10.26s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -10.5130	Cost: 13.04s
Train Epoch: 380 	Average Loss: -10.1366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8497

Learning rate: 2.7103137257858838e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: -5.2858	Cost: 37.62s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -10.4967	Cost: 9.53s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -10.5454	Cost: 13.50s
Train Epoch: 381 	Average Loss: -10.1637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9331

Learning rate: 2.667446537774402e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: -5.6673	Cost: 33.55s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -10.6590	Cost: 9.78s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -10.6210	Cost: 19.28s
Train Epoch: 382 	Average Loss: -10.2072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1368

Saving model as e382_model.pt & e382_waveforms_supplementary.hdf5
Learning rate: 2.6248688264182623e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: -5.4202	Cost: 35.48s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -10.5212	Cost: 9.83s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -10.6686	Cost: 18.71s
Train Epoch: 383 	Average Loss: -10.2137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2261

Saving model as e383_model.pt & e383_waveforms_supplementary.hdf5
Learning rate: 2.5825822726126095e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: -5.1976	Cost: 36.03s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -10.5276	Cost: 9.66s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -10.4687	Cost: 15.01s
Train Epoch: 384 	Average Loss: -10.2307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1604

Learning rate: 2.5405885457581793e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: -5.3032	Cost: 33.83s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -10.5784	Cost: 9.57s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -10.5876	Cost: 12.47s
Train Epoch: 385 	Average Loss: -10.2492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1317

Learning rate: 2.4988893036954043e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: -5.4327	Cost: 33.18s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -10.7802	Cost: 10.11s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -10.6522	Cost: 16.43s
Train Epoch: 386 	Average Loss: -10.2864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2073

Learning rate: 2.4574861926389615e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: -5.4555	Cost: 35.92s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -10.8457	Cost: 9.74s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -10.8049	Cost: 17.97s
Train Epoch: 387 	Average Loss: -10.2904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1509

Learning rate: 2.4163808471127812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: -5.1242	Cost: 36.24s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -10.6900	Cost: 9.78s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -10.6128	Cost: 13.68s
Train Epoch: 388 	Average Loss: -10.2318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0798

Learning rate: 2.3755748898855234e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: -5.7397	Cost: 37.38s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -10.6981	Cost: 9.57s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -10.5284	Cost: 17.33s
Train Epoch: 389 	Average Loss: -10.3472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1524

Learning rate: 2.3350699319065006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: -5.6733	Cost: 35.84s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -10.8466	Cost: 9.50s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -10.9775	Cost: 17.40s
Train Epoch: 390 	Average Loss: -10.4240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2452

Saving model as e390_model.pt & e390_waveforms_supplementary.hdf5
Learning rate: 2.2948675722421086e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: -5.4769	Cost: 35.99s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -10.8995	Cost: 9.72s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -10.8446	Cost: 18.62s
Train Epoch: 391 	Average Loss: -10.4206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2603

Saving model as e391_model.pt & e391_waveforms_supplementary.hdf5
Learning rate: 2.2549693980126627e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: -5.9852	Cost: 38.36s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -11.0697	Cost: 9.58s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -10.8123	Cost: 15.56s
Train Epoch: 392 	Average Loss: -10.4357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4285

Saving model as e392_model.pt & e392_waveforms_supplementary.hdf5
Learning rate: 2.2153769843297664e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: -5.8582	Cost: 35.43s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -10.9154	Cost: 9.69s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -10.6668	Cost: 12.15s
Train Epoch: 393 	Average Loss: -10.4592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9526

Learning rate: 2.1760918942341185e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: -5.4490	Cost: 35.30s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -10.9765	Cost: 9.91s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -10.8572	Cost: 18.71s
Train Epoch: 394 	Average Loss: -10.4627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4146

Learning rate: 2.1371156786338137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: -5.3736	Cost: 36.16s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -10.9202	Cost: 9.65s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -10.7528	Cost: 17.20s
Train Epoch: 395 	Average Loss: -10.4869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2805

Learning rate: 2.0984498762430954e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: -5.1339	Cost: 37.93s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -11.0747	Cost: 9.61s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -11.1340	Cost: 13.10s
Train Epoch: 396 	Average Loss: -10.4907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1858

Learning rate: 2.060096013521646e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: -5.5784	Cost: 38.13s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -10.9733	Cost: 9.72s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -11.0786	Cost: 12.59s
Train Epoch: 397 	Average Loss: -10.5538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3847

Learning rate: 2.022055604614291e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: -5.5653	Cost: 36.21s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -10.9909	Cost: 9.56s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -10.8645	Cost: 16.73s
Train Epoch: 398 	Average Loss: -10.5114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3660

Learning rate: 1.9843301512912324e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: -5.2039	Cost: 33.82s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -11.0924	Cost: 9.73s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -11.0295	Cost: 18.50s
Train Epoch: 399 	Average Loss: -10.4860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2683

Learning rate: 1.9469211428887808e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: -5.4957	Cost: 36.96s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -11.1337	Cost: 9.77s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -10.9523	Cost: 14.44s
Train Epoch: 400 	Average Loss: -10.6206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2869

Learning rate: 1.9098300562505263e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: -5.9985	Cost: 35.83s
Train Epoch: 401 [40960/90000 (45%)]	Loss: -11.1626	Cost: 9.64s
Train Epoch: 401 [81920/90000 (91%)]	Loss: -10.9490	Cost: 15.29s
Train Epoch: 401 	Average Loss: -10.6530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3491

Learning rate: 1.8730583556690602e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: -5.8905	Cost: 33.67s
Train Epoch: 402 [40960/90000 (45%)]	Loss: -11.1528	Cost: 9.68s
Train Epoch: 402 [81920/90000 (91%)]	Loss: -10.9361	Cost: 13.07s
Train Epoch: 402 	Average Loss: -10.6282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4538

Saving model as e402_model.pt & e402_waveforms_supplementary.hdf5
Learning rate: 1.8366074928281604e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: -5.5894	Cost: 34.92s
Train Epoch: 403 [40960/90000 (45%)]	Loss: -11.1485	Cost: 9.82s
Train Epoch: 403 [81920/90000 (91%)]	Loss: -11.0263	Cost: 18.36s
Train Epoch: 403 	Average Loss: -10.6346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2559

Learning rate: 1.8004789067454784e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: -5.9593	Cost: 37.17s
Train Epoch: 404 [40960/90000 (45%)]	Loss: -11.1152	Cost: 9.94s
Train Epoch: 404 [81920/90000 (91%)]	Loss: -11.2000	Cost: 18.24s
Train Epoch: 404 	Average Loss: -10.6525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3869

Learning rate: 1.7646740237157253e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: -5.4445	Cost: 36.30s
Train Epoch: 405 [40960/90000 (45%)]	Loss: -11.2571	Cost: 9.63s
Train Epoch: 405 [81920/90000 (91%)]	Loss: -10.9781	Cost: 15.31s
Train Epoch: 405 	Average Loss: -10.6770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2123

Learning rate: 1.7291942572543828e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: -6.1406	Cost: 35.12s
Train Epoch: 406 [40960/90000 (45%)]	Loss: -11.0559	Cost: 9.63s
Train Epoch: 406 [81920/90000 (91%)]	Loss: -11.1329	Cost: 14.11s
Train Epoch: 406 	Average Loss: -10.6967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3405

Learning rate: 1.6940410080418743e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: -5.6213	Cost: 34.65s
Train Epoch: 407 [40960/90000 (45%)]	Loss: -10.9395	Cost: 9.87s
Train Epoch: 407 [81920/90000 (91%)]	Loss: -10.9639	Cost: 18.20s
Train Epoch: 407 	Average Loss: -10.6991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3161

Learning rate: 1.6592156638682862e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: -5.7250	Cost: 35.07s
Train Epoch: 408 [40960/90000 (45%)]	Loss: -11.0957	Cost: 9.72s
Train Epoch: 408 [81920/90000 (91%)]	Loss: -10.8850	Cost: 16.76s
Train Epoch: 408 	Average Loss: -10.7513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5159

Saving model as e408_model.pt & e408_waveforms_supplementary.hdf5
Learning rate: 1.6247195995785833e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: -5.0790	Cost: 36.36s
Train Epoch: 409 [40960/90000 (45%)]	Loss: -11.0675	Cost: 9.69s
Train Epoch: 409 [81920/90000 (91%)]	Loss: -10.9906	Cost: 14.71s
Train Epoch: 409 	Average Loss: -10.7337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3847

Learning rate: 1.5905541770183092e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: -5.9622	Cost: 38.33s
Train Epoch: 410 [40960/90000 (45%)]	Loss: -11.3937	Cost: 9.60s
Train Epoch: 410 [81920/90000 (91%)]	Loss: -11.1180	Cost: 13.74s
Train Epoch: 410 	Average Loss: -10.7981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4705

Learning rate: 1.5567207449798488e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: -5.3902	Cost: 35.61s
Train Epoch: 411 [40960/90000 (45%)]	Loss: -11.3689	Cost: 9.91s
Train Epoch: 411 [81920/90000 (91%)]	Loss: -11.0213	Cost: 18.69s
Train Epoch: 411 	Average Loss: -10.7875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5711

Saving model as e411_model.pt & e411_waveforms_supplementary.hdf5
Learning rate: 1.5232206391491672e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: -5.7032	Cost: 36.19s
Train Epoch: 412 [40960/90000 (45%)]	Loss: -11.3156	Cost: 9.68s
Train Epoch: 412 [81920/90000 (91%)]	Loss: -11.1855	Cost: 16.81s
Train Epoch: 412 	Average Loss: -10.7647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4445

Learning rate: 1.4900551820530823e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: -5.4070	Cost: 36.62s
Train Epoch: 413 [40960/90000 (45%)]	Loss: -11.3188	Cost: 9.82s
Train Epoch: 413 [81920/90000 (91%)]	Loss: -11.2006	Cost: 14.55s
Train Epoch: 413 	Average Loss: -10.7892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3783

Learning rate: 1.457225683007047e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: -5.6215	Cost: 37.82s
Train Epoch: 414 [40960/90000 (45%)]	Loss: -11.4091	Cost: 9.72s
Train Epoch: 414 [81920/90000 (91%)]	Loss: -11.1017	Cost: 14.02s
Train Epoch: 414 	Average Loss: -10.8488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4219

Learning rate: 1.4247334380634787e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: -5.9441	Cost: 34.87s
Train Epoch: 415 [40960/90000 (45%)]	Loss: -11.1850	Cost: 9.74s
Train Epoch: 415 [81920/90000 (91%)]	Loss: -11.3269	Cost: 18.41s
Train Epoch: 415 	Average Loss: -10.8111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3787

Learning rate: 1.3925797299605641e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: -6.0227	Cost: 36.30s
Train Epoch: 416 [40960/90000 (45%)]	Loss: -11.2615	Cost: 9.80s
Train Epoch: 416 [81920/90000 (91%)]	Loss: -11.1477	Cost: 17.60s
Train Epoch: 416 	Average Loss: -10.8156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2538

Learning rate: 1.3607658280716445e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: -5.9635	Cost: 37.78s
Train Epoch: 417 [40960/90000 (45%)]	Loss: -11.6176	Cost: 9.59s
Train Epoch: 417 [81920/90000 (91%)]	Loss: -11.4465	Cost: 16.07s
Train Epoch: 417 	Average Loss: -10.9097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5649

Learning rate: 1.3292929883550993e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: -6.3999	Cost: 34.05s
Train Epoch: 418 [40960/90000 (45%)]	Loss: -11.3594	Cost: 9.62s
Train Epoch: 418 [81920/90000 (91%)]	Loss: -11.4288	Cost: 13.15s
Train Epoch: 418 	Average Loss: -10.9423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4538

Learning rate: 1.2981624533047427e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: -5.9414	Cost: 34.73s
Train Epoch: 419 [40960/90000 (45%)]	Loss: -11.2788	Cost: 9.89s
Train Epoch: 419 [81920/90000 (91%)]	Loss: -11.2026	Cost: 17.46s
Train Epoch: 419 	Average Loss: -10.8973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6100

Saving model as e419_model.pt & e419_waveforms_supplementary.hdf5
Learning rate: 1.2673754519007981e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: -5.7546	Cost: 36.26s
Train Epoch: 420 [40960/90000 (45%)]	Loss: -11.2266	Cost: 9.80s
Train Epoch: 420 [81920/90000 (91%)]	Loss: -11.2544	Cost: 19.13s
Train Epoch: 420 	Average Loss: -10.9057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5826

Learning rate: 1.2369331995613638e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: -6.0310	Cost: 37.62s
Train Epoch: 421 [40960/90000 (45%)]	Loss: -11.4766	Cost: 9.70s
Train Epoch: 421 [81920/90000 (91%)]	Loss: -11.3861	Cost: 13.62s
Train Epoch: 421 	Average Loss: -10.9495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6490

Saving model as e421_model.pt & e421_waveforms_supplementary.hdf5
Learning rate: 1.2068368980944384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: -5.6408	Cost: 38.34s
Train Epoch: 422 [40960/90000 (45%)]	Loss: -11.3200	Cost: 9.62s
Train Epoch: 422 [81920/90000 (91%)]	Loss: -11.4647	Cost: 13.62s
Train Epoch: 422 	Average Loss: -10.9644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5067

Learning rate: 1.1770877356504656e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: -5.4663	Cost: 34.97s
Train Epoch: 423 [40960/90000 (45%)]	Loss: -11.3430	Cost: 9.84s
Train Epoch: 423 [81920/90000 (91%)]	Loss: -11.4575	Cost: 17.82s
Train Epoch: 423 	Average Loss: -10.9554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3688

Learning rate: 1.1476868866754482e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: -6.0661	Cost: 37.09s
Train Epoch: 424 [40960/90000 (45%)]	Loss: -11.5275	Cost: 9.69s
Train Epoch: 424 [81920/90000 (91%)]	Loss: -11.4157	Cost: 19.99s
Train Epoch: 424 	Average Loss: -10.9617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6093

Learning rate: 1.1186355118645549e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: -6.1273	Cost: 37.98s
Train Epoch: 425 [40960/90000 (45%)]	Loss: -11.5865	Cost: 9.65s
Train Epoch: 425 [81920/90000 (91%)]	Loss: -11.2894	Cost: 15.54s
Train Epoch: 425 	Average Loss: -10.9920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7806

Saving model as e425_model.pt & e425_waveforms_supplementary.hdf5
Learning rate: 1.0899347581163218e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: -6.0482	Cost: 34.26s
Train Epoch: 426 [40960/90000 (45%)]	Loss: -11.4572	Cost: 9.59s
Train Epoch: 426 [81920/90000 (91%)]	Loss: -11.3858	Cost: 13.52s
Train Epoch: 426 	Average Loss: -11.0285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5470

Learning rate: 1.061585758487362e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: -6.1012	Cost: 33.57s
Train Epoch: 427 [40960/90000 (45%)]	Loss: -11.4908	Cost: 10.12s
Train Epoch: 427 [81920/90000 (91%)]	Loss: -11.5565	Cost: 16.55s
Train Epoch: 427 	Average Loss: -11.0271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6770

Learning rate: 1.033589632147641e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: -5.9744	Cost: 34.65s
Train Epoch: 428 [40960/90000 (45%)]	Loss: -11.6980	Cost: 9.69s
Train Epoch: 428 [81920/90000 (91%)]	Loss: -11.5625	Cost: 18.48s
Train Epoch: 428 	Average Loss: -11.0388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4622

Learning rate: 1.005947484336289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: -6.0959	Cost: 36.30s
Train Epoch: 429 [40960/90000 (45%)]	Loss: -11.5923	Cost: 9.71s
Train Epoch: 429 [81920/90000 (91%)]	Loss: -11.5924	Cost: 14.84s
Train Epoch: 429 	Average Loss: -11.0594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5618

Learning rate: 9.786604063179713e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: -5.8889	Cost: 37.53s
Train Epoch: 430 [40960/90000 (45%)]	Loss: -11.7509	Cost: 9.53s
Train Epoch: 430 [81920/90000 (91%)]	Loss: -11.2029	Cost: 12.95s
Train Epoch: 430 	Average Loss: -11.0523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5173

Learning rate: 9.517294753398061e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: -5.9101	Cost: 33.84s
Train Epoch: 431 [40960/90000 (45%)]	Loss: -11.6034	Cost: 9.55s
Train Epoch: 431 [81920/90000 (91%)]	Loss: -11.4392	Cost: 14.75s
Train Epoch: 431 	Average Loss: -11.0843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5750

Learning rate: 9.251557545888296e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: -6.1935	Cost: 33.39s
Train Epoch: 432 [40960/90000 (45%)]	Loss: -11.4703	Cost: 9.92s
Train Epoch: 432 [81920/90000 (91%)]	Loss: -11.5217	Cost: 20.99s
Train Epoch: 432 	Average Loss: -11.1382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6222

Learning rate: 8.98940293150043e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: -5.9903	Cost: 36.22s
Train Epoch: 433 [40960/90000 (45%)]	Loss: -11.5100	Cost: 9.94s
Train Epoch: 433 [81920/90000 (91%)]	Loss: -11.6139	Cost: 14.36s
Train Epoch: 433 	Average Loss: -11.1366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6449

Learning rate: 8.730841259649718e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: -5.5539	Cost: 34.66s
Train Epoch: 434 [40960/90000 (45%)]	Loss: -11.7013	Cost: 9.72s
Train Epoch: 434 [81920/90000 (91%)]	Loss: -11.3858	Cost: 13.73s
Train Epoch: 434 	Average Loss: -11.1224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6092

Learning rate: 8.475882737908241e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: -6.1007	Cost: 33.29s
Train Epoch: 435 [40960/90000 (45%)]	Loss: -11.7650	Cost: 9.61s
Train Epoch: 435 [81920/90000 (91%)]	Loss: -11.4624	Cost: 12.67s
Train Epoch: 435 	Average Loss: -11.1424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6228

Learning rate: 8.224537431601881e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: -6.3532	Cost: 34.18s
Train Epoch: 436 [40960/90000 (45%)]	Loss: -11.5664	Cost: 9.66s
Train Epoch: 436 [81920/90000 (91%)]	Loss: -11.5404	Cost: 17.41s
Train Epoch: 436 	Average Loss: -11.2037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6912

Learning rate: 7.97681526341298e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: -6.2382	Cost: 35.12s
Train Epoch: 437 [40960/90000 (45%)]	Loss: -11.6823	Cost: 9.69s
Train Epoch: 437 [81920/90000 (91%)]	Loss: -11.5749	Cost: 19.25s
Train Epoch: 437 	Average Loss: -11.1629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5803

Learning rate: 7.732726012988507e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: -6.3242	Cost: 39.73s
Train Epoch: 438 [40960/90000 (45%)]	Loss: -11.6473	Cost: 9.55s
Train Epoch: 438 [81920/90000 (91%)]	Loss: -11.7485	Cost: 15.89s
Train Epoch: 438 	Average Loss: -11.1970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7483

Learning rate: 7.492279316554181e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: -5.9529	Cost: 36.04s
Train Epoch: 439 [40960/90000 (45%)]	Loss: -11.7115	Cost: 10.11s
Train Epoch: 439 [81920/90000 (91%)]	Loss: -11.5324	Cost: 12.15s
Train Epoch: 439 	Average Loss: -11.1585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6834

Learning rate: 7.25548466653387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: -5.6547	Cost: 34.86s
Train Epoch: 440 [40960/90000 (45%)]	Loss: -11.5337	Cost: 9.69s
Train Epoch: 440 [81920/90000 (91%)]	Loss: -11.6179	Cost: 18.27s
Train Epoch: 440 	Average Loss: -11.1949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6771

Learning rate: 7.02235141117485e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: -6.2225	Cost: 34.56s
Train Epoch: 441 [40960/90000 (45%)]	Loss: -11.8718	Cost: 9.73s
Train Epoch: 441 [81920/90000 (91%)]	Loss: -11.8550	Cost: 20.19s
Train Epoch: 441 	Average Loss: -11.2583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6744

Learning rate: 6.792888754178901e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: -5.1690	Cost: 37.80s
Train Epoch: 442 [40960/90000 (45%)]	Loss: -11.7461	Cost: 9.57s
Train Epoch: 442 [81920/90000 (91%)]	Loss: -11.5486	Cost: 14.52s
Train Epoch: 442 	Average Loss: -11.1666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5715

Learning rate: 6.567105754338794e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: -6.1263	Cost: 37.55s
Train Epoch: 443 [40960/90000 (45%)]	Loss: -11.6931	Cost: 10.04s
Train Epoch: 443 [81920/90000 (91%)]	Loss: -11.7274	Cost: 12.85s
Train Epoch: 443 	Average Loss: -11.2638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7011

Learning rate: 6.3450113251807676e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: -6.0934	Cost: 36.11s
Train Epoch: 444 [40960/90000 (45%)]	Loss: -11.7064	Cost: 9.55s
Train Epoch: 444 [81920/90000 (91%)]	Loss: -11.8234	Cost: 17.53s
Train Epoch: 444 	Average Loss: -11.2664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7858

Saving model as e444_model.pt & e444_waveforms_supplementary.hdf5
Learning rate: 6.126614234612589e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: -6.2499	Cost: 35.97s
Train Epoch: 445 [40960/90000 (45%)]	Loss: -11.6731	Cost: 9.68s
Train Epoch: 445 [81920/90000 (91%)]	Loss: -11.8208	Cost: 18.93s
Train Epoch: 445 	Average Loss: -11.2322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6814

Learning rate: 5.911923104577461e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: -5.5355	Cost: 38.79s
Train Epoch: 446 [40960/90000 (45%)]	Loss: -11.9616	Cost: 9.79s
Train Epoch: 446 [81920/90000 (91%)]	Loss: -11.7357	Cost: 15.39s
Train Epoch: 446 	Average Loss: -11.2948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6964

Learning rate: 5.7009464107135434e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: -4.9773	Cost: 33.81s
Train Epoch: 447 [40960/90000 (45%)]	Loss: -11.8242	Cost: 9.77s
Train Epoch: 447 [81920/90000 (91%)]	Loss: -11.6614	Cost: 14.39s
Train Epoch: 447 	Average Loss: -11.2539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7179

Learning rate: 5.493692482019526e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: -6.0118	Cost: 33.78s
Train Epoch: 448 [40960/90000 (45%)]	Loss: -11.6787	Cost: 9.84s
Train Epoch: 448 [81920/90000 (91%)]	Loss: -11.5892	Cost: 18.05s
Train Epoch: 448 	Average Loss: -11.2957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6946

Learning rate: 5.290169500525573e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: -6.2609	Cost: 35.38s
Train Epoch: 449 [40960/90000 (45%)]	Loss: -11.8391	Cost: 9.73s
Train Epoch: 449 [81920/90000 (91%)]	Loss: -11.7303	Cost: 17.37s
Train Epoch: 449 	Average Loss: -11.2984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7316

Learning rate: 5.090385500970525e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: -5.9967	Cost: 37.48s
Train Epoch: 450 [40960/90000 (45%)]	Loss: -11.8242	Cost: 9.68s
Train Epoch: 450 [81920/90000 (91%)]	Loss: -11.9150	Cost: 14.38s
Train Epoch: 450 	Average Loss: -11.3112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9621

Saving model as e450_model.pt & e450_waveforms_supplementary.hdf5
Learning rate: 4.894348370484643e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: -6.1195	Cost: 37.60s
Train Epoch: 451 [40960/90000 (45%)]	Loss: -11.7752	Cost: 10.19s
Train Epoch: 451 [81920/90000 (91%)]	Loss: -11.6922	Cost: 13.68s
Train Epoch: 451 	Average Loss: -11.2887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8027

Learning rate: 4.702065848278122e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: -6.0968	Cost: 35.40s
Train Epoch: 452 [40960/90000 (45%)]	Loss: -11.8433	Cost: 9.62s
Train Epoch: 452 [81920/90000 (91%)]	Loss: -11.6716	Cost: 17.03s
Train Epoch: 452 	Average Loss: -11.3110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6316

Learning rate: 4.513545525335701e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: -5.7063	Cost: 36.13s
Train Epoch: 453 [40960/90000 (45%)]	Loss: -11.8654	Cost: 9.78s
Train Epoch: 453 [81920/90000 (91%)]	Loss: -11.6230	Cost: 20.32s
Train Epoch: 453 	Average Loss: -11.2857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6719

Learning rate: 4.328794844116942e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: -5.4390	Cost: 35.94s
Train Epoch: 454 [40960/90000 (45%)]	Loss: -11.8090	Cost: 9.72s
Train Epoch: 454 [81920/90000 (91%)]	Loss: -11.7522	Cost: 13.68s
Train Epoch: 454 	Average Loss: -11.2728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8559

Learning rate: 4.147821098262413e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: -6.1646	Cost: 34.47s
Train Epoch: 455 [40960/90000 (45%)]	Loss: -11.8849	Cost: 9.70s
Train Epoch: 455 [81920/90000 (91%)]	Loss: -11.7833	Cost: 13.57s
Train Epoch: 455 	Average Loss: -11.3845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6710

Learning rate: 3.97063143230569e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: -6.1052	Cost: 35.89s
Train Epoch: 456 [40960/90000 (45%)]	Loss: -11.9139	Cost: 9.65s
Train Epoch: 456 [81920/90000 (91%)]	Loss: -11.8687	Cost: 14.07s
Train Epoch: 456 	Average Loss: -11.3645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5879

Learning rate: 3.797232841391415e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: -6.0012	Cost: 34.16s
Train Epoch: 457 [40960/90000 (45%)]	Loss: -11.9637	Cost: 9.88s
Train Epoch: 457 [81920/90000 (91%)]	Loss: -11.9462	Cost: 18.88s
Train Epoch: 457 	Average Loss: -11.3818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6797

Learning rate: 3.627632170999026e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: -5.5591	Cost: 35.33s
Train Epoch: 458 [40960/90000 (45%)]	Loss: -11.8731	Cost: 9.83s
Train Epoch: 458 [81920/90000 (91%)]	Loss: -12.0589	Cost: 16.12s
Train Epoch: 458 	Average Loss: -11.3535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7946

Learning rate: 3.461836116672609e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: -6.0939	Cost: 36.34s
Train Epoch: 459 [40960/90000 (45%)]	Loss: -11.8373	Cost: 9.69s
Train Epoch: 459 [81920/90000 (91%)]	Loss: -11.7743	Cost: 14.11s
Train Epoch: 459 	Average Loss: -11.3987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8362

Learning rate: 3.2998512237564976e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: -5.9195	Cost: 39.33s
Train Epoch: 460 [40960/90000 (45%)]	Loss: -12.1035	Cost: 9.63s
Train Epoch: 460 [81920/90000 (91%)]	Loss: -11.9777	Cost: 13.24s
Train Epoch: 460 	Average Loss: -11.3508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7062

Learning rate: 3.14168388713689e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: -6.4093	Cost: 34.84s
Train Epoch: 461 [40960/90000 (45%)]	Loss: -11.9073	Cost: 9.66s
Train Epoch: 461 [81920/90000 (91%)]	Loss: -11.8930	Cost: 17.65s
Train Epoch: 461 	Average Loss: -11.3971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7285

Learning rate: 2.9873403509894177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: -6.1978	Cost: 35.15s
Train Epoch: 462 [40960/90000 (45%)]	Loss: -11.9501	Cost: 9.70s
Train Epoch: 462 [81920/90000 (91%)]	Loss: -11.8978	Cost: 17.74s
Train Epoch: 462 	Average Loss: -11.4018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6758

Learning rate: 2.8368267085326003e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: -6.0704	Cost: 39.75s
Train Epoch: 463 [40960/90000 (45%)]	Loss: -11.8747	Cost: 9.69s
Train Epoch: 463 [81920/90000 (91%)]	Loss: -11.4980	Cost: 13.23s
Train Epoch: 463 	Average Loss: -11.3920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6597

Learning rate: 2.690148901787346e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: -6.2090	Cost: 37.05s
Train Epoch: 464 [40960/90000 (45%)]	Loss: -11.8380	Cost: 9.56s
Train Epoch: 464 [81920/90000 (91%)]	Loss: -11.8178	Cost: 13.76s
Train Epoch: 464 	Average Loss: -11.3736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7544

Learning rate: 2.547312721342274e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: -6.0761	Cost: 35.66s
Train Epoch: 465 [40960/90000 (45%)]	Loss: -11.7964	Cost: 9.52s
Train Epoch: 465 [81920/90000 (91%)]	Loss: -11.8211	Cost: 17.12s
Train Epoch: 465 	Average Loss: -11.3819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8114

Learning rate: 2.4083238061252656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: -6.0376	Cost: 35.17s
Train Epoch: 466 [40960/90000 (45%)]	Loss: -11.9137	Cost: 9.68s
Train Epoch: 466 [81920/90000 (91%)]	Loss: -11.8719	Cost: 18.13s
Train Epoch: 466 	Average Loss: -11.4075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8855

Learning rate: 2.27318764318065e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: -6.7130	Cost: 37.02s
Train Epoch: 467 [40960/90000 (45%)]	Loss: -11.8557	Cost: 9.71s
Train Epoch: 467 [81920/90000 (91%)]	Loss: -11.9825	Cost: 14.93s
Train Epoch: 467 	Average Loss: -11.4851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7282

Learning rate: 2.1419095674527915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: -6.2341	Cost: 37.17s
Train Epoch: 468 [40960/90000 (45%)]	Loss: -11.9512	Cost: 9.60s
Train Epoch: 468 [81920/90000 (91%)]	Loss: -11.9058	Cost: 15.01s
Train Epoch: 468 	Average Loss: -11.3923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8552

Learning rate: 2.0144947615753123e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: -6.4005	Cost: 37.81s
Train Epoch: 469 [40960/90000 (45%)]	Loss: -11.9548	Cost: 9.49s
Train Epoch: 469 [81920/90000 (91%)]	Loss: -11.8544	Cost: 15.87s
Train Epoch: 469 	Average Loss: -11.4407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9023

Learning rate: 1.890948255666601e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: -6.0126	Cost: 34.88s
Train Epoch: 470 [40960/90000 (45%)]	Loss: -11.9415	Cost: 9.69s
Train Epoch: 470 [81920/90000 (91%)]	Loss: -11.8502	Cost: 18.44s
Train Epoch: 470 	Average Loss: -11.4526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8334

Learning rate: 1.7712749271311265e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: -5.8948	Cost: 36.17s
Train Epoch: 471 [40960/90000 (45%)]	Loss: -11.8931	Cost: 9.75s
Train Epoch: 471 [81920/90000 (91%)]	Loss: -11.8862	Cost: 15.35s
Train Epoch: 471 	Average Loss: -11.4215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8772

Learning rate: 1.6554795004670263e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: -6.0688	Cost: 36.32s
Train Epoch: 472 [40960/90000 (45%)]	Loss: -11.8623	Cost: 9.90s
Train Epoch: 472 [81920/90000 (91%)]	Loss: -11.9202	Cost: 13.36s
Train Epoch: 472 	Average Loss: -11.4375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8987

Learning rate: 1.5435665470794655e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: -6.1884	Cost: 33.95s
Train Epoch: 473 [40960/90000 (45%)]	Loss: -12.0466	Cost: 9.66s
Train Epoch: 473 [81920/90000 (91%)]	Loss: -11.7809	Cost: 13.39s
Train Epoch: 473 	Average Loss: -11.4863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8825

Learning rate: 1.435540485100194e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: -5.6583	Cost: 33.47s
Train Epoch: 474 [40960/90000 (45%)]	Loss: -11.8600	Cost: 9.59s
Train Epoch: 474 [81920/90000 (91%)]	Loss: -11.8485	Cost: 15.83s
Train Epoch: 474 	Average Loss: -11.4226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8874

Learning rate: 1.3314055792131951e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: -6.1141	Cost: 34.33s
Train Epoch: 475 [40960/90000 (45%)]	Loss: -12.1530	Cost: 9.67s
Train Epoch: 475 [81920/90000 (91%)]	Loss: -11.8996	Cost: 18.93s
Train Epoch: 475 	Average Loss: -11.4659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8839

Learning rate: 1.231165940486233e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: -6.2744	Cost: 34.63s
Train Epoch: 476 [40960/90000 (45%)]	Loss: -12.1030	Cost: 9.77s
Train Epoch: 476 [81920/90000 (91%)]	Loss: -11.7994	Cost: 17.39s
Train Epoch: 476 	Average Loss: -11.4674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0729

Saving model as e476_model.pt & e476_waveforms_supplementary.hdf5
Learning rate: 1.1348255262086039e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: -5.4651	Cost: 39.68s
Train Epoch: 477 [40960/90000 (45%)]	Loss: -11.9463	Cost: 9.66s
Train Epoch: 477 [81920/90000 (91%)]	Loss: -12.0048	Cost: 13.82s
Train Epoch: 477 	Average Loss: -11.4595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8370

Learning rate: 1.0423881397349057e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: -5.6262	Cost: 36.24s
Train Epoch: 478 [40960/90000 (45%)]	Loss: -11.9481	Cost: 9.66s
Train Epoch: 478 [81920/90000 (91%)]	Loss: -11.8731	Cost: 13.47s
Train Epoch: 478 	Average Loss: -11.4841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8970

Learning rate: 9.538574303348804e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: -6.3544	Cost: 33.40s
Train Epoch: 479 [40960/90000 (45%)]	Loss: -11.9065	Cost: 9.83s
Train Epoch: 479 [81920/90000 (91%)]	Loss: -12.1147	Cost: 19.15s
Train Epoch: 479 	Average Loss: -11.4917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0527

Learning rate: 8.692368930493404e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: -5.2362	Cost: 36.96s
Train Epoch: 480 [40960/90000 (45%)]	Loss: -12.1237	Cost: 9.86s
Train Epoch: 480 [81920/90000 (91%)]	Loss: -11.9440	Cost: 16.72s
Train Epoch: 480 	Average Loss: -11.4407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8360

Learning rate: 7.885298685522229e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: -6.2835	Cost: 41.50s
Train Epoch: 481 [40960/90000 (45%)]	Loss: -12.0261	Cost: 9.82s
Train Epoch: 481 [81920/90000 (91%)]	Loss: -11.8845	Cost: 15.16s
Train Epoch: 481 	Average Loss: -11.4957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9807

Learning rate: 7.117395430186407e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: -6.1490	Cost: 36.39s
Train Epoch: 482 [40960/90000 (45%)]	Loss: -12.0800	Cost: 9.60s
Train Epoch: 482 [81920/90000 (91%)]	Loss: -11.8660	Cost: 13.59s
Train Epoch: 482 	Average Loss: -11.4546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8993

Learning rate: 6.3886894799916e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: -6.3197	Cost: 34.48s
Train Epoch: 483 [40960/90000 (45%)]	Loss: -12.2181	Cost: 9.80s
Train Epoch: 483 [81920/90000 (91%)]	Loss: -11.9858	Cost: 18.78s
Train Epoch: 483 	Average Loss: -11.5104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8188

Learning rate: 5.699209603001072e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: -5.9203	Cost: 38.30s
Train Epoch: 484 [40960/90000 (45%)]	Loss: -11.9377	Cost: 9.67s
Train Epoch: 484 [81920/90000 (91%)]	Loss: -11.9005	Cost: 17.66s
Train Epoch: 484 	Average Loss: -11.5033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8479

Learning rate: 5.048983018699823e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: -6.1321	Cost: 36.15s
Train Epoch: 485 [40960/90000 (45%)]	Loss: -11.9219	Cost: 9.98s
Train Epoch: 485 [81920/90000 (91%)]	Loss: -11.8124	Cost: 14.11s
Train Epoch: 485 	Average Loss: -11.4433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9071

Learning rate: 4.43803539692e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: -6.1962	Cost: 33.94s
Train Epoch: 486 [40960/90000 (45%)]	Loss: -11.9983	Cost: 9.61s
Train Epoch: 486 [81920/90000 (91%)]	Loss: -11.9025	Cost: 12.75s
Train Epoch: 486 	Average Loss: -11.4691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9336

Learning rate: 3.8663908568274915e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: -6.4041	Cost: 34.66s
Train Epoch: 487 [40960/90000 (45%)]	Loss: -11.9079	Cost: 9.79s
Train Epoch: 487 [81920/90000 (91%)]	Loss: -12.0655	Cost: 19.07s
Train Epoch: 487 	Average Loss: -11.5284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9424

Learning rate: 3.334071965970128e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: -6.1874	Cost: 35.84s
Train Epoch: 488 [40960/90000 (45%)]	Loss: -11.9380	Cost: 9.82s
Train Epoch: 488 [81920/90000 (91%)]	Loss: -11.6813	Cost: 16.66s
Train Epoch: 488 	Average Loss: -11.4833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8448

Learning rate: 2.8410997393860634e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: -6.6070	Cost: 36.63s
Train Epoch: 489 [40960/90000 (45%)]	Loss: -12.1366	Cost: 9.60s
Train Epoch: 489 [81920/90000 (91%)]	Loss: -11.9515	Cost: 12.80s
Train Epoch: 489 	Average Loss: -11.5151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0261

Learning rate: 2.3874936387747717e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: -6.4438	Cost: 34.62s
Train Epoch: 490 [40960/90000 (45%)]	Loss: -12.0375	Cost: 9.58s
Train Epoch: 490 [81920/90000 (91%)]	Loss: -11.9338	Cost: 14.44s
Train Epoch: 490 	Average Loss: -11.5181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6947

Learning rate: 1.9732715717284395e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: -5.5628	Cost: 34.08s
Train Epoch: 491 [40960/90000 (45%)]	Loss: -12.0052	Cost: 9.77s
Train Epoch: 491 [81920/90000 (91%)]	Loss: -11.8025	Cost: 12.87s
Train Epoch: 491 	Average Loss: -11.4563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8089

Learning rate: 1.5984498910249766e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: -5.7790	Cost: 34.26s
Train Epoch: 492 [40960/90000 (45%)]	Loss: -11.9260	Cost: 9.73s
Train Epoch: 492 [81920/90000 (91%)]	Loss: -11.8613	Cost: 18.94s
Train Epoch: 492 	Average Loss: -11.4897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8600

Learning rate: 1.2630433939825314e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: -6.5464	Cost: 35.52s
Train Epoch: 493 [40960/90000 (45%)]	Loss: -12.0063	Cost: 9.60s
Train Epoch: 493 [81920/90000 (91%)]	Loss: -11.8809	Cost: 16.63s
Train Epoch: 493 	Average Loss: -11.5185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7926

Learning rate: 9.670653218752925e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: -5.9708	Cost: 36.05s
Train Epoch: 494 [40960/90000 (45%)]	Loss: -12.2024	Cost: 9.68s
Train Epoch: 494 [81920/90000 (91%)]	Loss: -11.9396	Cost: 13.73s
Train Epoch: 494 	Average Loss: -11.4682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7117

Learning rate: 7.105273594107945e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: -6.2617	Cost: 34.28s
Train Epoch: 495 [40960/90000 (45%)]	Loss: -12.1117	Cost: 9.57s
Train Epoch: 495 [81920/90000 (91%)]	Loss: -11.9823	Cost: 12.98s
Train Epoch: 495 	Average Loss: -11.5215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0801

Saving model as e495_model.pt & e495_waveforms_supplementary.hdf5
Learning rate: 4.9343963426839946e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: -6.1620	Cost: 34.40s
Train Epoch: 496 [40960/90000 (45%)]	Loss: -11.8127	Cost: 10.20s
Train Epoch: 496 [81920/90000 (91%)]	Loss: -11.8373	Cost: 14.02s
Train Epoch: 496 	Average Loss: -11.4976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8700

Learning rate: 3.158107167000598e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: -5.9096	Cost: 33.52s
Train Epoch: 497 [40960/90000 (45%)]	Loss: -12.0513	Cost: 9.72s
Train Epoch: 497 [81920/90000 (91%)]	Loss: -11.9843	Cost: 18.97s
Train Epoch: 497 	Average Loss: -11.4367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0283

Learning rate: 1.776476191910346e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: -5.8015	Cost: 35.84s
Train Epoch: 498 [40960/90000 (45%)]	Loss: -11.9503	Cost: 9.89s
Train Epoch: 498 [81920/90000 (91%)]	Loss: -12.0737	Cost: 16.62s
Train Epoch: 498 	Average Loss: -11.4902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7223

Learning rate: 7.895579618388819e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: -5.7974	Cost: 36.67s
Train Epoch: 499 [40960/90000 (45%)]	Loss: -12.0524	Cost: 9.61s
Train Epoch: 499 [81920/90000 (91%)]	Loss: -11.9251	Cost: 14.36s
Train Epoch: 499 	Average Loss: -11.4609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8097

Learning rate: 1.973914386288465e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: -6.1131	Cost: 35.37s
Train Epoch: 500 [40960/90000 (45%)]	Loss: -12.1940	Cost: 9.61s
Train Epoch: 500 [81920/90000 (91%)]	Loss: -11.9764	Cost: 14.67s
Train Epoch: 500 	Average Loss: -11.5238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8606

Stopping timer.
Training time (including validation): 167745.27268075943 seconds
Saving model
Transfer learning by starting with alpha=0.7!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 22.1235	Cost: 35.25s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 9.5951	Cost: 9.81s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 7.9427	Cost: 17.13s
Train Epoch: 1 	Average Loss: 9.9769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8020

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.0001999980260856137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 7.6839	Cost: 34.99s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 6.7689	Cost: 9.81s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 5.4300	Cost: 12.76s
Train Epoch: 2 	Average Loss: 6.3083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8565

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 5.4049	Cost: 39.29s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 4.7194	Cost: 9.76s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 3.8901	Cost: 13.69s
Train Epoch: 3 	Average Loss: 4.4546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4487

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 3.7852	Cost: 33.55s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 2.9942	Cost: 9.57s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 2.1388	Cost: 14.38s
Train Epoch: 4 	Average Loss: 2.7599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9267

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892833004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 2.1256	Cost: 31.45s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 2.0420	Cost: 9.74s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 1.1231	Cost: 18.90s
Train Epoch: 5 	Average Loss: 1.3875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9641

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 1.4030	Cost: 36.22s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 0.8942	Cost: 9.71s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 0.2588	Cost: 14.89s
Train Epoch: 6 	Average Loss: 0.5035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2855

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 0.6010	Cost: 35.15s
Train Epoch: 7 [40960/90000 (45%)]	Loss: -0.1111	Cost: 9.81s
Train Epoch: 7 [81920/90000 (91%)]	Loss: -0.3920	Cost: 12.53s
Train Epoch: 7 	Average Loss: -0.2474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8174

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: -0.3985	Cost: 36.29s
Train Epoch: 8 [40960/90000 (45%)]	Loss: -0.3929	Cost: 9.57s
Train Epoch: 8 [81920/90000 (91%)]	Loss: -0.8171	Cost: 12.45s
Train Epoch: 8 	Average Loss: -0.7209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6932

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019987369566060184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: -0.2792	Cost: 33.35s
Train Epoch: 9 [40960/90000 (45%)]	Loss: -0.4947	Cost: 10.04s
Train Epoch: 9 [81920/90000 (91%)]	Loss: -0.9880	Cost: 17.73s
Train Epoch: 9 	Average Loss: -0.8209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6068

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019984015501089758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: -0.2700	Cost: 36.45s
Train Epoch: 10 [40960/90000 (45%)]	Loss: -0.4837	Cost: 9.70s
Train Epoch: 10 [81920/90000 (91%)]	Loss: -0.9850	Cost: 18.07s
Train Epoch: 10 	Average Loss: -0.8171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6656

Learning rate: 0.00019980267284282723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: -0.5221	Cost: 36.57s
Train Epoch: 11 [40960/90000 (45%)]	Loss: -0.8526	Cost: 9.63s
Train Epoch: 11 [81920/90000 (91%)]	Loss: -0.9637	Cost: 12.58s
Train Epoch: 11 	Average Loss: -1.0970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5599

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019976125063612257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: -0.6007	Cost: 35.49s
Train Epoch: 12 [40960/90000 (45%)]	Loss: -1.0642	Cost: 10.12s
Train Epoch: 12 [81920/90000 (91%)]	Loss: -1.3657	Cost: 12.66s
Train Epoch: 12 	Average Loss: -1.3571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3684

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019971589002606144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: -0.8087	Cost: 35.78s
Train Epoch: 13 [40960/90000 (45%)]	Loss: -1.1324	Cost: 9.53s
Train Epoch: 13 [81920/90000 (91%)]	Loss: -1.4690	Cost: 15.62s
Train Epoch: 13 	Average Loss: -1.4401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3829

Learning rate: 0.00019966659280340303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: -0.3452	Cost: 34.04s
Train Epoch: 14 [40960/90000 (45%)]	Loss: -0.9506	Cost: 9.70s
Train Epoch: 14 [81920/90000 (91%)]	Loss: -1.1699	Cost: 18.06s
Train Epoch: 14 	Average Loss: -1.3574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4111

Learning rate: 0.0001996133609143173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: -0.5100	Cost: 39.47s
Train Epoch: 15 [40960/90000 (45%)]	Loss: -1.2498	Cost: 9.72s
Train Epoch: 15 [81920/90000 (91%)]	Loss: -1.6416	Cost: 14.71s
Train Epoch: 15 	Average Loss: -1.5069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1749

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: -1.0116	Cost: 34.92s
Train Epoch: 16 [40960/90000 (45%)]	Loss: -1.2014	Cost: 9.80s
Train Epoch: 16 [81920/90000 (91%)]	Loss: -1.3753	Cost: 12.53s
Train Epoch: 16 	Average Loss: -1.5735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1420

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.00019949510169813006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: -1.2830	Cost: 36.66s
Train Epoch: 17 [40960/90000 (45%)]	Loss: -1.4159	Cost: 9.43s
Train Epoch: 17 [81920/90000 (91%)]	Loss: -0.9153	Cost: 13.28s
Train Epoch: 17 	Average Loss: -1.5446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6167

Learning rate: 0.00019943007903969992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: -0.3133	Cost: 33.82s
Train Epoch: 18 [40960/90000 (45%)]	Loss: -1.0435	Cost: 9.90s
Train Epoch: 18 [81920/90000 (91%)]	Loss: -1.5053	Cost: 18.92s
Train Epoch: 18 	Average Loss: -1.2041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1983

Learning rate: 0.00019936113105200088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: -0.6856	Cost: 36.60s
Train Epoch: 19 [40960/90000 (45%)]	Loss: -1.7527	Cost: 9.79s
Train Epoch: 19 [81920/90000 (91%)]	Loss: -1.7560	Cost: 16.41s
Train Epoch: 19 	Average Loss: -1.7063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0924

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.0001992882604569814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: -0.6151	Cost: 37.55s
Train Epoch: 20 [40960/90000 (45%)]	Loss: -1.7401	Cost: 9.65s
Train Epoch: 20 [81920/90000 (91%)]	Loss: -1.9773	Cost: 14.91s
Train Epoch: 20 	Average Loss: -1.8999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0115

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019921147013144782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: -0.8770	Cost: 35.81s
Train Epoch: 21 [40960/90000 (45%)]	Loss: -1.8905	Cost: 9.57s
Train Epoch: 21 [81920/90000 (91%)]	Loss: -1.8046	Cost: 13.05s
Train Epoch: 21 	Average Loss: -1.9282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0721

Learning rate: 0.00019913076310695068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: -0.8048	Cost: 34.86s
Train Epoch: 22 [40960/90000 (45%)]	Loss: -1.5987	Cost: 10.12s
Train Epoch: 22 [81920/90000 (91%)]	Loss: -1.9065	Cost: 17.00s
Train Epoch: 22 	Average Loss: -1.8630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0387

Learning rate: 0.00019904614256966512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: -0.3087	Cost: 35.88s
Train Epoch: 23 [40960/90000 (45%)]	Loss: -2.0669	Cost: 9.74s
Train Epoch: 23 [81920/90000 (91%)]	Loss: -1.8523	Cost: 18.36s
Train Epoch: 23 	Average Loss: -1.9259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2334

Learning rate: 0.0001989576118602651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: -1.1085	Cost: 40.27s
Train Epoch: 24 [40960/90000 (45%)]	Loss: -1.7735	Cost: 9.65s
Train Epoch: 24 [81920/90000 (91%)]	Loss: -1.9978	Cost: 14.32s
Train Epoch: 24 	Average Loss: -1.9208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0744

Learning rate: 0.0001988651744737914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: -0.8360	Cost: 36.40s
Train Epoch: 25 [40960/90000 (45%)]	Loss: -1.9690	Cost: 10.16s
Train Epoch: 25 [81920/90000 (91%)]	Loss: -2.1701	Cost: 13.98s
Train Epoch: 25 	Average Loss: -2.1426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9004

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.0001987688340595138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: -0.8946	Cost: 34.67s
Train Epoch: 26 [40960/90000 (45%)]	Loss: -1.7889	Cost: 9.82s
Train Epoch: 26 [81920/90000 (91%)]	Loss: -2.4411	Cost: 19.16s
Train Epoch: 26 	Average Loss: -2.1121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9362

Learning rate: 0.00019866859442078683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: -0.9432	Cost: 35.70s
Train Epoch: 27 [40960/90000 (45%)]	Loss: -2.1273	Cost: 9.78s
Train Epoch: 27 [81920/90000 (91%)]	Loss: -2.0094	Cost: 17.82s
Train Epoch: 27 	Average Loss: -2.2560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0793

Learning rate: 0.00019856445951489985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: -1.1190	Cost: 36.06s
Train Epoch: 28 [40960/90000 (45%)]	Loss: -2.2437	Cost: 9.66s
Train Epoch: 28 [81920/90000 (91%)]	Loss: -2.1800	Cost: 14.28s
Train Epoch: 28 	Average Loss: -2.3275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8611

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.0001984564334529206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: -1.0004	Cost: 34.60s
Train Epoch: 29 [40960/90000 (45%)]	Loss: -2.3254	Cost: 9.61s
Train Epoch: 29 [81920/90000 (91%)]	Loss: -2.5265	Cost: 12.15s
Train Epoch: 29 	Average Loss: -2.4631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8307

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.00019834452049953302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: -1.2847	Cost: 35.46s
Train Epoch: 30 [40960/90000 (45%)]	Loss: -2.5094	Cost: 9.66s
Train Epoch: 30 [81920/90000 (91%)]	Loss: -2.4468	Cost: 15.29s
Train Epoch: 30 	Average Loss: -2.5704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5042

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.00019822872507286893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: -1.1964	Cost: 34.97s
Train Epoch: 31 [40960/90000 (45%)]	Loss: -2.4280	Cost: 9.70s
Train Epoch: 31 [81920/90000 (91%)]	Loss: -2.4117	Cost: 17.50s
Train Epoch: 31 	Average Loss: -2.6428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7786

Learning rate: 0.00019810905174433345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: -1.3539	Cost: 37.00s
Train Epoch: 32 [40960/90000 (45%)]	Loss: -2.2929	Cost: 9.72s
Train Epoch: 32 [81920/90000 (91%)]	Loss: -2.3170	Cost: 13.43s
Train Epoch: 32 	Average Loss: -2.5060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9055

Learning rate: 0.00019798550523842474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: -1.1582	Cost: 34.49s
Train Epoch: 33 [40960/90000 (45%)]	Loss: -2.5479	Cost: 9.70s
Train Epoch: 33 [81920/90000 (91%)]	Loss: -2.5200	Cost: 12.55s
Train Epoch: 33 	Average Loss: -2.5418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7787

Learning rate: 0.00019785809043254728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: -1.2584	Cost: 33.48s
Train Epoch: 34 [40960/90000 (45%)]	Loss: -2.4583	Cost: 9.79s
Train Epoch: 34 [81920/90000 (91%)]	Loss: -2.4657	Cost: 12.39s
Train Epoch: 34 	Average Loss: -2.6548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7697

Learning rate: 0.00019772681235681944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: -1.3908	Cost: 36.60s
Train Epoch: 35 [40960/90000 (45%)]	Loss: -2.3963	Cost: 9.88s
Train Epoch: 35 [81920/90000 (91%)]	Loss: -2.5674	Cost: 18.27s
Train Epoch: 35 	Average Loss: -2.6039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6539

Learning rate: 0.00019759167619387482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: -1.3846	Cost: 35.67s
Train Epoch: 36 [40960/90000 (45%)]	Loss: -2.5848	Cost: 9.71s
Train Epoch: 36 [81920/90000 (91%)]	Loss: -2.7313	Cost: 18.14s
Train Epoch: 36 	Average Loss: -2.7070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7194

Learning rate: 0.0001974526872786578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: -1.1938	Cost: 39.73s
Train Epoch: 37 [40960/90000 (45%)]	Loss: -2.4538	Cost: 9.67s
Train Epoch: 37 [81920/90000 (91%)]	Loss: -2.2953	Cost: 13.18s
Train Epoch: 37 	Average Loss: -2.5890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8920

Learning rate: 0.00019730985109821272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: -1.2817	Cost: 36.54s
Train Epoch: 38 [40960/90000 (45%)]	Loss: -2.6172	Cost: 9.92s
Train Epoch: 38 [81920/90000 (91%)]	Loss: -2.7665	Cost: 11.60s
Train Epoch: 38 	Average Loss: -2.6568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6355

Learning rate: 0.00019716317329146745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: -1.2336	Cost: 35.98s
Train Epoch: 39 [40960/90000 (45%)]	Loss: -2.5456	Cost: 9.65s
Train Epoch: 39 [81920/90000 (91%)]	Loss: -2.7529	Cost: 18.02s
Train Epoch: 39 	Average Loss: -2.8219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7188

Learning rate: 0.00019701265964901062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: -0.8674	Cost: 35.57s
Train Epoch: 40 [40960/90000 (45%)]	Loss: -2.8114	Cost: 9.68s
Train Epoch: 40 [81920/90000 (91%)]	Loss: -2.5080	Cost: 18.49s
Train Epoch: 40 	Average Loss: -2.7449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6202

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: -1.3241	Cost: 36.90s
Train Epoch: 41 [40960/90000 (45%)]	Loss: -2.6703	Cost: 9.72s
Train Epoch: 41 [81920/90000 (91%)]	Loss: -2.6890	Cost: 13.18s
Train Epoch: 41 	Average Loss: -2.7854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5395

Learning rate: 0.00019670014877624353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: -1.5301	Cost: 36.70s
Train Epoch: 42 [40960/90000 (45%)]	Loss: -2.4901	Cost: 9.92s
Train Epoch: 42 [81920/90000 (91%)]	Loss: -2.6315	Cost: 12.97s
Train Epoch: 42 	Average Loss: -2.6776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8025

Learning rate: 0.0001965381638833274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: -1.1327	Cost: 35.56s
Train Epoch: 43 [40960/90000 (45%)]	Loss: -2.7150	Cost: 9.59s
Train Epoch: 43 [81920/90000 (91%)]	Loss: -2.6829	Cost: 17.49s
Train Epoch: 43 	Average Loss: -2.8154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6708

Learning rate: 0.000196372367829001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: -1.5081	Cost: 35.17s
Train Epoch: 44 [40960/90000 (45%)]	Loss: -3.0025	Cost: 9.71s
Train Epoch: 44 [81920/90000 (91%)]	Loss: -2.9649	Cost: 17.87s
Train Epoch: 44 	Average Loss: -2.8627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5938

Learning rate: 0.00019620276715860861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: -1.4373	Cost: 35.40s
Train Epoch: 45 [40960/90000 (45%)]	Loss: -2.9640	Cost: 9.74s
Train Epoch: 45 [81920/90000 (91%)]	Loss: -3.1618	Cost: 13.54s
Train Epoch: 45 	Average Loss: -2.9992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5833

Learning rate: 0.00019602936856769434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: -1.8114	Cost: 38.63s
Train Epoch: 46 [40960/90000 (45%)]	Loss: -2.9918	Cost: 9.59s
Train Epoch: 46 [81920/90000 (91%)]	Loss: -3.0468	Cost: 14.60s
Train Epoch: 46 	Average Loss: -3.0465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6935

Learning rate: 0.00019585217890173763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: -1.8072	Cost: 36.53s
Train Epoch: 47 [40960/90000 (45%)]	Loss: -3.0400	Cost: 9.71s
Train Epoch: 47 [81920/90000 (91%)]	Loss: -3.1182	Cost: 13.22s
Train Epoch: 47 	Average Loss: -3.1085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5987

Learning rate: 0.0001956712051558831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: -1.7229	Cost: 33.36s
Train Epoch: 48 [40960/90000 (45%)]	Loss: -2.7005	Cost: 9.72s
Train Epoch: 48 [81920/90000 (91%)]	Loss: -3.0216	Cost: 19.39s
Train Epoch: 48 	Average Loss: -3.0649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5272

Learning rate: 0.00019548645447466434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: -1.3676	Cost: 38.83s
Train Epoch: 49 [40960/90000 (45%)]	Loss: -3.0380	Cost: 9.71s
Train Epoch: 49 [81920/90000 (91%)]	Loss: -3.1063	Cost: 14.65s
Train Epoch: 49 	Average Loss: -3.1085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5899

Learning rate: 0.00019529793415172192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: -1.5078	Cost: 38.38s
Train Epoch: 50 [40960/90000 (45%)]	Loss: -3.2624	Cost: 9.71s
Train Epoch: 50 [81920/90000 (91%)]	Loss: -3.2249	Cost: 13.81s
Train Epoch: 50 	Average Loss: -3.1618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6014

Learning rate: 0.0001951056516295154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: -1.6366	Cost: 35.58s
Train Epoch: 51 [40960/90000 (45%)]	Loss: -2.9528	Cost: 9.68s
Train Epoch: 51 [81920/90000 (91%)]	Loss: -3.1586	Cost: 13.48s
Train Epoch: 51 	Average Loss: -3.1508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5719

Learning rate: 0.0001949096144990295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: -1.8489	Cost: 33.10s
Train Epoch: 52 [40960/90000 (45%)]	Loss: -3.0782	Cost: 9.81s
Train Epoch: 52 [81920/90000 (91%)]	Loss: -2.9207	Cost: 18.39s
Train Epoch: 52 	Average Loss: -3.1144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7533

Learning rate: 0.00019470983049947442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: -1.1377	Cost: 35.75s
Train Epoch: 53 [40960/90000 (45%)]	Loss: -2.9061	Cost: 9.88s
Train Epoch: 53 [81920/90000 (91%)]	Loss: -3.3322	Cost: 17.03s
Train Epoch: 53 	Average Loss: -3.0202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6940

Learning rate: 0.00019450630751798048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: -1.3366	Cost: 38.10s
Train Epoch: 54 [40960/90000 (45%)]	Loss: -3.1304	Cost: 9.49s
Train Epoch: 54 [81920/90000 (91%)]	Loss: -3.3109	Cost: 15.19s
Train Epoch: 54 	Average Loss: -3.2458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7928

Learning rate: 0.00019429905358928646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: -1.5931	Cost: 34.83s
Train Epoch: 55 [40960/90000 (45%)]	Loss: -3.1140	Cost: 9.60s
Train Epoch: 55 [81920/90000 (91%)]	Loss: -3.0935	Cost: 12.87s
Train Epoch: 55 	Average Loss: -3.0464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5855

Learning rate: 0.00019408807689542257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: -1.3484	Cost: 34.75s
Train Epoch: 56 [40960/90000 (45%)]	Loss: -3.0719	Cost: 9.71s
Train Epoch: 56 [81920/90000 (91%)]	Loss: -3.0871	Cost: 18.88s
Train Epoch: 56 	Average Loss: -3.1061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6474

Learning rate: 0.00019387338576538744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: -1.3194	Cost: 34.40s
Train Epoch: 57 [40960/90000 (45%)]	Loss: -2.9529	Cost: 9.92s
Train Epoch: 57 [81920/90000 (91%)]	Loss: -3.0215	Cost: 17.58s
Train Epoch: 57 	Average Loss: -3.0655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7427

Learning rate: 0.00019365498867481926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: -1.3415	Cost: 35.69s
Train Epoch: 58 [40960/90000 (45%)]	Loss: -3.0077	Cost: 9.73s
Train Epoch: 58 [81920/90000 (91%)]	Loss: -3.2753	Cost: 13.09s
Train Epoch: 58 	Average Loss: -3.0106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8469

Learning rate: 0.00019343289424566122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: -1.2790	Cost: 37.75s
Train Epoch: 59 [40960/90000 (45%)]	Loss: -3.1753	Cost: 9.51s
Train Epoch: 59 [81920/90000 (91%)]	Loss: -3.5087	Cost: 13.86s
Train Epoch: 59 	Average Loss: -3.1235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4852

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00019320711124582108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: -1.3065	Cost: 35.93s
Train Epoch: 60 [40960/90000 (45%)]	Loss: -3.2879	Cost: 9.44s
Train Epoch: 60 [81920/90000 (91%)]	Loss: -3.2291	Cost: 13.61s
Train Epoch: 60 	Average Loss: -3.2899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7183

Learning rate: 0.00019297764858882514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: -1.3631	Cost: 33.33s
Train Epoch: 61 [40960/90000 (45%)]	Loss: -3.1190	Cost: 9.80s
Train Epoch: 61 [81920/90000 (91%)]	Loss: -3.4542	Cost: 18.64s
Train Epoch: 61 	Average Loss: -3.2729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5246

Learning rate: 0.00019274451533346612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: -1.7860	Cost: 35.33s
Train Epoch: 62 [40960/90000 (45%)]	Loss: -3.3652	Cost: 9.64s
Train Epoch: 62 [81920/90000 (91%)]	Loss: -3.4578	Cost: 16.71s
Train Epoch: 62 	Average Loss: -3.4396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3116

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019250772068344577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: -1.8386	Cost: 39.50s
Train Epoch: 63 [40960/90000 (45%)]	Loss: -3.4316	Cost: 9.60s
Train Epoch: 63 [81920/90000 (91%)]	Loss: -3.5741	Cost: 14.01s
Train Epoch: 63 	Average Loss: -3.5435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3443

Learning rate: 0.00019226727398701147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: -1.4177	Cost: 33.93s
Train Epoch: 64 [40960/90000 (45%)]	Loss: -3.5555	Cost: 9.62s
Train Epoch: 64 [81920/90000 (91%)]	Loss: -3.5576	Cost: 13.99s
Train Epoch: 64 	Average Loss: -3.5400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3016

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00019202318473658702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: -1.8685	Cost: 34.02s
Train Epoch: 65 [40960/90000 (45%)]	Loss: -3.4444	Cost: 10.19s
Train Epoch: 65 [81920/90000 (91%)]	Loss: -3.5494	Cost: 17.49s
Train Epoch: 65 	Average Loss: -3.5716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4894

Learning rate: 0.0001917754625683981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: -1.7269	Cost: 34.24s
Train Epoch: 66 [40960/90000 (45%)]	Loss: -3.3928	Cost: 9.74s
Train Epoch: 66 [81920/90000 (91%)]	Loss: -3.6627	Cost: 17.19s
Train Epoch: 66 	Average Loss: -3.4095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6386

Learning rate: 0.00019152411726209174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: -1.5996	Cost: 36.65s
Train Epoch: 67 [40960/90000 (45%)]	Loss: -3.2382	Cost: 9.68s
Train Epoch: 67 [81920/90000 (91%)]	Loss: -3.4580	Cost: 13.12s
Train Epoch: 67 	Average Loss: -3.4251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5617

Learning rate: 0.00019126915874035028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: -1.0730	Cost: 34.79s
Train Epoch: 68 [40960/90000 (45%)]	Loss: -3.0389	Cost: 9.62s
Train Epoch: 68 [81920/90000 (91%)]	Loss: -2.9838	Cost: 12.55s
Train Epoch: 68 	Average Loss: -3.1366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8301

Learning rate: 0.00019101059706849957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: -1.3696	Cost: 34.31s
Train Epoch: 69 [40960/90000 (45%)]	Loss: -3.0058	Cost: 9.62s
Train Epoch: 69 [81920/90000 (91%)]	Loss: -3.5064	Cost: 13.77s
Train Epoch: 69 	Average Loss: -3.1335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5310

Learning rate: 0.0001907484424541117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: -1.5390	Cost: 34.61s
Train Epoch: 70 [40960/90000 (45%)]	Loss: -3.3863	Cost: 9.80s
Train Epoch: 70 [81920/90000 (91%)]	Loss: -3.4560	Cost: 18.08s
Train Epoch: 70 	Average Loss: -3.4370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4281

Learning rate: 0.00019048270524660196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: -1.8121	Cost: 35.60s
Train Epoch: 71 [40960/90000 (45%)]	Loss: -3.2822	Cost: 9.82s
Train Epoch: 71 [81920/90000 (91%)]	Loss: -3.0872	Cost: 18.29s
Train Epoch: 71 	Average Loss: -3.4175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7959

Learning rate: 0.00019021339593682028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: -0.7669	Cost: 35.42s
Train Epoch: 72 [40960/90000 (45%)]	Loss: -2.2230	Cost: 9.60s
Train Epoch: 72 [81920/90000 (91%)]	Loss: -1.8695	Cost: 13.16s
Train Epoch: 72 	Average Loss: -2.2711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5213

Learning rate: 0.0001899405251566371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: -0.2227	Cost: 36.57s
Train Epoch: 73 [40960/90000 (45%)]	Loss: -2.3102	Cost: 9.88s
Train Epoch: 73 [81920/90000 (91%)]	Loss: -2.9111	Cost: 13.02s
Train Epoch: 73 	Average Loss: -2.3173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9212

Learning rate: 0.0001896641036785236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: -1.1670	Cost: 35.01s
Train Epoch: 74 [40960/90000 (45%)]	Loss: -3.2261	Cost: 9.65s
Train Epoch: 74 [81920/90000 (91%)]	Loss: -3.4783	Cost: 13.53s
Train Epoch: 74 	Average Loss: -3.1423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5763

Learning rate: 0.00018938414241512636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: -1.3160	Cost: 32.81s
Train Epoch: 75 [40960/90000 (45%)]	Loss: -3.4208	Cost: 9.58s
Train Epoch: 75 [81920/90000 (91%)]	Loss: -3.7234	Cost: 18.49s
Train Epoch: 75 	Average Loss: -3.5288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4148

Learning rate: 0.00018910065241883677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: -1.3744	Cost: 35.36s
Train Epoch: 76 [40960/90000 (45%)]	Loss: -3.7712	Cost: 9.75s
Train Epoch: 76 [81920/90000 (91%)]	Loss: -3.8054	Cost: 19.05s
Train Epoch: 76 	Average Loss: -3.7567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1857

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00018881364488135445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: -1.6159	Cost: 38.72s
Train Epoch: 77 [40960/90000 (45%)]	Loss: -3.9375	Cost: 9.58s
Train Epoch: 77 [81920/90000 (91%)]	Loss: -3.6823	Cost: 14.41s
Train Epoch: 77 	Average Loss: -3.7781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4128

Learning rate: 0.00018852313113324552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: -1.7701	Cost: 35.10s
Train Epoch: 78 [40960/90000 (45%)]	Loss: -3.8355	Cost: 9.65s
Train Epoch: 78 [81920/90000 (91%)]	Loss: -3.7508	Cost: 13.52s
Train Epoch: 78 	Average Loss: -3.7653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2784

Learning rate: 0.00018822912264349534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: -1.7114	Cost: 34.84s
Train Epoch: 79 [40960/90000 (45%)]	Loss: -3.6823	Cost: 9.92s
Train Epoch: 79 [81920/90000 (91%)]	Loss: -3.9402	Cost: 18.06s
Train Epoch: 79 	Average Loss: -3.8134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3898

Learning rate: 0.00018793163101905563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: -1.7810	Cost: 36.00s
Train Epoch: 80 [40960/90000 (45%)]	Loss: -3.6556	Cost: 9.69s
Train Epoch: 80 [81920/90000 (91%)]	Loss: -3.7703	Cost: 16.98s
Train Epoch: 80 	Average Loss: -3.6813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6977

Learning rate: 0.00018763066800438636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: -1.2889	Cost: 36.92s
Train Epoch: 81 [40960/90000 (45%)]	Loss: -3.3847	Cost: 9.72s
Train Epoch: 81 [81920/90000 (91%)]	Loss: -3.6725	Cost: 14.33s
Train Epoch: 81 	Average Loss: -3.3638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3556

Learning rate: 0.000187326245480992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: -1.3783	Cost: 34.84s
Train Epoch: 82 [40960/90000 (45%)]	Loss: -3.6708	Cost: 9.62s
Train Epoch: 82 [81920/90000 (91%)]	Loss: -3.7385	Cost: 13.69s
Train Epoch: 82 	Average Loss: -3.4942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4812

Learning rate: 0.00018701837546695256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: -1.2233	Cost: 35.89s
Train Epoch: 83 [40960/90000 (45%)]	Loss: -3.8263	Cost: 9.63s
Train Epoch: 83 [81920/90000 (91%)]	Loss: -3.9468	Cost: 13.40s
Train Epoch: 83 	Average Loss: -3.7912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4809

Learning rate: 0.00018670707011644898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: -1.6023	Cost: 32.04s
Train Epoch: 84 [40960/90000 (45%)]	Loss: -3.7300	Cost: 9.70s
Train Epoch: 84 [81920/90000 (91%)]	Loss: -4.0202	Cost: 20.43s
Train Epoch: 84 	Average Loss: -3.8348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5427

Learning rate: 0.0001863923417192835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: -1.9039	Cost: 35.22s
Train Epoch: 85 [40960/90000 (45%)]	Loss: -4.0913	Cost: 9.91s
Train Epoch: 85 [81920/90000 (91%)]	Loss: -4.0542	Cost: 15.86s
Train Epoch: 85 	Average Loss: -3.9734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3979

Learning rate: 0.00018607420270039436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: -1.7141	Cost: 37.41s
Train Epoch: 86 [40960/90000 (45%)]	Loss: -4.0927	Cost: 9.58s
Train Epoch: 86 [81920/90000 (91%)]	Loss: -4.2435	Cost: 14.76s
Train Epoch: 86 	Average Loss: -3.9802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1248

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 0.00018575266561936523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: -1.7947	Cost: 35.79s
Train Epoch: 87 [40960/90000 (45%)]	Loss: -4.1279	Cost: 9.67s
Train Epoch: 87 [81920/90000 (91%)]	Loss: -3.9717	Cost: 13.59s
Train Epoch: 87 	Average Loss: -4.1252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2344

Learning rate: 0.0001854277431699295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: -1.6056	Cost: 35.13s
Train Epoch: 88 [40960/90000 (45%)]	Loss: -4.1814	Cost: 10.01s
Train Epoch: 88 [81920/90000 (91%)]	Loss: -4.2900	Cost: 18.03s
Train Epoch: 88 	Average Loss: -4.1025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3413

Learning rate: 0.0001850994481794692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: -1.7717	Cost: 36.06s
Train Epoch: 89 [40960/90000 (45%)]	Loss: -4.1793	Cost: 9.77s
Train Epoch: 89 [81920/90000 (91%)]	Loss: -4.0763	Cost: 17.47s
Train Epoch: 89 	Average Loss: -4.0753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3877

Learning rate: 0.0001847677936085083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: -1.6803	Cost: 35.66s
Train Epoch: 90 [40960/90000 (45%)]	Loss: -4.1901	Cost: 9.79s
Train Epoch: 90 [81920/90000 (91%)]	Loss: -3.8612	Cost: 13.61s
Train Epoch: 90 	Average Loss: -4.0487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3487

Learning rate: 0.00018443279255020146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: -1.7909	Cost: 38.52s
Train Epoch: 91 [40960/90000 (45%)]	Loss: -3.9384	Cost: 9.71s
Train Epoch: 91 [81920/90000 (91%)]	Loss: -4.0752	Cost: 12.48s
Train Epoch: 91 	Average Loss: -4.0062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2708

Learning rate: 0.00018409445822981687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: -1.6802	Cost: 33.18s
Train Epoch: 92 [40960/90000 (45%)]	Loss: -3.9860	Cost: 9.62s
Train Epoch: 92 [81920/90000 (91%)]	Loss: -3.9730	Cost: 13.39s
Train Epoch: 92 	Average Loss: -4.0449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3903

Learning rate: 0.00018375280400421414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: -1.8459	Cost: 32.63s
Train Epoch: 93 [40960/90000 (45%)]	Loss: -3.7068	Cost: 9.78s
Train Epoch: 93 [81920/90000 (91%)]	Loss: -3.7564	Cost: 18.69s
Train Epoch: 93 	Average Loss: -3.8610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3721

Learning rate: 0.00018340784336131708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: -1.5474	Cost: 37.18s
Train Epoch: 94 [40960/90000 (45%)]	Loss: -4.0269	Cost: 9.65s
Train Epoch: 94 [81920/90000 (91%)]	Loss: -3.9330	Cost: 15.93s
Train Epoch: 94 	Average Loss: -3.8896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4627

Learning rate: 0.00018305958991958124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: -1.8151	Cost: 40.09s
Train Epoch: 95 [40960/90000 (45%)]	Loss: -3.9905	Cost: 9.45s
Train Epoch: 95 [81920/90000 (91%)]	Loss: -4.0574	Cost: 15.03s
Train Epoch: 95 	Average Loss: -4.0871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3977

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: -2.0164	Cost: 35.73s
Train Epoch: 96 [40960/90000 (45%)]	Loss: -4.4189	Cost: 9.60s
Train Epoch: 96 [81920/90000 (91%)]	Loss: -4.2499	Cost: 13.77s
Train Epoch: 96 	Average Loss: -4.1788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3446

Learning rate: 0.0001823532597628427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: -1.8848	Cost: 33.64s
Train Epoch: 97 [40960/90000 (45%)]	Loss: -4.4950	Cost: 9.98s
Train Epoch: 97 [81920/90000 (91%)]	Loss: -4.2445	Cost: 17.79s
Train Epoch: 97 	Average Loss: -4.2389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2071

Learning rate: 0.0001819952109325452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: -1.7834	Cost: 36.10s
Train Epoch: 98 [40960/90000 (45%)]	Loss: -4.1219	Cost: 9.77s
Train Epoch: 98 [81920/90000 (91%)]	Loss: -4.2320	Cost: 18.60s
Train Epoch: 98 	Average Loss: -4.1518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1746

Learning rate: 0.00018163392507171837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: -1.8174	Cost: 38.43s
Train Epoch: 99 [40960/90000 (45%)]	Loss: -4.2478	Cost: 9.98s
Train Epoch: 99 [81920/90000 (91%)]	Loss: -4.2190	Cost: 14.93s
Train Epoch: 99 	Average Loss: -4.1198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3973

Learning rate: 0.00018126941644330935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: -1.5861	Cost: 36.87s
Train Epoch: 100 [40960/90000 (45%)]	Loss: -4.2374	Cost: 9.58s
Train Epoch: 100 [81920/90000 (91%)]	Loss: -4.3455	Cost: 13.29s
Train Epoch: 100 	Average Loss: -4.1867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1803

Learning rate: 0.0001809016994374947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: -1.8049	Cost: 34.61s
Train Epoch: 101 [40960/90000 (45%)]	Loss: -4.3903	Cost: 9.76s
Train Epoch: 101 [81920/90000 (91%)]	Loss: -4.1307	Cost: 18.03s
Train Epoch: 101 	Average Loss: -4.2380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2613

Learning rate: 0.00018053078857111214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: -2.1249	Cost: 34.73s
Train Epoch: 102 [40960/90000 (45%)]	Loss: -4.0531	Cost: 9.80s
Train Epoch: 102 [81920/90000 (91%)]	Loss: -4.2385	Cost: 17.54s
Train Epoch: 102 	Average Loss: -4.1622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0552

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00018015669848708761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: -1.9273	Cost: 37.02s
Train Epoch: 103 [40960/90000 (45%)]	Loss: -4.2817	Cost: 9.60s
Train Epoch: 103 [81920/90000 (91%)]	Loss: -4.3746	Cost: 13.87s
Train Epoch: 103 	Average Loss: -4.2306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1489

Learning rate: 0.00017977944395385705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: -2.0867	Cost: 35.29s
Train Epoch: 104 [40960/90000 (45%)]	Loss: -4.3433	Cost: 9.57s
Train Epoch: 104 [81920/90000 (91%)]	Loss: -4.3774	Cost: 12.99s
Train Epoch: 104 	Average Loss: -4.3603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2032

Learning rate: 0.00017939903986478347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: -2.0119	Cost: 33.09s
Train Epoch: 105 [40960/90000 (45%)]	Loss: -4.3724	Cost: 9.55s
Train Epoch: 105 [81920/90000 (91%)]	Loss: -4.2210	Cost: 14.70s
Train Epoch: 105 	Average Loss: -4.2922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3165

Learning rate: 0.00017901550123756898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: -1.7449	Cost: 33.63s
Train Epoch: 106 [40960/90000 (45%)]	Loss: -4.3726	Cost: 9.70s
Train Epoch: 106 [81920/90000 (91%)]	Loss: -4.1151	Cost: 19.11s
Train Epoch: 106 	Average Loss: -4.1708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2709

Learning rate: 0.00017862884321366183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: -1.8634	Cost: 35.58s
Train Epoch: 107 [40960/90000 (45%)]	Loss: -4.4233	Cost: 9.75s
Train Epoch: 107 [81920/90000 (91%)]	Loss: -4.5291	Cost: 16.16s
Train Epoch: 107 	Average Loss: -4.3544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1171

Learning rate: 0.00017823908105765875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: -2.0392	Cost: 37.69s
Train Epoch: 108 [40960/90000 (45%)]	Loss: -4.3860	Cost: 9.77s
Train Epoch: 108 [81920/90000 (91%)]	Loss: -4.5825	Cost: 15.49s
Train Epoch: 108 	Average Loss: -4.5413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0077

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Learning rate: 0.00017784623015670232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: -2.0775	Cost: 35.11s
Train Epoch: 109 [40960/90000 (45%)]	Loss: -4.4802	Cost: 9.63s
Train Epoch: 109 [81920/90000 (91%)]	Loss: -4.4615	Cost: 14.17s
Train Epoch: 109 	Average Loss: -4.4985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1547

Learning rate: 0.00017745030601987337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: -1.7831	Cost: 33.73s
Train Epoch: 110 [40960/90000 (45%)]	Loss: -4.7611	Cost: 9.97s
Train Epoch: 110 [81920/90000 (91%)]	Loss: -4.6127	Cost: 18.57s
Train Epoch: 110 	Average Loss: -4.5357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1117

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 0.0001770513242775789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: -2.2199	Cost: 36.15s
Train Epoch: 111 [40960/90000 (45%)]	Loss: -4.6709	Cost: 9.75s
Train Epoch: 111 [81920/90000 (91%)]	Loss: -4.6378	Cost: 17.27s
Train Epoch: 111 	Average Loss: -4.6033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0666

Learning rate: 0.00017664930068093498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: -1.5331	Cost: 38.45s
Train Epoch: 112 [40960/90000 (45%)]	Loss: -4.7296	Cost: 9.59s
Train Epoch: 112 [81920/90000 (91%)]	Loss: -4.8548	Cost: 15.49s
Train Epoch: 112 	Average Loss: -4.5415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0609

Learning rate: 0.0001762442511011448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: -1.6219	Cost: 36.22s
Train Epoch: 113 [40960/90000 (45%)]	Loss: -4.5563	Cost: 9.93s
Train Epoch: 113 [81920/90000 (91%)]	Loss: -4.5845	Cost: 12.79s
Train Epoch: 113 	Average Loss: -4.5717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1437

Learning rate: 0.0001758361915288722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: -2.0821	Cost: 35.14s
Train Epoch: 114 [40960/90000 (45%)]	Loss: -4.7899	Cost: 9.63s
Train Epoch: 114 [81920/90000 (91%)]	Loss: -4.7929	Cost: 16.86s
Train Epoch: 114 	Average Loss: -4.6211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0013

Learning rate: 0.0001754251380736104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: -2.0219	Cost: 34.92s
Train Epoch: 115 [40960/90000 (45%)]	Loss: -4.6349	Cost: 9.71s
Train Epoch: 115 [81920/90000 (91%)]	Loss: -4.7678	Cost: 18.33s
Train Epoch: 115 	Average Loss: -4.6378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1441

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: -1.9498	Cost: 35.81s
Train Epoch: 116 [40960/90000 (45%)]	Loss: -4.7154	Cost: 9.87s
Train Epoch: 116 [81920/90000 (91%)]	Loss: -4.7294	Cost: 13.17s
Train Epoch: 116 	Average Loss: -4.6484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0626

Learning rate: 0.00017459411454241822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: -1.9255	Cost: 39.07s
Train Epoch: 117 [40960/90000 (45%)]	Loss: -4.4696	Cost: 9.60s
Train Epoch: 117 [81920/90000 (91%)]	Loss: -4.6795	Cost: 14.51s
Train Epoch: 117 	Average Loss: -4.5370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0189

Learning rate: 0.00017417417727387391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: -1.9944	Cost: 36.26s
Train Epoch: 118 [40960/90000 (45%)]	Loss: -4.8645	Cost: 9.69s
Train Epoch: 118 [81920/90000 (91%)]	Loss: -4.8729	Cost: 13.74s
Train Epoch: 118 	Average Loss: -4.7154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0360

Learning rate: 0.00017375131173581737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: -2.0560	Cost: 33.26s
Train Epoch: 119 [40960/90000 (45%)]	Loss: -4.9730	Cost: 9.82s
Train Epoch: 119 [81920/90000 (91%)]	Loss: -4.9091	Cost: 18.34s
Train Epoch: 119 	Average Loss: -4.7886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0526

Learning rate: 0.000173325534622256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: -2.3748	Cost: 35.35s
Train Epoch: 120 [40960/90000 (45%)]	Loss: -5.1075	Cost: 9.74s
Train Epoch: 120 [81920/90000 (91%)]	Loss: -4.6956	Cost: 18.28s
Train Epoch: 120 	Average Loss: -4.8135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1648

Learning rate: 0.00017289686274214115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: -2.0898	Cost: 35.81s
Train Epoch: 121 [40960/90000 (45%)]	Loss: -4.6947	Cost: 9.66s
Train Epoch: 121 [81920/90000 (91%)]	Loss: -4.8850	Cost: 13.32s
Train Epoch: 121 	Average Loss: -4.7407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1380

Learning rate: 0.00017246531301870466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: -1.1694	Cost: 38.05s
Train Epoch: 122 [40960/90000 (45%)]	Loss: -4.8316	Cost: 10.16s
Train Epoch: 122 [81920/90000 (91%)]	Loss: -4.9481	Cost: 11.41s
Train Epoch: 122 	Average Loss: -4.6724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0297

Learning rate: 0.00017203090248879067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: -2.1681	Cost: 35.43s
Train Epoch: 123 [40960/90000 (45%)]	Loss: -4.2585	Cost: 9.97s
Train Epoch: 123 [81920/90000 (91%)]	Loss: -4.0786	Cost: 17.19s
Train Epoch: 123 	Average Loss: -4.5714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4652

Learning rate: 0.00017159364830218312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: -1.8125	Cost: 34.23s
Train Epoch: 124 [40960/90000 (45%)]	Loss: -4.5052	Cost: 9.77s
Train Epoch: 124 [81920/90000 (91%)]	Loss: -4.6359	Cost: 18.28s
Train Epoch: 124 	Average Loss: -4.3811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1903

Learning rate: 0.00017115356772092854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: -1.4780	Cost: 39.00s
Train Epoch: 125 [40960/90000 (45%)]	Loss: -4.7790	Cost: 9.67s
Train Epoch: 125 [81920/90000 (91%)]	Loss: -4.5824	Cost: 13.79s
Train Epoch: 125 	Average Loss: -4.5431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1035

Learning rate: 0.00017071067811865473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: -2.0896	Cost: 34.71s
Train Epoch: 126 [40960/90000 (45%)]	Loss: -4.7347	Cost: 9.71s
Train Epoch: 126 [81920/90000 (91%)]	Loss: -4.4272	Cost: 13.94s
Train Epoch: 126 	Average Loss: -4.5250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4688

Learning rate: 0.00017026499697988493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: -1.4728	Cost: 34.30s
Train Epoch: 127 [40960/90000 (45%)]	Loss: -4.5251	Cost: 9.72s
Train Epoch: 127 [81920/90000 (91%)]	Loss: -4.6951	Cost: 13.42s
Train Epoch: 127 	Average Loss: -4.4431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0285

Learning rate: 0.00016981654189934727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: -1.9206	Cost: 34.21s
Train Epoch: 128 [40960/90000 (45%)]	Loss: -4.7762	Cost: 9.94s
Train Epoch: 128 [81920/90000 (91%)]	Loss: -5.0773	Cost: 18.72s
Train Epoch: 128 	Average Loss: -4.7725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1760

Learning rate: 0.0001693653305812805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: -1.4883	Cost: 35.84s
Train Epoch: 129 [40960/90000 (45%)]	Loss: -4.8678	Cost: 9.69s
Train Epoch: 129 [81920/90000 (91%)]	Loss: -5.1425	Cost: 18.01s
Train Epoch: 129 	Average Loss: -4.7861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2589

Saving model as e129_model.pt & e129_waveforms_supplementary.hdf5
Learning rate: 0.00016891138083873484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: -1.7941	Cost: 37.52s
Train Epoch: 130 [40960/90000 (45%)]	Loss: -5.0053	Cost: 9.64s
Train Epoch: 130 [81920/90000 (91%)]	Loss: -5.0344	Cost: 13.56s
Train Epoch: 130 	Average Loss: -4.8785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0012

Learning rate: 0.00016845471059286887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: -2.2426	Cost: 36.31s
Train Epoch: 131 [40960/90000 (45%)]	Loss: -5.2065	Cost: 9.59s
Train Epoch: 131 [81920/90000 (91%)]	Loss: -5.2743	Cost: 12.89s
Train Epoch: 131 	Average Loss: -5.0017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0150

Learning rate: 0.0001679953378722419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: -2.2387	Cost: 33.93s
Train Epoch: 132 [40960/90000 (45%)]	Loss: -5.1586	Cost: 9.77s
Train Epoch: 132 [81920/90000 (91%)]	Loss: -5.1724	Cost: 17.84s
Train Epoch: 132 	Average Loss: -4.9844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0088

Learning rate: 0.00016753328081210242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: -2.2405	Cost: 36.17s
Train Epoch: 133 [40960/90000 (45%)]	Loss: -4.8757	Cost: 9.66s
Train Epoch: 133 [81920/90000 (91%)]	Loss: -5.3152	Cost: 17.83s
Train Epoch: 133 	Average Loss: -5.1119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0938

Learning rate: 0.000167068557653672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: -2.2794	Cost: 35.48s
Train Epoch: 134 [40960/90000 (45%)]	Loss: -5.2417	Cost: 9.80s
Train Epoch: 134 [81920/90000 (91%)]	Loss: -5.2009	Cost: 13.13s
Train Epoch: 134 	Average Loss: -5.0873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0407

Learning rate: 0.00016660118674342514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: -2.2324	Cost: 35.36s
Train Epoch: 135 [40960/90000 (45%)]	Loss: -5.1570	Cost: 9.59s
Train Epoch: 135 [81920/90000 (91%)]	Loss: -5.2621	Cost: 14.58s
Train Epoch: 135 	Average Loss: -5.0725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0052

Learning rate: 0.00016613118653236516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: -1.9705	Cost: 35.82s
Train Epoch: 136 [40960/90000 (45%)]	Loss: -5.2671	Cost: 9.73s
Train Epoch: 136 [81920/90000 (91%)]	Loss: -5.0770	Cost: 12.94s
Train Epoch: 136 	Average Loss: -5.0390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0315

Learning rate: 0.0001656585755752956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: -1.8948	Cost: 33.61s
Train Epoch: 137 [40960/90000 (45%)]	Loss: -5.3567	Cost: 9.67s
Train Epoch: 137 [81920/90000 (91%)]	Loss: -4.9785	Cost: 18.29s
Train Epoch: 137 	Average Loss: -5.0653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1242

Learning rate: 0.00016518337253008784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: -1.8609	Cost: 36.02s
Train Epoch: 138 [40960/90000 (45%)]	Loss: -5.0731	Cost: 9.86s
Train Epoch: 138 [81920/90000 (91%)]	Loss: -4.9734	Cost: 17.78s
Train Epoch: 138 	Average Loss: -4.9295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0271

Learning rate: 0.0001647055961569444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: -1.5566	Cost: 37.41s
Train Epoch: 139 [40960/90000 (45%)]	Loss: -5.0207	Cost: 9.68s
Train Epoch: 139 [81920/90000 (91%)]	Loss: -5.1084	Cost: 15.68s
Train Epoch: 139 	Average Loss: -4.8738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0204

Learning rate: 0.0001642252653176584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: -2.1253	Cost: 36.33s
Train Epoch: 140 [40960/90000 (45%)]	Loss: -5.2088	Cost: 9.64s
Train Epoch: 140 [81920/90000 (91%)]	Loss: -5.2106	Cost: 13.93s
Train Epoch: 140 	Average Loss: -5.0759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0503

Learning rate: 0.00016374239897486894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: -1.9361	Cost: 34.35s
Train Epoch: 141 [40960/90000 (45%)]	Loss: -5.4850	Cost: 9.82s
Train Epoch: 141 [81920/90000 (91%)]	Loss: -5.3268	Cost: 18.27s
Train Epoch: 141 	Average Loss: -5.1121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1036

Learning rate: 0.0001632570161913124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: -2.4155	Cost: 35.29s
Train Epoch: 142 [40960/90000 (45%)]	Loss: -5.2354	Cost: 9.67s
Train Epoch: 142 [81920/90000 (91%)]	Loss: -4.9279	Cost: 18.65s
Train Epoch: 142 	Average Loss: -4.9473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2042

Learning rate: 0.00016276913612907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: -1.8277	Cost: 36.52s
Train Epoch: 143 [40960/90000 (45%)]	Loss: -5.1041	Cost: 9.59s
Train Epoch: 143 [81920/90000 (91%)]	Loss: -5.2574	Cost: 13.11s
Train Epoch: 143 	Average Loss: -4.9056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0777

Learning rate: 0.00016227877804881122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: -1.9505	Cost: 34.80s
Train Epoch: 144 [40960/90000 (45%)]	Loss: -5.2028	Cost: 9.65s
Train Epoch: 144 [81920/90000 (91%)]	Loss: -5.2033	Cost: 13.44s
Train Epoch: 144 	Average Loss: -5.1735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1545

Learning rate: 0.0001617859613090334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: -2.2951	Cost: 37.27s
Train Epoch: 145 [40960/90000 (45%)]	Loss: -5.3549	Cost: 9.50s
Train Epoch: 145 [81920/90000 (91%)]	Loss: -5.2779	Cost: 14.79s
Train Epoch: 145 	Average Loss: -5.1951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0374

Learning rate: 0.00016129070536529763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: -2.5653	Cost: 33.29s
Train Epoch: 146 [40960/90000 (45%)]	Loss: -5.2467	Cost: 9.80s
Train Epoch: 146 [81920/90000 (91%)]	Loss: -5.4062	Cost: 18.89s
Train Epoch: 146 	Average Loss: -5.2838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2418

Learning rate: 0.00016079302976946053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: -2.5762	Cost: 36.58s
Train Epoch: 147 [40960/90000 (45%)]	Loss: -5.3469	Cost: 9.71s
Train Epoch: 147 [81920/90000 (91%)]	Loss: -5.3775	Cost: 14.90s
Train Epoch: 147 	Average Loss: -5.2095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1565

Learning rate: 0.00016029295416890245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: -2.3722	Cost: 37.66s
Train Epoch: 148 [40960/90000 (45%)]	Loss: -5.2775	Cost: 9.55s
Train Epoch: 148 [81920/90000 (91%)]	Loss: -5.4286	Cost: 14.84s
Train Epoch: 148 	Average Loss: -5.1599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1639

Learning rate: 0.00015979049830575187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: -1.7569	Cost: 35.87s
Train Epoch: 149 [40960/90000 (45%)]	Loss: -5.1764	Cost: 9.55s
Train Epoch: 149 [81920/90000 (91%)]	Loss: -5.2310	Cost: 12.71s
Train Epoch: 149 	Average Loss: -5.1535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1989

Learning rate: 0.00015928568201610592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: -1.8320	Cost: 36.20s
Train Epoch: 150 [40960/90000 (45%)]	Loss: -5.3172	Cost: 9.51s
Train Epoch: 150 [81920/90000 (91%)]	Loss: -5.2974	Cost: 15.28s
Train Epoch: 150 	Average Loss: -5.2357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0397

Learning rate: 0.00015877852522924732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: -2.3453	Cost: 31.47s
Train Epoch: 151 [40960/90000 (45%)]	Loss: -5.3797	Cost: 9.69s
Train Epoch: 151 [81920/90000 (91%)]	Loss: -5.4042	Cost: 19.30s
Train Epoch: 151 	Average Loss: -5.3489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2040

Learning rate: 0.00015826904796685762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: -2.3862	Cost: 37.32s
Train Epoch: 152 [40960/90000 (45%)]	Loss: -5.1450	Cost: 9.71s
Train Epoch: 152 [81920/90000 (91%)]	Loss: -5.4213	Cost: 15.85s
Train Epoch: 152 	Average Loss: -5.3713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2023

Learning rate: 0.00015775727034222675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: -2.2576	Cost: 36.56s
Train Epoch: 153 [40960/90000 (45%)]	Loss: -5.4629	Cost: 9.55s
Train Epoch: 153 [81920/90000 (91%)]	Loss: -5.3317	Cost: 13.47s
Train Epoch: 153 	Average Loss: -5.2669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0047

Learning rate: 0.00015724321255945907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: -2.0643	Cost: 34.07s
Train Epoch: 154 [40960/90000 (45%)]	Loss: -5.3872	Cost: 9.80s
Train Epoch: 154 [81920/90000 (91%)]	Loss: -5.4693	Cost: 12.52s
Train Epoch: 154 	Average Loss: -5.3129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2510

Learning rate: 0.00015672689491267567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: -2.2202	Cost: 35.12s
Train Epoch: 155 [40960/90000 (45%)]	Loss: -5.3143	Cost: 9.87s
Train Epoch: 155 [81920/90000 (91%)]	Loss: -5.4737	Cost: 16.95s
Train Epoch: 155 	Average Loss: -5.4328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2574

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: -2.2305	Cost: 34.49s
Train Epoch: 156 [40960/90000 (45%)]	Loss: -5.6908	Cost: 9.69s
Train Epoch: 156 [81920/90000 (91%)]	Loss: -5.6471	Cost: 17.32s
Train Epoch: 156 	Average Loss: -5.5426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2933

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Learning rate: 0.00015568756164881882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: -2.1698	Cost: 37.55s
Train Epoch: 157 [40960/90000 (45%)]	Loss: -5.7655	Cost: 9.65s
Train Epoch: 157 [81920/90000 (91%)]	Loss: -5.7364	Cost: 13.66s
Train Epoch: 157 	Average Loss: -5.5877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4154

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Learning rate: 0.00015516458706284303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: -2.1738	Cost: 36.61s
Train Epoch: 158 [40960/90000 (45%)]	Loss: -5.8025	Cost: 9.77s
Train Epoch: 158 [81920/90000 (91%)]	Loss: -5.9079	Cost: 13.03s
Train Epoch: 158 	Average Loss: -5.6323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1976

Learning rate: 0.0001546394346734269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: -2.6748	Cost: 35.38s
Train Epoch: 159 [40960/90000 (45%)]	Loss: -5.7633	Cost: 9.64s
Train Epoch: 159 [81920/90000 (91%)]	Loss: -5.5859	Cost: 15.26s
Train Epoch: 159 	Average Loss: -5.6188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2524

Learning rate: 0.00015411212521268755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: -2.1638	Cost: 32.55s
Train Epoch: 160 [40960/90000 (45%)]	Loss: -5.5971	Cost: 9.71s
Train Epoch: 160 [81920/90000 (91%)]	Loss: -5.7158	Cost: 19.06s
Train Epoch: 160 	Average Loss: -5.4758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2706

Learning rate: 0.00015358267949789963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: -1.9874	Cost: 36.32s
Train Epoch: 161 [40960/90000 (45%)]	Loss: -5.5796	Cost: 9.96s
Train Epoch: 161 [81920/90000 (91%)]	Loss: -5.7702	Cost: 16.57s
Train Epoch: 161 	Average Loss: -5.6429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3655

Learning rate: 0.00015305111843067339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: -2.6069	Cost: 38.63s
Train Epoch: 162 [40960/90000 (45%)]	Loss: -5.9543	Cost: 9.72s
Train Epoch: 162 [81920/90000 (91%)]	Loss: -5.9481	Cost: 13.95s
Train Epoch: 162 	Average Loss: -5.8056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4695

Saving model as e162_model.pt & e162_waveforms_supplementary.hdf5
Learning rate: 0.00015251746299612957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: -2.2620	Cost: 33.53s
Train Epoch: 163 [40960/90000 (45%)]	Loss: -5.8481	Cost: 9.60s
Train Epoch: 163 [81920/90000 (91%)]	Loss: -5.7894	Cost: 12.56s
Train Epoch: 163 	Average Loss: -5.6949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0657

Learning rate: 0.00015198173426207094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: -2.8992	Cost: 34.07s
Train Epoch: 164 [40960/90000 (45%)]	Loss: -5.9107	Cost: 9.61s
Train Epoch: 164 [81920/90000 (91%)]	Loss: -5.8071	Cost: 19.42s
Train Epoch: 164 	Average Loss: -5.7430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0132

Learning rate: 0.00015144395337815067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: -2.5882	Cost: 34.63s
Train Epoch: 165 [40960/90000 (45%)]	Loss: -5.7763	Cost: 9.71s
Train Epoch: 165 [81920/90000 (91%)]	Loss: -5.8663	Cost: 17.78s
Train Epoch: 165 	Average Loss: -5.6445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2216

Learning rate: 0.00015090414157503714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: -2.5668	Cost: 39.46s
Train Epoch: 166 [40960/90000 (45%)]	Loss: -5.8908	Cost: 9.55s
Train Epoch: 166 [81920/90000 (91%)]	Loss: -5.9088	Cost: 12.33s
Train Epoch: 166 	Average Loss: -5.7571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2445

Learning rate: 0.00015036232016357607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: -2.6856	Cost: 35.48s
Train Epoch: 167 [40960/90000 (45%)]	Loss: -5.6371	Cost: 9.99s
Train Epoch: 167 [81920/90000 (91%)]	Loss: -5.9882	Cost: 12.63s
Train Epoch: 167 	Average Loss: -5.7374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3013

Learning rate: 0.00014981851053394907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: -2.6378	Cost: 35.89s
Train Epoch: 168 [40960/90000 (45%)]	Loss: -5.8494	Cost: 9.53s
Train Epoch: 168 [81920/90000 (91%)]	Loss: -5.9590	Cost: 14.71s
Train Epoch: 168 	Average Loss: -5.7713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3603

Learning rate: 0.00014927273415482915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: -2.8330	Cost: 32.26s
Train Epoch: 169 [40960/90000 (45%)]	Loss: -5.9004	Cost: 9.81s
Train Epoch: 169 [81920/90000 (91%)]	Loss: -6.1187	Cost: 18.71s
Train Epoch: 169 	Average Loss: -5.8528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3828

Learning rate: 0.00014872501257253323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: -2.3954	Cost: 36.38s
Train Epoch: 170 [40960/90000 (45%)]	Loss: -5.7381	Cost: 10.22s
Train Epoch: 170 [81920/90000 (91%)]	Loss: -5.5218	Cost: 15.80s
Train Epoch: 170 	Average Loss: -5.6151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0316

Learning rate: 0.00014817536741017152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: -2.0369	Cost: 35.90s
Train Epoch: 171 [40960/90000 (45%)]	Loss: -5.6413	Cost: 9.65s
Train Epoch: 171 [81920/90000 (91%)]	Loss: -5.6568	Cost: 14.32s
Train Epoch: 171 	Average Loss: -5.5000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4001

Learning rate: 0.0001476238203667939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: -2.6690	Cost: 34.75s
Train Epoch: 172 [40960/90000 (45%)]	Loss: -5.9243	Cost: 9.54s
Train Epoch: 172 [81920/90000 (91%)]	Loss: -6.0226	Cost: 12.33s
Train Epoch: 172 	Average Loss: -5.7515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2209

Learning rate: 0.00014707039321653327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: -2.7056	Cost: 35.10s
Train Epoch: 173 [40960/90000 (45%)]	Loss: -5.9564	Cost: 10.02s
Train Epoch: 173 [81920/90000 (91%)]	Loss: -6.0116	Cost: 17.66s
Train Epoch: 173 	Average Loss: -5.8621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3702

Learning rate: 0.00014651510780774586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: -2.2923	Cost: 35.18s
Train Epoch: 174 [40960/90000 (45%)]	Loss: -6.0423	Cost: 9.71s
Train Epoch: 174 [81920/90000 (91%)]	Loss: -6.1045	Cost: 17.68s
Train Epoch: 174 	Average Loss: -5.8782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5028

Saving model as e174_model.pt & e174_waveforms_supplementary.hdf5
Learning rate: 0.00014595798606214882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: -2.5568	Cost: 38.39s
Train Epoch: 175 [40960/90000 (45%)]	Loss: -6.0943	Cost: 9.59s
Train Epoch: 175 [81920/90000 (91%)]	Loss: -5.9929	Cost: 12.79s
Train Epoch: 175 	Average Loss: -5.8780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4699

Learning rate: 0.00014539904997395468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: -2.5175	Cost: 35.07s
Train Epoch: 176 [40960/90000 (45%)]	Loss: -5.8471	Cost: 9.63s
Train Epoch: 176 [81920/90000 (91%)]	Loss: -6.1090	Cost: 12.81s
Train Epoch: 176 	Average Loss: -5.9375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3121

Learning rate: 0.00014483832160900326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: -2.1686	Cost: 36.11s
Train Epoch: 177 [40960/90000 (45%)]	Loss: -6.2030	Cost: 9.70s
Train Epoch: 177 [81920/90000 (91%)]	Loss: -6.1706	Cost: 15.24s
Train Epoch: 177 	Average Loss: -6.0372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6101

Saving model as e177_model.pt & e177_waveforms_supplementary.hdf5
Learning rate: 0.00014427582310389016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: -2.5009	Cost: 32.78s
Train Epoch: 178 [40960/90000 (45%)]	Loss: -5.9578	Cost: 9.75s
Train Epoch: 178 [81920/90000 (91%)]	Loss: -6.0562	Cost: 18.76s
Train Epoch: 178 	Average Loss: -6.0239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4523

Learning rate: 0.0001437115766650933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: -2.9015	Cost: 37.51s
Train Epoch: 179 [40960/90000 (45%)]	Loss: -6.1508	Cost: 9.69s
Train Epoch: 179 [81920/90000 (91%)]	Loss: -5.9846	Cost: 14.68s
Train Epoch: 179 	Average Loss: -5.9975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5995

Learning rate: 0.0001431456045680959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: -2.3064	Cost: 36.59s
Train Epoch: 180 [40960/90000 (45%)]	Loss: -6.3456	Cost: 9.64s
Train Epoch: 180 [81920/90000 (91%)]	Loss: -6.3962	Cost: 15.47s
Train Epoch: 180 	Average Loss: -6.0976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5974

Learning rate: 0.00014257792915650726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: -2.6218	Cost: 34.41s
Train Epoch: 181 [40960/90000 (45%)]	Loss: -6.2170	Cost: 9.61s
Train Epoch: 181 [81920/90000 (91%)]	Loss: -6.4284	Cost: 13.30s
Train Epoch: 181 	Average Loss: -6.2414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7233

Saving model as e181_model.pt & e181_waveforms_supplementary.hdf5
Learning rate: 0.0001420085728411806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: -2.4517	Cost: 32.92s
Train Epoch: 182 [40960/90000 (45%)]	Loss: -6.1722	Cost: 9.72s
Train Epoch: 182 [81920/90000 (91%)]	Loss: -6.2953	Cost: 18.30s
Train Epoch: 182 	Average Loss: -6.1555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5222

Learning rate: 0.0001414375580993284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: -2.7683	Cost: 35.87s
Train Epoch: 183 [40960/90000 (45%)]	Loss: -6.1253	Cost: 10.01s
Train Epoch: 183 [81920/90000 (91%)]	Loss: -6.3196	Cost: 17.20s
Train Epoch: 183 	Average Loss: -6.1202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6427

Learning rate: 0.00014086490747363488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: -2.6713	Cost: 37.87s
Train Epoch: 184 [40960/90000 (45%)]	Loss: -6.6869	Cost: 9.56s
Train Epoch: 184 [81920/90000 (91%)]	Loss: -6.6360	Cost: 14.88s
Train Epoch: 184 	Average Loss: -6.2785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5288

Learning rate: 0.00014029064357136623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: -2.3925	Cost: 36.53s
Train Epoch: 185 [40960/90000 (45%)]	Loss: -6.2817	Cost: 9.64s
Train Epoch: 185 [81920/90000 (91%)]	Loss: -6.2627	Cost: 13.18s
Train Epoch: 185 	Average Loss: -6.1805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6457

Learning rate: 0.00013971478906347803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: -2.7673	Cost: 33.93s
Train Epoch: 186 [40960/90000 (45%)]	Loss: -6.3068	Cost: 9.82s
Train Epoch: 186 [81920/90000 (91%)]	Loss: -6.3068	Cost: 18.06s
Train Epoch: 186 	Average Loss: -6.2949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6064

Learning rate: 0.0001391373666837202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: -2.3996	Cost: 34.60s
Train Epoch: 187 [40960/90000 (45%)]	Loss: -6.2476	Cost: 9.72s
Train Epoch: 187 [81920/90000 (91%)]	Loss: -6.5054	Cost: 16.65s
Train Epoch: 187 	Average Loss: -6.2680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5259

Learning rate: 0.0001385583992277396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: -2.8243	Cost: 35.44s
Train Epoch: 188 [40960/90000 (45%)]	Loss: -6.2752	Cost: 9.72s
Train Epoch: 188 [81920/90000 (91%)]	Loss: -6.2746	Cost: 13.04s
Train Epoch: 188 	Average Loss: -6.2167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5887

Learning rate: 0.00013797790955218008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: -2.7798	Cost: 35.13s
Train Epoch: 189 [40960/90000 (45%)]	Loss: -6.5501	Cost: 9.65s
Train Epoch: 189 [81920/90000 (91%)]	Loss: -6.4723	Cost: 14.63s
Train Epoch: 189 	Average Loss: -6.2810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5438

Learning rate: 0.00013739592057378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: -2.5680	Cost: 35.86s
Train Epoch: 190 [40960/90000 (45%)]	Loss: -6.3751	Cost: 9.73s
Train Epoch: 190 [81920/90000 (91%)]	Loss: -6.5379	Cost: 13.16s
Train Epoch: 190 	Average Loss: -6.2835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5388

Learning rate: 0.00013681245526846775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: -2.3918	Cost: 33.73s
Train Epoch: 191 [40960/90000 (45%)]	Loss: -6.2116	Cost: 9.84s
Train Epoch: 191 [81920/90000 (91%)]	Loss: -6.1399	Cost: 19.14s
Train Epoch: 191 	Average Loss: -6.1385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4038

Learning rate: 0.00013622753667045454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: -2.0322	Cost: 36.36s
Train Epoch: 192 [40960/90000 (45%)]	Loss: -6.3390	Cost: 9.91s
Train Epoch: 192 [81920/90000 (91%)]	Loss: -6.2706	Cost: 15.82s
Train Epoch: 192 	Average Loss: -6.0681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4572

Learning rate: 0.00013564118787132503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: -2.5767	Cost: 38.45s
Train Epoch: 193 [40960/90000 (45%)]	Loss: -6.4083	Cost: 9.63s
Train Epoch: 193 [81920/90000 (91%)]	Loss: -6.5705	Cost: 14.19s
Train Epoch: 193 	Average Loss: -6.2580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4990

Learning rate: 0.00013505343201912587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: -2.4360	Cost: 35.02s
Train Epoch: 194 [40960/90000 (45%)]	Loss: -6.5149	Cost: 9.66s
Train Epoch: 194 [81920/90000 (91%)]	Loss: -6.5361	Cost: 12.71s
Train Epoch: 194 	Average Loss: -6.3111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5511

Learning rate: 0.0001344642923174517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: -2.5686	Cost: 34.73s
Train Epoch: 195 [40960/90000 (45%)]	Loss: -6.6265	Cost: 9.87s
Train Epoch: 195 [81920/90000 (91%)]	Loss: -6.6152	Cost: 14.69s
Train Epoch: 195 	Average Loss: -6.4272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5813

Learning rate: 0.00013387379202452914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: -2.9920	Cost: 32.99s
Train Epoch: 196 [40960/90000 (45%)]	Loss: -6.6341	Cost: 9.76s
Train Epoch: 196 [81920/90000 (91%)]	Loss: -6.5466	Cost: 18.26s
Train Epoch: 196 	Average Loss: -6.4226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4585

Learning rate: 0.00013328195445229865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: -2.5857	Cost: 39.18s
Train Epoch: 197 [40960/90000 (45%)]	Loss: -6.6227	Cost: 9.72s
Train Epoch: 197 [81920/90000 (91%)]	Loss: -6.5662	Cost: 14.77s
Train Epoch: 197 	Average Loss: -6.3567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6238

Learning rate: 0.00013268880296549425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: -2.4703	Cost: 35.97s
Train Epoch: 198 [40960/90000 (45%)]	Loss: -6.5393	Cost: 9.69s
Train Epoch: 198 [81920/90000 (91%)]	Loss: -6.4500	Cost: 15.51s
Train Epoch: 198 	Average Loss: -6.3287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7300

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 0.00013209436098072093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: -3.2162	Cost: 36.78s
Train Epoch: 199 [40960/90000 (45%)]	Loss: -6.7550	Cost: 9.56s
Train Epoch: 199 [81920/90000 (91%)]	Loss: -6.5515	Cost: 13.54s
Train Epoch: 199 	Average Loss: -6.4814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5493

Learning rate: 0.00013149865196553047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: -2.6380	Cost: 33.91s
Train Epoch: 200 [40960/90000 (45%)]	Loss: -6.6738	Cost: 9.90s
Train Epoch: 200 [81920/90000 (91%)]	Loss: -6.7416	Cost: 19.41s
Train Epoch: 200 	Average Loss: -6.5093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8537

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 0.00013090169943749474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: -2.8474	Cost: 37.44s
Train Epoch: 201 [40960/90000 (45%)]	Loss: -6.8794	Cost: 9.67s
Train Epoch: 201 [81920/90000 (91%)]	Loss: -6.6790	Cost: 15.04s
Train Epoch: 201 	Average Loss: -6.6013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6838

Learning rate: 0.0001303035269632774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: -3.0083	Cost: 35.48s
Train Epoch: 202 [40960/90000 (45%)]	Loss: -6.6019	Cost: 9.70s
Train Epoch: 202 [81920/90000 (91%)]	Loss: -6.6273	Cost: 14.42s
Train Epoch: 202 	Average Loss: -6.5469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3737

Learning rate: 0.00012970415815770348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: -2.9188	Cost: 35.41s
Train Epoch: 203 [40960/90000 (45%)]	Loss: -6.6459	Cost: 9.59s
Train Epoch: 203 [81920/90000 (91%)]	Loss: -6.5924	Cost: 12.56s
Train Epoch: 203 	Average Loss: -6.5261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6329

Learning rate: 0.00012910361668282719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: -3.0319	Cost: 35.06s
Train Epoch: 204 [40960/90000 (45%)]	Loss: -6.7768	Cost: 9.62s
Train Epoch: 204 [81920/90000 (91%)]	Loss: -6.5787	Cost: 18.42s
Train Epoch: 204 	Average Loss: -6.4826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5465

Learning rate: 0.0001285019262469976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: -3.0614	Cost: 35.87s
Train Epoch: 205 [40960/90000 (45%)]	Loss: -6.5954	Cost: 9.70s
Train Epoch: 205 [81920/90000 (91%)]	Loss: -6.8463	Cost: 18.38s
Train Epoch: 205 	Average Loss: -6.5228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6026

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: -2.7995	Cost: 36.17s
Train Epoch: 206 [40960/90000 (45%)]	Loss: -6.8409	Cost: 9.74s
Train Epoch: 206 [81920/90000 (91%)]	Loss: -7.0289	Cost: 13.16s
Train Epoch: 206 	Average Loss: -6.7160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7126

Learning rate: 0.00012729519355173254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: -2.9146	Cost: 34.44s
Train Epoch: 207 [40960/90000 (45%)]	Loss: -7.1906	Cost: 9.66s
Train Epoch: 207 [81920/90000 (91%)]	Loss: -7.0088	Cost: 12.98s
Train Epoch: 207 	Average Loss: -6.7965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7133

Learning rate: 0.00012669019893203759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: -3.1510	Cost: 34.44s
Train Epoch: 208 [40960/90000 (45%)]	Loss: -6.9811	Cost: 9.96s
Train Epoch: 208 [81920/90000 (91%)]	Loss: -7.2586	Cost: 12.85s
Train Epoch: 208 	Average Loss: -6.9048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8915

Saving model as e208_model.pt & e208_waveforms_supplementary.hdf5
Learning rate: 0.0001260841506289897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: -2.9587	Cost: 33.06s
Train Epoch: 209 [40960/90000 (45%)]	Loss: -6.6006	Cost: 9.80s
Train Epoch: 209 [81920/90000 (91%)]	Loss: -6.7449	Cost: 19.57s
Train Epoch: 209 	Average Loss: -6.6447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9538

Saving model as e209_model.pt & e209_waveforms_supplementary.hdf5
Learning rate: 0.00012547707256833825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: -3.3760	Cost: 36.03s
Train Epoch: 210 [40960/90000 (45%)]	Loss: -7.0095	Cost: 9.74s
Train Epoch: 210 [81920/90000 (91%)]	Loss: -6.9556	Cost: 14.35s
Train Epoch: 210 	Average Loss: -6.7637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7208

Learning rate: 0.00012486898871648549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: -2.6844	Cost: 39.53s
Train Epoch: 211 [40960/90000 (45%)]	Loss: -6.9479	Cost: 9.55s
Train Epoch: 211 [81920/90000 (91%)]	Loss: -6.8519	Cost: 14.79s
Train Epoch: 211 	Average Loss: -6.6604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7227

Learning rate: 0.00012425992307954077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: -2.5830	Cost: 33.45s
Train Epoch: 212 [40960/90000 (45%)]	Loss: -6.9964	Cost: 9.61s
Train Epoch: 212 [81920/90000 (91%)]	Loss: -6.8433	Cost: 12.52s
Train Epoch: 212 	Average Loss: -6.7117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7762

Learning rate: 0.0001236498997023725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: -3.1532	Cost: 32.91s
Train Epoch: 213 [40960/90000 (45%)]	Loss: -7.0875	Cost: 9.80s
Train Epoch: 213 [81920/90000 (91%)]	Loss: -6.9346	Cost: 18.92s
Train Epoch: 213 	Average Loss: -6.7760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6063

Learning rate: 0.00012303894266765908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: -2.8906	Cost: 35.30s
Train Epoch: 214 [40960/90000 (45%)]	Loss: -6.9358	Cost: 9.77s
Train Epoch: 214 [81920/90000 (91%)]	Loss: -6.9079	Cost: 18.80s
Train Epoch: 214 	Average Loss: -6.7535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7013

Learning rate: 0.00012242707609493814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: -3.1795	Cost: 38.65s
Train Epoch: 215 [40960/90000 (45%)]	Loss: -7.0948	Cost: 9.57s
Train Epoch: 215 [81920/90000 (91%)]	Loss: -6.8931	Cost: 13.47s
Train Epoch: 215 	Average Loss: -6.8543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8524

Learning rate: 0.0001218143241396543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: -2.7955	Cost: 35.59s
Train Epoch: 216 [40960/90000 (45%)]	Loss: -7.2168	Cost: 9.83s
Train Epoch: 216 [81920/90000 (91%)]	Loss: -7.2926	Cost: 12.48s
Train Epoch: 216 	Average Loss: -6.9339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0844

Saving model as e216_model.pt & e216_waveforms_supplementary.hdf5
Learning rate: 0.0001212007109922055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: -3.3916	Cost: 36.07s
Train Epoch: 217 [40960/90000 (45%)]	Loss: -7.2940	Cost: 10.03s
Train Epoch: 217 [81920/90000 (91%)]	Loss: -7.2607	Cost: 16.24s
Train Epoch: 217 	Average Loss: -7.0878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8428

Learning rate: 0.00012058626087698816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: -3.2235	Cost: 35.29s
Train Epoch: 218 [40960/90000 (45%)]	Loss: -7.3657	Cost: 9.71s
Train Epoch: 218 [81920/90000 (91%)]	Loss: -7.1941	Cost: 16.90s
Train Epoch: 218 	Average Loss: -7.1278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9692

Learning rate: 0.00011997099805144073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: -3.3123	Cost: 36.15s
Train Epoch: 219 [40960/90000 (45%)]	Loss: -7.2396	Cost: 9.66s
Train Epoch: 219 [81920/90000 (91%)]	Loss: -7.0963	Cost: 13.76s
Train Epoch: 219 	Average Loss: -7.0029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0300

Learning rate: 0.00011935494680508606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: -2.8855	Cost: 38.08s
Train Epoch: 220 [40960/90000 (45%)]	Loss: -7.0145	Cost: 9.59s
Train Epoch: 220 [81920/90000 (91%)]	Loss: -7.0407	Cost: 13.66s
Train Epoch: 220 	Average Loss: -6.8758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8022

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: -3.1731	Cost: 33.07s
Train Epoch: 221 [40960/90000 (45%)]	Loss: -7.4564	Cost: 9.74s
Train Epoch: 221 [81920/90000 (91%)]	Loss: -7.3334	Cost: 12.41s
Train Epoch: 221 	Average Loss: -7.1089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8217

Learning rate: 0.00011812057636271377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: -3.2966	Cost: 32.82s
Train Epoch: 222 [40960/90000 (45%)]	Loss: -7.3290	Cost: 9.65s
Train Epoch: 222 [81920/90000 (91%)]	Loss: -7.2818	Cost: 18.20s
Train Epoch: 222 	Average Loss: -7.1658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0124

Learning rate: 0.00011750230589752765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: -3.3247	Cost: 35.35s
Train Epoch: 223 [40960/90000 (45%)]	Loss: -7.1785	Cost: 9.70s
Train Epoch: 223 [81920/90000 (91%)]	Loss: -7.1768	Cost: 17.39s
Train Epoch: 223 	Average Loss: -7.0836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4170

Learning rate: 0.0001168833444712734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: -2.1512	Cost: 36.72s
Train Epoch: 224 [40960/90000 (45%)]	Loss: -6.1717	Cost: 9.67s
Train Epoch: 224 [81920/90000 (91%)]	Loss: -6.5932	Cost: 14.16s
Train Epoch: 224 	Average Loss: -6.1247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4743

Learning rate: 0.00011626371651948839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: -2.4364	Cost: 35.16s
Train Epoch: 225 [40960/90000 (45%)]	Loss: -6.6795	Cost: 9.74s
Train Epoch: 225 [81920/90000 (91%)]	Loss: -6.9897	Cost: 13.10s
Train Epoch: 225 	Average Loss: -6.6000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7766

Learning rate: 0.00011564344650402312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: -3.3876	Cost: 33.40s
Train Epoch: 226 [40960/90000 (45%)]	Loss: -7.2821	Cost: 9.59s
Train Epoch: 226 [81920/90000 (91%)]	Loss: -7.1834	Cost: 12.59s
Train Epoch: 226 	Average Loss: -6.9707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6179

Learning rate: 0.00011502255891207573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: -2.7818	Cost: 34.12s
Train Epoch: 227 [40960/90000 (45%)]	Loss: -7.2910	Cost: 9.81s
Train Epoch: 227 [81920/90000 (91%)]	Loss: -7.4610	Cost: 18.51s
Train Epoch: 227 	Average Loss: -7.0445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9653

Learning rate: 0.00011440107825522525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: -2.5079	Cost: 35.11s
Train Epoch: 228 [40960/90000 (45%)]	Loss: -7.5064	Cost: 9.84s
Train Epoch: 228 [81920/90000 (91%)]	Loss: -7.4815	Cost: 17.58s
Train Epoch: 228 	Average Loss: -7.2064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0301

Learning rate: 0.00011377902906846383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: -3.2470	Cost: 38.23s
Train Epoch: 229 [40960/90000 (45%)]	Loss: -7.3033	Cost: 9.58s
Train Epoch: 229 [81920/90000 (91%)]	Loss: -7.3537	Cost: 14.62s
Train Epoch: 229 	Average Loss: -7.1839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9980

Learning rate: 0.00011315643590922827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: -3.1868	Cost: 36.40s
Train Epoch: 230 [40960/90000 (45%)]	Loss: -7.6402	Cost: 9.64s
Train Epoch: 230 [81920/90000 (91%)]	Loss: -7.4031	Cost: 12.96s
Train Epoch: 230 	Average Loss: -7.3437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1560

Saving model as e230_model.pt & e230_waveforms_supplementary.hdf5
Learning rate: 0.00011253332335643043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: -3.6379	Cost: 35.21s
Train Epoch: 231 [40960/90000 (45%)]	Loss: -7.5799	Cost: 9.65s
Train Epoch: 231 [81920/90000 (91%)]	Loss: -7.5693	Cost: 18.59s
Train Epoch: 231 	Average Loss: -7.3583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0289

Learning rate: 0.00011190971600948699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: -3.2830	Cost: 35.87s
Train Epoch: 232 [40960/90000 (45%)]	Loss: -7.5264	Cost: 9.77s
Train Epoch: 232 [81920/90000 (91%)]	Loss: -7.5035	Cost: 17.74s
Train Epoch: 232 	Average Loss: -7.2862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8476

Learning rate: 0.00011128563848734816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: -3.0863	Cost: 37.95s
Train Epoch: 233 [40960/90000 (45%)]	Loss: -7.5614	Cost: 9.73s
Train Epoch: 233 [81920/90000 (91%)]	Loss: -7.6588	Cost: 13.25s
Train Epoch: 233 	Average Loss: -7.3838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0866

Learning rate: 0.000110661115427526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: -2.4993	Cost: 34.90s
Train Epoch: 234 [40960/90000 (45%)]	Loss: -7.5426	Cost: 9.67s
Train Epoch: 234 [81920/90000 (91%)]	Loss: -7.4693	Cost: 13.89s
Train Epoch: 234 	Average Loss: -7.3428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9976

Learning rate: 0.00011003617148512149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: -3.2994	Cost: 33.97s
Train Epoch: 235 [40960/90000 (45%)]	Loss: -7.6576	Cost: 9.62s
Train Epoch: 235 [81920/90000 (91%)]	Loss: -7.5667	Cost: 12.96s
Train Epoch: 235 	Average Loss: -7.3820
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0570

Learning rate: 0.00010941083133185143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: -3.4853	Cost: 32.53s
Train Epoch: 236 [40960/90000 (45%)]	Loss: -7.7739	Cost: 9.87s
Train Epoch: 236 [81920/90000 (91%)]	Loss: -7.7586	Cost: 17.32s
Train Epoch: 236 	Average Loss: -7.4793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0734

Learning rate: 0.00010878511965507434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: -2.8540	Cost: 35.23s
Train Epoch: 237 [40960/90000 (45%)]	Loss: -7.5673	Cost: 9.67s
Train Epoch: 237 [81920/90000 (91%)]	Loss: -7.5792	Cost: 18.16s
Train Epoch: 237 	Average Loss: -7.4265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7861

Learning rate: 0.00010815906115681577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: -3.1358	Cost: 38.33s
Train Epoch: 238 [40960/90000 (45%)]	Loss: -7.8412	Cost: 9.59s
Train Epoch: 238 [81920/90000 (91%)]	Loss: -7.8228	Cost: 14.27s
Train Epoch: 238 	Average Loss: -7.5139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8980

Learning rate: 0.00010753268055279328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: -3.5886	Cost: 35.10s
Train Epoch: 239 [40960/90000 (45%)]	Loss: -8.0268	Cost: 9.72s
Train Epoch: 239 [81920/90000 (91%)]	Loss: -7.7199	Cost: 12.56s
Train Epoch: 239 	Average Loss: -7.4936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9567

Learning rate: 0.0001069060025714406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: -3.6114	Cost: 35.96s
Train Epoch: 240 [40960/90000 (45%)]	Loss: -7.6662	Cost: 9.63s
Train Epoch: 240 [81920/90000 (91%)]	Loss: -7.5329	Cost: 13.48s
Train Epoch: 240 	Average Loss: -7.4592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8664

Learning rate: 0.00010627905195293134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: -3.4321	Cost: 33.15s
Train Epoch: 241 [40960/90000 (45%)]	Loss: -7.6559	Cost: 9.99s
Train Epoch: 241 [81920/90000 (91%)]	Loss: -7.8521	Cost: 18.67s
Train Epoch: 241 	Average Loss: -7.5052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8970

Learning rate: 0.00010565185344820243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: -3.3645	Cost: 34.86s
Train Epoch: 242 [40960/90000 (45%)]	Loss: -7.6887	Cost: 9.78s
Train Epoch: 242 [81920/90000 (91%)]	Loss: -7.7315	Cost: 17.20s
Train Epoch: 242 	Average Loss: -7.4551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0627

Learning rate: 0.00010502443181797694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: -3.3127	Cost: 38.41s
Train Epoch: 243 [40960/90000 (45%)]	Loss: -7.7257	Cost: 9.53s
Train Epoch: 243 [81920/90000 (91%)]	Loss: -7.9317	Cost: 15.14s
Train Epoch: 243 	Average Loss: -7.5297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8918

Learning rate: 0.00010439681183178646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: -2.9292	Cost: 33.92s
Train Epoch: 244 [40960/90000 (45%)]	Loss: -7.6673	Cost: 9.86s
Train Epoch: 244 [81920/90000 (91%)]	Loss: -7.8854	Cost: 13.32s
Train Epoch: 244 	Average Loss: -7.5202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0944

Learning rate: 0.00010376901826699342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: -3.1607	Cost: 35.08s
Train Epoch: 245 [40960/90000 (45%)]	Loss: -7.8282	Cost: 9.76s
Train Epoch: 245 [81920/90000 (91%)]	Loss: -7.8117	Cost: 18.43s
Train Epoch: 245 	Average Loss: -7.5183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0677

Learning rate: 0.0001031410759078128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: -3.2468	Cost: 35.27s
Train Epoch: 246 [40960/90000 (45%)]	Loss: -7.6917	Cost: 9.95s
Train Epoch: 246 [81920/90000 (91%)]	Loss: -7.8003	Cost: 17.11s
Train Epoch: 246 	Average Loss: -7.5351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7456

Learning rate: 0.00010251300954433372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: -2.9651	Cost: 37.38s
Train Epoch: 247 [40960/90000 (45%)]	Loss: -7.7137	Cost: 9.70s
Train Epoch: 247 [81920/90000 (91%)]	Loss: -7.7996	Cost: 14.54s
Train Epoch: 247 	Average Loss: -7.4596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8055

Learning rate: 0.0001018848439715408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: -3.2587	Cost: 35.24s
Train Epoch: 248 [40960/90000 (45%)]	Loss: -7.8571	Cost: 9.62s
Train Epoch: 248 [81920/90000 (91%)]	Loss: -7.9170	Cost: 14.07s
Train Epoch: 248 	Average Loss: -7.4885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6483

Learning rate: 0.00010125660398833524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: -3.1500	Cost: 35.73s
Train Epoch: 249 [40960/90000 (45%)]	Loss: -7.8921	Cost: 9.58s
Train Epoch: 249 [81920/90000 (91%)]	Loss: -7.7262	Cost: 17.81s
Train Epoch: 249 	Average Loss: -7.4173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0826

Learning rate: 0.00010062831439655587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: -3.3850	Cost: 35.70s
Train Epoch: 250 [40960/90000 (45%)]	Loss: -7.8979	Cost: 9.78s
Train Epoch: 250 [81920/90000 (91%)]	Loss: -7.7556	Cost: 17.78s
Train Epoch: 250 	Average Loss: -7.4560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1117

Learning rate: 9.999999999999996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: -3.4639	Cost: 37.79s
Train Epoch: 251 [40960/90000 (45%)]	Loss: -7.8327	Cost: 9.61s
Train Epoch: 251 [81920/90000 (91%)]	Loss: -7.8752	Cost: 13.01s
Train Epoch: 251 	Average Loss: -7.5800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0857

Learning rate: 9.937168560344407e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: -3.6063	Cost: 37.11s
Train Epoch: 252 [40960/90000 (45%)]	Loss: -8.0393	Cost: 9.96s
Train Epoch: 252 [81920/90000 (91%)]	Loss: -8.0122	Cost: 12.14s
Train Epoch: 252 	Average Loss: -7.7572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1761

Saving model as e252_model.pt & e252_waveforms_supplementary.hdf5
Learning rate: 9.87433960116647e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: -3.8989	Cost: 35.67s
Train Epoch: 253 [40960/90000 (45%)]	Loss: -7.9172	Cost: 9.71s
Train Epoch: 253 [81920/90000 (91%)]	Loss: -7.7195	Cost: 15.56s
Train Epoch: 253 	Average Loss: -7.8333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4524

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 9.811515602845915e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: -4.0227	Cost: 34.27s
Train Epoch: 254 [40960/90000 (45%)]	Loss: -8.1576	Cost: 9.70s
Train Epoch: 254 [81920/90000 (91%)]	Loss: -7.8956	Cost: 17.99s
Train Epoch: 254 	Average Loss: -7.8854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3048

Learning rate: 9.748699045566624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: -3.8652	Cost: 38.84s
Train Epoch: 255 [40960/90000 (45%)]	Loss: -8.0669	Cost: 9.72s
Train Epoch: 255 [81920/90000 (91%)]	Loss: -8.0236	Cost: 13.64s
Train Epoch: 255 	Average Loss: -7.7801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4160

Learning rate: 9.685892409218716e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: -3.8225	Cost: 34.75s
Train Epoch: 256 [40960/90000 (45%)]	Loss: -8.1268	Cost: 9.67s
Train Epoch: 256 [81920/90000 (91%)]	Loss: -7.9471	Cost: 13.03s
Train Epoch: 256 	Average Loss: -7.8767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2302

Learning rate: 9.623098173300653e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: -3.7410	Cost: 36.15s
Train Epoch: 257 [40960/90000 (45%)]	Loss: -7.9290	Cost: 9.62s
Train Epoch: 257 [81920/90000 (91%)]	Loss: -7.9778	Cost: 13.44s
Train Epoch: 257 	Average Loss: -7.8913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2988

Learning rate: 9.560318816821353e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: -3.5247	Cost: 34.28s
Train Epoch: 258 [40960/90000 (45%)]	Loss: -8.1847	Cost: 9.82s
Train Epoch: 258 [81920/90000 (91%)]	Loss: -8.2865	Cost: 18.57s
Train Epoch: 258 	Average Loss: -7.8905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0805

Learning rate: 9.497556818202306e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: -3.5700	Cost: 35.74s
Train Epoch: 259 [40960/90000 (45%)]	Loss: -8.2123	Cost: 9.85s
Train Epoch: 259 [81920/90000 (91%)]	Loss: -8.4224	Cost: 16.56s
Train Epoch: 259 	Average Loss: -8.0068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1774

Learning rate: 9.434814655179755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: -3.4059	Cost: 39.18s
Train Epoch: 260 [40960/90000 (45%)]	Loss: -8.1392	Cost: 9.53s
Train Epoch: 260 [81920/90000 (91%)]	Loss: -8.3934	Cost: 14.12s
Train Epoch: 260 	Average Loss: -8.0252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4587

Saving model as e260_model.pt & e260_waveforms_supplementary.hdf5
Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: -3.6238	Cost: 35.22s
Train Epoch: 261 [40960/90000 (45%)]	Loss: -8.2062	Cost: 9.63s
Train Epoch: 261 [81920/90000 (91%)]	Loss: -8.2557	Cost: 13.49s
Train Epoch: 261 	Average Loss: -7.9896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4129

Learning rate: 9.309399742855944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: -2.9639	Cost: 35.66s
Train Epoch: 262 [40960/90000 (45%)]	Loss: -8.3756	Cost: 9.74s
Train Epoch: 262 [81920/90000 (91%)]	Loss: -8.3934	Cost: 17.64s
Train Epoch: 262 	Average Loss: -8.0147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5950

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 9.246731944720672e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: -3.6806	Cost: 36.72s
Train Epoch: 263 [40960/90000 (45%)]	Loss: -8.4414	Cost: 9.95s
Train Epoch: 263 [81920/90000 (91%)]	Loss: -8.5005	Cost: 16.41s
Train Epoch: 263 	Average Loss: -8.0979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4365

Learning rate: 9.184093884318424e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: -3.5904	Cost: 41.23s
Train Epoch: 264 [40960/90000 (45%)]	Loss: -8.5308	Cost: 9.55s
Train Epoch: 264 [81920/90000 (91%)]	Loss: -8.2293	Cost: 13.74s
Train Epoch: 264 	Average Loss: -8.1835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3587

Learning rate: 9.121488034492569e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: -3.5259	Cost: 36.14s
Train Epoch: 265 [40960/90000 (45%)]	Loss: -8.2821	Cost: 9.52s
Train Epoch: 265 [81920/90000 (91%)]	Loss: -8.3812	Cost: 13.54s
Train Epoch: 265 	Average Loss: -8.0775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4020

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: -3.6197	Cost: 33.96s
Train Epoch: 266 [40960/90000 (45%)]	Loss: -8.4850	Cost: 9.67s
Train Epoch: 266 [81920/90000 (91%)]	Loss: -8.3889	Cost: 18.24s
Train Epoch: 266 	Average Loss: -8.1131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2157

Learning rate: 8.996382851487852e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: -3.7612	Cost: 35.23s
Train Epoch: 267 [40960/90000 (45%)]	Loss: -8.5400	Cost: 9.67s
Train Epoch: 267 [81920/90000 (91%)]	Loss: -8.4765	Cost: 17.98s
Train Epoch: 267 	Average Loss: -8.2208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3475

Learning rate: 8.9338884572474e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: -3.8440	Cost: 36.94s
Train Epoch: 268 [40960/90000 (45%)]	Loss: -8.4625	Cost: 9.77s
Train Epoch: 268 [81920/90000 (91%)]	Loss: -8.4403	Cost: 13.60s
Train Epoch: 268 	Average Loss: -8.2770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3965

Learning rate: 8.871436151265182e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: -3.9118	Cost: 37.92s
Train Epoch: 269 [40960/90000 (45%)]	Loss: -8.6531	Cost: 10.61s
Train Epoch: 269 [81920/90000 (91%)]	Loss: -8.5467	Cost: 11.63s
Train Epoch: 269 	Average Loss: -8.3560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3140

Learning rate: 8.809028399051304e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: -4.1180	Cost: 35.14s
Train Epoch: 270 [40960/90000 (45%)]	Loss: -8.6449	Cost: 9.62s
Train Epoch: 270 [81920/90000 (91%)]	Loss: -8.4915	Cost: 15.15s
Train Epoch: 270 	Average Loss: -8.3675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6414

Saving model as e270_model.pt & e270_waveforms_supplementary.hdf5
Learning rate: 8.746667664356958e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: -3.9773	Cost: 34.45s
Train Epoch: 271 [40960/90000 (45%)]	Loss: -8.6422	Cost: 9.73s
Train Epoch: 271 [81920/90000 (91%)]	Loss: -8.3511	Cost: 19.04s
Train Epoch: 271 	Average Loss: -8.3994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2864

Learning rate: 8.684356409077174e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: -3.8178	Cost: 39.73s
Train Epoch: 272 [40960/90000 (45%)]	Loss: -8.6415	Cost: 9.66s
Train Epoch: 272 [81920/90000 (91%)]	Loss: -8.7792	Cost: 13.53s
Train Epoch: 272 	Average Loss: -8.3703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6155

Learning rate: 8.622097093153619e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: -3.8787	Cost: 35.76s
Train Epoch: 273 [40960/90000 (45%)]	Loss: -8.5778	Cost: 9.70s
Train Epoch: 273 [81920/90000 (91%)]	Loss: -8.6991	Cost: 13.90s
Train Epoch: 273 	Average Loss: -8.3731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5170

Learning rate: 8.559892174477476e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: -4.0405	Cost: 33.41s
Train Epoch: 274 [40960/90000 (45%)]	Loss: -8.6420	Cost: 9.73s
Train Epoch: 274 [81920/90000 (91%)]	Loss: -8.7838	Cost: 12.57s
Train Epoch: 274 	Average Loss: -8.4083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6142

Learning rate: 8.497744108792427e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: -3.9814	Cost: 32.47s
Train Epoch: 275 [40960/90000 (45%)]	Loss: -8.9176	Cost: 9.74s
Train Epoch: 275 [81920/90000 (91%)]	Loss: -8.8590	Cost: 19.29s
Train Epoch: 275 	Average Loss: -8.5309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4300

Learning rate: 8.435655349597689e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: -3.6898	Cost: 36.42s
Train Epoch: 276 [40960/90000 (45%)]	Loss: -9.1219	Cost: 9.85s
Train Epoch: 276 [81920/90000 (91%)]	Loss: -8.8041	Cost: 16.23s
Train Epoch: 276 	Average Loss: -8.5054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5217

Learning rate: 8.373628348051162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: -3.7589	Cost: 37.60s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -8.9043	Cost: 9.60s
Train Epoch: 277 [81920/90000 (91%)]	Loss: -8.7620	Cost: 15.31s
Train Epoch: 277 	Average Loss: -8.5338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4658

Learning rate: 8.311665552872659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: -3.7399	Cost: 36.38s
Train Epoch: 278 [40960/90000 (45%)]	Loss: -8.8920	Cost: 9.57s
Train Epoch: 278 [81920/90000 (91%)]	Loss: -8.8847	Cost: 13.23s
Train Epoch: 278 	Average Loss: -8.5690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5694

Learning rate: 8.249769410247239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: -3.8676	Cost: 33.74s
Train Epoch: 279 [40960/90000 (45%)]	Loss: -9.0007	Cost: 9.80s
Train Epoch: 279 [81920/90000 (91%)]	Loss: -8.9389	Cost: 18.80s
Train Epoch: 279 	Average Loss: -8.6437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5936

Learning rate: 8.187942363728625e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: -4.4157	Cost: 36.10s
Train Epoch: 280 [40960/90000 (45%)]	Loss: -8.9851	Cost: 9.88s
Train Epoch: 280 [81920/90000 (91%)]	Loss: -8.8255	Cost: 19.07s
Train Epoch: 280 	Average Loss: -8.6439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5644

Learning rate: 8.126186854142752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: -3.8618	Cost: 37.48s
Train Epoch: 281 [40960/90000 (45%)]	Loss: -8.7832	Cost: 9.67s
Train Epoch: 281 [81920/90000 (91%)]	Loss: -8.9862	Cost: 15.18s
Train Epoch: 281 	Average Loss: -8.6737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4994

Learning rate: 8.064505319491398e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: -3.9550	Cost: 35.45s
Train Epoch: 282 [40960/90000 (45%)]	Loss: -8.9182	Cost: 9.90s
Train Epoch: 282 [81920/90000 (91%)]	Loss: -9.0172	Cost: 13.52s
Train Epoch: 282 	Average Loss: -8.7091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7416

Saving model as e282_model.pt & e282_waveforms_supplementary.hdf5
Learning rate: 8.002900194855929e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: -4.1503	Cost: 34.64s
Train Epoch: 283 [40960/90000 (45%)]	Loss: -9.0729	Cost: 10.15s
Train Epoch: 283 [81920/90000 (91%)]	Loss: -8.8729	Cost: 18.53s
Train Epoch: 283 	Average Loss: -8.7429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3079

Learning rate: 7.941373912301183e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: -3.9188	Cost: 35.95s
Train Epoch: 284 [40960/90000 (45%)]	Loss: -9.0282	Cost: 9.63s
Train Epoch: 284 [81920/90000 (91%)]	Loss: -9.0256	Cost: 17.55s
Train Epoch: 284 	Average Loss: -8.6765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5473

Learning rate: 7.879928900779452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: -4.2201	Cost: 39.57s
Train Epoch: 285 [40960/90000 (45%)]	Loss: -9.1015	Cost: 9.73s
Train Epoch: 285 [81920/90000 (91%)]	Loss: -8.8310	Cost: 14.85s
Train Epoch: 285 	Average Loss: -8.7004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5079

Learning rate: 7.818567586034573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: -3.7266	Cost: 36.93s
Train Epoch: 286 [40960/90000 (45%)]	Loss: -9.1398	Cost: 9.59s
Train Epoch: 286 [81920/90000 (91%)]	Loss: -8.9382	Cost: 14.43s
Train Epoch: 286 	Average Loss: -8.6513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5960

Learning rate: 7.757292390506185e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: -4.1462	Cost: 33.66s
Train Epoch: 287 [40960/90000 (45%)]	Loss: -9.2601	Cost: 9.71s
Train Epoch: 287 [81920/90000 (91%)]	Loss: -9.0483	Cost: 18.43s
Train Epoch: 287 	Average Loss: -8.7903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7424

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Learning rate: 7.696105733234094e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: -3.7371	Cost: 40.30s
Train Epoch: 288 [40960/90000 (45%)]	Loss: -9.2105	Cost: 9.64s
Train Epoch: 288 [81920/90000 (91%)]	Loss: -9.2473	Cost: 14.42s
Train Epoch: 288 	Average Loss: -8.8602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9223

Saving model as e288_model.pt & e288_waveforms_supplementary.hdf5
Learning rate: 7.635010029762752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: -3.9008	Cost: 38.69s
Train Epoch: 289 [40960/90000 (45%)]	Loss: -9.0374	Cost: 9.60s
Train Epoch: 289 [81920/90000 (91%)]	Loss: -9.0585	Cost: 13.38s
Train Epoch: 289 	Average Loss: -8.7767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5699

Learning rate: 7.574007692045924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: -4.1605	Cost: 33.30s
Train Epoch: 290 [40960/90000 (45%)]	Loss: -8.8686	Cost: 9.53s
Train Epoch: 290 [81920/90000 (91%)]	Loss: -9.1978	Cost: 12.23s
Train Epoch: 290 	Average Loss: -8.7763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7429

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: -4.3647	Cost: 32.23s
Train Epoch: 291 [40960/90000 (45%)]	Loss: -9.1237	Cost: 9.84s
Train Epoch: 291 [81920/90000 (91%)]	Loss: -9.2361	Cost: 19.48s
Train Epoch: 291 	Average Loss: -8.8822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5036

Learning rate: 7.452292743166178e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: -4.0189	Cost: 35.83s
Train Epoch: 292 [40960/90000 (45%)]	Loss: -9.2691	Cost: 9.92s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -9.2965	Cost: 16.63s
Train Epoch: 292 	Average Loss: -8.9887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8075

Learning rate: 7.391584937101029e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: -4.3946	Cost: 38.65s
Train Epoch: 293 [40960/90000 (45%)]	Loss: -9.2849	Cost: 9.58s
Train Epoch: 293 [81920/90000 (91%)]	Loss: -9.2271	Cost: 11.98s
Train Epoch: 293 	Average Loss: -9.0597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7619

Learning rate: 7.330980106796245e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: -4.0441	Cost: 36.40s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -9.2823	Cost: 9.54s
Train Epoch: 294 [81920/90000 (91%)]	Loss: -9.2727	Cost: 12.44s
Train Epoch: 294 	Average Loss: -9.0669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7723

Learning rate: 7.270480644826745e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: -4.0535	Cost: 36.41s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -9.4410	Cost: 9.63s
Train Epoch: 295 [81920/90000 (91%)]	Loss: -9.4549	Cost: 14.19s
Train Epoch: 295 	Average Loss: -9.0552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6906

Learning rate: 7.210088939607704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: -4.4111	Cost: 32.94s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -9.2787	Cost: 9.75s
Train Epoch: 296 [81920/90000 (91%)]	Loss: -9.4167	Cost: 19.00s
Train Epoch: 296 	Average Loss: -9.0846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8485

Learning rate: 7.149807375300236e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: -4.3567	Cost: 35.33s
Train Epoch: 297 [40960/90000 (45%)]	Loss: -9.5335	Cost: 9.66s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -9.3592	Cost: 15.39s
Train Epoch: 297 	Average Loss: -9.0907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8792

Learning rate: 7.08963833171728e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: -4.1241	Cost: 36.05s
Train Epoch: 298 [40960/90000 (45%)]	Loss: -9.4971	Cost: 9.54s
Train Epoch: 298 [81920/90000 (91%)]	Loss: -9.2874	Cost: 13.91s
Train Epoch: 298 	Average Loss: -9.1303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8208

Learning rate: 7.029584184229648e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: -4.1523	Cost: 36.60s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -9.2664	Cost: 9.56s
Train Epoch: 299 [81920/90000 (91%)]	Loss: -9.0957	Cost: 12.82s
Train Epoch: 299 	Average Loss: -9.0147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7228

Learning rate: 6.969647303672259e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: -4.1117	Cost: 33.26s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -9.4330	Cost: 10.04s
Train Epoch: 300 [81920/90000 (91%)]	Loss: -9.0214	Cost: 18.44s
Train Epoch: 300 	Average Loss: -9.0090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7411

Learning rate: 6.909830056250523e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: -3.7785	Cost: 34.24s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -9.1598	Cost: 9.71s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -9.4928	Cost: 18.10s
Train Epoch: 301 	Average Loss: -9.0876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7460

Learning rate: 6.850134803446949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: -4.2999	Cost: 38.14s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -9.4775	Cost: 9.66s
Train Epoch: 302 [81920/90000 (91%)]	Loss: -9.3379	Cost: 14.62s
Train Epoch: 302 	Average Loss: -9.0997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8391

Learning rate: 6.790563901927903e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: -3.9292	Cost: 36.30s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -9.6489	Cost: 9.75s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -9.5239	Cost: 12.47s
Train Epoch: 303 	Average Loss: -9.1997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9101

Learning rate: 6.731119703450573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: -4.0326	Cost: 35.41s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -9.6900	Cost: 9.59s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -9.6720	Cost: 16.78s
Train Epoch: 304 	Average Loss: -9.2748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9711

Saving model as e304_model.pt & e304_waveforms_supplementary.hdf5
Learning rate: 6.67180455477013e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: -4.2570	Cost: 34.59s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -9.7107	Cost: 9.75s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -9.5928	Cost: 17.52s
Train Epoch: 305 	Average Loss: -9.2712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9323

Learning rate: 6.612620797547083e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: -4.3726	Cost: 35.43s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -9.5654	Cost: 9.77s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -9.5234	Cost: 13.13s
Train Epoch: 306 	Average Loss: -9.2613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7338

Learning rate: 6.553570768254825e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: -4.0040	Cost: 35.39s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -9.5407	Cost: 9.75s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -9.7277	Cost: 13.19s
Train Epoch: 307 	Average Loss: -9.2378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8853

Learning rate: 6.494656798087406e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: -4.3802	Cost: 33.36s
Train Epoch: 308 [40960/90000 (45%)]	Loss: -9.6567	Cost: 9.55s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -9.4132	Cost: 12.43s
Train Epoch: 308 	Average Loss: -9.2612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0526

Saving model as e308_model.pt & e308_waveforms_supplementary.hdf5
Learning rate: 6.435881212867491e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: -4.5588	Cost: 33.45s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -9.6778	Cost: 9.90s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -9.7227	Cost: 18.46s
Train Epoch: 309 	Average Loss: -9.3275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9866

Learning rate: 6.377246332954541e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: -4.3872	Cost: 35.80s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -9.8517	Cost: 9.85s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -9.8456	Cost: 15.66s
Train Epoch: 310 	Average Loss: -9.4151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9272

Learning rate: 6.318754473153218e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: -4.4679	Cost: 36.28s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -9.6851	Cost: 9.66s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -9.7743	Cost: 14.27s
Train Epoch: 311 	Average Loss: -9.4098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9728

Learning rate: 6.260407942621994e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: -4.1443	Cost: 37.86s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -9.8618	Cost: 9.64s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -9.9617	Cost: 13.79s
Train Epoch: 312 	Average Loss: -9.4786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9588

Learning rate: 6.202209044781987e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: -4.5281	Cost: 34.77s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -10.0073	Cost: 9.86s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -9.7628	Cost: 18.64s
Train Epoch: 313 	Average Loss: -9.5194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0970

Saving model as e313_model.pt & e313_waveforms_supplementary.hdf5
Learning rate: 6.144160077226032e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: -4.5873	Cost: 35.31s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -10.0138	Cost: 9.71s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -9.7145	Cost: 18.92s
Train Epoch: 314 	Average Loss: -9.5630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9888

Learning rate: 6.0862633316279744e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: -4.5016	Cost: 38.08s
Train Epoch: 315 [40960/90000 (45%)]	Loss: -9.6318	Cost: 9.62s
Train Epoch: 315 [81920/90000 (91%)]	Loss: -9.7072	Cost: 12.51s
Train Epoch: 315 	Average Loss: -9.5071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8192

Learning rate: 6.028521093652189e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: -4.1212	Cost: 36.97s
Train Epoch: 316 [40960/90000 (45%)]	Loss: -9.7963	Cost: 9.56s
Train Epoch: 316 [81920/90000 (91%)]	Loss: -9.8134	Cost: 12.65s
Train Epoch: 316 	Average Loss: -9.5507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3522

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 5.970935642863369e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: -4.5348	Cost: 33.45s
Train Epoch: 317 [40960/90000 (45%)]	Loss: -9.9765	Cost: 9.62s
Train Epoch: 317 [81920/90000 (91%)]	Loss: -9.8461	Cost: 14.25s
Train Epoch: 317 	Average Loss: -9.6176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9688

Learning rate: 5.9135092526365064e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: -4.6929	Cost: 33.10s
Train Epoch: 318 [40960/90000 (45%)]	Loss: -9.7391	Cost: 9.75s
Train Epoch: 318 [81920/90000 (91%)]	Loss: -9.9001	Cost: 18.36s
Train Epoch: 318 	Average Loss: -9.5861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0446

Learning rate: 5.8562441900671545e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: -4.6701	Cost: 37.73s
Train Epoch: 319 [40960/90000 (45%)]	Loss: -9.9371	Cost: 9.63s
Train Epoch: 319 [81920/90000 (91%)]	Loss: -10.0757	Cost: 16.23s
Train Epoch: 319 	Average Loss: -9.6188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0735

Learning rate: 5.799142715881933e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: -4.9845	Cost: 35.72s
Train Epoch: 320 [40960/90000 (45%)]	Loss: -10.0254	Cost: 9.62s
Train Epoch: 320 [81920/90000 (91%)]	Loss: -9.9363	Cost: 14.53s
Train Epoch: 320 	Average Loss: -9.6931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0671

Learning rate: 5.742207084349269e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: -4.3990	Cost: 38.20s
Train Epoch: 321 [40960/90000 (45%)]	Loss: -9.9156	Cost: 9.84s
Train Epoch: 321 [81920/90000 (91%)]	Loss: -10.1709	Cost: 13.67s
Train Epoch: 321 	Average Loss: -9.6156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1673

Learning rate: 5.68543954319041e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: -4.7109	Cost: 34.50s
Train Epoch: 322 [40960/90000 (45%)]	Loss: -9.9427	Cost: 9.77s
Train Epoch: 322 [81920/90000 (91%)]	Loss: -10.1709	Cost: 18.39s
Train Epoch: 322 	Average Loss: -9.6884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1699

Learning rate: 5.62884233349067e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: -4.2348	Cost: 35.62s
Train Epoch: 323 [40960/90000 (45%)]	Loss: -9.8884	Cost: 9.78s
Train Epoch: 323 [81920/90000 (91%)]	Loss: -10.0562	Cost: 16.47s
Train Epoch: 323 	Average Loss: -9.6986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1474

Learning rate: 5.572417689610984e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: -4.3743	Cost: 37.99s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -10.0893	Cost: 9.67s
Train Epoch: 324 [81920/90000 (91%)]	Loss: -9.8507	Cost: 12.84s
Train Epoch: 324 	Average Loss: -9.7438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1226

Learning rate: 5.516167839099677e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: -5.1232	Cost: 36.29s
Train Epoch: 325 [40960/90000 (45%)]	Loss: -9.7973	Cost: 9.61s
Train Epoch: 325 [81920/90000 (91%)]	Loss: -10.0136	Cost: 12.49s
Train Epoch: 325 	Average Loss: -9.8101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0208

Learning rate: 5.46009500260453e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: -4.2308	Cost: 35.54s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -10.2772	Cost: 9.66s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -10.1449	Cost: 15.44s
Train Epoch: 326 	Average Loss: -9.7599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0711

Learning rate: 5.4042013937851194e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: -4.1108	Cost: 33.14s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -9.9795	Cost: 9.66s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -9.7419	Cost: 18.10s
Train Epoch: 327 	Average Loss: -9.6090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7928

Learning rate: 5.3484892192254136e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: -4.8762	Cost: 37.53s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -9.8355	Cost: 9.67s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -10.2266	Cost: 15.14s
Train Epoch: 328 	Average Loss: -9.5460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9228

Learning rate: 5.292960678346675e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: -4.3847	Cost: 37.88s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -10.0602	Cost: 9.53s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -10.0819	Cost: 12.42s
Train Epoch: 329 	Average Loss: -9.6847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0486

Learning rate: 5.237617963320605e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: -4.6119	Cost: 35.19s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -10.3228	Cost: 9.63s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -10.3748	Cost: 13.41s
Train Epoch: 330 	Average Loss: -9.8495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0839

Learning rate: 5.182463258982848e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: -4.8637	Cost: 34.88s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -10.2059	Cost: 9.63s
Train Epoch: 331 [81920/90000 (91%)]	Loss: -10.1077	Cost: 19.11s
Train Epoch: 331 	Average Loss: -9.9006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1524

Learning rate: 5.127498742746677e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: -4.9373	Cost: 36.84s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -10.3949	Cost: 9.61s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -10.3994	Cost: 16.98s
Train Epoch: 332 	Average Loss: -10.0317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1874

Learning rate: 5.07272658451708e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: -4.5155	Cost: 36.71s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -10.5369	Cost: 9.68s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -10.2989	Cost: 12.90s
Train Epoch: 333 	Average Loss: -10.0100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3765

Saving model as e333_model.pt & e333_waveforms_supplementary.hdf5
Learning rate: 5.01814894660509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: -5.1027	Cost: 37.60s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -10.4384	Cost: 9.90s
Train Epoch: 334 [81920/90000 (91%)]	Loss: -10.1648	Cost: 12.55s
Train Epoch: 334 	Average Loss: -9.9548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2277

Learning rate: 4.96376798364239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: -4.2397	Cost: 35.73s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -10.2710	Cost: 9.58s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -10.3460	Cost: 15.27s
Train Epoch: 335 	Average Loss: -9.8843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1592

Learning rate: 4.9095858424962844e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: -4.6058	Cost: 32.93s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -10.5055	Cost: 9.83s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -10.4178	Cost: 18.61s
Train Epoch: 336 	Average Loss: -10.0325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5430

Saving model as e336_model.pt & e336_waveforms_supplementary.hdf5
Learning rate: 4.855604662184932e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: -4.2473	Cost: 39.75s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -10.4879	Cost: 9.62s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -10.3405	Cost: 13.89s
Train Epoch: 337 	Average Loss: -10.0693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1621

Learning rate: 4.801826573792905e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: -5.1442	Cost: 35.19s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -10.3874	Cost: 9.69s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -10.6021	Cost: 12.57s
Train Epoch: 338 	Average Loss: -10.0983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2305

Learning rate: 4.748253700387039e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: -4.7663	Cost: 33.20s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -10.5349	Cost: 10.04s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -10.5796	Cost: 11.62s
Train Epoch: 339 	Average Loss: -10.1056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3035

Learning rate: 4.694888156932659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: -4.7598	Cost: 34.57s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -10.5850	Cost: 9.61s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -10.6028	Cost: 14.86s
Train Epoch: 340 	Average Loss: -10.1166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1963

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: -4.9620	Cost: 32.17s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -10.3951	Cost: 9.72s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -10.5901	Cost: 18.69s
Train Epoch: 341 	Average Loss: -10.1776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2918

Learning rate: 4.5887874787312395e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: -4.9734	Cost: 37.52s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -10.6272	Cost: 9.72s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -10.5488	Cost: 14.53s
Train Epoch: 342 	Average Loss: -10.2614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3900

Learning rate: 4.536056532657307e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: -4.9984	Cost: 35.29s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -10.7617	Cost: 9.73s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -10.5800	Cost: 13.79s
Train Epoch: 343 	Average Loss: -10.3289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5622

Saving model as e343_model.pt & e343_waveforms_supplementary.hdf5
Learning rate: 4.4835412937156955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: -5.0032	Cost: 33.41s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -10.7726	Cost: 9.63s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -10.8228	Cost: 12.35s
Train Epoch: 344 	Average Loss: -10.3117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3646

Learning rate: 4.431243835118117e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: -4.8651	Cost: 33.14s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -10.5539	Cost: 9.87s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -10.6531	Cost: 17.65s
Train Epoch: 345 	Average Loss: -10.3473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6084

Saving model as e345_model.pt & e345_waveforms_supplementary.hdf5
Learning rate: 4.379166221478691e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: -4.7795	Cost: 35.72s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -10.6458	Cost: 9.72s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -10.6520	Cost: 18.63s
Train Epoch: 346 	Average Loss: -10.3043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3802

Learning rate: 4.327310508732435e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: -4.2205	Cost: 37.16s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -10.6536	Cost: 9.67s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -10.5743	Cost: 14.85s
Train Epoch: 347 	Average Loss: -10.2592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5627

Learning rate: 4.275678744054088e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: -5.2325	Cost: 36.85s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -10.6003	Cost: 9.63s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -10.7871	Cost: 13.47s
Train Epoch: 348 	Average Loss: -10.3605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4783

Learning rate: 4.224272965777324e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: -5.0640	Cost: 34.75s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -10.8677	Cost: 9.62s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -10.9084	Cost: 17.67s
Train Epoch: 349 	Average Loss: -10.4356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2886

Learning rate: 4.173095203314239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: -4.0506	Cost: 37.51s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -10.6681	Cost: 9.69s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -10.8523	Cost: 16.79s
Train Epoch: 350 	Average Loss: -10.3881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3904

Learning rate: 4.1221474770752684e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: -5.2242	Cost: 38.02s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -10.7075	Cost: 9.61s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -10.7904	Cost: 13.79s
Train Epoch: 351 	Average Loss: -10.4379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4183

Learning rate: 4.071431798389406e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: -4.8126	Cost: 37.43s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -10.8832	Cost: 9.68s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -10.8912	Cost: 12.82s
Train Epoch: 352 	Average Loss: -10.4621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4219

Learning rate: 4.020950169424814e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: -4.7242	Cost: 35.08s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -10.7554	Cost: 9.61s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -10.9384	Cost: 15.09s
Train Epoch: 353 	Average Loss: -10.4804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5322

Learning rate: 3.970704583109751e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: -4.4867	Cost: 32.03s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -10.9973	Cost: 9.68s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -10.7551	Cost: 18.02s
Train Epoch: 354 	Average Loss: -10.5038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5440

Learning rate: 3.920697023053944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: -4.2488	Cost: 37.09s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -10.9838	Cost: 9.75s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -10.7035	Cost: 16.16s
Train Epoch: 355 	Average Loss: -10.4548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4982

Learning rate: 3.870929463470237e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: -5.3766	Cost: 36.32s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -10.8896	Cost: 9.59s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -11.2190	Cost: 14.39s
Train Epoch: 356 	Average Loss: -10.6127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4804

Learning rate: 3.821403869096654e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: -4.4429	Cost: 34.35s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -10.8989	Cost: 9.65s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -11.1695	Cost: 14.24s
Train Epoch: 357 	Average Loss: -10.5425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5034

Learning rate: 3.772122195118876e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: -5.6464	Cost: 35.72s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -10.9908	Cost: 10.16s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -11.1215	Cost: 17.77s
Train Epoch: 358 	Average Loss: -10.6161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6156

Saving model as e358_model.pt & e358_waveforms_supplementary.hdf5
Learning rate: 3.723086387092996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: -5.1017	Cost: 35.72s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -10.9771	Cost: 9.72s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -11.0521	Cost: 17.47s
Train Epoch: 359 	Average Loss: -10.5950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4597

Learning rate: 3.674298380868755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: -4.4903	Cost: 38.04s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -11.0082	Cost: 9.54s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -11.0447	Cost: 15.41s
Train Epoch: 360 	Average Loss: -10.6307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4870

Learning rate: 3.6257601025131026e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: -5.2644	Cost: 34.41s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -11.0103	Cost: 9.91s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -10.9486	Cost: 13.66s
Train Epoch: 361 	Average Loss: -10.6123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4966

Learning rate: 3.5774734682341595e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: -4.9541	Cost: 33.84s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -10.8918	Cost: 9.43s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -11.2255	Cost: 17.70s
Train Epoch: 362 	Average Loss: -10.6714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4258

Learning rate: 3.529440384305556e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: -4.8073	Cost: 35.38s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -11.1830	Cost: 9.73s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -11.0797	Cost: 18.51s
Train Epoch: 363 	Average Loss: -10.7051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6421

Saving model as e363_model.pt & e363_waveforms_supplementary.hdf5
Learning rate: 3.481662746991211e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: -4.8018	Cost: 35.98s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -11.1028	Cost: 9.74s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -11.3151	Cost: 12.77s
Train Epoch: 364 	Average Loss: -10.7104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6112

Learning rate: 3.434142442470437e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: -5.6277	Cost: 39.02s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -11.0287	Cost: 9.80s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -11.2442	Cost: 12.25s
Train Epoch: 365 	Average Loss: -10.7745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6073

Learning rate: 3.3868813467634793e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: -5.2004	Cost: 35.79s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -11.3291	Cost: 9.45s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -11.2590	Cost: 14.50s
Train Epoch: 366 	Average Loss: -10.7687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8591

Saving model as e366_model.pt & e366_waveforms_supplementary.hdf5
Learning rate: 3.339881325657484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: -5.0544	Cost: 33.51s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -11.1059	Cost: 9.72s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -11.4069	Cost: 17.60s
Train Epoch: 367 	Average Loss: -10.8350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6446

Learning rate: 3.2931442346328e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: -5.0592	Cost: 38.54s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -11.2240	Cost: 9.72s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -11.2443	Cost: 14.63s
Train Epoch: 368 	Average Loss: -10.7877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4865

Learning rate: 3.246671918789755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: -5.3164	Cost: 34.39s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -11.1408	Cost: 9.70s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -11.1456	Cost: 14.29s
Train Epoch: 369 	Average Loss: -10.8112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6730

Learning rate: 3.200466212775808e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: -4.8487	Cost: 33.38s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -11.2736	Cost: 9.66s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -11.3356	Cost: 12.30s
Train Epoch: 370 	Average Loss: -10.8890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8763

Saving model as e370_model.pt & e370_waveforms_supplementary.hdf5
Learning rate: 3.1545289407131164e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: -4.9283	Cost: 34.93s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -11.3299	Cost: 9.91s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -11.2867	Cost: 19.04s
Train Epoch: 371 	Average Loss: -10.7832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6980

Learning rate: 3.1088619161265144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: -5.1664	Cost: 35.13s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -11.0284	Cost: 9.83s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -11.3296	Cost: 15.90s
Train Epoch: 372 	Average Loss: -10.8901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6211

Learning rate: 3.0634669418719525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: -4.7929	Cost: 38.87s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -11.0367	Cost: 9.75s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -11.2892	Cost: 15.23s
Train Epoch: 373 	Average Loss: -10.8340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4986

Learning rate: 3.0183458100652757e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: -5.5131	Cost: 37.22s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -11.3705	Cost: 9.54s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -11.3174	Cost: 13.68s
Train Epoch: 374 	Average Loss: -10.9109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7559

Learning rate: 2.9735003020115068e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: -4.8656	Cost: 33.14s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -11.4099	Cost: 9.55s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -11.5281	Cost: 18.75s
Train Epoch: 375 	Average Loss: -10.8801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7078

Learning rate: 2.928932188134526e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: -5.3785	Cost: 36.47s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -11.4751	Cost: 9.73s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -11.3424	Cost: 18.26s
Train Epoch: 376 	Average Loss: -10.8788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4568

Learning rate: 2.8846432279071474e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: -5.0885	Cost: 37.53s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -11.1740	Cost: 9.69s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -11.3359	Cost: 15.33s
Train Epoch: 377 	Average Loss: -10.7836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5841

Learning rate: 2.8406351697816885e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: -5.2755	Cost: 35.17s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -11.0977	Cost: 9.67s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -11.0470	Cost: 14.90s
Train Epoch: 378 	Average Loss: -10.8706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6712

Learning rate: 2.796909751120931e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: -4.9214	Cost: 34.06s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -11.2759	Cost: 9.65s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -11.4109	Cost: 16.91s
Train Epoch: 379 	Average Loss: -10.9324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5703

Learning rate: 2.7534686981295358e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: -4.7340	Cost: 34.72s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -11.3874	Cost: 9.67s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -11.4798	Cost: 17.66s
Train Epoch: 380 	Average Loss: -11.0082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7186

Learning rate: 2.7103137257858838e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: -5.1371	Cost: 36.67s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -11.5160	Cost: 9.77s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -11.5880	Cost: 14.31s
Train Epoch: 381 	Average Loss: -11.0927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8119

Learning rate: 2.667446537774402e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: -5.2366	Cost: 34.69s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -11.4494	Cost: 9.69s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -11.6069	Cost: 13.41s
Train Epoch: 382 	Average Loss: -11.1523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7998

Learning rate: 2.6248688264182623e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: -5.9754	Cost: 33.39s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -11.5231	Cost: 9.64s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -11.4888	Cost: 13.40s
Train Epoch: 383 	Average Loss: -11.1527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6327

Learning rate: 2.5825822726126095e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: -4.8917	Cost: 34.63s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -11.5520	Cost: 9.68s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -11.4080	Cost: 19.14s
Train Epoch: 384 	Average Loss: -11.0774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8596

Learning rate: 2.5405885457581793e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: -5.2596	Cost: 36.10s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -11.5542	Cost: 9.83s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -11.6623	Cost: 17.75s
Train Epoch: 385 	Average Loss: -11.1316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7421

Learning rate: 2.4988893036954043e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: -4.8413	Cost: 37.09s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -11.8045	Cost: 9.68s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -11.6022	Cost: 13.40s
Train Epoch: 386 	Average Loss: -11.1669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7195

Learning rate: 2.4574861926389615e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: -5.4740	Cost: 35.87s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -11.6562	Cost: 9.83s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -11.5675	Cost: 12.82s
Train Epoch: 387 	Average Loss: -11.1986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8468

Learning rate: 2.4163808471127812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: -5.4770	Cost: 35.63s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -11.5086	Cost: 9.89s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -11.5376	Cost: 16.73s
Train Epoch: 388 	Average Loss: -11.2204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8670

Learning rate: 2.3755748898855234e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: -5.2977	Cost: 33.80s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -11.6912	Cost: 9.76s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -11.6483	Cost: 17.91s
Train Epoch: 389 	Average Loss: -11.2829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9945

Saving model as e389_model.pt & e389_waveforms_supplementary.hdf5
Learning rate: 2.3350699319065006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: -5.5511	Cost: 37.63s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -11.5707	Cost: 9.68s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -11.6747	Cost: 13.20s
Train Epoch: 390 	Average Loss: -11.3601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8698

Learning rate: 2.2948675722421086e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: -5.2623	Cost: 38.77s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -11.7453	Cost: 9.56s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -11.8824	Cost: 12.71s
Train Epoch: 391 	Average Loss: -11.3392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9456

Learning rate: 2.2549693980126627e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: -5.9173	Cost: 36.29s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -11.9002	Cost: 9.54s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -11.8087	Cost: 13.11s
Train Epoch: 392 	Average Loss: -11.3401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8960

Learning rate: 2.2153769843297664e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: -4.5729	Cost: 33.28s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -11.8163	Cost: 9.93s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -11.8184	Cost: 18.62s
Train Epoch: 393 	Average Loss: -11.3431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0390

Saving model as e393_model.pt & e393_waveforms_supplementary.hdf5
Learning rate: 2.1760918942341185e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: -5.2016	Cost: 36.44s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -11.9972	Cost: 9.80s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -11.8437	Cost: 16.11s
Train Epoch: 394 	Average Loss: -11.4366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0642

Saving model as e394_model.pt & e394_waveforms_supplementary.hdf5
Learning rate: 2.1371156786338137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: -5.3060	Cost: 39.37s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -11.8557	Cost: 9.67s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -11.9323	Cost: 13.40s
Train Epoch: 395 	Average Loss: -11.4234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9695

Learning rate: 2.0984498762430954e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: -5.4698	Cost: 35.94s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -11.9056	Cost: 9.70s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -11.7601	Cost: 13.67s
Train Epoch: 396 	Average Loss: -11.4781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1049

Saving model as e396_model.pt & e396_waveforms_supplementary.hdf5
Learning rate: 2.060096013521646e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: -5.5306	Cost: 32.31s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -11.8427	Cost: 9.89s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -11.9930	Cost: 19.26s
Train Epoch: 397 	Average Loss: -11.5112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9898

Learning rate: 2.022055604614291e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: -5.5194	Cost: 35.66s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -11.9599	Cost: 9.86s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -11.9038	Cost: 17.59s
Train Epoch: 398 	Average Loss: -11.4614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0365

Learning rate: 1.9843301512912324e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: -5.6751	Cost: 36.24s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -12.1752	Cost: 9.63s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -12.1625	Cost: 14.23s
Train Epoch: 399 	Average Loss: -11.5510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1011

Learning rate: 1.9469211428887808e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: -4.8147	Cost: 36.67s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -11.9826	Cost: 9.67s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -12.0753	Cost: 13.24s
Train Epoch: 400 	Average Loss: -11.5385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2521

Saving model as e400_model.pt & e400_waveforms_supplementary.hdf5
Learning rate: 1.9098300562505263e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: -5.3578	Cost: 34.17s
Train Epoch: 401 [40960/90000 (45%)]	Loss: -11.9564	Cost: 10.12s
Train Epoch: 401 [81920/90000 (91%)]	Loss: -11.9528	Cost: 17.92s
Train Epoch: 401 	Average Loss: -11.5436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0215

Learning rate: 1.8730583556690602e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: -5.4652	Cost: 35.33s
Train Epoch: 402 [40960/90000 (45%)]	Loss: -12.1186	Cost: 9.80s
Train Epoch: 402 [81920/90000 (91%)]	Loss: -12.1538	Cost: 18.51s
Train Epoch: 402 	Average Loss: -11.5930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1054

Learning rate: 1.8366074928281604e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: -5.5228	Cost: 39.10s
Train Epoch: 403 [40960/90000 (45%)]	Loss: -11.9773	Cost: 9.53s
Train Epoch: 403 [81920/90000 (91%)]	Loss: -12.1342	Cost: 15.59s
Train Epoch: 403 	Average Loss: -11.6370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2923

Saving model as e403_model.pt & e403_waveforms_supplementary.hdf5
Learning rate: 1.8004789067454784e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: -5.5242	Cost: 34.21s
Train Epoch: 404 [40960/90000 (45%)]	Loss: -12.1497	Cost: 9.67s
Train Epoch: 404 [81920/90000 (91%)]	Loss: -12.2747	Cost: 12.14s
Train Epoch: 404 	Average Loss: -11.5959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2096

Learning rate: 1.7646740237157253e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: -5.6044	Cost: 34.71s
Train Epoch: 405 [40960/90000 (45%)]	Loss: -12.2817	Cost: 9.63s
Train Epoch: 405 [81920/90000 (91%)]	Loss: -12.1542	Cost: 17.92s
Train Epoch: 405 	Average Loss: -11.6464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0139

Learning rate: 1.7291942572543828e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: -5.3584	Cost: 37.30s
Train Epoch: 406 [40960/90000 (45%)]	Loss: -12.1203	Cost: 9.61s
Train Epoch: 406 [81920/90000 (91%)]	Loss: -12.0445	Cost: 19.89s
Train Epoch: 406 	Average Loss: -11.6477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0964

Learning rate: 1.6940410080418743e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: -5.0469	Cost: 35.93s
Train Epoch: 407 [40960/90000 (45%)]	Loss: -11.9679	Cost: 9.78s
Train Epoch: 407 [81920/90000 (91%)]	Loss: -12.1540	Cost: 12.92s
Train Epoch: 407 	Average Loss: -11.6662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1438

Learning rate: 1.6592156638682862e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: -5.2065	Cost: 37.51s
Train Epoch: 408 [40960/90000 (45%)]	Loss: -12.2212	Cost: 9.56s
Train Epoch: 408 [81920/90000 (91%)]	Loss: -12.3036	Cost: 13.72s
Train Epoch: 408 	Average Loss: -11.6797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0249

Learning rate: 1.6247195995785833e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: -5.6168	Cost: 33.53s
Train Epoch: 409 [40960/90000 (45%)]	Loss: -12.1319	Cost: 10.07s
Train Epoch: 409 [81920/90000 (91%)]	Loss: -12.4326	Cost: 12.27s
Train Epoch: 409 	Average Loss: -11.7640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3642

Saving model as e409_model.pt & e409_waveforms_supplementary.hdf5
Learning rate: 1.5905541770183092e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: -5.7020	Cost: 33.17s
Train Epoch: 410 [40960/90000 (45%)]	Loss: -12.1920	Cost: 9.77s
Train Epoch: 410 [81920/90000 (91%)]	Loss: -12.2090	Cost: 19.42s
Train Epoch: 410 	Average Loss: -11.7478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0981

Learning rate: 1.5567207449798488e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: -5.4959	Cost: 37.88s
Train Epoch: 411 [40960/90000 (45%)]	Loss: -12.3634	Cost: 9.78s
Train Epoch: 411 [81920/90000 (91%)]	Loss: -12.2682	Cost: 15.05s
Train Epoch: 411 	Average Loss: -11.7932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9551

Learning rate: 1.5232206391491672e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: -5.4008	Cost: 38.35s
Train Epoch: 412 [40960/90000 (45%)]	Loss: -12.1198	Cost: 9.54s
Train Epoch: 412 [81920/90000 (91%)]	Loss: -12.2951	Cost: 16.46s
Train Epoch: 412 	Average Loss: -11.8272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2575

Learning rate: 1.4900551820530823e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: -5.4616	Cost: 34.41s
Train Epoch: 413 [40960/90000 (45%)]	Loss: -12.4426	Cost: 9.65s
Train Epoch: 413 [81920/90000 (91%)]	Loss: -12.2140	Cost: 12.62s
Train Epoch: 413 	Average Loss: -11.8040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0951

Learning rate: 1.457225683007047e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: -6.3995	Cost: 34.13s
Train Epoch: 414 [40960/90000 (45%)]	Loss: -12.3031	Cost: 9.79s
Train Epoch: 414 [81920/90000 (91%)]	Loss: -12.2798	Cost: 18.32s
Train Epoch: 414 	Average Loss: -11.8821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1932

Learning rate: 1.4247334380634787e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: -5.7870	Cost: 37.89s
Train Epoch: 415 [40960/90000 (45%)]	Loss: -12.2391	Cost: 9.85s
Train Epoch: 415 [81920/90000 (91%)]	Loss: -12.1725	Cost: 17.95s
Train Epoch: 415 	Average Loss: -11.8119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9402

Learning rate: 1.3925797299605641e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: -6.3333	Cost: 36.54s
Train Epoch: 416 [40960/90000 (45%)]	Loss: -12.0629	Cost: 9.62s
Train Epoch: 416 [81920/90000 (91%)]	Loss: -12.3324	Cost: 14.38s
Train Epoch: 416 	Average Loss: -11.8652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4278

Saving model as e416_model.pt & e416_waveforms_supplementary.hdf5
Learning rate: 1.3607658280716445e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: -5.6669	Cost: 36.45s
Train Epoch: 417 [40960/90000 (45%)]	Loss: -12.3607	Cost: 10.07s
Train Epoch: 417 [81920/90000 (91%)]	Loss: -12.4208	Cost: 12.59s
Train Epoch: 417 	Average Loss: -11.8924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4073

Learning rate: 1.3292929883550993e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: -5.3124	Cost: 35.06s
Train Epoch: 418 [40960/90000 (45%)]	Loss: -12.2310	Cost: 9.73s
Train Epoch: 418 [81920/90000 (91%)]	Loss: -12.4166	Cost: 18.92s
Train Epoch: 418 	Average Loss: -11.8898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2478

Learning rate: 1.2981624533047427e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: -5.2239	Cost: 35.03s
Train Epoch: 419 [40960/90000 (45%)]	Loss: -12.2948	Cost: 9.69s
Train Epoch: 419 [81920/90000 (91%)]	Loss: -12.4568	Cost: 18.33s
Train Epoch: 419 	Average Loss: -11.8586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2693

Learning rate: 1.2673754519007981e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: -4.8355	Cost: 36.18s
Train Epoch: 420 [40960/90000 (45%)]	Loss: -12.4029	Cost: 9.74s
Train Epoch: 420 [81920/90000 (91%)]	Loss: -12.3730	Cost: 12.88s
Train Epoch: 420 	Average Loss: -11.9032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1798

Learning rate: 1.2369331995613638e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: -5.9472	Cost: 35.24s
Train Epoch: 421 [40960/90000 (45%)]	Loss: -12.3818	Cost: 9.84s
Train Epoch: 421 [81920/90000 (91%)]	Loss: -12.3828	Cost: 12.48s
Train Epoch: 421 	Average Loss: -11.9802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1467

Learning rate: 1.2068368980944384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: -5.6866	Cost: 36.89s
Train Epoch: 422 [40960/90000 (45%)]	Loss: -12.3553	Cost: 9.62s
Train Epoch: 422 [81920/90000 (91%)]	Loss: -12.3663	Cost: 13.61s
Train Epoch: 422 	Average Loss: -11.9824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4644

Saving model as e422_model.pt & e422_waveforms_supplementary.hdf5
Learning rate: 1.1770877356504656e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: -5.8170	Cost: 34.24s
Train Epoch: 423 [40960/90000 (45%)]	Loss: -12.3785	Cost: 9.77s
Train Epoch: 423 [81920/90000 (91%)]	Loss: -12.5229	Cost: 17.60s
Train Epoch: 423 	Average Loss: -12.0105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3595

Learning rate: 1.1476868866754482e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: -6.0935	Cost: 33.68s
Train Epoch: 424 [40960/90000 (45%)]	Loss: -12.4241	Cost: 9.54s
Train Epoch: 424 [81920/90000 (91%)]	Loss: -12.6141	Cost: 12.89s
Train Epoch: 424 	Average Loss: -12.0285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2902

Learning rate: 1.1186355118645549e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: -5.6161	Cost: 33.18s
Train Epoch: 425 [40960/90000 (45%)]	Loss: -12.7117	Cost: 9.47s
Train Epoch: 425 [81920/90000 (91%)]	Loss: -12.4302	Cost: 12.92s
Train Epoch: 425 	Average Loss: -12.0237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1543

Learning rate: 1.0899347581163218e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: -6.4661	Cost: 31.42s
Train Epoch: 426 [40960/90000 (45%)]	Loss: -12.4322	Cost: 9.52s
Train Epoch: 426 [81920/90000 (91%)]	Loss: -12.5230	Cost: 12.13s
Train Epoch: 426 	Average Loss: -12.0817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2888

Learning rate: 1.061585758487362e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: -5.6273	Cost: 33.78s
Train Epoch: 427 [40960/90000 (45%)]	Loss: -12.3271	Cost: 9.49s
Train Epoch: 427 [81920/90000 (91%)]	Loss: -12.2969	Cost: 12.71s
Train Epoch: 427 	Average Loss: -12.0672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1949

Learning rate: 1.033589632147641e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: -5.7718	Cost: 31.52s
Train Epoch: 428 [40960/90000 (45%)]	Loss: -12.6716	Cost: 9.52s
Train Epoch: 428 [81920/90000 (91%)]	Loss: -12.5703	Cost: 12.60s
Train Epoch: 428 	Average Loss: -12.0712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4347

Learning rate: 1.005947484336289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: -5.7382	Cost: 31.61s
Train Epoch: 429 [40960/90000 (45%)]	Loss: -12.6304	Cost: 9.51s
Train Epoch: 429 [81920/90000 (91%)]	Loss: -12.5686	Cost: 12.17s
Train Epoch: 429 	Average Loss: -12.1024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2707

Learning rate: 9.786604063179713e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: -6.0572	Cost: 32.21s
Train Epoch: 430 [40960/90000 (45%)]	Loss: -12.4492	Cost: 9.55s
Train Epoch: 430 [81920/90000 (91%)]	Loss: -12.4824	Cost: 12.35s
Train Epoch: 430 	Average Loss: -12.0782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4711

Saving model as e430_model.pt & e430_waveforms_supplementary.hdf5
Learning rate: 9.517294753398061e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: -5.1870	Cost: 33.05s
Train Epoch: 431 [40960/90000 (45%)]	Loss: -12.4782	Cost: 9.53s
Train Epoch: 431 [81920/90000 (91%)]	Loss: -12.6484	Cost: 12.08s
Train Epoch: 431 	Average Loss: -12.1236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3923

Learning rate: 9.251557545888296e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: -6.3575	Cost: 33.34s
Train Epoch: 432 [40960/90000 (45%)]	Loss: -12.6421	Cost: 9.58s
Train Epoch: 432 [81920/90000 (91%)]	Loss: -12.7084	Cost: 12.42s
Train Epoch: 432 	Average Loss: -12.1651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4433

Learning rate: 8.98940293150043e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: -5.9022	Cost: 32.20s
Train Epoch: 433 [40960/90000 (45%)]	Loss: -12.4444	Cost: 10.04s
Train Epoch: 433 [81920/90000 (91%)]	Loss: -12.6116	Cost: 12.55s
Train Epoch: 433 	Average Loss: -12.1849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4070

Learning rate: 8.730841259649718e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: -5.9576	Cost: 32.26s
Train Epoch: 434 [40960/90000 (45%)]	Loss: -12.6471	Cost: 9.41s
Train Epoch: 434 [81920/90000 (91%)]	Loss: -12.5771	Cost: 13.15s
Train Epoch: 434 	Average Loss: -12.1487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3059

Learning rate: 8.475882737908241e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: -5.6259	Cost: 30.97s
Train Epoch: 435 [40960/90000 (45%)]	Loss: -12.6879	Cost: 9.41s
Train Epoch: 435 [81920/90000 (91%)]	Loss: -12.4773	Cost: 12.73s
Train Epoch: 435 	Average Loss: -12.1740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2657

Learning rate: 8.224537431601881e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: -5.7207	Cost: 31.14s
Train Epoch: 436 [40960/90000 (45%)]	Loss: -12.5208	Cost: 9.39s
Train Epoch: 436 [81920/90000 (91%)]	Loss: -12.5933	Cost: 12.29s
Train Epoch: 436 	Average Loss: -12.1531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4632

Learning rate: 7.97681526341298e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: -5.8764	Cost: 31.86s
Train Epoch: 437 [40960/90000 (45%)]	Loss: -12.7570	Cost: 9.39s
Train Epoch: 437 [81920/90000 (91%)]	Loss: -12.7351	Cost: 12.66s
Train Epoch: 437 	Average Loss: -12.2085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4736

Saving model as e437_model.pt & e437_waveforms_supplementary.hdf5
Learning rate: 7.732726012988507e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: -5.8452	Cost: 30.99s
Train Epoch: 438 [40960/90000 (45%)]	Loss: -12.7597	Cost: 9.38s
Train Epoch: 438 [81920/90000 (91%)]	Loss: -12.5733	Cost: 12.19s
Train Epoch: 438 	Average Loss: -12.2238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4832

Saving model as e438_model.pt & e438_waveforms_supplementary.hdf5
Learning rate: 7.492279316554181e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: -5.5158	Cost: 31.18s
Train Epoch: 439 [40960/90000 (45%)]	Loss: -12.6326	Cost: 9.44s
Train Epoch: 439 [81920/90000 (91%)]	Loss: -12.8223	Cost: 12.19s
Train Epoch: 439 	Average Loss: -12.2333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3919

Learning rate: 7.25548466653387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: -5.9177	Cost: 31.11s
Train Epoch: 440 [40960/90000 (45%)]	Loss: -12.5208	Cost: 9.41s
Train Epoch: 440 [81920/90000 (91%)]	Loss: -12.7361	Cost: 12.09s
Train Epoch: 440 	Average Loss: -12.2616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4687

Learning rate: 7.02235141117485e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: -5.5586	Cost: 31.85s
Train Epoch: 441 [40960/90000 (45%)]	Loss: -12.8061	Cost: 9.41s
Train Epoch: 441 [81920/90000 (91%)]	Loss: -12.8103	Cost: 12.24s
Train Epoch: 441 	Average Loss: -12.2674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4813

Learning rate: 6.792888754178901e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: -5.3871	Cost: 31.17s
Train Epoch: 442 [40960/90000 (45%)]	Loss: -12.7789	Cost: 9.38s
Train Epoch: 442 [81920/90000 (91%)]	Loss: -12.7669	Cost: 12.65s
Train Epoch: 442 	Average Loss: -12.2526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3541

Learning rate: 6.567105754338794e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: -5.4933	Cost: 30.96s
Train Epoch: 443 [40960/90000 (45%)]	Loss: -12.7324	Cost: 9.42s
Train Epoch: 443 [81920/90000 (91%)]	Loss: -12.8679	Cost: 13.05s
Train Epoch: 443 	Average Loss: -12.3207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3799

Learning rate: 6.3450113251807676e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: -6.0688	Cost: 30.74s
Train Epoch: 444 [40960/90000 (45%)]	Loss: -12.7293	Cost: 9.39s
Train Epoch: 444 [81920/90000 (91%)]	Loss: -12.6282	Cost: 12.97s
Train Epoch: 444 	Average Loss: -12.3280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4649

Learning rate: 6.126614234612589e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: -5.4366	Cost: 32.70s
Train Epoch: 445 [40960/90000 (45%)]	Loss: -12.5994	Cost: 9.42s
Train Epoch: 445 [81920/90000 (91%)]	Loss: -12.7941	Cost: 12.69s
Train Epoch: 445 	Average Loss: -12.2868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4276

Learning rate: 5.911923104577461e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: -5.7941	Cost: 30.80s
Train Epoch: 446 [40960/90000 (45%)]	Loss: -12.7289	Cost: 9.42s
Train Epoch: 446 [81920/90000 (91%)]	Loss: -12.6295	Cost: 12.37s
Train Epoch: 446 	Average Loss: -12.2767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3029

Learning rate: 5.7009464107135434e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: -6.0491	Cost: 32.28s
Train Epoch: 447 [40960/90000 (45%)]	Loss: -12.7869	Cost: 9.44s
Train Epoch: 447 [81920/90000 (91%)]	Loss: -12.8700	Cost: 12.29s
Train Epoch: 447 	Average Loss: -12.3457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5187

Saving model as e447_model.pt & e447_waveforms_supplementary.hdf5
Learning rate: 5.493692482019526e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: -5.9799	Cost: 30.99s
Train Epoch: 448 [40960/90000 (45%)]	Loss: -12.7639	Cost: 9.45s
Train Epoch: 448 [81920/90000 (91%)]	Loss: -12.8281	Cost: 11.90s
Train Epoch: 448 	Average Loss: -12.3681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6451

Saving model as e448_model.pt & e448_waveforms_supplementary.hdf5
Learning rate: 5.290169500525573e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: -6.3382	Cost: 32.81s
Train Epoch: 449 [40960/90000 (45%)]	Loss: -12.6742	Cost: 9.39s
Train Epoch: 449 [81920/90000 (91%)]	Loss: -12.9223	Cost: 12.27s
Train Epoch: 449 	Average Loss: -12.4485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4908

Learning rate: 5.090385500970525e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: -6.4653	Cost: 30.92s
Train Epoch: 450 [40960/90000 (45%)]	Loss: -12.7878	Cost: 9.44s
Train Epoch: 450 [81920/90000 (91%)]	Loss: -12.9206	Cost: 11.85s
Train Epoch: 450 	Average Loss: -12.3360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8465

Saving model as e450_model.pt & e450_waveforms_supplementary.hdf5
Learning rate: 4.894348370484643e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: -5.7576	Cost: 30.80s
Train Epoch: 451 [40960/90000 (45%)]	Loss: -12.7818	Cost: 9.44s
Train Epoch: 451 [81920/90000 (91%)]	Loss: -13.1207	Cost: 12.04s
Train Epoch: 451 	Average Loss: -12.4166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4951

Learning rate: 4.702065848278122e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: -6.2847	Cost: 32.27s
Train Epoch: 452 [40960/90000 (45%)]	Loss: -12.8552	Cost: 9.41s
Train Epoch: 452 [81920/90000 (91%)]	Loss: -12.8690	Cost: 12.20s
Train Epoch: 452 	Average Loss: -12.3996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5215

Learning rate: 4.513545525335701e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: -5.5963	Cost: 31.98s
Train Epoch: 453 [40960/90000 (45%)]	Loss: -12.7322	Cost: 9.40s
Train Epoch: 453 [81920/90000 (91%)]	Loss: -12.8818	Cost: 12.28s
Train Epoch: 453 	Average Loss: -12.4421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4206

Learning rate: 4.328794844116942e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: -5.9930	Cost: 31.36s
Train Epoch: 454 [40960/90000 (45%)]	Loss: -12.8599	Cost: 9.42s
Train Epoch: 454 [81920/90000 (91%)]	Loss: -12.9473	Cost: 12.79s
Train Epoch: 454 	Average Loss: -12.4277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4148

Learning rate: 4.147821098262413e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: -5.9897	Cost: 31.65s
Train Epoch: 455 [40960/90000 (45%)]	Loss: -12.7371	Cost: 9.40s
Train Epoch: 455 [81920/90000 (91%)]	Loss: -12.8376	Cost: 11.82s
Train Epoch: 455 	Average Loss: -12.4008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4424

Learning rate: 3.97063143230569e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: -6.4153	Cost: 30.83s
Train Epoch: 456 [40960/90000 (45%)]	Loss: -12.9877	Cost: 9.40s
Train Epoch: 456 [81920/90000 (91%)]	Loss: -13.0469	Cost: 12.06s
Train Epoch: 456 	Average Loss: -12.4492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9391

Saving model as e456_model.pt & e456_waveforms_supplementary.hdf5
Learning rate: 3.797232841391415e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: -5.6079	Cost: 31.86s
Train Epoch: 457 [40960/90000 (45%)]	Loss: -12.7320	Cost: 9.43s
Train Epoch: 457 [81920/90000 (91%)]	Loss: -12.7977	Cost: 12.44s
Train Epoch: 457 	Average Loss: -12.4006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4110

Stopping timer.
Training time (including validation): 218102.70469284058 seconds
Saving model
