Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=4096, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=1.0, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_mixed_prior_transfered/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=500, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_mixed_prior_transfered/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Now, transfer learning from alpha=1.0!
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.0964	Cost: 33.15s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.7169	Cost: 9.58s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.7500	Cost: 11.99s
Train Epoch: 1 	Average Loss: 21.9926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8326

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.5987	Cost: 32.86s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 20.2733	Cost: 9.52s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 19.9354	Cost: 12.04s
Train Epoch: 2 	Average Loss: 20.2568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8465

Learning rate: 0.00019999998026079186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 19.8740	Cost: 32.59s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 19.3369	Cost: 9.77s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 18.9827	Cost: 11.76s
Train Epoch: 3 	Average Loss: 19.3769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0765

Learning rate: 0.00019999995558678347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 18.8549	Cost: 34.09s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 18.3489	Cost: 10.41s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 17.9241	Cost: 11.39s
Train Epoch: 4 	Average Loss: 18.3551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0586

Learning rate: 0.0001999999210431752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 17.9502	Cost: 33.21s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.5701	Cost: 9.58s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 17.3686	Cost: 12.63s
Train Epoch: 5 	Average Loss: 17.6060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6742

Learning rate: 0.00019999987662997035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 17.2300	Cost: 32.73s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 16.9993	Cost: 9.68s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 16.8591	Cost: 13.06s
Train Epoch: 6 	Average Loss: 17.0502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9868

Learning rate: 0.00019999982234717337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 16.8217	Cost: 33.06s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 16.5212	Cost: 9.65s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 16.3203	Cost: 11.61s
Train Epoch: 7 	Average Loss: 16.5323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4886

Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 16.3747	Cost: 32.79s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 16.0435	Cost: 9.48s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 16.0221	Cost: 12.20s
Train Epoch: 8 	Average Loss: 16.1544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2065

Learning rate: 0.0001999996841728254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 16.0606	Cost: 33.54s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 15.7778	Cost: 10.13s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 15.7043	Cost: 11.54s
Train Epoch: 9 	Average Loss: 15.7760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6990

Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 15.6162	Cost: 33.16s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 15.4229	Cost: 9.73s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 15.3969	Cost: 12.36s
Train Epoch: 10 	Average Loss: 15.4696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3464

Learning rate: 0.00019999950652018584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 15.3120	Cost: 33.19s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 15.1226	Cost: 9.85s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 15.1066	Cost: 12.42s
Train Epoch: 11 	Average Loss: 15.2379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3540

Learning rate: 0.00019999940288952797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 15.1301	Cost: 33.80s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 14.9774	Cost: 9.61s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 14.8270	Cost: 12.49s
Train Epoch: 12 	Average Loss: 14.9370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8872

Learning rate: 0.00019999928938932473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 14.7416	Cost: 33.92s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 14.7143	Cost: 9.69s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 14.7328	Cost: 12.63s
Train Epoch: 13 	Average Loss: 14.7489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7786

Learning rate: 0.0001999991660195873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 14.5740	Cost: 33.83s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 14.4296	Cost: 9.62s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 14.3621	Cost: 13.06s
Train Epoch: 14 	Average Loss: 14.4838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3648

Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 14.3362	Cost: 32.99s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 14.4080	Cost: 9.71s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 14.0527	Cost: 12.41s
Train Epoch: 15 	Average Loss: 14.2439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1316

Learning rate: 0.00019999888967155963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 13.9827	Cost: 34.17s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 14.0147	Cost: 9.64s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 14.0264	Cost: 12.87s
Train Epoch: 16 	Average Loss: 14.0217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1594

Learning rate: 0.0001999987366932966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 13.9686	Cost: 34.21s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 13.7789	Cost: 10.19s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 13.6197	Cost: 12.54s
Train Epoch: 17 	Average Loss: 13.7843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8785

Learning rate: 0.00019999857384555393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 13.6475	Cost: 33.46s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 13.5692	Cost: 9.44s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 13.4317	Cost: 12.19s
Train Epoch: 18 	Average Loss: 13.5939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6578

Learning rate: 0.0001999984011283477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 13.5787	Cost: 33.77s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 13.4110	Cost: 9.67s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 13.2238	Cost: 12.28s
Train Epoch: 19 	Average Loss: 13.4294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2777

Learning rate: 0.00019999821854169497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 13.3666	Cost: 33.28s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 13.2589	Cost: 9.67s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 13.3529	Cost: 11.80s
Train Epoch: 20 	Average Loss: 13.2439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3551

Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 13.3339	Cost: 32.63s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 13.0756	Cost: 10.15s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 13.0263	Cost: 11.83s
Train Epoch: 21 	Average Loss: 13.0666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9428

Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 12.9232	Cost: 34.17s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 13.0275	Cost: 10.05s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 12.9439	Cost: 11.87s
Train Epoch: 22 	Average Loss: 12.9359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0190

Learning rate: 0.00019999761156524272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 12.8752	Cost: 33.55s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 12.7729	Cost: 10.14s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 12.8319	Cost: 12.34s
Train Epoch: 23 	Average Loss: 12.8210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8189

Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 12.7384	Cost: 34.64s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 12.6153	Cost: 9.50s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 12.6052	Cost: 12.68s
Train Epoch: 24 	Average Loss: 12.6583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6970

Learning rate: 0.00019999715756739833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 12.7330	Cost: 32.97s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 12.6955	Cost: 9.73s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 12.5582	Cost: 12.98s
Train Epoch: 25 	Average Loss: 12.5637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6911

Learning rate: 0.000199996915764479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 12.4386	Cost: 33.57s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 12.4637	Cost: 9.53s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 12.4968	Cost: 11.89s
Train Epoch: 26 	Average Loss: 12.4088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4757

Learning rate: 0.00019999666409225975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 12.4443	Cost: 34.07s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 12.2287	Cost: 9.56s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 12.2371	Cost: 12.23s
Train Epoch: 27 	Average Loss: 12.3270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4902

Learning rate: 0.00019999640255076543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 12.3327	Cost: 32.56s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 12.2116	Cost: 9.51s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 12.2230	Cost: 12.28s
Train Epoch: 28 	Average Loss: 12.1957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2399

Learning rate: 0.00019999613114002186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 12.1184	Cost: 33.79s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 12.2990	Cost: 9.52s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 12.2052	Cost: 12.14s
Train Epoch: 29 	Average Loss: 12.1951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1443

Learning rate: 0.0001999958498600558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 12.0735	Cost: 32.70s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 12.3130	Cost: 9.63s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 12.0913	Cost: 12.35s
Train Epoch: 30 	Average Loss: 12.1031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0130

Learning rate: 0.000199995558710895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 12.0256	Cost: 34.00s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 11.9448	Cost: 9.57s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 11.9073	Cost: 12.89s
Train Epoch: 31 	Average Loss: 11.9828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9855

Learning rate: 0.00019999525769256825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 11.9277	Cost: 32.68s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 11.9343	Cost: 9.68s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 11.8383	Cost: 12.38s
Train Epoch: 32 	Average Loss: 11.9328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9296

Learning rate: 0.00019999494680510518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 11.8705	Cost: 32.67s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 11.8020	Cost: 9.55s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 11.7414	Cost: 12.68s
Train Epoch: 33 	Average Loss: 11.8235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7041

Learning rate: 0.00019999462604853658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 11.7740	Cost: 33.77s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 11.7244	Cost: 10.01s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 11.7104	Cost: 11.88s
Train Epoch: 34 	Average Loss: 11.7430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7237

Learning rate: 0.00019999429542289402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 11.7563	Cost: 33.17s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 11.6891	Cost: 9.91s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 11.6630	Cost: 12.57s
Train Epoch: 35 	Average Loss: 11.6557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6343

Learning rate: 0.00019999395492821016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 11.6403	Cost: 32.61s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 11.6237	Cost: 9.54s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 11.6212	Cost: 12.44s
Train Epoch: 36 	Average Loss: 11.5868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6080

Learning rate: 0.0001999936045645186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 11.6262	Cost: 33.53s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 11.5999	Cost: 9.99s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 11.5870	Cost: 12.17s
Train Epoch: 37 	Average Loss: 11.5482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5021

Learning rate: 0.00019999324433185394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 11.4843	Cost: 33.29s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 11.4578	Cost: 9.72s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 11.4527	Cost: 11.96s
Train Epoch: 38 	Average Loss: 11.4632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4522

Learning rate: 0.0001999928742302517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 11.4262	Cost: 33.67s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 11.3469	Cost: 9.53s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 11.4653	Cost: 13.41s
Train Epoch: 39 	Average Loss: 11.3922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5189

Learning rate: 0.00019999249425974844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 11.3918	Cost: 33.30s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 11.4175	Cost: 9.49s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 11.2570	Cost: 12.70s
Train Epoch: 40 	Average Loss: 11.3530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2984

Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 11.2773	Cost: 32.48s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 11.2904	Cost: 9.51s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 11.3227	Cost: 13.08s
Train Epoch: 41 	Average Loss: 11.2826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3473

Learning rate: 0.00019999170471218976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 11.2658	Cost: 32.86s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 11.1834	Cost: 9.52s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 11.1591	Cost: 12.08s
Train Epoch: 42 	Average Loss: 11.2315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1899

Learning rate: 0.0001999912951352123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 11.2320	Cost: 32.90s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 11.0964	Cost: 9.52s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 11.1449	Cost: 12.82s
Train Epoch: 43 	Average Loss: 11.1557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2174

Learning rate: 0.00019999087568948966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 11.0914	Cost: 32.73s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 11.0953	Cost: 9.50s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 10.9837	Cost: 13.60s
Train Epoch: 44 	Average Loss: 11.0746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1306

Learning rate: 0.0001999904463750632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 11.1092	Cost: 33.22s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 11.1171	Cost: 9.51s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 11.0139	Cost: 11.76s
Train Epoch: 45 	Average Loss: 11.0636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1449

Learning rate: 0.00019999000719197536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 11.2139	Cost: 32.86s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 11.0131	Cost: 9.49s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 10.8809	Cost: 11.87s
Train Epoch: 46 	Average Loss: 11.0349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1140

Learning rate: 0.00019998955814026943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 10.9835	Cost: 33.30s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 10.9466	Cost: 9.50s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 11.1277	Cost: 12.83s
Train Epoch: 47 	Average Loss: 10.9474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9145

Learning rate: 0.00019998909921998973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 11.0267	Cost: 33.20s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 10.9561	Cost: 9.49s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 10.8940	Cost: 11.89s
Train Epoch: 48 	Average Loss: 10.9269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0994

Learning rate: 0.0001999886304311816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 10.9767	Cost: 32.61s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 10.8544	Cost: 9.52s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 10.9749	Cost: 13.21s
Train Epoch: 49 	Average Loss: 10.9095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8789

Learning rate: 0.00019998815177389132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 10.9543	Cost: 32.88s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 10.6683	Cost: 9.51s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 10.8176	Cost: 13.01s
Train Epoch: 50 	Average Loss: 10.7903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8342

Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 10.8392	Cost: 33.91s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 10.8070	Cost: 9.49s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 10.7325	Cost: 12.96s
Train Epoch: 51 	Average Loss: 10.7622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7248

Learning rate: 0.00019998716485405404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 10.7716	Cost: 32.77s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 10.7831	Cost: 9.50s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 10.7600	Cost: 12.84s
Train Epoch: 52 	Average Loss: 10.7475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7000

Learning rate: 0.0001999866565916045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 10.6900	Cost: 32.89s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 10.6944	Cost: 9.50s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 10.5776	Cost: 11.78s
Train Epoch: 53 	Average Loss: 10.6512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6377

Learning rate: 0.0001999861384608676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 10.6571	Cost: 33.12s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 10.7745	Cost: 9.47s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 10.5957	Cost: 11.92s
Train Epoch: 54 	Average Loss: 10.6285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7019

Learning rate: 0.00019998561046189446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 10.7193	Cost: 32.52s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 10.6532	Cost: 9.53s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 10.5851	Cost: 11.97s
Train Epoch: 55 	Average Loss: 10.5933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5996

Learning rate: 0.00019998507259473718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 10.5603	Cost: 32.91s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 10.4708	Cost: 9.58s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 10.4759	Cost: 13.64s
Train Epoch: 56 	Average Loss: 10.5396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5718

Learning rate: 0.00019998452485944885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 10.5549	Cost: 33.36s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 10.4764	Cost: 9.53s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 10.5535	Cost: 13.59s
Train Epoch: 57 	Average Loss: 10.5007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5449

Learning rate: 0.00019998396725608354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 10.5339	Cost: 32.66s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 10.5642	Cost: 9.50s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 10.4754	Cost: 12.35s
Train Epoch: 58 	Average Loss: 10.4448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4682

Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 10.4954	Cost: 33.26s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 10.4680	Cost: 9.51s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 10.4488	Cost: 13.53s
Train Epoch: 59 	Average Loss: 10.4264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4930

Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 10.6111	Cost: 33.39s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 10.4729	Cost: 9.44s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 10.4054	Cost: 11.74s
Train Epoch: 60 	Average Loss: 10.4475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7082

Learning rate: 0.00019998223523808088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 10.4634	Cost: 33.23s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 10.4720	Cost: 9.51s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 10.3605	Cost: 13.59s
Train Epoch: 61 	Average Loss: 10.3912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4551

Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 10.4732	Cost: 32.75s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 10.2984	Cost: 9.48s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 10.3114	Cost: 12.25s
Train Epoch: 62 	Average Loss: 10.2958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2876

Learning rate: 0.00019998103122006246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 10.2245	Cost: 33.45s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 10.2439	Cost: 9.48s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 10.2115	Cost: 11.79s
Train Epoch: 63 	Average Loss: 10.2464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3205

Learning rate: 0.00019998041440942506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 10.2684	Cost: 32.93s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 10.2791	Cost: 9.48s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 10.2708	Cost: 12.46s
Train Epoch: 64 	Average Loss: 10.2680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2696

Learning rate: 0.00019997978773111632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 10.2676	Cost: 33.45s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 10.2164	Cost: 9.48s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 10.1282	Cost: 12.14s
Train Epoch: 65 	Average Loss: 10.2078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2301

Learning rate: 0.00019997915118519813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 10.1560	Cost: 33.27s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 10.2038	Cost: 9.50s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 10.1016	Cost: 12.07s
Train Epoch: 66 	Average Loss: 10.1308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0882

Learning rate: 0.0001999785047717333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 10.0972	Cost: 32.84s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 10.1370	Cost: 9.49s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 10.0905	Cost: 12.65s
Train Epoch: 67 	Average Loss: 10.1158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1827

Learning rate: 0.00019997784849078566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 10.1246	Cost: 33.27s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 10.1912	Cost: 9.49s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 9.9939	Cost: 11.89s
Train Epoch: 68 	Average Loss: 10.1245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1685

Learning rate: 0.00019997718234242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 10.0592	Cost: 33.57s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 10.1004	Cost: 9.48s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 9.9778	Cost: 11.94s
Train Epoch: 69 	Average Loss: 10.0505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1075

Learning rate: 0.00019997650632670199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 10.1386	Cost: 32.99s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 10.1038	Cost: 9.53s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 10.0490	Cost: 12.29s
Train Epoch: 70 	Average Loss: 10.0314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0596

Learning rate: 0.0001999758204436984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 10.0164	Cost: 33.39s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 10.0584	Cost: 9.50s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 9.9641	Cost: 12.94s
Train Epoch: 71 	Average Loss: 9.9793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1282

Learning rate: 0.00019997512469347695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 10.0645	Cost: 33.80s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 10.0141	Cost: 9.50s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 10.0131	Cost: 12.85s
Train Epoch: 72 	Average Loss: 9.9734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0356

Learning rate: 0.00019997441907610624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 9.9574	Cost: 32.63s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 9.9524	Cost: 9.53s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 9.9185	Cost: 13.50s
Train Epoch: 73 	Average Loss: 9.9114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0143

Learning rate: 0.00019997370359165596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 9.9354	Cost: 33.58s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 9.8374	Cost: 9.52s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 9.8428	Cost: 12.36s
Train Epoch: 74 	Average Loss: 9.8961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1302

Learning rate: 0.0001999729782401967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 9.9990	Cost: 33.46s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 9.8389	Cost: 9.49s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 9.9034	Cost: 12.14s
Train Epoch: 75 	Average Loss: 9.9242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9220

Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 9.9669	Cost: 33.18s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 9.9283	Cost: 9.49s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 9.8610	Cost: 13.70s
Train Epoch: 76 	Average Loss: 9.8753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8551

Learning rate: 0.00019997149793653861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 9.8740	Cost: 32.93s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 9.8846	Cost: 9.66s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 9.7877	Cost: 12.64s
Train Epoch: 77 	Average Loss: 9.8320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9070

Learning rate: 0.00019997074298448586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 9.8132	Cost: 32.60s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 9.8140	Cost: 9.51s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 9.7657	Cost: 12.82s
Train Epoch: 78 	Average Loss: 9.7941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8068

Learning rate: 0.00019996997816571638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 9.8471	Cost: 32.61s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 9.6631	Cost: 9.50s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 9.7793	Cost: 11.93s
Train Epoch: 79 	Average Loss: 9.7632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8098

Learning rate: 0.00019996920348030559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 9.8150	Cost: 33.52s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 9.8310	Cost: 9.52s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 9.7618	Cost: 12.83s
Train Epoch: 80 	Average Loss: 9.7437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7685

Learning rate: 0.00019996841892832998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 9.7440	Cost: 33.13s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 9.6970	Cost: 9.49s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 9.6939	Cost: 12.56s
Train Epoch: 81 	Average Loss: 9.6883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8291

Learning rate: 0.00019996762450986697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 9.8228	Cost: 33.36s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 9.6354	Cost: 9.50s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 9.6070	Cost: 13.18s
Train Epoch: 82 	Average Loss: 9.6732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6793

Learning rate: 0.00019996682022499498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 9.6337	Cost: 33.61s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 9.6901	Cost: 9.50s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 9.6085	Cost: 12.32s
Train Epoch: 83 	Average Loss: 9.6473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6257

Learning rate: 0.0001999660060737934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 9.7062	Cost: 33.51s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 9.6481	Cost: 9.47s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 9.6628	Cost: 12.76s
Train Epoch: 84 	Average Loss: 9.6256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7041

Learning rate: 0.00019996518205634255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 9.7601	Cost: 33.26s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 9.5903	Cost: 9.50s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 9.6974	Cost: 12.93s
Train Epoch: 85 	Average Loss: 9.6157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6811

Learning rate: 0.0001999643481727238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 9.7259	Cost: 32.71s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 9.6053	Cost: 9.51s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 9.7284	Cost: 13.28s
Train Epoch: 86 	Average Loss: 9.6053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7274

Learning rate: 0.0001999635044230194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 9.7054	Cost: 32.36s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 9.5979	Cost: 9.56s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 9.5805	Cost: 12.87s
Train Epoch: 87 	Average Loss: 9.5658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6393

Learning rate: 0.00019996265080731267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 9.5827	Cost: 32.80s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 9.5131	Cost: 9.66s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 9.5750	Cost: 12.91s
Train Epoch: 88 	Average Loss: 9.5224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5357

Learning rate: 0.00019996178732568782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 9.6554	Cost: 32.61s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 9.4163	Cost: 9.51s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 9.5239	Cost: 11.59s
Train Epoch: 89 	Average Loss: 9.4860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5728

Learning rate: 0.00019996091397823007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 9.6137	Cost: 33.05s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 9.4920	Cost: 9.52s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 9.5296	Cost: 12.55s
Train Epoch: 90 	Average Loss: 9.5606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6195

Learning rate: 0.00019996003076502562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 9.6388	Cost: 33.72s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 9.5081	Cost: 9.50s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 9.4723	Cost: 11.53s
Train Epoch: 91 	Average Loss: 9.4934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5604

Learning rate: 0.0001999591376861617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 9.5665	Cost: 33.09s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 9.4146	Cost: 9.49s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 9.4725	Cost: 12.45s
Train Epoch: 92 	Average Loss: 9.4913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6074

Learning rate: 0.0001999582347417264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 9.6320	Cost: 33.85s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 9.3730	Cost: 9.49s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 9.4943	Cost: 12.91s
Train Epoch: 93 	Average Loss: 9.4084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4206

Learning rate: 0.00019995732193180883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 9.4732	Cost: 33.91s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 9.3685	Cost: 9.47s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 9.4310	Cost: 11.97s
Train Epoch: 94 	Average Loss: 9.3946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4967

Learning rate: 0.00019995639925649909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 9.6001	Cost: 32.49s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 9.3518	Cost: 9.54s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 9.3415	Cost: 12.57s
Train Epoch: 95 	Average Loss: 9.3817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5902

Learning rate: 0.00019995546671588827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 9.4607	Cost: 33.11s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 9.4386	Cost: 9.54s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 9.3507	Cost: 12.03s
Train Epoch: 96 	Average Loss: 9.3650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4879

Learning rate: 0.0001999545243100684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 9.4427	Cost: 32.66s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 9.3289	Cost: 9.49s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 9.3971	Cost: 13.53s
Train Epoch: 97 	Average Loss: 9.3533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4757

Learning rate: 0.00019995357203913245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 9.5112	Cost: 32.31s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 9.2910	Cost: 9.53s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 9.2431	Cost: 11.97s
Train Epoch: 98 	Average Loss: 9.3239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4810

Learning rate: 0.00019995260990317447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 9.3626	Cost: 33.01s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 9.3739	Cost: 9.50s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 9.3156	Cost: 13.63s
Train Epoch: 99 	Average Loss: 9.3128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4193

Learning rate: 0.00019995163790228936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 9.4263	Cost: 33.81s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 9.2728	Cost: 9.51s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 9.1583	Cost: 13.18s
Train Epoch: 100 	Average Loss: 9.2585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3980

Learning rate: 0.0001999506560365731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 9.3650	Cost: 32.88s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 9.2673	Cost: 9.49s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 9.3314	Cost: 12.84s
Train Epoch: 101 	Average Loss: 9.2763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3664

Learning rate: 0.00019994966430612258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 9.3227	Cost: 33.34s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 9.2865	Cost: 9.48s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 9.3369	Cost: 12.60s
Train Epoch: 102 	Average Loss: 9.2583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3435

Learning rate: 0.00019994866271103568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 9.2708	Cost: 33.64s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 9.2962	Cost: 9.52s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 9.2032	Cost: 12.32s
Train Epoch: 103 	Average Loss: 9.2011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2519

Learning rate: 0.0001999476512514112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 9.2328	Cost: 32.37s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 9.1245	Cost: 9.51s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 9.2323	Cost: 13.92s
Train Epoch: 104 	Average Loss: 9.1707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3616

Learning rate: 0.00019994662992734905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 9.2669	Cost: 33.76s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 9.2665	Cost: 9.50s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 9.2199	Cost: 12.78s
Train Epoch: 105 	Average Loss: 9.2009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2529

Learning rate: 0.00019994559873894998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 9.1862	Cost: 33.58s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 9.1456	Cost: 9.50s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 9.2005	Cost: 12.77s
Train Epoch: 106 	Average Loss: 9.1771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2430

Learning rate: 0.00019994455768631577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 9.2469	Cost: 33.04s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 9.0793	Cost: 9.49s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 9.1715	Cost: 12.08s
Train Epoch: 107 	Average Loss: 9.1386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2151

Learning rate: 0.00019994350676954918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 9.1767	Cost: 33.36s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 9.1379	Cost: 9.50s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 9.1038	Cost: 12.62s
Train Epoch: 108 	Average Loss: 9.0957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2120

Learning rate: 0.00019994244598875392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 9.1876	Cost: 33.28s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 9.1288	Cost: 9.50s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 9.0755	Cost: 12.84s
Train Epoch: 109 	Average Loss: 9.0893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1775

Learning rate: 0.00019994137534403472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 9.2506	Cost: 32.57s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 9.0855	Cost: 9.50s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 9.1488	Cost: 12.21s
Train Epoch: 110 	Average Loss: 9.1161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1850

Learning rate: 0.00019994029483549723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 9.1680	Cost: 33.00s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 9.1383	Cost: 9.50s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 8.9946	Cost: 13.96s
Train Epoch: 111 	Average Loss: 9.0679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1732

Learning rate: 0.00019993920446324803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 9.1205	Cost: 34.01s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 9.0383	Cost: 9.49s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 8.9923	Cost: 13.06s
Train Epoch: 112 	Average Loss: 9.0240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1680

Learning rate: 0.00019993810422739487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 9.1370	Cost: 32.79s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 8.9799	Cost: 9.49s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 9.0426	Cost: 12.09s
Train Epoch: 113 	Average Loss: 9.0150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0577

Learning rate: 0.00019993699412804622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 9.1016	Cost: 33.33s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 9.0585	Cost: 9.49s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 8.9491	Cost: 13.04s
Train Epoch: 114 	Average Loss: 9.0151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0543

Learning rate: 0.00019993587416531166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 9.1031	Cost: 32.86s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 8.8756	Cost: 9.50s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 9.0950	Cost: 11.92s
Train Epoch: 115 	Average Loss: 8.9883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2103

Learning rate: 0.00019993474433930176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 9.0837	Cost: 33.64s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 8.9629	Cost: 9.49s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 8.9829	Cost: 12.25s
Train Epoch: 116 	Average Loss: 8.9775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1389

Learning rate: 0.000199933604650128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 9.0697	Cost: 33.20s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 8.9207	Cost: 9.49s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 9.1101	Cost: 12.56s
Train Epoch: 117 	Average Loss: 8.9823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0936

Learning rate: 0.0001999324550979029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 8.9785	Cost: 33.31s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 9.0181	Cost: 9.52s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 8.8845	Cost: 12.27s
Train Epoch: 118 	Average Loss: 8.9395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0304

Learning rate: 0.00019993129568273988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 9.0057	Cost: 32.89s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 8.9678	Cost: 9.53s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 8.9079	Cost: 12.33s
Train Epoch: 119 	Average Loss: 8.9134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0671

Learning rate: 0.0001999301264047534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 9.0227	Cost: 33.39s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 8.8978	Cost: 9.51s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 8.8570	Cost: 12.47s
Train Epoch: 120 	Average Loss: 8.8902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0921

Learning rate: 0.00019992894726405882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 8.9374	Cost: 33.23s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 8.8559	Cost: 9.51s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 8.8284	Cost: 13.20s
Train Epoch: 121 	Average Loss: 8.8683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0173

Learning rate: 0.00019992775826077256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 8.9935	Cost: 32.68s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 8.9011	Cost: 9.49s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 8.9445	Cost: 12.51s
Train Epoch: 122 	Average Loss: 8.8988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0866

Learning rate: 0.00019992655939501196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 8.9696	Cost: 33.37s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 8.8024	Cost: 9.50s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 8.9024	Cost: 12.08s
Train Epoch: 123 	Average Loss: 8.8453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9614

Learning rate: 0.00019992535066689534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 8.9787	Cost: 33.03s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 8.8251	Cost: 9.53s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 8.7945	Cost: 12.08s
Train Epoch: 124 	Average Loss: 8.8423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9803

Learning rate: 0.00019992413207654198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 8.9550	Cost: 33.22s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 8.7359	Cost: 9.47s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 8.9008	Cost: 12.58s
Train Epoch: 125 	Average Loss: 8.8393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9485

Learning rate: 0.0001999229036240722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 8.8720	Cost: 33.42s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 8.8162	Cost: 9.53s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 8.8171	Cost: 13.45s
Train Epoch: 126 	Average Loss: 8.7888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9037

Learning rate: 0.0001999216653096072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 8.9237	Cost: 33.27s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 8.7474	Cost: 9.51s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 8.7985	Cost: 12.18s
Train Epoch: 127 	Average Loss: 8.7644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9542

Learning rate: 0.00019992041713326917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 8.9208	Cost: 33.06s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 8.7688	Cost: 9.49s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 8.9062	Cost: 12.12s
Train Epoch: 128 	Average Loss: 8.7964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8903

Learning rate: 0.00019991915909518135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 8.8608	Cost: 32.67s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 8.7650	Cost: 9.48s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 8.8547	Cost: 13.54s
Train Epoch: 129 	Average Loss: 8.7678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8694

Learning rate: 0.0001999178911954679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 8.9133	Cost: 33.04s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 8.7191	Cost: 9.49s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 8.7889	Cost: 12.29s
Train Epoch: 130 	Average Loss: 8.7488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8708

Learning rate: 0.0001999166134342539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 8.9045	Cost: 32.45s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 8.7058	Cost: 9.47s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 8.7149	Cost: 11.99s
Train Epoch: 131 	Average Loss: 8.7327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8486

Learning rate: 0.00019991532581166554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 8.7929	Cost: 33.55s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 8.6211	Cost: 9.50s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 8.7655	Cost: 13.88s
Train Epoch: 132 	Average Loss: 8.7003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8107

Learning rate: 0.00019991402832782987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 8.9141	Cost: 33.59s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 8.7728	Cost: 9.50s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 8.6399	Cost: 12.51s
Train Epoch: 133 	Average Loss: 8.7014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8199

Learning rate: 0.00019991272098287494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 8.8356	Cost: 32.65s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 8.7566	Cost: 9.50s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 8.6838	Cost: 11.83s
Train Epoch: 134 	Average Loss: 8.6920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8485

Learning rate: 0.00019991140377692977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 8.8142	Cost: 33.40s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 8.5766	Cost: 9.51s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 8.6146	Cost: 12.33s
Train Epoch: 135 	Average Loss: 8.6493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8511

Learning rate: 0.0001999100767101244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 8.7855	Cost: 34.39s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 8.6604	Cost: 9.50s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 8.6658	Cost: 12.43s
Train Epoch: 136 	Average Loss: 8.6496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8240

Learning rate: 0.00019990873978258976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 8.8117	Cost: 32.81s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 8.5616	Cost: 9.51s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 8.6174	Cost: 13.38s
Train Epoch: 137 	Average Loss: 8.6298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8444

Learning rate: 0.0001999073929944578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 8.6021	Cost: 34.01s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 8.5976	Cost: 9.50s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 8.5543	Cost: 12.57s
Train Epoch: 138 	Average Loss: 8.5884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7559

Learning rate: 0.00019990603634586154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 8.8177	Cost: 33.53s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 8.5947	Cost: 9.53s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 8.5852	Cost: 11.82s
Train Epoch: 139 	Average Loss: 8.5973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6652

Learning rate: 0.00019990466983693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 8.7269	Cost: 32.77s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 8.6019	Cost: 9.52s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 8.5476	Cost: 13.50s
Train Epoch: 140 	Average Loss: 8.5899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7417

Learning rate: 0.00019990329346781236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 8.7225	Cost: 34.43s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 8.5528	Cost: 9.51s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 8.5143	Cost: 12.98s
Train Epoch: 141 	Average Loss: 8.5604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6522

Learning rate: 0.00019990190723863022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 8.7293	Cost: 33.53s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 8.5664	Cost: 9.49s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 8.5265	Cost: 12.73s
Train Epoch: 142 	Average Loss: 8.5492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6389

Learning rate: 0.00019990051114952508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 8.6342	Cost: 33.10s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 8.5776	Cost: 9.48s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 8.4686	Cost: 13.69s
Train Epoch: 143 	Average Loss: 8.5515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7025

Learning rate: 0.0001998991052006348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 8.6516	Cost: 33.71s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 8.4337	Cost: 9.69s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 8.5156	Cost: 13.22s
Train Epoch: 144 	Average Loss: 8.5186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6373

Learning rate: 0.0001998976893920981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 8.6688	Cost: 33.21s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 8.5058	Cost: 9.48s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 8.5474	Cost: 11.97s
Train Epoch: 145 	Average Loss: 8.5149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7365

Learning rate: 0.00019989626372405477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 8.7477	Cost: 33.81s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 8.4964	Cost: 9.48s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 8.4958	Cost: 12.75s
Train Epoch: 146 	Average Loss: 8.4975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6785

Learning rate: 0.00019989482819664545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 8.6425	Cost: 33.37s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 8.4857	Cost: 9.48s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 8.5639	Cost: 11.63s
Train Epoch: 147 	Average Loss: 8.4926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6278

Learning rate: 0.00019989338281001189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 8.6421	Cost: 32.97s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 8.5179	Cost: 9.52s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 8.4299	Cost: 12.24s
Train Epoch: 148 	Average Loss: 8.4626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5719

Learning rate: 0.00019989192756429667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 8.6082	Cost: 32.82s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 8.4451	Cost: 9.51s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 8.4201	Cost: 13.26s
Train Epoch: 149 	Average Loss: 8.4346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6272

Learning rate: 0.00019989046245964345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 8.7541	Cost: 32.60s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 8.4561	Cost: 9.50s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 8.3870	Cost: 11.79s
Train Epoch: 150 	Average Loss: 8.4402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6161

Learning rate: 0.00019988898749619688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 8.5677	Cost: 33.89s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 8.3816	Cost: 9.49s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 8.4895	Cost: 12.72s
Train Epoch: 151 	Average Loss: 8.4286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5882

Learning rate: 0.00019988750267410245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 8.6095	Cost: 33.36s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 8.4176	Cost: 9.50s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 8.3628	Cost: 12.67s
Train Epoch: 152 	Average Loss: 8.3982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5653

Learning rate: 0.0001998860079935067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 8.5606	Cost: 33.23s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 8.3363	Cost: 9.50s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 8.3806	Cost: 11.80s
Train Epoch: 153 	Average Loss: 8.3731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5112

Learning rate: 0.00019988450345455726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 8.4832	Cost: 32.89s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 8.3179	Cost: 9.53s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 8.3967	Cost: 11.93s
Train Epoch: 154 	Average Loss: 8.3728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6495

Learning rate: 0.00019988298905740252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 8.4711	Cost: 33.03s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 8.3869	Cost: 9.78s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 8.3669	Cost: 12.89s
Train Epoch: 155 	Average Loss: 8.3512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5656

Learning rate: 0.000199881464802192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 8.5683	Cost: 33.22s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 8.4020	Cost: 9.54s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 8.3469	Cost: 13.78s
Train Epoch: 156 	Average Loss: 8.4011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5448

Learning rate: 0.0001998799306890761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 8.5438	Cost: 32.61s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 8.3544	Cost: 9.52s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 8.3461	Cost: 13.37s
Train Epoch: 157 	Average Loss: 8.3300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5608

Learning rate: 0.00019987838671820622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 8.3929	Cost: 33.73s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 8.3604	Cost: 9.53s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 8.3565	Cost: 12.51s
Train Epoch: 158 	Average Loss: 8.3360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5082

Learning rate: 0.00019987683288973478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 8.4463	Cost: 33.00s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 8.2889	Cost: 9.53s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 8.3637	Cost: 12.08s
Train Epoch: 159 	Average Loss: 8.3099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4417

Learning rate: 0.00019987526920381513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 8.4973	Cost: 33.17s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 8.2158	Cost: 9.50s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 8.2974	Cost: 12.73s
Train Epoch: 160 	Average Loss: 8.2760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5356

Learning rate: 0.00019987369566060162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 8.4710	Cost: 33.03s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 8.2185	Cost: 9.49s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 8.2831	Cost: 13.33s
Train Epoch: 161 	Average Loss: 8.2799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5792

Learning rate: 0.0001998721122602495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 8.4905	Cost: 33.03s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 8.2662	Cost: 9.50s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 8.3276	Cost: 12.51s
Train Epoch: 162 	Average Loss: 8.2931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5675

Learning rate: 0.00019987051900291508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 8.4384	Cost: 33.34s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 8.2081	Cost: 9.50s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 8.2715	Cost: 13.03s
Train Epoch: 163 	Average Loss: 8.2278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4012

Learning rate: 0.00019986891588875562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 8.4862	Cost: 32.61s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 8.1972	Cost: 9.51s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 8.1975	Cost: 12.60s
Train Epoch: 164 	Average Loss: 8.2025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4026

Learning rate: 0.0001998673029179293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 8.3702	Cost: 33.47s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 8.1107	Cost: 9.49s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 8.2475	Cost: 12.99s
Train Epoch: 165 	Average Loss: 8.2185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3628

Learning rate: 0.00019986568009059536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 8.4477	Cost: 33.31s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 8.1818	Cost: 9.50s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 8.1894	Cost: 12.09s
Train Epoch: 166 	Average Loss: 8.1966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3711

Learning rate: 0.00019986404740691393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 8.3635	Cost: 33.32s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 8.1723	Cost: 9.51s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 8.2003	Cost: 12.21s
Train Epoch: 167 	Average Loss: 8.2003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3932

Learning rate: 0.00019986240486704617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 8.4207	Cost: 33.39s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 8.0969	Cost: 9.50s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 8.0791	Cost: 13.95s
Train Epoch: 168 	Average Loss: 8.1392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3276

Learning rate: 0.00019986075247115415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 8.2662	Cost: 33.41s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 8.0499	Cost: 9.52s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 8.0885	Cost: 12.68s
Train Epoch: 169 	Average Loss: 8.1359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3419

Learning rate: 0.00019985909021940103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 8.3174	Cost: 33.54s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 8.0538	Cost: 9.49s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 8.1380	Cost: 12.22s
Train Epoch: 170 	Average Loss: 8.1234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3396

Learning rate: 0.0001998574181119508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 8.3722	Cost: 32.93s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 8.1888	Cost: 9.50s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 8.1589	Cost: 13.38s
Train Epoch: 171 	Average Loss: 8.1397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2652

Learning rate: 0.00019985573614896853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 8.3376	Cost: 32.81s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 8.0943	Cost: 9.50s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 7.9849	Cost: 13.02s
Train Epoch: 172 	Average Loss: 8.0847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3062

Learning rate: 0.00019985404433062024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 8.2550	Cost: 33.09s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 8.0533	Cost: 9.51s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 8.0188	Cost: 11.91s
Train Epoch: 173 	Average Loss: 8.0946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2924

Learning rate: 0.00019985234265707287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 8.2803	Cost: 33.22s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 8.0613	Cost: 9.54s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 8.1003	Cost: 13.35s
Train Epoch: 174 	Average Loss: 8.0839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2518

Learning rate: 0.00019985063112849436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 8.1816	Cost: 32.64s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 7.9681	Cost: 9.48s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 8.0139	Cost: 12.77s
Train Epoch: 175 	Average Loss: 8.0293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1915

Learning rate: 0.00019984890974505368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 8.1957	Cost: 33.74s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 7.9792	Cost: 9.53s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 8.0040	Cost: 13.13s
Train Epoch: 176 	Average Loss: 8.0260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2556

Learning rate: 0.00019984717850692066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 8.2573	Cost: 33.61s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 7.9981	Cost: 9.69s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 7.9938	Cost: 12.47s
Train Epoch: 177 	Average Loss: 8.0384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3101

Learning rate: 0.00019984543741426617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 8.2586	Cost: 33.25s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 7.9891	Cost: 9.51s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 7.9907	Cost: 13.23s
Train Epoch: 178 	Average Loss: 8.0029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2792

Learning rate: 0.0001998436864672621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 8.2461	Cost: 33.42s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 8.0363	Cost: 9.49s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 7.9483	Cost: 12.14s
Train Epoch: 179 	Average Loss: 7.9904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2641

Learning rate: 0.00019984192566608125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 8.2128	Cost: 34.63s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 7.9857	Cost: 9.48s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 7.9418	Cost: 11.99s
Train Epoch: 180 	Average Loss: 7.9742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2314

Learning rate: 0.00019984015501089739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 8.1843	Cost: 32.92s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 7.9515	Cost: 9.50s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 7.9843	Cost: 12.19s
Train Epoch: 181 	Average Loss: 7.9589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2332

Learning rate: 0.00019983837450188524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 8.2218	Cost: 34.45s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 7.9121	Cost: 9.48s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 8.0120	Cost: 13.14s
Train Epoch: 182 	Average Loss: 7.9650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2033

Learning rate: 0.0001998365841392206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 8.2110	Cost: 33.28s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 7.8770	Cost: 9.51s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 7.8323	Cost: 13.14s
Train Epoch: 183 	Average Loss: 7.9302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1913

Learning rate: 0.00019983478392308012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 8.1734	Cost: 33.58s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 7.7596	Cost: 9.57s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 7.8240	Cost: 12.63s
Train Epoch: 184 	Average Loss: 7.9098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1774

Learning rate: 0.0001998329738536415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 8.2039	Cost: 32.67s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 7.8416	Cost: 9.51s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 7.9095	Cost: 12.27s
Train Epoch: 185 	Average Loss: 7.8967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2165

Learning rate: 0.00019983115393108338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 8.1403	Cost: 33.36s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 7.9741	Cost: 9.52s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 7.9120	Cost: 11.83s
Train Epoch: 186 	Average Loss: 7.8879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1694

Learning rate: 0.0001998293241555854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 8.1468	Cost: 32.41s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 7.8483	Cost: 9.53s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 7.7309	Cost: 12.32s
Train Epoch: 187 	Average Loss: 7.8535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0453

Learning rate: 0.0001998274845273281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 8.0837	Cost: 33.25s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 7.9284	Cost: 9.67s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 7.7466	Cost: 13.23s
Train Epoch: 188 	Average Loss: 7.8472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1637

Learning rate: 0.00019982563504649309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 8.1797	Cost: 33.14s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 7.8101	Cost: 9.47s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 7.8298	Cost: 12.78s
Train Epoch: 189 	Average Loss: 7.8556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0633

Learning rate: 0.00019982377571326284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 8.1518	Cost: 32.80s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 7.8296	Cost: 9.50s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 7.9176	Cost: 12.19s
Train Epoch: 190 	Average Loss: 7.8506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1757

Learning rate: 0.00019982190652782097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 8.0763	Cost: 33.85s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 7.7830	Cost: 9.73s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 7.7240	Cost: 12.18s
Train Epoch: 191 	Average Loss: 7.8154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0924

Learning rate: 0.0001998200274903519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 7.9697	Cost: 32.83s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 7.7136	Cost: 9.50s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 7.7933	Cost: 12.70s
Train Epoch: 192 	Average Loss: 7.7858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1371

Learning rate: 0.00019981813860104106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 8.1324	Cost: 33.34s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 7.6555	Cost: 9.53s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 7.7679	Cost: 13.61s
Train Epoch: 193 	Average Loss: 7.7675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0737

Learning rate: 0.0001998162398600749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 8.0752	Cost: 33.20s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 7.7197	Cost: 9.51s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 7.6926	Cost: 12.66s
Train Epoch: 194 	Average Loss: 7.7705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0247

Learning rate: 0.00019981433126764085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 8.0824	Cost: 33.31s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 7.6646	Cost: 9.51s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 7.6659	Cost: 13.51s
Train Epoch: 195 	Average Loss: 7.7530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9476

Learning rate: 0.00019981241282392723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 8.0142	Cost: 33.14s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 7.7662	Cost: 9.49s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 7.8244	Cost: 11.80s
Train Epoch: 196 	Average Loss: 7.7298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0509

Learning rate: 0.0001998104845291234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 8.0219	Cost: 32.98s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 7.6803	Cost: 9.49s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 7.6271	Cost: 11.85s
Train Epoch: 197 	Average Loss: 7.7140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0006

Learning rate: 0.00019980854638341968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 8.0325	Cost: 32.75s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 7.6532	Cost: 9.49s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 7.5855	Cost: 12.30s
Train Epoch: 198 	Average Loss: 7.6723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0097

Learning rate: 0.00019980659838700736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 8.0647	Cost: 32.86s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 7.6204	Cost: 9.45s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 7.5845	Cost: 13.18s
Train Epoch: 199 	Average Loss: 7.6659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0137

Learning rate: 0.0001998046405400787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 8.0212	Cost: 32.31s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 7.5600	Cost: 9.52s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 7.6710	Cost: 12.11s
Train Epoch: 200 	Average Loss: 7.6549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9771

Learning rate: 0.00019980267284282693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 7.9197	Cost: 32.82s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 7.6716	Cost: 9.54s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 7.6362	Cost: 12.18s
Train Epoch: 201 	Average Loss: 7.6813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0019

Learning rate: 0.00019980069529544622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 8.0162	Cost: 33.59s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 7.5752	Cost: 9.52s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 7.6315	Cost: 13.30s
Train Epoch: 202 	Average Loss: 7.6950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9748

Learning rate: 0.0001997987078981318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 7.9361	Cost: 33.72s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 7.5936	Cost: 9.53s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 7.6049	Cost: 12.87s
Train Epoch: 203 	Average Loss: 7.6049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9391

Learning rate: 0.00019979671065107978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 7.8479	Cost: 33.10s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 7.6143	Cost: 9.49s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 7.6111	Cost: 12.83s
Train Epoch: 204 	Average Loss: 7.5978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9272

Learning rate: 0.0001997947035544873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 8.0048	Cost: 33.70s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 7.5944	Cost: 9.51s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 7.5428	Cost: 12.24s
Train Epoch: 205 	Average Loss: 7.5879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9245

Learning rate: 0.00019979268660855247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 7.9845	Cost: 32.97s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 7.5783	Cost: 9.48s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 7.5434	Cost: 12.46s
Train Epoch: 206 	Average Loss: 7.6021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8997

Learning rate: 0.00019979065981347432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 7.9506	Cost: 33.59s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 7.6240	Cost: 9.55s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 7.6516	Cost: 12.19s
Train Epoch: 207 	Average Loss: 7.5877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8965

Learning rate: 0.0001997886231694529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 7.9679	Cost: 33.64s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 7.5127	Cost: 9.54s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 7.4523	Cost: 12.55s
Train Epoch: 208 	Average Loss: 7.5435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8395

Learning rate: 0.0001997865766766892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 7.7361	Cost: 32.85s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 7.4530	Cost: 9.53s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 7.4817	Cost: 13.89s
Train Epoch: 209 	Average Loss: 7.5167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9082

Learning rate: 0.00019978452033538524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 7.7796	Cost: 33.33s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 7.5298	Cost: 9.49s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 7.4251	Cost: 13.72s
Train Epoch: 210 	Average Loss: 7.5268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8505

Learning rate: 0.00019978245414574395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 7.7941	Cost: 32.96s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 7.3845	Cost: 9.51s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 7.4627	Cost: 12.87s
Train Epoch: 211 	Average Loss: 7.4700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8909

Learning rate: 0.00019978037810796924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 7.9150	Cost: 33.01s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 7.3707	Cost: 9.49s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 7.5507	Cost: 14.16s
Train Epoch: 212 	Average Loss: 7.5004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8579

Learning rate: 0.000199778292222266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 7.8963	Cost: 33.33s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 7.3980	Cost: 9.49s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 7.3597	Cost: 12.97s
Train Epoch: 213 	Average Loss: 7.4946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8309

Learning rate: 0.00019977619648884015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 7.8376	Cost: 32.87s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 7.4346	Cost: 9.46s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 7.3948	Cost: 11.96s
Train Epoch: 214 	Average Loss: 7.4570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7979

Learning rate: 0.0001997740909078985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 7.8462	Cost: 33.43s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 7.3836	Cost: 9.50s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 7.4139	Cost: 13.33s
Train Epoch: 215 	Average Loss: 7.4457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8312

Learning rate: 0.0001997719754796489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 7.8068	Cost: 33.34s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 7.4744	Cost: 9.49s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 7.4367	Cost: 12.98s
Train Epoch: 216 	Average Loss: 7.4348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7783

Learning rate: 0.00019976985020430003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 7.7821	Cost: 32.85s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 7.3075	Cost: 9.50s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 7.4093	Cost: 12.38s
Train Epoch: 217 	Average Loss: 7.4052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8158

Learning rate: 0.00019976771508206176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 7.7607	Cost: 33.38s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 7.3338	Cost: 9.49s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 7.3521	Cost: 13.66s
Train Epoch: 218 	Average Loss: 7.3830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7424

Learning rate: 0.00019976557011314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 7.6932	Cost: 33.85s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 7.3466	Cost: 9.48s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 7.3434	Cost: 11.85s
Train Epoch: 219 	Average Loss: 7.3818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7334

Learning rate: 0.00019976341529776072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 7.7400	Cost: 32.76s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 7.2957	Cost: 9.51s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 7.2972	Cost: 13.17s
Train Epoch: 220 	Average Loss: 7.3654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8282

Learning rate: 0.00019976125063612233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 7.8144	Cost: 33.19s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 7.4543	Cost: 9.49s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 7.3291	Cost: 12.82s
Train Epoch: 221 	Average Loss: 7.3587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8654

Learning rate: 0.00019975907612844327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 7.8130	Cost: 33.74s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 7.3166	Cost: 9.50s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 7.3169	Cost: 12.51s
Train Epoch: 222 	Average Loss: 7.3385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7273

Learning rate: 0.00019975689177493812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 7.7135	Cost: 32.76s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 7.3031	Cost: 9.49s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 7.2558	Cost: 12.32s
Train Epoch: 223 	Average Loss: 7.3455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7382

Learning rate: 0.00019975469757582245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 7.7468	Cost: 33.46s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 7.3915	Cost: 9.55s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 7.2149	Cost: 11.87s
Train Epoch: 224 	Average Loss: 7.3210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6865

Learning rate: 0.00019975249353131286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 7.6933	Cost: 32.79s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 7.3550	Cost: 9.51s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 7.1711	Cost: 11.76s
Train Epoch: 225 	Average Loss: 7.3091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6972

Learning rate: 0.00019975027964162683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 7.6864	Cost: 33.12s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 7.2190	Cost: 9.49s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 7.1377	Cost: 12.05s
Train Epoch: 226 	Average Loss: 7.2246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6379

Learning rate: 0.0001997480559069829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 7.6719	Cost: 33.11s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 7.1863	Cost: 9.49s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 7.1625	Cost: 12.91s
Train Epoch: 227 	Average Loss: 7.2319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6523

Learning rate: 0.00019974582232760058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 7.6469	Cost: 34.33s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 7.1343	Cost: 9.48s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 7.1883	Cost: 12.23s
Train Epoch: 228 	Average Loss: 7.2372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6953

Learning rate: 0.0001997435789037002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 7.5863	Cost: 33.06s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 7.1041	Cost: 9.50s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 7.0848	Cost: 13.13s
Train Epoch: 229 	Average Loss: 7.1889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6630

Learning rate: 0.0001997413256355033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 7.6824	Cost: 33.17s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 7.1677	Cost: 9.51s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 7.1779	Cost: 12.81s
Train Epoch: 230 	Average Loss: 7.1834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6782

Learning rate: 0.0001997390625232322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 7.6934	Cost: 33.14s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 7.1046	Cost: 9.49s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 7.0569	Cost: 11.94s
Train Epoch: 231 	Average Loss: 7.1638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6168

Learning rate: 0.00019973678956711026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 7.6498	Cost: 33.19s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 7.0991	Cost: 9.51s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 7.1085	Cost: 12.58s
Train Epoch: 232 	Average Loss: 7.1445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5640

Learning rate: 0.00019973450676736185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 7.5430	Cost: 32.62s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 7.0183	Cost: 9.50s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 7.1235	Cost: 13.27s
Train Epoch: 233 	Average Loss: 7.1346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5818

Learning rate: 0.00019973221412421225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 7.4846	Cost: 34.88s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 6.9992	Cost: 9.51s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 7.0626	Cost: 12.56s
Train Epoch: 234 	Average Loss: 7.0974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5946

Learning rate: 0.0001997299116378877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 7.5433	Cost: 32.72s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 7.0636	Cost: 9.50s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 6.9288	Cost: 12.83s
Train Epoch: 235 	Average Loss: 7.0928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6308

Learning rate: 0.0001997275993086155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 7.6013	Cost: 32.87s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 7.0655	Cost: 9.50s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 7.0743	Cost: 11.96s
Train Epoch: 236 	Average Loss: 7.0638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5259

Learning rate: 0.0001997252771366239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 7.5308	Cost: 33.36s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 7.0981	Cost: 9.51s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 7.0436	Cost: 13.55s
Train Epoch: 237 	Average Loss: 7.0961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6328

Learning rate: 0.000199722945122142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 7.4885	Cost: 32.68s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 6.9264	Cost: 9.50s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 7.0206	Cost: 12.72s
Train Epoch: 238 	Average Loss: 7.0368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4797

Learning rate: 0.0001997206032654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 7.4222	Cost: 32.98s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 6.8814	Cost: 9.50s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 6.9857	Cost: 13.86s
Train Epoch: 239 	Average Loss: 7.0054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6114

Learning rate: 0.00019971825156662903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 7.5055	Cost: 32.86s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 6.9678	Cost: 9.48s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 6.9401	Cost: 11.84s
Train Epoch: 240 	Average Loss: 6.9950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4584

Learning rate: 0.00019971589002606117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 7.5690	Cost: 32.91s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 6.8367	Cost: 9.50s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 6.9578	Cost: 12.57s
Train Epoch: 241 	Average Loss: 6.9859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5016

Learning rate: 0.00019971351864392958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 7.4490	Cost: 33.07s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 6.9410	Cost: 9.52s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 6.9107	Cost: 13.66s
Train Epoch: 242 	Average Loss: 6.9822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4530

Learning rate: 0.00019971113742046817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 7.6004	Cost: 34.02s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 6.9584	Cost: 9.49s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 7.0070	Cost: 13.65s
Train Epoch: 243 	Average Loss: 6.9782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4469

Learning rate: 0.00019970874635591207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 7.5164	Cost: 33.27s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 6.8174	Cost: 9.52s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 6.8610	Cost: 12.95s
Train Epoch: 244 	Average Loss: 6.8829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4542

Learning rate: 0.00019970634545049727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 7.4533	Cost: 32.58s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 6.8390	Cost: 9.50s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 6.9164	Cost: 12.24s
Train Epoch: 245 	Average Loss: 6.9388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4611

Learning rate: 0.0001997039347044607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 7.4871	Cost: 32.94s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 6.8292	Cost: 9.51s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 6.8210	Cost: 11.67s
Train Epoch: 246 	Average Loss: 6.9053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3769

Learning rate: 0.00019970151411804023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 7.4019	Cost: 33.21s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 6.7955	Cost: 9.50s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 6.8206	Cost: 12.62s
Train Epoch: 247 	Average Loss: 6.8711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3817

Learning rate: 0.00019969908369147485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 7.4049	Cost: 32.50s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 6.6781	Cost: 9.55s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 6.8216	Cost: 12.49s
Train Epoch: 248 	Average Loss: 6.8488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4299

Learning rate: 0.00019969664342500438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 7.3026	Cost: 34.17s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 6.7061	Cost: 9.52s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 6.7527	Cost: 11.72s
Train Epoch: 249 	Average Loss: 6.8502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4153

Learning rate: 0.00019969419331886966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 7.2772	Cost: 32.69s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 6.8010	Cost: 9.41s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 6.7797	Cost: 13.97s
Train Epoch: 250 	Average Loss: 6.8124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4262

Learning rate: 0.0001996917333733126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 7.5971	Cost: 32.18s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 6.7488	Cost: 9.49s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 6.7555	Cost: 12.85s
Train Epoch: 251 	Average Loss: 6.8161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4057

Learning rate: 0.00019968926358857587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 7.3412	Cost: 34.26s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 6.7422	Cost: 9.49s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 6.6761	Cost: 11.90s
Train Epoch: 252 	Average Loss: 6.7959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2789

Learning rate: 0.00019968678396490325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 7.3131	Cost: 32.54s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 6.6540	Cost: 9.52s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 6.8341	Cost: 12.17s
Train Epoch: 253 	Average Loss: 6.7865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3985

Learning rate: 0.00019968429450253954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 7.3622	Cost: 33.17s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 6.6269	Cost: 9.50s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 6.6880	Cost: 13.24s
Train Epoch: 254 	Average Loss: 6.7331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3026

Learning rate: 0.0001996817952017304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 7.2753	Cost: 34.27s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 6.7169	Cost: 9.48s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 6.7356	Cost: 11.94s
Train Epoch: 255 	Average Loss: 6.7231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3552

Learning rate: 0.00019967928606272244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 7.3645	Cost: 33.18s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 6.5803	Cost: 9.50s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 6.6539	Cost: 12.58s
Train Epoch: 256 	Average Loss: 6.7032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2793

Learning rate: 0.0001996767670857634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 7.3467	Cost: 32.71s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 6.6361	Cost: 9.47s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 6.5749	Cost: 13.90s
Train Epoch: 257 	Average Loss: 6.7012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2853

Learning rate: 0.00019967423827110182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 7.2490	Cost: 33.78s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 6.5475	Cost: 9.51s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 6.5973	Cost: 11.87s
Train Epoch: 258 	Average Loss: 6.6613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2401

Learning rate: 0.00019967169961898734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 7.2127	Cost: 33.17s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 6.5351	Cost: 9.53s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 6.5826	Cost: 13.63s
Train Epoch: 259 	Average Loss: 6.6437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2191

Learning rate: 0.00019966915112967047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 7.2244	Cost: 32.48s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 6.5094	Cost: 9.49s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 6.5110	Cost: 12.34s
Train Epoch: 260 	Average Loss: 6.6091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2309

Learning rate: 0.00019966659280340273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 7.1831	Cost: 34.00s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 6.5525	Cost: 9.52s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 6.5538	Cost: 13.01s
Train Epoch: 261 	Average Loss: 6.5937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2552

Learning rate: 0.00019966402464043667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 7.2271	Cost: 33.11s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 6.4820	Cost: 9.48s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 6.6052	Cost: 12.83s
Train Epoch: 262 	Average Loss: 6.6123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2293

Learning rate: 0.00019966144664102572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 7.1565	Cost: 33.14s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 6.5597	Cost: 9.49s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 6.5103	Cost: 13.28s
Train Epoch: 263 	Average Loss: 6.6121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3306

Learning rate: 0.00019965885880542434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 7.0927	Cost: 34.89s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 6.4864	Cost: 9.52s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 6.4166	Cost: 12.44s
Train Epoch: 264 	Average Loss: 6.5367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2528

Learning rate: 0.00019965626113388794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 7.3011	Cost: 32.54s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 6.5034	Cost: 9.50s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 6.4662	Cost: 13.12s
Train Epoch: 265 	Average Loss: 6.5365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2432

Learning rate: 0.00019965365362667288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 7.1734	Cost: 32.96s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 6.4603	Cost: 9.49s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 6.4621	Cost: 13.68s
Train Epoch: 266 	Average Loss: 6.5562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2232

Learning rate: 0.0001996510362840365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 7.1034	Cost: 33.87s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 6.4576	Cost: 9.48s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 6.4001	Cost: 13.48s
Train Epoch: 267 	Average Loss: 6.5076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1631

Learning rate: 0.00019964840910623716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 7.1369	Cost: 32.47s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 6.4005	Cost: 9.50s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 6.4174	Cost: 13.14s
Train Epoch: 268 	Average Loss: 6.4734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1011

Learning rate: 0.00019964577209353413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 7.1945	Cost: 33.06s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 6.2990	Cost: 9.51s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 6.3513	Cost: 11.75s
Train Epoch: 269 	Average Loss: 6.4750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0931

Learning rate: 0.00019964312524618766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 7.0855	Cost: 33.95s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 6.4341	Cost: 9.49s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 6.3797	Cost: 13.38s
Train Epoch: 270 	Average Loss: 6.4311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1080

Learning rate: 0.000199640468564459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 7.0710	Cost: 33.00s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 6.3023	Cost: 9.49s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 6.2215	Cost: 13.03s
Train Epoch: 271 	Average Loss: 6.3785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0656

Learning rate: 0.00019963780204861037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 7.1391	Cost: 32.81s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 6.3467	Cost: 9.49s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 6.2980	Cost: 13.71s
Train Epoch: 272 	Average Loss: 6.4022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0324

Learning rate: 0.0001996351256989049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 6.9994	Cost: 33.45s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 6.2999	Cost: 9.51s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 6.2751	Cost: 12.92s
Train Epoch: 273 	Average Loss: 6.3847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1107

Learning rate: 0.0001996324395156068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 7.1479	Cost: 32.64s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 6.2126	Cost: 9.48s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 6.1919	Cost: 13.16s
Train Epoch: 274 	Average Loss: 6.3421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0700

Learning rate: 0.00019962974349898107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 7.0942	Cost: 32.57s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 6.2989	Cost: 9.51s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 6.2470	Cost: 12.88s
Train Epoch: 275 	Average Loss: 6.3718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0718

Learning rate: 0.0001996270376492939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 7.0152	Cost: 33.59s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 6.3535	Cost: 9.47s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 6.3512	Cost: 12.47s
Train Epoch: 276 	Average Loss: 6.3318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9977

Learning rate: 0.00019962432196681234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 6.9281	Cost: 32.79s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 6.3267	Cost: 9.49s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 6.2028	Cost: 12.92s
Train Epoch: 277 	Average Loss: 6.3114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0340

Learning rate: 0.00019962159645180437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 6.8954	Cost: 32.99s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 6.1618	Cost: 9.50s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 6.1911	Cost: 13.37s
Train Epoch: 278 	Average Loss: 6.2684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0514

Learning rate: 0.00019961886110453903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 6.9993	Cost: 33.65s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 6.2440	Cost: 9.47s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 6.2391	Cost: 12.00s
Train Epoch: 279 	Average Loss: 6.2931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9606

Learning rate: 0.00019961611592528625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 6.9219	Cost: 33.37s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 6.1542	Cost: 9.48s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 6.2356	Cost: 12.05s
Train Epoch: 280 	Average Loss: 6.2475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9437

Learning rate: 0.000199613360914317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 6.9041	Cost: 33.08s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 6.1431	Cost: 9.51s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 6.1591	Cost: 12.20s
Train Epoch: 281 	Average Loss: 6.2303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9923

Learning rate: 0.00019961059607190318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 6.9339	Cost: 33.49s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 6.1850	Cost: 9.55s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 6.0837	Cost: 12.69s
Train Epoch: 282 	Average Loss: 6.1883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9330

Learning rate: 0.00019960782139831766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 6.7634	Cost: 32.41s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 6.0700	Cost: 9.50s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 6.0816	Cost: 12.00s
Train Epoch: 283 	Average Loss: 6.1520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9850

Learning rate: 0.00019960503689383428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 6.7794	Cost: 33.23s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 5.9974	Cost: 9.51s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 6.1122	Cost: 13.34s
Train Epoch: 284 	Average Loss: 6.1421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9696

Learning rate: 0.0001996022425587279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 6.8392	Cost: 33.47s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 6.0299	Cost: 9.54s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 6.0387	Cost: 13.29s
Train Epoch: 285 	Average Loss: 6.1272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8768

Learning rate: 0.0001995994383932743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 6.7196	Cost: 32.53s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 5.9857	Cost: 9.49s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 6.0264	Cost: 13.61s
Train Epoch: 286 	Average Loss: 6.1205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9153

Learning rate: 0.0001995966243977502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 6.9615	Cost: 33.10s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 6.0114	Cost: 9.50s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 6.0446	Cost: 12.89s
Train Epoch: 287 	Average Loss: 6.1124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9111

Learning rate: 0.0001995938005724334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 6.8355	Cost: 33.65s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 5.9912	Cost: 9.50s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 5.9613	Cost: 12.79s
Train Epoch: 288 	Average Loss: 6.0749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9014

Learning rate: 0.00019959096691760252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 7.0170	Cost: 32.34s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 5.8941	Cost: 9.49s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 5.9579	Cost: 12.93s
Train Epoch: 289 	Average Loss: 6.0692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8123

Learning rate: 0.00019958812343353726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 6.8987	Cost: 33.21s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 6.0200	Cost: 9.48s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 5.9073	Cost: 12.13s
Train Epoch: 290 	Average Loss: 6.0617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9042

Learning rate: 0.0001995852701205183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 6.7173	Cost: 32.49s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 5.8318	Cost: 9.51s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 5.9434	Cost: 11.67s
Train Epoch: 291 	Average Loss: 6.0012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7589

Learning rate: 0.0001995824069788272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 6.8259	Cost: 32.70s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 5.8532	Cost: 9.47s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 5.8381	Cost: 12.52s
Train Epoch: 292 	Average Loss: 5.9906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7596

Learning rate: 0.00019957953400874656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 6.6363	Cost: 33.54s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 5.8968	Cost: 9.53s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 5.9291	Cost: 11.84s
Train Epoch: 293 	Average Loss: 5.9638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7908

Learning rate: 0.00019957665121055995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 6.9399	Cost: 33.21s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 5.7944	Cost: 9.52s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 5.9136	Cost: 13.39s
Train Epoch: 294 	Average Loss: 6.0081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8226

Learning rate: 0.00019957375858455185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 6.7144	Cost: 32.50s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 5.7776	Cost: 9.49s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 5.8740	Cost: 11.82s
Train Epoch: 295 	Average Loss: 5.9550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7389

Learning rate: 0.00019957085613100776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 6.6764	Cost: 33.44s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 5.8381	Cost: 9.72s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 5.8048	Cost: 11.85s
Train Epoch: 296 	Average Loss: 5.9279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7942

Learning rate: 0.00019956794385021415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 6.7269	Cost: 33.41s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 5.7443	Cost: 9.51s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 5.7516	Cost: 13.16s
Train Epoch: 297 	Average Loss: 5.8811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7091

Learning rate: 0.00019956502174245846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 6.7909	Cost: 33.02s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 5.8095	Cost: 9.48s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 5.7632	Cost: 11.88s
Train Epoch: 298 	Average Loss: 5.8818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7065

Learning rate: 0.0001995620898080291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 6.6547	Cost: 33.97s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 5.7136	Cost: 9.52s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 5.6865	Cost: 11.95s
Train Epoch: 299 	Average Loss: 5.8349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6947

Learning rate: 0.00019955914804721542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 6.6769	Cost: 33.28s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 5.6779	Cost: 9.49s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 5.8555	Cost: 12.95s
Train Epoch: 300 	Average Loss: 5.8112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7097

Learning rate: 0.00019955619646030775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 6.5481	Cost: 32.49s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 5.6047	Cost: 9.50s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 5.7162	Cost: 12.96s
Train Epoch: 301 	Average Loss: 5.7856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7179

Learning rate: 0.0001995532350475974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 6.6934	Cost: 33.98s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 5.6958	Cost: 9.50s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 5.6857	Cost: 12.36s
Train Epoch: 302 	Average Loss: 5.8062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6384

Learning rate: 0.00019955026380937669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 6.7612	Cost: 33.06s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 5.6755	Cost: 9.49s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 5.6861	Cost: 12.30s
Train Epoch: 303 	Average Loss: 5.7952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6380

Learning rate: 0.00019954728274593884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 6.5959	Cost: 33.08s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 5.6294	Cost: 9.49s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 5.6559	Cost: 12.05s
Train Epoch: 304 	Average Loss: 5.7423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6187

Learning rate: 0.00019954429185757805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 6.6060	Cost: 33.71s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 5.5561	Cost: 9.51s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 5.5891	Cost: 13.07s
Train Epoch: 305 	Average Loss: 5.7005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7280

Learning rate: 0.00019954129114458955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 6.6614	Cost: 33.40s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 5.5130	Cost: 9.48s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 5.5186	Cost: 12.24s
Train Epoch: 306 	Average Loss: 5.6945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5320

Learning rate: 0.00019953828060726943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 6.5307	Cost: 33.84s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 5.6049	Cost: 9.75s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 5.5947	Cost: 13.22s
Train Epoch: 307 	Average Loss: 5.6626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6097

Learning rate: 0.00019953526024591494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 6.6083	Cost: 33.65s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 5.5523	Cost: 9.51s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 5.5550	Cost: 12.78s
Train Epoch: 308 	Average Loss: 5.6738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5960

Learning rate: 0.00019953223006082406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 6.6379	Cost: 33.46s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 5.5753	Cost: 9.49s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 5.5154	Cost: 12.38s
Train Epoch: 309 	Average Loss: 5.6583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5681

Learning rate: 0.00019952919005229592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 6.5604	Cost: 33.61s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 5.3731	Cost: 9.48s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 5.5103	Cost: 11.98s
Train Epoch: 310 	Average Loss: 5.5970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5273

Learning rate: 0.00019952614022063054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 6.5107	Cost: 32.76s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 5.3773	Cost: 9.55s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 5.3447	Cost: 12.68s
Train Epoch: 311 	Average Loss: 5.5596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4563

Learning rate: 0.00019952308056612892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 6.3905	Cost: 32.95s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 5.4395	Cost: 9.49s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 5.4750	Cost: 11.94s
Train Epoch: 312 	Average Loss: 5.5515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4547

Learning rate: 0.00019952001108909304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 6.4248	Cost: 32.75s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 5.5750	Cost: 9.50s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 5.4292	Cost: 11.69s
Train Epoch: 313 	Average Loss: 5.5821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4543

Learning rate: 0.00019951693178982586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 6.4063	Cost: 32.81s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 5.4018	Cost: 9.49s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 5.3286	Cost: 13.34s
Train Epoch: 314 	Average Loss: 5.5211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5179

Learning rate: 0.00019951384266863126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 6.2542	Cost: 33.11s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 5.3308	Cost: 9.49s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 5.4779	Cost: 11.76s
Train Epoch: 315 	Average Loss: 5.4869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4520

Learning rate: 0.00019951074372581416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 6.3908	Cost: 33.84s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 5.3380	Cost: 9.48s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 5.4019	Cost: 11.84s
Train Epoch: 316 	Average Loss: 5.4799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4037

Learning rate: 0.00019950763496168037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 6.2469	Cost: 33.75s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 5.3796	Cost: 9.49s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 5.3771	Cost: 12.68s
Train Epoch: 317 	Average Loss: 5.4675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3926

Learning rate: 0.00019950451637653678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 6.2949	Cost: 32.93s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 5.3163	Cost: 9.67s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 5.3740	Cost: 12.90s
Train Epoch: 318 	Average Loss: 5.4326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4989

Learning rate: 0.00019950138797069118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 6.4636	Cost: 33.63s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 5.2924	Cost: 9.47s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 5.2815	Cost: 12.65s
Train Epoch: 319 	Average Loss: 5.4335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4812

Learning rate: 0.00019949824974445222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 6.2483	Cost: 32.98s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 5.3064	Cost: 9.48s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 5.2755	Cost: 12.80s
Train Epoch: 320 	Average Loss: 5.4158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4009

Learning rate: 0.00019949510169812976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 6.3933	Cost: 33.70s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 5.2534	Cost: 9.48s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 5.3012	Cost: 12.74s
Train Epoch: 321 	Average Loss: 5.3903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4101

Learning rate: 0.00019949194383203438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 6.4886	Cost: 32.51s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 5.2681	Cost: 9.51s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 5.1967	Cost: 11.69s
Train Epoch: 322 	Average Loss: 5.3903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3833

Learning rate: 0.00019948877614647787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 6.3612	Cost: 33.52s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 5.2032	Cost: 9.54s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 5.2125	Cost: 12.98s
Train Epoch: 323 	Average Loss: 5.3246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3199

Learning rate: 0.0001994855986417728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 6.3963	Cost: 33.03s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 5.2149	Cost: 9.48s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 5.2205	Cost: 12.96s
Train Epoch: 324 	Average Loss: 5.3395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3504

Learning rate: 0.0001994824113182328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 6.2796	Cost: 32.94s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 5.1274	Cost: 9.53s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 5.1722	Cost: 12.62s
Train Epoch: 325 	Average Loss: 5.2865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4245

Learning rate: 0.00019947921417617242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 6.4745	Cost: 32.38s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 5.2691	Cost: 9.54s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 5.2724	Cost: 11.62s
Train Epoch: 326 	Average Loss: 5.2867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1537

Learning rate: 0.0001994760072159072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 6.2409	Cost: 33.28s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 5.1517	Cost: 9.51s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 5.1127	Cost: 14.04s
Train Epoch: 327 	Average Loss: 5.2575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2900

Learning rate: 0.00019947279043775368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 6.3088	Cost: 33.18s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 5.1468	Cost: 9.51s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 5.0859	Cost: 12.05s
Train Epoch: 328 	Average Loss: 5.2383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2824

Learning rate: 0.00019946956384202932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 6.1758	Cost: 33.26s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 4.9946	Cost: 9.68s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 5.0806	Cost: 11.96s
Train Epoch: 329 	Average Loss: 5.2062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3495

Learning rate: 0.00019946632742905265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 6.1443	Cost: 32.75s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 5.0379	Cost: 9.48s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 5.1573	Cost: 12.95s
Train Epoch: 330 	Average Loss: 5.1974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3206

Learning rate: 0.000199463081199143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 6.3346	Cost: 33.36s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 5.0234	Cost: 9.49s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 5.0329	Cost: 12.94s
Train Epoch: 331 	Average Loss: 5.2149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1747

Learning rate: 0.0001994598251526208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 6.1656	Cost: 34.99s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 4.9339	Cost: 9.51s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 5.0859	Cost: 12.51s
Train Epoch: 332 	Average Loss: 5.1774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2318

Learning rate: 0.00019945655928980737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 6.0493	Cost: 32.44s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 4.9265	Cost: 9.53s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 4.9116	Cost: 13.31s
Train Epoch: 333 	Average Loss: 5.1066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2166

Learning rate: 0.0001994532836110251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 6.0655	Cost: 32.74s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 4.9121	Cost: 9.50s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 4.9200	Cost: 13.46s
Train Epoch: 334 	Average Loss: 5.0813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1409

Learning rate: 0.00019944999811659725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 6.1568	Cost: 34.11s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 4.8651	Cost: 9.50s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 5.0853	Cost: 12.59s
Train Epoch: 335 	Average Loss: 5.0816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2211

Learning rate: 0.00019944670280684805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 6.1508	Cost: 32.86s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 5.0515	Cost: 9.56s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 5.0167	Cost: 12.23s
Train Epoch: 336 	Average Loss: 5.0939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1736

Learning rate: 0.00019944339768210285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 6.0975	Cost: 32.39s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 4.8204	Cost: 9.51s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 4.8630	Cost: 11.89s
Train Epoch: 337 	Average Loss: 5.0162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2818

Learning rate: 0.0001994400827426877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 6.0383	Cost: 33.06s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 4.8817	Cost: 9.50s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 4.9573	Cost: 11.84s
Train Epoch: 338 	Average Loss: 5.0499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2420

Learning rate: 0.0001994367579889299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 6.1193	Cost: 32.60s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 5.1214	Cost: 9.53s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 5.0770	Cost: 13.11s
Train Epoch: 339 	Average Loss: 5.1951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3016

Learning rate: 0.0001994334234211575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 6.1747	Cost: 33.31s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 4.9223	Cost: 9.52s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 4.8962	Cost: 11.83s
Train Epoch: 340 	Average Loss: 5.0964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1140

Learning rate: 0.00019943007903969968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 6.0222	Cost: 32.30s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 4.7603	Cost: 9.52s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 4.8451	Cost: 11.89s
Train Epoch: 341 	Average Loss: 4.9668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1733

Learning rate: 0.00019942672484488645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 6.0447	Cost: 33.46s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 4.7927	Cost: 9.54s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 4.6870	Cost: 13.55s
Train Epoch: 342 	Average Loss: 4.9004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0513

Learning rate: 0.0001994233608370489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 6.2096	Cost: 32.79s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 4.7898	Cost: 9.52s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 4.6882	Cost: 12.05s
Train Epoch: 343 	Average Loss: 4.8946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0900

Learning rate: 0.00019941998701651908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 5.9460	Cost: 33.67s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 4.6646	Cost: 9.48s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 4.8360	Cost: 13.56s
Train Epoch: 344 	Average Loss: 4.8589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9840

Learning rate: 0.00019941660338362987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 6.0338	Cost: 32.97s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 4.6917	Cost: 9.45s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 4.6767	Cost: 11.80s
Train Epoch: 345 	Average Loss: 4.8371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0088

Learning rate: 0.0001994132099387153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 5.9910	Cost: 32.90s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 4.7260	Cost: 9.48s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 4.8161	Cost: 13.39s
Train Epoch: 346 	Average Loss: 4.8719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9833

Learning rate: 0.00019940980668211027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 5.9962	Cost: 33.47s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 4.7123	Cost: 9.48s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 4.8056	Cost: 13.42s
Train Epoch: 347 	Average Loss: 4.8700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0242

Learning rate: 0.00019940639361415064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 5.9869	Cost: 35.26s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 4.6101	Cost: 9.50s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 4.6594	Cost: 12.51s
Train Epoch: 348 	Average Loss: 4.8021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9871

Learning rate: 0.00019940297073517331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 5.9448	Cost: 33.75s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 4.5823	Cost: 9.56s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 4.6366	Cost: 12.69s
Train Epoch: 349 	Average Loss: 4.7694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9658

Learning rate: 0.00019939953804551608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 5.9076	Cost: 33.58s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 4.5742	Cost: 9.50s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 4.5491	Cost: 13.29s
Train Epoch: 350 	Average Loss: 4.7290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8909

Learning rate: 0.00019939609554551777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 5.9326	Cost: 33.14s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 4.7067	Cost: 9.53s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 4.5264	Cost: 11.88s
Train Epoch: 351 	Average Loss: 4.7804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9631

Learning rate: 0.0001993926432355181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 5.9352	Cost: 32.89s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 4.5766	Cost: 9.51s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 4.5761	Cost: 13.70s
Train Epoch: 352 	Average Loss: 4.7029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8819

Learning rate: 0.00019938918111585784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 5.8138	Cost: 32.75s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 4.5478	Cost: 9.49s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 4.6530	Cost: 11.87s
Train Epoch: 353 	Average Loss: 4.6912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8224

Learning rate: 0.00019938570918687863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 5.8173	Cost: 32.91s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 4.4755	Cost: 9.47s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 4.5162	Cost: 11.80s
Train Epoch: 354 	Average Loss: 4.6469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8230

Learning rate: 0.0001993822274489232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 5.6726	Cost: 32.62s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 4.4438	Cost: 9.55s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 4.4783	Cost: 12.66s
Train Epoch: 355 	Average Loss: 4.6298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8206

Learning rate: 0.00019937873590233516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 5.7662	Cost: 33.11s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 4.4981	Cost: 9.50s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 4.5776	Cost: 11.96s
Train Epoch: 356 	Average Loss: 4.6205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8650

Learning rate: 0.0001993752345474591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 5.8418	Cost: 33.10s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 4.4378	Cost: 9.52s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 4.6233	Cost: 13.23s
Train Epoch: 357 	Average Loss: 4.6385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9772

Learning rate: 0.0001993717233846406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 5.8716	Cost: 33.15s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 4.4533	Cost: 9.51s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 4.3177	Cost: 12.06s
Train Epoch: 358 	Average Loss: 4.6137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7893

Learning rate: 0.0001993682024142262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 5.6573	Cost: 33.01s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 4.2055	Cost: 9.49s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 4.3754	Cost: 12.26s
Train Epoch: 359 	Average Loss: 4.5390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8239

Learning rate: 0.00019936467163656337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 5.6468	Cost: 32.99s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 4.4243	Cost: 9.51s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 4.4790	Cost: 12.09s
Train Epoch: 360 	Average Loss: 4.5606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8331

Learning rate: 0.00019936113105200064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 5.6783	Cost: 33.81s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 4.4034	Cost: 9.50s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 4.3734	Cost: 13.35s
Train Epoch: 361 	Average Loss: 4.5060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8004

Learning rate: 0.00019935758066088742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 5.7752	Cost: 32.89s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 4.3555	Cost: 9.53s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 4.3333	Cost: 11.90s
Train Epoch: 362 	Average Loss: 4.4624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7425

Learning rate: 0.00019935402046357414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 5.8017	Cost: 33.75s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 4.3226	Cost: 9.50s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 4.2807	Cost: 13.66s
Train Epoch: 363 	Average Loss: 4.4604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8051

Learning rate: 0.00019935045046041218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 5.6854	Cost: 34.09s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 4.2351	Cost: 9.52s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 4.2174	Cost: 12.99s
Train Epoch: 364 	Average Loss: 4.4057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7122

Learning rate: 0.00019934687065175386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 5.6800	Cost: 33.25s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 4.2338	Cost: 9.48s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 4.2963	Cost: 11.89s
Train Epoch: 365 	Average Loss: 4.4258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6744

Learning rate: 0.00019934328103795248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 5.6662	Cost: 32.90s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 4.1757	Cost: 9.50s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 4.1802	Cost: 12.38s
Train Epoch: 366 	Average Loss: 4.3588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6664

Learning rate: 0.00019933968161936236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 5.6159	Cost: 33.61s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 4.2395	Cost: 9.48s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 4.2219	Cost: 12.89s
Train Epoch: 367 	Average Loss: 4.3372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6309

Learning rate: 0.00019933607239633875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 5.6159	Cost: 33.01s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 4.1583	Cost: 9.49s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 4.1700	Cost: 12.57s
Train Epoch: 368 	Average Loss: 4.3231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5538

Learning rate: 0.00019933245336923783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 5.6820	Cost: 32.73s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 4.0621	Cost: 9.51s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 4.1800	Cost: 12.84s
Train Epoch: 369 	Average Loss: 4.2778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6766

Learning rate: 0.0001993288245384168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 5.5687	Cost: 32.64s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 4.1275	Cost: 9.49s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 4.1424	Cost: 12.03s
Train Epoch: 370 	Average Loss: 4.3137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7267

Learning rate: 0.00019932518590423377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 5.7297	Cost: 33.81s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 4.1647	Cost: 9.51s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 4.1451	Cost: 12.63s
Train Epoch: 371 	Average Loss: 4.2914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5524

Learning rate: 0.00019932153746704794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 5.4780	Cost: 33.66s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 3.9997	Cost: 9.50s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 4.0494	Cost: 13.02s
Train Epoch: 372 	Average Loss: 4.2125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4622

Learning rate: 0.00019931787922721937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 5.6067	Cost: 32.96s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 3.9682	Cost: 9.48s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 3.9869	Cost: 13.32s
Train Epoch: 373 	Average Loss: 4.1898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5167

Learning rate: 0.00019931421118510906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 5.4157	Cost: 32.95s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 3.9733	Cost: 9.47s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 4.0734	Cost: 12.07s
Train Epoch: 374 	Average Loss: 4.1733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5196

Learning rate: 0.0001993105333410791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 5.5734	Cost: 32.72s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 3.9309	Cost: 9.51s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 4.0549	Cost: 13.15s
Train Epoch: 375 	Average Loss: 4.1365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5258

Learning rate: 0.00019930684569549248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 5.4012	Cost: 33.21s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 3.9406	Cost: 9.51s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 3.9207	Cost: 12.25s
Train Epoch: 376 	Average Loss: 4.1179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5001

Learning rate: 0.0001993031482487131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 5.4546	Cost: 33.15s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 3.8834	Cost: 9.54s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 4.1439	Cost: 12.42s
Train Epoch: 377 	Average Loss: 4.1747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6362

Learning rate: 0.0001992994410011059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 5.5670	Cost: 33.17s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 4.0870	Cost: 9.51s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 4.0631	Cost: 11.79s
Train Epoch: 378 	Average Loss: 4.2663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6184

Learning rate: 0.00019929572395303678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 5.4570	Cost: 33.57s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 3.9575	Cost: 9.51s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 3.9505	Cost: 12.53s
Train Epoch: 379 	Average Loss: 4.1817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6112

Learning rate: 0.0001992919971048726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 5.5850	Cost: 33.66s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 3.9327	Cost: 9.49s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 3.9176	Cost: 12.33s
Train Epoch: 380 	Average Loss: 4.1191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5901

Learning rate: 0.0001992882604569812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 5.4789	Cost: 32.58s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 3.8308	Cost: 9.50s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 3.9475	Cost: 12.23s
Train Epoch: 381 	Average Loss: 4.0550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4496

Learning rate: 0.00019928451400973133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 5.5375	Cost: 33.25s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 3.7388	Cost: 9.53s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 3.8183	Cost: 12.12s
Train Epoch: 382 	Average Loss: 3.9921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4004

Learning rate: 0.0001992807577634928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 5.3368	Cost: 33.17s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 3.7961	Cost: 9.53s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 3.7707	Cost: 12.91s
Train Epoch: 383 	Average Loss: 3.9583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4076

Learning rate: 0.00019927699171863632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 5.2548	Cost: 33.17s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 3.7788	Cost: 9.52s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 3.8515	Cost: 12.88s
Train Epoch: 384 	Average Loss: 3.9538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4128

Learning rate: 0.00019927321587553357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 5.2896	Cost: 33.94s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 3.7514	Cost: 9.51s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 3.8418	Cost: 12.65s
Train Epoch: 385 	Average Loss: 3.9275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4040

Learning rate: 0.00019926943023455717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 5.2899	Cost: 33.33s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 3.7177	Cost: 9.50s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 3.7390	Cost: 11.90s
Train Epoch: 386 	Average Loss: 3.9173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3354

Learning rate: 0.00019926563479608086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 5.3214	Cost: 32.94s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 3.6774	Cost: 9.61s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 3.7835	Cost: 12.06s
Train Epoch: 387 	Average Loss: 3.9287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3365

Learning rate: 0.00019926182956047912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 5.1048	Cost: 33.40s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 3.5901	Cost: 9.53s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 3.7221	Cost: 12.13s
Train Epoch: 388 	Average Loss: 3.8645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2695

Learning rate: 0.00019925801452812757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 5.2291	Cost: 33.18s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 3.5987	Cost: 9.53s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 3.7396	Cost: 12.20s
Train Epoch: 389 	Average Loss: 3.8406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
