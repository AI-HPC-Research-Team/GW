Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=4096, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=1.0, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_mixed_prior_transfered/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=500, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_mixed_prior_transfered/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Now, transfer learning from alpha=1.0!
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.2626	Cost: 33.22s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.6170	Cost: 9.46s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.7745	Cost: 11.93s
Train Epoch: 1 	Average Loss: 22.0400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9050

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.6534	Cost: 32.43s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 20.3324	Cost: 9.43s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 19.9864	Cost: 12.98s
Train Epoch: 2 	Average Loss: 20.2597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6987

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999998026079186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 19.8072	Cost: 33.71s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 19.2605	Cost: 10.28s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 18.6905	Cost: 11.56s
Train Epoch: 3 	Average Loss: 19.1822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6666

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019999995558678347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 18.5744	Cost: 33.11s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 18.4608	Cost: 9.44s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 17.8089	Cost: 12.05s
Train Epoch: 4 	Average Loss: 18.2484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0535

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.0001999999210431752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 17.8330	Cost: 32.60s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.5135	Cost: 10.11s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 17.1855	Cost: 11.64s
Train Epoch: 5 	Average Loss: 17.5150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4909

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019999987662997035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 17.1067	Cost: 33.01s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 16.9649	Cost: 9.42s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 16.6564	Cost: 12.18s
Train Epoch: 6 	Average Loss: 16.9079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8955

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019999982234717337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 16.6576	Cost: 33.60s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 16.4305	Cost: 9.54s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 16.2072	Cost: 12.13s
Train Epoch: 7 	Average Loss: 16.3788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3528

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 16.1322	Cost: 33.00s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 16.0216	Cost: 9.44s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 15.7103	Cost: 12.17s
Train Epoch: 8 	Average Loss: 15.9675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9044

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.0001999996841728254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 15.7868	Cost: 32.98s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 15.6827	Cost: 9.68s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 15.3990	Cost: 12.37s
Train Epoch: 9 	Average Loss: 15.6211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6029

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 15.4888	Cost: 33.44s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 15.2736	Cost: 9.54s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 15.1846	Cost: 12.45s
Train Epoch: 10 	Average Loss: 15.2592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2478

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019999950652018584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 15.2368	Cost: 33.28s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 15.0508	Cost: 10.38s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 14.8393	Cost: 12.16s
Train Epoch: 11 	Average Loss: 15.0255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9731

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019999940288952797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 14.8711	Cost: 33.48s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 14.9705	Cost: 10.13s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 14.7702	Cost: 12.03s
Train Epoch: 12 	Average Loss: 14.8083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7403

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019999928938932473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 14.5597	Cost: 32.26s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 14.6525	Cost: 9.43s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 14.4453	Cost: 12.25s
Train Epoch: 13 	Average Loss: 14.4978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4493

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.0001999991660195873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 14.4531	Cost: 33.88s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 14.4397	Cost: 10.12s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 14.1673	Cost: 11.72s
Train Epoch: 14 	Average Loss: 14.2975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2567

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 14.1732	Cost: 33.14s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 14.0471	Cost: 10.25s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 14.0442	Cost: 11.38s
Train Epoch: 15 	Average Loss: 14.0655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1265

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019999888967155963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 13.9357	Cost: 33.38s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 13.8975	Cost: 9.42s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 13.7973	Cost: 12.48s
Train Epoch: 16 	Average Loss: 13.8535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9811

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001999987366932966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 13.7684	Cost: 33.53s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 13.7456	Cost: 9.59s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 13.6454	Cost: 13.22s
Train Epoch: 17 	Average Loss: 13.6647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7518

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019999857384555393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 13.5987	Cost: 33.04s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 13.4805	Cost: 9.53s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 13.4315	Cost: 12.25s
Train Epoch: 18 	Average Loss: 13.4693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3829

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.0001999984011283477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 13.4042	Cost: 34.05s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 13.3465	Cost: 9.74s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 13.1163	Cost: 12.25s
Train Epoch: 19 	Average Loss: 13.3124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3744

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019999821854169497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 13.3054	Cost: 32.99s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 13.1447	Cost: 9.55s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 12.9826	Cost: 11.67s
Train Epoch: 20 	Average Loss: 13.1184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0517

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 12.9996	Cost: 33.33s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 12.8667	Cost: 9.51s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 12.8604	Cost: 12.45s
Train Epoch: 21 	Average Loss: 12.9362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8069

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 12.7972	Cost: 33.51s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 12.9152	Cost: 9.96s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 12.9533	Cost: 11.88s
Train Epoch: 22 	Average Loss: 12.8368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8621

Learning rate: 0.00019999761156524272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 12.7788	Cost: 33.35s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 12.8260	Cost: 9.58s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 12.6773	Cost: 12.88s
Train Epoch: 23 	Average Loss: 12.7529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6311

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 12.6376	Cost: 33.31s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 12.6798	Cost: 9.62s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 12.5258	Cost: 12.54s
Train Epoch: 24 	Average Loss: 12.6394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6219

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.00019999715756739833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 12.5576	Cost: 33.30s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 12.4460	Cost: 10.22s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 12.3824	Cost: 11.66s
Train Epoch: 25 	Average Loss: 12.4940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4676

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.000199996915764479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 12.4065	Cost: 33.24s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 12.2420	Cost: 9.58s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 12.3028	Cost: 12.64s
Train Epoch: 26 	Average Loss: 12.3449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4032

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019999666409225975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 12.3745	Cost: 33.14s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 12.2158	Cost: 9.60s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 12.3508	Cost: 11.56s
Train Epoch: 27 	Average Loss: 12.2952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2694

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019999640255076543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 12.2372	Cost: 32.99s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 12.1834	Cost: 9.49s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 12.0931	Cost: 11.98s
Train Epoch: 28 	Average Loss: 12.1205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2392

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019999613114002186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 12.2680	Cost: 33.36s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 12.0467	Cost: 9.58s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 12.0199	Cost: 11.84s
Train Epoch: 29 	Average Loss: 12.1185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1008

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.0001999958498600558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 11.9728	Cost: 32.89s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 12.0162	Cost: 9.59s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 11.9619	Cost: 11.64s
Train Epoch: 30 	Average Loss: 11.9369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0678

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.000199995558710895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 11.8804	Cost: 33.27s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 11.8935	Cost: 10.25s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 11.9240	Cost: 11.98s
Train Epoch: 31 	Average Loss: 11.8958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9210

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 0.00019999525769256825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 11.8966	Cost: 33.12s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 11.8191	Cost: 9.55s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 11.8602	Cost: 11.82s
Train Epoch: 32 	Average Loss: 11.7887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9574

Learning rate: 0.00019999494680510518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 11.9258	Cost: 33.44s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 11.7747	Cost: 9.56s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 11.7308	Cost: 12.10s
Train Epoch: 33 	Average Loss: 11.7580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8649

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019999462604853658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 11.7723	Cost: 32.88s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 11.7016	Cost: 9.50s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 11.5851	Cost: 12.36s
Train Epoch: 34 	Average Loss: 11.6604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6471

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019999429542289402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 11.5902	Cost: 33.08s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 11.6519	Cost: 10.27s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 11.6029	Cost: 12.39s
Train Epoch: 35 	Average Loss: 11.5286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5420

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.00019999395492821016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 11.5466	Cost: 33.54s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 11.4984	Cost: 9.51s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 11.5309	Cost: 12.31s
Train Epoch: 36 	Average Loss: 11.5038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5062

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.0001999936045645186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 11.3915	Cost: 33.11s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 11.3237	Cost: 9.58s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 11.3619	Cost: 12.93s
Train Epoch: 37 	Average Loss: 11.4047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3977

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.00019999324433185394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 11.3799	Cost: 33.05s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 11.3500	Cost: 10.23s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 11.2327	Cost: 11.91s
Train Epoch: 38 	Average Loss: 11.3580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4383

Learning rate: 0.0001999928742302517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 11.4174	Cost: 33.66s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 11.2249	Cost: 9.58s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 11.2856	Cost: 13.18s
Train Epoch: 39 	Average Loss: 11.2925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2541

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019999249425974844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 11.2223	Cost: 33.11s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 11.2739	Cost: 10.21s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 11.1733	Cost: 11.87s
Train Epoch: 40 	Average Loss: 11.2107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2507

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 11.3092	Cost: 32.47s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 11.2704	Cost: 9.63s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 11.1423	Cost: 12.18s
Train Epoch: 41 	Average Loss: 11.1773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1722

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019999170471218976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 11.0898	Cost: 34.12s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 11.1434	Cost: 9.62s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 11.0825	Cost: 12.72s
Train Epoch: 42 	Average Loss: 11.1176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1433

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.0001999912951352123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 11.1391	Cost: 33.67s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 11.1388	Cost: 9.62s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 11.0227	Cost: 11.81s
Train Epoch: 43 	Average Loss: 11.0398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8988

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.00019999087568948966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 10.8380	Cost: 33.88s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 10.9370	Cost: 9.44s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 11.0187	Cost: 12.75s
Train Epoch: 44 	Average Loss: 10.9303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0927

Learning rate: 0.0001999904463750632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 11.0719	Cost: 33.47s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 10.9848	Cost: 9.44s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 10.8783	Cost: 12.20s
Train Epoch: 45 	Average Loss: 10.9184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8793

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019999000719197536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 10.9402	Cost: 33.79s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 10.9002	Cost: 9.44s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 10.9204	Cost: 12.90s
Train Epoch: 46 	Average Loss: 10.8557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9139

Learning rate: 0.00019998955814026943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 10.8837	Cost: 33.48s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 10.7177	Cost: 10.08s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 10.8321	Cost: 11.50s
Train Epoch: 47 	Average Loss: 10.8146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8589

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 0.00019998909921998973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 10.8400	Cost: 34.08s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 10.8668	Cost: 9.49s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 10.7985	Cost: 12.73s
Train Epoch: 48 	Average Loss: 10.8092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9003

Learning rate: 0.0001999886304311816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 10.9150	Cost: 33.38s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 10.7973	Cost: 9.51s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 10.6644	Cost: 12.46s
Train Epoch: 49 	Average Loss: 10.7635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8195

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019998815177389132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 10.7682	Cost: 33.98s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 10.6759	Cost: 9.52s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 10.6784	Cost: 12.56s
Train Epoch: 50 	Average Loss: 10.6697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7851

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 10.5645	Cost: 33.38s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 10.6940	Cost: 9.63s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 10.8487	Cost: 12.51s
Train Epoch: 51 	Average Loss: 10.7250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6929

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019998716485405404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 10.5514	Cost: 33.03s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 10.5656	Cost: 9.62s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 10.5517	Cost: 12.97s
Train Epoch: 52 	Average Loss: 10.5610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6803

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 0.0001999866565916045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 10.6159	Cost: 33.14s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 10.6110	Cost: 9.71s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 10.5385	Cost: 11.85s
Train Epoch: 53 	Average Loss: 10.5870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5201

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 0.0001999861384608676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 10.5101	Cost: 33.56s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 10.4540	Cost: 9.51s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 10.4357	Cost: 12.29s
Train Epoch: 54 	Average Loss: 10.4700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5383

Learning rate: 0.00019998561046189446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 10.4369	Cost: 33.63s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 10.4266	Cost: 9.57s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 10.4696	Cost: 12.48s
Train Epoch: 55 	Average Loss: 10.4637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5076

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.00019998507259473718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 10.4309	Cost: 33.67s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 10.2858	Cost: 9.51s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 10.4367	Cost: 12.73s
Train Epoch: 56 	Average Loss: 10.4050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3997

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019998452485944885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 10.4001	Cost: 32.51s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 10.3741	Cost: 9.50s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 10.4183	Cost: 12.91s
Train Epoch: 57 	Average Loss: 10.3610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3424

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 0.00019998396725608354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 10.4325	Cost: 33.56s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 10.3683	Cost: 9.80s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 10.2859	Cost: 11.82s
Train Epoch: 58 	Average Loss: 10.3089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3198

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 10.3067	Cost: 32.71s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 10.3574	Cost: 9.52s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 10.3610	Cost: 11.85s
Train Epoch: 59 	Average Loss: 10.2840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3079

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 10.3541	Cost: 33.43s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 10.3883	Cost: 9.76s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 10.3669	Cost: 12.47s
Train Epoch: 60 	Average Loss: 10.2628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2561

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 10.2700	Cost: 32.64s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 10.3068	Cost: 9.50s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 10.1707	Cost: 12.20s
Train Epoch: 61 	Average Loss: 10.2248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2388

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 10.1114	Cost: 33.00s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 10.2065	Cost: 9.53s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 10.1549	Cost: 12.43s
Train Epoch: 62 	Average Loss: 10.1333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1876

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019998103122006246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 10.0402	Cost: 33.12s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 10.1602	Cost: 9.53s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 10.2178	Cost: 12.78s
Train Epoch: 63 	Average Loss: 10.1089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1334

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 0.00019998041440942506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 10.2075	Cost: 33.91s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 10.2389	Cost: 9.60s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 10.1703	Cost: 12.08s
Train Epoch: 64 	Average Loss: 10.0923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1167

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00019997978773111632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 10.0989	Cost: 32.81s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 10.1169	Cost: 9.95s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 10.0714	Cost: 12.18s
Train Epoch: 65 	Average Loss: 10.0566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1549

Learning rate: 0.00019997915118519813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 10.1359	Cost: 33.36s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 10.1292	Cost: 9.53s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 10.0025	Cost: 12.76s
Train Epoch: 66 	Average Loss: 10.0102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0237

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.0001999785047717333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 10.0397	Cost: 33.35s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 10.0735	Cost: 9.60s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 10.1498	Cost: 12.59s
Train Epoch: 67 	Average Loss: 10.0124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0852

Learning rate: 0.00019997784849078566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 10.0810	Cost: 33.13s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 10.0315	Cost: 9.50s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 9.9479	Cost: 12.45s
Train Epoch: 68 	Average Loss: 9.9362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0312

Learning rate: 0.00019997718234242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 9.9888	Cost: 33.98s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 10.0565	Cost: 9.56s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 9.9581	Cost: 12.83s
Train Epoch: 69 	Average Loss: 9.9497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9685

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Learning rate: 0.00019997650632670199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 10.0043	Cost: 33.30s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 9.8668	Cost: 9.92s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 9.8786	Cost: 11.79s
Train Epoch: 70 	Average Loss: 9.8975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0671

Learning rate: 0.0001999758204436984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 10.0089	Cost: 33.25s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 9.9028	Cost: 9.57s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 9.8496	Cost: 12.46s
Train Epoch: 71 	Average Loss: 9.8548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8895

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00019997512469347695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 9.9382	Cost: 33.11s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 9.9165	Cost: 9.49s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 9.8380	Cost: 12.38s
Train Epoch: 72 	Average Loss: 9.8546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9324

Learning rate: 0.00019997441907610624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 9.9183	Cost: 32.89s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 9.8493	Cost: 9.62s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 9.7811	Cost: 12.79s
Train Epoch: 73 	Average Loss: 9.8011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8668

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Learning rate: 0.00019997370359165596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 9.8349	Cost: 33.06s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 9.6818	Cost: 9.65s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 9.7147	Cost: 12.70s
Train Epoch: 74 	Average Loss: 9.7224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8002

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.0001999729782401967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 9.6735	Cost: 33.50s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 9.7393	Cost: 9.62s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 9.7290	Cost: 12.47s
Train Epoch: 75 	Average Loss: 9.7506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9160

Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 9.8495	Cost: 33.83s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 9.7407	Cost: 9.60s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 9.6930	Cost: 12.17s
Train Epoch: 76 	Average Loss: 9.7381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7367

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00019997149793653861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 9.6991	Cost: 33.51s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 9.5967	Cost: 9.61s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 9.5859	Cost: 12.49s
Train Epoch: 77 	Average Loss: 9.6624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7041

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Learning rate: 0.00019997074298448586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 9.7416	Cost: 32.88s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 9.6448	Cost: 10.10s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 9.6992	Cost: 11.45s
Train Epoch: 78 	Average Loss: 9.6486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6115

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Learning rate: 0.00019996997816571638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 9.6664	Cost: 33.91s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 9.7488	Cost: 9.41s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 9.6245	Cost: 12.66s
Train Epoch: 79 	Average Loss: 9.6151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6809

Learning rate: 0.00019996920348030559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 9.7299	Cost: 33.83s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 9.6589	Cost: 9.47s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 9.6417	Cost: 12.80s
Train Epoch: 80 	Average Loss: 9.6119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6566

Learning rate: 0.00019996841892832998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 9.6402	Cost: 33.94s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 9.7021	Cost: 10.09s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 9.5957	Cost: 12.20s
Train Epoch: 81 	Average Loss: 9.5781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5177

Saving model as e81_model.pt & e81_waveforms_supplementary.hdf5
Learning rate: 0.00019996762450986697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 9.5574	Cost: 33.62s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 9.5750	Cost: 10.25s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 9.5736	Cost: 12.18s
Train Epoch: 82 	Average Loss: 9.5346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5345

Learning rate: 0.00019996682022499498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 9.6280	Cost: 32.87s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 9.5178	Cost: 9.86s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 9.4743	Cost: 11.96s
Train Epoch: 83 	Average Loss: 9.5048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5265

Learning rate: 0.0001999660060737934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 9.5067	Cost: 33.54s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 9.4955	Cost: 9.71s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 9.5445	Cost: 12.26s
Train Epoch: 84 	Average Loss: 9.4759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5944

Learning rate: 0.00019996518205634255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 9.5975	Cost: 33.32s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 9.5332	Cost: 9.77s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 9.4753	Cost: 11.56s
Train Epoch: 85 	Average Loss: 9.4527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4701

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Learning rate: 0.0001999643481727238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 9.5848	Cost: 34.32s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 9.3928	Cost: 9.56s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 9.3869	Cost: 12.76s
Train Epoch: 86 	Average Loss: 9.4157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7216

Learning rate: 0.0001999635044230194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 9.4827	Cost: 33.06s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 9.5399	Cost: 9.52s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 9.4295	Cost: 12.49s
Train Epoch: 87 	Average Loss: 9.4530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5310

Learning rate: 0.00019996265080731267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 9.6621	Cost: 32.95s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 9.4203	Cost: 9.60s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 9.3575	Cost: 12.53s
Train Epoch: 88 	Average Loss: 9.3969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4120

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 0.00019996178732568782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 9.3374	Cost: 32.52s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 9.3675	Cost: 9.49s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 9.4253	Cost: 12.82s
Train Epoch: 89 	Average Loss: 9.3586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4567

Learning rate: 0.00019996091397823007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 9.4048	Cost: 33.45s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 9.3489	Cost: 10.06s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 9.3163	Cost: 11.47s
Train Epoch: 90 	Average Loss: 9.3092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4306

Learning rate: 0.00019996003076502562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 9.5208	Cost: 34.03s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 9.4196	Cost: 9.53s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 9.4339	Cost: 12.89s
Train Epoch: 91 	Average Loss: 9.3401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4313

Learning rate: 0.0001999591376861617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 9.4057	Cost: 33.60s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 9.3112	Cost: 9.56s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 9.3298	Cost: 12.39s
Train Epoch: 92 	Average Loss: 9.3062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3633

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 0.0001999582347417264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 9.4237	Cost: 33.07s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 9.3855	Cost: 9.55s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 9.2527	Cost: 12.76s
Train Epoch: 93 	Average Loss: 9.2953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2635

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 0.00019995732193180883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 9.2132	Cost: 33.55s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 9.2549	Cost: 10.12s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 9.3032	Cost: 11.83s
Train Epoch: 94 	Average Loss: 9.2482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3005

Learning rate: 0.00019995639925649909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 9.3542	Cost: 33.87s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 9.2778	Cost: 9.57s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 9.3841	Cost: 12.56s
Train Epoch: 95 	Average Loss: 9.2629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3270

Learning rate: 0.00019995546671588827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 9.3208	Cost: 33.49s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 9.3055	Cost: 9.55s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 9.3458	Cost: 12.40s
Train Epoch: 96 	Average Loss: 9.2423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3852

Learning rate: 0.0001999545243100684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 9.2749	Cost: 33.57s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 9.3247	Cost: 9.55s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 9.2545	Cost: 12.65s
Train Epoch: 97 	Average Loss: 9.2798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3823

Learning rate: 0.00019995357203913245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 9.3327	Cost: 33.43s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 9.2394	Cost: 10.21s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 9.2344	Cost: 12.30s
Train Epoch: 98 	Average Loss: 9.2117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3234

Learning rate: 0.00019995260990317447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 9.3684	Cost: 33.96s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 9.1416	Cost: 10.09s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 9.2962	Cost: 11.84s
Train Epoch: 99 	Average Loss: 9.1910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1831

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Learning rate: 0.00019995163790228936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 9.2121	Cost: 33.31s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 9.1543	Cost: 9.46s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 9.1672	Cost: 12.47s
Train Epoch: 100 	Average Loss: 9.1282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2752

Learning rate: 0.0001999506560365731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 9.2405	Cost: 33.62s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 9.1873	Cost: 9.65s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 9.2309	Cost: 12.47s
Train Epoch: 101 	Average Loss: 9.1534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2342

Learning rate: 0.00019994966430612258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 9.2796	Cost: 32.84s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 9.1390	Cost: 9.63s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 9.1664	Cost: 12.39s
Train Epoch: 102 	Average Loss: 9.1489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1356

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00019994866271103568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 9.2535	Cost: 33.61s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 9.0955	Cost: 9.64s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 9.1692	Cost: 12.75s
Train Epoch: 103 	Average Loss: 9.0764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1425

Learning rate: 0.0001999476512514112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 9.1591	Cost: 34.14s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 9.0610	Cost: 9.62s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 9.0204	Cost: 12.50s
Train Epoch: 104 	Average Loss: 9.0356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1468

Learning rate: 0.00019994662992734905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 9.1798	Cost: 33.29s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 9.1115	Cost: 10.11s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 9.0328	Cost: 11.36s
Train Epoch: 105 	Average Loss: 9.0806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1804

Learning rate: 0.00019994559873894998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 9.1437	Cost: 33.52s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 9.0430	Cost: 9.42s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 9.1590	Cost: 12.69s
Train Epoch: 106 	Average Loss: 9.0584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2050

Learning rate: 0.00019994455768631577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 9.1205	Cost: 32.71s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 9.0869	Cost: 9.50s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 9.0077	Cost: 12.27s
Train Epoch: 107 	Average Loss: 9.0580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1515

Learning rate: 0.00019994350676954918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 9.2066	Cost: 33.45s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 9.0712	Cost: 9.45s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 9.0174	Cost: 12.77s
Train Epoch: 108 	Average Loss: 9.0289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1153

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Learning rate: 0.00019994244598875392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 9.1302	Cost: 33.55s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 9.1842	Cost: 9.67s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 9.1480	Cost: 11.84s
Train Epoch: 109 	Average Loss: 9.0409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1269

Learning rate: 0.00019994137534403472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 9.0919	Cost: 33.14s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 9.1695	Cost: 9.61s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 8.9680	Cost: 12.58s
Train Epoch: 110 	Average Loss: 9.0154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0909

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 0.00019994029483549723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 9.0769	Cost: 33.53s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 9.0718	Cost: 9.63s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 8.9719	Cost: 12.22s
Train Epoch: 111 	Average Loss: 8.9702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0929

Learning rate: 0.00019993920446324803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 9.0805	Cost: 33.17s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 9.0457	Cost: 9.42s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 8.9437	Cost: 12.19s
Train Epoch: 112 	Average Loss: 8.9722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0853

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Learning rate: 0.00019993810422739487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 9.1746	Cost: 33.81s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 8.9183	Cost: 9.43s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 8.9797	Cost: 12.13s
Train Epoch: 113 	Average Loss: 8.9543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0115

Saving model as e113_model.pt & e113_waveforms_supplementary.hdf5
Learning rate: 0.00019993699412804622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 9.0077	Cost: 34.40s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 8.8536	Cost: 9.56s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 8.9160	Cost: 12.90s
Train Epoch: 114 	Average Loss: 8.9045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9890

Saving model as e114_model.pt & e114_waveforms_supplementary.hdf5
Learning rate: 0.00019993587416531166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 8.9299	Cost: 33.05s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 8.8986	Cost: 10.18s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 8.8489	Cost: 11.51s
Train Epoch: 115 	Average Loss: 8.8624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0256

Learning rate: 0.00019993474433930176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 8.9525	Cost: 33.05s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 8.8722	Cost: 9.58s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 8.9939	Cost: 11.87s
Train Epoch: 116 	Average Loss: 8.8999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0190

Learning rate: 0.000199933604650128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 9.0378	Cost: 32.85s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 8.8069	Cost: 9.46s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 8.7987	Cost: 11.97s
Train Epoch: 117 	Average Loss: 8.8370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8967

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 0.0001999324550979029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 8.8592	Cost: 33.51s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 8.9064	Cost: 10.24s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 8.7368	Cost: 11.92s
Train Epoch: 118 	Average Loss: 8.8089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8605

Saving model as e118_model.pt & e118_waveforms_supplementary.hdf5
Learning rate: 0.00019993129568273988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 8.8901	Cost: 33.17s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 8.8484	Cost: 9.58s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 8.8625	Cost: 12.94s
Train Epoch: 119 	Average Loss: 8.8223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9475

Learning rate: 0.0001999301264047534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 8.9249	Cost: 33.56s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 8.7995	Cost: 9.62s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 8.8958	Cost: 12.66s
Train Epoch: 120 	Average Loss: 8.8275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9242

Learning rate: 0.00019992894726405882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 8.9112	Cost: 32.99s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 8.8247	Cost: 9.60s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 8.7426	Cost: 12.59s
Train Epoch: 121 	Average Loss: 8.7751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9025

Learning rate: 0.00019992775826077256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 8.8943	Cost: 32.86s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 8.8371	Cost: 9.60s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 8.7513	Cost: 12.72s
Train Epoch: 122 	Average Loss: 8.7705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8724

Learning rate: 0.00019992655939501196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 8.7869	Cost: 33.43s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 8.7729	Cost: 9.84s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 8.8020	Cost: 12.14s
Train Epoch: 123 	Average Loss: 8.7602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8979

Learning rate: 0.00019992535066689534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 8.8967	Cost: 32.81s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 8.7526	Cost: 9.62s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 8.7659	Cost: 12.46s
Train Epoch: 124 	Average Loss: 8.7406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8261

Saving model as e124_model.pt & e124_waveforms_supplementary.hdf5
Learning rate: 0.00019992413207654198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 8.8912	Cost: 32.90s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 8.6559	Cost: 9.76s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 8.6764	Cost: 12.73s
Train Epoch: 125 	Average Loss: 8.7010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7454

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 8.7763	Cost: 33.84s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 8.6604	Cost: 9.59s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 8.7609	Cost: 13.15s
Train Epoch: 126 	Average Loss: 8.6993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8905

Learning rate: 0.0001999216653096072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 8.9073	Cost: 33.91s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 8.7460	Cost: 9.55s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 8.7917	Cost: 12.47s
Train Epoch: 127 	Average Loss: 8.7102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8756

Learning rate: 0.00019992041713326917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 8.7892	Cost: 33.69s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 8.7650	Cost: 9.51s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 8.7437	Cost: 12.88s
Train Epoch: 128 	Average Loss: 8.7008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8652

Learning rate: 0.00019991915909518135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 8.7733	Cost: 34.17s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 8.6344	Cost: 10.16s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 8.6955	Cost: 11.57s
Train Epoch: 129 	Average Loss: 8.6407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7017

Saving model as e129_model.pt & e129_waveforms_supplementary.hdf5
Learning rate: 0.0001999178911954679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 8.8371	Cost: 32.61s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 8.6406	Cost: 9.49s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 8.6668	Cost: 12.64s
Train Epoch: 130 	Average Loss: 8.6386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7392

Learning rate: 0.0001999166134342539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 8.6955	Cost: 34.28s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 8.6619	Cost: 9.62s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 8.5678	Cost: 12.72s
Train Epoch: 131 	Average Loss: 8.6180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7595

Learning rate: 0.00019991532581166554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 8.7334	Cost: 32.96s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 8.7420	Cost: 9.61s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 8.6070	Cost: 12.05s
Train Epoch: 132 	Average Loss: 8.6244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7246

Learning rate: 0.00019991402832782987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 8.7062	Cost: 33.87s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 8.5536	Cost: 9.64s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 8.6413	Cost: 12.32s
Train Epoch: 133 	Average Loss: 8.5845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7984

Learning rate: 0.00019991272098287494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 8.8648	Cost: 32.89s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 8.6463	Cost: 9.54s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 8.5950	Cost: 11.89s
Train Epoch: 134 	Average Loss: 8.5808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6413

Saving model as e134_model.pt & e134_waveforms_supplementary.hdf5
Learning rate: 0.00019991140377692977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 8.7228	Cost: 34.16s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 8.5972	Cost: 10.10s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 8.5229	Cost: 12.06s
Train Epoch: 135 	Average Loss: 8.5520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6381

Saving model as e135_model.pt & e135_waveforms_supplementary.hdf5
Learning rate: 0.0001999100767101244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 8.6404	Cost: 33.90s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 8.6013	Cost: 9.42s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 8.5664	Cost: 12.17s
Train Epoch: 136 	Average Loss: 8.5372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7182

Learning rate: 0.00019990873978258976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 8.7069	Cost: 33.10s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 8.5057	Cost: 9.62s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 8.5122	Cost: 11.81s
Train Epoch: 137 	Average Loss: 8.5386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6276

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 0.0001999073929944578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 8.5402	Cost: 33.84s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 8.5282	Cost: 9.65s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 8.6089	Cost: 12.89s
Train Epoch: 138 	Average Loss: 8.4992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6599

Learning rate: 0.00019990603634586154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 8.6569	Cost: 33.87s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 8.6432	Cost: 9.63s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 8.4720	Cost: 12.77s
Train Epoch: 139 	Average Loss: 8.5130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6716

Learning rate: 0.00019990466983693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 8.6597	Cost: 33.79s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 8.4691	Cost: 9.65s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 8.4652	Cost: 12.32s
Train Epoch: 140 	Average Loss: 8.4700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5860

Saving model as e140_model.pt & e140_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 8.6810	Cost: 32.60s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 8.4358	Cost: 10.12s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 8.4941	Cost: 11.73s
Train Epoch: 141 	Average Loss: 8.4670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6129

Learning rate: 0.00019990190723863022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 8.5118	Cost: 32.55s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 8.4714	Cost: 10.09s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 8.4017	Cost: 11.79s
Train Epoch: 142 	Average Loss: 8.4567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5455

Saving model as e142_model.pt & e142_waveforms_supplementary.hdf5
Learning rate: 0.00019990051114952508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 8.4905	Cost: 33.02s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 8.4416	Cost: 9.41s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 8.4651	Cost: 11.91s
Train Epoch: 143 	Average Loss: 8.4167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5519

Learning rate: 0.0001998991052006348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 8.5475	Cost: 33.51s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 8.4330	Cost: 9.43s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 8.3526	Cost: 13.13s
Train Epoch: 144 	Average Loss: 8.3782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5306

Saving model as e144_model.pt & e144_waveforms_supplementary.hdf5
Learning rate: 0.0001998976893920981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 8.5792	Cost: 33.45s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 8.4449	Cost: 9.37s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 8.3174	Cost: 12.65s
Train Epoch: 145 	Average Loss: 8.3887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5582

Learning rate: 0.00019989626372405477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 8.5878	Cost: 32.82s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 8.4478	Cost: 9.43s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 8.4149	Cost: 12.54s
Train Epoch: 146 	Average Loss: 8.3902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5231

Saving model as e146_model.pt & e146_waveforms_supplementary.hdf5
Learning rate: 0.00019989482819664545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 8.5952	Cost: 33.60s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 8.4159	Cost: 9.63s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 8.3604	Cost: 11.84s
Train Epoch: 147 	Average Loss: 8.3653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5168

Saving model as e147_model.pt & e147_waveforms_supplementary.hdf5
Learning rate: 0.00019989338281001189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 8.5501	Cost: 32.92s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 8.3825	Cost: 9.79s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 8.3872	Cost: 11.84s
Train Epoch: 148 	Average Loss: 8.3773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5107

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 0.00019989192756429667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 8.4733	Cost: 33.70s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 8.3141	Cost: 10.11s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 8.4244	Cost: 12.02s
Train Epoch: 149 	Average Loss: 8.3317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5149

Learning rate: 0.00019989046245964345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 8.4492	Cost: 33.61s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 8.3219	Cost: 10.27s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 8.4134	Cost: 11.80s
Train Epoch: 150 	Average Loss: 8.3437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5543

Learning rate: 0.00019988898749619688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 8.5357	Cost: 33.52s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 8.3912	Cost: 9.63s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 8.3336	Cost: 12.15s
Train Epoch: 151 	Average Loss: 8.3355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4980

Saving model as e151_model.pt & e151_waveforms_supplementary.hdf5
Learning rate: 0.00019988750267410245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 8.5238	Cost: 33.33s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 8.3119	Cost: 9.62s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 8.3533	Cost: 11.84s
Train Epoch: 152 	Average Loss: 8.2959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4685

Saving model as e152_model.pt & e152_waveforms_supplementary.hdf5
Learning rate: 0.0001998860079935067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 8.4064	Cost: 34.03s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 8.2885	Cost: 9.63s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 8.2985	Cost: 12.65s
Train Epoch: 153 	Average Loss: 8.2794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4495

Saving model as e153_model.pt & e153_waveforms_supplementary.hdf5
Learning rate: 0.00019988450345455726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 8.3622	Cost: 33.42s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 8.2969	Cost: 9.58s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 8.2929	Cost: 12.38s
Train Epoch: 154 	Average Loss: 8.2549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4404

Saving model as e154_model.pt & e154_waveforms_supplementary.hdf5
Learning rate: 0.00019988298905740252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 8.4351	Cost: 33.37s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 8.2833	Cost: 9.52s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 8.3339	Cost: 12.89s
Train Epoch: 155 	Average Loss: 8.2757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4141

Saving model as e155_model.pt & e155_waveforms_supplementary.hdf5
Learning rate: 0.000199881464802192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 8.4894	Cost: 33.36s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 8.2625	Cost: 9.57s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 8.1831	Cost: 12.78s
Train Epoch: 156 	Average Loss: 8.2484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4422

Learning rate: 0.0001998799306890761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 8.4288	Cost: 33.33s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 8.2303	Cost: 9.49s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 8.3073	Cost: 12.91s
Train Epoch: 157 	Average Loss: 8.2745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4366

Learning rate: 0.00019987838671820622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 8.4926	Cost: 33.20s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 8.1586	Cost: 10.20s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 8.1567	Cost: 12.12s
Train Epoch: 158 	Average Loss: 8.1937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3137

Saving model as e158_model.pt & e158_waveforms_supplementary.hdf5
Learning rate: 0.00019987683288973478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 8.4803	Cost: 33.09s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 8.2017	Cost: 9.50s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 8.2162	Cost: 13.01s
Train Epoch: 159 	Average Loss: 8.2164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4123

Learning rate: 0.00019987526920381513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 8.3925	Cost: 33.47s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 8.1475	Cost: 9.50s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 8.1843	Cost: 12.55s
Train Epoch: 160 	Average Loss: 8.2066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3947

Learning rate: 0.00019987369566060162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 8.4632	Cost: 33.15s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 8.1685	Cost: 9.49s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 8.0928	Cost: 12.43s
Train Epoch: 161 	Average Loss: 8.1652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2947

Saving model as e161_model.pt & e161_waveforms_supplementary.hdf5
Learning rate: 0.0001998721122602495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 8.4000	Cost: 33.53s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 8.1281	Cost: 9.61s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 8.1172	Cost: 12.53s
Train Epoch: 162 	Average Loss: 8.1494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4329

Learning rate: 0.00019987051900291508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 8.3307	Cost: 33.01s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 8.0992	Cost: 10.19s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 8.0952	Cost: 11.45s
Train Epoch: 163 	Average Loss: 8.1186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3463

Learning rate: 0.00019986891588875562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 8.2778	Cost: 33.97s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 8.0949	Cost: 9.53s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 8.0765	Cost: 12.35s
Train Epoch: 164 	Average Loss: 8.1374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3666

Learning rate: 0.0001998673029179293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 8.4031	Cost: 33.93s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 8.1058	Cost: 9.53s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 8.1380	Cost: 12.63s
Train Epoch: 165 	Average Loss: 8.1380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3869

Learning rate: 0.00019986568009059536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 8.3233	Cost: 33.23s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 8.1977	Cost: 9.50s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 8.0686	Cost: 12.36s
Train Epoch: 166 	Average Loss: 8.0963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3183

Learning rate: 0.00019986404740691393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 8.1968	Cost: 32.94s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 8.0478	Cost: 10.25s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 8.1034	Cost: 11.37s
Train Epoch: 167 	Average Loss: 8.0672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3230

Learning rate: 0.00019986240486704617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 8.3369	Cost: 33.94s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 8.0839	Cost: 9.56s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 8.0411	Cost: 12.51s
Train Epoch: 168 	Average Loss: 8.0832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2980

Learning rate: 0.00019986075247115415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 8.2798	Cost: 33.30s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 8.1157	Cost: 9.52s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 8.0509	Cost: 12.56s
Train Epoch: 169 	Average Loss: 8.0381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3156

Learning rate: 0.00019985909021940103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 8.2708	Cost: 34.68s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 8.0160	Cost: 10.00s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 8.0416	Cost: 12.02s
Train Epoch: 170 	Average Loss: 8.0535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1995

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 0.0001998574181119508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 8.1801	Cost: 33.53s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 8.0717	Cost: 9.54s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 8.0347	Cost: 11.90s
Train Epoch: 171 	Average Loss: 8.0199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2492

Learning rate: 0.00019985573614896853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 8.1968	Cost: 33.47s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 7.9048	Cost: 9.52s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 7.9723	Cost: 12.33s
Train Epoch: 172 	Average Loss: 8.0295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2670

Learning rate: 0.00019985404433062024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 8.3114	Cost: 33.34s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 8.0863	Cost: 9.54s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 8.0457	Cost: 12.88s
Train Epoch: 173 	Average Loss: 8.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1849

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 0.00019985234265707287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 8.2760	Cost: 33.79s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 7.9587	Cost: 9.52s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 8.0239	Cost: 12.80s
Train Epoch: 174 	Average Loss: 7.9560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2181

Learning rate: 0.00019985063112849436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 8.1455	Cost: 34.49s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 8.0549	Cost: 9.52s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 7.9726	Cost: 12.82s
Train Epoch: 175 	Average Loss: 7.9602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1626

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 8.0988	Cost: 33.91s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 7.9444	Cost: 9.55s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 7.9578	Cost: 12.60s
Train Epoch: 176 	Average Loss: 7.9261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1527

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Learning rate: 0.00019984717850692066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 8.1912	Cost: 33.49s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 7.9806	Cost: 10.13s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 8.0240	Cost: 12.32s
Train Epoch: 177 	Average Loss: 7.9219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1567

Learning rate: 0.00019984543741426617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 8.1083	Cost: 33.46s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 7.8931	Cost: 9.54s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 7.9077	Cost: 12.76s
Train Epoch: 178 	Average Loss: 7.9102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1984

Learning rate: 0.0001998436864672621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 8.2307	Cost: 32.92s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 7.8786	Cost: 9.64s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 7.9025	Cost: 12.67s
Train Epoch: 179 	Average Loss: 7.8939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1143

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Learning rate: 0.00019984192566608125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 8.1685	Cost: 33.12s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 7.9132	Cost: 9.56s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 7.8932	Cost: 12.27s
Train Epoch: 180 	Average Loss: 7.8768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1241

Learning rate: 0.00019984015501089739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 8.0748	Cost: 32.70s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 7.8978	Cost: 10.12s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 7.8898	Cost: 12.46s
Train Epoch: 181 	Average Loss: 7.8831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0920

Saving model as e181_model.pt & e181_waveforms_supplementary.hdf5
Learning rate: 0.00019983837450188524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 8.1172	Cost: 33.34s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 7.8384	Cost: 9.50s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 7.8735	Cost: 12.89s
Train Epoch: 182 	Average Loss: 7.8572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1813

Learning rate: 0.0001998365841392206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 8.1925	Cost: 33.86s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 7.9327	Cost: 10.09s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 7.7728	Cost: 11.96s
Train Epoch: 183 	Average Loss: 7.8460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1382

Learning rate: 0.00019983478392308012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 8.1497	Cost: 33.96s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 7.7398	Cost: 9.59s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 7.8397	Cost: 12.11s
Train Epoch: 184 	Average Loss: 7.8147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1901

Learning rate: 0.0001998329738536415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 8.1416	Cost: 33.54s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 7.7311	Cost: 9.43s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 7.8281	Cost: 12.66s
Train Epoch: 185 	Average Loss: 7.8075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0915

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Learning rate: 0.00019983115393108338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 8.1001	Cost: 32.96s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 7.8237	Cost: 9.63s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 7.7751	Cost: 11.91s
Train Epoch: 186 	Average Loss: 7.7876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0466

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Learning rate: 0.0001998293241555854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 8.0503	Cost: 33.59s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 7.8051	Cost: 10.24s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 7.7877	Cost: 11.97s
Train Epoch: 187 	Average Loss: 7.7686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9743

Saving model as e187_model.pt & e187_waveforms_supplementary.hdf5
Learning rate: 0.0001998274845273281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 7.9683	Cost: 32.99s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 7.7459	Cost: 9.42s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 7.7319	Cost: 12.11s
Train Epoch: 188 	Average Loss: 7.7521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0015

Learning rate: 0.00019982563504649309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 8.1050	Cost: 33.11s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 7.7570	Cost: 9.44s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 7.6913	Cost: 12.59s
Train Epoch: 189 	Average Loss: 7.7340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0127

Learning rate: 0.00019982377571326284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 8.0011	Cost: 33.64s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 7.7269	Cost: 9.44s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 7.6894	Cost: 12.85s
Train Epoch: 190 	Average Loss: 7.7057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9561

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 0.00019982190652782097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 8.0063	Cost: 33.09s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 7.8816	Cost: 9.45s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 7.6745	Cost: 11.96s
Train Epoch: 191 	Average Loss: 7.7487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0034

Learning rate: 0.0001998200274903519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 8.0165	Cost: 33.35s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 7.7870	Cost: 9.42s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 7.6755	Cost: 12.24s
Train Epoch: 192 	Average Loss: 7.7243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0183

Learning rate: 0.00019981813860104106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 7.9701	Cost: 34.24s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 7.5994	Cost: 9.56s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 7.6758	Cost: 12.59s
Train Epoch: 193 	Average Loss: 7.6917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9584

Learning rate: 0.0001998162398600749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 7.9600	Cost: 34.77s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 7.6245	Cost: 9.56s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 7.6884	Cost: 12.88s
Train Epoch: 194 	Average Loss: 7.6548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9709

Learning rate: 0.00019981433126764085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 7.9815	Cost: 33.99s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 7.6408	Cost: 9.44s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 7.5568	Cost: 12.85s
Train Epoch: 195 	Average Loss: 7.6518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9065

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Learning rate: 0.00019981241282392723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 7.8991	Cost: 33.44s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 7.6974	Cost: 10.11s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 7.6572	Cost: 12.24s
Train Epoch: 196 	Average Loss: 7.6611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9960

Learning rate: 0.0001998104845291234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 7.9795	Cost: 34.13s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 7.6339	Cost: 10.15s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 7.6189	Cost: 12.38s
Train Epoch: 197 	Average Loss: 7.6385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9694

Learning rate: 0.00019980854638341968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 7.9504	Cost: 33.85s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 7.6962	Cost: 9.45s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 7.5773	Cost: 12.32s
Train Epoch: 198 	Average Loss: 7.6202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8961

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 0.00019980659838700736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 7.7764	Cost: 33.63s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 7.5338	Cost: 9.43s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 7.6231	Cost: 12.46s
Train Epoch: 199 	Average Loss: 7.5769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8492

Saving model as e199_model.pt & e199_waveforms_supplementary.hdf5
Learning rate: 0.0001998046405400787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 7.9317	Cost: 33.57s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 7.6046	Cost: 9.44s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 7.5762	Cost: 12.56s
Train Epoch: 200 	Average Loss: 7.5862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9320

Learning rate: 0.00019980267284282693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 7.8275	Cost: 33.10s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 7.5178	Cost: 9.40s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 7.6171	Cost: 12.74s
Train Epoch: 201 	Average Loss: 7.5881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8904

Learning rate: 0.00019980069529544622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 7.9365	Cost: 33.30s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 7.5779	Cost: 9.41s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 7.4361	Cost: 12.46s
Train Epoch: 202 	Average Loss: 7.5506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8515

Learning rate: 0.0001997987078981318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 7.8513	Cost: 33.12s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 7.6051	Cost: 9.47s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 7.5199	Cost: 12.21s
Train Epoch: 203 	Average Loss: 7.5525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8969

Learning rate: 0.00019979671065107978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 7.7755	Cost: 33.16s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 7.4974	Cost: 9.72s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 7.5205	Cost: 11.88s
Train Epoch: 204 	Average Loss: 7.5378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9209

Learning rate: 0.0001997947035544873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 7.8906	Cost: 33.56s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 7.5430	Cost: 9.98s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 7.5931	Cost: 12.02s
Train Epoch: 205 	Average Loss: 7.5050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7963

Saving model as e205_model.pt & e205_waveforms_supplementary.hdf5
Learning rate: 0.00019979268660855247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 7.8227	Cost: 35.54s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 7.5206	Cost: 9.46s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 7.3941	Cost: 14.35s
Train Epoch: 206 	Average Loss: 7.4813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8468

Learning rate: 0.00019979065981347432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 7.7775	Cost: 33.72s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 7.4658	Cost: 9.63s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 7.3990	Cost: 12.79s
Train Epoch: 207 	Average Loss: 7.4563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7818

Saving model as e207_model.pt & e207_waveforms_supplementary.hdf5
Learning rate: 0.0001997886231694529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 7.7944	Cost: 33.64s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 7.5026	Cost: 9.75s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 7.4180	Cost: 12.06s
Train Epoch: 208 	Average Loss: 7.4401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7988

Learning rate: 0.0001997865766766892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 7.7816	Cost: 33.35s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 7.3870	Cost: 9.43s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 7.3860	Cost: 12.48s
Train Epoch: 209 	Average Loss: 7.4086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7921

Learning rate: 0.00019978452033538524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 7.8227	Cost: 33.15s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 7.3648	Cost: 9.45s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 7.4534	Cost: 12.45s
Train Epoch: 210 	Average Loss: 7.4198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7679

Saving model as e210_model.pt & e210_waveforms_supplementary.hdf5
Learning rate: 0.00019978245414574395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 7.6949	Cost: 33.59s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 7.4054	Cost: 9.43s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 7.3397	Cost: 12.98s
Train Epoch: 211 	Average Loss: 7.3839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7633

Saving model as e211_model.pt & e211_waveforms_supplementary.hdf5
Learning rate: 0.00019978037810796924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 7.8011	Cost: 33.08s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 7.3960	Cost: 10.11s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 7.3528	Cost: 11.52s
Train Epoch: 212 	Average Loss: 7.3611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7339

Saving model as e212_model.pt & e212_waveforms_supplementary.hdf5
Learning rate: 0.000199778292222266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 7.6816	Cost: 33.11s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 7.3041	Cost: 9.42s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 7.3416	Cost: 12.11s
Train Epoch: 213 	Average Loss: 7.3511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7594

Learning rate: 0.00019977619648884015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 7.6983	Cost: 33.21s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 7.3230	Cost: 9.41s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 7.4270	Cost: 12.10s
Train Epoch: 214 	Average Loss: 7.3521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7408

Learning rate: 0.0001997740909078985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 7.7460	Cost: 33.91s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 7.3311	Cost: 9.43s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 7.3601	Cost: 12.89s
Train Epoch: 215 	Average Loss: 7.3138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7075

Saving model as e215_model.pt & e215_waveforms_supplementary.hdf5
Learning rate: 0.0001997719754796489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 7.6056	Cost: 32.74s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 7.3518	Cost: 9.42s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 7.2816	Cost: 12.13s
Train Epoch: 216 	Average Loss: 7.2874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7210

Learning rate: 0.00019976985020430003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 7.6578	Cost: 32.83s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 7.2434	Cost: 9.43s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 7.2721	Cost: 12.47s
Train Epoch: 217 	Average Loss: 7.2789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6426

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 0.00019976771508206176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 7.6755	Cost: 33.41s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 7.2622	Cost: 9.42s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 7.3041	Cost: 12.26s
Train Epoch: 218 	Average Loss: 7.2757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6746

Learning rate: 0.00019976557011314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 7.7217	Cost: 33.42s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 7.2855	Cost: 9.43s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 7.1751	Cost: 12.40s
Train Epoch: 219 	Average Loss: 7.2760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6438

Learning rate: 0.00019976341529776072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 7.6068	Cost: 33.34s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 7.2058	Cost: 9.43s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 7.3210	Cost: 12.28s
Train Epoch: 220 	Average Loss: 7.2351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6889

Learning rate: 0.00019976125063612233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 7.6079	Cost: 33.71s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 7.2063	Cost: 10.12s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 7.1643	Cost: 12.66s
Train Epoch: 221 	Average Loss: 7.2474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5981

Saving model as e221_model.pt & e221_waveforms_supplementary.hdf5
Learning rate: 0.00019975907612844327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 7.5900	Cost: 33.52s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 7.1099	Cost: 10.12s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 7.1653	Cost: 11.56s
Train Epoch: 222 	Average Loss: 7.2163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5994

Learning rate: 0.00019975689177493812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 7.4363	Cost: 32.93s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 7.1317	Cost: 9.40s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 7.2110	Cost: 12.51s
Train Epoch: 223 	Average Loss: 7.1786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6382

Learning rate: 0.00019975469757582245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 7.6495	Cost: 34.26s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 7.1034	Cost: 9.41s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 7.1842	Cost: 12.87s
Train Epoch: 224 	Average Loss: 7.1704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6120

Learning rate: 0.00019975249353131286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 7.5599	Cost: 33.45s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 7.1808	Cost: 9.37s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 7.0680	Cost: 12.67s
Train Epoch: 225 	Average Loss: 7.1496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5953

Saving model as e225_model.pt & e225_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 7.5586	Cost: 34.24s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 7.1369	Cost: 9.65s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 7.1510	Cost: 12.10s
Train Epoch: 226 	Average Loss: 7.1504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6434

Learning rate: 0.0001997480559069829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 7.5953	Cost: 33.65s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 7.0893	Cost: 9.59s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 7.2315	Cost: 12.17s
Train Epoch: 227 	Average Loss: 7.1173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6089

Learning rate: 0.00019974582232760058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 7.5218	Cost: 34.30s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 7.1654	Cost: 9.53s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 7.0277	Cost: 13.00s
Train Epoch: 228 	Average Loss: 7.1288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5421

Saving model as e228_model.pt & e228_waveforms_supplementary.hdf5
Learning rate: 0.0001997435789037002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 7.4759	Cost: 32.79s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 7.0712	Cost: 9.42s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 7.0136	Cost: 12.03s
Train Epoch: 229 	Average Loss: 7.1062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5633

Learning rate: 0.0001997413256355033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 7.5037	Cost: 34.09s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 7.0183	Cost: 9.73s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 7.0975	Cost: 12.09s
Train Epoch: 230 	Average Loss: 7.0684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4989

Saving model as e230_model.pt & e230_waveforms_supplementary.hdf5
Learning rate: 0.0001997390625232322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 7.5124	Cost: 33.39s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 7.0016	Cost: 9.55s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 6.9284	Cost: 12.57s
Train Epoch: 231 	Average Loss: 7.0344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5137

Learning rate: 0.00019973678956711026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 7.6050	Cost: 33.11s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 6.9779	Cost: 9.54s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 7.0188	Cost: 12.50s
Train Epoch: 232 	Average Loss: 7.0507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5113

Learning rate: 0.00019973450676736185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 7.4187	Cost: 32.84s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 6.9718	Cost: 9.49s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 6.9792	Cost: 12.87s
Train Epoch: 233 	Average Loss: 7.0025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5288

Learning rate: 0.00019973221412421225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 7.4296	Cost: 33.18s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 6.9296	Cost: 9.52s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 6.9498	Cost: 12.66s
Train Epoch: 234 	Average Loss: 7.0027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5247

Learning rate: 0.0001997299116378877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 7.4591	Cost: 32.99s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 7.0060	Cost: 9.46s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 6.9692	Cost: 11.91s
Train Epoch: 235 	Average Loss: 6.9708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5625

Learning rate: 0.0001997275993086155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 7.4783	Cost: 33.52s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 6.9255	Cost: 9.43s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 6.9077	Cost: 11.99s
Train Epoch: 236 	Average Loss: 6.9629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4031

Saving model as e236_model.pt & e236_waveforms_supplementary.hdf5
Learning rate: 0.0001997252771366239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 7.4006	Cost: 33.24s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 6.9443	Cost: 9.48s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 6.9306	Cost: 11.68s
Train Epoch: 237 	Average Loss: 6.9317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4483

Learning rate: 0.000199722945122142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 7.4154	Cost: 33.37s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 6.8012	Cost: 9.47s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 6.8614	Cost: 12.79s
Train Epoch: 238 	Average Loss: 6.9074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4470

Learning rate: 0.0001997206032654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 7.4257	Cost: 33.76s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 6.9116	Cost: 9.45s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 6.8874	Cost: 12.62s
Train Epoch: 239 	Average Loss: 6.9015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4216

Learning rate: 0.00019971825156662903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 7.3779	Cost: 34.13s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 6.8468	Cost: 9.47s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 6.8031	Cost: 12.74s
Train Epoch: 240 	Average Loss: 6.8592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3639

Saving model as e240_model.pt & e240_waveforms_supplementary.hdf5
Learning rate: 0.00019971589002606117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 7.4249	Cost: 33.90s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 6.8476	Cost: 9.49s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 6.8021	Cost: 12.95s
Train Epoch: 241 	Average Loss: 6.8654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4063

Learning rate: 0.00019971351864392958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 7.3967	Cost: 33.28s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 6.8011	Cost: 9.47s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 6.7838	Cost: 12.79s
Train Epoch: 242 	Average Loss: 6.8339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3879

Learning rate: 0.00019971113742046817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 7.3680	Cost: 33.03s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 6.7946	Cost: 9.47s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 6.7445	Cost: 13.64s
Train Epoch: 243 	Average Loss: 6.8196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3644

Learning rate: 0.00019970874635591207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 7.3946	Cost: 33.14s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 6.7657	Cost: 9.68s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 6.7456	Cost: 11.69s
Train Epoch: 244 	Average Loss: 6.7939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3432

Saving model as e244_model.pt & e244_waveforms_supplementary.hdf5
Learning rate: 0.00019970634545049727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 7.2452	Cost: 33.17s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 6.7808	Cost: 9.48s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 6.7351	Cost: 12.83s
Train Epoch: 245 	Average Loss: 6.7904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3427

Saving model as e245_model.pt & e245_waveforms_supplementary.hdf5
Learning rate: 0.0001997039347044607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 7.3751	Cost: 34.02s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 6.7044	Cost: 9.47s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 6.7264	Cost: 12.99s
Train Epoch: 246 	Average Loss: 6.7464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2593

Saving model as e246_model.pt & e246_waveforms_supplementary.hdf5
Learning rate: 0.00019970151411804023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 7.2939	Cost: 32.74s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 6.6799	Cost: 9.48s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 6.6857	Cost: 11.86s
Train Epoch: 247 	Average Loss: 6.7429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3334

Learning rate: 0.00019969908369147485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 7.2066	Cost: 33.42s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 6.6579	Cost: 9.51s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 6.6255	Cost: 12.71s
Train Epoch: 248 	Average Loss: 6.7243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2922

Learning rate: 0.00019969664342500438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 7.3014	Cost: 32.82s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 6.5364	Cost: 9.47s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 6.6400	Cost: 11.90s
Train Epoch: 249 	Average Loss: 6.6960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3126

Learning rate: 0.00019969419331886966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 7.2065	Cost: 32.72s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 6.6099	Cost: 9.48s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 6.6434	Cost: 13.25s
Train Epoch: 250 	Average Loss: 6.6895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2328

Saving model as e250_model.pt & e250_waveforms_supplementary.hdf5
Learning rate: 0.0001996917333733126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 7.2629	Cost: 33.65s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 6.6089	Cost: 9.46s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 6.6800	Cost: 12.37s
Train Epoch: 251 	Average Loss: 6.6773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2032

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Learning rate: 0.00019968926358857587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 7.1486	Cost: 33.44s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 6.6022	Cost: 9.47s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 6.6892	Cost: 12.77s
Train Epoch: 252 	Average Loss: 6.6609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2671

Learning rate: 0.00019968678396490325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 7.2892	Cost: 32.96s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 6.5983	Cost: 9.46s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 6.6541	Cost: 11.75s
Train Epoch: 253 	Average Loss: 6.6360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1988

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 0.00019968429450253954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 7.1099	Cost: 32.68s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 6.5518	Cost: 9.46s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 6.5629	Cost: 13.42s
Train Epoch: 254 	Average Loss: 6.6153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1958

Saving model as e254_model.pt & e254_waveforms_supplementary.hdf5
Learning rate: 0.0001996817952017304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 7.0061	Cost: 33.44s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 6.5848	Cost: 9.46s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 6.5030	Cost: 13.91s
Train Epoch: 255 	Average Loss: 6.5612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1701

Saving model as e255_model.pt & e255_waveforms_supplementary.hdf5
Learning rate: 0.00019967928606272244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 7.1919	Cost: 32.94s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 6.5561	Cost: 9.46s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 6.5591	Cost: 13.26s
Train Epoch: 256 	Average Loss: 6.5680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2491

Learning rate: 0.0001996767670857634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 7.3164	Cost: 32.75s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 6.5642	Cost: 9.47s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 6.5482	Cost: 12.00s
Train Epoch: 257 	Average Loss: 6.5942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1493

Saving model as e257_model.pt & e257_waveforms_supplementary.hdf5
Learning rate: 0.00019967423827110182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 7.1351	Cost: 32.98s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 6.4468	Cost: 9.47s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 6.4935	Cost: 11.83s
Train Epoch: 258 	Average Loss: 6.5101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0475

Saving model as e258_model.pt & e258_waveforms_supplementary.hdf5
Learning rate: 0.00019967169961898734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 7.0899	Cost: 33.29s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 6.3831	Cost: 9.46s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 6.4927	Cost: 13.09s
Train Epoch: 259 	Average Loss: 6.4889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1455

Learning rate: 0.00019966915112967047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 7.1591	Cost: 32.47s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 6.3802	Cost: 9.46s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 6.4280	Cost: 11.88s
Train Epoch: 260 	Average Loss: 6.4768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1155

Learning rate: 0.00019966659280340273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 7.0354	Cost: 33.45s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 6.4738	Cost: 9.52s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 6.3842	Cost: 12.16s
Train Epoch: 261 	Average Loss: 6.4561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1999

Learning rate: 0.00019966402464043667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 7.1242	Cost: 33.40s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 6.4980	Cost: 9.61s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 6.4736	Cost: 12.63s
Train Epoch: 262 	Average Loss: 6.4866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1204

Learning rate: 0.00019966144664102572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 7.1683	Cost: 32.90s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 6.4246	Cost: 9.49s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 6.3679	Cost: 12.88s
Train Epoch: 263 	Average Loss: 6.4479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0301

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Learning rate: 0.00019965885880542434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 6.9594	Cost: 32.98s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 6.3298	Cost: 9.47s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 6.4816	Cost: 12.16s
Train Epoch: 264 	Average Loss: 6.4104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0972

Learning rate: 0.00019965626113388794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 7.0446	Cost: 32.93s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 6.3334	Cost: 9.47s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 6.4184	Cost: 11.91s
Train Epoch: 265 	Average Loss: 6.4194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0581

Learning rate: 0.00019965365362667288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 7.0006	Cost: 32.67s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 6.3962	Cost: 9.47s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 6.4140	Cost: 12.80s
Train Epoch: 266 	Average Loss: 6.3747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0337

Learning rate: 0.0001996510362840365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 7.0754	Cost: 33.04s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 6.3861	Cost: 9.47s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 6.3808	Cost: 13.94s
Train Epoch: 267 	Average Loss: 6.3626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0569

Learning rate: 0.00019964840910623716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 7.0844	Cost: 33.54s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 6.2288	Cost: 9.46s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 6.3381	Cost: 12.93s
Train Epoch: 268 	Average Loss: 6.3203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0115

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Learning rate: 0.00019964577209353413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 6.9764	Cost: 33.51s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 6.3302	Cost: 9.52s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 6.2703	Cost: 12.37s
Train Epoch: 269 	Average Loss: 6.3075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0280

Learning rate: 0.00019964312524618766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 7.0613	Cost: 33.62s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 6.1094	Cost: 9.47s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 6.2473	Cost: 12.17s
Train Epoch: 270 	Average Loss: 6.2883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9580

Saving model as e270_model.pt & e270_waveforms_supplementary.hdf5
Learning rate: 0.000199640468564459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 6.8925	Cost: 33.42s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 6.2430	Cost: 9.49s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 6.3043	Cost: 13.35s
Train Epoch: 271 	Average Loss: 6.2571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0142

Learning rate: 0.00019963780204861037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 6.8820	Cost: 32.80s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 6.1728	Cost: 9.48s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 6.2469	Cost: 12.05s
Train Epoch: 272 	Average Loss: 6.2578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9594

Learning rate: 0.0001996351256989049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 6.9588	Cost: 33.50s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 6.2199	Cost: 9.48s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 6.1859	Cost: 12.23s
Train Epoch: 273 	Average Loss: 6.2472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9125

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 0.0001996324395156068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 6.9539	Cost: 33.40s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 6.1356	Cost: 9.48s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 6.1193	Cost: 12.49s
Train Epoch: 274 	Average Loss: 6.1894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9218

Learning rate: 0.00019962974349898107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 6.9213	Cost: 33.19s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 6.1537	Cost: 9.43s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 6.2421	Cost: 12.82s
Train Epoch: 275 	Average Loss: 6.2000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9959

Learning rate: 0.0001996270376492939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 6.9441	Cost: 33.88s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 6.0582	Cost: 9.54s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 6.1015	Cost: 13.29s
Train Epoch: 276 	Average Loss: 6.1683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8863

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Learning rate: 0.00019962432196681234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 6.8642	Cost: 33.60s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 6.1510	Cost: 9.49s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 6.2182	Cost: 12.22s
Train Epoch: 277 	Average Loss: 6.1714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8856

Saving model as e277_model.pt & e277_waveforms_supplementary.hdf5
Learning rate: 0.00019962159645180437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 6.9666	Cost: 33.86s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 6.0602	Cost: 9.47s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 6.0649	Cost: 12.53s
Train Epoch: 278 	Average Loss: 6.1323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8722

Saving model as e278_model.pt & e278_waveforms_supplementary.hdf5
Learning rate: 0.00019961886110453903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 6.7535	Cost: 33.15s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 5.9947	Cost: 9.47s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 6.0343	Cost: 12.68s
Train Epoch: 279 	Average Loss: 6.0616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8961

Learning rate: 0.00019961611592528625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 6.9137	Cost: 33.30s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 6.0155	Cost: 9.47s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 6.0235	Cost: 12.58s
Train Epoch: 280 	Average Loss: 6.0714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8288

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Learning rate: 0.000199613360914317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 6.7585	Cost: 33.88s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 5.9845	Cost: 9.46s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 5.9869	Cost: 11.79s
Train Epoch: 281 	Average Loss: 6.0298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8113

Saving model as e281_model.pt & e281_waveforms_supplementary.hdf5
Learning rate: 0.00019961059607190318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 6.7145	Cost: 33.17s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 5.9174	Cost: 9.47s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 6.0103	Cost: 11.98s
Train Epoch: 282 	Average Loss: 6.0367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8145

Learning rate: 0.00019960782139831766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 6.7363	Cost: 32.75s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 5.8612	Cost: 9.41s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 6.0112	Cost: 12.18s
Train Epoch: 283 	Average Loss: 5.9712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7630

Saving model as e283_model.pt & e283_waveforms_supplementary.hdf5
Learning rate: 0.00019960503689383428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 6.7257	Cost: 32.94s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 5.8690	Cost: 9.49s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 6.0163	Cost: 13.27s
Train Epoch: 284 	Average Loss: 6.0210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8946

Learning rate: 0.0001996022425587279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 6.7681	Cost: 32.94s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 5.9189	Cost: 9.48s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 5.8192	Cost: 13.24s
Train Epoch: 285 	Average Loss: 5.9930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7799

Learning rate: 0.0001995994383932743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 6.7125	Cost: 32.96s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 5.8764	Cost: 9.64s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 5.8899	Cost: 12.49s
Train Epoch: 286 	Average Loss: 5.9177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6872

Saving model as e286_model.pt & e286_waveforms_supplementary.hdf5
Learning rate: 0.0001995966243977502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 6.7643	Cost: 34.00s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 5.7457	Cost: 9.46s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 5.7468	Cost: 12.62s
Train Epoch: 287 	Average Loss: 5.8539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7160

Learning rate: 0.0001995938005724334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 6.7810	Cost: 33.55s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 5.8493	Cost: 9.46s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 5.9505	Cost: 12.57s
Train Epoch: 288 	Average Loss: 5.8895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7398

Learning rate: 0.00019959096691760252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 6.6369	Cost: 32.85s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 5.7719	Cost: 9.45s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 5.8510	Cost: 12.93s
Train Epoch: 289 	Average Loss: 5.8555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7010

Learning rate: 0.00019958812343353726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 6.5810	Cost: 33.49s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 5.8229	Cost: 9.46s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 5.8628	Cost: 12.51s
Train Epoch: 290 	Average Loss: 5.9035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6771

Saving model as e290_model.pt & e290_waveforms_supplementary.hdf5
Learning rate: 0.0001995852701205183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 6.7365	Cost: 33.21s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 5.7340	Cost: 9.50s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 5.6797	Cost: 12.02s
Train Epoch: 291 	Average Loss: 5.8449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6378

Saving model as e291_model.pt & e291_waveforms_supplementary.hdf5
Learning rate: 0.0001995824069788272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 6.6798	Cost: 33.14s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 5.6507	Cost: 9.47s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 5.7773	Cost: 11.82s
Train Epoch: 292 	Average Loss: 5.7822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7191

Learning rate: 0.00019957953400874656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 6.5438	Cost: 32.87s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 5.6011	Cost: 9.47s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 5.6815	Cost: 13.87s
Train Epoch: 293 	Average Loss: 5.7460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5660

Saving model as e293_model.pt & e293_waveforms_supplementary.hdf5
Learning rate: 0.00019957665121055995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 6.4984	Cost: 33.33s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 5.7028	Cost: 9.46s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 5.6701	Cost: 12.71s
Train Epoch: 294 	Average Loss: 5.7554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6216

Learning rate: 0.00019957375858455185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 6.5912	Cost: 33.67s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 5.7919	Cost: 9.49s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 5.7151	Cost: 12.23s
Train Epoch: 295 	Average Loss: 5.7466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5401

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 0.00019957085613100776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 6.5341	Cost: 32.96s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 5.6381	Cost: 9.48s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 5.6028	Cost: 12.88s
Train Epoch: 296 	Average Loss: 5.6992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5542

Learning rate: 0.00019956794385021415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 6.4664	Cost: 33.94s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 5.6463	Cost: 9.52s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 5.5587	Cost: 13.27s
Train Epoch: 297 	Average Loss: 5.6704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5451

Learning rate: 0.00019956502174245846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 6.5609	Cost: 33.28s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 5.5868	Cost: 9.49s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 5.6614	Cost: 13.29s
Train Epoch: 298 	Average Loss: 5.6467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5869

Learning rate: 0.0001995620898080291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 6.4908	Cost: 33.17s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 5.6311	Cost: 9.48s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 5.5420	Cost: 13.41s
Train Epoch: 299 	Average Loss: 5.6548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5085

Saving model as e299_model.pt & e299_waveforms_supplementary.hdf5
Learning rate: 0.00019955914804721542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 6.5910	Cost: 32.80s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 5.6058	Cost: 9.48s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 5.5605	Cost: 13.23s
Train Epoch: 300 	Average Loss: 5.6445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4946

Saving model as e300_model.pt & e300_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 6.4212	Cost: 33.31s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 5.4973	Cost: 9.48s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 5.5781	Cost: 13.05s
Train Epoch: 301 	Average Loss: 5.6038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4892

Saving model as e301_model.pt & e301_waveforms_supplementary.hdf5
Learning rate: 0.0001995532350475974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 6.6046	Cost: 33.59s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 5.5149	Cost: 9.54s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 5.5084	Cost: 13.11s
Train Epoch: 302 	Average Loss: 5.5887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5248

Learning rate: 0.00019955026380937669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 6.4320	Cost: 33.22s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 5.4042	Cost: 9.49s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 5.5131	Cost: 12.98s
Train Epoch: 303 	Average Loss: 5.5339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4585

Saving model as e303_model.pt & e303_waveforms_supplementary.hdf5
Learning rate: 0.00019954728274593884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 6.4183	Cost: 33.06s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 5.5529	Cost: 9.48s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 5.5470	Cost: 12.93s
Train Epoch: 304 	Average Loss: 5.5565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4785

Learning rate: 0.00019954429185757805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 6.4792	Cost: 33.21s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 5.4454	Cost: 9.49s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 5.3828	Cost: 13.04s
Train Epoch: 305 	Average Loss: 5.5307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4438

Saving model as e305_model.pt & e305_waveforms_supplementary.hdf5
Learning rate: 0.00019954129114458955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 6.6002	Cost: 33.56s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 5.4311	Cost: 9.47s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 5.4366	Cost: 13.46s
Train Epoch: 306 	Average Loss: 5.5139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4764

Learning rate: 0.00019953828060726943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 6.3750	Cost: 33.09s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 5.3815	Cost: 9.48s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 5.3618	Cost: 11.89s
Train Epoch: 307 	Average Loss: 5.4979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4917

Learning rate: 0.00019953526024591494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 6.4594	Cost: 32.59s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 5.3406	Cost: 9.49s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 5.3995	Cost: 13.53s
Train Epoch: 308 	Average Loss: 5.4735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4511

Learning rate: 0.00019953223006082406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 6.2991	Cost: 33.59s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 5.2340	Cost: 9.49s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 5.3272	Cost: 11.87s
Train Epoch: 309 	Average Loss: 5.3979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3857

Saving model as e309_model.pt & e309_waveforms_supplementary.hdf5
Learning rate: 0.00019952919005229592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 6.2601	Cost: 33.10s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 5.3061	Cost: 9.48s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 5.3228	Cost: 12.70s
Train Epoch: 310 	Average Loss: 5.3759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3902

Learning rate: 0.00019952614022063054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 6.3007	Cost: 33.92s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 5.3285	Cost: 9.48s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 5.3114	Cost: 12.09s
Train Epoch: 311 	Average Loss: 5.3483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3895

Learning rate: 0.00019952308056612892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 6.3365	Cost: 33.24s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 5.2692	Cost: 9.48s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 5.3592	Cost: 13.83s
Train Epoch: 312 	Average Loss: 5.3672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3639

Saving model as e312_model.pt & e312_waveforms_supplementary.hdf5
Learning rate: 0.00019952001108909304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 6.4150	Cost: 33.29s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 5.2505	Cost: 9.48s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 5.2203	Cost: 13.17s
Train Epoch: 313 	Average Loss: 5.3134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3906

Learning rate: 0.00019951693178982586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 6.1669	Cost: 33.55s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 5.2044	Cost: 9.49s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 5.1969	Cost: 13.15s
Train Epoch: 314 	Average Loss: 5.2887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3750

Learning rate: 0.00019951384266863126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 6.2914	Cost: 33.83s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 5.2511	Cost: 9.51s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 5.2721	Cost: 12.98s
Train Epoch: 315 	Average Loss: 5.2755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3144

Saving model as e315_model.pt & e315_waveforms_supplementary.hdf5
Learning rate: 0.00019951074372581416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 6.2377	Cost: 33.64s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 5.2379	Cost: 9.46s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 5.1958	Cost: 12.85s
Train Epoch: 316 	Average Loss: 5.2589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2768

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 0.00019950763496168037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 6.2149	Cost: 32.70s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 5.2258	Cost: 9.45s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 5.1053	Cost: 11.75s
Train Epoch: 317 	Average Loss: 5.2471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2751

Saving model as e317_model.pt & e317_waveforms_supplementary.hdf5
Learning rate: 0.00019950451637653678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 6.1440	Cost: 32.97s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 5.0749	Cost: 9.48s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 5.0909	Cost: 12.14s
Train Epoch: 318 	Average Loss: 5.1887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2515

Saving model as e318_model.pt & e318_waveforms_supplementary.hdf5
Learning rate: 0.00019950138797069118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 6.2294	Cost: 33.46s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 5.0457	Cost: 9.48s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 5.0777	Cost: 11.95s
Train Epoch: 319 	Average Loss: 5.1550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1650

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Learning rate: 0.00019949824974445222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 6.0938	Cost: 33.55s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 5.0280	Cost: 9.44s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 5.1313	Cost: 12.39s
Train Epoch: 320 	Average Loss: 5.1211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0356

Saving model as e320_model.pt & e320_waveforms_supplementary.hdf5
Learning rate: 0.00019949510169812976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 6.0349	Cost: 33.70s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 4.9932	Cost: 9.45s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 5.0456	Cost: 13.25s
Train Epoch: 321 	Average Loss: 5.1076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1798

Learning rate: 0.00019949194383203438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 6.1409	Cost: 33.51s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 4.9962	Cost: 9.46s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 5.0888	Cost: 11.74s
Train Epoch: 322 	Average Loss: 5.0920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1981

Learning rate: 0.00019948877614647787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 6.0711	Cost: 33.83s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 4.9436	Cost: 9.47s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 4.9240	Cost: 12.23s
Train Epoch: 323 	Average Loss: 5.0289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0949

Learning rate: 0.0001994855986417728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 6.0993	Cost: 33.13s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 4.9593	Cost: 9.51s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 4.9213	Cost: 11.86s
Train Epoch: 324 	Average Loss: 5.0219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1994

Learning rate: 0.0001994824113182328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 6.1527	Cost: 33.77s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 4.9693	Cost: 9.52s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 4.8883	Cost: 12.38s
Train Epoch: 325 	Average Loss: 5.0159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1150

Learning rate: 0.00019947921417617242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 6.0200	Cost: 34.25s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 4.9838	Cost: 9.48s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 5.0329	Cost: 12.49s
Train Epoch: 326 	Average Loss: 5.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0851

Learning rate: 0.0001994760072159072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 6.1727	Cost: 32.32s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 5.0062	Cost: 9.49s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 5.0222	Cost: 12.01s
Train Epoch: 327 	Average Loss: 5.0933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0814

Learning rate: 0.00019947279043775368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 6.0515	Cost: 33.87s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 4.9777	Cost: 9.50s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 4.9567	Cost: 11.88s
Train Epoch: 328 	Average Loss: 5.0258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0778

Learning rate: 0.00019946956384202932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 6.2432	Cost: 33.11s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 4.8688	Cost: 9.47s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 4.8630	Cost: 13.54s
Train Epoch: 329 	Average Loss: 4.9647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0893

Learning rate: 0.00019946632742905265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 6.1707	Cost: 33.73s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 4.8370	Cost: 9.48s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 4.8182	Cost: 12.58s
Train Epoch: 330 	Average Loss: 4.9375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9928

Saving model as e330_model.pt & e330_waveforms_supplementary.hdf5
Learning rate: 0.000199463081199143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 5.9983	Cost: 33.07s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 4.7821	Cost: 9.45s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 4.7975	Cost: 13.10s
Train Epoch: 331 	Average Loss: 4.8776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9433

Saving model as e331_model.pt & e331_waveforms_supplementary.hdf5
Learning rate: 0.0001994598251526208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 5.9982	Cost: 32.92s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 4.7669	Cost: 9.46s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 4.8137	Cost: 13.26s
Train Epoch: 332 	Average Loss: 4.8454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0454

Learning rate: 0.00019945655928980737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 6.0790	Cost: 33.43s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 4.7235	Cost: 9.48s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 4.7507	Cost: 11.99s
Train Epoch: 333 	Average Loss: 4.8506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9960

Learning rate: 0.0001994532836110251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 5.9971	Cost: 34.45s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 4.7076	Cost: 9.47s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 4.6226	Cost: 13.53s
Train Epoch: 334 	Average Loss: 4.8016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0073

Learning rate: 0.00019944999811659725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 6.1313	Cost: 33.34s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 4.7695	Cost: 9.50s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 4.7330	Cost: 13.35s
Train Epoch: 335 	Average Loss: 4.8514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8650

Saving model as e335_model.pt & e335_waveforms_supplementary.hdf5
Learning rate: 0.00019944670280684805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 5.8447	Cost: 33.04s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 4.6737	Cost: 9.47s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 4.7718	Cost: 11.81s
Train Epoch: 336 	Average Loss: 4.7775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0455

Learning rate: 0.00019944339768210285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 6.0046	Cost: 33.58s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 4.6618	Cost: 9.49s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 4.6060	Cost: 12.14s
Train Epoch: 337 	Average Loss: 4.7391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8820

Learning rate: 0.0001994400827426877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 5.8823	Cost: 32.91s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 4.6119	Cost: 9.47s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 4.6721	Cost: 12.95s
Train Epoch: 338 	Average Loss: 4.7014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9269

Learning rate: 0.0001994367579889299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 5.9233	Cost: 34.15s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 4.6311	Cost: 9.47s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 4.6407	Cost: 13.74s
Train Epoch: 339 	Average Loss: 4.7093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9607

Learning rate: 0.0001994334234211575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 5.8171	Cost: 32.92s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 4.5730	Cost: 9.46s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 4.5053	Cost: 11.90s
Train Epoch: 340 	Average Loss: 4.6953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9224

Learning rate: 0.00019943007903969968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 5.8003	Cost: 33.92s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 4.6243	Cost: 9.48s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 4.5837	Cost: 13.09s
Train Epoch: 341 	Average Loss: 4.6687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7349

Saving model as e341_model.pt & e341_waveforms_supplementary.hdf5
Learning rate: 0.00019942672484488645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 5.7846	Cost: 32.88s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 4.4871	Cost: 9.48s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 4.4982	Cost: 12.02s
Train Epoch: 342 	Average Loss: 4.5919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8682

Learning rate: 0.0001994233608370489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 5.9559	Cost: 33.19s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 4.5218	Cost: 9.47s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 4.5384	Cost: 13.41s
Train Epoch: 343 	Average Loss: 4.6059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7998

Learning rate: 0.00019941998701651908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 5.6638	Cost: 32.55s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 4.4705	Cost: 9.48s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 4.4311	Cost: 13.36s
Train Epoch: 344 	Average Loss: 4.5722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7951

Learning rate: 0.00019941660338362987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 5.8602	Cost: 33.49s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 4.4810	Cost: 9.51s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 4.5720	Cost: 13.94s
Train Epoch: 345 	Average Loss: 4.6128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8500

Learning rate: 0.0001994132099387153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 5.6871	Cost: 33.51s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 4.3361	Cost: 9.47s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 4.4501	Cost: 13.22s
Train Epoch: 346 	Average Loss: 4.5136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7707

Learning rate: 0.00019940980668211027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 5.5893	Cost: 33.37s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 4.3703	Cost: 9.48s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 4.4148	Cost: 13.40s
Train Epoch: 347 	Average Loss: 4.4678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7051

Saving model as e347_model.pt & e347_waveforms_supplementary.hdf5
Learning rate: 0.00019940639361415064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 5.6654	Cost: 33.53s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 4.2917	Cost: 9.46s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 4.3790	Cost: 11.77s
Train Epoch: 348 	Average Loss: 4.4325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7184

Learning rate: 0.00019940297073517331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 5.4841	Cost: 33.50s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 4.3417	Cost: 9.50s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 4.3249	Cost: 11.76s
Train Epoch: 349 	Average Loss: 4.4119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6771

Saving model as e349_model.pt & e349_waveforms_supplementary.hdf5
Learning rate: 0.00019939953804551608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 5.6327	Cost: 33.09s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 4.2949	Cost: 9.49s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 4.3076	Cost: 12.72s
Train Epoch: 350 	Average Loss: 4.3916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6756

Saving model as e350_model.pt & e350_waveforms_supplementary.hdf5
Learning rate: 0.00019939609554551777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 5.4981	Cost: 33.98s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 4.2568	Cost: 9.49s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 4.3083	Cost: 12.24s
Train Epoch: 351 	Average Loss: 4.3653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6926

Learning rate: 0.0001993926432355181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 5.6744	Cost: 33.09s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 4.2705	Cost: 9.48s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 4.2832	Cost: 13.78s
Train Epoch: 352 	Average Loss: 4.3551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6368

Saving model as e352_model.pt & e352_waveforms_supplementary.hdf5
Learning rate: 0.00019938918111585784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 5.5811	Cost: 33.28s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 4.1314	Cost: 9.47s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 4.3000	Cost: 12.96s
Train Epoch: 353 	Average Loss: 4.3005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5708

Saving model as e353_model.pt & e353_waveforms_supplementary.hdf5
Learning rate: 0.00019938570918687863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 5.4774	Cost: 33.29s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 4.2976	Cost: 9.46s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 4.2355	Cost: 12.21s
Train Epoch: 354 	Average Loss: 4.2796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5912

Learning rate: 0.0001993822274489232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 5.5618	Cost: 33.51s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 4.1060	Cost: 9.51s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 4.2084	Cost: 11.72s
Train Epoch: 355 	Average Loss: 4.2925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7460

Learning rate: 0.00019937873590233516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 5.8343	Cost: 33.09s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 4.2859	Cost: 9.49s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 4.0743	Cost: 13.44s
Train Epoch: 356 	Average Loss: 4.3101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4853

Saving model as e356_model.pt & e356_waveforms_supplementary.hdf5
Learning rate: 0.0001993752345474591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 5.5021	Cost: 33.86s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 4.0947	Cost: 9.45s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 4.1154	Cost: 12.21s
Train Epoch: 357 	Average Loss: 4.2215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5188

Learning rate: 0.0001993717233846406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 5.5359	Cost: 34.01s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 4.1253	Cost: 9.48s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 4.1402	Cost: 12.79s
Train Epoch: 358 	Average Loss: 4.2118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4967

Learning rate: 0.0001993682024142262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 5.3884	Cost: 33.36s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 4.6236	Cost: 9.46s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 4.4450	Cost: 11.80s
Train Epoch: 359 	Average Loss: 4.5683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8743

Learning rate: 0.00019936467163656337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 5.7780	Cost: 33.09s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 4.3425	Cost: 9.50s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 4.4341	Cost: 12.45s
Train Epoch: 360 	Average Loss: 4.5375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6764

Learning rate: 0.00019936113105200064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 5.8342	Cost: 33.70s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 4.2629	Cost: 9.46s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 4.1043	Cost: 12.61s
Train Epoch: 361 	Average Loss: 4.3650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5519

Learning rate: 0.00019935758066088742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 5.4590	Cost: 33.47s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 4.1218	Cost: 9.47s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 4.0307	Cost: 12.46s
Train Epoch: 362 	Average Loss: 4.1528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4266

Saving model as e362_model.pt & e362_waveforms_supplementary.hdf5
Learning rate: 0.00019935402046357414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 5.4067	Cost: 33.40s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 4.0016	Cost: 9.47s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 3.9661	Cost: 11.90s
Train Epoch: 363 	Average Loss: 4.0923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3931

Saving model as e363_model.pt & e363_waveforms_supplementary.hdf5
Learning rate: 0.00019935045046041218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 5.3773	Cost: 33.94s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 3.9228	Cost: 9.47s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 3.9503	Cost: 12.20s
Train Epoch: 364 	Average Loss: 4.0677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3538

Saving model as e364_model.pt & e364_waveforms_supplementary.hdf5
Learning rate: 0.00019934687065175386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 5.3051	Cost: 33.17s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 3.9270	Cost: 9.53s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 3.9365	Cost: 13.49s
Train Epoch: 365 	Average Loss: 4.0421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4425

Learning rate: 0.00019934328103795248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 5.2980	Cost: 33.76s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 3.9334	Cost: 9.52s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 3.8296	Cost: 12.76s
Train Epoch: 366 	Average Loss: 3.9985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3916

Learning rate: 0.00019933968161936236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 5.2995	Cost: 33.78s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 3.8820	Cost: 9.49s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 3.8351	Cost: 12.83s
Train Epoch: 367 	Average Loss: 3.9545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3266

Saving model as e367_model.pt & e367_waveforms_supplementary.hdf5
Learning rate: 0.00019933607239633875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 5.2375	Cost: 33.45s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 3.9151	Cost: 9.49s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 3.8655	Cost: 12.09s
Train Epoch: 368 	Average Loss: 3.9816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3824

Learning rate: 0.00019933245336923783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 5.3938	Cost: 34.07s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 3.8343	Cost: 9.47s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 3.9255	Cost: 12.94s
Train Epoch: 369 	Average Loss: 3.9660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4452

Learning rate: 0.0001993288245384168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 5.3879	Cost: 32.70s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 3.8471	Cost: 9.47s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 3.8803	Cost: 12.10s
Train Epoch: 370 	Average Loss: 3.9674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3260

Saving model as e370_model.pt & e370_waveforms_supplementary.hdf5
Learning rate: 0.00019932518590423377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 5.1991	Cost: 33.39s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 3.8029	Cost: 9.48s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 3.8680	Cost: 12.23s
Train Epoch: 371 	Average Loss: 3.9085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2962

Saving model as e371_model.pt & e371_waveforms_supplementary.hdf5
Learning rate: 0.00019932153746704794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 5.4478	Cost: 34.01s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 3.9213	Cost: 9.48s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 3.8561	Cost: 12.90s
Train Epoch: 372 	Average Loss: 3.9403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3311

Learning rate: 0.00019931787922721937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 5.4576	Cost: 33.22s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 3.7898	Cost: 9.48s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 3.8173	Cost: 12.91s
Train Epoch: 373 	Average Loss: 3.9394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2862

Saving model as e373_model.pt & e373_waveforms_supplementary.hdf5
Learning rate: 0.00019931421118510906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 5.2883	Cost: 33.30s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 3.9598	Cost: 9.48s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 3.8755	Cost: 12.83s
Train Epoch: 374 	Average Loss: 3.9907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3920

Learning rate: 0.0001993105333410791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 5.3495	Cost: 33.56s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 3.8240	Cost: 9.48s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 3.8113	Cost: 12.48s
Train Epoch: 375 	Average Loss: 3.9110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2959

Learning rate: 0.00019930684569549248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 5.4282	Cost: 33.07s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 3.8275	Cost: 9.47s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 3.6223	Cost: 12.39s
Train Epoch: 376 	Average Loss: 3.7962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0784

Saving model as e376_model.pt & e376_waveforms_supplementary.hdf5
Learning rate: 0.0001993031482487131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 4.9089	Cost: 32.65s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 3.6519	Cost: 9.47s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 3.8766	Cost: 11.72s
Train Epoch: 377 	Average Loss: 3.7584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3090

Learning rate: 0.0001992994410011059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 5.2473	Cost: 33.43s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 3.7529	Cost: 9.47s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 3.7515	Cost: 12.61s
Train Epoch: 378 	Average Loss: 3.8337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2417

Learning rate: 0.00019929572395303678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 5.2452	Cost: 34.16s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 3.6269	Cost: 9.47s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 4.0342	Cost: 12.46s
Train Epoch: 379 	Average Loss: 3.8540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3836

Learning rate: 0.0001992919971048726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 5.3946	Cost: 33.55s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 4.0456	Cost: 9.48s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 3.7540	Cost: 12.03s
Train Epoch: 380 	Average Loss: 3.9862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3241

Learning rate: 0.0001992882604569812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 5.0999	Cost: 34.01s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 3.6430	Cost: 9.51s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 3.6423	Cost: 12.93s
Train Epoch: 381 	Average Loss: 3.7054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0271

Saving model as e381_model.pt & e381_waveforms_supplementary.hdf5
Learning rate: 0.00019928451400973133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 5.0702	Cost: 33.96s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 3.5275	Cost: 9.49s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 3.6296	Cost: 12.41s
Train Epoch: 382 	Average Loss: 3.6262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1036

Learning rate: 0.0001992807577634928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 5.0923	Cost: 33.90s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 3.5478	Cost: 9.57s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 3.4923	Cost: 11.90s
Train Epoch: 383 	Average Loss: 3.6484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0879

Learning rate: 0.00019927699171863632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 5.0096	Cost: 32.87s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 3.5381	Cost: 9.49s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 3.5280	Cost: 12.51s
Train Epoch: 384 	Average Loss: 3.5716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0927

Learning rate: 0.00019927321587553357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 4.9563	Cost: 32.80s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 3.4812	Cost: 9.48s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 3.4399	Cost: 12.05s
Train Epoch: 385 	Average Loss: 3.5330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9829

Saving model as e385_model.pt & e385_waveforms_supplementary.hdf5
Learning rate: 0.00019926943023455717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 4.8728	Cost: 33.35s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 3.4888	Cost: 9.55s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 3.4823	Cost: 12.17s
Train Epoch: 386 	Average Loss: 3.5101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1051

Learning rate: 0.00019926563479608086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 5.0307	Cost: 33.24s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 3.3685	Cost: 9.47s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 3.5403	Cost: 11.96s
Train Epoch: 387 	Average Loss: 3.5474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9865

Learning rate: 0.00019926182956047912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 5.0202	Cost: 33.78s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 3.3697	Cost: 9.48s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 3.4545	Cost: 11.94s
Train Epoch: 388 	Average Loss: 3.5174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9661

Saving model as e388_model.pt & e388_waveforms_supplementary.hdf5
Learning rate: 0.00019925801452812757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 5.0164	Cost: 33.51s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 3.5513	Cost: 9.49s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 3.5393	Cost: 11.98s
Train Epoch: 389 	Average Loss: 3.5854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0859

Learning rate: 0.00019925418969940278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 5.0490	Cost: 33.86s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 3.3052	Cost: 9.49s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 3.4292	Cost: 13.49s
Train Epoch: 390 	Average Loss: 3.4867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9801

Learning rate: 0.00019925035507468219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 4.7993	Cost: 33.03s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 3.3144	Cost: 9.51s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 3.3669	Cost: 13.24s
Train Epoch: 391 	Average Loss: 3.4016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8572

Saving model as e391_model.pt & e391_waveforms_supplementary.hdf5
Learning rate: 0.00019924651065434423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 4.9010	Cost: 32.94s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 3.2741	Cost: 9.41s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 3.3566	Cost: 11.90s
Train Epoch: 392 	Average Loss: 3.3729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8986

Learning rate: 0.0001992426564387684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 4.9043	Cost: 33.35s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 3.2126	Cost: 9.46s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 3.3285	Cost: 11.68s
Train Epoch: 393 	Average Loss: 3.3691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9283

Learning rate: 0.00019923879242833502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 4.9368	Cost: 34.08s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 3.3223	Cost: 9.47s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 3.2236	Cost: 13.22s
Train Epoch: 394 	Average Loss: 3.3706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8955

Learning rate: 0.00019923491862342552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 4.9960	Cost: 33.09s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 3.5444	Cost: 9.46s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 3.4064	Cost: 13.16s
Train Epoch: 395 	Average Loss: 3.5156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9614

Learning rate: 0.0001992310350244222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 4.8670	Cost: 33.33s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 3.3193	Cost: 9.50s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 3.3420	Cost: 12.36s
Train Epoch: 396 	Average Loss: 3.4193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9803

Learning rate: 0.0001992271416317084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 4.9663	Cost: 33.41s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 3.3831	Cost: 9.56s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 3.2911	Cost: 12.20s
Train Epoch: 397 	Average Loss: 3.4189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8643

Learning rate: 0.0001992232384456683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 4.9394	Cost: 33.06s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 3.5178	Cost: 9.48s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 3.6073	Cost: 12.21s
Train Epoch: 398 	Average Loss: 3.5401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1540

Learning rate: 0.00019921932546668718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 5.0861	Cost: 35.10s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 3.3926	Cost: 9.49s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 3.3596	Cost: 12.59s
Train Epoch: 399 	Average Loss: 3.4864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8694

Learning rate: 0.00019921540269515121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 4.8283	Cost: 32.81s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 3.2086	Cost: 9.46s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 3.2811	Cost: 13.46s
Train Epoch: 400 	Average Loss: 3.3545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8387

Saving model as e400_model.pt & e400_waveforms_supplementary.hdf5
Learning rate: 0.0001992114701314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 4.9285	Cost: 33.28s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 3.0430	Cost: 9.47s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 3.1979	Cost: 12.10s
Train Epoch: 401 	Average Loss: 3.2635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8246

Saving model as e401_model.pt & e401_waveforms_supplementary.hdf5
Learning rate: 0.00019920752777596444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 4.7912	Cost: 33.55s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 3.1102	Cost: 9.48s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 3.1686	Cost: 11.72s
Train Epoch: 402 	Average Loss: 3.2099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9243

Learning rate: 0.00019920357562909082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 4.8332	Cost: 34.03s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 3.2916	Cost: 9.48s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 3.1921	Cost: 12.61s
Train Epoch: 403 	Average Loss: 3.3129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8901

Learning rate: 0.00019919961369121682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 4.8682	Cost: 33.57s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 3.1712	Cost: 9.50s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 3.2188	Cost: 11.83s
Train Epoch: 404 	Average Loss: 3.2599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7414

Saving model as e404_model.pt & e404_waveforms_supplementary.hdf5
Learning rate: 0.00019919564196273348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 4.7390	Cost: 33.72s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 2.9166	Cost: 9.47s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 2.9762	Cost: 12.08s
Train Epoch: 405 	Average Loss: 3.1006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6633

Saving model as e405_model.pt & e405_waveforms_supplementary.hdf5
Learning rate: 0.00019919166044403278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 4.5685	Cost: 33.34s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 2.9601	Cost: 9.51s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 2.9576	Cost: 12.02s
Train Epoch: 406 	Average Loss: 3.0882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6741

Learning rate: 0.00019918766913550764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 4.5117	Cost: 33.09s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 2.8802	Cost: 9.55s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 3.1419	Cost: 12.25s
Train Epoch: 407 	Average Loss: 3.0654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9928

Learning rate: 0.00019918366803755205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 4.8039	Cost: 33.05s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 3.2239	Cost: 9.49s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 3.1970	Cost: 13.23s
Train Epoch: 408 	Average Loss: 3.3075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8961

Learning rate: 0.00019917965715056087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 4.6779	Cost: 32.87s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 3.2310	Cost: 9.49s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 3.1686	Cost: 12.82s
Train Epoch: 409 	Average Loss: 3.2992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8517

Learning rate: 0.00019917563647492995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 4.7651	Cost: 33.12s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 3.0052	Cost: 9.52s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 3.0129	Cost: 13.32s
Train Epoch: 410 	Average Loss: 3.1241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6851

Learning rate: 0.00019917160601105614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 4.6685	Cost: 33.10s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 2.9725	Cost: 9.52s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 2.9714	Cost: 12.33s
Train Epoch: 411 	Average Loss: 2.9985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5591

Saving model as e411_model.pt & e411_waveforms_supplementary.hdf5
Learning rate: 0.0001991675657593372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 4.6009	Cost: 33.84s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 2.8557	Cost: 9.54s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 2.8378	Cost: 12.73s
Train Epoch: 412 	Average Loss: 2.9307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5162

Saving model as e412_model.pt & e412_waveforms_supplementary.hdf5
Learning rate: 0.00019916351572017192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 4.4538	Cost: 33.23s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 2.7865	Cost: 9.48s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 2.8653	Cost: 12.13s
Train Epoch: 413 	Average Loss: 2.8886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6506

Learning rate: 0.00019915945589396003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 4.5036	Cost: 33.13s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 3.0354	Cost: 9.47s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 3.2461	Cost: 12.96s
Train Epoch: 414 	Average Loss: 3.1208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0407

Learning rate: 0.00019915538628110217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 4.8144	Cost: 33.47s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 3.2391	Cost: 9.49s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 3.0605	Cost: 13.61s
Train Epoch: 415 	Average Loss: 3.3115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7502

Learning rate: 0.00019915130688200001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 4.6720	Cost: 33.46s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 3.6004	Cost: 9.54s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 3.3862	Cost: 12.10s
Train Epoch: 416 	Average Loss: 3.4938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1586

Learning rate: 0.0001991472176970562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 5.2479	Cost: 33.89s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 3.4621	Cost: 9.46s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 3.2891	Cost: 12.21s
Train Epoch: 417 	Average Loss: 3.5206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8201

Learning rate: 0.00019914311872667434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 4.9069	Cost: 33.07s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 2.8785	Cost: 9.46s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 2.7852	Cost: 12.25s
Train Epoch: 418 	Average Loss: 3.0843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5579

Learning rate: 0.0001991390099712589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 4.7291	Cost: 32.74s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 2.6852	Cost: 9.47s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 2.8220	Cost: 12.11s
Train Epoch: 419 	Average Loss: 2.8790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5112

Saving model as e419_model.pt & e419_waveforms_supplementary.hdf5
Learning rate: 0.00019913489143121547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 4.3678	Cost: 33.62s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 2.7663	Cost: 9.50s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 2.7933	Cost: 12.79s
Train Epoch: 420 	Average Loss: 2.8367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4530

Saving model as e420_model.pt & e420_waveforms_supplementary.hdf5
Learning rate: 0.0001991307631069505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 4.4854	Cost: 33.19s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 2.8046	Cost: 9.48s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 2.8711	Cost: 12.74s
Train Epoch: 421 	Average Loss: 2.9289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7491

Learning rate: 0.0001991266249988715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 4.6307	Cost: 33.35s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 2.7753	Cost: 9.47s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 2.7866	Cost: 12.17s
Train Epoch: 422 	Average Loss: 2.9508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5128

Learning rate: 0.00019912247710738676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 4.5070	Cost: 33.87s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 2.6316	Cost: 9.46s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 2.5785	Cost: 12.14s
Train Epoch: 423 	Average Loss: 2.7491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3825

Saving model as e423_model.pt & e423_waveforms_supplementary.hdf5
Learning rate: 0.0001991183194329058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 4.3277	Cost: 33.83s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 2.6112	Cost: 9.47s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 2.7033	Cost: 12.77s
Train Epoch: 424 	Average Loss: 2.7086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4071

Learning rate: 0.00019911415197583891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 4.3807	Cost: 33.63s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 2.5411	Cost: 9.49s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 2.8062	Cost: 11.91s
Train Epoch: 425 	Average Loss: 2.7571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4839

Learning rate: 0.00019910997473659734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 4.6544	Cost: 33.43s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 2.6509	Cost: 9.50s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 2.6545	Cost: 12.54s
Train Epoch: 426 	Average Loss: 2.8321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4224

Learning rate: 0.00019910578771559345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 4.4068	Cost: 32.62s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 2.4666	Cost: 9.48s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 2.5020	Cost: 13.48s
Train Epoch: 427 	Average Loss: 2.6685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3334

Saving model as e427_model.pt & e427_waveforms_supplementary.hdf5
Learning rate: 0.00019910159091324043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 4.3834	Cost: 33.31s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 2.5898	Cost: 9.48s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 2.4972	Cost: 12.04s
Train Epoch: 428 	Average Loss: 2.6416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3111

Saving model as e428_model.pt & e428_waveforms_supplementary.hdf5
Learning rate: 0.00019909738432995254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 4.1798	Cost: 33.25s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 2.4777	Cost: 9.51s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 2.4700	Cost: 13.36s
Train Epoch: 429 	Average Loss: 2.5735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3134

Learning rate: 0.00019909316796614494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 4.2818	Cost: 33.32s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 2.3825	Cost: 9.47s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 2.4165	Cost: 12.03s
Train Epoch: 430 	Average Loss: 2.5473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3508

Learning rate: 0.00019908894182223372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 4.2790	Cost: 33.48s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 2.3938	Cost: 9.48s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 2.4164	Cost: 13.44s
Train Epoch: 431 	Average Loss: 2.5085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2501

Saving model as e431_model.pt & e431_waveforms_supplementary.hdf5
Learning rate: 0.00019908470589863605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 4.0886	Cost: 33.22s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 2.3442	Cost: 9.48s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 2.4110	Cost: 11.83s
Train Epoch: 432 	Average Loss: 2.4844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2964

Learning rate: 0.00019908046019576994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 4.2194	Cost: 33.90s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 2.9797	Cost: 9.46s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 2.9186	Cost: 12.37s
Train Epoch: 433 	Average Loss: 2.9470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8489

Learning rate: 0.00019907620471405445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 4.8321	Cost: 33.62s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 3.0116	Cost: 9.48s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 2.7458	Cost: 12.16s
Train Epoch: 434 	Average Loss: 3.0781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4911

Learning rate: 0.0001990719394539096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 4.4018	Cost: 32.83s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 2.5775	Cost: 9.48s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 2.4765	Cost: 12.04s
Train Epoch: 435 	Average Loss: 2.7092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3110

Learning rate: 0.0001990676644157563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 4.3033	Cost: 33.11s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 2.4026	Cost: 9.47s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 2.3393	Cost: 13.03s
Train Epoch: 436 	Average Loss: 2.5487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2919

Learning rate: 0.00019906337960001657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 4.3459	Cost: 33.49s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 2.2147	Cost: 9.64s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 2.3671	Cost: 11.92s
Train Epoch: 437 	Average Loss: 2.4323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3264

Learning rate: 0.0001990590850071132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 4.3035	Cost: 32.81s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 2.2066	Cost: 9.49s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 2.3760	Cost: 13.47s
Train Epoch: 438 	Average Loss: 2.3970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1820

Saving model as e438_model.pt & e438_waveforms_supplementary.hdf5
Learning rate: 0.0001990547806374701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 4.0851	Cost: 33.22s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 2.2065	Cost: 9.50s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 2.1992	Cost: 11.79s
Train Epoch: 439 	Average Loss: 2.3385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1871

Learning rate: 0.00019905046649151213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 3.9085	Cost: 33.23s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 2.0282	Cost: 9.48s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 2.1519	Cost: 13.47s
Train Epoch: 440 	Average Loss: 2.2732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2110

Learning rate: 0.00019904614256966498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 4.0756	Cost: 33.12s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 2.2402	Cost: 9.46s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 2.3085	Cost: 11.92s
Train Epoch: 441 	Average Loss: 2.3498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1882

Learning rate: 0.00019904180887235552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 4.1503	Cost: 33.29s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 2.3659	Cost: 9.47s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 2.6709	Cost: 11.76s
Train Epoch: 442 	Average Loss: 2.4913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4447

Learning rate: 0.0001990374654000114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 4.3525	Cost: 32.99s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 2.5775	Cost: 9.46s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 2.4547	Cost: 11.96s
Train Epoch: 443 	Average Loss: 2.6358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2796

Learning rate: 0.0001990331121530613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 4.1491	Cost: 33.33s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 2.2728	Cost: 9.47s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 2.2841	Cost: 13.03s
Train Epoch: 444 	Average Loss: 2.4164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1990

Learning rate: 0.0001990287491319349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 4.2008	Cost: 33.58s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 2.4641	Cost: 9.46s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 2.3409	Cost: 11.98s
Train Epoch: 445 	Average Loss: 2.5345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2331

Learning rate: 0.00019902437633706276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 4.1294	Cost: 33.47s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 2.1428	Cost: 9.46s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 2.1301	Cost: 13.15s
Train Epoch: 446 	Average Loss: 2.3123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0039

Saving model as e446_model.pt & e446_waveforms_supplementary.hdf5
Learning rate: 0.0001990199937688765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 4.0200	Cost: 33.12s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 2.0933	Cost: 9.46s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 1.9901	Cost: 12.04s
Train Epoch: 447 	Average Loss: 2.1934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0628

Learning rate: 0.00019901560142780868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 4.1037	Cost: 32.90s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 2.0844	Cost: 9.47s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 2.0504	Cost: 11.88s
Train Epoch: 448 	Average Loss: 2.1978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0347

Learning rate: 0.0001990111993142928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 3.8679	Cost: 33.28s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 2.0254	Cost: 9.49s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 2.0701	Cost: 13.07s
Train Epoch: 449 	Average Loss: 2.1426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0106

Learning rate: 0.0001990067874287633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 3.8978	Cost: 34.44s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 2.0591	Cost: 9.53s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 2.0406	Cost: 12.61s
Train Epoch: 450 	Average Loss: 2.1808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9960

Saving model as e450_model.pt & e450_waveforms_supplementary.hdf5
Learning rate: 0.00019900236577165563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 3.8943	Cost: 33.42s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 1.9013	Cost: 9.46s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 2.0252	Cost: 13.40s
Train Epoch: 451 	Average Loss: 2.1225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0064

Learning rate: 0.00019899793434340619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 3.7513	Cost: 33.33s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 2.0254	Cost: 9.48s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 1.9554	Cost: 13.22s
Train Epoch: 452 	Average Loss: 2.0487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8704

Saving model as e452_model.pt & e452_waveforms_supplementary.hdf5
Learning rate: 0.00019899349314445237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 3.9865	Cost: 33.74s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 1.9872	Cost: 9.50s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 2.0103	Cost: 12.53s
Train Epoch: 453 	Average Loss: 2.1110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0878

Learning rate: 0.00019898904217523244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 3.7684	Cost: 33.04s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 2.0306	Cost: 9.44s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 1.9793	Cost: 13.30s
Train Epoch: 454 	Average Loss: 2.0985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0064

Learning rate: 0.00019898458143618574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 3.9035	Cost: 33.50s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 1.8992	Cost: 9.50s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 1.8708	Cost: 12.72s
Train Epoch: 455 	Average Loss: 1.9960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7495

Saving model as e455_model.pt & e455_waveforms_supplementary.hdf5
Learning rate: 0.0001989801109277525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 3.9093	Cost: 33.94s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 1.7023	Cost: 9.47s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 1.8557	Cost: 12.58s
Train Epoch: 456 	Average Loss: 1.9534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9604

Learning rate: 0.000198975630650374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 3.9123	Cost: 33.66s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 1.9057	Cost: 9.50s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 1.8050	Cost: 13.44s
Train Epoch: 457 	Average Loss: 1.9699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8097

Learning rate: 0.0001989711406044923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 3.9164	Cost: 33.10s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 1.7972	Cost: 9.46s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 1.7414	Cost: 12.08s
Train Epoch: 458 	Average Loss: 1.9088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8466

Learning rate: 0.0001989666407905507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 3.7601	Cost: 33.52s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 1.6432	Cost: 9.52s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 1.9477	Cost: 13.06s
Train Epoch: 459 	Average Loss: 1.8780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8192

Learning rate: 0.00019896213120899325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 3.8865	Cost: 33.63s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 1.9025	Cost: 9.48s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 1.7663	Cost: 12.68s
Train Epoch: 460 	Average Loss: 1.9827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7315

Saving model as e460_model.pt & e460_waveforms_supplementary.hdf5
Learning rate: 0.00019895761186026497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 3.7657	Cost: 32.82s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 1.7725	Cost: 9.47s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 1.6397	Cost: 11.93s
Train Epoch: 461 	Average Loss: 1.8343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7933

Learning rate: 0.000198953082744812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 3.7537	Cost: 33.48s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 1.6246	Cost: 9.48s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 1.5759	Cost: 11.86s
Train Epoch: 462 	Average Loss: 1.7641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7964

Learning rate: 0.0001989485438630813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 3.7869	Cost: 33.40s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 1.5471	Cost: 9.48s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 1.6348	Cost: 12.25s
Train Epoch: 463 	Average Loss: 1.7414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6370

Saving model as e463_model.pt & e463_waveforms_supplementary.hdf5
Learning rate: 0.00019894399521552084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 3.4645	Cost: 33.43s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 1.6662	Cost: 9.46s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 1.8088	Cost: 11.95s
Train Epoch: 464 	Average Loss: 1.8017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8904

Learning rate: 0.0001989394368025795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 3.6373	Cost: 32.97s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 1.7620	Cost: 9.49s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 1.6616	Cost: 13.19s
Train Epoch: 465 	Average Loss: 1.8164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6620

Learning rate: 0.0001989348686247073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 3.5401	Cost: 33.45s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 1.7090	Cost: 9.47s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 1.8048	Cost: 13.06s
Train Epoch: 466 	Average Loss: 1.8257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8847

Learning rate: 0.000198930290682355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 3.7698	Cost: 32.70s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 1.5672	Cost: 9.49s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 1.4456	Cost: 11.82s
Train Epoch: 467 	Average Loss: 1.7479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7216

Learning rate: 0.00019892570297597447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 3.4710	Cost: 32.38s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 1.5424	Cost: 9.52s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 1.5751	Cost: 13.20s
Train Epoch: 468 	Average Loss: 1.6380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6612

Learning rate: 0.00019892110550601846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 3.5543	Cost: 33.22s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 1.5851	Cost: 9.48s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 1.6365	Cost: 13.46s
Train Epoch: 469 	Average Loss: 1.7246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6362

Saving model as e469_model.pt & e469_waveforms_supplementary.hdf5
Learning rate: 0.00019891649827294077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 3.8606	Cost: 32.86s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 1.4598	Cost: 9.47s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 1.7179	Cost: 11.86s
Train Epoch: 470 	Average Loss: 1.6771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7044

Learning rate: 0.00019891188127719607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 3.6095	Cost: 33.37s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 1.5235	Cost: 9.49s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 1.6823	Cost: 11.93s
Train Epoch: 471 	Average Loss: 1.7222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6117

Saving model as e471_model.pt & e471_waveforms_supplementary.hdf5
Learning rate: 0.00019890725451924011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 3.6508	Cost: 33.61s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 1.5425	Cost: 9.47s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 1.6813	Cost: 12.45s
Train Epoch: 472 	Average Loss: 1.6633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6881

Learning rate: 0.00019890261799952944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 3.5512	Cost: 33.68s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 1.6232	Cost: 9.50s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 1.6555	Cost: 13.31s
Train Epoch: 473 	Average Loss: 1.7597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7474

Learning rate: 0.00019889797171852172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 3.7533	Cost: 33.87s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 1.5682	Cost: 9.48s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 1.9207	Cost: 12.89s
Train Epoch: 474 	Average Loss: 1.7462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9650

Learning rate: 0.0001988933156766755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 3.8569	Cost: 33.29s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 1.8372	Cost: 9.46s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 1.6557	Cost: 12.25s
Train Epoch: 475 	Average Loss: 1.9195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7309

Learning rate: 0.00019888864987445035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 3.5301	Cost: 33.37s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 1.5830	Cost: 9.49s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 1.7022	Cost: 13.40s
Train Epoch: 476 	Average Loss: 1.7581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7705

Learning rate: 0.00019888397431230674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 3.5035	Cost: 33.35s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 1.5675	Cost: 9.50s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 1.5731	Cost: 12.55s
Train Epoch: 477 	Average Loss: 1.6389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5890

Saving model as e477_model.pt & e477_waveforms_supplementary.hdf5
Learning rate: 0.00019887928899070613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 3.4582	Cost: 33.03s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 1.3413	Cost: 9.47s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 1.3688	Cost: 11.95s
Train Epoch: 478 	Average Loss: 1.5049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5415

Saving model as e478_model.pt & e478_waveforms_supplementary.hdf5
Learning rate: 0.00019887459391011093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 3.4805	Cost: 33.40s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 1.3558	Cost: 9.49s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 1.3561	Cost: 12.98s
Train Epoch: 479 	Average Loss: 1.4764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3977

Saving model as e479_model.pt & e479_waveforms_supplementary.hdf5
Learning rate: 0.0001988698890709845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 3.6030	Cost: 34.05s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 1.3205	Cost: 9.47s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 1.2425	Cost: 12.66s
Train Epoch: 480 	Average Loss: 1.4570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4923

Learning rate: 0.0001988651744737913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 3.4085	Cost: 33.72s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 1.2989	Cost: 9.47s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 1.1727	Cost: 12.81s
Train Epoch: 481 	Average Loss: 1.3784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3614

Saving model as e481_model.pt & e481_waveforms_supplementary.hdf5
Learning rate: 0.00019886045011899655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 3.2036	Cost: 32.67s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 1.1527	Cost: 9.46s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 1.2053	Cost: 11.77s
Train Epoch: 482 	Average Loss: 1.4393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5705

Learning rate: 0.00019885571600706652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 3.5840	Cost: 33.55s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 1.2130	Cost: 9.48s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 1.2556	Cost: 12.83s
Train Epoch: 483 	Average Loss: 1.4280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4698

Learning rate: 0.00019885097213846847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 3.2633	Cost: 34.01s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 1.1916	Cost: 9.49s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 1.2000	Cost: 13.34s
Train Epoch: 484 	Average Loss: 1.3998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3780

Learning rate: 0.00019884621851367065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 3.3792	Cost: 33.46s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 1.2127	Cost: 9.47s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 1.1641	Cost: 13.94s
Train Epoch: 485 	Average Loss: 1.3602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4119

Learning rate: 0.00019884145513314214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 3.3472	Cost: 33.35s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 1.0892	Cost: 9.47s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 1.0043	Cost: 12.05s
Train Epoch: 486 	Average Loss: 1.2761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3565

Saving model as e486_model.pt & e486_waveforms_supplementary.hdf5
Learning rate: 0.00019883668199735307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 3.5153	Cost: 32.58s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 1.0810	Cost: 9.51s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 1.1648	Cost: 12.42s
Train Epoch: 487 	Average Loss: 1.2697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3394

Saving model as e487_model.pt & e487_waveforms_supplementary.hdf5
Learning rate: 0.00019883189910677464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 3.1262	Cost: 32.74s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 1.0888	Cost: 9.48s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 1.1276	Cost: 11.61s
Train Epoch: 488 	Average Loss: 1.2834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4430

Learning rate: 0.00019882710646187875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 3.2665	Cost: 32.92s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 1.0941	Cost: 9.47s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 1.0444	Cost: 13.17s
Train Epoch: 489 	Average Loss: 1.2447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4047

Learning rate: 0.00019882230406313855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 3.1458	Cost: 33.02s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 1.1893	Cost: 9.49s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 1.0168	Cost: 13.50s
Train Epoch: 490 	Average Loss: 1.2807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3085

Saving model as e490_model.pt & e490_waveforms_supplementary.hdf5
Learning rate: 0.00019881749191102795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 3.3299	Cost: 33.81s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 1.0469	Cost: 9.47s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 1.1785	Cost: 12.96s
Train Epoch: 491 	Average Loss: 1.2227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4387

Learning rate: 0.00019881267000602186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 3.2891	Cost: 33.54s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 1.0135	Cost: 9.49s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 0.9662	Cost: 12.54s
Train Epoch: 492 	Average Loss: 1.1979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3267

Learning rate: 0.00019880783834859626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 3.2462	Cost: 33.55s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 0.9448	Cost: 9.44s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 1.0786	Cost: 12.13s
Train Epoch: 493 	Average Loss: 1.1635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1965

Saving model as e493_model.pt & e493_waveforms_supplementary.hdf5
Learning rate: 0.000198802996939228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 3.2250	Cost: 33.45s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 0.9487	Cost: 9.49s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 0.9779	Cost: 13.42s
Train Epoch: 494 	Average Loss: 1.1364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1662

Saving model as e494_model.pt & e494_waveforms_supplementary.hdf5
Learning rate: 0.0001987981457783948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 3.2177	Cost: 32.77s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 0.8323	Cost: 9.48s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 0.9155	Cost: 12.07s
Train Epoch: 495 	Average Loss: 1.0765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1339

Saving model as e495_model.pt & e495_waveforms_supplementary.hdf5
Learning rate: 0.00019879328486657562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 3.2392	Cost: 33.12s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 1.1704	Cost: 9.43s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 1.1365	Cost: 11.56s
Train Epoch: 496 	Average Loss: 1.2313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3366

Learning rate: 0.0001987884142042501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 3.1839	Cost: 33.73s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 0.9807	Cost: 9.49s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 0.9100	Cost: 13.14s
Train Epoch: 497 	Average Loss: 1.1016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2061

Learning rate: 0.00019878353379189899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 3.1013	Cost: 33.34s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 0.9374	Cost: 9.51s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 0.9863	Cost: 12.14s
Train Epoch: 498 	Average Loss: 1.1328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2254

Learning rate: 0.00019877864363000396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 3.2675	Cost: 33.18s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 0.8121	Cost: 9.50s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 0.8498	Cost: 12.60s
Train Epoch: 499 	Average Loss: 1.0307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1201

Saving model as e499_model.pt & e499_waveforms_supplementary.hdf5
Learning rate: 0.00019877374371904765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 3.1399	Cost: 33.63s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 1.0226	Cost: 9.47s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 1.1084	Cost: 11.91s
Train Epoch: 500 	Average Loss: 1.1304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4147

Stopping timer.
Training time (including validation): 49513.03754615784 seconds
Saving model
Transfer learning by starting with alpha=0.8!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 47.1361	Cost: 32.04s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 23.6078	Cost: 9.50s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 18.7103	Cost: 11.85s
Train Epoch: 1 	Average Loss: 25.9911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3578

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.0001999980260856137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 18.2273	Cost: 31.96s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 15.8687	Cost: 9.51s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 13.2244	Cost: 11.59s
Train Epoch: 2 	Average Loss: 15.3515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5776

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 12.9678	Cost: 33.25s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 11.9731	Cost: 9.51s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 10.6629	Cost: 12.62s
Train Epoch: 3 	Average Loss: 12.0537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4014

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 11.3910	Cost: 33.16s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 10.2317	Cost: 9.66s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 9.5298	Cost: 12.06s
Train Epoch: 4 	Average Loss: 10.2837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0990

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892833004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 9.3391	Cost: 32.12s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 8.8542	Cost: 9.74s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 8.7412	Cost: 11.83s
Train Epoch: 5 	Average Loss: 9.1256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0122

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 8.8136	Cost: 31.62s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 8.3948	Cost: 9.53s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 7.7057	Cost: 11.76s
Train Epoch: 6 	Average Loss: 8.4136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3064

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 8.0704	Cost: 32.14s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 7.7155	Cost: 9.51s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 7.5970	Cost: 12.54s
Train Epoch: 7 	Average Loss: 7.6610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5595

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 7.6047	Cost: 32.16s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 6.9569	Cost: 9.59s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 7.2190	Cost: 11.55s
Train Epoch: 8 	Average Loss: 7.0573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9027

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019987369566060184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 7.0800	Cost: 32.12s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 6.8629	Cost: 9.68s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 6.5095	Cost: 11.49s
Train Epoch: 9 	Average Loss: 6.7436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6874

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019984015501089758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 6.4025	Cost: 32.00s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 6.5714	Cost: 9.51s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 6.0752	Cost: 12.08s
Train Epoch: 10 	Average Loss: 6.3997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3864

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 6.3425	Cost: 33.19s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 6.1197	Cost: 9.44s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 5.8502	Cost: 12.59s
Train Epoch: 11 	Average Loss: 6.1754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3160

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019976125063612257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 6.3656	Cost: 33.32s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 5.8716	Cost: 9.48s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 5.4985	Cost: 12.67s
Train Epoch: 12 	Average Loss: 5.9040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0641

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019971589002606144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 6.2204	Cost: 32.55s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 5.5125	Cost: 9.64s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 5.5841	Cost: 11.87s
Train Epoch: 13 	Average Loss: 5.6990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9673

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.00019966659280340303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 6.1747	Cost: 33.14s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 5.7729	Cost: 9.50s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 5.4097	Cost: 12.74s
Train Epoch: 14 	Average Loss: 5.5811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7273

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001996133609143173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 5.8718	Cost: 33.58s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 5.2035	Cost: 9.66s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 5.1261	Cost: 12.36s
Train Epoch: 15 	Average Loss: 5.3297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4397

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 5.5630	Cost: 32.12s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 5.0053	Cost: 9.54s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 5.0253	Cost: 12.62s
Train Epoch: 16 	Average Loss: 5.1125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3160

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.00019949510169813006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 5.1863	Cost: 32.64s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 4.7748	Cost: 9.72s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 4.8648	Cost: 11.69s
Train Epoch: 17 	Average Loss: 4.9397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2713

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019943007903969992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 5.2951	Cost: 32.34s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 4.8647	Cost: 9.57s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 4.6103	Cost: 12.32s
Train Epoch: 18 	Average Loss: 4.8407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9902

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.00019936113105200088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 5.0846	Cost: 32.03s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 4.5226	Cost: 9.78s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 4.3905	Cost: 11.80s
Train Epoch: 19 	Average Loss: 4.6678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9812

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.0001992882604569814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 4.9350	Cost: 31.56s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 4.3689	Cost: 9.58s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 4.5720	Cost: 12.07s
Train Epoch: 20 	Average Loss: 4.5838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8657

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019921147013144782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 4.8450	Cost: 32.15s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 4.4528	Cost: 10.39s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 4.3903	Cost: 11.06s
Train Epoch: 21 	Average Loss: 4.4725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7372

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.00019913076310695068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 4.8760	Cost: 31.59s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 4.3553	Cost: 9.68s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 4.0857	Cost: 11.34s
Train Epoch: 22 	Average Loss: 4.3277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7984

Learning rate: 0.00019904614256966512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 4.6455	Cost: 31.93s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 3.9454	Cost: 9.41s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 3.9992	Cost: 12.15s
Train Epoch: 23 	Average Loss: 4.1864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5776

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.0001989576118602651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 4.4689	Cost: 30.62s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 4.0014	Cost: 9.46s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 3.9968	Cost: 11.74s
Train Epoch: 24 	Average Loss: 4.1129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5940

Learning rate: 0.0001988651744737914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 4.7382	Cost: 31.72s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 3.8958	Cost: 9.42s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 3.8927	Cost: 12.50s
Train Epoch: 25 	Average Loss: 4.0544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6232

Learning rate: 0.0001987688340595138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 4.8849	Cost: 31.78s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 3.9922	Cost: 9.40s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 3.6795	Cost: 12.47s
Train Epoch: 26 	Average Loss: 4.0123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4315

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019866859442078683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 4.1059	Cost: 31.06s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 3.6425	Cost: 9.41s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 3.5813	Cost: 11.75s
Train Epoch: 27 	Average Loss: 3.7725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2146

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019856445951489985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 4.4743	Cost: 31.24s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 3.5453	Cost: 9.40s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 3.4420	Cost: 11.52s
Train Epoch: 28 	Average Loss: 3.6540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4646

Learning rate: 0.0001984564334529206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 4.2978	Cost: 31.06s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 3.6556	Cost: 9.39s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 3.6281	Cost: 11.87s
Train Epoch: 29 	Average Loss: 3.6109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1940

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.00019834452049953302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 4.2818	Cost: 31.17s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 3.6043	Cost: 9.35s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 3.4706	Cost: 12.68s
Train Epoch: 30 	Average Loss: 3.5819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2498

Learning rate: 0.00019822872507286893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 4.5236	Cost: 32.83s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 3.3623	Cost: 9.36s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 3.4179	Cost: 12.45s
Train Epoch: 31 	Average Loss: 3.4584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2940

Learning rate: 0.00019810905174433345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 4.3757	Cost: 32.07s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 3.2769	Cost: 9.40s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 3.3104	Cost: 12.50s
Train Epoch: 32 	Average Loss: 3.3801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9188

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.00019798550523842474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 3.9952	Cost: 34.90s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 3.2780	Cost: 9.52s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 3.1763	Cost: 12.34s
Train Epoch: 33 	Average Loss: 3.2860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8934

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019785809043254728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 4.0998	Cost: 34.82s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 2.8908	Cost: 9.58s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 3.0013	Cost: 12.47s
Train Epoch: 34 	Average Loss: 3.1242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7377

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019772681235681944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 3.9355	Cost: 32.11s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 3.0128	Cost: 9.62s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 2.9478	Cost: 11.92s
Train Epoch: 35 	Average Loss: 3.0653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6962

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.00019759167619387482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 3.5542	Cost: 31.89s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 3.0142	Cost: 10.21s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 2.8630	Cost: 11.94s
Train Epoch: 36 	Average Loss: 3.0428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9014

Learning rate: 0.0001974526872786578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 3.8554	Cost: 32.14s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 2.9870	Cost: 9.56s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 2.8389	Cost: 12.02s
Train Epoch: 37 	Average Loss: 2.9733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8661

Learning rate: 0.00019730985109821272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 3.7000	Cost: 31.55s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 2.9646	Cost: 10.20s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 2.7857	Cost: 11.52s
Train Epoch: 38 	Average Loss: 2.9207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6853

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.00019716317329146745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 3.3903	Cost: 32.42s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 2.6492	Cost: 9.39s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 2.6796	Cost: 11.87s
Train Epoch: 39 	Average Loss: 2.8398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5286

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019701265964901062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 3.7954	Cost: 31.89s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 2.7696	Cost: 9.52s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 2.5419	Cost: 11.53s
Train Epoch: 40 	Average Loss: 2.7070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4448

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 3.6759	Cost: 32.38s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 2.6779	Cost: 9.44s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 2.3091	Cost: 11.91s
Train Epoch: 41 	Average Loss: 2.6797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4118

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019670014877624353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 3.4092	Cost: 32.04s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 2.5694	Cost: 9.39s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 2.4837	Cost: 12.33s
Train Epoch: 42 	Average Loss: 2.5839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6734

Learning rate: 0.0001965381638833274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 3.5107	Cost: 31.23s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 2.6890	Cost: 9.42s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 2.4598	Cost: 12.22s
Train Epoch: 43 	Average Loss: 2.6261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1892

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.000196372367829001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 3.2881	Cost: 31.22s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 2.5324	Cost: 9.59s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 2.0449	Cost: 11.84s
Train Epoch: 44 	Average Loss: 2.4304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3616

Learning rate: 0.00019620276715860861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 3.4297	Cost: 32.03s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 2.3677	Cost: 9.61s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 2.1712	Cost: 12.72s
Train Epoch: 45 	Average Loss: 2.4530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3422

Learning rate: 0.00019602936856769434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 3.0103	Cost: 32.28s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 2.2963	Cost: 9.56s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 2.1673	Cost: 12.14s
Train Epoch: 46 	Average Loss: 2.3763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3134

Learning rate: 0.00019585217890173763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 3.2814	Cost: 31.50s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 2.1591	Cost: 9.59s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 2.0623	Cost: 11.68s
Train Epoch: 47 	Average Loss: 2.3023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2405

Learning rate: 0.0001956712051558831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 3.1754	Cost: 31.60s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 2.1045	Cost: 9.42s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 1.8091	Cost: 12.42s
Train Epoch: 48 	Average Loss: 2.1779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2883

Learning rate: 0.00019548645447466434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 2.9634	Cost: 31.51s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 2.0052	Cost: 9.41s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 2.0166	Cost: 11.94s
Train Epoch: 49 	Average Loss: 2.1264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9893

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019529793415172192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 3.0531	Cost: 31.57s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 2.0943	Cost: 9.36s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 1.6806	Cost: 12.55s
Train Epoch: 50 	Average Loss: 2.0525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1524

Learning rate: 0.0001951056516295154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 2.9954	Cost: 30.86s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 1.9904	Cost: 9.38s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 1.7142	Cost: 11.83s
Train Epoch: 51 	Average Loss: 1.9899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1354

Learning rate: 0.0001949096144990295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 2.9489	Cost: 31.36s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 1.8593	Cost: 9.39s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 1.9395	Cost: 12.13s
Train Epoch: 52 	Average Loss: 2.0069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0873

Learning rate: 0.00019470983049947442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 2.9574	Cost: 31.90s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 1.6204	Cost: 9.37s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 1.9184	Cost: 12.66s
Train Epoch: 53 	Average Loss: 1.9157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9368

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 0.00019450630751798048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 3.0865	Cost: 31.32s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 1.7572	Cost: 9.40s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 1.8980	Cost: 11.80s
Train Epoch: 54 	Average Loss: 1.8810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0052

Learning rate: 0.00019429905358928646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 2.7470	Cost: 30.46s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 1.5284	Cost: 9.40s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 1.6173	Cost: 12.79s
Train Epoch: 55 	Average Loss: 1.7415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7800

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.00019408807689542257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 2.7788	Cost: 31.05s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 1.8512	Cost: 9.39s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 1.4372	Cost: 11.63s
Train Epoch: 56 	Average Loss: 1.8016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9768

Learning rate: 0.00019387338576538744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 2.8676	Cost: 32.15s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 1.6255	Cost: 9.41s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 1.5439	Cost: 11.88s
Train Epoch: 57 	Average Loss: 1.6896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8962

Learning rate: 0.00019365498867481926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 2.9177	Cost: 31.76s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 1.5270	Cost: 9.37s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 1.3399	Cost: 12.43s
Train Epoch: 58 	Average Loss: 1.6471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7482

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Learning rate: 0.00019343289424566122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 2.9607	Cost: 31.94s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 1.5924	Cost: 9.39s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 1.3316	Cost: 12.57s
Train Epoch: 59 	Average Loss: 1.5875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6825

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00019320711124582108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 2.9172	Cost: 31.72s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 1.4188	Cost: 9.39s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 1.6168	Cost: 12.36s
Train Epoch: 60 	Average Loss: 1.5724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7765

Learning rate: 0.00019297764858882514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 2.5155	Cost: 30.92s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 1.4116	Cost: 9.38s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 1.3823	Cost: 11.61s
Train Epoch: 61 	Average Loss: 1.5339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9006

Learning rate: 0.00019274451533346612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 3.1067	Cost: 31.70s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 1.5006	Cost: 9.43s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 1.1980	Cost: 12.92s
Train Epoch: 62 	Average Loss: 1.5149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6635

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019250772068344577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 2.6700	Cost: 30.65s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 1.3709	Cost: 9.40s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 1.0131	Cost: 11.69s
Train Epoch: 63 	Average Loss: 1.4016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5251

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 0.00019226727398701147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 2.7580	Cost: 31.65s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 0.9626	Cost: 9.38s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 1.1209	Cost: 12.05s
Train Epoch: 64 	Average Loss: 1.2942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6064

Learning rate: 0.00019202318473658702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 2.5068	Cost: 32.38s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 1.1302	Cost: 9.40s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 1.0861	Cost: 12.34s
Train Epoch: 65 	Average Loss: 1.3378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6450

Learning rate: 0.0001917754625683981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 2.5052	Cost: 31.59s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 0.9952	Cost: 9.39s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 1.0282	Cost: 11.92s
Train Epoch: 66 	Average Loss: 1.1869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6166

Learning rate: 0.00019152411726209174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 2.3274	Cost: 32.06s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 1.0543	Cost: 9.39s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 0.9348	Cost: 11.98s
Train Epoch: 67 	Average Loss: 1.2153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5918

Learning rate: 0.00019126915874035028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 2.6888	Cost: 31.55s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 1.0437	Cost: 9.41s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 0.9738	Cost: 12.44s
Train Epoch: 68 	Average Loss: 1.1349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5160

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 0.00019101059706849957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 2.2125	Cost: 31.55s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 0.9292	Cost: 9.43s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 0.9752	Cost: 12.18s
Train Epoch: 69 	Average Loss: 1.1351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5780

Learning rate: 0.0001907484424541117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 2.2856	Cost: 31.18s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 0.9473	Cost: 10.07s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 0.8624	Cost: 11.34s
Train Epoch: 70 	Average Loss: 1.0645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4100

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Learning rate: 0.00019048270524660196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 2.1494	Cost: 31.92s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 0.9698	Cost: 9.39s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 0.8567	Cost: 12.41s
Train Epoch: 71 	Average Loss: 1.0953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4905

Learning rate: 0.00019021339593682028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 2.2207	Cost: 31.58s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 0.7411	Cost: 9.39s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 0.8871	Cost: 12.19s
Train Epoch: 72 	Average Loss: 0.9935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3005

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 0.0001899405251566371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 2.3499	Cost: 31.35s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 0.7666	Cost: 9.40s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 0.8026	Cost: 12.16s
Train Epoch: 73 	Average Loss: 0.9051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3369

Learning rate: 0.0001896641036785236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 2.1764	Cost: 31.39s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 0.4266	Cost: 9.38s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 0.5129	Cost: 12.84s
Train Epoch: 74 	Average Loss: 0.8262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3607

Learning rate: 0.00018938414241512636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 2.2442	Cost: 31.61s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 0.5944	Cost: 9.38s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 0.5966	Cost: 12.70s
Train Epoch: 75 	Average Loss: 0.8267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2396

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 0.00018910065241883677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 2.1049	Cost: 32.32s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 0.7103	Cost: 9.37s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 0.4236	Cost: 12.48s
Train Epoch: 76 	Average Loss: 0.7528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0903

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00018881364488135445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 2.1324	Cost: 30.81s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 0.8415	Cost: 9.40s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 0.7569	Cost: 12.65s
Train Epoch: 77 	Average Loss: 0.8639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2544

Learning rate: 0.00018852313113324552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 2.3653	Cost: 32.24s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 0.7165	Cost: 9.41s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 1.2076	Cost: 12.40s
Train Epoch: 78 	Average Loss: 1.1278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7033

Learning rate: 0.00018822912264349534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 2.7588	Cost: 31.16s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 1.0067	Cost: 9.41s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 0.8864	Cost: 11.92s
Train Epoch: 79 	Average Loss: 1.1889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3382

Learning rate: 0.00018793163101905563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 2.2056	Cost: 31.41s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 0.7170	Cost: 9.43s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 0.6491	Cost: 11.93s
Train Epoch: 80 	Average Loss: 0.7844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2159

Learning rate: 0.00018763066800438636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 1.9113	Cost: 31.52s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 0.6579	Cost: 9.40s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 0.4412	Cost: 12.74s
Train Epoch: 81 	Average Loss: 0.6919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2626

Learning rate: 0.000187326245480992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 2.1761	Cost: 32.22s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 0.3382	Cost: 9.36s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 0.4052	Cost: 12.40s
Train Epoch: 82 	Average Loss: 0.6640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2667

Learning rate: 0.00018701837546695256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 2.0835	Cost: 30.94s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 0.4400	Cost: 9.41s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 0.2334	Cost: 12.62s
Train Epoch: 83 	Average Loss: 0.5143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1607

Learning rate: 0.00018670707011644898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 1.9801	Cost: 32.46s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 0.4926	Cost: 9.38s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 0.4263	Cost: 12.48s
Train Epoch: 84 	Average Loss: 0.5401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3503

Learning rate: 0.0001863923417192835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 2.0104	Cost: 31.46s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 0.5009	Cost: 9.38s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 0.2703	Cost: 11.64s
Train Epoch: 85 	Average Loss: 0.5916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0731

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Learning rate: 0.00018607420270039436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 2.0753	Cost: 32.12s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 0.3666	Cost: 9.38s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 0.2270	Cost: 12.03s
Train Epoch: 86 	Average Loss: 0.4753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9728

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 0.00018575266561936523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 1.8663	Cost: 31.83s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 0.3819	Cost: 9.36s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 0.1225	Cost: 12.56s
Train Epoch: 87 	Average Loss: 0.4193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1264

Learning rate: 0.0001854277431699295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 1.7885	Cost: 31.37s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 0.1079	Cost: 9.39s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 0.0105	Cost: 11.72s
Train Epoch: 88 	Average Loss: 0.3533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1412

Learning rate: 0.0001850994481794692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 1.6116	Cost: 31.06s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 0.2876	Cost: 9.41s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 0.2560	Cost: 11.76s
Train Epoch: 89 	Average Loss: 0.3700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8056

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 0.0001847677936085083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 1.7161	Cost: 31.96s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 0.0911	Cost: 9.50s
Train Epoch: 90 [81920/90000 (91%)]	Loss: -0.0189	Cost: 12.30s
Train Epoch: 90 	Average Loss: 0.2501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8648

Learning rate: 0.00018443279255020146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 1.8944	Cost: 30.77s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 0.1450	Cost: 9.41s
Train Epoch: 91 [81920/90000 (91%)]	Loss: -0.0225	Cost: 12.13s
Train Epoch: 91 	Average Loss: 0.1964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8289

Learning rate: 0.00018409445822981687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 1.4026	Cost: 32.43s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 0.1318	Cost: 9.37s
Train Epoch: 92 [81920/90000 (91%)]	Loss: -0.1315	Cost: 11.80s
Train Epoch: 92 	Average Loss: 0.1791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9663

Learning rate: 0.00018375280400421414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 1.8048	Cost: 30.96s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 0.0014	Cost: 9.40s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 0.0878	Cost: 11.79s
Train Epoch: 93 	Average Loss: 0.2562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8955

Learning rate: 0.00018340784336131708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 1.6835	Cost: 31.12s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 0.0213	Cost: 9.42s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 0.1624	Cost: 12.76s
Train Epoch: 94 	Average Loss: 0.2445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8539

Learning rate: 0.00018305958991958124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 1.5372	Cost: 31.19s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 0.0650	Cost: 9.41s
Train Epoch: 95 [81920/90000 (91%)]	Loss: -0.2310	Cost: 11.69s
Train Epoch: 95 	Average Loss: 0.1274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7818

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 1.5038	Cost: 30.68s
Train Epoch: 96 [40960/90000 (45%)]	Loss: -0.2231	Cost: 9.44s
Train Epoch: 96 [81920/90000 (91%)]	Loss: -0.0343	Cost: 12.02s
Train Epoch: 96 	Average Loss: 0.0604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7939

Learning rate: 0.0001823532597628427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 1.9104	Cost: 31.56s
Train Epoch: 97 [40960/90000 (45%)]	Loss: -0.0223	Cost: 9.38s
Train Epoch: 97 [81920/90000 (91%)]	Loss: -0.2861	Cost: 12.64s
Train Epoch: 97 	Average Loss: 0.1049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7192

Saving model as e97_model.pt & e97_waveforms_supplementary.hdf5
Learning rate: 0.0001819952109325452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 1.4495	Cost: 31.08s
Train Epoch: 98 [40960/90000 (45%)]	Loss: -0.4139	Cost: 9.40s
Train Epoch: 98 [81920/90000 (91%)]	Loss: -0.4091	Cost: 11.83s
Train Epoch: 98 	Average Loss: -0.0084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8780

Learning rate: 0.00018163392507171837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 1.6904	Cost: 32.16s
Train Epoch: 99 [40960/90000 (45%)]	Loss: -0.2560	Cost: 9.38s
Train Epoch: 99 [81920/90000 (91%)]	Loss: -0.4736	Cost: 12.61s
Train Epoch: 99 	Average Loss: -0.0382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6712

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Learning rate: 0.00018126941644330935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 1.4771	Cost: 32.28s
Train Epoch: 100 [40960/90000 (45%)]	Loss: -0.3581	Cost: 9.39s
Train Epoch: 100 [81920/90000 (91%)]	Loss: -0.2547	Cost: 12.74s
Train Epoch: 100 	Average Loss: -0.1037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5058

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 0.0001809016994374947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 1.2099	Cost: 30.48s
Train Epoch: 101 [40960/90000 (45%)]	Loss: -0.4196	Cost: 9.39s
Train Epoch: 101 [81920/90000 (91%)]	Loss: -0.4284	Cost: 12.93s
Train Epoch: 101 	Average Loss: -0.1728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5928

Learning rate: 0.00018053078857111214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 1.6421	Cost: 30.60s
Train Epoch: 102 [40960/90000 (45%)]	Loss: -0.3329	Cost: 9.40s
Train Epoch: 102 [81920/90000 (91%)]	Loss: -0.5030	Cost: 12.02s
Train Epoch: 102 	Average Loss: -0.1805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4701

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00018015669848708761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 1.5042	Cost: 31.16s
Train Epoch: 103 [40960/90000 (45%)]	Loss: -0.3409	Cost: 9.36s
Train Epoch: 103 [81920/90000 (91%)]	Loss: -0.4679	Cost: 12.37s
Train Epoch: 103 	Average Loss: -0.1843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5489

Learning rate: 0.00017977944395385705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 1.3102	Cost: 31.07s
Train Epoch: 104 [40960/90000 (45%)]	Loss: -0.6317	Cost: 9.41s
Train Epoch: 104 [81920/90000 (91%)]	Loss: -0.2323	Cost: 11.64s
Train Epoch: 104 	Average Loss: -0.2161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6544

Learning rate: 0.00017939903986478347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 1.5235	Cost: 32.03s
Train Epoch: 105 [40960/90000 (45%)]	Loss: -0.5002	Cost: 9.40s
Train Epoch: 105 [81920/90000 (91%)]	Loss: -0.8303	Cost: 12.34s
Train Epoch: 105 	Average Loss: -0.3162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4647

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00017901550123756898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 1.5924	Cost: 32.94s
Train Epoch: 106 [40960/90000 (45%)]	Loss: -0.4913	Cost: 9.36s
Train Epoch: 106 [81920/90000 (91%)]	Loss: -0.6807	Cost: 12.68s
Train Epoch: 106 	Average Loss: -0.3657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4630

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 0.00017862884321366183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 1.0479	Cost: 31.90s
Train Epoch: 107 [40960/90000 (45%)]	Loss: -0.7977	Cost: 9.40s
Train Epoch: 107 [81920/90000 (91%)]	Loss: -0.6027	Cost: 11.79s
Train Epoch: 107 	Average Loss: -0.4323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5321

Learning rate: 0.00017823908105765875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 0.9457	Cost: 31.40s
Train Epoch: 108 [40960/90000 (45%)]	Loss: -0.5690	Cost: 9.39s
Train Epoch: 108 [81920/90000 (91%)]	Loss: -0.6584	Cost: 12.10s
Train Epoch: 108 	Average Loss: -0.3998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5275

Learning rate: 0.00017784623015670232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 1.3030	Cost: 32.39s
Train Epoch: 109 [40960/90000 (45%)]	Loss: -0.4564	Cost: 9.34s
Train Epoch: 109 [81920/90000 (91%)]	Loss: -0.8138	Cost: 12.53s
Train Epoch: 109 	Average Loss: -0.4330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5862

Learning rate: 0.00017745030601987337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 1.1655	Cost: 32.02s
Train Epoch: 110 [40960/90000 (45%)]	Loss: -0.7166	Cost: 9.38s
Train Epoch: 110 [81920/90000 (91%)]	Loss: -0.7391	Cost: 12.45s
Train Epoch: 110 	Average Loss: -0.4724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4470

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 0.0001770513242775789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 1.1962	Cost: 30.99s
Train Epoch: 111 [40960/90000 (45%)]	Loss: -0.6836	Cost: 9.40s
Train Epoch: 111 [81920/90000 (91%)]	Loss: -0.7930	Cost: 12.35s
Train Epoch: 111 	Average Loss: -0.4324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5314

Learning rate: 0.00017664930068093498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 1.3441	Cost: 31.33s
Train Epoch: 112 [40960/90000 (45%)]	Loss: -0.6747	Cost: 9.43s
Train Epoch: 112 [81920/90000 (91%)]	Loss: -0.6735	Cost: 11.70s
Train Epoch: 112 	Average Loss: -0.5026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3676

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Learning rate: 0.0001762442511011448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 1.3337	Cost: 32.77s
Train Epoch: 113 [40960/90000 (45%)]	Loss: -0.5341	Cost: 9.41s
Train Epoch: 113 [81920/90000 (91%)]	Loss: -0.6523	Cost: 12.27s
Train Epoch: 113 	Average Loss: -0.5604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4561

Learning rate: 0.0001758361915288722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 1.1546	Cost: 31.04s
Train Epoch: 114 [40960/90000 (45%)]	Loss: -0.8037	Cost: 9.40s
Train Epoch: 114 [81920/90000 (91%)]	Loss: -0.7707	Cost: 12.13s
Train Epoch: 114 	Average Loss: -0.6147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4600

Learning rate: 0.0001754251380736104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 1.1310	Cost: 32.31s
Train Epoch: 115 [40960/90000 (45%)]	Loss: -0.8102	Cost: 9.40s
Train Epoch: 115 [81920/90000 (91%)]	Loss: -1.0342	Cost: 12.49s
Train Epoch: 115 	Average Loss: -0.6169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4100

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 1.4284	Cost: 31.69s
Train Epoch: 116 [40960/90000 (45%)]	Loss: -0.7833	Cost: 9.41s
Train Epoch: 116 [81920/90000 (91%)]	Loss: -0.9080	Cost: 11.94s
Train Epoch: 116 	Average Loss: -0.6223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2425

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Learning rate: 0.00017459411454241822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 1.3642	Cost: 31.34s
Train Epoch: 117 [40960/90000 (45%)]	Loss: -0.9789	Cost: 9.40s
Train Epoch: 117 [81920/90000 (91%)]	Loss: -1.0964	Cost: 12.33s
Train Epoch: 117 	Average Loss: -0.6694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1584

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 0.00017417417727387391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 0.8863	Cost: 31.07s
Train Epoch: 118 [40960/90000 (45%)]	Loss: -0.7732	Cost: 10.05s
Train Epoch: 118 [81920/90000 (91%)]	Loss: -0.8198	Cost: 11.83s
Train Epoch: 118 	Average Loss: -0.7188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2034

Learning rate: 0.00017375131173581737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 0.9833	Cost: 31.15s
Train Epoch: 119 [40960/90000 (45%)]	Loss: -0.7523	Cost: 9.40s
Train Epoch: 119 [81920/90000 (91%)]	Loss: -0.7326	Cost: 11.88s
Train Epoch: 119 	Average Loss: -0.7034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3093

Learning rate: 0.000173325534622256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 0.8890	Cost: 32.42s
Train Epoch: 120 [40960/90000 (45%)]	Loss: -0.8153	Cost: 9.39s
Train Epoch: 120 [81920/90000 (91%)]	Loss: -0.9513	Cost: 12.88s
Train Epoch: 120 	Average Loss: -0.7428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2739

Learning rate: 0.00017289686274214115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 1.0400	Cost: 31.10s
Train Epoch: 121 [40960/90000 (45%)]	Loss: -1.0106	Cost: 9.46s
Train Epoch: 121 [81920/90000 (91%)]	Loss: -1.1526	Cost: 12.22s
Train Epoch: 121 	Average Loss: -0.8089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4875

Learning rate: 0.00017246531301870466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 1.1906	Cost: 31.47s
Train Epoch: 122 [40960/90000 (45%)]	Loss: -1.0874	Cost: 9.42s
Train Epoch: 122 [81920/90000 (91%)]	Loss: -1.0251	Cost: 12.62s
Train Epoch: 122 	Average Loss: -0.8225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1761

Learning rate: 0.00017203090248879067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 0.9477	Cost: 31.47s
Train Epoch: 123 [40960/90000 (45%)]	Loss: -1.2071	Cost: 9.41s
Train Epoch: 123 [81920/90000 (91%)]	Loss: -1.3279	Cost: 12.08s
Train Epoch: 123 	Average Loss: -0.8877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2750

Learning rate: 0.00017159364830218312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 1.2505	Cost: 30.93s
Train Epoch: 124 [40960/90000 (45%)]	Loss: -1.0720	Cost: 9.41s
Train Epoch: 124 [81920/90000 (91%)]	Loss: -1.3687	Cost: 11.69s
Train Epoch: 124 	Average Loss: -0.9306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1120

Saving model as e124_model.pt & e124_waveforms_supplementary.hdf5
Learning rate: 0.00017115356772092854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 1.0270	Cost: 32.21s
Train Epoch: 125 [40960/90000 (45%)]	Loss: -1.2143	Cost: 9.40s
Train Epoch: 125 [81920/90000 (91%)]	Loss: -1.3167	Cost: 12.76s
Train Epoch: 125 	Average Loss: -1.0188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1372

Learning rate: 0.00017071067811865473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 1.1504	Cost: 32.03s
Train Epoch: 126 [40960/90000 (45%)]	Loss: -1.1692	Cost: 9.39s
Train Epoch: 126 [81920/90000 (91%)]	Loss: -1.3612	Cost: 12.48s
Train Epoch: 126 	Average Loss: -1.0274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9076

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Learning rate: 0.00017026499697988493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 1.2397	Cost: 31.50s
Train Epoch: 127 [40960/90000 (45%)]	Loss: -1.3177	Cost: 9.37s
Train Epoch: 127 [81920/90000 (91%)]	Loss: -0.9876	Cost: 11.70s
Train Epoch: 127 	Average Loss: -0.9445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1873

Learning rate: 0.00016981654189934727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 1.0556	Cost: 31.00s
Train Epoch: 128 [40960/90000 (45%)]	Loss: -1.1046	Cost: 9.39s
Train Epoch: 128 [81920/90000 (91%)]	Loss: -1.1803	Cost: 12.21s
Train Epoch: 128 	Average Loss: -0.8949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0421

Learning rate: 0.0001693653305812805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 0.8900	Cost: 32.40s
Train Epoch: 129 [40960/90000 (45%)]	Loss: -1.1692	Cost: 9.39s
Train Epoch: 129 [81920/90000 (91%)]	Loss: -1.4155	Cost: 12.59s
Train Epoch: 129 	Average Loss: -1.0702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9866

Learning rate: 0.00016891138083873484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 0.6958	Cost: 30.89s
Train Epoch: 130 [40960/90000 (45%)]	Loss: -1.0645	Cost: 9.40s
Train Epoch: 130 [81920/90000 (91%)]	Loss: -1.4439	Cost: 12.00s
Train Epoch: 130 	Average Loss: -1.1455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8984

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 0.00016845471059286887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 0.6442	Cost: 30.78s
Train Epoch: 131 [40960/90000 (45%)]	Loss: -1.5120	Cost: 9.41s
Train Epoch: 131 [81920/90000 (91%)]	Loss: -1.4447	Cost: 11.79s
Train Epoch: 131 	Average Loss: -1.2654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1690

Learning rate: 0.0001679953378722419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 1.0774	Cost: 30.91s
Train Epoch: 132 [40960/90000 (45%)]	Loss: -1.3746	Cost: 9.42s
Train Epoch: 132 [81920/90000 (91%)]	Loss: -1.5548	Cost: 11.73s
Train Epoch: 132 	Average Loss: -1.2113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9912

Learning rate: 0.00016753328081210242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 1.0011	Cost: 30.66s
Train Epoch: 133 [40960/90000 (45%)]	Loss: -1.2168	Cost: 9.38s
Train Epoch: 133 [81920/90000 (91%)]	Loss: -1.4732	Cost: 12.33s
Train Epoch: 133 	Average Loss: -1.2153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0743

Learning rate: 0.000167068557653672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 0.5282	Cost: 31.93s
Train Epoch: 134 [40960/90000 (45%)]	Loss: -1.3874	Cost: 9.42s
Train Epoch: 134 [81920/90000 (91%)]	Loss: -1.6371	Cost: 12.56s
Train Epoch: 134 	Average Loss: -1.1875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0146

Learning rate: 0.00016660118674342514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 0.6305	Cost: 32.56s
Train Epoch: 135 [40960/90000 (45%)]	Loss: -1.5837	Cost: 9.36s
Train Epoch: 135 [81920/90000 (91%)]	Loss: -1.7224	Cost: 12.13s
Train Epoch: 135 	Average Loss: -1.3359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9190

Learning rate: 0.00016613118653236516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 0.7955	Cost: 31.66s
Train Epoch: 136 [40960/90000 (45%)]	Loss: -1.4641	Cost: 9.39s
Train Epoch: 136 [81920/90000 (91%)]	Loss: -1.7654	Cost: 12.10s
Train Epoch: 136 	Average Loss: -1.3769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9434

Learning rate: 0.0001656585755752956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 0.7252	Cost: 31.33s
Train Epoch: 137 [40960/90000 (45%)]	Loss: -1.5674	Cost: 9.38s
Train Epoch: 137 [81920/90000 (91%)]	Loss: -1.5335	Cost: 12.15s
Train Epoch: 137 	Average Loss: -1.3719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8738

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 0.00016518337253008784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 0.5321	Cost: 31.57s
Train Epoch: 138 [40960/90000 (45%)]	Loss: -1.6245	Cost: 9.60s
Train Epoch: 138 [81920/90000 (91%)]	Loss: -1.7571	Cost: 11.78s
Train Epoch: 138 	Average Loss: -1.4028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9253

Learning rate: 0.0001647055961569444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 0.6065	Cost: 31.08s
Train Epoch: 139 [40960/90000 (45%)]	Loss: -1.6069	Cost: 9.39s
Train Epoch: 139 [81920/90000 (91%)]	Loss: -1.6357	Cost: 12.69s
Train Epoch: 139 	Average Loss: -1.3864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1082

Learning rate: 0.0001642252653176584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 0.8926	Cost: 31.96s
Train Epoch: 140 [40960/90000 (45%)]	Loss: -1.2545	Cost: 9.40s
Train Epoch: 140 [81920/90000 (91%)]	Loss: -1.4671	Cost: 11.90s
Train Epoch: 140 	Average Loss: -1.2569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9830

Learning rate: 0.00016374239897486894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 0.5670	Cost: 30.91s
Train Epoch: 141 [40960/90000 (45%)]	Loss: -1.6654	Cost: 9.39s
Train Epoch: 141 [81920/90000 (91%)]	Loss: -1.8974	Cost: 11.64s
Train Epoch: 141 	Average Loss: -1.4207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8995

Learning rate: 0.0001632570161913124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 0.6805	Cost: 33.12s
Train Epoch: 142 [40960/90000 (45%)]	Loss: -1.6387	Cost: 9.39s
Train Epoch: 142 [81920/90000 (91%)]	Loss: -1.8672	Cost: 12.29s
Train Epoch: 142 	Average Loss: -1.5060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6766

Saving model as e142_model.pt & e142_waveforms_supplementary.hdf5
Learning rate: 0.00016276913612907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 0.8385	Cost: 32.42s
Train Epoch: 143 [40960/90000 (45%)]	Loss: -1.9079	Cost: 9.40s
Train Epoch: 143 [81920/90000 (91%)]	Loss: -2.0413	Cost: 12.16s
Train Epoch: 143 	Average Loss: -1.5884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6289

Saving model as e143_model.pt & e143_waveforms_supplementary.hdf5
Learning rate: 0.00016227877804881122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 0.2077	Cost: 31.61s
Train Epoch: 144 [40960/90000 (45%)]	Loss: -1.8515	Cost: 9.40s
Train Epoch: 144 [81920/90000 (91%)]	Loss: -1.7637	Cost: 12.44s
Train Epoch: 144 	Average Loss: -1.5845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9334

Learning rate: 0.0001617859613090334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 0.4621	Cost: 31.53s
Train Epoch: 145 [40960/90000 (45%)]	Loss: -1.8170	Cost: 9.39s
Train Epoch: 145 [81920/90000 (91%)]	Loss: -1.9300	Cost: 11.59s
Train Epoch: 145 	Average Loss: -1.5791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7861

Learning rate: 0.00016129070536529763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 0.4453	Cost: 31.94s
Train Epoch: 146 [40960/90000 (45%)]	Loss: -1.9117	Cost: 9.36s
Train Epoch: 146 [81920/90000 (91%)]	Loss: -1.7805	Cost: 12.11s
Train Epoch: 146 	Average Loss: -1.6605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8754

Learning rate: 0.00016079302976946053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 0.2718	Cost: 31.52s
Train Epoch: 147 [40960/90000 (45%)]	Loss: -1.7703	Cost: 9.39s
Train Epoch: 147 [81920/90000 (91%)]	Loss: -1.6758	Cost: 12.61s
Train Epoch: 147 	Average Loss: -1.6335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9992

Learning rate: 0.00016029295416890245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 0.4766	Cost: 31.46s
Train Epoch: 148 [40960/90000 (45%)]	Loss: -1.7869	Cost: 9.40s
Train Epoch: 148 [81920/90000 (91%)]	Loss: -1.9094	Cost: 11.96s
Train Epoch: 148 	Average Loss: -1.6006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7605

Learning rate: 0.00015979049830575187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 0.7805	Cost: 31.16s
Train Epoch: 149 [40960/90000 (45%)]	Loss: -1.8712	Cost: 9.39s
Train Epoch: 149 [81920/90000 (91%)]	Loss: -1.9398	Cost: 12.00s
Train Epoch: 149 	Average Loss: -1.6398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6833

Learning rate: 0.00015928568201610592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 0.6462	Cost: 30.75s
Train Epoch: 150 [40960/90000 (45%)]	Loss: -1.8879	Cost: 9.42s
Train Epoch: 150 [81920/90000 (91%)]	Loss: -2.1002	Cost: 12.90s
Train Epoch: 150 	Average Loss: -1.6520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6777

Learning rate: 0.00015877852522924732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 0.3126	Cost: 31.75s
Train Epoch: 151 [40960/90000 (45%)]	Loss: -2.2453	Cost: 9.40s
Train Epoch: 151 [81920/90000 (91%)]	Loss: -1.9753	Cost: 11.70s
Train Epoch: 151 	Average Loss: -1.8374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7794

Learning rate: 0.00015826904796685762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 0.0899	Cost: 31.14s
Train Epoch: 152 [40960/90000 (45%)]	Loss: -2.0901	Cost: 9.41s
Train Epoch: 152 [81920/90000 (91%)]	Loss: -2.1882	Cost: 12.71s
Train Epoch: 152 	Average Loss: -1.9164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7417

Learning rate: 0.00015775727034222675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 0.1495	Cost: 32.40s
Train Epoch: 153 [40960/90000 (45%)]	Loss: -1.9901	Cost: 9.35s
Train Epoch: 153 [81920/90000 (91%)]	Loss: -2.0314	Cost: 12.30s
Train Epoch: 153 	Average Loss: -1.8416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6954

Learning rate: 0.00015724321255945907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 0.2131	Cost: 32.45s
Train Epoch: 154 [40960/90000 (45%)]	Loss: -2.0675	Cost: 9.34s
Train Epoch: 154 [81920/90000 (91%)]	Loss: -1.9568	Cost: 12.25s
Train Epoch: 154 	Average Loss: -1.7416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7900

Learning rate: 0.00015672689491267567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 0.5471	Cost: 31.57s
Train Epoch: 155 [40960/90000 (45%)]	Loss: -2.2090	Cost: 9.42s
Train Epoch: 155 [81920/90000 (91%)]	Loss: -2.2330	Cost: 12.00s
Train Epoch: 155 	Average Loss: -1.8308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7099

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 0.1986	Cost: 32.27s
Train Epoch: 156 [40960/90000 (45%)]	Loss: -1.9841	Cost: 9.39s
Train Epoch: 156 [81920/90000 (91%)]	Loss: -1.9768	Cost: 12.56s
Train Epoch: 156 	Average Loss: -1.9176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6882

Learning rate: 0.00015568756164881882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 0.7238	Cost: 31.16s
Train Epoch: 157 [40960/90000 (45%)]	Loss: -2.2847	Cost: 9.42s
Train Epoch: 157 [81920/90000 (91%)]	Loss: -2.2933	Cost: 11.68s
Train Epoch: 157 	Average Loss: -1.9286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5108

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Learning rate: 0.00015516458706284303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 0.2895	Cost: 31.05s
Train Epoch: 158 [40960/90000 (45%)]	Loss: -2.3628	Cost: 9.40s
Train Epoch: 158 [81920/90000 (91%)]	Loss: -2.3923	Cost: 11.54s
Train Epoch: 158 	Average Loss: -2.0698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4426

Saving model as e158_model.pt & e158_waveforms_supplementary.hdf5
Learning rate: 0.0001546394346734269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 0.0254	Cost: 31.59s
Train Epoch: 159 [40960/90000 (45%)]	Loss: -2.1912	Cost: 9.36s
Train Epoch: 159 [81920/90000 (91%)]	Loss: -2.4610	Cost: 12.61s
Train Epoch: 159 	Average Loss: -2.1157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3638

Saving model as e159_model.pt & e159_waveforms_supplementary.hdf5
Learning rate: 0.00015411212521268755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 0.3021	Cost: 30.76s
Train Epoch: 160 [40960/90000 (45%)]	Loss: -2.4770	Cost: 9.40s
Train Epoch: 160 [81920/90000 (91%)]	Loss: -2.5115	Cost: 12.45s
Train Epoch: 160 	Average Loss: -2.1472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3811

Learning rate: 0.00015358267949789963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 0.3452	Cost: 32.56s
Train Epoch: 161 [40960/90000 (45%)]	Loss: -2.3903	Cost: 9.36s
Train Epoch: 161 [81920/90000 (91%)]	Loss: -2.3509	Cost: 12.20s
Train Epoch: 161 	Average Loss: -2.1833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6026

Learning rate: 0.00015305111843067339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: -0.0520	Cost: 32.17s
Train Epoch: 162 [40960/90000 (45%)]	Loss: -2.5175	Cost: 9.41s
Train Epoch: 162 [81920/90000 (91%)]	Loss: -2.6159	Cost: 12.73s
Train Epoch: 162 	Average Loss: -2.2195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3491

Saving model as e162_model.pt & e162_waveforms_supplementary.hdf5
Learning rate: 0.00015251746299612957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 0.2372	Cost: 31.81s
Train Epoch: 163 [40960/90000 (45%)]	Loss: -2.3671	Cost: 9.40s
Train Epoch: 163 [81920/90000 (91%)]	Loss: -2.4696	Cost: 12.09s
Train Epoch: 163 	Average Loss: -2.2359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3422

Saving model as e163_model.pt & e163_waveforms_supplementary.hdf5
Learning rate: 0.00015198173426207094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 0.2074	Cost: 30.97s
Train Epoch: 164 [40960/90000 (45%)]	Loss: -2.4941	Cost: 9.40s
Train Epoch: 164 [81920/90000 (91%)]	Loss: -2.4727	Cost: 11.88s
Train Epoch: 164 	Average Loss: -2.1585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4409

Learning rate: 0.00015144395337815067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: -0.0278	Cost: 31.38s
Train Epoch: 165 [40960/90000 (45%)]	Loss: -2.3479	Cost: 9.41s
Train Epoch: 165 [81920/90000 (91%)]	Loss: -2.5168	Cost: 12.55s
Train Epoch: 165 	Average Loss: -2.2092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3724

Learning rate: 0.00015090414157503714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 0.1003	Cost: 31.21s
Train Epoch: 166 [40960/90000 (45%)]	Loss: -2.5031	Cost: 9.58s
Train Epoch: 166 [81920/90000 (91%)]	Loss: -2.5212	Cost: 11.80s
Train Epoch: 166 	Average Loss: -2.3139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3842

Learning rate: 0.00015036232016357607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 0.0142	Cost: 31.14s
Train Epoch: 167 [40960/90000 (45%)]	Loss: -2.5281	Cost: 9.60s
Train Epoch: 167 [81920/90000 (91%)]	Loss: -2.7037	Cost: 12.38s
Train Epoch: 167 	Average Loss: -2.3683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2179

Saving model as e167_model.pt & e167_waveforms_supplementary.hdf5
Learning rate: 0.00014981851053394907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 0.0646	Cost: 31.28s
Train Epoch: 168 [40960/90000 (45%)]	Loss: -2.8151	Cost: 9.60s
Train Epoch: 168 [81920/90000 (91%)]	Loss: -2.7385	Cost: 12.27s
Train Epoch: 168 	Average Loss: -2.3809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3187

Learning rate: 0.00014927273415482915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: -0.0575	Cost: 30.90s
Train Epoch: 169 [40960/90000 (45%)]	Loss: -2.5270	Cost: 9.42s
Train Epoch: 169 [81920/90000 (91%)]	Loss: -2.6941	Cost: 12.80s
Train Epoch: 169 	Average Loss: -2.4448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1803

Saving model as e169_model.pt & e169_waveforms_supplementary.hdf5
Learning rate: 0.00014872501257253323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: -0.1567	Cost: 30.00s
Train Epoch: 170 [40960/90000 (45%)]	Loss: -2.7732	Cost: 9.91s
Train Epoch: 170 [81920/90000 (91%)]	Loss: -2.9339	Cost: 12.67s
Train Epoch: 170 	Average Loss: -2.4825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3336

Learning rate: 0.00014817536741017152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: -0.1141	Cost: 35.25s
Train Epoch: 171 [40960/90000 (45%)]	Loss: -2.9895	Cost: 9.61s
Train Epoch: 171 [81920/90000 (91%)]	Loss: -2.8082	Cost: 12.45s
Train Epoch: 171 	Average Loss: -2.5283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3006

Learning rate: 0.0001476238203667939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 0.1303	Cost: 33.94s
Train Epoch: 172 [40960/90000 (45%)]	Loss: -2.8044	Cost: 9.54s
Train Epoch: 172 [81920/90000 (91%)]	Loss: -2.6870	Cost: 12.47s
Train Epoch: 172 	Average Loss: -2.5494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2006

Learning rate: 0.00014707039321653327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: -0.3469	Cost: 32.22s
Train Epoch: 173 [40960/90000 (45%)]	Loss: -2.7934	Cost: 9.55s
Train Epoch: 173 [81920/90000 (91%)]	Loss: -2.8069	Cost: 11.65s
Train Epoch: 173 	Average Loss: -2.3996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3240

Learning rate: 0.00014651510780774586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: -0.0618	Cost: 32.77s
Train Epoch: 174 [40960/90000 (45%)]	Loss: -2.5998	Cost: 9.57s
Train Epoch: 174 [81920/90000 (91%)]	Loss: -2.7008	Cost: 12.22s
Train Epoch: 174 	Average Loss: -2.3195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3715

Learning rate: 0.00014595798606214882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 0.0016	Cost: 31.42s
Train Epoch: 175 [40960/90000 (45%)]	Loss: -2.6964	Cost: 9.54s
Train Epoch: 175 [81920/90000 (91%)]	Loss: -2.9412	Cost: 12.38s
Train Epoch: 175 	Average Loss: -2.4236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1945

Learning rate: 0.00014539904997395468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: -0.1520	Cost: 31.78s
Train Epoch: 176 [40960/90000 (45%)]	Loss: -2.7924	Cost: 9.98s
Train Epoch: 176 [81920/90000 (91%)]	Loss: -2.9895	Cost: 11.89s
Train Epoch: 176 	Average Loss: -2.5638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1795

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Learning rate: 0.00014483832160900326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: -0.2510	Cost: 31.36s
Train Epoch: 177 [40960/90000 (45%)]	Loss: -2.7659	Cost: 9.44s
Train Epoch: 177 [81920/90000 (91%)]	Loss: -3.0017	Cost: 12.66s
Train Epoch: 177 	Average Loss: -2.6353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1537

Saving model as e177_model.pt & e177_waveforms_supplementary.hdf5
Learning rate: 0.00014427582310389016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: -0.2678	Cost: 31.29s
Train Epoch: 178 [40960/90000 (45%)]	Loss: -2.9399	Cost: 9.41s
Train Epoch: 178 [81920/90000 (91%)]	Loss: -2.9981	Cost: 12.18s
Train Epoch: 178 	Average Loss: -2.6577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0683

Saving model as e178_model.pt & e178_waveforms_supplementary.hdf5
Learning rate: 0.0001437115766650933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: -0.1630	Cost: 31.15s
Train Epoch: 179 [40960/90000 (45%)]	Loss: -2.9440	Cost: 9.41s
Train Epoch: 179 [81920/90000 (91%)]	Loss: -3.1148	Cost: 12.21s
Train Epoch: 179 	Average Loss: -2.6560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1389

Learning rate: 0.0001431456045680959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 0.0986	Cost: 30.93s
Train Epoch: 180 [40960/90000 (45%)]	Loss: -3.0324	Cost: 9.39s
Train Epoch: 180 [81920/90000 (91%)]	Loss: -2.8429	Cost: 12.14s
Train Epoch: 180 	Average Loss: -2.6879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1741

Learning rate: 0.00014257792915650726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: -0.2937	Cost: 32.72s
Train Epoch: 181 [40960/90000 (45%)]	Loss: -2.8212	Cost: 9.42s
Train Epoch: 181 [81920/90000 (91%)]	Loss: -2.9518	Cost: 12.36s
Train Epoch: 181 	Average Loss: -2.6018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1390

Learning rate: 0.0001420085728411806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 0.1352	Cost: 31.48s
Train Epoch: 182 [40960/90000 (45%)]	Loss: -2.9097	Cost: 9.42s
Train Epoch: 182 [81920/90000 (91%)]	Loss: -2.9738	Cost: 11.74s
Train Epoch: 182 	Average Loss: -2.6774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1004

Learning rate: 0.0001414375580993284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: -0.3526	Cost: 31.19s
Train Epoch: 183 [40960/90000 (45%)]	Loss: -3.1862	Cost: 9.61s
Train Epoch: 183 [81920/90000 (91%)]	Loss: -3.2310	Cost: 12.63s
Train Epoch: 183 	Average Loss: -2.7997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0882

Learning rate: 0.00014086490747363488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: -0.0261	Cost: 33.09s
Train Epoch: 184 [40960/90000 (45%)]	Loss: -3.1498	Cost: 9.52s
Train Epoch: 184 [81920/90000 (91%)]	Loss: -3.1390	Cost: 12.23s
Train Epoch: 184 	Average Loss: -2.8266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0386

Saving model as e184_model.pt & e184_waveforms_supplementary.hdf5
Learning rate: 0.00014029064357136623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: -0.3386	Cost: 31.81s
Train Epoch: 185 [40960/90000 (45%)]	Loss: -3.1123	Cost: 9.41s
Train Epoch: 185 [81920/90000 (91%)]	Loss: -3.2927	Cost: 12.18s
Train Epoch: 185 	Average Loss: -2.8400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9630

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Learning rate: 0.00013971478906347803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: -0.2195	Cost: 30.39s
Train Epoch: 186 [40960/90000 (45%)]	Loss: -3.0157	Cost: 9.40s
Train Epoch: 186 [81920/90000 (91%)]	Loss: -3.1397	Cost: 11.96s
Train Epoch: 186 	Average Loss: -2.7909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1236

Learning rate: 0.0001391373666837202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: -0.5477	Cost: 32.33s
Train Epoch: 187 [40960/90000 (45%)]	Loss: -2.9974	Cost: 9.35s
Train Epoch: 187 [81920/90000 (91%)]	Loss: -3.2725	Cost: 12.24s
Train Epoch: 187 	Average Loss: -2.8382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0840

Learning rate: 0.0001385583992277396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: -0.2063	Cost: 32.41s
Train Epoch: 188 [40960/90000 (45%)]	Loss: -3.1062	Cost: 9.39s
Train Epoch: 188 [81920/90000 (91%)]	Loss: -3.3019	Cost: 12.28s
Train Epoch: 188 	Average Loss: -2.8309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9426

Saving model as e188_model.pt & e188_waveforms_supplementary.hdf5
Learning rate: 0.00013797790955218008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: -0.4682	Cost: 30.99s
Train Epoch: 189 [40960/90000 (45%)]	Loss: -3.2148	Cost: 9.39s
Train Epoch: 189 [81920/90000 (91%)]	Loss: -3.3689	Cost: 11.68s
Train Epoch: 189 	Average Loss: -3.0242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0169

Learning rate: 0.00013739592057378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: -0.6388	Cost: 32.42s
Train Epoch: 190 [40960/90000 (45%)]	Loss: -3.2512	Cost: 9.39s
Train Epoch: 190 [81920/90000 (91%)]	Loss: -3.2263	Cost: 12.45s
Train Epoch: 190 	Average Loss: -3.0074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0330

Learning rate: 0.00013681245526846775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: -0.5563	Cost: 31.59s
Train Epoch: 191 [40960/90000 (45%)]	Loss: -3.3966	Cost: 9.40s
Train Epoch: 191 [81920/90000 (91%)]	Loss: -3.1586	Cost: 12.78s
Train Epoch: 191 	Average Loss: -2.9710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1402

Learning rate: 0.00013622753667045454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: -0.4554	Cost: 32.15s
Train Epoch: 192 [40960/90000 (45%)]	Loss: -3.2048	Cost: 9.41s
Train Epoch: 192 [81920/90000 (91%)]	Loss: -3.4923	Cost: 12.14s
Train Epoch: 192 	Average Loss: -2.9487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0400

Learning rate: 0.00013564118787132503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: -0.4673	Cost: 32.03s
Train Epoch: 193 [40960/90000 (45%)]	Loss: -3.1385	Cost: 9.38s
Train Epoch: 193 [81920/90000 (91%)]	Loss: -3.4661	Cost: 12.42s
Train Epoch: 193 	Average Loss: -2.9909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8072

Saving model as e193_model.pt & e193_waveforms_supplementary.hdf5
Learning rate: 0.00013505343201912587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: -0.5568	Cost: 30.85s
Train Epoch: 194 [40960/90000 (45%)]	Loss: -3.1873	Cost: 9.39s
Train Epoch: 194 [81920/90000 (91%)]	Loss: -3.5416	Cost: 11.83s
Train Epoch: 194 	Average Loss: -3.1273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8157

Learning rate: 0.0001344642923174517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: -0.3893	Cost: 30.87s
Train Epoch: 195 [40960/90000 (45%)]	Loss: -3.3878	Cost: 9.40s
Train Epoch: 195 [81920/90000 (91%)]	Loss: -3.6249	Cost: 12.05s
Train Epoch: 195 	Average Loss: -3.2008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7942

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Learning rate: 0.00013387379202452914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: -0.7346	Cost: 32.48s
Train Epoch: 196 [40960/90000 (45%)]	Loss: -3.5486	Cost: 9.38s
Train Epoch: 196 [81920/90000 (91%)]	Loss: -3.4991	Cost: 12.17s
Train Epoch: 196 	Average Loss: -3.2272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7362

Saving model as e196_model.pt & e196_waveforms_supplementary.hdf5
Learning rate: 0.00013328195445229865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: -0.5142	Cost: 31.60s
Train Epoch: 197 [40960/90000 (45%)]	Loss: -3.4507	Cost: 9.39s
Train Epoch: 197 [81920/90000 (91%)]	Loss: -3.5611	Cost: 11.95s
Train Epoch: 197 	Average Loss: -3.2231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8199

Learning rate: 0.00013268880296549425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: -0.3331	Cost: 32.48s
Train Epoch: 198 [40960/90000 (45%)]	Loss: -3.3382	Cost: 9.44s
Train Epoch: 198 [81920/90000 (91%)]	Loss: -3.5239	Cost: 12.32s
Train Epoch: 198 	Average Loss: -3.1889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8349

Learning rate: 0.00013209436098072093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: -0.7176	Cost: 31.56s
Train Epoch: 199 [40960/90000 (45%)]	Loss: -3.3622	Cost: 10.06s
Train Epoch: 199 [81920/90000 (91%)]	Loss: -3.7691	Cost: 12.21s
Train Epoch: 199 	Average Loss: -3.3063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7500

Learning rate: 0.00013149865196553047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: -0.6501	Cost: 32.41s
Train Epoch: 200 [40960/90000 (45%)]	Loss: -3.4505	Cost: 9.40s
Train Epoch: 200 [81920/90000 (91%)]	Loss: -3.6811	Cost: 12.81s
Train Epoch: 200 	Average Loss: -3.3000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6786

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 0.00013090169943749474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: -0.6035	Cost: 31.49s
Train Epoch: 201 [40960/90000 (45%)]	Loss: -3.5227	Cost: 9.39s
Train Epoch: 201 [81920/90000 (91%)]	Loss: -3.6996	Cost: 12.14s
Train Epoch: 201 	Average Loss: -3.3488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6468

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 0.0001303035269632774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: -0.5159	Cost: 31.31s
Train Epoch: 202 [40960/90000 (45%)]	Loss: -3.7190	Cost: 9.38s
Train Epoch: 202 [81920/90000 (91%)]	Loss: -3.7613	Cost: 11.69s
Train Epoch: 202 	Average Loss: -3.3419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7505

Learning rate: 0.00012970415815770348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: -0.6541	Cost: 32.12s
Train Epoch: 203 [40960/90000 (45%)]	Loss: -3.7435	Cost: 9.42s
Train Epoch: 203 [81920/90000 (91%)]	Loss: -3.6738	Cost: 12.47s
Train Epoch: 203 	Average Loss: -3.3442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5223

Saving model as e203_model.pt & e203_waveforms_supplementary.hdf5
Learning rate: 0.00012910361668282719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: -0.5811	Cost: 31.94s
Train Epoch: 204 [40960/90000 (45%)]	Loss: -3.5206	Cost: 9.40s
Train Epoch: 204 [81920/90000 (91%)]	Loss: -3.8191	Cost: 12.47s
Train Epoch: 204 	Average Loss: -3.4480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8833

Learning rate: 0.0001285019262469976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: -0.4721	Cost: 30.94s
Train Epoch: 205 [40960/90000 (45%)]	Loss: -3.6032	Cost: 9.42s
Train Epoch: 205 [81920/90000 (91%)]	Loss: -3.5584	Cost: 12.89s
Train Epoch: 205 	Average Loss: -3.3681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6882

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: -0.5336	Cost: 32.45s
Train Epoch: 206 [40960/90000 (45%)]	Loss: -3.7094	Cost: 9.38s
Train Epoch: 206 [81920/90000 (91%)]	Loss: -3.5901	Cost: 12.38s
Train Epoch: 206 	Average Loss: -3.3385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7948

Learning rate: 0.00012729519355173254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: -0.5117	Cost: 31.95s
Train Epoch: 207 [40960/90000 (45%)]	Loss: -3.7303	Cost: 9.39s
Train Epoch: 207 [81920/90000 (91%)]	Loss: -3.6205	Cost: 12.20s
Train Epoch: 207 	Average Loss: -3.4007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5769

Learning rate: 0.00012669019893203759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: -0.5854	Cost: 32.52s
Train Epoch: 208 [40960/90000 (45%)]	Loss: -3.5664	Cost: 9.59s
Train Epoch: 208 [81920/90000 (91%)]	Loss: -3.8035	Cost: 12.33s
Train Epoch: 208 	Average Loss: -3.4231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7861

Learning rate: 0.0001260841506289897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: -0.7647	Cost: 31.82s
Train Epoch: 209 [40960/90000 (45%)]	Loss: -3.8364	Cost: 9.44s
Train Epoch: 209 [81920/90000 (91%)]	Loss: -3.9236	Cost: 12.91s
Train Epoch: 209 	Average Loss: -3.4678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4983

Saving model as e209_model.pt & e209_waveforms_supplementary.hdf5
Learning rate: 0.00012547707256833825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: -0.6594	Cost: 32.25s
Train Epoch: 210 [40960/90000 (45%)]	Loss: -3.7034	Cost: 9.40s
Train Epoch: 210 [81920/90000 (91%)]	Loss: -3.8962	Cost: 12.40s
Train Epoch: 210 	Average Loss: -3.3871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7918

Learning rate: 0.00012486898871648549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: -0.6012	Cost: 31.22s
Train Epoch: 211 [40960/90000 (45%)]	Loss: -3.7374	Cost: 10.09s
Train Epoch: 211 [81920/90000 (91%)]	Loss: -3.8999	Cost: 11.11s
Train Epoch: 211 	Average Loss: -3.5100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7127

Learning rate: 0.00012425992307954077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: -0.6953	Cost: 32.00s
Train Epoch: 212 [40960/90000 (45%)]	Loss: -3.9118	Cost: 9.59s
Train Epoch: 212 [81920/90000 (91%)]	Loss: -4.0493	Cost: 11.88s
Train Epoch: 212 	Average Loss: -3.6627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6110

Learning rate: 0.0001236498997023725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: -0.8442	Cost: 31.79s
Train Epoch: 213 [40960/90000 (45%)]	Loss: -4.1016	Cost: 9.39s
Train Epoch: 213 [81920/90000 (91%)]	Loss: -4.1677	Cost: 11.65s
Train Epoch: 213 	Average Loss: -3.7064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5384

Learning rate: 0.00012303894266765908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: -0.7166	Cost: 32.07s
Train Epoch: 214 [40960/90000 (45%)]	Loss: -3.9407	Cost: 9.38s
Train Epoch: 214 [81920/90000 (91%)]	Loss: -4.0786	Cost: 12.42s
Train Epoch: 214 	Average Loss: -3.6991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4342

Saving model as e214_model.pt & e214_waveforms_supplementary.hdf5
Learning rate: 0.00012242707609493814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: -0.9423	Cost: 30.93s
Train Epoch: 215 [40960/90000 (45%)]	Loss: -3.9043	Cost: 9.43s
Train Epoch: 215 [81920/90000 (91%)]	Loss: -3.9743	Cost: 12.51s
Train Epoch: 215 	Average Loss: -3.6687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5165

Learning rate: 0.0001218143241396543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: -0.8977	Cost: 31.23s
Train Epoch: 216 [40960/90000 (45%)]	Loss: -4.0177	Cost: 9.41s
Train Epoch: 216 [81920/90000 (91%)]	Loss: -4.1263	Cost: 12.24s
Train Epoch: 216 	Average Loss: -3.6994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3851

Saving model as e216_model.pt & e216_waveforms_supplementary.hdf5
Learning rate: 0.0001212007109922055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: -0.7794	Cost: 31.96s
Train Epoch: 217 [40960/90000 (45%)]	Loss: -3.9198	Cost: 9.36s
Train Epoch: 217 [81920/90000 (91%)]	Loss: -4.1998	Cost: 12.13s
Train Epoch: 217 	Average Loss: -3.7254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4863

Learning rate: 0.00012058626087698816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: -0.8534	Cost: 31.08s
Train Epoch: 218 [40960/90000 (45%)]	Loss: -4.0187	Cost: 9.41s
Train Epoch: 218 [81920/90000 (91%)]	Loss: -3.9843	Cost: 12.61s
Train Epoch: 218 	Average Loss: -3.7578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4803

Learning rate: 0.00011997099805144073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: -0.7830	Cost: 30.88s
Train Epoch: 219 [40960/90000 (45%)]	Loss: -4.1738	Cost: 9.40s
Train Epoch: 219 [81920/90000 (91%)]	Loss: -4.2186	Cost: 11.48s
Train Epoch: 219 	Average Loss: -3.8567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4635

Learning rate: 0.00011935494680508606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: -1.0497	Cost: 31.55s
Train Epoch: 220 [40960/90000 (45%)]	Loss: -4.1579	Cost: 9.40s
Train Epoch: 220 [81920/90000 (91%)]	Loss: -4.2699	Cost: 12.65s
Train Epoch: 220 	Average Loss: -3.9368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4488

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: -0.8637	Cost: 32.03s
Train Epoch: 221 [40960/90000 (45%)]	Loss: -4.2041	Cost: 9.40s
Train Epoch: 221 [81920/90000 (91%)]	Loss: -4.1118	Cost: 12.59s
Train Epoch: 221 	Average Loss: -3.9290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3199

Saving model as e221_model.pt & e221_waveforms_supplementary.hdf5
Learning rate: 0.00011812057636271377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: -0.9229	Cost: 31.15s
Train Epoch: 222 [40960/90000 (45%)]	Loss: -4.1834	Cost: 9.40s
Train Epoch: 222 [81920/90000 (91%)]	Loss: -4.1359	Cost: 11.80s
Train Epoch: 222 	Average Loss: -3.9283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4132

Learning rate: 0.00011750230589752765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: -0.9379	Cost: 31.65s
Train Epoch: 223 [40960/90000 (45%)]	Loss: -4.2492	Cost: 10.05s
Train Epoch: 223 [81920/90000 (91%)]	Loss: -4.3419	Cost: 11.49s
Train Epoch: 223 	Average Loss: -3.9293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3349

Learning rate: 0.0001168833444712734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: -0.8838	Cost: 32.20s
Train Epoch: 224 [40960/90000 (45%)]	Loss: -4.2335	Cost: 9.36s
Train Epoch: 224 [81920/90000 (91%)]	Loss: -4.2221	Cost: 11.94s
Train Epoch: 224 	Average Loss: -3.9818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4145

Learning rate: 0.00011626371651948839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: -0.9769	Cost: 30.86s
Train Epoch: 225 [40960/90000 (45%)]	Loss: -4.4417	Cost: 9.60s
Train Epoch: 225 [81920/90000 (91%)]	Loss: -4.3057	Cost: 11.64s
Train Epoch: 225 	Average Loss: -4.0082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3254

Learning rate: 0.00011564344650402312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: -1.2635	Cost: 32.83s
Train Epoch: 226 [40960/90000 (45%)]	Loss: -4.1397	Cost: 9.38s
Train Epoch: 226 [81920/90000 (91%)]	Loss: -4.3916	Cost: 12.49s
Train Epoch: 226 	Average Loss: -4.0032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3278

Learning rate: 0.00011502255891207573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: -1.0850	Cost: 32.43s
Train Epoch: 227 [40960/90000 (45%)]	Loss: -4.3704	Cost: 9.38s
Train Epoch: 227 [81920/90000 (91%)]	Loss: -4.6161	Cost: 12.59s
Train Epoch: 227 	Average Loss: -4.0434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3270

Learning rate: 0.00011440107825522525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: -0.8690	Cost: 32.35s
Train Epoch: 228 [40960/90000 (45%)]	Loss: -4.3175	Cost: 9.38s
Train Epoch: 228 [81920/90000 (91%)]	Loss: -4.3607	Cost: 12.28s
Train Epoch: 228 	Average Loss: -4.0527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2629

Saving model as e228_model.pt & e228_waveforms_supplementary.hdf5
Learning rate: 0.00011377902906846383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: -0.8895	Cost: 31.89s
Train Epoch: 229 [40960/90000 (45%)]	Loss: -4.5379	Cost: 9.38s
Train Epoch: 229 [81920/90000 (91%)]	Loss: -4.6182	Cost: 11.66s
Train Epoch: 229 	Average Loss: -4.1331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2907

Learning rate: 0.00011315643590922827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: -1.3147	Cost: 32.29s
Train Epoch: 230 [40960/90000 (45%)]	Loss: -4.3304	Cost: 9.37s
Train Epoch: 230 [81920/90000 (91%)]	Loss: -4.3382	Cost: 12.45s
Train Epoch: 230 	Average Loss: -4.1578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3262

Learning rate: 0.00011253332335643043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: -1.2945	Cost: 30.56s
Train Epoch: 231 [40960/90000 (45%)]	Loss: -4.5154	Cost: 9.42s
Train Epoch: 231 [81920/90000 (91%)]	Loss: -4.6225	Cost: 11.45s
Train Epoch: 231 	Average Loss: -4.1597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3108

Learning rate: 0.00011190971600948699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: -0.8794	Cost: 31.86s
Train Epoch: 232 [40960/90000 (45%)]	Loss: -4.3162	Cost: 9.36s
Train Epoch: 232 [81920/90000 (91%)]	Loss: -4.7625	Cost: 12.36s
Train Epoch: 232 	Average Loss: -4.1687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3734

Learning rate: 0.00011128563848734816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: -1.2272	Cost: 32.17s
Train Epoch: 233 [40960/90000 (45%)]	Loss: -4.5588	Cost: 9.38s
Train Epoch: 233 [81920/90000 (91%)]	Loss: -4.6496	Cost: 12.59s
Train Epoch: 233 	Average Loss: -4.2367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3384

Learning rate: 0.000110661115427526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: -1.4209	Cost: 32.11s
Train Epoch: 234 [40960/90000 (45%)]	Loss: -4.6377	Cost: 9.39s
Train Epoch: 234 [81920/90000 (91%)]	Loss: -4.7225	Cost: 12.72s
Train Epoch: 234 	Average Loss: -4.2669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2628

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 0.00011003617148512149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: -1.2094	Cost: 32.76s
Train Epoch: 235 [40960/90000 (45%)]	Loss: -4.4714	Cost: 9.39s
Train Epoch: 235 [81920/90000 (91%)]	Loss: -4.4981	Cost: 12.26s
Train Epoch: 235 	Average Loss: -4.2171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1288

Saving model as e235_model.pt & e235_waveforms_supplementary.hdf5
Learning rate: 0.00010941083133185143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: -1.1496	Cost: 31.71s
Train Epoch: 236 [40960/90000 (45%)]	Loss: -4.6870	Cost: 9.41s
Train Epoch: 236 [81920/90000 (91%)]	Loss: -4.6897	Cost: 12.46s
Train Epoch: 236 	Average Loss: -4.2522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1506

Learning rate: 0.00010878511965507434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: -1.4618	Cost: 31.33s
Train Epoch: 237 [40960/90000 (45%)]	Loss: -4.5777	Cost: 9.37s
Train Epoch: 237 [81920/90000 (91%)]	Loss: -4.6986	Cost: 12.51s
Train Epoch: 237 	Average Loss: -4.3560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0501

Saving model as e237_model.pt & e237_waveforms_supplementary.hdf5
Learning rate: 0.00010815906115681577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: -1.0283	Cost: 31.02s
Train Epoch: 238 [40960/90000 (45%)]	Loss: -4.7748	Cost: 9.39s
Train Epoch: 238 [81920/90000 (91%)]	Loss: -4.8468	Cost: 12.34s
Train Epoch: 238 	Average Loss: -4.4137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0629

Learning rate: 0.00010753268055279328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: -1.2574	Cost: 31.96s
Train Epoch: 239 [40960/90000 (45%)]	Loss: -4.4703	Cost: 9.40s
Train Epoch: 239 [81920/90000 (91%)]	Loss: -4.7849	Cost: 12.46s
Train Epoch: 239 	Average Loss: -4.3755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0655

Saving model as e239_model.pt & e239_waveforms_supplementary.hdf5
Learning rate: 0.0001069060025714406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: -1.3741	Cost: 30.85s
Train Epoch: 240 [40960/90000 (45%)]	Loss: -4.7770	Cost: 9.39s
Train Epoch: 240 [81920/90000 (91%)]	Loss: -4.6741	Cost: 12.65s
Train Epoch: 240 	Average Loss: -4.4082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2326

Learning rate: 0.00010627905195293134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: -1.3642	Cost: 32.64s
Train Epoch: 241 [40960/90000 (45%)]	Loss: -4.7443	Cost: 9.39s
Train Epoch: 241 [81920/90000 (91%)]	Loss: -4.7345	Cost: 12.40s
Train Epoch: 241 	Average Loss: -4.4772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1656

Learning rate: 0.00010565185344820243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: -1.1685	Cost: 31.19s
Train Epoch: 242 [40960/90000 (45%)]	Loss: -4.5868	Cost: 9.41s
Train Epoch: 242 [81920/90000 (91%)]	Loss: -4.8862	Cost: 12.73s
Train Epoch: 242 	Average Loss: -4.4796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1213

Learning rate: 0.00010502443181797694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: -1.0839	Cost: 31.11s
Train Epoch: 243 [40960/90000 (45%)]	Loss: -4.8130	Cost: 9.41s
Train Epoch: 243 [81920/90000 (91%)]	Loss: -4.8439	Cost: 11.87s
Train Epoch: 243 	Average Loss: -4.4942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0116

Learning rate: 0.00010439681183178646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: -1.0316	Cost: 31.85s
Train Epoch: 244 [40960/90000 (45%)]	Loss: -4.7059	Cost: 9.41s
Train Epoch: 244 [81920/90000 (91%)]	Loss: -4.7304	Cost: 12.33s
Train Epoch: 244 	Average Loss: -4.3772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1721

Learning rate: 0.00010376901826699342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: -1.2279	Cost: 31.92s
Train Epoch: 245 [40960/90000 (45%)]	Loss: -4.6227	Cost: 9.40s
Train Epoch: 245 [81920/90000 (91%)]	Loss: -4.7178	Cost: 12.29s
Train Epoch: 245 	Average Loss: -4.3872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0149

Learning rate: 0.0001031410759078128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: -1.1279	Cost: 31.59s
Train Epoch: 246 [40960/90000 (45%)]	Loss: -4.8253	Cost: 9.41s
Train Epoch: 246 [81920/90000 (91%)]	Loss: -4.9609	Cost: 12.71s
Train Epoch: 246 	Average Loss: -4.5279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0791

Learning rate: 0.00010251300954433372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: -1.3887	Cost: 31.48s
Train Epoch: 247 [40960/90000 (45%)]	Loss: -4.7699	Cost: 9.43s
Train Epoch: 247 [81920/90000 (91%)]	Loss: -4.8782	Cost: 12.39s
Train Epoch: 247 	Average Loss: -4.4515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1250

Learning rate: 0.0001018848439715408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: -1.1751	Cost: 32.09s
Train Epoch: 248 [40960/90000 (45%)]	Loss: -4.7375	Cost: 9.46s
Train Epoch: 248 [81920/90000 (91%)]	Loss: -4.8795	Cost: 12.87s
Train Epoch: 248 	Average Loss: -4.4529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1143

Saving model as e248_model.pt & e248_waveforms_supplementary.hdf5
Learning rate: 0.00010125660398833524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: -1.3565	Cost: 30.54s
Train Epoch: 249 [40960/90000 (45%)]	Loss: -5.0692	Cost: 9.36s
Train Epoch: 249 [81920/90000 (91%)]	Loss: -5.0517	Cost: 12.44s
Train Epoch: 249 	Average Loss: -4.6695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0609

Learning rate: 0.00010062831439655587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: -1.4919	Cost: 31.97s
Train Epoch: 250 [40960/90000 (45%)]	Loss: -5.0055	Cost: 9.39s
Train Epoch: 250 [81920/90000 (91%)]	Loss: -4.8736	Cost: 12.78s
Train Epoch: 250 	Average Loss: -4.6602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0088

Learning rate: 9.999999999999996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: -1.3493	Cost: 31.68s
Train Epoch: 251 [40960/90000 (45%)]	Loss: -4.9683	Cost: 9.34s
Train Epoch: 251 [81920/90000 (91%)]	Loss: -4.8044	Cost: 12.33s
Train Epoch: 251 	Average Loss: -4.6208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1537

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Learning rate: 9.937168560344407e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: -1.4915	Cost: 30.78s
Train Epoch: 252 [40960/90000 (45%)]	Loss: -4.8838	Cost: 9.38s
Train Epoch: 252 [81920/90000 (91%)]	Loss: -4.8806	Cost: 11.57s
Train Epoch: 252 	Average Loss: -4.6827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0809

Learning rate: 9.87433960116647e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: -1.5337	Cost: 32.30s
Train Epoch: 253 [40960/90000 (45%)]	Loss: -5.1339	Cost: 9.37s
Train Epoch: 253 [81920/90000 (91%)]	Loss: -5.0550	Cost: 12.34s
Train Epoch: 253 	Average Loss: -4.7306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0514

Learning rate: 9.811515602845915e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: -1.3596	Cost: 32.45s
Train Epoch: 254 [40960/90000 (45%)]	Loss: -5.2205	Cost: 9.36s
Train Epoch: 254 [81920/90000 (91%)]	Loss: -5.3545	Cost: 12.66s
Train Epoch: 254 	Average Loss: -4.7817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0624

Learning rate: 9.748699045566624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: -1.6161	Cost: 31.30s
Train Epoch: 255 [40960/90000 (45%)]	Loss: -4.8959	Cost: 9.41s
Train Epoch: 255 [81920/90000 (91%)]	Loss: -5.3441	Cost: 11.91s
Train Epoch: 255 	Average Loss: -4.8408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1064

Learning rate: 9.685892409218716e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: -1.3276	Cost: 31.99s
Train Epoch: 256 [40960/90000 (45%)]	Loss: -5.2396	Cost: 9.38s
Train Epoch: 256 [81920/90000 (91%)]	Loss: -4.9317	Cost: 12.21s
Train Epoch: 256 	Average Loss: -4.8351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0157

Learning rate: 9.623098173300653e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: -1.4211	Cost: 31.13s
Train Epoch: 257 [40960/90000 (45%)]	Loss: -5.2154	Cost: 9.39s
Train Epoch: 257 [81920/90000 (91%)]	Loss: -5.2778	Cost: 12.64s
Train Epoch: 257 	Average Loss: -4.8758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0586

Learning rate: 9.560318816821353e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: -1.7876	Cost: 32.13s
Train Epoch: 258 [40960/90000 (45%)]	Loss: -5.2689	Cost: 9.60s
Train Epoch: 258 [81920/90000 (91%)]	Loss: -5.2447	Cost: 12.44s
Train Epoch: 258 	Average Loss: -4.8790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0897

Learning rate: 9.497556818202306e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: -1.5310	Cost: 31.99s
Train Epoch: 259 [40960/90000 (45%)]	Loss: -5.1801	Cost: 9.40s
Train Epoch: 259 [81920/90000 (91%)]	Loss: -5.3083	Cost: 12.10s
Train Epoch: 259 	Average Loss: -4.8777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0184

Learning rate: 9.434814655179755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: -1.4498	Cost: 30.83s
Train Epoch: 260 [40960/90000 (45%)]	Loss: -5.2335	Cost: 9.39s
Train Epoch: 260 [81920/90000 (91%)]	Loss: -5.4655	Cost: 12.80s
Train Epoch: 260 	Average Loss: -4.9171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1902

Saving model as e260_model.pt & e260_waveforms_supplementary.hdf5
Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: -1.5058	Cost: 30.81s
Train Epoch: 261 [40960/90000 (45%)]	Loss: -5.2280	Cost: 9.60s
Train Epoch: 261 [81920/90000 (91%)]	Loss: -5.2427	Cost: 11.54s
Train Epoch: 261 	Average Loss: -4.9381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0354

Learning rate: 9.309399742855944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: -1.8431	Cost: 31.20s
Train Epoch: 262 [40960/90000 (45%)]	Loss: -5.0111	Cost: 9.40s
Train Epoch: 262 [81920/90000 (91%)]	Loss: -5.3249	Cost: 11.74s
Train Epoch: 262 	Average Loss: -4.9314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3729

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 9.246731944720672e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: -1.5575	Cost: 32.39s
Train Epoch: 263 [40960/90000 (45%)]	Loss: -5.3282	Cost: 9.43s
Train Epoch: 263 [81920/90000 (91%)]	Loss: -5.4515	Cost: 12.38s
Train Epoch: 263 	Average Loss: -5.0094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1319

Learning rate: 9.184093884318424e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: -1.5520	Cost: 32.16s
Train Epoch: 264 [40960/90000 (45%)]	Loss: -5.2149	Cost: 9.43s
Train Epoch: 264 [81920/90000 (91%)]	Loss: -5.3905	Cost: 12.04s
Train Epoch: 264 	Average Loss: -5.0332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2336

Learning rate: 9.121488034492569e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: -1.3057	Cost: 31.05s
Train Epoch: 265 [40960/90000 (45%)]	Loss: -5.3231	Cost: 9.38s
Train Epoch: 265 [81920/90000 (91%)]	Loss: -5.4406	Cost: 12.27s
Train Epoch: 265 	Average Loss: -5.0267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1257

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: -1.6451	Cost: 30.77s
Train Epoch: 266 [40960/90000 (45%)]	Loss: -5.3670	Cost: 9.40s
Train Epoch: 266 [81920/90000 (91%)]	Loss: -4.9777	Cost: 11.73s
Train Epoch: 266 	Average Loss: -4.9005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1778

Learning rate: 8.996382851487852e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: -0.8754	Cost: 32.83s
Train Epoch: 267 [40960/90000 (45%)]	Loss: -5.0126	Cost: 9.36s
Train Epoch: 267 [81920/90000 (91%)]	Loss: -5.1128	Cost: 12.28s
Train Epoch: 267 	Average Loss: -4.6668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0100

Learning rate: 8.9338884572474e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: -1.4472	Cost: 32.09s
Train Epoch: 268 [40960/90000 (45%)]	Loss: -5.3941	Cost: 9.42s
Train Epoch: 268 [81920/90000 (91%)]	Loss: -5.5645	Cost: 12.67s
Train Epoch: 268 	Average Loss: -4.9783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1487

Learning rate: 8.871436151265182e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: -1.7383	Cost: 30.47s
Train Epoch: 269 [40960/90000 (45%)]	Loss: -5.3666	Cost: 9.59s
Train Epoch: 269 [81920/90000 (91%)]	Loss: -5.4743	Cost: 12.32s
Train Epoch: 269 	Average Loss: -5.0281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3783

Saving model as e269_model.pt & e269_waveforms_supplementary.hdf5
Learning rate: 8.809028399051304e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: -1.8378	Cost: 31.50s
Train Epoch: 270 [40960/90000 (45%)]	Loss: -5.4860	Cost: 9.40s
Train Epoch: 270 [81920/90000 (91%)]	Loss: -5.4697	Cost: 12.48s
Train Epoch: 270 	Average Loss: -5.1051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5160

Saving model as e270_model.pt & e270_waveforms_supplementary.hdf5
Learning rate: 8.746667664356958e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: -1.5979	Cost: 30.88s
Train Epoch: 271 [40960/90000 (45%)]	Loss: -5.5230	Cost: 9.40s
Train Epoch: 271 [81920/90000 (91%)]	Loss: -5.7343	Cost: 12.14s
Train Epoch: 271 	Average Loss: -5.2062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2771

Learning rate: 8.684356409077174e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: -1.6473	Cost: 32.29s
Train Epoch: 272 [40960/90000 (45%)]	Loss: -5.6008	Cost: 9.35s
Train Epoch: 272 [81920/90000 (91%)]	Loss: -5.6640	Cost: 12.41s
Train Epoch: 272 	Average Loss: -5.2166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2655

Learning rate: 8.622097093153619e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: -1.8626	Cost: 31.11s
Train Epoch: 273 [40960/90000 (45%)]	Loss: -5.6819	Cost: 9.39s
Train Epoch: 273 [81920/90000 (91%)]	Loss: -5.6876	Cost: 11.61s
Train Epoch: 273 	Average Loss: -5.2601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5233

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 8.559892174477476e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: -2.0882	Cost: 31.14s
Train Epoch: 274 [40960/90000 (45%)]	Loss: -5.5507	Cost: 9.42s
Train Epoch: 274 [81920/90000 (91%)]	Loss: -5.6833	Cost: 11.74s
Train Epoch: 274 	Average Loss: -5.2860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3009

Learning rate: 8.497744108792427e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: -1.6868	Cost: 30.61s
Train Epoch: 275 [40960/90000 (45%)]	Loss: -5.6871	Cost: 9.39s
Train Epoch: 275 [81920/90000 (91%)]	Loss: -5.6237	Cost: 12.24s
Train Epoch: 275 	Average Loss: -5.2956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4481

Learning rate: 8.435655349597689e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: -1.6476	Cost: 30.76s
Train Epoch: 276 [40960/90000 (45%)]	Loss: -5.6745	Cost: 9.38s
Train Epoch: 276 [81920/90000 (91%)]	Loss: -5.7915	Cost: 11.91s
Train Epoch: 276 	Average Loss: -5.2870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3719

Learning rate: 8.373628348051162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: -1.7477	Cost: 31.76s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -5.6844	Cost: 9.41s
Train Epoch: 277 [81920/90000 (91%)]	Loss: -5.6309	Cost: 12.47s
Train Epoch: 277 	Average Loss: -5.3249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2966

Learning rate: 8.311665552872659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: -2.0877	Cost: 30.86s
Train Epoch: 278 [40960/90000 (45%)]	Loss: -5.6476	Cost: 9.36s
Train Epoch: 278 [81920/90000 (91%)]	Loss: -5.7581	Cost: 12.62s
Train Epoch: 278 	Average Loss: -5.3719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
