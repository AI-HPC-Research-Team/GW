Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=4096, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=1.0, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_mixed_prior_transfered/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=500, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_mixed_prior_transfered/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Now, transfer learning from alpha=1.0!
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.2626	Cost: 33.22s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.6170	Cost: 9.46s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.7745	Cost: 11.93s
Train Epoch: 1 	Average Loss: 22.0400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9050

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.6534	Cost: 32.43s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 20.3324	Cost: 9.43s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 19.9864	Cost: 12.98s
Train Epoch: 2 	Average Loss: 20.2597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6987

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999998026079186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 19.8072	Cost: 33.71s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 19.2605	Cost: 10.28s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 18.6905	Cost: 11.56s
Train Epoch: 3 	Average Loss: 19.1822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6666

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019999995558678347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 18.5744	Cost: 33.11s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 18.4608	Cost: 9.44s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 17.8089	Cost: 12.05s
Train Epoch: 4 	Average Loss: 18.2484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0535

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.0001999999210431752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 17.8330	Cost: 32.60s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.5135	Cost: 10.11s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 17.1855	Cost: 11.64s
Train Epoch: 5 	Average Loss: 17.5150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4909

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019999987662997035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 17.1067	Cost: 33.01s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 16.9649	Cost: 9.42s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 16.6564	Cost: 12.18s
Train Epoch: 6 	Average Loss: 16.9079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8955

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019999982234717337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 16.6576	Cost: 33.60s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 16.4305	Cost: 9.54s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 16.2072	Cost: 12.13s
Train Epoch: 7 	Average Loss: 16.3788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3528

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 16.1322	Cost: 33.00s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 16.0216	Cost: 9.44s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 15.7103	Cost: 12.17s
Train Epoch: 8 	Average Loss: 15.9675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9044

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.0001999996841728254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 15.7868	Cost: 32.98s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 15.6827	Cost: 9.68s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 15.3990	Cost: 12.37s
Train Epoch: 9 	Average Loss: 15.6211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6029

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 15.4888	Cost: 33.44s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 15.2736	Cost: 9.54s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 15.1846	Cost: 12.45s
Train Epoch: 10 	Average Loss: 15.2592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2478

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019999950652018584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 15.2368	Cost: 33.28s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 15.0508	Cost: 10.38s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 14.8393	Cost: 12.16s
Train Epoch: 11 	Average Loss: 15.0255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9731

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019999940288952797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 14.8711	Cost: 33.48s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 14.9705	Cost: 10.13s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 14.7702	Cost: 12.03s
Train Epoch: 12 	Average Loss: 14.8083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7403

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019999928938932473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 14.5597	Cost: 32.26s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 14.6525	Cost: 9.43s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 14.4453	Cost: 12.25s
Train Epoch: 13 	Average Loss: 14.4978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4493

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.0001999991660195873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 14.4531	Cost: 33.88s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 14.4397	Cost: 10.12s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 14.1673	Cost: 11.72s
Train Epoch: 14 	Average Loss: 14.2975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2567

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 14.1732	Cost: 33.14s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 14.0471	Cost: 10.25s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 14.0442	Cost: 11.38s
Train Epoch: 15 	Average Loss: 14.0655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1265

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019999888967155963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 13.9357	Cost: 33.38s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 13.8975	Cost: 9.42s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 13.7973	Cost: 12.48s
Train Epoch: 16 	Average Loss: 13.8535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9811

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001999987366932966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 13.7684	Cost: 33.53s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 13.7456	Cost: 9.59s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 13.6454	Cost: 13.22s
Train Epoch: 17 	Average Loss: 13.6647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7518

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019999857384555393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 13.5987	Cost: 33.04s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 13.4805	Cost: 9.53s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 13.4315	Cost: 12.25s
Train Epoch: 18 	Average Loss: 13.4693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3829

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.0001999984011283477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 13.4042	Cost: 34.05s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 13.3465	Cost: 9.74s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 13.1163	Cost: 12.25s
Train Epoch: 19 	Average Loss: 13.3124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3744

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019999821854169497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 13.3054	Cost: 32.99s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 13.1447	Cost: 9.55s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 12.9826	Cost: 11.67s
Train Epoch: 20 	Average Loss: 13.1184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0517

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 12.9996	Cost: 33.33s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 12.8667	Cost: 9.51s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 12.8604	Cost: 12.45s
Train Epoch: 21 	Average Loss: 12.9362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8069

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 12.7972	Cost: 33.51s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 12.9152	Cost: 9.96s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 12.9533	Cost: 11.88s
Train Epoch: 22 	Average Loss: 12.8368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8621

Learning rate: 0.00019999761156524272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 12.7788	Cost: 33.35s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 12.8260	Cost: 9.58s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 12.6773	Cost: 12.88s
Train Epoch: 23 	Average Loss: 12.7529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6311

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 12.6376	Cost: 33.31s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 12.6798	Cost: 9.62s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 12.5258	Cost: 12.54s
Train Epoch: 24 	Average Loss: 12.6394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6219

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.00019999715756739833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 12.5576	Cost: 33.30s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 12.4460	Cost: 10.22s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 12.3824	Cost: 11.66s
Train Epoch: 25 	Average Loss: 12.4940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4676

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.000199996915764479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 12.4065	Cost: 33.24s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 12.2420	Cost: 9.58s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 12.3028	Cost: 12.64s
Train Epoch: 26 	Average Loss: 12.3449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4032

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019999666409225975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 12.3745	Cost: 33.14s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 12.2158	Cost: 9.60s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 12.3508	Cost: 11.56s
Train Epoch: 27 	Average Loss: 12.2952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2694

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019999640255076543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 12.2372	Cost: 32.99s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 12.1834	Cost: 9.49s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 12.0931	Cost: 11.98s
Train Epoch: 28 	Average Loss: 12.1205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2392

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019999613114002186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 12.2680	Cost: 33.36s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 12.0467	Cost: 9.58s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 12.0199	Cost: 11.84s
Train Epoch: 29 	Average Loss: 12.1185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1008

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.0001999958498600558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 11.9728	Cost: 32.89s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 12.0162	Cost: 9.59s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 11.9619	Cost: 11.64s
Train Epoch: 30 	Average Loss: 11.9369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0678

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.000199995558710895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 11.8804	Cost: 33.27s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 11.8935	Cost: 10.25s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 11.9240	Cost: 11.98s
Train Epoch: 31 	Average Loss: 11.8958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9210

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 0.00019999525769256825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 11.8966	Cost: 33.12s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 11.8191	Cost: 9.55s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 11.8602	Cost: 11.82s
Train Epoch: 32 	Average Loss: 11.7887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9574

Learning rate: 0.00019999494680510518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 11.9258	Cost: 33.44s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 11.7747	Cost: 9.56s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 11.7308	Cost: 12.10s
Train Epoch: 33 	Average Loss: 11.7580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8649

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019999462604853658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 11.7723	Cost: 32.88s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 11.7016	Cost: 9.50s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 11.5851	Cost: 12.36s
Train Epoch: 34 	Average Loss: 11.6604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6471

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019999429542289402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 11.5902	Cost: 33.08s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 11.6519	Cost: 10.27s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 11.6029	Cost: 12.39s
Train Epoch: 35 	Average Loss: 11.5286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5420

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.00019999395492821016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 11.5466	Cost: 33.54s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 11.4984	Cost: 9.51s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 11.5309	Cost: 12.31s
Train Epoch: 36 	Average Loss: 11.5038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5062

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.0001999936045645186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 11.3915	Cost: 33.11s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 11.3237	Cost: 9.58s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 11.3619	Cost: 12.93s
Train Epoch: 37 	Average Loss: 11.4047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3977

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.00019999324433185394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 11.3799	Cost: 33.05s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 11.3500	Cost: 10.23s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 11.2327	Cost: 11.91s
Train Epoch: 38 	Average Loss: 11.3580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4383

Learning rate: 0.0001999928742302517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 11.4174	Cost: 33.66s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 11.2249	Cost: 9.58s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 11.2856	Cost: 13.18s
Train Epoch: 39 	Average Loss: 11.2925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2541

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019999249425974844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 11.2223	Cost: 33.11s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 11.2739	Cost: 10.21s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 11.1733	Cost: 11.87s
Train Epoch: 40 	Average Loss: 11.2107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2507

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 11.3092	Cost: 32.47s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 11.2704	Cost: 9.63s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 11.1423	Cost: 12.18s
Train Epoch: 41 	Average Loss: 11.1773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1722

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019999170471218976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 11.0898	Cost: 34.12s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 11.1434	Cost: 9.62s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 11.0825	Cost: 12.72s
Train Epoch: 42 	Average Loss: 11.1176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1433

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.0001999912951352123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 11.1391	Cost: 33.67s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 11.1388	Cost: 9.62s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 11.0227	Cost: 11.81s
Train Epoch: 43 	Average Loss: 11.0398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8988

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.00019999087568948966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 10.8380	Cost: 33.88s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 10.9370	Cost: 9.44s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 11.0187	Cost: 12.75s
Train Epoch: 44 	Average Loss: 10.9303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0927

Learning rate: 0.0001999904463750632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 11.0719	Cost: 33.47s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 10.9848	Cost: 9.44s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 10.8783	Cost: 12.20s
Train Epoch: 45 	Average Loss: 10.9184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8793

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019999000719197536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 10.9402	Cost: 33.79s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 10.9002	Cost: 9.44s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 10.9204	Cost: 12.90s
Train Epoch: 46 	Average Loss: 10.8557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9139

Learning rate: 0.00019998955814026943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 10.8837	Cost: 33.48s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 10.7177	Cost: 10.08s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 10.8321	Cost: 11.50s
Train Epoch: 47 	Average Loss: 10.8146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8589

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 0.00019998909921998973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 10.8400	Cost: 34.08s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 10.8668	Cost: 9.49s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 10.7985	Cost: 12.73s
Train Epoch: 48 	Average Loss: 10.8092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9003

Learning rate: 0.0001999886304311816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 10.9150	Cost: 33.38s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 10.7973	Cost: 9.51s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 10.6644	Cost: 12.46s
Train Epoch: 49 	Average Loss: 10.7635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8195

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019998815177389132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 10.7682	Cost: 33.98s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 10.6759	Cost: 9.52s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 10.6784	Cost: 12.56s
Train Epoch: 50 	Average Loss: 10.6697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7851

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 10.5645	Cost: 33.38s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 10.6940	Cost: 9.63s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 10.8487	Cost: 12.51s
Train Epoch: 51 	Average Loss: 10.7250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6929

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019998716485405404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 10.5514	Cost: 33.03s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 10.5656	Cost: 9.62s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 10.5517	Cost: 12.97s
Train Epoch: 52 	Average Loss: 10.5610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6803

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 0.0001999866565916045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 10.6159	Cost: 33.14s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 10.6110	Cost: 9.71s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 10.5385	Cost: 11.85s
Train Epoch: 53 	Average Loss: 10.5870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5201

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 0.0001999861384608676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 10.5101	Cost: 33.56s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 10.4540	Cost: 9.51s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 10.4357	Cost: 12.29s
Train Epoch: 54 	Average Loss: 10.4700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5383

Learning rate: 0.00019998561046189446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 10.4369	Cost: 33.63s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 10.4266	Cost: 9.57s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 10.4696	Cost: 12.48s
Train Epoch: 55 	Average Loss: 10.4637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5076

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.00019998507259473718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 10.4309	Cost: 33.67s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 10.2858	Cost: 9.51s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 10.4367	Cost: 12.73s
Train Epoch: 56 	Average Loss: 10.4050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3997

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019998452485944885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 10.4001	Cost: 32.51s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 10.3741	Cost: 9.50s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 10.4183	Cost: 12.91s
Train Epoch: 57 	Average Loss: 10.3610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3424

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 0.00019998396725608354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 10.4325	Cost: 33.56s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 10.3683	Cost: 9.80s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 10.2859	Cost: 11.82s
Train Epoch: 58 	Average Loss: 10.3089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3198

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 10.3067	Cost: 32.71s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 10.3574	Cost: 9.52s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 10.3610	Cost: 11.85s
Train Epoch: 59 	Average Loss: 10.2840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3079

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 10.3541	Cost: 33.43s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 10.3883	Cost: 9.76s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 10.3669	Cost: 12.47s
Train Epoch: 60 	Average Loss: 10.2628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2561

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 10.2700	Cost: 32.64s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 10.3068	Cost: 9.50s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 10.1707	Cost: 12.20s
Train Epoch: 61 	Average Loss: 10.2248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2388

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 10.1114	Cost: 33.00s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 10.2065	Cost: 9.53s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 10.1549	Cost: 12.43s
Train Epoch: 62 	Average Loss: 10.1333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1876

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019998103122006246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 10.0402	Cost: 33.12s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 10.1602	Cost: 9.53s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 10.2178	Cost: 12.78s
Train Epoch: 63 	Average Loss: 10.1089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1334

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 0.00019998041440942506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 10.2075	Cost: 33.91s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 10.2389	Cost: 9.60s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 10.1703	Cost: 12.08s
Train Epoch: 64 	Average Loss: 10.0923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1167

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00019997978773111632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 10.0989	Cost: 32.81s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 10.1169	Cost: 9.95s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 10.0714	Cost: 12.18s
Train Epoch: 65 	Average Loss: 10.0566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1549

Learning rate: 0.00019997915118519813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 10.1359	Cost: 33.36s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 10.1292	Cost: 9.53s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 10.0025	Cost: 12.76s
Train Epoch: 66 	Average Loss: 10.0102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0237

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.0001999785047717333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 10.0397	Cost: 33.35s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 10.0735	Cost: 9.60s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 10.1498	Cost: 12.59s
Train Epoch: 67 	Average Loss: 10.0124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0852

Learning rate: 0.00019997784849078566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 10.0810	Cost: 33.13s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 10.0315	Cost: 9.50s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 9.9479	Cost: 12.45s
Train Epoch: 68 	Average Loss: 9.9362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0312

Learning rate: 0.00019997718234242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 9.9888	Cost: 33.98s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 10.0565	Cost: 9.56s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 9.9581	Cost: 12.83s
Train Epoch: 69 	Average Loss: 9.9497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9685

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Learning rate: 0.00019997650632670199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 10.0043	Cost: 33.30s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 9.8668	Cost: 9.92s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 9.8786	Cost: 11.79s
Train Epoch: 70 	Average Loss: 9.8975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0671

Learning rate: 0.0001999758204436984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 10.0089	Cost: 33.25s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 9.9028	Cost: 9.57s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 9.8496	Cost: 12.46s
Train Epoch: 71 	Average Loss: 9.8548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8895

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00019997512469347695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 9.9382	Cost: 33.11s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 9.9165	Cost: 9.49s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 9.8380	Cost: 12.38s
Train Epoch: 72 	Average Loss: 9.8546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9324

Learning rate: 0.00019997441907610624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 9.9183	Cost: 32.89s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 9.8493	Cost: 9.62s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 9.7811	Cost: 12.79s
Train Epoch: 73 	Average Loss: 9.8011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8668

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Learning rate: 0.00019997370359165596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 9.8349	Cost: 33.06s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 9.6818	Cost: 9.65s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 9.7147	Cost: 12.70s
Train Epoch: 74 	Average Loss: 9.7224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8002

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.0001999729782401967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 9.6735	Cost: 33.50s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 9.7393	Cost: 9.62s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 9.7290	Cost: 12.47s
Train Epoch: 75 	Average Loss: 9.7506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9160

Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 9.8495	Cost: 33.83s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 9.7407	Cost: 9.60s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 9.6930	Cost: 12.17s
Train Epoch: 76 	Average Loss: 9.7381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7367

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00019997149793653861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 9.6991	Cost: 33.51s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 9.5967	Cost: 9.61s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 9.5859	Cost: 12.49s
Train Epoch: 77 	Average Loss: 9.6624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7041

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Learning rate: 0.00019997074298448586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 9.7416	Cost: 32.88s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 9.6448	Cost: 10.10s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 9.6992	Cost: 11.45s
Train Epoch: 78 	Average Loss: 9.6486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6115

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Learning rate: 0.00019996997816571638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 9.6664	Cost: 33.91s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 9.7488	Cost: 9.41s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 9.6245	Cost: 12.66s
Train Epoch: 79 	Average Loss: 9.6151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6809

Learning rate: 0.00019996920348030559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 9.7299	Cost: 33.83s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 9.6589	Cost: 9.47s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 9.6417	Cost: 12.80s
Train Epoch: 80 	Average Loss: 9.6119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6566

Learning rate: 0.00019996841892832998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 9.6402	Cost: 33.94s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 9.7021	Cost: 10.09s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 9.5957	Cost: 12.20s
Train Epoch: 81 	Average Loss: 9.5781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5177

Saving model as e81_model.pt & e81_waveforms_supplementary.hdf5
Learning rate: 0.00019996762450986697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 9.5574	Cost: 33.62s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 9.5750	Cost: 10.25s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 9.5736	Cost: 12.18s
Train Epoch: 82 	Average Loss: 9.5346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5345

Learning rate: 0.00019996682022499498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 9.6280	Cost: 32.87s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 9.5178	Cost: 9.86s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 9.4743	Cost: 11.96s
Train Epoch: 83 	Average Loss: 9.5048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5265

Learning rate: 0.0001999660060737934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 9.5067	Cost: 33.54s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 9.4955	Cost: 9.71s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 9.5445	Cost: 12.26s
Train Epoch: 84 	Average Loss: 9.4759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5944

Learning rate: 0.00019996518205634255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 9.5975	Cost: 33.32s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 9.5332	Cost: 9.77s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 9.4753	Cost: 11.56s
Train Epoch: 85 	Average Loss: 9.4527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4701

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Learning rate: 0.0001999643481727238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 9.5848	Cost: 34.32s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 9.3928	Cost: 9.56s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 9.3869	Cost: 12.76s
Train Epoch: 86 	Average Loss: 9.4157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7216

Learning rate: 0.0001999635044230194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 9.4827	Cost: 33.06s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 9.5399	Cost: 9.52s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 9.4295	Cost: 12.49s
Train Epoch: 87 	Average Loss: 9.4530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5310

Learning rate: 0.00019996265080731267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 9.6621	Cost: 32.95s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 9.4203	Cost: 9.60s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 9.3575	Cost: 12.53s
Train Epoch: 88 	Average Loss: 9.3969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4120

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 0.00019996178732568782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 9.3374	Cost: 32.52s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 9.3675	Cost: 9.49s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 9.4253	Cost: 12.82s
Train Epoch: 89 	Average Loss: 9.3586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4567

Learning rate: 0.00019996091397823007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 9.4048	Cost: 33.45s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 9.3489	Cost: 10.06s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 9.3163	Cost: 11.47s
Train Epoch: 90 	Average Loss: 9.3092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4306

Learning rate: 0.00019996003076502562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 9.5208	Cost: 34.03s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 9.4196	Cost: 9.53s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 9.4339	Cost: 12.89s
Train Epoch: 91 	Average Loss: 9.3401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4313

Learning rate: 0.0001999591376861617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 9.4057	Cost: 33.60s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 9.3112	Cost: 9.56s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 9.3298	Cost: 12.39s
Train Epoch: 92 	Average Loss: 9.3062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3633

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 0.0001999582347417264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 9.4237	Cost: 33.07s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 9.3855	Cost: 9.55s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 9.2527	Cost: 12.76s
Train Epoch: 93 	Average Loss: 9.2953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2635

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 0.00019995732193180883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 9.2132	Cost: 33.55s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 9.2549	Cost: 10.12s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 9.3032	Cost: 11.83s
Train Epoch: 94 	Average Loss: 9.2482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3005

Learning rate: 0.00019995639925649909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 9.3542	Cost: 33.87s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 9.2778	Cost: 9.57s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 9.3841	Cost: 12.56s
Train Epoch: 95 	Average Loss: 9.2629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3270

Learning rate: 0.00019995546671588827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 9.3208	Cost: 33.49s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 9.3055	Cost: 9.55s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 9.3458	Cost: 12.40s
Train Epoch: 96 	Average Loss: 9.2423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3852

Learning rate: 0.0001999545243100684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 9.2749	Cost: 33.57s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 9.3247	Cost: 9.55s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 9.2545	Cost: 12.65s
Train Epoch: 97 	Average Loss: 9.2798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3823

Learning rate: 0.00019995357203913245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 9.3327	Cost: 33.43s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 9.2394	Cost: 10.21s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 9.2344	Cost: 12.30s
Train Epoch: 98 	Average Loss: 9.2117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3234

Learning rate: 0.00019995260990317447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 9.3684	Cost: 33.96s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 9.1416	Cost: 10.09s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 9.2962	Cost: 11.84s
Train Epoch: 99 	Average Loss: 9.1910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1831

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Learning rate: 0.00019995163790228936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 9.2121	Cost: 33.31s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 9.1543	Cost: 9.46s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 9.1672	Cost: 12.47s
Train Epoch: 100 	Average Loss: 9.1282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2752

Learning rate: 0.0001999506560365731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 9.2405	Cost: 33.62s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 9.1873	Cost: 9.65s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 9.2309	Cost: 12.47s
Train Epoch: 101 	Average Loss: 9.1534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2342

Learning rate: 0.00019994966430612258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 9.2796	Cost: 32.84s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 9.1390	Cost: 9.63s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 9.1664	Cost: 12.39s
Train Epoch: 102 	Average Loss: 9.1489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1356

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00019994866271103568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 9.2535	Cost: 33.61s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 9.0955	Cost: 9.64s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 9.1692	Cost: 12.75s
Train Epoch: 103 	Average Loss: 9.0764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1425

Learning rate: 0.0001999476512514112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 9.1591	Cost: 34.14s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 9.0610	Cost: 9.62s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 9.0204	Cost: 12.50s
Train Epoch: 104 	Average Loss: 9.0356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1468

Learning rate: 0.00019994662992734905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 9.1798	Cost: 33.29s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 9.1115	Cost: 10.11s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 9.0328	Cost: 11.36s
Train Epoch: 105 	Average Loss: 9.0806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1804

Learning rate: 0.00019994559873894998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 9.1437	Cost: 33.52s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 9.0430	Cost: 9.42s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 9.1590	Cost: 12.69s
Train Epoch: 106 	Average Loss: 9.0584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2050

Learning rate: 0.00019994455768631577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 9.1205	Cost: 32.71s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 9.0869	Cost: 9.50s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 9.0077	Cost: 12.27s
Train Epoch: 107 	Average Loss: 9.0580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1515

Learning rate: 0.00019994350676954918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 9.2066	Cost: 33.45s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 9.0712	Cost: 9.45s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 9.0174	Cost: 12.77s
Train Epoch: 108 	Average Loss: 9.0289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1153

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Learning rate: 0.00019994244598875392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 9.1302	Cost: 33.55s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 9.1842	Cost: 9.67s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 9.1480	Cost: 11.84s
Train Epoch: 109 	Average Loss: 9.0409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1269

Learning rate: 0.00019994137534403472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 9.0919	Cost: 33.14s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 9.1695	Cost: 9.61s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 8.9680	Cost: 12.58s
Train Epoch: 110 	Average Loss: 9.0154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0909

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 0.00019994029483549723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 9.0769	Cost: 33.53s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 9.0718	Cost: 9.63s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 8.9719	Cost: 12.22s
Train Epoch: 111 	Average Loss: 8.9702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0929

Learning rate: 0.00019993920446324803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 9.0805	Cost: 33.17s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 9.0457	Cost: 9.42s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 8.9437	Cost: 12.19s
Train Epoch: 112 	Average Loss: 8.9722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0853

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Learning rate: 0.00019993810422739487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 9.1746	Cost: 33.81s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 8.9183	Cost: 9.43s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 8.9797	Cost: 12.13s
Train Epoch: 113 	Average Loss: 8.9543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0115

Saving model as e113_model.pt & e113_waveforms_supplementary.hdf5
Learning rate: 0.00019993699412804622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 9.0077	Cost: 34.40s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 8.8536	Cost: 9.56s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 8.9160	Cost: 12.90s
Train Epoch: 114 	Average Loss: 8.9045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9890

Saving model as e114_model.pt & e114_waveforms_supplementary.hdf5
Learning rate: 0.00019993587416531166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 8.9299	Cost: 33.05s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 8.8986	Cost: 10.18s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 8.8489	Cost: 11.51s
Train Epoch: 115 	Average Loss: 8.8624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0256

Learning rate: 0.00019993474433930176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 8.9525	Cost: 33.05s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 8.8722	Cost: 9.58s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 8.9939	Cost: 11.87s
Train Epoch: 116 	Average Loss: 8.8999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0190

Learning rate: 0.000199933604650128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 9.0378	Cost: 32.85s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 8.8069	Cost: 9.46s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 8.7987	Cost: 11.97s
Train Epoch: 117 	Average Loss: 8.8370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8967

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 0.0001999324550979029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 8.8592	Cost: 33.51s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 8.9064	Cost: 10.24s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 8.7368	Cost: 11.92s
Train Epoch: 118 	Average Loss: 8.8089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8605

Saving model as e118_model.pt & e118_waveforms_supplementary.hdf5
Learning rate: 0.00019993129568273988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 8.8901	Cost: 33.17s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 8.8484	Cost: 9.58s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 8.8625	Cost: 12.94s
Train Epoch: 119 	Average Loss: 8.8223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9475

Learning rate: 0.0001999301264047534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 8.9249	Cost: 33.56s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 8.7995	Cost: 9.62s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 8.8958	Cost: 12.66s
Train Epoch: 120 	Average Loss: 8.8275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9242

Learning rate: 0.00019992894726405882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 8.9112	Cost: 32.99s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 8.8247	Cost: 9.60s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 8.7426	Cost: 12.59s
Train Epoch: 121 	Average Loss: 8.7751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9025

Learning rate: 0.00019992775826077256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 8.8943	Cost: 32.86s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 8.8371	Cost: 9.60s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 8.7513	Cost: 12.72s
Train Epoch: 122 	Average Loss: 8.7705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8724

Learning rate: 0.00019992655939501196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 8.7869	Cost: 33.43s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 8.7729	Cost: 9.84s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 8.8020	Cost: 12.14s
Train Epoch: 123 	Average Loss: 8.7602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8979

Learning rate: 0.00019992535066689534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 8.8967	Cost: 32.81s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 8.7526	Cost: 9.62s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 8.7659	Cost: 12.46s
Train Epoch: 124 	Average Loss: 8.7406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8261

Saving model as e124_model.pt & e124_waveforms_supplementary.hdf5
Learning rate: 0.00019992413207654198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 8.8912	Cost: 32.90s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 8.6559	Cost: 9.76s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 8.6764	Cost: 12.73s
Train Epoch: 125 	Average Loss: 8.7010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7454

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 8.7763	Cost: 33.84s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 8.6604	Cost: 9.59s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 8.7609	Cost: 13.15s
Train Epoch: 126 	Average Loss: 8.6993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8905

Learning rate: 0.0001999216653096072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 8.9073	Cost: 33.91s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 8.7460	Cost: 9.55s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 8.7917	Cost: 12.47s
Train Epoch: 127 	Average Loss: 8.7102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8756

Learning rate: 0.00019992041713326917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 8.7892	Cost: 33.69s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 8.7650	Cost: 9.51s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 8.7437	Cost: 12.88s
Train Epoch: 128 	Average Loss: 8.7008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8652

Learning rate: 0.00019991915909518135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 8.7733	Cost: 34.17s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 8.6344	Cost: 10.16s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 8.6955	Cost: 11.57s
Train Epoch: 129 	Average Loss: 8.6407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7017

Saving model as e129_model.pt & e129_waveforms_supplementary.hdf5
Learning rate: 0.0001999178911954679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 8.8371	Cost: 32.61s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 8.6406	Cost: 9.49s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 8.6668	Cost: 12.64s
Train Epoch: 130 	Average Loss: 8.6386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7392

Learning rate: 0.0001999166134342539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 8.6955	Cost: 34.28s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 8.6619	Cost: 9.62s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 8.5678	Cost: 12.72s
Train Epoch: 131 	Average Loss: 8.6180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7595

Learning rate: 0.00019991532581166554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 8.7334	Cost: 32.96s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 8.7420	Cost: 9.61s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 8.6070	Cost: 12.05s
Train Epoch: 132 	Average Loss: 8.6244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7246

Learning rate: 0.00019991402832782987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 8.7062	Cost: 33.87s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 8.5536	Cost: 9.64s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 8.6413	Cost: 12.32s
Train Epoch: 133 	Average Loss: 8.5845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7984

Learning rate: 0.00019991272098287494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 8.8648	Cost: 32.89s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 8.6463	Cost: 9.54s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 8.5950	Cost: 11.89s
Train Epoch: 134 	Average Loss: 8.5808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6413

Saving model as e134_model.pt & e134_waveforms_supplementary.hdf5
Learning rate: 0.00019991140377692977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 8.7228	Cost: 34.16s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 8.5972	Cost: 10.10s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 8.5229	Cost: 12.06s
Train Epoch: 135 	Average Loss: 8.5520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6381

Saving model as e135_model.pt & e135_waveforms_supplementary.hdf5
Learning rate: 0.0001999100767101244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 8.6404	Cost: 33.90s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 8.6013	Cost: 9.42s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 8.5664	Cost: 12.17s
Train Epoch: 136 	Average Loss: 8.5372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7182

Learning rate: 0.00019990873978258976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 8.7069	Cost: 33.10s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 8.5057	Cost: 9.62s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 8.5122	Cost: 11.81s
Train Epoch: 137 	Average Loss: 8.5386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6276

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 0.0001999073929944578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 8.5402	Cost: 33.84s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 8.5282	Cost: 9.65s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 8.6089	Cost: 12.89s
Train Epoch: 138 	Average Loss: 8.4992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6599

Learning rate: 0.00019990603634586154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 8.6569	Cost: 33.87s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 8.6432	Cost: 9.63s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 8.4720	Cost: 12.77s
Train Epoch: 139 	Average Loss: 8.5130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6716

Learning rate: 0.00019990466983693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 8.6597	Cost: 33.79s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 8.4691	Cost: 9.65s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 8.4652	Cost: 12.32s
Train Epoch: 140 	Average Loss: 8.4700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5860

Saving model as e140_model.pt & e140_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 8.6810	Cost: 32.60s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 8.4358	Cost: 10.12s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 8.4941	Cost: 11.73s
Train Epoch: 141 	Average Loss: 8.4670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6129

Learning rate: 0.00019990190723863022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 8.5118	Cost: 32.55s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 8.4714	Cost: 10.09s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 8.4017	Cost: 11.79s
Train Epoch: 142 	Average Loss: 8.4567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5455

Saving model as e142_model.pt & e142_waveforms_supplementary.hdf5
Learning rate: 0.00019990051114952508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 8.4905	Cost: 33.02s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 8.4416	Cost: 9.41s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 8.4651	Cost: 11.91s
Train Epoch: 143 	Average Loss: 8.4167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5519

Learning rate: 0.0001998991052006348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 8.5475	Cost: 33.51s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 8.4330	Cost: 9.43s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 8.3526	Cost: 13.13s
Train Epoch: 144 	Average Loss: 8.3782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5306

Saving model as e144_model.pt & e144_waveforms_supplementary.hdf5
Learning rate: 0.0001998976893920981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 8.5792	Cost: 33.45s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 8.4449	Cost: 9.37s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 8.3174	Cost: 12.65s
Train Epoch: 145 	Average Loss: 8.3887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5582

Learning rate: 0.00019989626372405477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 8.5878	Cost: 32.82s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 8.4478	Cost: 9.43s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 8.4149	Cost: 12.54s
Train Epoch: 146 	Average Loss: 8.3902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5231

Saving model as e146_model.pt & e146_waveforms_supplementary.hdf5
Learning rate: 0.00019989482819664545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 8.5952	Cost: 33.60s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 8.4159	Cost: 9.63s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 8.3604	Cost: 11.84s
Train Epoch: 147 	Average Loss: 8.3653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5168

Saving model as e147_model.pt & e147_waveforms_supplementary.hdf5
Learning rate: 0.00019989338281001189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 8.5501	Cost: 32.92s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 8.3825	Cost: 9.79s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 8.3872	Cost: 11.84s
Train Epoch: 148 	Average Loss: 8.3773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5107

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 0.00019989192756429667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 8.4733	Cost: 33.70s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 8.3141	Cost: 10.11s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 8.4244	Cost: 12.02s
Train Epoch: 149 	Average Loss: 8.3317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5149

Learning rate: 0.00019989046245964345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 8.4492	Cost: 33.61s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 8.3219	Cost: 10.27s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 8.4134	Cost: 11.80s
Train Epoch: 150 	Average Loss: 8.3437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5543

Learning rate: 0.00019988898749619688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 8.5357	Cost: 33.52s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 8.3912	Cost: 9.63s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 8.3336	Cost: 12.15s
Train Epoch: 151 	Average Loss: 8.3355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4980

Saving model as e151_model.pt & e151_waveforms_supplementary.hdf5
Learning rate: 0.00019988750267410245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 8.5238	Cost: 33.33s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 8.3119	Cost: 9.62s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 8.3533	Cost: 11.84s
Train Epoch: 152 	Average Loss: 8.2959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4685

Saving model as e152_model.pt & e152_waveforms_supplementary.hdf5
Learning rate: 0.0001998860079935067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 8.4064	Cost: 34.03s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 8.2885	Cost: 9.63s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 8.2985	Cost: 12.65s
Train Epoch: 153 	Average Loss: 8.2794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4495

Saving model as e153_model.pt & e153_waveforms_supplementary.hdf5
Learning rate: 0.00019988450345455726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 8.3622	Cost: 33.42s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 8.2969	Cost: 9.58s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 8.2929	Cost: 12.38s
Train Epoch: 154 	Average Loss: 8.2549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4404

Saving model as e154_model.pt & e154_waveforms_supplementary.hdf5
Learning rate: 0.00019988298905740252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 8.4351	Cost: 33.37s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 8.2833	Cost: 9.52s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 8.3339	Cost: 12.89s
Train Epoch: 155 	Average Loss: 8.2757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4141

Saving model as e155_model.pt & e155_waveforms_supplementary.hdf5
Learning rate: 0.000199881464802192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 8.4894	Cost: 33.36s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 8.2625	Cost: 9.57s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 8.1831	Cost: 12.78s
Train Epoch: 156 	Average Loss: 8.2484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4422

Learning rate: 0.0001998799306890761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 8.4288	Cost: 33.33s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 8.2303	Cost: 9.49s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 8.3073	Cost: 12.91s
Train Epoch: 157 	Average Loss: 8.2745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4366

Learning rate: 0.00019987838671820622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 8.4926	Cost: 33.20s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 8.1586	Cost: 10.20s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 8.1567	Cost: 12.12s
Train Epoch: 158 	Average Loss: 8.1937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3137

Saving model as e158_model.pt & e158_waveforms_supplementary.hdf5
Learning rate: 0.00019987683288973478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 8.4803	Cost: 33.09s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 8.2017	Cost: 9.50s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 8.2162	Cost: 13.01s
Train Epoch: 159 	Average Loss: 8.2164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4123

Learning rate: 0.00019987526920381513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 8.3925	Cost: 33.47s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 8.1475	Cost: 9.50s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 8.1843	Cost: 12.55s
Train Epoch: 160 	Average Loss: 8.2066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3947

Learning rate: 0.00019987369566060162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 8.4632	Cost: 33.15s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 8.1685	Cost: 9.49s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 8.0928	Cost: 12.43s
Train Epoch: 161 	Average Loss: 8.1652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2947

Saving model as e161_model.pt & e161_waveforms_supplementary.hdf5
Learning rate: 0.0001998721122602495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 8.4000	Cost: 33.53s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 8.1281	Cost: 9.61s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 8.1172	Cost: 12.53s
Train Epoch: 162 	Average Loss: 8.1494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4329

Learning rate: 0.00019987051900291508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 8.3307	Cost: 33.01s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 8.0992	Cost: 10.19s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 8.0952	Cost: 11.45s
Train Epoch: 163 	Average Loss: 8.1186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3463

Learning rate: 0.00019986891588875562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 8.2778	Cost: 33.97s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 8.0949	Cost: 9.53s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 8.0765	Cost: 12.35s
Train Epoch: 164 	Average Loss: 8.1374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3666

Learning rate: 0.0001998673029179293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 8.4031	Cost: 33.93s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 8.1058	Cost: 9.53s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 8.1380	Cost: 12.63s
Train Epoch: 165 	Average Loss: 8.1380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3869

Learning rate: 0.00019986568009059536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 8.3233	Cost: 33.23s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 8.1977	Cost: 9.50s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 8.0686	Cost: 12.36s
Train Epoch: 166 	Average Loss: 8.0963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3183

Learning rate: 0.00019986404740691393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 8.1968	Cost: 32.94s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 8.0478	Cost: 10.25s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 8.1034	Cost: 11.37s
Train Epoch: 167 	Average Loss: 8.0672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3230

Learning rate: 0.00019986240486704617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 8.3369	Cost: 33.94s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 8.0839	Cost: 9.56s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 8.0411	Cost: 12.51s
Train Epoch: 168 	Average Loss: 8.0832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2980

Learning rate: 0.00019986075247115415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 8.2798	Cost: 33.30s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 8.1157	Cost: 9.52s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 8.0509	Cost: 12.56s
Train Epoch: 169 	Average Loss: 8.0381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3156

Learning rate: 0.00019985909021940103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 8.2708	Cost: 34.68s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 8.0160	Cost: 10.00s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 8.0416	Cost: 12.02s
Train Epoch: 170 	Average Loss: 8.0535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1995

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 0.0001998574181119508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 8.1801	Cost: 33.53s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 8.0717	Cost: 9.54s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 8.0347	Cost: 11.90s
Train Epoch: 171 	Average Loss: 8.0199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2492

Learning rate: 0.00019985573614896853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 8.1968	Cost: 33.47s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 7.9048	Cost: 9.52s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 7.9723	Cost: 12.33s
Train Epoch: 172 	Average Loss: 8.0295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2670

Learning rate: 0.00019985404433062024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 8.3114	Cost: 33.34s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 8.0863	Cost: 9.54s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 8.0457	Cost: 12.88s
Train Epoch: 173 	Average Loss: 8.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1849

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 0.00019985234265707287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 8.2760	Cost: 33.79s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 7.9587	Cost: 9.52s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 8.0239	Cost: 12.80s
Train Epoch: 174 	Average Loss: 7.9560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2181

Learning rate: 0.00019985063112849436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 8.1455	Cost: 34.49s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 8.0549	Cost: 9.52s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 7.9726	Cost: 12.82s
Train Epoch: 175 	Average Loss: 7.9602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1626

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 8.0988	Cost: 33.91s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 7.9444	Cost: 9.55s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 7.9578	Cost: 12.60s
Train Epoch: 176 	Average Loss: 7.9261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1527

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Learning rate: 0.00019984717850692066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 8.1912	Cost: 33.49s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 7.9806	Cost: 10.13s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 8.0240	Cost: 12.32s
Train Epoch: 177 	Average Loss: 7.9219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1567

Learning rate: 0.00019984543741426617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 8.1083	Cost: 33.46s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 7.8931	Cost: 9.54s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 7.9077	Cost: 12.76s
Train Epoch: 178 	Average Loss: 7.9102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1984

Learning rate: 0.0001998436864672621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 8.2307	Cost: 32.92s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 7.8786	Cost: 9.64s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 7.9025	Cost: 12.67s
Train Epoch: 179 	Average Loss: 7.8939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1143

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Learning rate: 0.00019984192566608125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 8.1685	Cost: 33.12s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 7.9132	Cost: 9.56s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 7.8932	Cost: 12.27s
Train Epoch: 180 	Average Loss: 7.8768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1241

Learning rate: 0.00019984015501089739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 8.0748	Cost: 32.70s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 7.8978	Cost: 10.12s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 7.8898	Cost: 12.46s
Train Epoch: 181 	Average Loss: 7.8831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0920

Saving model as e181_model.pt & e181_waveforms_supplementary.hdf5
Learning rate: 0.00019983837450188524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 8.1172	Cost: 33.34s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 7.8384	Cost: 9.50s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 7.8735	Cost: 12.89s
Train Epoch: 182 	Average Loss: 7.8572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1813

Learning rate: 0.0001998365841392206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 8.1925	Cost: 33.86s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 7.9327	Cost: 10.09s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 7.7728	Cost: 11.96s
Train Epoch: 183 	Average Loss: 7.8460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1382

Learning rate: 0.00019983478392308012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 8.1497	Cost: 33.96s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 7.7398	Cost: 9.59s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 7.8397	Cost: 12.11s
Train Epoch: 184 	Average Loss: 7.8147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1901

Learning rate: 0.0001998329738536415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 8.1416	Cost: 33.54s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 7.7311	Cost: 9.43s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 7.8281	Cost: 12.66s
Train Epoch: 185 	Average Loss: 7.8075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0915

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Learning rate: 0.00019983115393108338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 8.1001	Cost: 32.96s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 7.8237	Cost: 9.63s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 7.7751	Cost: 11.91s
Train Epoch: 186 	Average Loss: 7.7876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0466

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Learning rate: 0.0001998293241555854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 8.0503	Cost: 33.59s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 7.8051	Cost: 10.24s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 7.7877	Cost: 11.97s
Train Epoch: 187 	Average Loss: 7.7686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9743

Saving model as e187_model.pt & e187_waveforms_supplementary.hdf5
Learning rate: 0.0001998274845273281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 7.9683	Cost: 32.99s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 7.7459	Cost: 9.42s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 7.7319	Cost: 12.11s
Train Epoch: 188 	Average Loss: 7.7521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0015

Learning rate: 0.00019982563504649309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 8.1050	Cost: 33.11s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 7.7570	Cost: 9.44s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 7.6913	Cost: 12.59s
Train Epoch: 189 	Average Loss: 7.7340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0127

Learning rate: 0.00019982377571326284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 8.0011	Cost: 33.64s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 7.7269	Cost: 9.44s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 7.6894	Cost: 12.85s
Train Epoch: 190 	Average Loss: 7.7057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9561

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 0.00019982190652782097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 8.0063	Cost: 33.09s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 7.8816	Cost: 9.45s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 7.6745	Cost: 11.96s
Train Epoch: 191 	Average Loss: 7.7487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0034

Learning rate: 0.0001998200274903519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 8.0165	Cost: 33.35s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 7.7870	Cost: 9.42s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 7.6755	Cost: 12.24s
Train Epoch: 192 	Average Loss: 7.7243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0183

Learning rate: 0.00019981813860104106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 7.9701	Cost: 34.24s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 7.5994	Cost: 9.56s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 7.6758	Cost: 12.59s
Train Epoch: 193 	Average Loss: 7.6917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9584

Learning rate: 0.0001998162398600749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 7.9600	Cost: 34.77s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 7.6245	Cost: 9.56s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 7.6884	Cost: 12.88s
Train Epoch: 194 	Average Loss: 7.6548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9709

Learning rate: 0.00019981433126764085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 7.9815	Cost: 33.99s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 7.6408	Cost: 9.44s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 7.5568	Cost: 12.85s
Train Epoch: 195 	Average Loss: 7.6518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9065

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Learning rate: 0.00019981241282392723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 7.8991	Cost: 33.44s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 7.6974	Cost: 10.11s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 7.6572	Cost: 12.24s
Train Epoch: 196 	Average Loss: 7.6611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9960

Learning rate: 0.0001998104845291234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 7.9795	Cost: 34.13s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 7.6339	Cost: 10.15s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 7.6189	Cost: 12.38s
Train Epoch: 197 	Average Loss: 7.6385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9694

Learning rate: 0.00019980854638341968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 7.9504	Cost: 33.85s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 7.6962	Cost: 9.45s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 7.5773	Cost: 12.32s
Train Epoch: 198 	Average Loss: 7.6202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8961

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 0.00019980659838700736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 7.7764	Cost: 33.63s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 7.5338	Cost: 9.43s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 7.6231	Cost: 12.46s
Train Epoch: 199 	Average Loss: 7.5769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8492

Saving model as e199_model.pt & e199_waveforms_supplementary.hdf5
Learning rate: 0.0001998046405400787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 7.9317	Cost: 33.57s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 7.6046	Cost: 9.44s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 7.5762	Cost: 12.56s
Train Epoch: 200 	Average Loss: 7.5862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9320

Learning rate: 0.00019980267284282693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 7.8275	Cost: 33.10s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 7.5178	Cost: 9.40s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 7.6171	Cost: 12.74s
Train Epoch: 201 	Average Loss: 7.5881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8904

Learning rate: 0.00019980069529544622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 7.9365	Cost: 33.30s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 7.5779	Cost: 9.41s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 7.4361	Cost: 12.46s
Train Epoch: 202 	Average Loss: 7.5506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8515

Learning rate: 0.0001997987078981318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 7.8513	Cost: 33.12s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 7.6051	Cost: 9.47s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 7.5199	Cost: 12.21s
Train Epoch: 203 	Average Loss: 7.5525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8969

Learning rate: 0.00019979671065107978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 7.7755	Cost: 33.16s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 7.4974	Cost: 9.72s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 7.5205	Cost: 11.88s
Train Epoch: 204 	Average Loss: 7.5378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9209

Learning rate: 0.0001997947035544873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 7.8906	Cost: 33.56s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 7.5430	Cost: 9.98s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 7.5931	Cost: 12.02s
Train Epoch: 205 	Average Loss: 7.5050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7963

Saving model as e205_model.pt & e205_waveforms_supplementary.hdf5
Learning rate: 0.00019979268660855247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 7.8227	Cost: 35.54s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 7.5206	Cost: 9.46s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 7.3941	Cost: 14.35s
Train Epoch: 206 	Average Loss: 7.4813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8468

Learning rate: 0.00019979065981347432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 7.7775	Cost: 33.72s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 7.4658	Cost: 9.63s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 7.3990	Cost: 12.79s
Train Epoch: 207 	Average Loss: 7.4563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7818

Saving model as e207_model.pt & e207_waveforms_supplementary.hdf5
Learning rate: 0.0001997886231694529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 7.7944	Cost: 33.64s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 7.5026	Cost: 9.75s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 7.4180	Cost: 12.06s
Train Epoch: 208 	Average Loss: 7.4401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7988

Learning rate: 0.0001997865766766892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 7.7816	Cost: 33.35s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 7.3870	Cost: 9.43s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 7.3860	Cost: 12.48s
Train Epoch: 209 	Average Loss: 7.4086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7921

Learning rate: 0.00019978452033538524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 7.8227	Cost: 33.15s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 7.3648	Cost: 9.45s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 7.4534	Cost: 12.45s
Train Epoch: 210 	Average Loss: 7.4198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7679

Saving model as e210_model.pt & e210_waveforms_supplementary.hdf5
Learning rate: 0.00019978245414574395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 7.6949	Cost: 33.59s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 7.4054	Cost: 9.43s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 7.3397	Cost: 12.98s
Train Epoch: 211 	Average Loss: 7.3839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7633

Saving model as e211_model.pt & e211_waveforms_supplementary.hdf5
Learning rate: 0.00019978037810796924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 7.8011	Cost: 33.08s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 7.3960	Cost: 10.11s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 7.3528	Cost: 11.52s
Train Epoch: 212 	Average Loss: 7.3611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7339

Saving model as e212_model.pt & e212_waveforms_supplementary.hdf5
Learning rate: 0.000199778292222266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 7.6816	Cost: 33.11s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 7.3041	Cost: 9.42s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 7.3416	Cost: 12.11s
Train Epoch: 213 	Average Loss: 7.3511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7594

Learning rate: 0.00019977619648884015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 7.6983	Cost: 33.21s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 7.3230	Cost: 9.41s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 7.4270	Cost: 12.10s
Train Epoch: 214 	Average Loss: 7.3521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7408

Learning rate: 0.0001997740909078985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 7.7460	Cost: 33.91s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 7.3311	Cost: 9.43s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 7.3601	Cost: 12.89s
Train Epoch: 215 	Average Loss: 7.3138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7075

Saving model as e215_model.pt & e215_waveforms_supplementary.hdf5
Learning rate: 0.0001997719754796489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 7.6056	Cost: 32.74s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 7.3518	Cost: 9.42s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 7.2816	Cost: 12.13s
Train Epoch: 216 	Average Loss: 7.2874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7210

Learning rate: 0.00019976985020430003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 7.6578	Cost: 32.83s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 7.2434	Cost: 9.43s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 7.2721	Cost: 12.47s
Train Epoch: 217 	Average Loss: 7.2789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6426

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 0.00019976771508206176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 7.6755	Cost: 33.41s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 7.2622	Cost: 9.42s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 7.3041	Cost: 12.26s
Train Epoch: 218 	Average Loss: 7.2757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6746

Learning rate: 0.00019976557011314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 7.7217	Cost: 33.42s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 7.2855	Cost: 9.43s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 7.1751	Cost: 12.40s
Train Epoch: 219 	Average Loss: 7.2760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6438

Learning rate: 0.00019976341529776072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 7.6068	Cost: 33.34s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 7.2058	Cost: 9.43s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 7.3210	Cost: 12.28s
Train Epoch: 220 	Average Loss: 7.2351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6889

Learning rate: 0.00019976125063612233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 7.6079	Cost: 33.71s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 7.2063	Cost: 10.12s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 7.1643	Cost: 12.66s
Train Epoch: 221 	Average Loss: 7.2474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5981

Saving model as e221_model.pt & e221_waveforms_supplementary.hdf5
Learning rate: 0.00019975907612844327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 7.5900	Cost: 33.52s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 7.1099	Cost: 10.12s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 7.1653	Cost: 11.56s
Train Epoch: 222 	Average Loss: 7.2163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5994

Learning rate: 0.00019975689177493812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 7.4363	Cost: 32.93s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 7.1317	Cost: 9.40s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 7.2110	Cost: 12.51s
Train Epoch: 223 	Average Loss: 7.1786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6382

Learning rate: 0.00019975469757582245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 7.6495	Cost: 34.26s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 7.1034	Cost: 9.41s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 7.1842	Cost: 12.87s
Train Epoch: 224 	Average Loss: 7.1704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6120

Learning rate: 0.00019975249353131286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 7.5599	Cost: 33.45s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 7.1808	Cost: 9.37s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 7.0680	Cost: 12.67s
Train Epoch: 225 	Average Loss: 7.1496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5953

Saving model as e225_model.pt & e225_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 7.5586	Cost: 34.24s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 7.1369	Cost: 9.65s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 7.1510	Cost: 12.10s
Train Epoch: 226 	Average Loss: 7.1504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6434

Learning rate: 0.0001997480559069829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 7.5953	Cost: 33.65s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 7.0893	Cost: 9.59s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 7.2315	Cost: 12.17s
Train Epoch: 227 	Average Loss: 7.1173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6089

Learning rate: 0.00019974582232760058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 7.5218	Cost: 34.30s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 7.1654	Cost: 9.53s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 7.0277	Cost: 13.00s
Train Epoch: 228 	Average Loss: 7.1288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5421

Saving model as e228_model.pt & e228_waveforms_supplementary.hdf5
Learning rate: 0.0001997435789037002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 7.4759	Cost: 32.79s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 7.0712	Cost: 9.42s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 7.0136	Cost: 12.03s
Train Epoch: 229 	Average Loss: 7.1062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5633

Learning rate: 0.0001997413256355033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 7.5037	Cost: 34.09s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 7.0183	Cost: 9.73s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 7.0975	Cost: 12.09s
Train Epoch: 230 	Average Loss: 7.0684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4989

Saving model as e230_model.pt & e230_waveforms_supplementary.hdf5
Learning rate: 0.0001997390625232322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 7.5124	Cost: 33.39s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 7.0016	Cost: 9.55s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 6.9284	Cost: 12.57s
Train Epoch: 231 	Average Loss: 7.0344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5137

Learning rate: 0.00019973678956711026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 7.6050	Cost: 33.11s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 6.9779	Cost: 9.54s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 7.0188	Cost: 12.50s
Train Epoch: 232 	Average Loss: 7.0507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5113

Learning rate: 0.00019973450676736185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 7.4187	Cost: 32.84s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 6.9718	Cost: 9.49s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 6.9792	Cost: 12.87s
Train Epoch: 233 	Average Loss: 7.0025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5288

Learning rate: 0.00019973221412421225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 7.4296	Cost: 33.18s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 6.9296	Cost: 9.52s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 6.9498	Cost: 12.66s
Train Epoch: 234 	Average Loss: 7.0027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5247

Learning rate: 0.0001997299116378877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 7.4591	Cost: 32.99s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 7.0060	Cost: 9.46s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 6.9692	Cost: 11.91s
Train Epoch: 235 	Average Loss: 6.9708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5625

Learning rate: 0.0001997275993086155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 7.4783	Cost: 33.52s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 6.9255	Cost: 9.43s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 6.9077	Cost: 11.99s
Train Epoch: 236 	Average Loss: 6.9629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4031

Saving model as e236_model.pt & e236_waveforms_supplementary.hdf5
Learning rate: 0.0001997252771366239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 7.4006	Cost: 33.24s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 6.9443	Cost: 9.48s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 6.9306	Cost: 11.68s
Train Epoch: 237 	Average Loss: 6.9317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4483

Learning rate: 0.000199722945122142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 7.4154	Cost: 33.37s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 6.8012	Cost: 9.47s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 6.8614	Cost: 12.79s
Train Epoch: 238 	Average Loss: 6.9074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4470

Learning rate: 0.0001997206032654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 7.4257	Cost: 33.76s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 6.9116	Cost: 9.45s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 6.8874	Cost: 12.62s
Train Epoch: 239 	Average Loss: 6.9015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4216

Learning rate: 0.00019971825156662903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 7.3779	Cost: 34.13s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 6.8468	Cost: 9.47s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 6.8031	Cost: 12.74s
Train Epoch: 240 	Average Loss: 6.8592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3639

Saving model as e240_model.pt & e240_waveforms_supplementary.hdf5
Learning rate: 0.00019971589002606117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 7.4249	Cost: 33.90s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 6.8476	Cost: 9.49s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 6.8021	Cost: 12.95s
Train Epoch: 241 	Average Loss: 6.8654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4063

Learning rate: 0.00019971351864392958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 7.3967	Cost: 33.28s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 6.8011	Cost: 9.47s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 6.7838	Cost: 12.79s
Train Epoch: 242 	Average Loss: 6.8339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3879

Learning rate: 0.00019971113742046817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 7.3680	Cost: 33.03s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 6.7946	Cost: 9.47s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 6.7445	Cost: 13.64s
Train Epoch: 243 	Average Loss: 6.8196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3644

Learning rate: 0.00019970874635591207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 7.3946	Cost: 33.14s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 6.7657	Cost: 9.68s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 6.7456	Cost: 11.69s
Train Epoch: 244 	Average Loss: 6.7939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3432

Saving model as e244_model.pt & e244_waveforms_supplementary.hdf5
Learning rate: 0.00019970634545049727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 7.2452	Cost: 33.17s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 6.7808	Cost: 9.48s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 6.7351	Cost: 12.83s
Train Epoch: 245 	Average Loss: 6.7904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3427

Saving model as e245_model.pt & e245_waveforms_supplementary.hdf5
Learning rate: 0.0001997039347044607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 7.3751	Cost: 34.02s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 6.7044	Cost: 9.47s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 6.7264	Cost: 12.99s
Train Epoch: 246 	Average Loss: 6.7464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2593

Saving model as e246_model.pt & e246_waveforms_supplementary.hdf5
Learning rate: 0.00019970151411804023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 7.2939	Cost: 32.74s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 6.6799	Cost: 9.48s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 6.6857	Cost: 11.86s
Train Epoch: 247 	Average Loss: 6.7429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3334

Learning rate: 0.00019969908369147485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 7.2066	Cost: 33.42s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 6.6579	Cost: 9.51s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 6.6255	Cost: 12.71s
Train Epoch: 248 	Average Loss: 6.7243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2922

Learning rate: 0.00019969664342500438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 7.3014	Cost: 32.82s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 6.5364	Cost: 9.47s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 6.6400	Cost: 11.90s
Train Epoch: 249 	Average Loss: 6.6960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3126

Learning rate: 0.00019969419331886966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 7.2065	Cost: 32.72s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 6.6099	Cost: 9.48s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 6.6434	Cost: 13.25s
Train Epoch: 250 	Average Loss: 6.6895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2328

Saving model as e250_model.pt & e250_waveforms_supplementary.hdf5
Learning rate: 0.0001996917333733126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 7.2629	Cost: 33.65s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 6.6089	Cost: 9.46s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 6.6800	Cost: 12.37s
Train Epoch: 251 	Average Loss: 6.6773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2032

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Learning rate: 0.00019968926358857587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 7.1486	Cost: 33.44s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 6.6022	Cost: 9.47s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 6.6892	Cost: 12.77s
Train Epoch: 252 	Average Loss: 6.6609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2671

Learning rate: 0.00019968678396490325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 7.2892	Cost: 32.96s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 6.5983	Cost: 9.46s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 6.6541	Cost: 11.75s
Train Epoch: 253 	Average Loss: 6.6360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1988

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 0.00019968429450253954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 7.1099	Cost: 32.68s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 6.5518	Cost: 9.46s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 6.5629	Cost: 13.42s
Train Epoch: 254 	Average Loss: 6.6153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1958

Saving model as e254_model.pt & e254_waveforms_supplementary.hdf5
Learning rate: 0.0001996817952017304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 7.0061	Cost: 33.44s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 6.5848	Cost: 9.46s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 6.5030	Cost: 13.91s
Train Epoch: 255 	Average Loss: 6.5612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1701

Saving model as e255_model.pt & e255_waveforms_supplementary.hdf5
Learning rate: 0.00019967928606272244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 7.1919	Cost: 32.94s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 6.5561	Cost: 9.46s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 6.5591	Cost: 13.26s
Train Epoch: 256 	Average Loss: 6.5680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2491

Learning rate: 0.0001996767670857634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 7.3164	Cost: 32.75s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 6.5642	Cost: 9.47s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 6.5482	Cost: 12.00s
Train Epoch: 257 	Average Loss: 6.5942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1493

Saving model as e257_model.pt & e257_waveforms_supplementary.hdf5
Learning rate: 0.00019967423827110182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 7.1351	Cost: 32.98s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 6.4468	Cost: 9.47s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 6.4935	Cost: 11.83s
Train Epoch: 258 	Average Loss: 6.5101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0475

Saving model as e258_model.pt & e258_waveforms_supplementary.hdf5
Learning rate: 0.00019967169961898734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 7.0899	Cost: 33.29s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 6.3831	Cost: 9.46s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 6.4927	Cost: 13.09s
Train Epoch: 259 	Average Loss: 6.4889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1455

Learning rate: 0.00019966915112967047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 7.1591	Cost: 32.47s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 6.3802	Cost: 9.46s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 6.4280	Cost: 11.88s
Train Epoch: 260 	Average Loss: 6.4768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1155

Learning rate: 0.00019966659280340273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 7.0354	Cost: 33.45s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 6.4738	Cost: 9.52s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 6.3842	Cost: 12.16s
Train Epoch: 261 	Average Loss: 6.4561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1999

Learning rate: 0.00019966402464043667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 7.1242	Cost: 33.40s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 6.4980	Cost: 9.61s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 6.4736	Cost: 12.63s
Train Epoch: 262 	Average Loss: 6.4866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1204

Learning rate: 0.00019966144664102572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 7.1683	Cost: 32.90s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 6.4246	Cost: 9.49s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 6.3679	Cost: 12.88s
Train Epoch: 263 	Average Loss: 6.4479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0301

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Learning rate: 0.00019965885880542434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 6.9594	Cost: 32.98s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 6.3298	Cost: 9.47s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 6.4816	Cost: 12.16s
Train Epoch: 264 	Average Loss: 6.4104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0972

Learning rate: 0.00019965626113388794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 7.0446	Cost: 32.93s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 6.3334	Cost: 9.47s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 6.4184	Cost: 11.91s
Train Epoch: 265 	Average Loss: 6.4194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0581

Learning rate: 0.00019965365362667288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 7.0006	Cost: 32.67s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 6.3962	Cost: 9.47s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 6.4140	Cost: 12.80s
Train Epoch: 266 	Average Loss: 6.3747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0337

Learning rate: 0.0001996510362840365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 7.0754	Cost: 33.04s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 6.3861	Cost: 9.47s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 6.3808	Cost: 13.94s
Train Epoch: 267 	Average Loss: 6.3626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0569

Learning rate: 0.00019964840910623716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 7.0844	Cost: 33.54s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 6.2288	Cost: 9.46s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 6.3381	Cost: 12.93s
Train Epoch: 268 	Average Loss: 6.3203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0115

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Learning rate: 0.00019964577209353413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 6.9764	Cost: 33.51s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 6.3302	Cost: 9.52s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 6.2703	Cost: 12.37s
Train Epoch: 269 	Average Loss: 6.3075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0280

Learning rate: 0.00019964312524618766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 7.0613	Cost: 33.62s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 6.1094	Cost: 9.47s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 6.2473	Cost: 12.17s
Train Epoch: 270 	Average Loss: 6.2883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9580

Saving model as e270_model.pt & e270_waveforms_supplementary.hdf5
Learning rate: 0.000199640468564459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 6.8925	Cost: 33.42s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 6.2430	Cost: 9.49s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 6.3043	Cost: 13.35s
Train Epoch: 271 	Average Loss: 6.2571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0142

Learning rate: 0.00019963780204861037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 6.8820	Cost: 32.80s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 6.1728	Cost: 9.48s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 6.2469	Cost: 12.05s
Train Epoch: 272 	Average Loss: 6.2578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9594

Learning rate: 0.0001996351256989049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 6.9588	Cost: 33.50s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 6.2199	Cost: 9.48s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 6.1859	Cost: 12.23s
Train Epoch: 273 	Average Loss: 6.2472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9125

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 0.0001996324395156068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 6.9539	Cost: 33.40s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 6.1356	Cost: 9.48s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 6.1193	Cost: 12.49s
Train Epoch: 274 	Average Loss: 6.1894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9218

Learning rate: 0.00019962974349898107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 6.9213	Cost: 33.19s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 6.1537	Cost: 9.43s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 6.2421	Cost: 12.82s
Train Epoch: 275 	Average Loss: 6.2000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9959

Learning rate: 0.0001996270376492939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 6.9441	Cost: 33.88s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 6.0582	Cost: 9.54s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 6.1015	Cost: 13.29s
Train Epoch: 276 	Average Loss: 6.1683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8863

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Learning rate: 0.00019962432196681234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 6.8642	Cost: 33.60s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 6.1510	Cost: 9.49s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 6.2182	Cost: 12.22s
Train Epoch: 277 	Average Loss: 6.1714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8856

Saving model as e277_model.pt & e277_waveforms_supplementary.hdf5
Learning rate: 0.00019962159645180437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 6.9666	Cost: 33.86s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 6.0602	Cost: 9.47s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 6.0649	Cost: 12.53s
Train Epoch: 278 	Average Loss: 6.1323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8722

Saving model as e278_model.pt & e278_waveforms_supplementary.hdf5
Learning rate: 0.00019961886110453903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 6.7535	Cost: 33.15s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 5.9947	Cost: 9.47s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 6.0343	Cost: 12.68s
Train Epoch: 279 	Average Loss: 6.0616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8961

Learning rate: 0.00019961611592528625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 6.9137	Cost: 33.30s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 6.0155	Cost: 9.47s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 6.0235	Cost: 12.58s
Train Epoch: 280 	Average Loss: 6.0714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8288

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Learning rate: 0.000199613360914317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 6.7585	Cost: 33.88s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 5.9845	Cost: 9.46s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 5.9869	Cost: 11.79s
Train Epoch: 281 	Average Loss: 6.0298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8113

Saving model as e281_model.pt & e281_waveforms_supplementary.hdf5
Learning rate: 0.00019961059607190318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 6.7145	Cost: 33.17s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 5.9174	Cost: 9.47s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 6.0103	Cost: 11.98s
Train Epoch: 282 	Average Loss: 6.0367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8145

Learning rate: 0.00019960782139831766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 6.7363	Cost: 32.75s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 5.8612	Cost: 9.41s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 6.0112	Cost: 12.18s
Train Epoch: 283 	Average Loss: 5.9712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7630

Saving model as e283_model.pt & e283_waveforms_supplementary.hdf5
Learning rate: 0.00019960503689383428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 6.7257	Cost: 32.94s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 5.8690	Cost: 9.49s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 6.0163	Cost: 13.27s
Train Epoch: 284 	Average Loss: 6.0210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8946

Learning rate: 0.0001996022425587279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 6.7681	Cost: 32.94s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 5.9189	Cost: 9.48s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 5.8192	Cost: 13.24s
Train Epoch: 285 	Average Loss: 5.9930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7799

Learning rate: 0.0001995994383932743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 6.7125	Cost: 32.96s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 5.8764	Cost: 9.64s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 5.8899	Cost: 12.49s
Train Epoch: 286 	Average Loss: 5.9177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6872

Saving model as e286_model.pt & e286_waveforms_supplementary.hdf5
Learning rate: 0.0001995966243977502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 6.7643	Cost: 34.00s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 5.7457	Cost: 9.46s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 5.7468	Cost: 12.62s
Train Epoch: 287 	Average Loss: 5.8539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7160

Learning rate: 0.0001995938005724334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 6.7810	Cost: 33.55s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 5.8493	Cost: 9.46s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 5.9505	Cost: 12.57s
Train Epoch: 288 	Average Loss: 5.8895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7398

Learning rate: 0.00019959096691760252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 6.6369	Cost: 32.85s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 5.7719	Cost: 9.45s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 5.8510	Cost: 12.93s
Train Epoch: 289 	Average Loss: 5.8555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7010

Learning rate: 0.00019958812343353726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 6.5810	Cost: 33.49s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 5.8229	Cost: 9.46s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 5.8628	Cost: 12.51s
Train Epoch: 290 	Average Loss: 5.9035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6771

Saving model as e290_model.pt & e290_waveforms_supplementary.hdf5
Learning rate: 0.0001995852701205183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 6.7365	Cost: 33.21s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 5.7340	Cost: 9.50s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 5.6797	Cost: 12.02s
Train Epoch: 291 	Average Loss: 5.8449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6378

Saving model as e291_model.pt & e291_waveforms_supplementary.hdf5
Learning rate: 0.0001995824069788272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 6.6798	Cost: 33.14s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 5.6507	Cost: 9.47s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 5.7773	Cost: 11.82s
Train Epoch: 292 	Average Loss: 5.7822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7191

Learning rate: 0.00019957953400874656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 6.5438	Cost: 32.87s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 5.6011	Cost: 9.47s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 5.6815	Cost: 13.87s
Train Epoch: 293 	Average Loss: 5.7460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5660

Saving model as e293_model.pt & e293_waveforms_supplementary.hdf5
Learning rate: 0.00019957665121055995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 6.4984	Cost: 33.33s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 5.7028	Cost: 9.46s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 5.6701	Cost: 12.71s
Train Epoch: 294 	Average Loss: 5.7554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6216

Learning rate: 0.00019957375858455185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 6.5912	Cost: 33.67s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 5.7919	Cost: 9.49s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 5.7151	Cost: 12.23s
Train Epoch: 295 	Average Loss: 5.7466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5401

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 0.00019957085613100776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 6.5341	Cost: 32.96s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 5.6381	Cost: 9.48s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 5.6028	Cost: 12.88s
Train Epoch: 296 	Average Loss: 5.6992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5542

Learning rate: 0.00019956794385021415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 6.4664	Cost: 33.94s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 5.6463	Cost: 9.52s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 5.5587	Cost: 13.27s
Train Epoch: 297 	Average Loss: 5.6704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5451

Learning rate: 0.00019956502174245846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 6.5609	Cost: 33.28s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 5.5868	Cost: 9.49s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 5.6614	Cost: 13.29s
Train Epoch: 298 	Average Loss: 5.6467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5869

Learning rate: 0.0001995620898080291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 6.4908	Cost: 33.17s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 5.6311	Cost: 9.48s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 5.5420	Cost: 13.41s
Train Epoch: 299 	Average Loss: 5.6548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5085

Saving model as e299_model.pt & e299_waveforms_supplementary.hdf5
Learning rate: 0.00019955914804721542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 6.5910	Cost: 32.80s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 5.6058	Cost: 9.48s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 5.5605	Cost: 13.23s
Train Epoch: 300 	Average Loss: 5.6445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4946

Saving model as e300_model.pt & e300_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 6.4212	Cost: 33.31s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 5.4973	Cost: 9.48s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 5.5781	Cost: 13.05s
Train Epoch: 301 	Average Loss: 5.6038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4892

Saving model as e301_model.pt & e301_waveforms_supplementary.hdf5
Learning rate: 0.0001995532350475974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 6.6046	Cost: 33.59s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 5.5149	Cost: 9.54s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 5.5084	Cost: 13.11s
Train Epoch: 302 	Average Loss: 5.5887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5248

Learning rate: 0.00019955026380937669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 6.4320	Cost: 33.22s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 5.4042	Cost: 9.49s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 5.5131	Cost: 12.98s
Train Epoch: 303 	Average Loss: 5.5339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4585

Saving model as e303_model.pt & e303_waveforms_supplementary.hdf5
Learning rate: 0.00019954728274593884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 6.4183	Cost: 33.06s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 5.5529	Cost: 9.48s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 5.5470	Cost: 12.93s
Train Epoch: 304 	Average Loss: 5.5565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4785

Learning rate: 0.00019954429185757805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 6.4792	Cost: 33.21s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 5.4454	Cost: 9.49s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 5.3828	Cost: 13.04s
Train Epoch: 305 	Average Loss: 5.5307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4438

Saving model as e305_model.pt & e305_waveforms_supplementary.hdf5
Learning rate: 0.00019954129114458955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 6.6002	Cost: 33.56s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 5.4311	Cost: 9.47s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 5.4366	Cost: 13.46s
Train Epoch: 306 	Average Loss: 5.5139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4764

Learning rate: 0.00019953828060726943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 6.3750	Cost: 33.09s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 5.3815	Cost: 9.48s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 5.3618	Cost: 11.89s
Train Epoch: 307 	Average Loss: 5.4979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4917

Learning rate: 0.00019953526024591494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 6.4594	Cost: 32.59s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 5.3406	Cost: 9.49s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 5.3995	Cost: 13.53s
Train Epoch: 308 	Average Loss: 5.4735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4511

Learning rate: 0.00019953223006082406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 6.2991	Cost: 33.59s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 5.2340	Cost: 9.49s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 5.3272	Cost: 11.87s
Train Epoch: 309 	Average Loss: 5.3979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3857

Saving model as e309_model.pt & e309_waveforms_supplementary.hdf5
Learning rate: 0.00019952919005229592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 6.2601	Cost: 33.10s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 5.3061	Cost: 9.48s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 5.3228	Cost: 12.70s
Train Epoch: 310 	Average Loss: 5.3759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3902

Learning rate: 0.00019952614022063054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 6.3007	Cost: 33.92s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 5.3285	Cost: 9.48s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 5.3114	Cost: 12.09s
Train Epoch: 311 	Average Loss: 5.3483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3895

Learning rate: 0.00019952308056612892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 6.3365	Cost: 33.24s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 5.2692	Cost: 9.48s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 5.3592	Cost: 13.83s
Train Epoch: 312 	Average Loss: 5.3672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3639

Saving model as e312_model.pt & e312_waveforms_supplementary.hdf5
Learning rate: 0.00019952001108909304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 6.4150	Cost: 33.29s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 5.2505	Cost: 9.48s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 5.2203	Cost: 13.17s
Train Epoch: 313 	Average Loss: 5.3134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3906

Learning rate: 0.00019951693178982586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 6.1669	Cost: 33.55s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 5.2044	Cost: 9.49s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 5.1969	Cost: 13.15s
Train Epoch: 314 	Average Loss: 5.2887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3750

Learning rate: 0.00019951384266863126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 6.2914	Cost: 33.83s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 5.2511	Cost: 9.51s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 5.2721	Cost: 12.98s
Train Epoch: 315 	Average Loss: 5.2755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3144

Saving model as e315_model.pt & e315_waveforms_supplementary.hdf5
Learning rate: 0.00019951074372581416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 6.2377	Cost: 33.64s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 5.2379	Cost: 9.46s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 5.1958	Cost: 12.85s
Train Epoch: 316 	Average Loss: 5.2589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2768

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 0.00019950763496168037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 6.2149	Cost: 32.70s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 5.2258	Cost: 9.45s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 5.1053	Cost: 11.75s
Train Epoch: 317 	Average Loss: 5.2471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2751

Saving model as e317_model.pt & e317_waveforms_supplementary.hdf5
Learning rate: 0.00019950451637653678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 6.1440	Cost: 32.97s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 5.0749	Cost: 9.48s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 5.0909	Cost: 12.14s
Train Epoch: 318 	Average Loss: 5.1887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2515

Saving model as e318_model.pt & e318_waveforms_supplementary.hdf5
Learning rate: 0.00019950138797069118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 6.2294	Cost: 33.46s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 5.0457	Cost: 9.48s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 5.0777	Cost: 11.95s
Train Epoch: 319 	Average Loss: 5.1550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1650

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Learning rate: 0.00019949824974445222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 6.0938	Cost: 33.55s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 5.0280	Cost: 9.44s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 5.1313	Cost: 12.39s
Train Epoch: 320 	Average Loss: 5.1211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0356

Saving model as e320_model.pt & e320_waveforms_supplementary.hdf5
Learning rate: 0.00019949510169812976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 6.0349	Cost: 33.70s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 4.9932	Cost: 9.45s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 5.0456	Cost: 13.25s
Train Epoch: 321 	Average Loss: 5.1076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1798

Learning rate: 0.00019949194383203438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 6.1409	Cost: 33.51s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 4.9962	Cost: 9.46s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 5.0888	Cost: 11.74s
Train Epoch: 322 	Average Loss: 5.0920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1981

Learning rate: 0.00019948877614647787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 6.0711	Cost: 33.83s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 4.9436	Cost: 9.47s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 4.9240	Cost: 12.23s
Train Epoch: 323 	Average Loss: 5.0289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0949

Learning rate: 0.0001994855986417728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 6.0993	Cost: 33.13s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 4.9593	Cost: 9.51s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 4.9213	Cost: 11.86s
Train Epoch: 324 	Average Loss: 5.0219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1994

Learning rate: 0.0001994824113182328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 6.1527	Cost: 33.77s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 4.9693	Cost: 9.52s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 4.8883	Cost: 12.38s
Train Epoch: 325 	Average Loss: 5.0159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1150

Learning rate: 0.00019947921417617242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 6.0200	Cost: 34.25s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 4.9838	Cost: 9.48s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 5.0329	Cost: 12.49s
Train Epoch: 326 	Average Loss: 5.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0851

Learning rate: 0.0001994760072159072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 6.1727	Cost: 32.32s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 5.0062	Cost: 9.49s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 5.0222	Cost: 12.01s
Train Epoch: 327 	Average Loss: 5.0933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0814

Learning rate: 0.00019947279043775368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 6.0515	Cost: 33.87s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 4.9777	Cost: 9.50s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 4.9567	Cost: 11.88s
Train Epoch: 328 	Average Loss: 5.0258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0778

Learning rate: 0.00019946956384202932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 6.2432	Cost: 33.11s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 4.8688	Cost: 9.47s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 4.8630	Cost: 13.54s
Train Epoch: 329 	Average Loss: 4.9647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0893

Learning rate: 0.00019946632742905265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 6.1707	Cost: 33.73s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 4.8370	Cost: 9.48s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 4.8182	Cost: 12.58s
Train Epoch: 330 	Average Loss: 4.9375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9928

Saving model as e330_model.pt & e330_waveforms_supplementary.hdf5
Learning rate: 0.000199463081199143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 5.9983	Cost: 33.07s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 4.7821	Cost: 9.45s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 4.7975	Cost: 13.10s
Train Epoch: 331 	Average Loss: 4.8776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9433

Saving model as e331_model.pt & e331_waveforms_supplementary.hdf5
Learning rate: 0.0001994598251526208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 5.9982	Cost: 32.92s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 4.7669	Cost: 9.46s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 4.8137	Cost: 13.26s
Train Epoch: 332 	Average Loss: 4.8454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0454

Learning rate: 0.00019945655928980737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 6.0790	Cost: 33.43s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 4.7235	Cost: 9.48s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 4.7507	Cost: 11.99s
Train Epoch: 333 	Average Loss: 4.8506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9960

Learning rate: 0.0001994532836110251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 5.9971	Cost: 34.45s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 4.7076	Cost: 9.47s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 4.6226	Cost: 13.53s
Train Epoch: 334 	Average Loss: 4.8016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0073

Learning rate: 0.00019944999811659725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 6.1313	Cost: 33.34s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 4.7695	Cost: 9.50s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 4.7330	Cost: 13.35s
Train Epoch: 335 	Average Loss: 4.8514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8650

Saving model as e335_model.pt & e335_waveforms_supplementary.hdf5
Learning rate: 0.00019944670280684805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 5.8447	Cost: 33.04s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 4.6737	Cost: 9.47s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 4.7718	Cost: 11.81s
Train Epoch: 336 	Average Loss: 4.7775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0455

Learning rate: 0.00019944339768210285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 6.0046	Cost: 33.58s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 4.6618	Cost: 9.49s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 4.6060	Cost: 12.14s
Train Epoch: 337 	Average Loss: 4.7391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8820

Learning rate: 0.0001994400827426877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 5.8823	Cost: 32.91s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 4.6119	Cost: 9.47s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 4.6721	Cost: 12.95s
Train Epoch: 338 	Average Loss: 4.7014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9269

Learning rate: 0.0001994367579889299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 5.9233	Cost: 34.15s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 4.6311	Cost: 9.47s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 4.6407	Cost: 13.74s
Train Epoch: 339 	Average Loss: 4.7093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9607

Learning rate: 0.0001994334234211575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 5.8171	Cost: 32.92s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 4.5730	Cost: 9.46s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 4.5053	Cost: 11.90s
Train Epoch: 340 	Average Loss: 4.6953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9224

Learning rate: 0.00019943007903969968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 5.8003	Cost: 33.92s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 4.6243	Cost: 9.48s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 4.5837	Cost: 13.09s
Train Epoch: 341 	Average Loss: 4.6687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7349

Saving model as e341_model.pt & e341_waveforms_supplementary.hdf5
Learning rate: 0.00019942672484488645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 5.7846	Cost: 32.88s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 4.4871	Cost: 9.48s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 4.4982	Cost: 12.02s
Train Epoch: 342 	Average Loss: 4.5919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8682

Learning rate: 0.0001994233608370489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 5.9559	Cost: 33.19s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 4.5218	Cost: 9.47s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 4.5384	Cost: 13.41s
Train Epoch: 343 	Average Loss: 4.6059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7998

Learning rate: 0.00019941998701651908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 5.6638	Cost: 32.55s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 4.4705	Cost: 9.48s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 4.4311	Cost: 13.36s
Train Epoch: 344 	Average Loss: 4.5722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7951

Learning rate: 0.00019941660338362987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 5.8602	Cost: 33.49s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 4.4810	Cost: 9.51s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 4.5720	Cost: 13.94s
Train Epoch: 345 	Average Loss: 4.6128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8500

Learning rate: 0.0001994132099387153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 5.6871	Cost: 33.51s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 4.3361	Cost: 9.47s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 4.4501	Cost: 13.22s
Train Epoch: 346 	Average Loss: 4.5136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7707

Learning rate: 0.00019940980668211027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 5.5893	Cost: 33.37s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 4.3703	Cost: 9.48s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 4.4148	Cost: 13.40s
Train Epoch: 347 	Average Loss: 4.4678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7051

Saving model as e347_model.pt & e347_waveforms_supplementary.hdf5
Learning rate: 0.00019940639361415064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 5.6654	Cost: 33.53s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 4.2917	Cost: 9.46s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 4.3790	Cost: 11.77s
Train Epoch: 348 	Average Loss: 4.4325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7184

Learning rate: 0.00019940297073517331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 5.4841	Cost: 33.50s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 4.3417	Cost: 9.50s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 4.3249	Cost: 11.76s
Train Epoch: 349 	Average Loss: 4.4119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6771

Saving model as e349_model.pt & e349_waveforms_supplementary.hdf5
Learning rate: 0.00019939953804551608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 5.6327	Cost: 33.09s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 4.2949	Cost: 9.49s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 4.3076	Cost: 12.72s
Train Epoch: 350 	Average Loss: 4.3916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6756

Saving model as e350_model.pt & e350_waveforms_supplementary.hdf5
Learning rate: 0.00019939609554551777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 5.4981	Cost: 33.98s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 4.2568	Cost: 9.49s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 4.3083	Cost: 12.24s
Train Epoch: 351 	Average Loss: 4.3653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6926

Learning rate: 0.0001993926432355181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 5.6744	Cost: 33.09s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 4.2705	Cost: 9.48s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 4.2832	Cost: 13.78s
Train Epoch: 352 	Average Loss: 4.3551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6368

Saving model as e352_model.pt & e352_waveforms_supplementary.hdf5
Learning rate: 0.00019938918111585784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 5.5811	Cost: 33.28s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 4.1314	Cost: 9.47s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 4.3000	Cost: 12.96s
Train Epoch: 353 	Average Loss: 4.3005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5708

Saving model as e353_model.pt & e353_waveforms_supplementary.hdf5
Learning rate: 0.00019938570918687863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 5.4774	Cost: 33.29s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 4.2976	Cost: 9.46s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 4.2355	Cost: 12.21s
Train Epoch: 354 	Average Loss: 4.2796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5912

Learning rate: 0.0001993822274489232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 5.5618	Cost: 33.51s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 4.1060	Cost: 9.51s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 4.2084	Cost: 11.72s
Train Epoch: 355 	Average Loss: 4.2925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7460

Learning rate: 0.00019937873590233516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 5.8343	Cost: 33.09s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 4.2859	Cost: 9.49s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 4.0743	Cost: 13.44s
Train Epoch: 356 	Average Loss: 4.3101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4853

Saving model as e356_model.pt & e356_waveforms_supplementary.hdf5
Learning rate: 0.0001993752345474591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 5.5021	Cost: 33.86s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 4.0947	Cost: 9.45s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 4.1154	Cost: 12.21s
Train Epoch: 357 	Average Loss: 4.2215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5188

Learning rate: 0.0001993717233846406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 5.5359	Cost: 34.01s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 4.1253	Cost: 9.48s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 4.1402	Cost: 12.79s
Train Epoch: 358 	Average Loss: 4.2118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4967

Learning rate: 0.0001993682024142262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 5.3884	Cost: 33.36s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 4.6236	Cost: 9.46s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 4.4450	Cost: 11.80s
Train Epoch: 359 	Average Loss: 4.5683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8743

Learning rate: 0.00019936467163656337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 5.7780	Cost: 33.09s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 4.3425	Cost: 9.50s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 4.4341	Cost: 12.45s
Train Epoch: 360 	Average Loss: 4.5375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6764

Learning rate: 0.00019936113105200064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 5.8342	Cost: 33.70s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 4.2629	Cost: 9.46s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 4.1043	Cost: 12.61s
Train Epoch: 361 	Average Loss: 4.3650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5519

Learning rate: 0.00019935758066088742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 5.4590	Cost: 33.47s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 4.1218	Cost: 9.47s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 4.0307	Cost: 12.46s
Train Epoch: 362 	Average Loss: 4.1528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4266

Saving model as e362_model.pt & e362_waveforms_supplementary.hdf5
Learning rate: 0.00019935402046357414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 5.4067	Cost: 33.40s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 4.0016	Cost: 9.47s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 3.9661	Cost: 11.90s
Train Epoch: 363 	Average Loss: 4.0923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3931

Saving model as e363_model.pt & e363_waveforms_supplementary.hdf5
Learning rate: 0.00019935045046041218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 5.3773	Cost: 33.94s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 3.9228	Cost: 9.47s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 3.9503	Cost: 12.20s
Train Epoch: 364 	Average Loss: 4.0677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3538

Saving model as e364_model.pt & e364_waveforms_supplementary.hdf5
Learning rate: 0.00019934687065175386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 5.3051	Cost: 33.17s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 3.9270	Cost: 9.53s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 3.9365	Cost: 13.49s
Train Epoch: 365 	Average Loss: 4.0421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4425

Learning rate: 0.00019934328103795248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 5.2980	Cost: 33.76s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 3.9334	Cost: 9.52s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 3.8296	Cost: 12.76s
Train Epoch: 366 	Average Loss: 3.9985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3916

Learning rate: 0.00019933968161936236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 5.2995	Cost: 33.78s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 3.8820	Cost: 9.49s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 3.8351	Cost: 12.83s
Train Epoch: 367 	Average Loss: 3.9545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3266

Saving model as e367_model.pt & e367_waveforms_supplementary.hdf5
Learning rate: 0.00019933607239633875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 5.2375	Cost: 33.45s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 3.9151	Cost: 9.49s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 3.8655	Cost: 12.09s
Train Epoch: 368 	Average Loss: 3.9816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3824

Learning rate: 0.00019933245336923783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 5.3938	Cost: 34.07s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 3.8343	Cost: 9.47s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 3.9255	Cost: 12.94s
Train Epoch: 369 	Average Loss: 3.9660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4452

Learning rate: 0.0001993288245384168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 5.3879	Cost: 32.70s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 3.8471	Cost: 9.47s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 3.8803	Cost: 12.10s
Train Epoch: 370 	Average Loss: 3.9674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3260

Saving model as e370_model.pt & e370_waveforms_supplementary.hdf5
Learning rate: 0.00019932518590423377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 5.1991	Cost: 33.39s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 3.8029	Cost: 9.48s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 3.8680	Cost: 12.23s
Train Epoch: 371 	Average Loss: 3.9085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2962

Saving model as e371_model.pt & e371_waveforms_supplementary.hdf5
Learning rate: 0.00019932153746704794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 5.4478	Cost: 34.01s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 3.9213	Cost: 9.48s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 3.8561	Cost: 12.90s
Train Epoch: 372 	Average Loss: 3.9403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3311

Learning rate: 0.00019931787922721937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 5.4576	Cost: 33.22s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 3.7898	Cost: 9.48s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 3.8173	Cost: 12.91s
Train Epoch: 373 	Average Loss: 3.9394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2862

Saving model as e373_model.pt & e373_waveforms_supplementary.hdf5
Learning rate: 0.00019931421118510906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 5.2883	Cost: 33.30s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 3.9598	Cost: 9.48s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 3.8755	Cost: 12.83s
Train Epoch: 374 	Average Loss: 3.9907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3920

Learning rate: 0.0001993105333410791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 5.3495	Cost: 33.56s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 3.8240	Cost: 9.48s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 3.8113	Cost: 12.48s
Train Epoch: 375 	Average Loss: 3.9110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2959

Learning rate: 0.00019930684569549248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 5.4282	Cost: 33.07s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 3.8275	Cost: 9.47s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 3.6223	Cost: 12.39s
Train Epoch: 376 	Average Loss: 3.7962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0784

Saving model as e376_model.pt & e376_waveforms_supplementary.hdf5
Learning rate: 0.0001993031482487131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 4.9089	Cost: 32.65s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 3.6519	Cost: 9.47s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 3.8766	Cost: 11.72s
Train Epoch: 377 	Average Loss: 3.7584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3090

Learning rate: 0.0001992994410011059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 5.2473	Cost: 33.43s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 3.7529	Cost: 9.47s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 3.7515	Cost: 12.61s
Train Epoch: 378 	Average Loss: 3.8337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2417

Learning rate: 0.00019929572395303678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 5.2452	Cost: 34.16s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 3.6269	Cost: 9.47s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 4.0342	Cost: 12.46s
Train Epoch: 379 	Average Loss: 3.8540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3836

Learning rate: 0.0001992919971048726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 5.3946	Cost: 33.55s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 4.0456	Cost: 9.48s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 3.7540	Cost: 12.03s
Train Epoch: 380 	Average Loss: 3.9862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3241

Learning rate: 0.0001992882604569812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 5.0999	Cost: 34.01s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 3.6430	Cost: 9.51s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 3.6423	Cost: 12.93s
Train Epoch: 381 	Average Loss: 3.7054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0271

Saving model as e381_model.pt & e381_waveforms_supplementary.hdf5
Learning rate: 0.00019928451400973133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 5.0702	Cost: 33.96s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 3.5275	Cost: 9.49s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 3.6296	Cost: 12.41s
Train Epoch: 382 	Average Loss: 3.6262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1036

Learning rate: 0.0001992807577634928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 5.0923	Cost: 33.90s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 3.5478	Cost: 9.57s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 3.4923	Cost: 11.90s
Train Epoch: 383 	Average Loss: 3.6484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0879

Learning rate: 0.00019927699171863632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 5.0096	Cost: 32.87s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 3.5381	Cost: 9.49s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 3.5280	Cost: 12.51s
Train Epoch: 384 	Average Loss: 3.5716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0927

Learning rate: 0.00019927321587553357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 4.9563	Cost: 32.80s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 3.4812	Cost: 9.48s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 3.4399	Cost: 12.05s
Train Epoch: 385 	Average Loss: 3.5330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9829

Saving model as e385_model.pt & e385_waveforms_supplementary.hdf5
Learning rate: 0.00019926943023455717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 4.8728	Cost: 33.35s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 3.4888	Cost: 9.55s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 3.4823	Cost: 12.17s
Train Epoch: 386 	Average Loss: 3.5101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1051

Learning rate: 0.00019926563479608086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 5.0307	Cost: 33.24s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 3.3685	Cost: 9.47s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 3.5403	Cost: 11.96s
Train Epoch: 387 	Average Loss: 3.5474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9865

Learning rate: 0.00019926182956047912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 5.0202	Cost: 33.78s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 3.3697	Cost: 9.48s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 3.4545	Cost: 11.94s
Train Epoch: 388 	Average Loss: 3.5174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9661

Saving model as e388_model.pt & e388_waveforms_supplementary.hdf5
Learning rate: 0.00019925801452812757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 5.0164	Cost: 33.51s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 3.5513	Cost: 9.49s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 3.5393	Cost: 11.98s
Train Epoch: 389 	Average Loss: 3.5854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0859

Learning rate: 0.00019925418969940278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 5.0490	Cost: 33.86s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 3.3052	Cost: 9.49s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 3.4292	Cost: 13.49s
Train Epoch: 390 	Average Loss: 3.4867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9801

Learning rate: 0.00019925035507468219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 4.7993	Cost: 33.03s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 3.3144	Cost: 9.51s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 3.3669	Cost: 13.24s
Train Epoch: 391 	Average Loss: 3.4016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8572

Saving model as e391_model.pt & e391_waveforms_supplementary.hdf5
Learning rate: 0.00019924651065434423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 4.9010	Cost: 32.94s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 3.2741	Cost: 9.41s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 3.3566	Cost: 11.90s
Train Epoch: 392 	Average Loss: 3.3729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8986

Learning rate: 0.0001992426564387684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 4.9043	Cost: 33.35s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 3.2126	Cost: 9.46s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 3.3285	Cost: 11.68s
Train Epoch: 393 	Average Loss: 3.3691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9283

Learning rate: 0.00019923879242833502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 4.9368	Cost: 34.08s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 3.3223	Cost: 9.47s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 3.2236	Cost: 13.22s
Train Epoch: 394 	Average Loss: 3.3706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8955

Learning rate: 0.00019923491862342552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 4.9960	Cost: 33.09s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 3.5444	Cost: 9.46s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 3.4064	Cost: 13.16s
Train Epoch: 395 	Average Loss: 3.5156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9614

Learning rate: 0.0001992310350244222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 4.8670	Cost: 33.33s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 3.3193	Cost: 9.50s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 3.3420	Cost: 12.36s
Train Epoch: 396 	Average Loss: 3.4193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9803

Learning rate: 0.0001992271416317084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 4.9663	Cost: 33.41s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 3.3831	Cost: 9.56s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 3.2911	Cost: 12.20s
Train Epoch: 397 	Average Loss: 3.4189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8643

Learning rate: 0.0001992232384456683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 4.9394	Cost: 33.06s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 3.5178	Cost: 9.48s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 3.6073	Cost: 12.21s
Train Epoch: 398 	Average Loss: 3.5401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1540

Learning rate: 0.00019921932546668718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 5.0861	Cost: 35.10s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 3.3926	Cost: 9.49s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 3.3596	Cost: 12.59s
Train Epoch: 399 	Average Loss: 3.4864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8694

Learning rate: 0.00019921540269515121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 4.8283	Cost: 32.81s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 3.2086	Cost: 9.46s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 3.2811	Cost: 13.46s
Train Epoch: 400 	Average Loss: 3.3545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8387

Saving model as e400_model.pt & e400_waveforms_supplementary.hdf5
Learning rate: 0.0001992114701314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 4.9285	Cost: 33.28s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 3.0430	Cost: 9.47s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 3.1979	Cost: 12.10s
Train Epoch: 401 	Average Loss: 3.2635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8246

Saving model as e401_model.pt & e401_waveforms_supplementary.hdf5
Learning rate: 0.00019920752777596444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 4.7912	Cost: 33.55s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 3.1102	Cost: 9.48s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 3.1686	Cost: 11.72s
Train Epoch: 402 	Average Loss: 3.2099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9243

Learning rate: 0.00019920357562909082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 4.8332	Cost: 34.03s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 3.2916	Cost: 9.48s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 3.1921	Cost: 12.61s
Train Epoch: 403 	Average Loss: 3.3129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8901

Learning rate: 0.00019919961369121682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 4.8682	Cost: 33.57s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 3.1712	Cost: 9.50s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 3.2188	Cost: 11.83s
Train Epoch: 404 	Average Loss: 3.2599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7414

Saving model as e404_model.pt & e404_waveforms_supplementary.hdf5
Learning rate: 0.00019919564196273348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 4.7390	Cost: 33.72s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 2.9166	Cost: 9.47s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 2.9762	Cost: 12.08s
Train Epoch: 405 	Average Loss: 3.1006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6633

Saving model as e405_model.pt & e405_waveforms_supplementary.hdf5
Learning rate: 0.00019919166044403278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 4.5685	Cost: 33.34s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 2.9601	Cost: 9.51s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 2.9576	Cost: 12.02s
Train Epoch: 406 	Average Loss: 3.0882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6741

Learning rate: 0.00019918766913550764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 4.5117	Cost: 33.09s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 2.8802	Cost: 9.55s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 3.1419	Cost: 12.25s
Train Epoch: 407 	Average Loss: 3.0654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9928

Learning rate: 0.00019918366803755205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 4.8039	Cost: 33.05s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 3.2239	Cost: 9.49s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 3.1970	Cost: 13.23s
Train Epoch: 408 	Average Loss: 3.3075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8961

Learning rate: 0.00019917965715056087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 4.6779	Cost: 32.87s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 3.2310	Cost: 9.49s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 3.1686	Cost: 12.82s
Train Epoch: 409 	Average Loss: 3.2992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8517

Learning rate: 0.00019917563647492995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 4.7651	Cost: 33.12s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 3.0052	Cost: 9.52s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 3.0129	Cost: 13.32s
Train Epoch: 410 	Average Loss: 3.1241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6851

Learning rate: 0.00019917160601105614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 4.6685	Cost: 33.10s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 2.9725	Cost: 9.52s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 2.9714	Cost: 12.33s
Train Epoch: 411 	Average Loss: 2.9985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5591

Saving model as e411_model.pt & e411_waveforms_supplementary.hdf5
Learning rate: 0.0001991675657593372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 4.6009	Cost: 33.84s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 2.8557	Cost: 9.54s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 2.8378	Cost: 12.73s
Train Epoch: 412 	Average Loss: 2.9307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5162

Saving model as e412_model.pt & e412_waveforms_supplementary.hdf5
Learning rate: 0.00019916351572017192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 4.4538	Cost: 33.23s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 2.7865	Cost: 9.48s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 2.8653	Cost: 12.13s
Train Epoch: 413 	Average Loss: 2.8886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6506

Learning rate: 0.00019915945589396003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 4.5036	Cost: 33.13s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 3.0354	Cost: 9.47s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 3.2461	Cost: 12.96s
Train Epoch: 414 	Average Loss: 3.1208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0407

Learning rate: 0.00019915538628110217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 4.8144	Cost: 33.47s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 3.2391	Cost: 9.49s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 3.0605	Cost: 13.61s
Train Epoch: 415 	Average Loss: 3.3115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7502

Learning rate: 0.00019915130688200001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 4.6720	Cost: 33.46s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 3.6004	Cost: 9.54s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 3.3862	Cost: 12.10s
Train Epoch: 416 	Average Loss: 3.4938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1586

Learning rate: 0.0001991472176970562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 5.2479	Cost: 33.89s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 3.4621	Cost: 9.46s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 3.2891	Cost: 12.21s
Train Epoch: 417 	Average Loss: 3.5206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8201

Learning rate: 0.00019914311872667434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 4.9069	Cost: 33.07s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 2.8785	Cost: 9.46s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 2.7852	Cost: 12.25s
Train Epoch: 418 	Average Loss: 3.0843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5579

Learning rate: 0.0001991390099712589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 4.7291	Cost: 32.74s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 2.6852	Cost: 9.47s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 2.8220	Cost: 12.11s
Train Epoch: 419 	Average Loss: 2.8790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5112

Saving model as e419_model.pt & e419_waveforms_supplementary.hdf5
Learning rate: 0.00019913489143121547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 4.3678	Cost: 33.62s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 2.7663	Cost: 9.50s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 2.7933	Cost: 12.79s
Train Epoch: 420 	Average Loss: 2.8367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4530

Saving model as e420_model.pt & e420_waveforms_supplementary.hdf5
Learning rate: 0.0001991307631069505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 4.4854	Cost: 33.19s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 2.8046	Cost: 9.48s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 2.8711	Cost: 12.74s
Train Epoch: 421 	Average Loss: 2.9289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7491

Learning rate: 0.0001991266249988715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 4.6307	Cost: 33.35s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 2.7753	Cost: 9.47s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 2.7866	Cost: 12.17s
Train Epoch: 422 	Average Loss: 2.9508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5128

Learning rate: 0.00019912247710738676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 4.5070	Cost: 33.87s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 2.6316	Cost: 9.46s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 2.5785	Cost: 12.14s
Train Epoch: 423 	Average Loss: 2.7491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3825

Saving model as e423_model.pt & e423_waveforms_supplementary.hdf5
Learning rate: 0.0001991183194329058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 4.3277	Cost: 33.83s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 2.6112	Cost: 9.47s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 2.7033	Cost: 12.77s
Train Epoch: 424 	Average Loss: 2.7086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4071

Learning rate: 0.00019911415197583891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 4.3807	Cost: 33.63s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 2.5411	Cost: 9.49s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 2.8062	Cost: 11.91s
Train Epoch: 425 	Average Loss: 2.7571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4839

Learning rate: 0.00019910997473659734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 4.6544	Cost: 33.43s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 2.6509	Cost: 9.50s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 2.6545	Cost: 12.54s
Train Epoch: 426 	Average Loss: 2.8321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4224

Learning rate: 0.00019910578771559345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 4.4068	Cost: 32.62s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 2.4666	Cost: 9.48s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 2.5020	Cost: 13.48s
Train Epoch: 427 	Average Loss: 2.6685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3334

Saving model as e427_model.pt & e427_waveforms_supplementary.hdf5
Learning rate: 0.00019910159091324043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 4.3834	Cost: 33.31s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 2.5898	Cost: 9.48s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 2.4972	Cost: 12.04s
Train Epoch: 428 	Average Loss: 2.6416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3111

Saving model as e428_model.pt & e428_waveforms_supplementary.hdf5
Learning rate: 0.00019909738432995254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 4.1798	Cost: 33.25s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 2.4777	Cost: 9.51s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 2.4700	Cost: 13.36s
Train Epoch: 429 	Average Loss: 2.5735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3134

Learning rate: 0.00019909316796614494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 4.2818	Cost: 33.32s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 2.3825	Cost: 9.47s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 2.4165	Cost: 12.03s
Train Epoch: 430 	Average Loss: 2.5473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3508

Learning rate: 0.00019908894182223372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 4.2790	Cost: 33.48s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 2.3938	Cost: 9.48s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 2.4164	Cost: 13.44s
Train Epoch: 431 	Average Loss: 2.5085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2501

Saving model as e431_model.pt & e431_waveforms_supplementary.hdf5
Learning rate: 0.00019908470589863605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 4.0886	Cost: 33.22s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 2.3442	Cost: 9.48s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 2.4110	Cost: 11.83s
Train Epoch: 432 	Average Loss: 2.4844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2964

Learning rate: 0.00019908046019576994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 4.2194	Cost: 33.90s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 2.9797	Cost: 9.46s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 2.9186	Cost: 12.37s
Train Epoch: 433 	Average Loss: 2.9470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8489

Learning rate: 0.00019907620471405445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 4.8321	Cost: 33.62s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 3.0116	Cost: 9.48s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 2.7458	Cost: 12.16s
Train Epoch: 434 	Average Loss: 3.0781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4911

Learning rate: 0.0001990719394539096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 4.4018	Cost: 32.83s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 2.5775	Cost: 9.48s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 2.4765	Cost: 12.04s
Train Epoch: 435 	Average Loss: 2.7092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3110

Learning rate: 0.0001990676644157563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 4.3033	Cost: 33.11s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 2.4026	Cost: 9.47s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 2.3393	Cost: 13.03s
Train Epoch: 436 	Average Loss: 2.5487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2919

Learning rate: 0.00019906337960001657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 4.3459	Cost: 33.49s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 2.2147	Cost: 9.64s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 2.3671	Cost: 11.92s
Train Epoch: 437 	Average Loss: 2.4323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3264

Learning rate: 0.0001990590850071132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 4.3035	Cost: 32.81s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 2.2066	Cost: 9.49s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 2.3760	Cost: 13.47s
Train Epoch: 438 	Average Loss: 2.3970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1820

Saving model as e438_model.pt & e438_waveforms_supplementary.hdf5
Learning rate: 0.0001990547806374701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 4.0851	Cost: 33.22s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 2.2065	Cost: 9.50s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 2.1992	Cost: 11.79s
Train Epoch: 439 	Average Loss: 2.3385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1871

Learning rate: 0.00019905046649151213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 3.9085	Cost: 33.23s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 2.0282	Cost: 9.48s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 2.1519	Cost: 13.47s
Train Epoch: 440 	Average Loss: 2.2732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2110

Learning rate: 0.00019904614256966498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 4.0756	Cost: 33.12s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 2.2402	Cost: 9.46s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 2.3085	Cost: 11.92s
Train Epoch: 441 	Average Loss: 2.3498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1882

Learning rate: 0.00019904180887235552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 4.1503	Cost: 33.29s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 2.3659	Cost: 9.47s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 2.6709	Cost: 11.76s
Train Epoch: 442 	Average Loss: 2.4913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4447

Learning rate: 0.0001990374654000114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 4.3525	Cost: 32.99s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 2.5775	Cost: 9.46s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 2.4547	Cost: 11.96s
Train Epoch: 443 	Average Loss: 2.6358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2796

Learning rate: 0.0001990331121530613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 4.1491	Cost: 33.33s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 2.2728	Cost: 9.47s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 2.2841	Cost: 13.03s
Train Epoch: 444 	Average Loss: 2.4164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1990

Learning rate: 0.0001990287491319349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 4.2008	Cost: 33.58s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 2.4641	Cost: 9.46s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 2.3409	Cost: 11.98s
Train Epoch: 445 	Average Loss: 2.5345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2331

Learning rate: 0.00019902437633706276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 4.1294	Cost: 33.47s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 2.1428	Cost: 9.46s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 2.1301	Cost: 13.15s
Train Epoch: 446 	Average Loss: 2.3123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0039

Saving model as e446_model.pt & e446_waveforms_supplementary.hdf5
Learning rate: 0.0001990199937688765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 4.0200	Cost: 33.12s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 2.0933	Cost: 9.46s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 1.9901	Cost: 12.04s
Train Epoch: 447 	Average Loss: 2.1934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0628

Learning rate: 0.00019901560142780868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 4.1037	Cost: 32.90s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 2.0844	Cost: 9.47s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 2.0504	Cost: 11.88s
Train Epoch: 448 	Average Loss: 2.1978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0347

Learning rate: 0.0001990111993142928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 3.8679	Cost: 33.28s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 2.0254	Cost: 9.49s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 2.0701	Cost: 13.07s
Train Epoch: 449 	Average Loss: 2.1426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0106

Learning rate: 0.0001990067874287633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 3.8978	Cost: 34.44s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 2.0591	Cost: 9.53s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 2.0406	Cost: 12.61s
Train Epoch: 450 	Average Loss: 2.1808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9960

Saving model as e450_model.pt & e450_waveforms_supplementary.hdf5
Learning rate: 0.00019900236577165563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 3.8943	Cost: 33.42s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 1.9013	Cost: 9.46s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 2.0252	Cost: 13.40s
Train Epoch: 451 	Average Loss: 2.1225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0064

Learning rate: 0.00019899793434340619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 3.7513	Cost: 33.33s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 2.0254	Cost: 9.48s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 1.9554	Cost: 13.22s
Train Epoch: 452 	Average Loss: 2.0487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8704

Saving model as e452_model.pt & e452_waveforms_supplementary.hdf5
Learning rate: 0.00019899349314445237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 3.9865	Cost: 33.74s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 1.9872	Cost: 9.50s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 2.0103	Cost: 12.53s
Train Epoch: 453 	Average Loss: 2.1110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0878

Learning rate: 0.00019898904217523244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 3.7684	Cost: 33.04s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 2.0306	Cost: 9.44s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 1.9793	Cost: 13.30s
Train Epoch: 454 	Average Loss: 2.0985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0064

Learning rate: 0.00019898458143618574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 3.9035	Cost: 33.50s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 1.8992	Cost: 9.50s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 1.8708	Cost: 12.72s
Train Epoch: 455 	Average Loss: 1.9960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7495

Saving model as e455_model.pt & e455_waveforms_supplementary.hdf5
Learning rate: 0.0001989801109277525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 3.9093	Cost: 33.94s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 1.7023	Cost: 9.47s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 1.8557	Cost: 12.58s
Train Epoch: 456 	Average Loss: 1.9534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9604

Learning rate: 0.000198975630650374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 3.9123	Cost: 33.66s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 1.9057	Cost: 9.50s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 1.8050	Cost: 13.44s
Train Epoch: 457 	Average Loss: 1.9699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8097

Learning rate: 0.0001989711406044923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 3.9164	Cost: 33.10s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 1.7972	Cost: 9.46s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 1.7414	Cost: 12.08s
Train Epoch: 458 	Average Loss: 1.9088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8466

Learning rate: 0.0001989666407905507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 3.7601	Cost: 33.52s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 1.6432	Cost: 9.52s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 1.9477	Cost: 13.06s
Train Epoch: 459 	Average Loss: 1.8780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8192

Learning rate: 0.00019896213120899325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 3.8865	Cost: 33.63s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 1.9025	Cost: 9.48s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 1.7663	Cost: 12.68s
Train Epoch: 460 	Average Loss: 1.9827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7315

Saving model as e460_model.pt & e460_waveforms_supplementary.hdf5
Learning rate: 0.00019895761186026497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 3.7657	Cost: 32.82s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 1.7725	Cost: 9.47s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 1.6397	Cost: 11.93s
Train Epoch: 461 	Average Loss: 1.8343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7933

Learning rate: 0.000198953082744812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 3.7537	Cost: 33.48s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 1.6246	Cost: 9.48s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 1.5759	Cost: 11.86s
Train Epoch: 462 	Average Loss: 1.7641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7964

Learning rate: 0.0001989485438630813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 3.7869	Cost: 33.40s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 1.5471	Cost: 9.48s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 1.6348	Cost: 12.25s
Train Epoch: 463 	Average Loss: 1.7414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6370

Saving model as e463_model.pt & e463_waveforms_supplementary.hdf5
Learning rate: 0.00019894399521552084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 3.4645	Cost: 33.43s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 1.6662	Cost: 9.46s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 1.8088	Cost: 11.95s
Train Epoch: 464 	Average Loss: 1.8017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8904

Learning rate: 0.0001989394368025795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 3.6373	Cost: 32.97s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 1.7620	Cost: 9.49s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 1.6616	Cost: 13.19s
Train Epoch: 465 	Average Loss: 1.8164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6620

Learning rate: 0.0001989348686247073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 3.5401	Cost: 33.45s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 1.7090	Cost: 9.47s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 1.8048	Cost: 13.06s
Train Epoch: 466 	Average Loss: 1.8257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8847

Learning rate: 0.000198930290682355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 3.7698	Cost: 32.70s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 1.5672	Cost: 9.49s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 1.4456	Cost: 11.82s
Train Epoch: 467 	Average Loss: 1.7479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7216

Learning rate: 0.00019892570297597447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 3.4710	Cost: 32.38s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 1.5424	Cost: 9.52s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 1.5751	Cost: 13.20s
Train Epoch: 468 	Average Loss: 1.6380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6612

Learning rate: 0.00019892110550601846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 3.5543	Cost: 33.22s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 1.5851	Cost: 9.48s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 1.6365	Cost: 13.46s
Train Epoch: 469 	Average Loss: 1.7246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6362

Saving model as e469_model.pt & e469_waveforms_supplementary.hdf5
Learning rate: 0.00019891649827294077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 3.8606	Cost: 32.86s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 1.4598	Cost: 9.47s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 1.7179	Cost: 11.86s
Train Epoch: 470 	Average Loss: 1.6771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7044

Learning rate: 0.00019891188127719607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 3.6095	Cost: 33.37s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 1.5235	Cost: 9.49s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 1.6823	Cost: 11.93s
Train Epoch: 471 	Average Loss: 1.7222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6117

Saving model as e471_model.pt & e471_waveforms_supplementary.hdf5
Learning rate: 0.00019890725451924011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 3.6508	Cost: 33.61s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 1.5425	Cost: 9.47s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 1.6813	Cost: 12.45s
Train Epoch: 472 	Average Loss: 1.6633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6881

Learning rate: 0.00019890261799952944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 3.5512	Cost: 33.68s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 1.6232	Cost: 9.50s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 1.6555	Cost: 13.31s
Train Epoch: 473 	Average Loss: 1.7597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7474

Learning rate: 0.00019889797171852172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 3.7533	Cost: 33.87s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 1.5682	Cost: 9.48s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 1.9207	Cost: 12.89s
Train Epoch: 474 	Average Loss: 1.7462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9650

Learning rate: 0.0001988933156766755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 3.8569	Cost: 33.29s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 1.8372	Cost: 9.46s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 1.6557	Cost: 12.25s
Train Epoch: 475 	Average Loss: 1.9195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7309

Learning rate: 0.00019888864987445035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 3.5301	Cost: 33.37s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 1.5830	Cost: 9.49s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 1.7022	Cost: 13.40s
Train Epoch: 476 	Average Loss: 1.7581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7705

Learning rate: 0.00019888397431230674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 3.5035	Cost: 33.35s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 1.5675	Cost: 9.50s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 1.5731	Cost: 12.55s
Train Epoch: 477 	Average Loss: 1.6389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5890

Saving model as e477_model.pt & e477_waveforms_supplementary.hdf5
Learning rate: 0.00019887928899070613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 3.4582	Cost: 33.03s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 1.3413	Cost: 9.47s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 1.3688	Cost: 11.95s
Train Epoch: 478 	Average Loss: 1.5049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5415

Saving model as e478_model.pt & e478_waveforms_supplementary.hdf5
Learning rate: 0.00019887459391011093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 3.4805	Cost: 33.40s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 1.3558	Cost: 9.49s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 1.3561	Cost: 12.98s
Train Epoch: 479 	Average Loss: 1.4764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3977

Saving model as e479_model.pt & e479_waveforms_supplementary.hdf5
Learning rate: 0.0001988698890709845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 3.6030	Cost: 34.05s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 1.3205	Cost: 9.47s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 1.2425	Cost: 12.66s
Train Epoch: 480 	Average Loss: 1.4570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4923

Learning rate: 0.0001988651744737913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 3.4085	Cost: 33.72s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 1.2989	Cost: 9.47s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 1.1727	Cost: 12.81s
Train Epoch: 481 	Average Loss: 1.3784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3614

Saving model as e481_model.pt & e481_waveforms_supplementary.hdf5
Learning rate: 0.00019886045011899655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 3.2036	Cost: 32.67s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 1.1527	Cost: 9.46s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 1.2053	Cost: 11.77s
Train Epoch: 482 	Average Loss: 1.4393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5705

Learning rate: 0.00019885571600706652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 3.5840	Cost: 33.55s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 1.2130	Cost: 9.48s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 1.2556	Cost: 12.83s
Train Epoch: 483 	Average Loss: 1.4280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4698

Learning rate: 0.00019885097213846847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 3.2633	Cost: 34.01s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 1.1916	Cost: 9.49s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 1.2000	Cost: 13.34s
Train Epoch: 484 	Average Loss: 1.3998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3780

Learning rate: 0.00019884621851367065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 3.3792	Cost: 33.46s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 1.2127	Cost: 9.47s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 1.1641	Cost: 13.94s
Train Epoch: 485 	Average Loss: 1.3602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4119

Learning rate: 0.00019884145513314214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 3.3472	Cost: 33.35s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 1.0892	Cost: 9.47s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 1.0043	Cost: 12.05s
Train Epoch: 486 	Average Loss: 1.2761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3565

Saving model as e486_model.pt & e486_waveforms_supplementary.hdf5
Learning rate: 0.00019883668199735307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 3.5153	Cost: 32.58s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 1.0810	Cost: 9.51s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 1.1648	Cost: 12.42s
Train Epoch: 487 	Average Loss: 1.2697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3394

Saving model as e487_model.pt & e487_waveforms_supplementary.hdf5
Learning rate: 0.00019883189910677464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 3.1262	Cost: 32.74s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 1.0888	Cost: 9.48s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 1.1276	Cost: 11.61s
Train Epoch: 488 	Average Loss: 1.2834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4430

Learning rate: 0.00019882710646187875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 3.2665	Cost: 32.92s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 1.0941	Cost: 9.47s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 1.0444	Cost: 13.17s
Train Epoch: 489 	Average Loss: 1.2447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4047

Learning rate: 0.00019882230406313855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 3.1458	Cost: 33.02s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 1.1893	Cost: 9.49s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 1.0168	Cost: 13.50s
Train Epoch: 490 	Average Loss: 1.2807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3085

Saving model as e490_model.pt & e490_waveforms_supplementary.hdf5
Learning rate: 0.00019881749191102795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 3.3299	Cost: 33.81s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 1.0469	Cost: 9.47s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 1.1785	Cost: 12.96s
Train Epoch: 491 	Average Loss: 1.2227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4387

Learning rate: 0.00019881267000602186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 3.2891	Cost: 33.54s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 1.0135	Cost: 9.49s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 0.9662	Cost: 12.54s
Train Epoch: 492 	Average Loss: 1.1979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3267

Learning rate: 0.00019880783834859626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 3.2462	Cost: 33.55s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 0.9448	Cost: 9.44s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 1.0786	Cost: 12.13s
Train Epoch: 493 	Average Loss: 1.1635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1965

Saving model as e493_model.pt & e493_waveforms_supplementary.hdf5
Learning rate: 0.000198802996939228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 3.2250	Cost: 33.45s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 0.9487	Cost: 9.49s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 0.9779	Cost: 13.42s
Train Epoch: 494 	Average Loss: 1.1364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1662

Saving model as e494_model.pt & e494_waveforms_supplementary.hdf5
Learning rate: 0.0001987981457783948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 3.2177	Cost: 32.77s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 0.8323	Cost: 9.48s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 0.9155	Cost: 12.07s
Train Epoch: 495 	Average Loss: 1.0765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1339

Saving model as e495_model.pt & e495_waveforms_supplementary.hdf5
Learning rate: 0.00019879328486657562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 3.2392	Cost: 33.12s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 1.1704	Cost: 9.43s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 1.1365	Cost: 11.56s
Train Epoch: 496 	Average Loss: 1.2313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3366

Learning rate: 0.0001987884142042501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 3.1839	Cost: 33.73s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 0.9807	Cost: 9.49s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 0.9100	Cost: 13.14s
Train Epoch: 497 	Average Loss: 1.1016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2061

Learning rate: 0.00019878353379189899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 3.1013	Cost: 33.34s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 0.9374	Cost: 9.51s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 0.9863	Cost: 12.14s
Train Epoch: 498 	Average Loss: 1.1328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2254

Learning rate: 0.00019877864363000396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 3.2675	Cost: 33.18s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 0.8121	Cost: 9.50s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 0.8498	Cost: 12.60s
Train Epoch: 499 	Average Loss: 1.0307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1201

Saving model as e499_model.pt & e499_waveforms_supplementary.hdf5
Learning rate: 0.00019877374371904765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 3.1399	Cost: 33.63s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 1.0226	Cost: 9.47s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 1.1084	Cost: 11.91s
Train Epoch: 500 	Average Loss: 1.1304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4147

Stopping timer.
Training time (including validation): 49513.03754615784 seconds
Saving model
Transfer learning by starting with alpha=0.8!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 47.1361	Cost: 32.04s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 23.6078	Cost: 9.50s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 18.7103	Cost: 11.85s
Train Epoch: 1 	Average Loss: 25.9911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3578

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.0001999980260856137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 18.2273	Cost: 31.96s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 15.8687	Cost: 9.51s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 13.2244	Cost: 11.59s
Train Epoch: 2 	Average Loss: 15.3515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5776

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 12.9678	Cost: 33.25s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 11.9731	Cost: 9.51s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 10.6629	Cost: 12.62s
Train Epoch: 3 	Average Loss: 12.0537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4014

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 11.3910	Cost: 33.16s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 10.2317	Cost: 9.66s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 9.5298	Cost: 12.06s
Train Epoch: 4 	Average Loss: 10.2837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0990

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892833004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 9.3391	Cost: 32.12s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 8.8542	Cost: 9.74s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 8.7412	Cost: 11.83s
Train Epoch: 5 	Average Loss: 9.1256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0122

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 8.8136	Cost: 31.62s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 8.3948	Cost: 9.53s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 7.7057	Cost: 11.76s
Train Epoch: 6 	Average Loss: 8.4136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3064

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 8.0704	Cost: 32.14s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 7.7155	Cost: 9.51s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 7.5970	Cost: 12.54s
Train Epoch: 7 	Average Loss: 7.6610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5595

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 7.6047	Cost: 32.16s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 6.9569	Cost: 9.59s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 7.2190	Cost: 11.55s
Train Epoch: 8 	Average Loss: 7.0573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9027

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019987369566060184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 7.0800	Cost: 32.12s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 6.8629	Cost: 9.68s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 6.5095	Cost: 11.49s
Train Epoch: 9 	Average Loss: 6.7436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6874

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019984015501089758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 6.4025	Cost: 32.00s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 6.5714	Cost: 9.51s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 6.0752	Cost: 12.08s
Train Epoch: 10 	Average Loss: 6.3997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3864

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 6.3425	Cost: 33.19s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 6.1197	Cost: 9.44s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 5.8502	Cost: 12.59s
Train Epoch: 11 	Average Loss: 6.1754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3160

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019976125063612257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 6.3656	Cost: 33.32s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 5.8716	Cost: 9.48s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 5.4985	Cost: 12.67s
Train Epoch: 12 	Average Loss: 5.9040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0641

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019971589002606144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 6.2204	Cost: 32.55s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 5.5125	Cost: 9.64s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 5.5841	Cost: 11.87s
Train Epoch: 13 	Average Loss: 5.6990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9673

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.00019966659280340303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 6.1747	Cost: 33.14s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 5.7729	Cost: 9.50s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 5.4097	Cost: 12.74s
Train Epoch: 14 	Average Loss: 5.5811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7273

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001996133609143173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 5.8718	Cost: 33.58s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 5.2035	Cost: 9.66s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 5.1261	Cost: 12.36s
Train Epoch: 15 	Average Loss: 5.3297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4397

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 5.5630	Cost: 32.12s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 5.0053	Cost: 9.54s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 5.0253	Cost: 12.62s
Train Epoch: 16 	Average Loss: 5.1125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3160

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.00019949510169813006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 5.1863	Cost: 32.64s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 4.7748	Cost: 9.72s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 4.8648	Cost: 11.69s
Train Epoch: 17 	Average Loss: 4.9397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2713

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019943007903969992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 5.2951	Cost: 32.34s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 4.8647	Cost: 9.57s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 4.6103	Cost: 12.32s
Train Epoch: 18 	Average Loss: 4.8407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9902

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.00019936113105200088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 5.0846	Cost: 32.03s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 4.5226	Cost: 9.78s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 4.3905	Cost: 11.80s
Train Epoch: 19 	Average Loss: 4.6678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9812

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.0001992882604569814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 4.9350	Cost: 31.56s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 4.3689	Cost: 9.58s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 4.5720	Cost: 12.07s
Train Epoch: 20 	Average Loss: 4.5838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8657

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019921147013144782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 4.8450	Cost: 32.15s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 4.4528	Cost: 10.39s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 4.3903	Cost: 11.06s
Train Epoch: 21 	Average Loss: 4.4725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7372

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.00019913076310695068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 4.8760	Cost: 31.59s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 4.3553	Cost: 9.68s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 4.0857	Cost: 11.34s
Train Epoch: 22 	Average Loss: 4.3277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7984

Learning rate: 0.00019904614256966512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 4.6455	Cost: 31.93s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 3.9454	Cost: 9.41s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 3.9992	Cost: 12.15s
Train Epoch: 23 	Average Loss: 4.1864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5776

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.0001989576118602651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 4.4689	Cost: 30.62s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 4.0014	Cost: 9.46s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 3.9968	Cost: 11.74s
Train Epoch: 24 	Average Loss: 4.1129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5940

Learning rate: 0.0001988651744737914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 4.7382	Cost: 31.72s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 3.8958	Cost: 9.42s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 3.8927	Cost: 12.50s
Train Epoch: 25 	Average Loss: 4.0544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6232

Learning rate: 0.0001987688340595138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 4.8849	Cost: 31.78s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 3.9922	Cost: 9.40s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 3.6795	Cost: 12.47s
Train Epoch: 26 	Average Loss: 4.0123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4315

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019866859442078683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 4.1059	Cost: 31.06s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 3.6425	Cost: 9.41s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 3.5813	Cost: 11.75s
Train Epoch: 27 	Average Loss: 3.7725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2146

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019856445951489985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 4.4743	Cost: 31.24s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 3.5453	Cost: 9.40s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 3.4420	Cost: 11.52s
Train Epoch: 28 	Average Loss: 3.6540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4646

Learning rate: 0.0001984564334529206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 4.2978	Cost: 31.06s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 3.6556	Cost: 9.39s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 3.6281	Cost: 11.87s
Train Epoch: 29 	Average Loss: 3.6109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1940

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.00019834452049953302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 4.2818	Cost: 31.17s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 3.6043	Cost: 9.35s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 3.4706	Cost: 12.68s
Train Epoch: 30 	Average Loss: 3.5819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2498

Learning rate: 0.00019822872507286893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 4.5236	Cost: 32.83s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 3.3623	Cost: 9.36s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 3.4179	Cost: 12.45s
Train Epoch: 31 	Average Loss: 3.4584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2940

Learning rate: 0.00019810905174433345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 4.3757	Cost: 32.07s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 3.2769	Cost: 9.40s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 3.3104	Cost: 12.50s
Train Epoch: 32 	Average Loss: 3.3801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9188

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.00019798550523842474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 3.9952	Cost: 34.90s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 3.2780	Cost: 9.52s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 3.1763	Cost: 12.34s
Train Epoch: 33 	Average Loss: 3.2860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8934

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019785809043254728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 4.0998	Cost: 34.82s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 2.8908	Cost: 9.58s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 3.0013	Cost: 12.47s
Train Epoch: 34 	Average Loss: 3.1242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7377

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019772681235681944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 3.9355	Cost: 32.11s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 3.0128	Cost: 9.62s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 2.9478	Cost: 11.92s
Train Epoch: 35 	Average Loss: 3.0653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6962

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.00019759167619387482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 3.5542	Cost: 31.89s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 3.0142	Cost: 10.21s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 2.8630	Cost: 11.94s
Train Epoch: 36 	Average Loss: 3.0428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9014

Learning rate: 0.0001974526872786578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 3.8554	Cost: 32.14s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 2.9870	Cost: 9.56s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 2.8389	Cost: 12.02s
Train Epoch: 37 	Average Loss: 2.9733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8661

Learning rate: 0.00019730985109821272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 3.7000	Cost: 31.55s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 2.9646	Cost: 10.20s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 2.7857	Cost: 11.52s
Train Epoch: 38 	Average Loss: 2.9207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6853

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.00019716317329146745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 3.3903	Cost: 32.42s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 2.6492	Cost: 9.39s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 2.6796	Cost: 11.87s
Train Epoch: 39 	Average Loss: 2.8398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5286

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019701265964901062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 3.7954	Cost: 31.89s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 2.7696	Cost: 9.52s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 2.5419	Cost: 11.53s
Train Epoch: 40 	Average Loss: 2.7070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4448

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 3.6759	Cost: 32.38s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 2.6779	Cost: 9.44s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 2.3091	Cost: 11.91s
Train Epoch: 41 	Average Loss: 2.6797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4118

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019670014877624353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 3.4092	Cost: 32.04s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 2.5694	Cost: 9.39s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 2.4837	Cost: 12.33s
Train Epoch: 42 	Average Loss: 2.5839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6734

Learning rate: 0.0001965381638833274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 3.5107	Cost: 31.23s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 2.6890	Cost: 9.42s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 2.4598	Cost: 12.22s
Train Epoch: 43 	Average Loss: 2.6261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1892

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.000196372367829001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 3.2881	Cost: 31.22s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 2.5324	Cost: 9.59s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 2.0449	Cost: 11.84s
Train Epoch: 44 	Average Loss: 2.4304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3616

Learning rate: 0.00019620276715860861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 3.4297	Cost: 32.03s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 2.3677	Cost: 9.61s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 2.1712	Cost: 12.72s
Train Epoch: 45 	Average Loss: 2.4530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3422

Learning rate: 0.00019602936856769434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 3.0103	Cost: 32.28s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 2.2963	Cost: 9.56s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 2.1673	Cost: 12.14s
Train Epoch: 46 	Average Loss: 2.3763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3134

Learning rate: 0.00019585217890173763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 3.2814	Cost: 31.50s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 2.1591	Cost: 9.59s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 2.0623	Cost: 11.68s
Train Epoch: 47 	Average Loss: 2.3023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2405

Learning rate: 0.0001956712051558831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 3.1754	Cost: 31.60s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 2.1045	Cost: 9.42s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 1.8091	Cost: 12.42s
Train Epoch: 48 	Average Loss: 2.1779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2883

Learning rate: 0.00019548645447466434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 2.9634	Cost: 31.51s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 2.0052	Cost: 9.41s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 2.0166	Cost: 11.94s
Train Epoch: 49 	Average Loss: 2.1264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9893

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019529793415172192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 3.0531	Cost: 31.57s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 2.0943	Cost: 9.36s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 1.6806	Cost: 12.55s
Train Epoch: 50 	Average Loss: 2.0525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1524

Learning rate: 0.0001951056516295154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 2.9954	Cost: 30.86s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 1.9904	Cost: 9.38s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 1.7142	Cost: 11.83s
Train Epoch: 51 	Average Loss: 1.9899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1354

Learning rate: 0.0001949096144990295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 2.9489	Cost: 31.36s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 1.8593	Cost: 9.39s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 1.9395	Cost: 12.13s
Train Epoch: 52 	Average Loss: 2.0069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0873

Learning rate: 0.00019470983049947442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 2.9574	Cost: 31.90s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 1.6204	Cost: 9.37s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 1.9184	Cost: 12.66s
Train Epoch: 53 	Average Loss: 1.9157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9368

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 0.00019450630751798048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 3.0865	Cost: 31.32s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 1.7572	Cost: 9.40s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 1.8980	Cost: 11.80s
Train Epoch: 54 	Average Loss: 1.8810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0052

Learning rate: 0.00019429905358928646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 2.7470	Cost: 30.46s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 1.5284	Cost: 9.40s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 1.6173	Cost: 12.79s
Train Epoch: 55 	Average Loss: 1.7415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7800

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.00019408807689542257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 2.7788	Cost: 31.05s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 1.8512	Cost: 9.39s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 1.4372	Cost: 11.63s
Train Epoch: 56 	Average Loss: 1.8016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9768

Learning rate: 0.00019387338576538744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 2.8676	Cost: 32.15s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 1.6255	Cost: 9.41s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 1.5439	Cost: 11.88s
Train Epoch: 57 	Average Loss: 1.6896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8962

Learning rate: 0.00019365498867481926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 2.9177	Cost: 31.76s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 1.5270	Cost: 9.37s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 1.3399	Cost: 12.43s
Train Epoch: 58 	Average Loss: 1.6471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7482

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Learning rate: 0.00019343289424566122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 2.9607	Cost: 31.94s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 1.5924	Cost: 9.39s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 1.3316	Cost: 12.57s
Train Epoch: 59 	Average Loss: 1.5875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6825

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00019320711124582108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 2.9172	Cost: 31.72s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 1.4188	Cost: 9.39s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 1.6168	Cost: 12.36s
Train Epoch: 60 	Average Loss: 1.5724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7765

Learning rate: 0.00019297764858882514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 2.5155	Cost: 30.92s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 1.4116	Cost: 9.38s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 1.3823	Cost: 11.61s
Train Epoch: 61 	Average Loss: 1.5339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9006

Learning rate: 0.00019274451533346612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 3.1067	Cost: 31.70s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 1.5006	Cost: 9.43s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 1.1980	Cost: 12.92s
Train Epoch: 62 	Average Loss: 1.5149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6635

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019250772068344577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 2.6700	Cost: 30.65s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 1.3709	Cost: 9.40s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 1.0131	Cost: 11.69s
Train Epoch: 63 	Average Loss: 1.4016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5251

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 0.00019226727398701147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 2.7580	Cost: 31.65s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 0.9626	Cost: 9.38s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 1.1209	Cost: 12.05s
Train Epoch: 64 	Average Loss: 1.2942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6064

Learning rate: 0.00019202318473658702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 2.5068	Cost: 32.38s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 1.1302	Cost: 9.40s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 1.0861	Cost: 12.34s
Train Epoch: 65 	Average Loss: 1.3378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6450

Learning rate: 0.0001917754625683981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 2.5052	Cost: 31.59s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 0.9952	Cost: 9.39s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 1.0282	Cost: 11.92s
Train Epoch: 66 	Average Loss: 1.1869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6166

Learning rate: 0.00019152411726209174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 2.3274	Cost: 32.06s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 1.0543	Cost: 9.39s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 0.9348	Cost: 11.98s
Train Epoch: 67 	Average Loss: 1.2153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5918

Learning rate: 0.00019126915874035028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 2.6888	Cost: 31.55s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 1.0437	Cost: 9.41s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 0.9738	Cost: 12.44s
Train Epoch: 68 	Average Loss: 1.1349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5160

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 0.00019101059706849957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 2.2125	Cost: 31.55s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 0.9292	Cost: 9.43s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 0.9752	Cost: 12.18s
Train Epoch: 69 	Average Loss: 1.1351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5780

Learning rate: 0.0001907484424541117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 2.2856	Cost: 31.18s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 0.9473	Cost: 10.07s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 0.8624	Cost: 11.34s
Train Epoch: 70 	Average Loss: 1.0645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4100

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Learning rate: 0.00019048270524660196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 2.1494	Cost: 31.92s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 0.9698	Cost: 9.39s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 0.8567	Cost: 12.41s
Train Epoch: 71 	Average Loss: 1.0953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4905

Learning rate: 0.00019021339593682028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 2.2207	Cost: 31.58s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 0.7411	Cost: 9.39s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 0.8871	Cost: 12.19s
Train Epoch: 72 	Average Loss: 0.9935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3005

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 0.0001899405251566371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 2.3499	Cost: 31.35s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 0.7666	Cost: 9.40s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 0.8026	Cost: 12.16s
Train Epoch: 73 	Average Loss: 0.9051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3369

Learning rate: 0.0001896641036785236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 2.1764	Cost: 31.39s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 0.4266	Cost: 9.38s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 0.5129	Cost: 12.84s
Train Epoch: 74 	Average Loss: 0.8262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3607

Learning rate: 0.00018938414241512636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 2.2442	Cost: 31.61s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 0.5944	Cost: 9.38s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 0.5966	Cost: 12.70s
Train Epoch: 75 	Average Loss: 0.8267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2396

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 0.00018910065241883677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 2.1049	Cost: 32.32s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 0.7103	Cost: 9.37s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 0.4236	Cost: 12.48s
Train Epoch: 76 	Average Loss: 0.7528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0903

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00018881364488135445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 2.1324	Cost: 30.81s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 0.8415	Cost: 9.40s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 0.7569	Cost: 12.65s
Train Epoch: 77 	Average Loss: 0.8639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2544

Learning rate: 0.00018852313113324552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 2.3653	Cost: 32.24s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 0.7165	Cost: 9.41s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 1.2076	Cost: 12.40s
Train Epoch: 78 	Average Loss: 1.1278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7033

Learning rate: 0.00018822912264349534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 2.7588	Cost: 31.16s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 1.0067	Cost: 9.41s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 0.8864	Cost: 11.92s
Train Epoch: 79 	Average Loss: 1.1889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3382

Learning rate: 0.00018793163101905563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 2.2056	Cost: 31.41s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 0.7170	Cost: 9.43s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 0.6491	Cost: 11.93s
Train Epoch: 80 	Average Loss: 0.7844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2159

Learning rate: 0.00018763066800438636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 1.9113	Cost: 31.52s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 0.6579	Cost: 9.40s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 0.4412	Cost: 12.74s
Train Epoch: 81 	Average Loss: 0.6919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2626

Learning rate: 0.000187326245480992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 2.1761	Cost: 32.22s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 0.3382	Cost: 9.36s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 0.4052	Cost: 12.40s
Train Epoch: 82 	Average Loss: 0.6640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2667

Learning rate: 0.00018701837546695256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 2.0835	Cost: 30.94s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 0.4400	Cost: 9.41s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 0.2334	Cost: 12.62s
Train Epoch: 83 	Average Loss: 0.5143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1607

Learning rate: 0.00018670707011644898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 1.9801	Cost: 32.46s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 0.4926	Cost: 9.38s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 0.4263	Cost: 12.48s
Train Epoch: 84 	Average Loss: 0.5401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3503

Learning rate: 0.0001863923417192835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 2.0104	Cost: 31.46s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 0.5009	Cost: 9.38s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 0.2703	Cost: 11.64s
Train Epoch: 85 	Average Loss: 0.5916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0731

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Learning rate: 0.00018607420270039436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 2.0753	Cost: 32.12s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 0.3666	Cost: 9.38s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 0.2270	Cost: 12.03s
Train Epoch: 86 	Average Loss: 0.4753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9728

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 0.00018575266561936523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 1.8663	Cost: 31.83s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 0.3819	Cost: 9.36s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 0.1225	Cost: 12.56s
Train Epoch: 87 	Average Loss: 0.4193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1264

Learning rate: 0.0001854277431699295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 1.7885	Cost: 31.37s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 0.1079	Cost: 9.39s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 0.0105	Cost: 11.72s
Train Epoch: 88 	Average Loss: 0.3533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1412

Learning rate: 0.0001850994481794692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 1.6116	Cost: 31.06s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 0.2876	Cost: 9.41s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 0.2560	Cost: 11.76s
Train Epoch: 89 	Average Loss: 0.3700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8056

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 0.0001847677936085083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 1.7161	Cost: 31.96s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 0.0911	Cost: 9.50s
Train Epoch: 90 [81920/90000 (91%)]	Loss: -0.0189	Cost: 12.30s
Train Epoch: 90 	Average Loss: 0.2501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8648

Learning rate: 0.00018443279255020146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 1.8944	Cost: 30.77s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 0.1450	Cost: 9.41s
Train Epoch: 91 [81920/90000 (91%)]	Loss: -0.0225	Cost: 12.13s
Train Epoch: 91 	Average Loss: 0.1964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8289

Learning rate: 0.00018409445822981687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 1.4026	Cost: 32.43s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 0.1318	Cost: 9.37s
Train Epoch: 92 [81920/90000 (91%)]	Loss: -0.1315	Cost: 11.80s
Train Epoch: 92 	Average Loss: 0.1791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9663

Learning rate: 0.00018375280400421414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 1.8048	Cost: 30.96s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 0.0014	Cost: 9.40s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 0.0878	Cost: 11.79s
Train Epoch: 93 	Average Loss: 0.2562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8955

Learning rate: 0.00018340784336131708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 1.6835	Cost: 31.12s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 0.0213	Cost: 9.42s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 0.1624	Cost: 12.76s
Train Epoch: 94 	Average Loss: 0.2445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8539

Learning rate: 0.00018305958991958124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 1.5372	Cost: 31.19s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 0.0650	Cost: 9.41s
Train Epoch: 95 [81920/90000 (91%)]	Loss: -0.2310	Cost: 11.69s
Train Epoch: 95 	Average Loss: 0.1274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7818

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 1.5038	Cost: 30.68s
Train Epoch: 96 [40960/90000 (45%)]	Loss: -0.2231	Cost: 9.44s
Train Epoch: 96 [81920/90000 (91%)]	Loss: -0.0343	Cost: 12.02s
Train Epoch: 96 	Average Loss: 0.0604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7939

Learning rate: 0.0001823532597628427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 1.9104	Cost: 31.56s
Train Epoch: 97 [40960/90000 (45%)]	Loss: -0.0223	Cost: 9.38s
Train Epoch: 97 [81920/90000 (91%)]	Loss: -0.2861	Cost: 12.64s
Train Epoch: 97 	Average Loss: 0.1049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7192

Saving model as e97_model.pt & e97_waveforms_supplementary.hdf5
Learning rate: 0.0001819952109325452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 1.4495	Cost: 31.08s
Train Epoch: 98 [40960/90000 (45%)]	Loss: -0.4139	Cost: 9.40s
Train Epoch: 98 [81920/90000 (91%)]	Loss: -0.4091	Cost: 11.83s
Train Epoch: 98 	Average Loss: -0.0084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8780

Learning rate: 0.00018163392507171837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 1.6904	Cost: 32.16s
Train Epoch: 99 [40960/90000 (45%)]	Loss: -0.2560	Cost: 9.38s
Train Epoch: 99 [81920/90000 (91%)]	Loss: -0.4736	Cost: 12.61s
Train Epoch: 99 	Average Loss: -0.0382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6712

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Learning rate: 0.00018126941644330935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 1.4771	Cost: 32.28s
Train Epoch: 100 [40960/90000 (45%)]	Loss: -0.3581	Cost: 9.39s
Train Epoch: 100 [81920/90000 (91%)]	Loss: -0.2547	Cost: 12.74s
Train Epoch: 100 	Average Loss: -0.1037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5058

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 0.0001809016994374947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 1.2099	Cost: 30.48s
Train Epoch: 101 [40960/90000 (45%)]	Loss: -0.4196	Cost: 9.39s
Train Epoch: 101 [81920/90000 (91%)]	Loss: -0.4284	Cost: 12.93s
Train Epoch: 101 	Average Loss: -0.1728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5928

Learning rate: 0.00018053078857111214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 1.6421	Cost: 30.60s
Train Epoch: 102 [40960/90000 (45%)]	Loss: -0.3329	Cost: 9.40s
Train Epoch: 102 [81920/90000 (91%)]	Loss: -0.5030	Cost: 12.02s
Train Epoch: 102 	Average Loss: -0.1805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4701

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00018015669848708761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 1.5042	Cost: 31.16s
Train Epoch: 103 [40960/90000 (45%)]	Loss: -0.3409	Cost: 9.36s
Train Epoch: 103 [81920/90000 (91%)]	Loss: -0.4679	Cost: 12.37s
Train Epoch: 103 	Average Loss: -0.1843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5489

Learning rate: 0.00017977944395385705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 1.3102	Cost: 31.07s
Train Epoch: 104 [40960/90000 (45%)]	Loss: -0.6317	Cost: 9.41s
Train Epoch: 104 [81920/90000 (91%)]	Loss: -0.2323	Cost: 11.64s
Train Epoch: 104 	Average Loss: -0.2161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6544

Learning rate: 0.00017939903986478347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 1.5235	Cost: 32.03s
Train Epoch: 105 [40960/90000 (45%)]	Loss: -0.5002	Cost: 9.40s
Train Epoch: 105 [81920/90000 (91%)]	Loss: -0.8303	Cost: 12.34s
Train Epoch: 105 	Average Loss: -0.3162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4647

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00017901550123756898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 1.5924	Cost: 32.94s
Train Epoch: 106 [40960/90000 (45%)]	Loss: -0.4913	Cost: 9.36s
Train Epoch: 106 [81920/90000 (91%)]	Loss: -0.6807	Cost: 12.68s
Train Epoch: 106 	Average Loss: -0.3657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4630

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 0.00017862884321366183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 1.0479	Cost: 31.90s
Train Epoch: 107 [40960/90000 (45%)]	Loss: -0.7977	Cost: 9.40s
Train Epoch: 107 [81920/90000 (91%)]	Loss: -0.6027	Cost: 11.79s
Train Epoch: 107 	Average Loss: -0.4323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5321

Learning rate: 0.00017823908105765875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 0.9457	Cost: 31.40s
Train Epoch: 108 [40960/90000 (45%)]	Loss: -0.5690	Cost: 9.39s
Train Epoch: 108 [81920/90000 (91%)]	Loss: -0.6584	Cost: 12.10s
Train Epoch: 108 	Average Loss: -0.3998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5275

Learning rate: 0.00017784623015670232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 1.3030	Cost: 32.39s
Train Epoch: 109 [40960/90000 (45%)]	Loss: -0.4564	Cost: 9.34s
Train Epoch: 109 [81920/90000 (91%)]	Loss: -0.8138	Cost: 12.53s
Train Epoch: 109 	Average Loss: -0.4330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5862

Learning rate: 0.00017745030601987337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 1.1655	Cost: 32.02s
Train Epoch: 110 [40960/90000 (45%)]	Loss: -0.7166	Cost: 9.38s
Train Epoch: 110 [81920/90000 (91%)]	Loss: -0.7391	Cost: 12.45s
Train Epoch: 110 	Average Loss: -0.4724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4470

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 0.0001770513242775789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 1.1962	Cost: 30.99s
Train Epoch: 111 [40960/90000 (45%)]	Loss: -0.6836	Cost: 9.40s
Train Epoch: 111 [81920/90000 (91%)]	Loss: -0.7930	Cost: 12.35s
Train Epoch: 111 	Average Loss: -0.4324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5314

Learning rate: 0.00017664930068093498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 1.3441	Cost: 31.33s
Train Epoch: 112 [40960/90000 (45%)]	Loss: -0.6747	Cost: 9.43s
Train Epoch: 112 [81920/90000 (91%)]	Loss: -0.6735	Cost: 11.70s
Train Epoch: 112 	Average Loss: -0.5026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3676

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Learning rate: 0.0001762442511011448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 1.3337	Cost: 32.77s
Train Epoch: 113 [40960/90000 (45%)]	Loss: -0.5341	Cost: 9.41s
Train Epoch: 113 [81920/90000 (91%)]	Loss: -0.6523	Cost: 12.27s
Train Epoch: 113 	Average Loss: -0.5604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4561

Learning rate: 0.0001758361915288722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 1.1546	Cost: 31.04s
Train Epoch: 114 [40960/90000 (45%)]	Loss: -0.8037	Cost: 9.40s
Train Epoch: 114 [81920/90000 (91%)]	Loss: -0.7707	Cost: 12.13s
Train Epoch: 114 	Average Loss: -0.6147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4600

Learning rate: 0.0001754251380736104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 1.1310	Cost: 32.31s
Train Epoch: 115 [40960/90000 (45%)]	Loss: -0.8102	Cost: 9.40s
Train Epoch: 115 [81920/90000 (91%)]	Loss: -1.0342	Cost: 12.49s
Train Epoch: 115 	Average Loss: -0.6169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4100

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 1.4284	Cost: 31.69s
Train Epoch: 116 [40960/90000 (45%)]	Loss: -0.7833	Cost: 9.41s
Train Epoch: 116 [81920/90000 (91%)]	Loss: -0.9080	Cost: 11.94s
Train Epoch: 116 	Average Loss: -0.6223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2425

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Learning rate: 0.00017459411454241822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 1.3642	Cost: 31.34s
Train Epoch: 117 [40960/90000 (45%)]	Loss: -0.9789	Cost: 9.40s
Train Epoch: 117 [81920/90000 (91%)]	Loss: -1.0964	Cost: 12.33s
Train Epoch: 117 	Average Loss: -0.6694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1584

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 0.00017417417727387391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 0.8863	Cost: 31.07s
Train Epoch: 118 [40960/90000 (45%)]	Loss: -0.7732	Cost: 10.05s
Train Epoch: 118 [81920/90000 (91%)]	Loss: -0.8198	Cost: 11.83s
Train Epoch: 118 	Average Loss: -0.7188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2034

Learning rate: 0.00017375131173581737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 0.9833	Cost: 31.15s
Train Epoch: 119 [40960/90000 (45%)]	Loss: -0.7523	Cost: 9.40s
Train Epoch: 119 [81920/90000 (91%)]	Loss: -0.7326	Cost: 11.88s
Train Epoch: 119 	Average Loss: -0.7034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3093

Learning rate: 0.000173325534622256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 0.8890	Cost: 32.42s
Train Epoch: 120 [40960/90000 (45%)]	Loss: -0.8153	Cost: 9.39s
Train Epoch: 120 [81920/90000 (91%)]	Loss: -0.9513	Cost: 12.88s
Train Epoch: 120 	Average Loss: -0.7428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2739

Learning rate: 0.00017289686274214115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 1.0400	Cost: 31.10s
Train Epoch: 121 [40960/90000 (45%)]	Loss: -1.0106	Cost: 9.46s
Train Epoch: 121 [81920/90000 (91%)]	Loss: -1.1526	Cost: 12.22s
Train Epoch: 121 	Average Loss: -0.8089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4875

Learning rate: 0.00017246531301870466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 1.1906	Cost: 31.47s
Train Epoch: 122 [40960/90000 (45%)]	Loss: -1.0874	Cost: 9.42s
Train Epoch: 122 [81920/90000 (91%)]	Loss: -1.0251	Cost: 12.62s
Train Epoch: 122 	Average Loss: -0.8225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1761

Learning rate: 0.00017203090248879067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 0.9477	Cost: 31.47s
Train Epoch: 123 [40960/90000 (45%)]	Loss: -1.2071	Cost: 9.41s
Train Epoch: 123 [81920/90000 (91%)]	Loss: -1.3279	Cost: 12.08s
Train Epoch: 123 	Average Loss: -0.8877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2750

Learning rate: 0.00017159364830218312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 1.2505	Cost: 30.93s
Train Epoch: 124 [40960/90000 (45%)]	Loss: -1.0720	Cost: 9.41s
Train Epoch: 124 [81920/90000 (91%)]	Loss: -1.3687	Cost: 11.69s
Train Epoch: 124 	Average Loss: -0.9306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1120

Saving model as e124_model.pt & e124_waveforms_supplementary.hdf5
Learning rate: 0.00017115356772092854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 1.0270	Cost: 32.21s
Train Epoch: 125 [40960/90000 (45%)]	Loss: -1.2143	Cost: 9.40s
Train Epoch: 125 [81920/90000 (91%)]	Loss: -1.3167	Cost: 12.76s
Train Epoch: 125 	Average Loss: -1.0188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1372

Learning rate: 0.00017071067811865473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 1.1504	Cost: 32.03s
Train Epoch: 126 [40960/90000 (45%)]	Loss: -1.1692	Cost: 9.39s
Train Epoch: 126 [81920/90000 (91%)]	Loss: -1.3612	Cost: 12.48s
Train Epoch: 126 	Average Loss: -1.0274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9076

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Learning rate: 0.00017026499697988493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 1.2397	Cost: 31.50s
Train Epoch: 127 [40960/90000 (45%)]	Loss: -1.3177	Cost: 9.37s
Train Epoch: 127 [81920/90000 (91%)]	Loss: -0.9876	Cost: 11.70s
Train Epoch: 127 	Average Loss: -0.9445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1873

Learning rate: 0.00016981654189934727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 1.0556	Cost: 31.00s
Train Epoch: 128 [40960/90000 (45%)]	Loss: -1.1046	Cost: 9.39s
Train Epoch: 128 [81920/90000 (91%)]	Loss: -1.1803	Cost: 12.21s
Train Epoch: 128 	Average Loss: -0.8949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0421

Learning rate: 0.0001693653305812805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 0.8900	Cost: 32.40s
Train Epoch: 129 [40960/90000 (45%)]	Loss: -1.1692	Cost: 9.39s
Train Epoch: 129 [81920/90000 (91%)]	Loss: -1.4155	Cost: 12.59s
Train Epoch: 129 	Average Loss: -1.0702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9866

Learning rate: 0.00016891138083873484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 0.6958	Cost: 30.89s
Train Epoch: 130 [40960/90000 (45%)]	Loss: -1.0645	Cost: 9.40s
Train Epoch: 130 [81920/90000 (91%)]	Loss: -1.4439	Cost: 12.00s
Train Epoch: 130 	Average Loss: -1.1455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8984

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 0.00016845471059286887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 0.6442	Cost: 30.78s
Train Epoch: 131 [40960/90000 (45%)]	Loss: -1.5120	Cost: 9.41s
Train Epoch: 131 [81920/90000 (91%)]	Loss: -1.4447	Cost: 11.79s
Train Epoch: 131 	Average Loss: -1.2654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1690

Learning rate: 0.0001679953378722419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 1.0774	Cost: 30.91s
Train Epoch: 132 [40960/90000 (45%)]	Loss: -1.3746	Cost: 9.42s
Train Epoch: 132 [81920/90000 (91%)]	Loss: -1.5548	Cost: 11.73s
Train Epoch: 132 	Average Loss: -1.2113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9912

Learning rate: 0.00016753328081210242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 1.0011	Cost: 30.66s
Train Epoch: 133 [40960/90000 (45%)]	Loss: -1.2168	Cost: 9.38s
Train Epoch: 133 [81920/90000 (91%)]	Loss: -1.4732	Cost: 12.33s
Train Epoch: 133 	Average Loss: -1.2153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0743

Learning rate: 0.000167068557653672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 0.5282	Cost: 31.93s
Train Epoch: 134 [40960/90000 (45%)]	Loss: -1.3874	Cost: 9.42s
Train Epoch: 134 [81920/90000 (91%)]	Loss: -1.6371	Cost: 12.56s
Train Epoch: 134 	Average Loss: -1.1875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0146

Learning rate: 0.00016660118674342514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 0.6305	Cost: 32.56s
Train Epoch: 135 [40960/90000 (45%)]	Loss: -1.5837	Cost: 9.36s
Train Epoch: 135 [81920/90000 (91%)]	Loss: -1.7224	Cost: 12.13s
Train Epoch: 135 	Average Loss: -1.3359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9190

Learning rate: 0.00016613118653236516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 0.7955	Cost: 31.66s
Train Epoch: 136 [40960/90000 (45%)]	Loss: -1.4641	Cost: 9.39s
Train Epoch: 136 [81920/90000 (91%)]	Loss: -1.7654	Cost: 12.10s
Train Epoch: 136 	Average Loss: -1.3769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9434

Learning rate: 0.0001656585755752956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 0.7252	Cost: 31.33s
Train Epoch: 137 [40960/90000 (45%)]	Loss: -1.5674	Cost: 9.38s
Train Epoch: 137 [81920/90000 (91%)]	Loss: -1.5335	Cost: 12.15s
Train Epoch: 137 	Average Loss: -1.3719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8738

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 0.00016518337253008784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 0.5321	Cost: 31.57s
Train Epoch: 138 [40960/90000 (45%)]	Loss: -1.6245	Cost: 9.60s
Train Epoch: 138 [81920/90000 (91%)]	Loss: -1.7571	Cost: 11.78s
Train Epoch: 138 	Average Loss: -1.4028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9253

Learning rate: 0.0001647055961569444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 0.6065	Cost: 31.08s
Train Epoch: 139 [40960/90000 (45%)]	Loss: -1.6069	Cost: 9.39s
Train Epoch: 139 [81920/90000 (91%)]	Loss: -1.6357	Cost: 12.69s
Train Epoch: 139 	Average Loss: -1.3864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1082

Learning rate: 0.0001642252653176584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 0.8926	Cost: 31.96s
Train Epoch: 140 [40960/90000 (45%)]	Loss: -1.2545	Cost: 9.40s
Train Epoch: 140 [81920/90000 (91%)]	Loss: -1.4671	Cost: 11.90s
Train Epoch: 140 	Average Loss: -1.2569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9830

Learning rate: 0.00016374239897486894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 0.5670	Cost: 30.91s
Train Epoch: 141 [40960/90000 (45%)]	Loss: -1.6654	Cost: 9.39s
Train Epoch: 141 [81920/90000 (91%)]	Loss: -1.8974	Cost: 11.64s
Train Epoch: 141 	Average Loss: -1.4207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8995

Learning rate: 0.0001632570161913124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 0.6805	Cost: 33.12s
Train Epoch: 142 [40960/90000 (45%)]	Loss: -1.6387	Cost: 9.39s
Train Epoch: 142 [81920/90000 (91%)]	Loss: -1.8672	Cost: 12.29s
Train Epoch: 142 	Average Loss: -1.5060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6766

Saving model as e142_model.pt & e142_waveforms_supplementary.hdf5
Learning rate: 0.00016276913612907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 0.8385	Cost: 32.42s
Train Epoch: 143 [40960/90000 (45%)]	Loss: -1.9079	Cost: 9.40s
Train Epoch: 143 [81920/90000 (91%)]	Loss: -2.0413	Cost: 12.16s
Train Epoch: 143 	Average Loss: -1.5884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6289

Saving model as e143_model.pt & e143_waveforms_supplementary.hdf5
Learning rate: 0.00016227877804881122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 0.2077	Cost: 31.61s
Train Epoch: 144 [40960/90000 (45%)]	Loss: -1.8515	Cost: 9.40s
Train Epoch: 144 [81920/90000 (91%)]	Loss: -1.7637	Cost: 12.44s
Train Epoch: 144 	Average Loss: -1.5845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9334

Learning rate: 0.0001617859613090334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 0.4621	Cost: 31.53s
Train Epoch: 145 [40960/90000 (45%)]	Loss: -1.8170	Cost: 9.39s
Train Epoch: 145 [81920/90000 (91%)]	Loss: -1.9300	Cost: 11.59s
Train Epoch: 145 	Average Loss: -1.5791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7861

Learning rate: 0.00016129070536529763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 0.4453	Cost: 31.94s
Train Epoch: 146 [40960/90000 (45%)]	Loss: -1.9117	Cost: 9.36s
Train Epoch: 146 [81920/90000 (91%)]	Loss: -1.7805	Cost: 12.11s
Train Epoch: 146 	Average Loss: -1.6605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8754

Learning rate: 0.00016079302976946053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 0.2718	Cost: 31.52s
Train Epoch: 147 [40960/90000 (45%)]	Loss: -1.7703	Cost: 9.39s
Train Epoch: 147 [81920/90000 (91%)]	Loss: -1.6758	Cost: 12.61s
Train Epoch: 147 	Average Loss: -1.6335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9992

Learning rate: 0.00016029295416890245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 0.4766	Cost: 31.46s
Train Epoch: 148 [40960/90000 (45%)]	Loss: -1.7869	Cost: 9.40s
Train Epoch: 148 [81920/90000 (91%)]	Loss: -1.9094	Cost: 11.96s
Train Epoch: 148 	Average Loss: -1.6006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7605

Learning rate: 0.00015979049830575187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 0.7805	Cost: 31.16s
Train Epoch: 149 [40960/90000 (45%)]	Loss: -1.8712	Cost: 9.39s
Train Epoch: 149 [81920/90000 (91%)]	Loss: -1.9398	Cost: 12.00s
Train Epoch: 149 	Average Loss: -1.6398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6833

Learning rate: 0.00015928568201610592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 0.6462	Cost: 30.75s
Train Epoch: 150 [40960/90000 (45%)]	Loss: -1.8879	Cost: 9.42s
Train Epoch: 150 [81920/90000 (91%)]	Loss: -2.1002	Cost: 12.90s
Train Epoch: 150 	Average Loss: -1.6520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6777

Learning rate: 0.00015877852522924732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 0.3126	Cost: 31.75s
Train Epoch: 151 [40960/90000 (45%)]	Loss: -2.2453	Cost: 9.40s
Train Epoch: 151 [81920/90000 (91%)]	Loss: -1.9753	Cost: 11.70s
Train Epoch: 151 	Average Loss: -1.8374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7794

Learning rate: 0.00015826904796685762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 0.0899	Cost: 31.14s
Train Epoch: 152 [40960/90000 (45%)]	Loss: -2.0901	Cost: 9.41s
Train Epoch: 152 [81920/90000 (91%)]	Loss: -2.1882	Cost: 12.71s
Train Epoch: 152 	Average Loss: -1.9164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7417

Learning rate: 0.00015775727034222675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 0.1495	Cost: 32.40s
Train Epoch: 153 [40960/90000 (45%)]	Loss: -1.9901	Cost: 9.35s
Train Epoch: 153 [81920/90000 (91%)]	Loss: -2.0314	Cost: 12.30s
Train Epoch: 153 	Average Loss: -1.8416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6954

Learning rate: 0.00015724321255945907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 0.2131	Cost: 32.45s
Train Epoch: 154 [40960/90000 (45%)]	Loss: -2.0675	Cost: 9.34s
Train Epoch: 154 [81920/90000 (91%)]	Loss: -1.9568	Cost: 12.25s
Train Epoch: 154 	Average Loss: -1.7416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7900

Learning rate: 0.00015672689491267567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 0.5471	Cost: 31.57s
Train Epoch: 155 [40960/90000 (45%)]	Loss: -2.2090	Cost: 9.42s
Train Epoch: 155 [81920/90000 (91%)]	Loss: -2.2330	Cost: 12.00s
Train Epoch: 155 	Average Loss: -1.8308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7099

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 0.1986	Cost: 32.27s
Train Epoch: 156 [40960/90000 (45%)]	Loss: -1.9841	Cost: 9.39s
Train Epoch: 156 [81920/90000 (91%)]	Loss: -1.9768	Cost: 12.56s
Train Epoch: 156 	Average Loss: -1.9176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6882

Learning rate: 0.00015568756164881882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 0.7238	Cost: 31.16s
Train Epoch: 157 [40960/90000 (45%)]	Loss: -2.2847	Cost: 9.42s
Train Epoch: 157 [81920/90000 (91%)]	Loss: -2.2933	Cost: 11.68s
Train Epoch: 157 	Average Loss: -1.9286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5108

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Learning rate: 0.00015516458706284303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 0.2895	Cost: 31.05s
Train Epoch: 158 [40960/90000 (45%)]	Loss: -2.3628	Cost: 9.40s
Train Epoch: 158 [81920/90000 (91%)]	Loss: -2.3923	Cost: 11.54s
Train Epoch: 158 	Average Loss: -2.0698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4426

Saving model as e158_model.pt & e158_waveforms_supplementary.hdf5
Learning rate: 0.0001546394346734269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 0.0254	Cost: 31.59s
Train Epoch: 159 [40960/90000 (45%)]	Loss: -2.1912	Cost: 9.36s
Train Epoch: 159 [81920/90000 (91%)]	Loss: -2.4610	Cost: 12.61s
Train Epoch: 159 	Average Loss: -2.1157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3638

Saving model as e159_model.pt & e159_waveforms_supplementary.hdf5
Learning rate: 0.00015411212521268755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 0.3021	Cost: 30.76s
Train Epoch: 160 [40960/90000 (45%)]	Loss: -2.4770	Cost: 9.40s
Train Epoch: 160 [81920/90000 (91%)]	Loss: -2.5115	Cost: 12.45s
Train Epoch: 160 	Average Loss: -2.1472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3811

Learning rate: 0.00015358267949789963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 0.3452	Cost: 32.56s
Train Epoch: 161 [40960/90000 (45%)]	Loss: -2.3903	Cost: 9.36s
Train Epoch: 161 [81920/90000 (91%)]	Loss: -2.3509	Cost: 12.20s
Train Epoch: 161 	Average Loss: -2.1833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6026

Learning rate: 0.00015305111843067339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: -0.0520	Cost: 32.17s
Train Epoch: 162 [40960/90000 (45%)]	Loss: -2.5175	Cost: 9.41s
Train Epoch: 162 [81920/90000 (91%)]	Loss: -2.6159	Cost: 12.73s
Train Epoch: 162 	Average Loss: -2.2195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3491

Saving model as e162_model.pt & e162_waveforms_supplementary.hdf5
Learning rate: 0.00015251746299612957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 0.2372	Cost: 31.81s
Train Epoch: 163 [40960/90000 (45%)]	Loss: -2.3671	Cost: 9.40s
Train Epoch: 163 [81920/90000 (91%)]	Loss: -2.4696	Cost: 12.09s
Train Epoch: 163 	Average Loss: -2.2359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3422

Saving model as e163_model.pt & e163_waveforms_supplementary.hdf5
Learning rate: 0.00015198173426207094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 0.2074	Cost: 30.97s
Train Epoch: 164 [40960/90000 (45%)]	Loss: -2.4941	Cost: 9.40s
Train Epoch: 164 [81920/90000 (91%)]	Loss: -2.4727	Cost: 11.88s
Train Epoch: 164 	Average Loss: -2.1585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4409

Learning rate: 0.00015144395337815067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: -0.0278	Cost: 31.38s
Train Epoch: 165 [40960/90000 (45%)]	Loss: -2.3479	Cost: 9.41s
Train Epoch: 165 [81920/90000 (91%)]	Loss: -2.5168	Cost: 12.55s
Train Epoch: 165 	Average Loss: -2.2092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3724

Learning rate: 0.00015090414157503714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 0.1003	Cost: 31.21s
Train Epoch: 166 [40960/90000 (45%)]	Loss: -2.5031	Cost: 9.58s
Train Epoch: 166 [81920/90000 (91%)]	Loss: -2.5212	Cost: 11.80s
Train Epoch: 166 	Average Loss: -2.3139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3842

Learning rate: 0.00015036232016357607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 0.0142	Cost: 31.14s
Train Epoch: 167 [40960/90000 (45%)]	Loss: -2.5281	Cost: 9.60s
Train Epoch: 167 [81920/90000 (91%)]	Loss: -2.7037	Cost: 12.38s
Train Epoch: 167 	Average Loss: -2.3683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2179

Saving model as e167_model.pt & e167_waveforms_supplementary.hdf5
Learning rate: 0.00014981851053394907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 0.0646	Cost: 31.28s
Train Epoch: 168 [40960/90000 (45%)]	Loss: -2.8151	Cost: 9.60s
Train Epoch: 168 [81920/90000 (91%)]	Loss: -2.7385	Cost: 12.27s
Train Epoch: 168 	Average Loss: -2.3809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3187

Learning rate: 0.00014927273415482915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: -0.0575	Cost: 30.90s
Train Epoch: 169 [40960/90000 (45%)]	Loss: -2.5270	Cost: 9.42s
Train Epoch: 169 [81920/90000 (91%)]	Loss: -2.6941	Cost: 12.80s
Train Epoch: 169 	Average Loss: -2.4448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1803

Saving model as e169_model.pt & e169_waveforms_supplementary.hdf5
Learning rate: 0.00014872501257253323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: -0.1567	Cost: 30.00s
Train Epoch: 170 [40960/90000 (45%)]	Loss: -2.7732	Cost: 9.91s
Train Epoch: 170 [81920/90000 (91%)]	Loss: -2.9339	Cost: 12.67s
Train Epoch: 170 	Average Loss: -2.4825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3336

Learning rate: 0.00014817536741017152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: -0.1141	Cost: 35.25s
Train Epoch: 171 [40960/90000 (45%)]	Loss: -2.9895	Cost: 9.61s
Train Epoch: 171 [81920/90000 (91%)]	Loss: -2.8082	Cost: 12.45s
Train Epoch: 171 	Average Loss: -2.5283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3006

Learning rate: 0.0001476238203667939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 0.1303	Cost: 33.94s
Train Epoch: 172 [40960/90000 (45%)]	Loss: -2.8044	Cost: 9.54s
Train Epoch: 172 [81920/90000 (91%)]	Loss: -2.6870	Cost: 12.47s
Train Epoch: 172 	Average Loss: -2.5494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2006

Learning rate: 0.00014707039321653327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: -0.3469	Cost: 32.22s
Train Epoch: 173 [40960/90000 (45%)]	Loss: -2.7934	Cost: 9.55s
Train Epoch: 173 [81920/90000 (91%)]	Loss: -2.8069	Cost: 11.65s
Train Epoch: 173 	Average Loss: -2.3996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3240

Learning rate: 0.00014651510780774586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: -0.0618	Cost: 32.77s
Train Epoch: 174 [40960/90000 (45%)]	Loss: -2.5998	Cost: 9.57s
Train Epoch: 174 [81920/90000 (91%)]	Loss: -2.7008	Cost: 12.22s
Train Epoch: 174 	Average Loss: -2.3195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3715

Learning rate: 0.00014595798606214882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 0.0016	Cost: 31.42s
Train Epoch: 175 [40960/90000 (45%)]	Loss: -2.6964	Cost: 9.54s
Train Epoch: 175 [81920/90000 (91%)]	Loss: -2.9412	Cost: 12.38s
Train Epoch: 175 	Average Loss: -2.4236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1945

Learning rate: 0.00014539904997395468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: -0.1520	Cost: 31.78s
Train Epoch: 176 [40960/90000 (45%)]	Loss: -2.7924	Cost: 9.98s
Train Epoch: 176 [81920/90000 (91%)]	Loss: -2.9895	Cost: 11.89s
Train Epoch: 176 	Average Loss: -2.5638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1795

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Learning rate: 0.00014483832160900326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: -0.2510	Cost: 31.36s
Train Epoch: 177 [40960/90000 (45%)]	Loss: -2.7659	Cost: 9.44s
Train Epoch: 177 [81920/90000 (91%)]	Loss: -3.0017	Cost: 12.66s
Train Epoch: 177 	Average Loss: -2.6353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1537

Saving model as e177_model.pt & e177_waveforms_supplementary.hdf5
Learning rate: 0.00014427582310389016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: -0.2678	Cost: 31.29s
Train Epoch: 178 [40960/90000 (45%)]	Loss: -2.9399	Cost: 9.41s
Train Epoch: 178 [81920/90000 (91%)]	Loss: -2.9981	Cost: 12.18s
Train Epoch: 178 	Average Loss: -2.6577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0683

Saving model as e178_model.pt & e178_waveforms_supplementary.hdf5
Learning rate: 0.0001437115766650933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: -0.1630	Cost: 31.15s
Train Epoch: 179 [40960/90000 (45%)]	Loss: -2.9440	Cost: 9.41s
Train Epoch: 179 [81920/90000 (91%)]	Loss: -3.1148	Cost: 12.21s
Train Epoch: 179 	Average Loss: -2.6560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1389

Learning rate: 0.0001431456045680959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 0.0986	Cost: 30.93s
Train Epoch: 180 [40960/90000 (45%)]	Loss: -3.0324	Cost: 9.39s
Train Epoch: 180 [81920/90000 (91%)]	Loss: -2.8429	Cost: 12.14s
Train Epoch: 180 	Average Loss: -2.6879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1741

Learning rate: 0.00014257792915650726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: -0.2937	Cost: 32.72s
Train Epoch: 181 [40960/90000 (45%)]	Loss: -2.8212	Cost: 9.42s
Train Epoch: 181 [81920/90000 (91%)]	Loss: -2.9518	Cost: 12.36s
Train Epoch: 181 	Average Loss: -2.6018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1390

Learning rate: 0.0001420085728411806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 0.1352	Cost: 31.48s
Train Epoch: 182 [40960/90000 (45%)]	Loss: -2.9097	Cost: 9.42s
Train Epoch: 182 [81920/90000 (91%)]	Loss: -2.9738	Cost: 11.74s
Train Epoch: 182 	Average Loss: -2.6774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1004

Learning rate: 0.0001414375580993284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: -0.3526	Cost: 31.19s
Train Epoch: 183 [40960/90000 (45%)]	Loss: -3.1862	Cost: 9.61s
Train Epoch: 183 [81920/90000 (91%)]	Loss: -3.2310	Cost: 12.63s
Train Epoch: 183 	Average Loss: -2.7997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0882

Learning rate: 0.00014086490747363488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: -0.0261	Cost: 33.09s
Train Epoch: 184 [40960/90000 (45%)]	Loss: -3.1498	Cost: 9.52s
Train Epoch: 184 [81920/90000 (91%)]	Loss: -3.1390	Cost: 12.23s
Train Epoch: 184 	Average Loss: -2.8266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0386

Saving model as e184_model.pt & e184_waveforms_supplementary.hdf5
Learning rate: 0.00014029064357136623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: -0.3386	Cost: 31.81s
Train Epoch: 185 [40960/90000 (45%)]	Loss: -3.1123	Cost: 9.41s
Train Epoch: 185 [81920/90000 (91%)]	Loss: -3.2927	Cost: 12.18s
Train Epoch: 185 	Average Loss: -2.8400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9630

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Learning rate: 0.00013971478906347803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: -0.2195	Cost: 30.39s
Train Epoch: 186 [40960/90000 (45%)]	Loss: -3.0157	Cost: 9.40s
Train Epoch: 186 [81920/90000 (91%)]	Loss: -3.1397	Cost: 11.96s
Train Epoch: 186 	Average Loss: -2.7909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1236

Learning rate: 0.0001391373666837202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: -0.5477	Cost: 32.33s
Train Epoch: 187 [40960/90000 (45%)]	Loss: -2.9974	Cost: 9.35s
Train Epoch: 187 [81920/90000 (91%)]	Loss: -3.2725	Cost: 12.24s
Train Epoch: 187 	Average Loss: -2.8382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0840

Learning rate: 0.0001385583992277396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: -0.2063	Cost: 32.41s
Train Epoch: 188 [40960/90000 (45%)]	Loss: -3.1062	Cost: 9.39s
Train Epoch: 188 [81920/90000 (91%)]	Loss: -3.3019	Cost: 12.28s
Train Epoch: 188 	Average Loss: -2.8309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9426

Saving model as e188_model.pt & e188_waveforms_supplementary.hdf5
Learning rate: 0.00013797790955218008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: -0.4682	Cost: 30.99s
Train Epoch: 189 [40960/90000 (45%)]	Loss: -3.2148	Cost: 9.39s
Train Epoch: 189 [81920/90000 (91%)]	Loss: -3.3689	Cost: 11.68s
Train Epoch: 189 	Average Loss: -3.0242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0169

Learning rate: 0.00013739592057378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: -0.6388	Cost: 32.42s
Train Epoch: 190 [40960/90000 (45%)]	Loss: -3.2512	Cost: 9.39s
Train Epoch: 190 [81920/90000 (91%)]	Loss: -3.2263	Cost: 12.45s
Train Epoch: 190 	Average Loss: -3.0074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0330

Learning rate: 0.00013681245526846775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: -0.5563	Cost: 31.59s
Train Epoch: 191 [40960/90000 (45%)]	Loss: -3.3966	Cost: 9.40s
Train Epoch: 191 [81920/90000 (91%)]	Loss: -3.1586	Cost: 12.78s
Train Epoch: 191 	Average Loss: -2.9710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1402

Learning rate: 0.00013622753667045454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: -0.4554	Cost: 32.15s
Train Epoch: 192 [40960/90000 (45%)]	Loss: -3.2048	Cost: 9.41s
Train Epoch: 192 [81920/90000 (91%)]	Loss: -3.4923	Cost: 12.14s
Train Epoch: 192 	Average Loss: -2.9487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0400

Learning rate: 0.00013564118787132503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: -0.4673	Cost: 32.03s
Train Epoch: 193 [40960/90000 (45%)]	Loss: -3.1385	Cost: 9.38s
Train Epoch: 193 [81920/90000 (91%)]	Loss: -3.4661	Cost: 12.42s
Train Epoch: 193 	Average Loss: -2.9909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8072

Saving model as e193_model.pt & e193_waveforms_supplementary.hdf5
Learning rate: 0.00013505343201912587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: -0.5568	Cost: 30.85s
Train Epoch: 194 [40960/90000 (45%)]	Loss: -3.1873	Cost: 9.39s
Train Epoch: 194 [81920/90000 (91%)]	Loss: -3.5416	Cost: 11.83s
Train Epoch: 194 	Average Loss: -3.1273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8157

Learning rate: 0.0001344642923174517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: -0.3893	Cost: 30.87s
Train Epoch: 195 [40960/90000 (45%)]	Loss: -3.3878	Cost: 9.40s
Train Epoch: 195 [81920/90000 (91%)]	Loss: -3.6249	Cost: 12.05s
Train Epoch: 195 	Average Loss: -3.2008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7942

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Learning rate: 0.00013387379202452914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: -0.7346	Cost: 32.48s
Train Epoch: 196 [40960/90000 (45%)]	Loss: -3.5486	Cost: 9.38s
Train Epoch: 196 [81920/90000 (91%)]	Loss: -3.4991	Cost: 12.17s
Train Epoch: 196 	Average Loss: -3.2272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7362

Saving model as e196_model.pt & e196_waveforms_supplementary.hdf5
Learning rate: 0.00013328195445229865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: -0.5142	Cost: 31.60s
Train Epoch: 197 [40960/90000 (45%)]	Loss: -3.4507	Cost: 9.39s
Train Epoch: 197 [81920/90000 (91%)]	Loss: -3.5611	Cost: 11.95s
Train Epoch: 197 	Average Loss: -3.2231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8199

Learning rate: 0.00013268880296549425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: -0.3331	Cost: 32.48s
Train Epoch: 198 [40960/90000 (45%)]	Loss: -3.3382	Cost: 9.44s
Train Epoch: 198 [81920/90000 (91%)]	Loss: -3.5239	Cost: 12.32s
Train Epoch: 198 	Average Loss: -3.1889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8349

Learning rate: 0.00013209436098072093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: -0.7176	Cost: 31.56s
Train Epoch: 199 [40960/90000 (45%)]	Loss: -3.3622	Cost: 10.06s
Train Epoch: 199 [81920/90000 (91%)]	Loss: -3.7691	Cost: 12.21s
Train Epoch: 199 	Average Loss: -3.3063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7500

Learning rate: 0.00013149865196553047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: -0.6501	Cost: 32.41s
Train Epoch: 200 [40960/90000 (45%)]	Loss: -3.4505	Cost: 9.40s
Train Epoch: 200 [81920/90000 (91%)]	Loss: -3.6811	Cost: 12.81s
Train Epoch: 200 	Average Loss: -3.3000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6786

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 0.00013090169943749474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: -0.6035	Cost: 31.49s
Train Epoch: 201 [40960/90000 (45%)]	Loss: -3.5227	Cost: 9.39s
Train Epoch: 201 [81920/90000 (91%)]	Loss: -3.6996	Cost: 12.14s
Train Epoch: 201 	Average Loss: -3.3488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6468

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 0.0001303035269632774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: -0.5159	Cost: 31.31s
Train Epoch: 202 [40960/90000 (45%)]	Loss: -3.7190	Cost: 9.38s
Train Epoch: 202 [81920/90000 (91%)]	Loss: -3.7613	Cost: 11.69s
Train Epoch: 202 	Average Loss: -3.3419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7505

Learning rate: 0.00012970415815770348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: -0.6541	Cost: 32.12s
Train Epoch: 203 [40960/90000 (45%)]	Loss: -3.7435	Cost: 9.42s
Train Epoch: 203 [81920/90000 (91%)]	Loss: -3.6738	Cost: 12.47s
Train Epoch: 203 	Average Loss: -3.3442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5223

Saving model as e203_model.pt & e203_waveforms_supplementary.hdf5
Learning rate: 0.00012910361668282719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: -0.5811	Cost: 31.94s
Train Epoch: 204 [40960/90000 (45%)]	Loss: -3.5206	Cost: 9.40s
Train Epoch: 204 [81920/90000 (91%)]	Loss: -3.8191	Cost: 12.47s
Train Epoch: 204 	Average Loss: -3.4480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8833

Learning rate: 0.0001285019262469976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: -0.4721	Cost: 30.94s
Train Epoch: 205 [40960/90000 (45%)]	Loss: -3.6032	Cost: 9.42s
Train Epoch: 205 [81920/90000 (91%)]	Loss: -3.5584	Cost: 12.89s
Train Epoch: 205 	Average Loss: -3.3681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6882

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: -0.5336	Cost: 32.45s
Train Epoch: 206 [40960/90000 (45%)]	Loss: -3.7094	Cost: 9.38s
Train Epoch: 206 [81920/90000 (91%)]	Loss: -3.5901	Cost: 12.38s
Train Epoch: 206 	Average Loss: -3.3385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7948

Learning rate: 0.00012729519355173254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: -0.5117	Cost: 31.95s
Train Epoch: 207 [40960/90000 (45%)]	Loss: -3.7303	Cost: 9.39s
Train Epoch: 207 [81920/90000 (91%)]	Loss: -3.6205	Cost: 12.20s
Train Epoch: 207 	Average Loss: -3.4007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5769

Learning rate: 0.00012669019893203759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: -0.5854	Cost: 32.52s
Train Epoch: 208 [40960/90000 (45%)]	Loss: -3.5664	Cost: 9.59s
Train Epoch: 208 [81920/90000 (91%)]	Loss: -3.8035	Cost: 12.33s
Train Epoch: 208 	Average Loss: -3.4231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7861

Learning rate: 0.0001260841506289897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: -0.7647	Cost: 31.82s
Train Epoch: 209 [40960/90000 (45%)]	Loss: -3.8364	Cost: 9.44s
Train Epoch: 209 [81920/90000 (91%)]	Loss: -3.9236	Cost: 12.91s
Train Epoch: 209 	Average Loss: -3.4678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4983

Saving model as e209_model.pt & e209_waveforms_supplementary.hdf5
Learning rate: 0.00012547707256833825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: -0.6594	Cost: 32.25s
Train Epoch: 210 [40960/90000 (45%)]	Loss: -3.7034	Cost: 9.40s
Train Epoch: 210 [81920/90000 (91%)]	Loss: -3.8962	Cost: 12.40s
Train Epoch: 210 	Average Loss: -3.3871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7918

Learning rate: 0.00012486898871648549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: -0.6012	Cost: 31.22s
Train Epoch: 211 [40960/90000 (45%)]	Loss: -3.7374	Cost: 10.09s
Train Epoch: 211 [81920/90000 (91%)]	Loss: -3.8999	Cost: 11.11s
Train Epoch: 211 	Average Loss: -3.5100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7127

Learning rate: 0.00012425992307954077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: -0.6953	Cost: 32.00s
Train Epoch: 212 [40960/90000 (45%)]	Loss: -3.9118	Cost: 9.59s
Train Epoch: 212 [81920/90000 (91%)]	Loss: -4.0493	Cost: 11.88s
Train Epoch: 212 	Average Loss: -3.6627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6110

Learning rate: 0.0001236498997023725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: -0.8442	Cost: 31.79s
Train Epoch: 213 [40960/90000 (45%)]	Loss: -4.1016	Cost: 9.39s
Train Epoch: 213 [81920/90000 (91%)]	Loss: -4.1677	Cost: 11.65s
Train Epoch: 213 	Average Loss: -3.7064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5384

Learning rate: 0.00012303894266765908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: -0.7166	Cost: 32.07s
Train Epoch: 214 [40960/90000 (45%)]	Loss: -3.9407	Cost: 9.38s
Train Epoch: 214 [81920/90000 (91%)]	Loss: -4.0786	Cost: 12.42s
Train Epoch: 214 	Average Loss: -3.6991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4342

Saving model as e214_model.pt & e214_waveforms_supplementary.hdf5
Learning rate: 0.00012242707609493814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: -0.9423	Cost: 30.93s
Train Epoch: 215 [40960/90000 (45%)]	Loss: -3.9043	Cost: 9.43s
Train Epoch: 215 [81920/90000 (91%)]	Loss: -3.9743	Cost: 12.51s
Train Epoch: 215 	Average Loss: -3.6687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5165

Learning rate: 0.0001218143241396543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: -0.8977	Cost: 31.23s
Train Epoch: 216 [40960/90000 (45%)]	Loss: -4.0177	Cost: 9.41s
Train Epoch: 216 [81920/90000 (91%)]	Loss: -4.1263	Cost: 12.24s
Train Epoch: 216 	Average Loss: -3.6994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3851

Saving model as e216_model.pt & e216_waveforms_supplementary.hdf5
Learning rate: 0.0001212007109922055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: -0.7794	Cost: 31.96s
Train Epoch: 217 [40960/90000 (45%)]	Loss: -3.9198	Cost: 9.36s
Train Epoch: 217 [81920/90000 (91%)]	Loss: -4.1998	Cost: 12.13s
Train Epoch: 217 	Average Loss: -3.7254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4863

Learning rate: 0.00012058626087698816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: -0.8534	Cost: 31.08s
Train Epoch: 218 [40960/90000 (45%)]	Loss: -4.0187	Cost: 9.41s
Train Epoch: 218 [81920/90000 (91%)]	Loss: -3.9843	Cost: 12.61s
Train Epoch: 218 	Average Loss: -3.7578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4803

Learning rate: 0.00011997099805144073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: -0.7830	Cost: 30.88s
Train Epoch: 219 [40960/90000 (45%)]	Loss: -4.1738	Cost: 9.40s
Train Epoch: 219 [81920/90000 (91%)]	Loss: -4.2186	Cost: 11.48s
Train Epoch: 219 	Average Loss: -3.8567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4635

Learning rate: 0.00011935494680508606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: -1.0497	Cost: 31.55s
Train Epoch: 220 [40960/90000 (45%)]	Loss: -4.1579	Cost: 9.40s
Train Epoch: 220 [81920/90000 (91%)]	Loss: -4.2699	Cost: 12.65s
Train Epoch: 220 	Average Loss: -3.9368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4488

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: -0.8637	Cost: 32.03s
Train Epoch: 221 [40960/90000 (45%)]	Loss: -4.2041	Cost: 9.40s
Train Epoch: 221 [81920/90000 (91%)]	Loss: -4.1118	Cost: 12.59s
Train Epoch: 221 	Average Loss: -3.9290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3199

Saving model as e221_model.pt & e221_waveforms_supplementary.hdf5
Learning rate: 0.00011812057636271377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: -0.9229	Cost: 31.15s
Train Epoch: 222 [40960/90000 (45%)]	Loss: -4.1834	Cost: 9.40s
Train Epoch: 222 [81920/90000 (91%)]	Loss: -4.1359	Cost: 11.80s
Train Epoch: 222 	Average Loss: -3.9283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4132

Learning rate: 0.00011750230589752765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: -0.9379	Cost: 31.65s
Train Epoch: 223 [40960/90000 (45%)]	Loss: -4.2492	Cost: 10.05s
Train Epoch: 223 [81920/90000 (91%)]	Loss: -4.3419	Cost: 11.49s
Train Epoch: 223 	Average Loss: -3.9293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3349

Learning rate: 0.0001168833444712734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: -0.8838	Cost: 32.20s
Train Epoch: 224 [40960/90000 (45%)]	Loss: -4.2335	Cost: 9.36s
Train Epoch: 224 [81920/90000 (91%)]	Loss: -4.2221	Cost: 11.94s
Train Epoch: 224 	Average Loss: -3.9818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4145

Learning rate: 0.00011626371651948839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: -0.9769	Cost: 30.86s
Train Epoch: 225 [40960/90000 (45%)]	Loss: -4.4417	Cost: 9.60s
Train Epoch: 225 [81920/90000 (91%)]	Loss: -4.3057	Cost: 11.64s
Train Epoch: 225 	Average Loss: -4.0082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3254

Learning rate: 0.00011564344650402312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: -1.2635	Cost: 32.83s
Train Epoch: 226 [40960/90000 (45%)]	Loss: -4.1397	Cost: 9.38s
Train Epoch: 226 [81920/90000 (91%)]	Loss: -4.3916	Cost: 12.49s
Train Epoch: 226 	Average Loss: -4.0032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3278

Learning rate: 0.00011502255891207573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: -1.0850	Cost: 32.43s
Train Epoch: 227 [40960/90000 (45%)]	Loss: -4.3704	Cost: 9.38s
Train Epoch: 227 [81920/90000 (91%)]	Loss: -4.6161	Cost: 12.59s
Train Epoch: 227 	Average Loss: -4.0434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3270

Learning rate: 0.00011440107825522525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: -0.8690	Cost: 32.35s
Train Epoch: 228 [40960/90000 (45%)]	Loss: -4.3175	Cost: 9.38s
Train Epoch: 228 [81920/90000 (91%)]	Loss: -4.3607	Cost: 12.28s
Train Epoch: 228 	Average Loss: -4.0527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2629

Saving model as e228_model.pt & e228_waveforms_supplementary.hdf5
Learning rate: 0.00011377902906846383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: -0.8895	Cost: 31.89s
Train Epoch: 229 [40960/90000 (45%)]	Loss: -4.5379	Cost: 9.38s
Train Epoch: 229 [81920/90000 (91%)]	Loss: -4.6182	Cost: 11.66s
Train Epoch: 229 	Average Loss: -4.1331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2907

Learning rate: 0.00011315643590922827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: -1.3147	Cost: 32.29s
Train Epoch: 230 [40960/90000 (45%)]	Loss: -4.3304	Cost: 9.37s
Train Epoch: 230 [81920/90000 (91%)]	Loss: -4.3382	Cost: 12.45s
Train Epoch: 230 	Average Loss: -4.1578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3262

Learning rate: 0.00011253332335643043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: -1.2945	Cost: 30.56s
Train Epoch: 231 [40960/90000 (45%)]	Loss: -4.5154	Cost: 9.42s
Train Epoch: 231 [81920/90000 (91%)]	Loss: -4.6225	Cost: 11.45s
Train Epoch: 231 	Average Loss: -4.1597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3108

Learning rate: 0.00011190971600948699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: -0.8794	Cost: 31.86s
Train Epoch: 232 [40960/90000 (45%)]	Loss: -4.3162	Cost: 9.36s
Train Epoch: 232 [81920/90000 (91%)]	Loss: -4.7625	Cost: 12.36s
Train Epoch: 232 	Average Loss: -4.1687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3734

Learning rate: 0.00011128563848734816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: -1.2272	Cost: 32.17s
Train Epoch: 233 [40960/90000 (45%)]	Loss: -4.5588	Cost: 9.38s
Train Epoch: 233 [81920/90000 (91%)]	Loss: -4.6496	Cost: 12.59s
Train Epoch: 233 	Average Loss: -4.2367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3384

Learning rate: 0.000110661115427526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: -1.4209	Cost: 32.11s
Train Epoch: 234 [40960/90000 (45%)]	Loss: -4.6377	Cost: 9.39s
Train Epoch: 234 [81920/90000 (91%)]	Loss: -4.7225	Cost: 12.72s
Train Epoch: 234 	Average Loss: -4.2669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2628

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 0.00011003617148512149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: -1.2094	Cost: 32.76s
Train Epoch: 235 [40960/90000 (45%)]	Loss: -4.4714	Cost: 9.39s
Train Epoch: 235 [81920/90000 (91%)]	Loss: -4.4981	Cost: 12.26s
Train Epoch: 235 	Average Loss: -4.2171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1288

Saving model as e235_model.pt & e235_waveforms_supplementary.hdf5
Learning rate: 0.00010941083133185143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: -1.1496	Cost: 31.71s
Train Epoch: 236 [40960/90000 (45%)]	Loss: -4.6870	Cost: 9.41s
Train Epoch: 236 [81920/90000 (91%)]	Loss: -4.6897	Cost: 12.46s
Train Epoch: 236 	Average Loss: -4.2522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1506

Learning rate: 0.00010878511965507434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: -1.4618	Cost: 31.33s
Train Epoch: 237 [40960/90000 (45%)]	Loss: -4.5777	Cost: 9.37s
Train Epoch: 237 [81920/90000 (91%)]	Loss: -4.6986	Cost: 12.51s
Train Epoch: 237 	Average Loss: -4.3560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0501

Saving model as e237_model.pt & e237_waveforms_supplementary.hdf5
Learning rate: 0.00010815906115681577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: -1.0283	Cost: 31.02s
Train Epoch: 238 [40960/90000 (45%)]	Loss: -4.7748	Cost: 9.39s
Train Epoch: 238 [81920/90000 (91%)]	Loss: -4.8468	Cost: 12.34s
Train Epoch: 238 	Average Loss: -4.4137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0629

Learning rate: 0.00010753268055279328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: -1.2574	Cost: 31.96s
Train Epoch: 239 [40960/90000 (45%)]	Loss: -4.4703	Cost: 9.40s
Train Epoch: 239 [81920/90000 (91%)]	Loss: -4.7849	Cost: 12.46s
Train Epoch: 239 	Average Loss: -4.3755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0655

Saving model as e239_model.pt & e239_waveforms_supplementary.hdf5
Learning rate: 0.0001069060025714406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: -1.3741	Cost: 30.85s
Train Epoch: 240 [40960/90000 (45%)]	Loss: -4.7770	Cost: 9.39s
Train Epoch: 240 [81920/90000 (91%)]	Loss: -4.6741	Cost: 12.65s
Train Epoch: 240 	Average Loss: -4.4082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2326

Learning rate: 0.00010627905195293134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: -1.3642	Cost: 32.64s
Train Epoch: 241 [40960/90000 (45%)]	Loss: -4.7443	Cost: 9.39s
Train Epoch: 241 [81920/90000 (91%)]	Loss: -4.7345	Cost: 12.40s
Train Epoch: 241 	Average Loss: -4.4772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1656

Learning rate: 0.00010565185344820243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: -1.1685	Cost: 31.19s
Train Epoch: 242 [40960/90000 (45%)]	Loss: -4.5868	Cost: 9.41s
Train Epoch: 242 [81920/90000 (91%)]	Loss: -4.8862	Cost: 12.73s
Train Epoch: 242 	Average Loss: -4.4796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1213

Learning rate: 0.00010502443181797694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: -1.0839	Cost: 31.11s
Train Epoch: 243 [40960/90000 (45%)]	Loss: -4.8130	Cost: 9.41s
Train Epoch: 243 [81920/90000 (91%)]	Loss: -4.8439	Cost: 11.87s
Train Epoch: 243 	Average Loss: -4.4942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0116

Learning rate: 0.00010439681183178646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: -1.0316	Cost: 31.85s
Train Epoch: 244 [40960/90000 (45%)]	Loss: -4.7059	Cost: 9.41s
Train Epoch: 244 [81920/90000 (91%)]	Loss: -4.7304	Cost: 12.33s
Train Epoch: 244 	Average Loss: -4.3772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1721

Learning rate: 0.00010376901826699342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: -1.2279	Cost: 31.92s
Train Epoch: 245 [40960/90000 (45%)]	Loss: -4.6227	Cost: 9.40s
Train Epoch: 245 [81920/90000 (91%)]	Loss: -4.7178	Cost: 12.29s
Train Epoch: 245 	Average Loss: -4.3872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0149

Learning rate: 0.0001031410759078128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: -1.1279	Cost: 31.59s
Train Epoch: 246 [40960/90000 (45%)]	Loss: -4.8253	Cost: 9.41s
Train Epoch: 246 [81920/90000 (91%)]	Loss: -4.9609	Cost: 12.71s
Train Epoch: 246 	Average Loss: -4.5279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0791

Learning rate: 0.00010251300954433372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: -1.3887	Cost: 31.48s
Train Epoch: 247 [40960/90000 (45%)]	Loss: -4.7699	Cost: 9.43s
Train Epoch: 247 [81920/90000 (91%)]	Loss: -4.8782	Cost: 12.39s
Train Epoch: 247 	Average Loss: -4.4515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1250

Learning rate: 0.0001018848439715408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: -1.1751	Cost: 32.09s
Train Epoch: 248 [40960/90000 (45%)]	Loss: -4.7375	Cost: 9.46s
Train Epoch: 248 [81920/90000 (91%)]	Loss: -4.8795	Cost: 12.87s
Train Epoch: 248 	Average Loss: -4.4529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1143

Saving model as e248_model.pt & e248_waveforms_supplementary.hdf5
Learning rate: 0.00010125660398833524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: -1.3565	Cost: 30.54s
Train Epoch: 249 [40960/90000 (45%)]	Loss: -5.0692	Cost: 9.36s
Train Epoch: 249 [81920/90000 (91%)]	Loss: -5.0517	Cost: 12.44s
Train Epoch: 249 	Average Loss: -4.6695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0609

Learning rate: 0.00010062831439655587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: -1.4919	Cost: 31.97s
Train Epoch: 250 [40960/90000 (45%)]	Loss: -5.0055	Cost: 9.39s
Train Epoch: 250 [81920/90000 (91%)]	Loss: -4.8736	Cost: 12.78s
Train Epoch: 250 	Average Loss: -4.6602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0088

Learning rate: 9.999999999999996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: -1.3493	Cost: 31.68s
Train Epoch: 251 [40960/90000 (45%)]	Loss: -4.9683	Cost: 9.34s
Train Epoch: 251 [81920/90000 (91%)]	Loss: -4.8044	Cost: 12.33s
Train Epoch: 251 	Average Loss: -4.6208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1537

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Learning rate: 9.937168560344407e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: -1.4915	Cost: 30.78s
Train Epoch: 252 [40960/90000 (45%)]	Loss: -4.8838	Cost: 9.38s
Train Epoch: 252 [81920/90000 (91%)]	Loss: -4.8806	Cost: 11.57s
Train Epoch: 252 	Average Loss: -4.6827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0809

Learning rate: 9.87433960116647e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: -1.5337	Cost: 32.30s
Train Epoch: 253 [40960/90000 (45%)]	Loss: -5.1339	Cost: 9.37s
Train Epoch: 253 [81920/90000 (91%)]	Loss: -5.0550	Cost: 12.34s
Train Epoch: 253 	Average Loss: -4.7306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0514

Learning rate: 9.811515602845915e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: -1.3596	Cost: 32.45s
Train Epoch: 254 [40960/90000 (45%)]	Loss: -5.2205	Cost: 9.36s
Train Epoch: 254 [81920/90000 (91%)]	Loss: -5.3545	Cost: 12.66s
Train Epoch: 254 	Average Loss: -4.7817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0624

Learning rate: 9.748699045566624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: -1.6161	Cost: 31.30s
Train Epoch: 255 [40960/90000 (45%)]	Loss: -4.8959	Cost: 9.41s
Train Epoch: 255 [81920/90000 (91%)]	Loss: -5.3441	Cost: 11.91s
Train Epoch: 255 	Average Loss: -4.8408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1064

Learning rate: 9.685892409218716e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: -1.3276	Cost: 31.99s
Train Epoch: 256 [40960/90000 (45%)]	Loss: -5.2396	Cost: 9.38s
Train Epoch: 256 [81920/90000 (91%)]	Loss: -4.9317	Cost: 12.21s
Train Epoch: 256 	Average Loss: -4.8351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0157

Learning rate: 9.623098173300653e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: -1.4211	Cost: 31.13s
Train Epoch: 257 [40960/90000 (45%)]	Loss: -5.2154	Cost: 9.39s
Train Epoch: 257 [81920/90000 (91%)]	Loss: -5.2778	Cost: 12.64s
Train Epoch: 257 	Average Loss: -4.8758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0586

Learning rate: 9.560318816821353e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: -1.7876	Cost: 32.13s
Train Epoch: 258 [40960/90000 (45%)]	Loss: -5.2689	Cost: 9.60s
Train Epoch: 258 [81920/90000 (91%)]	Loss: -5.2447	Cost: 12.44s
Train Epoch: 258 	Average Loss: -4.8790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0897

Learning rate: 9.497556818202306e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: -1.5310	Cost: 31.99s
Train Epoch: 259 [40960/90000 (45%)]	Loss: -5.1801	Cost: 9.40s
Train Epoch: 259 [81920/90000 (91%)]	Loss: -5.3083	Cost: 12.10s
Train Epoch: 259 	Average Loss: -4.8777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0184

Learning rate: 9.434814655179755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: -1.4498	Cost: 30.83s
Train Epoch: 260 [40960/90000 (45%)]	Loss: -5.2335	Cost: 9.39s
Train Epoch: 260 [81920/90000 (91%)]	Loss: -5.4655	Cost: 12.80s
Train Epoch: 260 	Average Loss: -4.9171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1902

Saving model as e260_model.pt & e260_waveforms_supplementary.hdf5
Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: -1.5058	Cost: 30.81s
Train Epoch: 261 [40960/90000 (45%)]	Loss: -5.2280	Cost: 9.60s
Train Epoch: 261 [81920/90000 (91%)]	Loss: -5.2427	Cost: 11.54s
Train Epoch: 261 	Average Loss: -4.9381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0354

Learning rate: 9.309399742855944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: -1.8431	Cost: 31.20s
Train Epoch: 262 [40960/90000 (45%)]	Loss: -5.0111	Cost: 9.40s
Train Epoch: 262 [81920/90000 (91%)]	Loss: -5.3249	Cost: 11.74s
Train Epoch: 262 	Average Loss: -4.9314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3729

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 9.246731944720672e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: -1.5575	Cost: 32.39s
Train Epoch: 263 [40960/90000 (45%)]	Loss: -5.3282	Cost: 9.43s
Train Epoch: 263 [81920/90000 (91%)]	Loss: -5.4515	Cost: 12.38s
Train Epoch: 263 	Average Loss: -5.0094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1319

Learning rate: 9.184093884318424e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: -1.5520	Cost: 32.16s
Train Epoch: 264 [40960/90000 (45%)]	Loss: -5.2149	Cost: 9.43s
Train Epoch: 264 [81920/90000 (91%)]	Loss: -5.3905	Cost: 12.04s
Train Epoch: 264 	Average Loss: -5.0332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2336

Learning rate: 9.121488034492569e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: -1.3057	Cost: 31.05s
Train Epoch: 265 [40960/90000 (45%)]	Loss: -5.3231	Cost: 9.38s
Train Epoch: 265 [81920/90000 (91%)]	Loss: -5.4406	Cost: 12.27s
Train Epoch: 265 	Average Loss: -5.0267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1257

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: -1.6451	Cost: 30.77s
Train Epoch: 266 [40960/90000 (45%)]	Loss: -5.3670	Cost: 9.40s
Train Epoch: 266 [81920/90000 (91%)]	Loss: -4.9777	Cost: 11.73s
Train Epoch: 266 	Average Loss: -4.9005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1778

Learning rate: 8.996382851487852e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: -0.8754	Cost: 32.83s
Train Epoch: 267 [40960/90000 (45%)]	Loss: -5.0126	Cost: 9.36s
Train Epoch: 267 [81920/90000 (91%)]	Loss: -5.1128	Cost: 12.28s
Train Epoch: 267 	Average Loss: -4.6668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0100

Learning rate: 8.9338884572474e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: -1.4472	Cost: 32.09s
Train Epoch: 268 [40960/90000 (45%)]	Loss: -5.3941	Cost: 9.42s
Train Epoch: 268 [81920/90000 (91%)]	Loss: -5.5645	Cost: 12.67s
Train Epoch: 268 	Average Loss: -4.9783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1487

Learning rate: 8.871436151265182e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: -1.7383	Cost: 30.47s
Train Epoch: 269 [40960/90000 (45%)]	Loss: -5.3666	Cost: 9.59s
Train Epoch: 269 [81920/90000 (91%)]	Loss: -5.4743	Cost: 12.32s
Train Epoch: 269 	Average Loss: -5.0281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3783

Saving model as e269_model.pt & e269_waveforms_supplementary.hdf5
Learning rate: 8.809028399051304e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: -1.8378	Cost: 31.50s
Train Epoch: 270 [40960/90000 (45%)]	Loss: -5.4860	Cost: 9.40s
Train Epoch: 270 [81920/90000 (91%)]	Loss: -5.4697	Cost: 12.48s
Train Epoch: 270 	Average Loss: -5.1051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5160

Saving model as e270_model.pt & e270_waveforms_supplementary.hdf5
Learning rate: 8.746667664356958e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: -1.5979	Cost: 30.88s
Train Epoch: 271 [40960/90000 (45%)]	Loss: -5.5230	Cost: 9.40s
Train Epoch: 271 [81920/90000 (91%)]	Loss: -5.7343	Cost: 12.14s
Train Epoch: 271 	Average Loss: -5.2062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2771

Learning rate: 8.684356409077174e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: -1.6473	Cost: 32.29s
Train Epoch: 272 [40960/90000 (45%)]	Loss: -5.6008	Cost: 9.35s
Train Epoch: 272 [81920/90000 (91%)]	Loss: -5.6640	Cost: 12.41s
Train Epoch: 272 	Average Loss: -5.2166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2655

Learning rate: 8.622097093153619e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: -1.8626	Cost: 31.11s
Train Epoch: 273 [40960/90000 (45%)]	Loss: -5.6819	Cost: 9.39s
Train Epoch: 273 [81920/90000 (91%)]	Loss: -5.6876	Cost: 11.61s
Train Epoch: 273 	Average Loss: -5.2601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5233

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 8.559892174477476e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: -2.0882	Cost: 31.14s
Train Epoch: 274 [40960/90000 (45%)]	Loss: -5.5507	Cost: 9.42s
Train Epoch: 274 [81920/90000 (91%)]	Loss: -5.6833	Cost: 11.74s
Train Epoch: 274 	Average Loss: -5.2860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3009

Learning rate: 8.497744108792427e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: -1.6868	Cost: 30.61s
Train Epoch: 275 [40960/90000 (45%)]	Loss: -5.6871	Cost: 9.39s
Train Epoch: 275 [81920/90000 (91%)]	Loss: -5.6237	Cost: 12.24s
Train Epoch: 275 	Average Loss: -5.2956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4481

Learning rate: 8.435655349597689e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: -1.6476	Cost: 30.76s
Train Epoch: 276 [40960/90000 (45%)]	Loss: -5.6745	Cost: 9.38s
Train Epoch: 276 [81920/90000 (91%)]	Loss: -5.7915	Cost: 11.91s
Train Epoch: 276 	Average Loss: -5.2870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3719

Learning rate: 8.373628348051162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: -1.7477	Cost: 31.76s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -5.6844	Cost: 9.41s
Train Epoch: 277 [81920/90000 (91%)]	Loss: -5.6309	Cost: 12.47s
Train Epoch: 277 	Average Loss: -5.3249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2966

Learning rate: 8.311665552872659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: -2.0877	Cost: 30.86s
Train Epoch: 278 [40960/90000 (45%)]	Loss: -5.6476	Cost: 9.36s
Train Epoch: 278 [81920/90000 (91%)]	Loss: -5.7581	Cost: 12.62s
Train Epoch: 278 	Average Loss: -5.3719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4972

Learning rate: 8.249769410247239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: -1.9862	Cost: 31.43s
Train Epoch: 279 [40960/90000 (45%)]	Loss: -5.8157	Cost: 9.40s
Train Epoch: 279 [81920/90000 (91%)]	Loss: -5.7610	Cost: 12.91s
Train Epoch: 279 	Average Loss: -5.3940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4745

Learning rate: 8.187942363728625e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: -1.9193	Cost: 31.33s
Train Epoch: 280 [40960/90000 (45%)]	Loss: -5.8931	Cost: 9.57s
Train Epoch: 280 [81920/90000 (91%)]	Loss: -5.9132	Cost: 11.89s
Train Epoch: 280 	Average Loss: -5.4447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2731

Learning rate: 8.126186854142752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: -1.9191	Cost: 31.46s
Train Epoch: 281 [40960/90000 (45%)]	Loss: -5.7567	Cost: 9.40s
Train Epoch: 281 [81920/90000 (91%)]	Loss: -5.8114	Cost: 12.56s
Train Epoch: 281 	Average Loss: -5.4613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4763

Learning rate: 8.064505319491398e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: -2.2664	Cost: 30.73s
Train Epoch: 282 [40960/90000 (45%)]	Loss: -5.7250	Cost: 9.36s
Train Epoch: 282 [81920/90000 (91%)]	Loss: -5.9259	Cost: 11.93s
Train Epoch: 282 	Average Loss: -5.4948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5177

Learning rate: 8.002900194855929e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: -1.9257	Cost: 31.12s
Train Epoch: 283 [40960/90000 (45%)]	Loss: -5.9121	Cost: 9.41s
Train Epoch: 283 [81920/90000 (91%)]	Loss: -5.8567	Cost: 12.34s
Train Epoch: 283 	Average Loss: -5.4991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3772

Learning rate: 7.941373912301183e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: -2.1046	Cost: 31.95s
Train Epoch: 284 [40960/90000 (45%)]	Loss: -5.7961	Cost: 9.39s
Train Epoch: 284 [81920/90000 (91%)]	Loss: -5.7869	Cost: 12.70s
Train Epoch: 284 	Average Loss: -5.4903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4191

Learning rate: 7.879928900779452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: -2.0014	Cost: 30.30s
Train Epoch: 285 [40960/90000 (45%)]	Loss: -5.8713	Cost: 9.41s
Train Epoch: 285 [81920/90000 (91%)]	Loss: -5.6456	Cost: 11.96s
Train Epoch: 285 	Average Loss: -5.3572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1867

Learning rate: 7.818567586034573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: -1.8150	Cost: 32.26s
Train Epoch: 286 [40960/90000 (45%)]	Loss: -5.5919	Cost: 9.37s
Train Epoch: 286 [81920/90000 (91%)]	Loss: -5.9278	Cost: 12.54s
Train Epoch: 286 	Average Loss: -5.3299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4234

Learning rate: 7.757292390506185e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: -1.4959	Cost: 30.64s
Train Epoch: 287 [40960/90000 (45%)]	Loss: -5.8164	Cost: 9.40s
Train Epoch: 287 [81920/90000 (91%)]	Loss: -6.0098	Cost: 11.94s
Train Epoch: 287 	Average Loss: -5.5073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6757

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Learning rate: 7.696105733234094e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: -1.5352	Cost: 31.79s
Train Epoch: 288 [40960/90000 (45%)]	Loss: -6.0223	Cost: 9.39s
Train Epoch: 288 [81920/90000 (91%)]	Loss: -6.2316	Cost: 12.38s
Train Epoch: 288 	Average Loss: -5.5808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5635

Learning rate: 7.635010029762752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: -2.2352	Cost: 31.97s
Train Epoch: 289 [40960/90000 (45%)]	Loss: -5.9866	Cost: 9.42s
Train Epoch: 289 [81920/90000 (91%)]	Loss: -5.8806	Cost: 12.46s
Train Epoch: 289 	Average Loss: -5.6539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6336

Learning rate: 7.574007692045924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: -2.0828	Cost: 30.54s
Train Epoch: 290 [40960/90000 (45%)]	Loss: -5.8986	Cost: 9.39s
Train Epoch: 290 [81920/90000 (91%)]	Loss: -6.0964	Cost: 11.68s
Train Epoch: 290 	Average Loss: -5.5852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5603

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: -2.0079	Cost: 31.48s
Train Epoch: 291 [40960/90000 (45%)]	Loss: -5.8902	Cost: 9.40s
Train Epoch: 291 [81920/90000 (91%)]	Loss: -6.2068	Cost: 12.24s
Train Epoch: 291 	Average Loss: -5.6582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7737

Saving model as e291_model.pt & e291_waveforms_supplementary.hdf5
Learning rate: 7.452292743166178e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: -2.3316	Cost: 31.61s
Train Epoch: 292 [40960/90000 (45%)]	Loss: -6.1044	Cost: 9.42s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -6.2347	Cost: 12.19s
Train Epoch: 292 	Average Loss: -5.7448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6337

Learning rate: 7.391584937101029e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: -2.2390	Cost: 32.52s
Train Epoch: 293 [40960/90000 (45%)]	Loss: -5.9144	Cost: 9.42s
Train Epoch: 293 [81920/90000 (91%)]	Loss: -6.1280	Cost: 12.34s
Train Epoch: 293 	Average Loss: -5.6355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5838

Learning rate: 7.330980106796245e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: -1.9746	Cost: 31.55s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -6.0799	Cost: 9.39s
Train Epoch: 294 [81920/90000 (91%)]	Loss: -6.0058	Cost: 12.50s
Train Epoch: 294 	Average Loss: -5.6138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4621

Learning rate: 7.270480644826745e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: -2.1291	Cost: 31.18s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -6.0277	Cost: 9.42s
Train Epoch: 295 [81920/90000 (91%)]	Loss: -6.1191	Cost: 11.62s
Train Epoch: 295 	Average Loss: -5.6527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6510

Learning rate: 7.210088939607704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: -2.1485	Cost: 31.29s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -6.1785	Cost: 9.41s
Train Epoch: 296 [81920/90000 (91%)]	Loss: -6.2884	Cost: 11.86s
Train Epoch: 296 	Average Loss: -5.7869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6304

Learning rate: 7.149807375300236e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: -2.0469	Cost: 31.03s
Train Epoch: 297 [40960/90000 (45%)]	Loss: -6.2133	Cost: 9.39s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -6.3935	Cost: 12.59s
Train Epoch: 297 	Average Loss: -5.8400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6930

Learning rate: 7.08963833171728e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: -2.0335	Cost: 31.36s
Train Epoch: 298 [40960/90000 (45%)]	Loss: -6.2572	Cost: 9.39s
Train Epoch: 298 [81920/90000 (91%)]	Loss: -6.4474	Cost: 12.25s
Train Epoch: 298 	Average Loss: -5.8561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7989

Saving model as e298_model.pt & e298_waveforms_supplementary.hdf5
Learning rate: 7.029584184229648e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: -2.0803	Cost: 31.22s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -6.2375	Cost: 9.42s
Train Epoch: 299 [81920/90000 (91%)]	Loss: -6.4992	Cost: 12.06s
Train Epoch: 299 	Average Loss: -5.9252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4847

Learning rate: 6.969647303672259e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: -1.9867	Cost: 30.94s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -6.2672	Cost: 9.38s
Train Epoch: 300 [81920/90000 (91%)]	Loss: -6.2540	Cost: 12.13s
Train Epoch: 300 	Average Loss: -5.9444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7694

Learning rate: 6.909830056250523e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: -2.2159	Cost: 30.79s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -6.3393	Cost: 9.41s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -6.4429	Cost: 11.56s
Train Epoch: 301 	Average Loss: -5.9444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7806

Learning rate: 6.850134803446949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: -2.1712	Cost: 31.58s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -6.4620	Cost: 9.38s
Train Epoch: 302 [81920/90000 (91%)]	Loss: -6.5273	Cost: 12.19s
Train Epoch: 302 	Average Loss: -6.0142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8421

Saving model as e302_model.pt & e302_waveforms_supplementary.hdf5
Learning rate: 6.790563901927903e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: -2.4259	Cost: 31.33s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -6.1962	Cost: 9.40s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -6.3208	Cost: 12.85s
Train Epoch: 303 	Average Loss: -5.9540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6032

Learning rate: 6.731119703450573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: -2.0765	Cost: 30.46s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -6.2766	Cost: 9.40s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -6.3897	Cost: 12.27s
Train Epoch: 304 	Average Loss: -5.9362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8843

Saving model as e304_model.pt & e304_waveforms_supplementary.hdf5
Learning rate: 6.67180455477013e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: -2.2666	Cost: 31.49s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -6.2707	Cost: 9.39s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -6.6652	Cost: 11.63s
Train Epoch: 305 	Average Loss: -6.0334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9321

Saving model as e305_model.pt & e305_waveforms_supplementary.hdf5
Learning rate: 6.612620797547083e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: -2.3308	Cost: 31.05s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -6.4241	Cost: 9.38s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -6.5015	Cost: 12.63s
Train Epoch: 306 	Average Loss: -6.0392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8166

Learning rate: 6.553570768254825e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: -2.3944	Cost: 31.22s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -6.4201	Cost: 9.39s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -6.6597	Cost: 12.58s
Train Epoch: 307 	Average Loss: -6.0773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9034

Learning rate: 6.494656798087406e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: -2.4844	Cost: 31.54s
Train Epoch: 308 [40960/90000 (45%)]	Loss: -6.5030	Cost: 9.52s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -6.6094	Cost: 12.38s
Train Epoch: 308 	Average Loss: -6.1285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8428

Learning rate: 6.435881212867491e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: -2.2579	Cost: 31.37s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -6.3149	Cost: 9.42s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -6.1734	Cost: 12.64s
Train Epoch: 309 	Average Loss: -5.9837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7608

Learning rate: 6.377246332954541e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: -2.2975	Cost: 31.73s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -6.4262	Cost: 9.59s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -6.4898	Cost: 12.16s
Train Epoch: 310 	Average Loss: -5.9377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7490

Learning rate: 6.318754473153218e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: -2.5332	Cost: 32.27s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -6.4702	Cost: 9.40s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -6.3514	Cost: 12.10s
Train Epoch: 311 	Average Loss: -6.0394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8075

Learning rate: 6.260407942621994e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: -2.2110	Cost: 30.98s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -6.5518	Cost: 9.44s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -6.5720	Cost: 11.62s
Train Epoch: 312 	Average Loss: -6.1684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7502

Learning rate: 6.202209044781987e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: -2.4208	Cost: 31.06s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -6.4013	Cost: 9.42s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -6.5939	Cost: 11.74s
Train Epoch: 313 	Average Loss: -6.1263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8732

Learning rate: 6.144160077226032e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: -2.3947	Cost: 31.19s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -6.6603	Cost: 9.44s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -6.7663	Cost: 12.16s
Train Epoch: 314 	Average Loss: -6.1617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8020

Learning rate: 6.0862633316279744e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: -2.3077	Cost: 32.69s
Train Epoch: 315 [40960/90000 (45%)]	Loss: -6.7222	Cost: 9.36s
Train Epoch: 315 [81920/90000 (91%)]	Loss: -6.6395	Cost: 12.99s
Train Epoch: 315 	Average Loss: -6.2797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9797

Saving model as e315_model.pt & e315_waveforms_supplementary.hdf5
Learning rate: 6.028521093652189e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: -2.7858	Cost: 31.99s
Train Epoch: 316 [40960/90000 (45%)]	Loss: -6.6522	Cost: 9.40s
Train Epoch: 316 [81920/90000 (91%)]	Loss: -6.6519	Cost: 12.44s
Train Epoch: 316 	Average Loss: -6.2742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9912

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 5.970935642863369e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: -2.3108	Cost: 31.48s
Train Epoch: 317 [40960/90000 (45%)]	Loss: -6.6623	Cost: 9.40s
Train Epoch: 317 [81920/90000 (91%)]	Loss: -6.8553	Cost: 12.20s
Train Epoch: 317 	Average Loss: -6.2092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9400

Learning rate: 5.9135092526365064e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: -2.6184	Cost: 32.10s
Train Epoch: 318 [40960/90000 (45%)]	Loss: -6.5602	Cost: 9.38s
Train Epoch: 318 [81920/90000 (91%)]	Loss: -6.8073	Cost: 12.17s
Train Epoch: 318 	Average Loss: -6.3509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9234

Learning rate: 5.8562441900671545e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: -2.6455	Cost: 32.12s
Train Epoch: 319 [40960/90000 (45%)]	Loss: -6.7907	Cost: 9.40s
Train Epoch: 319 [81920/90000 (91%)]	Loss: -7.0980	Cost: 12.35s
Train Epoch: 319 	Average Loss: -6.4434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9999

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Learning rate: 5.799142715881933e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: -2.3829	Cost: 31.20s
Train Epoch: 320 [40960/90000 (45%)]	Loss: -6.6713	Cost: 9.40s
Train Epoch: 320 [81920/90000 (91%)]	Loss: -6.8695	Cost: 12.51s
Train Epoch: 320 	Average Loss: -6.3877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0173

Saving model as e320_model.pt & e320_waveforms_supplementary.hdf5
Learning rate: 5.742207084349269e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: -2.4801	Cost: 30.76s
Train Epoch: 321 [40960/90000 (45%)]	Loss: -6.8790	Cost: 10.00s
Train Epoch: 321 [81920/90000 (91%)]	Loss: -6.8623	Cost: 11.80s
Train Epoch: 321 	Average Loss: -6.4382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0940

Saving model as e321_model.pt & e321_waveforms_supplementary.hdf5
Learning rate: 5.68543954319041e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: -2.5399	Cost: 32.84s
Train Epoch: 322 [40960/90000 (45%)]	Loss: -6.8528	Cost: 9.51s
Train Epoch: 322 [81920/90000 (91%)]	Loss: -6.8612	Cost: 12.35s
Train Epoch: 322 	Average Loss: -6.4262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0738

Learning rate: 5.62884233349067e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: -2.8389	Cost: 31.52s
Train Epoch: 323 [40960/90000 (45%)]	Loss: -6.7226	Cost: 9.52s
Train Epoch: 323 [81920/90000 (91%)]	Loss: -7.1905	Cost: 11.92s
Train Epoch: 323 	Average Loss: -6.4706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0580

Learning rate: 5.572417689610984e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: -2.8813	Cost: 31.03s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -6.8635	Cost: 9.40s
Train Epoch: 324 [81920/90000 (91%)]	Loss: -7.0984	Cost: 11.84s
Train Epoch: 324 	Average Loss: -6.5780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1701

Saving model as e324_model.pt & e324_waveforms_supplementary.hdf5
Learning rate: 5.516167839099677e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: -2.2875	Cost: 31.05s
Train Epoch: 325 [40960/90000 (45%)]	Loss: -7.0652	Cost: 9.40s
Train Epoch: 325 [81920/90000 (91%)]	Loss: -6.9118	Cost: 11.98s
Train Epoch: 325 	Average Loss: -6.5324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9781

Learning rate: 5.46009500260453e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: -2.8608	Cost: 32.34s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -7.0501	Cost: 9.40s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -6.9707	Cost: 11.93s
Train Epoch: 326 	Average Loss: -6.5110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0417

Learning rate: 5.4042013937851194e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: -2.7259	Cost: 30.36s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -7.0754	Cost: 9.39s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -7.1322	Cost: 12.29s
Train Epoch: 327 	Average Loss: -6.6143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2159

Saving model as e327_model.pt & e327_waveforms_supplementary.hdf5
Learning rate: 5.3484892192254136e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: -2.9904	Cost: 32.14s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -7.0332	Cost: 9.44s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -7.0071	Cost: 12.51s
Train Epoch: 328 	Average Loss: -6.6198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9604

Learning rate: 5.292960678346675e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: -2.6154	Cost: 31.35s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -6.9771	Cost: 9.41s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -7.0578	Cost: 12.87s
Train Epoch: 329 	Average Loss: -6.5316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1548

Learning rate: 5.237617963320605e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: -2.6919	Cost: 32.00s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -6.9935	Cost: 9.43s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -7.1029	Cost: 12.45s
Train Epoch: 330 	Average Loss: -6.5848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1491

Learning rate: 5.182463258982848e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: -2.8956	Cost: 31.43s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -6.9749	Cost: 9.42s
Train Epoch: 331 [81920/90000 (91%)]	Loss: -7.1941	Cost: 12.55s
Train Epoch: 331 	Average Loss: -6.6417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1126

Learning rate: 5.127498742746677e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: -2.6325	Cost: 31.87s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -6.8848	Cost: 9.39s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -7.2450	Cost: 12.47s
Train Epoch: 332 	Average Loss: -6.6816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1445

Learning rate: 5.07272658451708e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: -2.9707	Cost: 31.01s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -6.9769	Cost: 9.39s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -7.2340	Cost: 12.10s
Train Epoch: 333 	Average Loss: -6.6921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1585

Learning rate: 5.01814894660509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: -2.6949	Cost: 31.32s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -7.0203	Cost: 9.36s
Train Epoch: 334 [81920/90000 (91%)]	Loss: -7.1771	Cost: 12.80s
Train Epoch: 334 	Average Loss: -6.6606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1541

Learning rate: 4.96376798364239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: -2.5698	Cost: 31.60s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -7.2171	Cost: 9.39s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -7.3409	Cost: 12.13s
Train Epoch: 335 	Average Loss: -6.7323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0852

Learning rate: 4.9095858424962844e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: -2.6671	Cost: 30.94s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -7.1558	Cost: 10.06s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -7.1991	Cost: 11.41s
Train Epoch: 336 	Average Loss: -6.7602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3165

Saving model as e336_model.pt & e336_waveforms_supplementary.hdf5
Learning rate: 4.855604662184932e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: -3.0936	Cost: 30.72s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -7.2579	Cost: 9.40s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -7.2635	Cost: 12.69s
Train Epoch: 337 	Average Loss: -6.8098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1994

Learning rate: 4.801826573792905e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: -2.6137	Cost: 31.41s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -7.0395	Cost: 9.40s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -7.4246	Cost: 12.42s
Train Epoch: 338 	Average Loss: -6.7801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3166

Saving model as e338_model.pt & e338_waveforms_supplementary.hdf5
Learning rate: 4.748253700387039e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: -2.4418	Cost: 30.48s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -7.1680	Cost: 9.41s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -7.3153	Cost: 12.54s
Train Epoch: 339 	Average Loss: -6.7942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3903

Saving model as e339_model.pt & e339_waveforms_supplementary.hdf5
Learning rate: 4.694888156932659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: -2.6875	Cost: 31.52s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -7.1319	Cost: 9.38s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -7.0845	Cost: 12.36s
Train Epoch: 340 	Average Loss: -6.7813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2685

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: -2.9495	Cost: 31.52s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -7.3856	Cost: 9.40s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -7.3414	Cost: 11.79s
Train Epoch: 341 	Average Loss: -6.8021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3617

Learning rate: 4.5887874787312395e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: -2.7957	Cost: 30.81s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -7.1863	Cost: 9.42s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -7.3997	Cost: 12.23s
Train Epoch: 342 	Average Loss: -6.8393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2723

Learning rate: 4.536056532657307e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: -2.7987	Cost: 30.99s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -7.3060	Cost: 9.41s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -7.4006	Cost: 12.26s
Train Epoch: 343 	Average Loss: -6.8606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2744

Learning rate: 4.4835412937156955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: -2.6041	Cost: 30.81s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -7.3225	Cost: 9.41s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -7.4642	Cost: 11.62s
Train Epoch: 344 	Average Loss: -6.8690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2406

Learning rate: 4.431243835118117e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: -2.9724	Cost: 31.60s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -7.2594	Cost: 9.41s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -7.3577	Cost: 12.57s
Train Epoch: 345 	Average Loss: -6.8978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1824

Learning rate: 4.379166221478691e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: -2.7134	Cost: 31.58s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -7.2952	Cost: 9.38s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -7.4385	Cost: 11.95s
Train Epoch: 346 	Average Loss: -6.9155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3697

Learning rate: 4.327310508732435e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: -2.7454	Cost: 32.09s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -7.4388	Cost: 9.41s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -7.4383	Cost: 12.50s
Train Epoch: 347 	Average Loss: -6.9637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2858

Learning rate: 4.275678744054088e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: -3.2329	Cost: 31.31s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -7.4573	Cost: 9.40s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -7.4372	Cost: 11.64s
Train Epoch: 348 	Average Loss: -6.9996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4249

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Learning rate: 4.224272965777324e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: -2.5988	Cost: 31.25s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -7.3896	Cost: 9.40s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -7.4157	Cost: 12.44s
Train Epoch: 349 	Average Loss: -7.0531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3922

Learning rate: 4.173095203314239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: -3.2908	Cost: 31.24s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -7.4719	Cost: 9.39s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -7.4687	Cost: 12.71s
Train Epoch: 350 	Average Loss: -7.0704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3956

Learning rate: 4.1221474770752684e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: -2.6297	Cost: 30.60s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -7.5532	Cost: 9.40s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -7.5889	Cost: 11.79s
Train Epoch: 351 	Average Loss: -7.0862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5821

Saving model as e351_model.pt & e351_waveforms_supplementary.hdf5
Learning rate: 4.071431798389406e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: -3.1668	Cost: 31.80s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -7.4816	Cost: 9.38s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -7.5967	Cost: 12.15s
Train Epoch: 352 	Average Loss: -7.1306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4624

Learning rate: 4.020950169424814e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: -3.2545	Cost: 31.95s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -7.4043	Cost: 9.40s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -7.6256	Cost: 12.39s
Train Epoch: 353 	Average Loss: -7.1384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3167

Learning rate: 3.970704583109751e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: -2.8688	Cost: 30.84s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -7.5285	Cost: 9.41s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -7.7586	Cost: 12.75s
Train Epoch: 354 	Average Loss: -7.1413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3706

Learning rate: 3.920697023053944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: -3.0858	Cost: 31.77s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -7.4342	Cost: 9.39s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -7.5799	Cost: 11.71s
Train Epoch: 355 	Average Loss: -7.1071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4669

Learning rate: 3.870929463470237e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: -2.7244	Cost: 31.21s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -7.3330	Cost: 9.36s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -7.7977	Cost: 12.72s
Train Epoch: 356 	Average Loss: -7.1562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4993

Learning rate: 3.821403869096654e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: -3.0984	Cost: 31.11s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -7.5582	Cost: 9.40s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -7.8698	Cost: 11.80s
Train Epoch: 357 	Average Loss: -7.2678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3849

Learning rate: 3.772122195118876e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: -3.4888	Cost: 31.09s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -7.7768	Cost: 9.39s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -7.6955	Cost: 12.14s
Train Epoch: 358 	Average Loss: -7.2359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4499

Learning rate: 3.723086387092996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: -3.1281	Cost: 32.03s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -7.6158	Cost: 9.40s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -7.8708	Cost: 12.39s
Train Epoch: 359 	Average Loss: -7.2415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4240

Learning rate: 3.674298380868755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: -3.0043	Cost: 31.24s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -7.6536	Cost: 9.37s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -7.9744	Cost: 12.29s
Train Epoch: 360 	Average Loss: -7.3017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4782

Learning rate: 3.6257601025131026e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: -3.4217	Cost: 31.02s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -7.5710	Cost: 9.38s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -7.7170	Cost: 11.69s
Train Epoch: 361 	Average Loss: -7.3127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6314

Saving model as e361_model.pt & e361_waveforms_supplementary.hdf5
Learning rate: 3.5774734682341595e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: -3.1348	Cost: 31.54s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -7.6756	Cost: 9.39s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -7.9880	Cost: 12.03s
Train Epoch: 362 	Average Loss: -7.3328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6719

Saving model as e362_model.pt & e362_waveforms_supplementary.hdf5
Learning rate: 3.529440384305556e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: -3.2766	Cost: 32.38s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -7.8592	Cost: 9.37s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -7.9921	Cost: 12.53s
Train Epoch: 363 	Average Loss: -7.3779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8849

Saving model as e363_model.pt & e363_waveforms_supplementary.hdf5
Learning rate: 3.481662746991211e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: -3.0037	Cost: 31.66s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -7.7380	Cost: 9.41s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -7.9155	Cost: 12.11s
Train Epoch: 364 	Average Loss: -7.3739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6029

Learning rate: 3.434142442470437e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: -2.8600	Cost: 31.69s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -7.8670	Cost: 9.38s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -7.8483	Cost: 12.22s
Train Epoch: 365 	Average Loss: -7.3453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5985

Learning rate: 3.3868813467634793e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: -3.0488	Cost: 30.48s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -7.8816	Cost: 9.40s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -7.9271	Cost: 11.87s
Train Epoch: 366 	Average Loss: -7.4145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5807

Learning rate: 3.339881325657484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: -3.1664	Cost: 31.36s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -7.9451	Cost: 9.64s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -7.9150	Cost: 11.91s
Train Epoch: 367 	Average Loss: -7.4548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5445

Learning rate: 3.2931442346328e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: -3.3932	Cost: 31.98s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -7.8509	Cost: 9.40s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -7.7312	Cost: 12.59s
Train Epoch: 368 	Average Loss: -7.4104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4961

Learning rate: 3.246671918789755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: -2.7641	Cost: 32.49s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -7.6705	Cost: 9.36s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -7.8785	Cost: 11.78s
Train Epoch: 369 	Average Loss: -7.2353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5308

Learning rate: 3.200466212775808e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: -3.2701	Cost: 32.74s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -7.7284	Cost: 9.39s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -8.0231	Cost: 12.57s
Train Epoch: 370 	Average Loss: -7.4156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6696

Learning rate: 3.1545289407131164e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: -3.0569	Cost: 32.22s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -7.9226	Cost: 9.38s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -8.1545	Cost: 12.41s
Train Epoch: 371 	Average Loss: -7.4546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6156

Learning rate: 3.1088619161265144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: -3.1344	Cost: 31.16s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -7.8603	Cost: 9.41s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -7.9466	Cost: 12.94s
Train Epoch: 372 	Average Loss: -7.4959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5826

Learning rate: 3.0634669418719525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: -2.7327	Cost: 31.12s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -7.8307	Cost: 9.41s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -8.1289	Cost: 11.77s
Train Epoch: 373 	Average Loss: -7.5427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7289

Learning rate: 3.0183458100652757e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: -3.3756	Cost: 32.18s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -8.1705	Cost: 9.37s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -8.1874	Cost: 11.90s
Train Epoch: 374 	Average Loss: -7.5749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8651

Learning rate: 2.9735003020115068e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: -3.3809	Cost: 30.91s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -8.0194	Cost: 9.40s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -8.1920	Cost: 12.23s
Train Epoch: 375 	Average Loss: -7.5762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7891

Learning rate: 2.928932188134526e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: -2.8034	Cost: 30.56s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -8.2075	Cost: 9.61s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -8.1136	Cost: 11.64s
Train Epoch: 376 	Average Loss: -7.5931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6784

Learning rate: 2.8846432279071474e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: -3.1660	Cost: 31.94s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -8.1620	Cost: 9.41s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -8.2363	Cost: 12.31s
Train Epoch: 377 	Average Loss: -7.6341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9956

Saving model as e377_model.pt & e377_waveforms_supplementary.hdf5
Learning rate: 2.8406351697816885e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: -3.2394	Cost: 30.54s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -7.9963	Cost: 9.39s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -8.1160	Cost: 11.76s
Train Epoch: 378 	Average Loss: -7.6454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7510

Learning rate: 2.796909751120931e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: -3.5032	Cost: 31.23s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -8.0557	Cost: 9.40s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -8.1359	Cost: 12.18s
Train Epoch: 379 	Average Loss: -7.6665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7795

Learning rate: 2.7534686981295358e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: -3.2147	Cost: 31.43s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -8.1746	Cost: 9.40s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -8.1488	Cost: 12.12s
Train Epoch: 380 	Average Loss: -7.6689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7037

Learning rate: 2.7103137257858838e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: -3.7431	Cost: 30.78s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -8.1836	Cost: 9.38s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -8.2627	Cost: 12.71s
Train Epoch: 381 	Average Loss: -7.7769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7868

Learning rate: 2.667446537774402e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: -3.5524	Cost: 30.49s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -8.1658	Cost: 9.57s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -8.4126	Cost: 12.64s
Train Epoch: 382 	Average Loss: -7.7698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8195

Learning rate: 2.6248688264182623e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: -3.7976	Cost: 31.49s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -8.2991	Cost: 9.41s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -8.3570	Cost: 11.68s
Train Epoch: 383 	Average Loss: -7.7914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7236

Learning rate: 2.5825822726126095e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: -3.5365	Cost: 32.26s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -8.2599	Cost: 9.42s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -8.1963	Cost: 12.39s
Train Epoch: 384 	Average Loss: -7.7434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7310

Learning rate: 2.5405885457581793e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: -3.4159	Cost: 31.65s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -8.0374	Cost: 9.41s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -8.2624	Cost: 12.56s
Train Epoch: 385 	Average Loss: -7.7701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7267

Learning rate: 2.4988893036954043e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: -3.6171	Cost: 32.22s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -8.3921	Cost: 9.43s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -8.2926	Cost: 12.66s
Train Epoch: 386 	Average Loss: -7.7577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7357

Learning rate: 2.4574861926389615e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: -3.6644	Cost: 31.24s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -8.1150	Cost: 9.43s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -8.3793	Cost: 12.73s
Train Epoch: 387 	Average Loss: -7.7966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9262

Learning rate: 2.4163808471127812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: -3.6058	Cost: 30.88s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -8.4601	Cost: 9.42s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -8.4920	Cost: 12.21s
Train Epoch: 388 	Average Loss: -7.8495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9076

Learning rate: 2.3755748898855234e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: -3.5421	Cost: 31.52s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -8.2427	Cost: 9.40s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -8.4744	Cost: 12.17s
Train Epoch: 389 	Average Loss: -7.8452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9872

Learning rate: 2.3350699319065006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: -3.6444	Cost: 30.70s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -8.3531	Cost: 9.41s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -8.4501	Cost: 12.96s
Train Epoch: 390 	Average Loss: -7.8470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9909

Learning rate: 2.2948675722421086e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: -3.2577	Cost: 32.21s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -8.3457	Cost: 9.41s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -8.2746	Cost: 12.78s
Train Epoch: 391 	Average Loss: -7.8960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9321

Learning rate: 2.2549693980126627e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: -3.3507	Cost: 32.33s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -8.3785	Cost: 9.39s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -8.3345	Cost: 12.32s
Train Epoch: 392 	Average Loss: -7.8954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8186

Learning rate: 2.2153769843297664e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: -3.5454	Cost: 31.28s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -8.4846	Cost: 9.43s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -8.6120	Cost: 12.37s
Train Epoch: 393 	Average Loss: -7.9348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8035

Learning rate: 2.1760918942341185e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: -2.8994	Cost: 31.43s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -8.3187	Cost: 9.43s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -8.5609	Cost: 11.93s
Train Epoch: 394 	Average Loss: -7.9267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9104

Learning rate: 2.1371156786338137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: -3.2694	Cost: 31.01s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -8.4013	Cost: 9.41s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -8.5085	Cost: 12.95s
Train Epoch: 395 	Average Loss: -7.9722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0803

Saving model as e395_model.pt & e395_waveforms_supplementary.hdf5
Learning rate: 2.0984498762430954e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: -3.6415	Cost: 31.93s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -8.1615	Cost: 9.36s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -8.6783	Cost: 12.48s
Train Epoch: 396 	Average Loss: -7.9718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0191

Learning rate: 2.060096013521646e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: -3.5173	Cost: 30.85s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -8.4870	Cost: 9.44s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -8.7628	Cost: 12.46s
Train Epoch: 397 	Average Loss: -8.0434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8012

Learning rate: 2.022055604614291e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: -3.7794	Cost: 31.99s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -8.4536	Cost: 9.40s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -8.7692	Cost: 12.49s
Train Epoch: 398 	Average Loss: -8.0455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9627

Learning rate: 1.9843301512912324e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: -3.5471	Cost: 31.27s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -8.5035	Cost: 9.61s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -8.5100	Cost: 11.78s
Train Epoch: 399 	Average Loss: -8.0437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8766

Learning rate: 1.9469211428887808e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: -3.3928	Cost: 31.33s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -8.7220	Cost: 9.62s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -8.6632	Cost: 11.77s
Train Epoch: 400 	Average Loss: -8.0602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9243

Learning rate: 1.9098300562505263e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: -3.3482	Cost: 31.10s
Train Epoch: 401 [40960/90000 (45%)]	Loss: -8.6682	Cost: 9.57s
Train Epoch: 401 [81920/90000 (91%)]	Loss: -8.7815	Cost: 11.39s
Train Epoch: 401 	Average Loss: -8.0947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0228

Learning rate: 1.8730583556690602e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: -3.5741	Cost: 32.18s
Train Epoch: 402 [40960/90000 (45%)]	Loss: -8.3934	Cost: 10.03s
Train Epoch: 402 [81920/90000 (91%)]	Loss: -8.4990	Cost: 11.99s
Train Epoch: 402 	Average Loss: -8.0975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9717

Learning rate: 1.8366074928281604e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: -3.2606	Cost: 31.41s
Train Epoch: 403 [40960/90000 (45%)]	Loss: -8.4833	Cost: 10.08s
Train Epoch: 403 [81920/90000 (91%)]	Loss: -8.7109	Cost: 12.09s
Train Epoch: 403 	Average Loss: -8.0212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9904

Learning rate: 1.8004789067454784e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: -3.4353	Cost: 32.16s
Train Epoch: 404 [40960/90000 (45%)]	Loss: -8.5048	Cost: 9.42s
Train Epoch: 404 [81920/90000 (91%)]	Loss: -8.6593	Cost: 12.29s
Train Epoch: 404 	Average Loss: -8.0466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8128

Learning rate: 1.7646740237157253e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: -3.5095	Cost: 32.20s
Train Epoch: 405 [40960/90000 (45%)]	Loss: -8.6038	Cost: 9.41s
Train Epoch: 405 [81920/90000 (91%)]	Loss: -8.6477	Cost: 11.90s
Train Epoch: 405 	Average Loss: -8.0819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0039

Learning rate: 1.7291942572543828e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: -3.8815	Cost: 30.72s
Train Epoch: 406 [40960/90000 (45%)]	Loss: -8.6022	Cost: 9.39s
Train Epoch: 406 [81920/90000 (91%)]	Loss: -8.8135	Cost: 11.62s
Train Epoch: 406 	Average Loss: -8.1731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1400

Saving model as e406_model.pt & e406_waveforms_supplementary.hdf5
Learning rate: 1.6940410080418743e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: -3.4157	Cost: 31.17s
Train Epoch: 407 [40960/90000 (45%)]	Loss: -8.5158	Cost: 9.41s
Train Epoch: 407 [81920/90000 (91%)]	Loss: -8.8043	Cost: 11.82s
Train Epoch: 407 	Average Loss: -8.1213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9461

Learning rate: 1.6592156638682862e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: -3.4332	Cost: 31.32s
Train Epoch: 408 [40960/90000 (45%)]	Loss: -8.5367	Cost: 9.42s
Train Epoch: 408 [81920/90000 (91%)]	Loss: -8.8648	Cost: 11.79s
Train Epoch: 408 	Average Loss: -8.1657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9723

Learning rate: 1.6247195995785833e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: -3.6594	Cost: 31.57s
Train Epoch: 409 [40960/90000 (45%)]	Loss: -8.6942	Cost: 9.41s
Train Epoch: 409 [81920/90000 (91%)]	Loss: -8.9146	Cost: 12.13s
Train Epoch: 409 	Average Loss: -8.1920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1849

Saving model as e409_model.pt & e409_waveforms_supplementary.hdf5
Learning rate: 1.5905541770183092e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: -3.3388	Cost: 30.99s
Train Epoch: 410 [40960/90000 (45%)]	Loss: -8.5323	Cost: 9.62s
Train Epoch: 410 [81920/90000 (91%)]	Loss: -8.8589	Cost: 11.71s
Train Epoch: 410 	Average Loss: -8.1994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0875

Learning rate: 1.5567207449798488e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: -3.5418	Cost: 31.55s
Train Epoch: 411 [40960/90000 (45%)]	Loss: -8.5574	Cost: 9.40s
Train Epoch: 411 [81920/90000 (91%)]	Loss: -8.7200	Cost: 11.73s
Train Epoch: 411 	Average Loss: -8.2544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9754

Learning rate: 1.5232206391491672e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: -3.3433	Cost: 30.87s
Train Epoch: 412 [40960/90000 (45%)]	Loss: -8.9168	Cost: 9.63s
Train Epoch: 412 [81920/90000 (91%)]	Loss: -8.7017	Cost: 11.76s
Train Epoch: 412 	Average Loss: -8.2032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1213

Learning rate: 1.4900551820530823e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: -3.5640	Cost: 32.48s
Train Epoch: 413 [40960/90000 (45%)]	Loss: -8.6945	Cost: 9.38s
Train Epoch: 413 [81920/90000 (91%)]	Loss: -8.8556	Cost: 12.25s
Train Epoch: 413 	Average Loss: -8.2435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8704

Learning rate: 1.457225683007047e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: -3.6051	Cost: 31.85s
Train Epoch: 414 [40960/90000 (45%)]	Loss: -8.6401	Cost: 9.41s
Train Epoch: 414 [81920/90000 (91%)]	Loss: -8.9283	Cost: 11.75s
Train Epoch: 414 	Average Loss: -8.2337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2199

Saving model as e414_model.pt & e414_waveforms_supplementary.hdf5
Learning rate: 1.4247334380634787e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: -3.5903	Cost: 31.28s
Train Epoch: 415 [40960/90000 (45%)]	Loss: -8.6259	Cost: 9.42s
Train Epoch: 415 [81920/90000 (91%)]	Loss: -8.7217	Cost: 11.80s
Train Epoch: 415 	Average Loss: -8.2600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1885

Learning rate: 1.3925797299605641e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: -3.6120	Cost: 30.75s
Train Epoch: 416 [40960/90000 (45%)]	Loss: -8.7499	Cost: 9.41s
Train Epoch: 416 [81920/90000 (91%)]	Loss: -8.7958	Cost: 11.61s
Train Epoch: 416 	Average Loss: -8.2940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1377

Learning rate: 1.3607658280716445e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: -3.4260	Cost: 31.79s
Train Epoch: 417 [40960/90000 (45%)]	Loss: -8.7455	Cost: 9.40s
Train Epoch: 417 [81920/90000 (91%)]	Loss: -8.9398	Cost: 12.79s
Train Epoch: 417 	Average Loss: -8.2958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2215

Saving model as e417_model.pt & e417_waveforms_supplementary.hdf5
Learning rate: 1.3292929883550993e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: -3.7589	Cost: 31.03s
Train Epoch: 418 [40960/90000 (45%)]	Loss: -8.8351	Cost: 9.40s
Train Epoch: 418 [81920/90000 (91%)]	Loss: -9.0967	Cost: 12.70s
Train Epoch: 418 	Average Loss: -8.3369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1770

Learning rate: 1.2981624533047427e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: -3.4145	Cost: 31.45s
Train Epoch: 419 [40960/90000 (45%)]	Loss: -8.7837	Cost: 9.41s
Train Epoch: 419 [81920/90000 (91%)]	Loss: -8.9855	Cost: 11.84s
Train Epoch: 419 	Average Loss: -8.2976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1678

Learning rate: 1.2673754519007981e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: -3.9839	Cost: 31.89s
Train Epoch: 420 [40960/90000 (45%)]	Loss: -8.7657	Cost: 9.37s
Train Epoch: 420 [81920/90000 (91%)]	Loss: -9.2262	Cost: 12.12s
Train Epoch: 420 	Average Loss: -8.3893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2041

Learning rate: 1.2369331995613638e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: -3.6366	Cost: 32.63s
Train Epoch: 421 [40960/90000 (45%)]	Loss: -9.0141	Cost: 9.42s
Train Epoch: 421 [81920/90000 (91%)]	Loss: -9.0753	Cost: 12.69s
Train Epoch: 421 	Average Loss: -8.3790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2065

Learning rate: 1.2068368980944384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: -3.3280	Cost: 31.25s
Train Epoch: 422 [40960/90000 (45%)]	Loss: -8.7337	Cost: 9.63s
Train Epoch: 422 [81920/90000 (91%)]	Loss: -8.9549	Cost: 12.21s
Train Epoch: 422 	Average Loss: -8.3384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1637

Learning rate: 1.1770877356504656e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: -3.7795	Cost: 31.56s
Train Epoch: 423 [40960/90000 (45%)]	Loss: -8.5956	Cost: 9.59s
Train Epoch: 423 [81920/90000 (91%)]	Loss: -9.0695	Cost: 12.59s
Train Epoch: 423 	Average Loss: -8.3760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1432

Learning rate: 1.1476868866754482e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: -3.8091	Cost: 30.92s
Train Epoch: 424 [40960/90000 (45%)]	Loss: -8.7652	Cost: 9.43s
Train Epoch: 424 [81920/90000 (91%)]	Loss: -9.0650	Cost: 11.97s
Train Epoch: 424 	Average Loss: -8.4075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2299

Saving model as e424_model.pt & e424_waveforms_supplementary.hdf5
Learning rate: 1.1186355118645549e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: -3.5854	Cost: 31.05s
Train Epoch: 425 [40960/90000 (45%)]	Loss: -8.8056	Cost: 9.42s
Train Epoch: 425 [81920/90000 (91%)]	Loss: -9.0556	Cost: 11.48s
Train Epoch: 425 	Average Loss: -8.3888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2297

Learning rate: 1.0899347581163218e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: -3.7898	Cost: 32.50s
Train Epoch: 426 [40960/90000 (45%)]	Loss: -8.9761	Cost: 9.39s
Train Epoch: 426 [81920/90000 (91%)]	Loss: -9.1140	Cost: 12.52s
Train Epoch: 426 	Average Loss: -8.4381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0799

Learning rate: 1.061585758487362e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: -3.7854	Cost: 30.48s
Train Epoch: 427 [40960/90000 (45%)]	Loss: -8.9262	Cost: 9.40s
Train Epoch: 427 [81920/90000 (91%)]	Loss: -9.1565	Cost: 11.67s
Train Epoch: 427 	Average Loss: -8.4367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0802

Learning rate: 1.033589632147641e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: -3.7091	Cost: 31.07s
Train Epoch: 428 [40960/90000 (45%)]	Loss: -8.9100	Cost: 9.63s
Train Epoch: 428 [81920/90000 (91%)]	Loss: -9.0827	Cost: 12.58s
Train Epoch: 428 	Average Loss: -8.4168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3444

Saving model as e428_model.pt & e428_waveforms_supplementary.hdf5
Learning rate: 1.005947484336289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: -3.6644	Cost: 31.29s
Train Epoch: 429 [40960/90000 (45%)]	Loss: -8.8415	Cost: 9.43s
Train Epoch: 429 [81920/90000 (91%)]	Loss: -9.1289	Cost: 12.82s
Train Epoch: 429 	Average Loss: -8.3867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2959

Learning rate: 9.786604063179713e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: -4.0225	Cost: 32.88s
Train Epoch: 430 [40960/90000 (45%)]	Loss: -8.8226	Cost: 9.39s
Train Epoch: 430 [81920/90000 (91%)]	Loss: -9.0677	Cost: 12.34s
Train Epoch: 430 	Average Loss: -8.4544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1576

Learning rate: 9.517294753398061e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: -3.7211	Cost: 31.89s
Train Epoch: 431 [40960/90000 (45%)]	Loss: -9.0091	Cost: 9.42s
Train Epoch: 431 [81920/90000 (91%)]	Loss: -9.1310	Cost: 12.60s
Train Epoch: 431 	Average Loss: -8.4502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0651

Learning rate: 9.251557545888296e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: -3.8655	Cost: 30.33s
Train Epoch: 432 [40960/90000 (45%)]	Loss: -8.8490	Cost: 9.43s
Train Epoch: 432 [81920/90000 (91%)]	Loss: -8.9740	Cost: 12.47s
Train Epoch: 432 	Average Loss: -8.4900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4184

Saving model as e432_model.pt & e432_waveforms_supplementary.hdf5
Learning rate: 8.98940293150043e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: -3.6223	Cost: 31.37s
Train Epoch: 433 [40960/90000 (45%)]	Loss: -9.0406	Cost: 9.40s
Train Epoch: 433 [81920/90000 (91%)]	Loss: -9.2514	Cost: 12.46s
Train Epoch: 433 	Average Loss: -8.4896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3200

Learning rate: 8.730841259649718e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: -3.9876	Cost: 32.52s
Train Epoch: 434 [40960/90000 (45%)]	Loss: -9.1226	Cost: 9.40s
Train Epoch: 434 [81920/90000 (91%)]	Loss: -9.2078	Cost: 11.98s
Train Epoch: 434 	Average Loss: -8.4812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1075

Learning rate: 8.475882737908241e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: -3.4771	Cost: 32.01s
Train Epoch: 435 [40960/90000 (45%)]	Loss: -8.9736	Cost: 9.39s
Train Epoch: 435 [81920/90000 (91%)]	Loss: -9.0590	Cost: 11.81s
Train Epoch: 435 	Average Loss: -8.4789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3730

Learning rate: 8.224537431601881e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: -4.1630	Cost: 30.65s
Train Epoch: 436 [40960/90000 (45%)]	Loss: -8.9856	Cost: 9.46s
Train Epoch: 436 [81920/90000 (91%)]	Loss: -9.2841	Cost: 11.82s
Train Epoch: 436 	Average Loss: -8.5443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2298

Learning rate: 7.97681526341298e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: -3.7378	Cost: 31.71s
Train Epoch: 437 [40960/90000 (45%)]	Loss: -9.0921	Cost: 9.40s
Train Epoch: 437 [81920/90000 (91%)]	Loss: -9.1814	Cost: 11.72s
Train Epoch: 437 	Average Loss: -8.5283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2865

Learning rate: 7.732726012988507e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: -3.7125	Cost: 32.08s
Train Epoch: 438 [40960/90000 (45%)]	Loss: -8.8878	Cost: 9.61s
Train Epoch: 438 [81920/90000 (91%)]	Loss: -9.0943	Cost: 12.25s
Train Epoch: 438 	Average Loss: -8.5298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2260

Learning rate: 7.492279316554181e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: -4.2402	Cost: 31.89s
Train Epoch: 439 [40960/90000 (45%)]	Loss: -8.8857	Cost: 9.41s
Train Epoch: 439 [81920/90000 (91%)]	Loss: -9.2186	Cost: 12.66s
Train Epoch: 439 	Average Loss: -8.5348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4194

Saving model as e439_model.pt & e439_waveforms_supplementary.hdf5
Learning rate: 7.25548466653387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: -3.8813	Cost: 31.02s
Train Epoch: 440 [40960/90000 (45%)]	Loss: -9.0399	Cost: 9.42s
Train Epoch: 440 [81920/90000 (91%)]	Loss: -9.2653	Cost: 12.48s
Train Epoch: 440 	Average Loss: -8.5537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1999

Learning rate: 7.02235141117485e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: -4.1948	Cost: 31.28s
Train Epoch: 441 [40960/90000 (45%)]	Loss: -9.0586	Cost: 9.43s
Train Epoch: 441 [81920/90000 (91%)]	Loss: -9.1656	Cost: 12.53s
Train Epoch: 441 	Average Loss: -8.5564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4301

Saving model as e441_model.pt & e441_waveforms_supplementary.hdf5
Learning rate: 6.792888754178901e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: -3.8415	Cost: 31.01s
Train Epoch: 442 [40960/90000 (45%)]	Loss: -9.0472	Cost: 9.40s
Train Epoch: 442 [81920/90000 (91%)]	Loss: -9.1651	Cost: 11.84s
Train Epoch: 442 	Average Loss: -8.6039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3487

Learning rate: 6.567105754338794e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: -3.9572	Cost: 30.74s
Train Epoch: 443 [40960/90000 (45%)]	Loss: -9.0720	Cost: 9.41s
Train Epoch: 443 [81920/90000 (91%)]	Loss: -9.0699	Cost: 11.86s
Train Epoch: 443 	Average Loss: -8.6028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3256

Learning rate: 6.3450113251807676e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: -3.6914	Cost: 31.75s
Train Epoch: 444 [40960/90000 (45%)]	Loss: -9.0717	Cost: 9.41s
Train Epoch: 444 [81920/90000 (91%)]	Loss: -9.1726	Cost: 11.93s
Train Epoch: 444 	Average Loss: -8.5185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4988

Saving model as e444_model.pt & e444_waveforms_supplementary.hdf5
Learning rate: 6.126614234612589e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: -3.8357	Cost: 31.05s
Train Epoch: 445 [40960/90000 (45%)]	Loss: -9.0880	Cost: 9.42s
Train Epoch: 445 [81920/90000 (91%)]	Loss: -9.2252	Cost: 12.60s
Train Epoch: 445 	Average Loss: -8.5938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5199

Saving model as e445_model.pt & e445_waveforms_supplementary.hdf5
Learning rate: 5.911923104577461e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: -4.2071	Cost: 31.53s
Train Epoch: 446 [40960/90000 (45%)]	Loss: -9.0996	Cost: 9.42s
Train Epoch: 446 [81920/90000 (91%)]	Loss: -9.3288	Cost: 12.73s
Train Epoch: 446 	Average Loss: -8.6296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1963

Learning rate: 5.7009464107135434e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: -3.2806	Cost: 32.33s
Train Epoch: 447 [40960/90000 (45%)]	Loss: -9.1707	Cost: 9.42s
Train Epoch: 447 [81920/90000 (91%)]	Loss: -9.1117	Cost: 12.52s
Train Epoch: 447 	Average Loss: -8.5821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3454

Learning rate: 5.493692482019526e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: -3.5230	Cost: 31.96s
Train Epoch: 448 [40960/90000 (45%)]	Loss: -9.0835	Cost: 9.40s
Train Epoch: 448 [81920/90000 (91%)]	Loss: -9.4536	Cost: 12.72s
Train Epoch: 448 	Average Loss: -8.6216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2733

Learning rate: 5.290169500525573e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: -4.0525	Cost: 30.92s
Train Epoch: 449 [40960/90000 (45%)]	Loss: -9.0480	Cost: 9.38s
Train Epoch: 449 [81920/90000 (91%)]	Loss: -9.1681	Cost: 12.67s
Train Epoch: 449 	Average Loss: -8.6373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2494

Learning rate: 5.090385500970525e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: -3.7977	Cost: 32.56s
Train Epoch: 450 [40960/90000 (45%)]	Loss: -9.2143	Cost: 9.38s
Train Epoch: 450 [81920/90000 (91%)]	Loss: -9.2110	Cost: 12.18s
Train Epoch: 450 	Average Loss: -8.6295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3312

Learning rate: 4.894348370484643e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: -3.8153	Cost: 31.12s
Train Epoch: 451 [40960/90000 (45%)]	Loss: -9.3132	Cost: 9.40s
Train Epoch: 451 [81920/90000 (91%)]	Loss: -9.3532	Cost: 12.65s
Train Epoch: 451 	Average Loss: -8.6377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2566

Learning rate: 4.702065848278122e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: -3.7789	Cost: 31.83s
Train Epoch: 452 [40960/90000 (45%)]	Loss: -9.1280	Cost: 9.42s
Train Epoch: 452 [81920/90000 (91%)]	Loss: -9.1709	Cost: 12.34s
Train Epoch: 452 	Average Loss: -8.6503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3765

Learning rate: 4.513545525335701e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: -3.5447	Cost: 31.14s
Train Epoch: 453 [40960/90000 (45%)]	Loss: -9.2661	Cost: 9.40s
Train Epoch: 453 [81920/90000 (91%)]	Loss: -9.3546	Cost: 12.74s
Train Epoch: 453 	Average Loss: -8.6874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4084

Learning rate: 4.328794844116942e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: -4.1379	Cost: 32.04s
Train Epoch: 454 [40960/90000 (45%)]	Loss: -9.2091	Cost: 9.41s
Train Epoch: 454 [81920/90000 (91%)]	Loss: -9.1218	Cost: 12.46s
Train Epoch: 454 	Average Loss: -8.6719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1921

Learning rate: 4.147821098262413e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: -3.6038	Cost: 32.10s
Train Epoch: 455 [40960/90000 (45%)]	Loss: -9.0982	Cost: 9.57s
Train Epoch: 455 [81920/90000 (91%)]	Loss: -9.3869	Cost: 12.15s
Train Epoch: 455 	Average Loss: -8.6789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2327

Learning rate: 3.97063143230569e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: -3.9444	Cost: 31.00s
Train Epoch: 456 [40960/90000 (45%)]	Loss: -9.3705	Cost: 9.64s
Train Epoch: 456 [81920/90000 (91%)]	Loss: -9.2813	Cost: 11.86s
Train Epoch: 456 	Average Loss: -8.7122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2957

Learning rate: 3.797232841391415e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: -3.7991	Cost: 30.81s
Train Epoch: 457 [40960/90000 (45%)]	Loss: -9.0729	Cost: 9.42s
Train Epoch: 457 [81920/90000 (91%)]	Loss: -9.4724	Cost: 11.92s
Train Epoch: 457 	Average Loss: -8.6873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2721

Learning rate: 3.627632170999026e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: -4.0505	Cost: 32.30s
Train Epoch: 458 [40960/90000 (45%)]	Loss: -8.9599	Cost: 9.38s
Train Epoch: 458 [81920/90000 (91%)]	Loss: -9.3027	Cost: 12.43s
Train Epoch: 458 	Average Loss: -8.6684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4118

Learning rate: 3.461836116672609e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: -4.2528	Cost: 30.64s
Train Epoch: 459 [40960/90000 (45%)]	Loss: -9.4529	Cost: 10.08s
Train Epoch: 459 [81920/90000 (91%)]	Loss: -9.2751	Cost: 12.15s
Train Epoch: 459 	Average Loss: -8.7238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4465

Learning rate: 3.2998512237564976e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: -3.7841	Cost: 30.89s
Train Epoch: 460 [40960/90000 (45%)]	Loss: -9.2493	Cost: 9.38s
Train Epoch: 460 [81920/90000 (91%)]	Loss: -9.2044	Cost: 12.87s
Train Epoch: 460 	Average Loss: -8.6972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3976

Learning rate: 3.14168388713689e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: -3.8507	Cost: 30.77s
Train Epoch: 461 [40960/90000 (45%)]	Loss: -9.2306	Cost: 9.41s
Train Epoch: 461 [81920/90000 (91%)]	Loss: -9.3826	Cost: 11.91s
Train Epoch: 461 	Average Loss: -8.7146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4192

Learning rate: 2.9873403509894177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: -3.6677	Cost: 31.95s
Train Epoch: 462 [40960/90000 (45%)]	Loss: -9.0587	Cost: 9.42s
Train Epoch: 462 [81920/90000 (91%)]	Loss: -9.2818	Cost: 12.86s
Train Epoch: 462 	Average Loss: -8.6810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3945

Learning rate: 2.8368267085326003e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: -3.8705	Cost: 31.98s
Train Epoch: 463 [40960/90000 (45%)]	Loss: -9.2526	Cost: 9.63s
Train Epoch: 463 [81920/90000 (91%)]	Loss: -9.2365	Cost: 12.26s
Train Epoch: 463 	Average Loss: -8.7294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3218

Learning rate: 2.690148901787346e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: -3.8165	Cost: 30.79s
Train Epoch: 464 [40960/90000 (45%)]	Loss: -9.0948	Cost: 9.61s
Train Epoch: 464 [81920/90000 (91%)]	Loss: -9.2852	Cost: 11.64s
Train Epoch: 464 	Average Loss: -8.7376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3511

Learning rate: 2.547312721342274e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: -3.8020	Cost: 31.02s
Train Epoch: 465 [40960/90000 (45%)]	Loss: -9.0227	Cost: 9.44s
Train Epoch: 465 [81920/90000 (91%)]	Loss: -9.1965	Cost: 13.06s
Train Epoch: 465 	Average Loss: -8.7389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4056

Learning rate: 2.4083238061252656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: -4.0862	Cost: 32.19s
Train Epoch: 466 [40960/90000 (45%)]	Loss: -9.1970	Cost: 9.69s
Train Epoch: 466 [81920/90000 (91%)]	Loss: -9.3844	Cost: 12.24s
Train Epoch: 466 	Average Loss: -8.7156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3892

Learning rate: 2.27318764318065e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: -3.9573	Cost: 30.96s
Train Epoch: 467 [40960/90000 (45%)]	Loss: -9.1448	Cost: 9.41s
Train Epoch: 467 [81920/90000 (91%)]	Loss: -9.3431	Cost: 12.71s
Train Epoch: 467 	Average Loss: -8.7271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4070

Learning rate: 2.1419095674527915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: -4.2124	Cost: 32.28s
Train Epoch: 468 [40960/90000 (45%)]	Loss: -9.2920	Cost: 9.37s
Train Epoch: 468 [81920/90000 (91%)]	Loss: -9.3669	Cost: 12.68s
Train Epoch: 468 	Average Loss: -8.7455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3051

Learning rate: 2.0144947615753123e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: -3.8526	Cost: 31.60s
Train Epoch: 469 [40960/90000 (45%)]	Loss: -9.0856	Cost: 9.40s
Train Epoch: 469 [81920/90000 (91%)]	Loss: -9.3410	Cost: 11.90s
Train Epoch: 469 	Average Loss: -8.7159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2148

Learning rate: 1.890948255666601e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: -3.5152	Cost: 30.98s
Train Epoch: 470 [40960/90000 (45%)]	Loss: -9.1725	Cost: 9.39s
Train Epoch: 470 [81920/90000 (91%)]	Loss: -9.2042	Cost: 12.74s
Train Epoch: 470 	Average Loss: -8.6967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2903

Learning rate: 1.7712749271311265e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: -3.7423	Cost: 31.84s
Train Epoch: 471 [40960/90000 (45%)]	Loss: -9.2203	Cost: 9.41s
Train Epoch: 471 [81920/90000 (91%)]	Loss: -9.3325	Cost: 12.64s
Train Epoch: 471 	Average Loss: -8.7664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2767

Learning rate: 1.6554795004670263e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: -3.8226	Cost: 32.17s
Train Epoch: 472 [40960/90000 (45%)]	Loss: -9.1397	Cost: 9.41s
Train Epoch: 472 [81920/90000 (91%)]	Loss: -9.2734	Cost: 12.25s
Train Epoch: 472 	Average Loss: -8.7354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4035

Learning rate: 1.5435665470794655e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: -4.2133	Cost: 31.11s
Train Epoch: 473 [40960/90000 (45%)]	Loss: -9.2136	Cost: 9.40s
Train Epoch: 473 [81920/90000 (91%)]	Loss: -9.4336	Cost: 12.63s
Train Epoch: 473 	Average Loss: -8.7652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5658

Saving model as e473_model.pt & e473_waveforms_supplementary.hdf5
Learning rate: 1.435540485100194e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: -3.8908	Cost: 31.43s
Train Epoch: 474 [40960/90000 (45%)]	Loss: -9.1252	Cost: 9.40s
Train Epoch: 474 [81920/90000 (91%)]	Loss: -9.4989	Cost: 11.96s
Train Epoch: 474 	Average Loss: -8.7520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4857

Learning rate: 1.3314055792131951e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: -3.5026	Cost: 32.06s
Train Epoch: 475 [40960/90000 (45%)]	Loss: -9.3208	Cost: 9.36s
Train Epoch: 475 [81920/90000 (91%)]	Loss: -9.5421	Cost: 12.74s
Train Epoch: 475 	Average Loss: -8.7670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4879

Learning rate: 1.231165940486233e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: -4.0257	Cost: 31.76s
Train Epoch: 476 [40960/90000 (45%)]	Loss: -9.2286	Cost: 9.40s
Train Epoch: 476 [81920/90000 (91%)]	Loss: -9.3996	Cost: 12.12s
Train Epoch: 476 	Average Loss: -8.7740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3527

Learning rate: 1.1348255262086039e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: -3.5881	Cost: 31.76s
Train Epoch: 477 [40960/90000 (45%)]	Loss: -9.0200	Cost: 9.39s
Train Epoch: 477 [81920/90000 (91%)]	Loss: -9.4144	Cost: 12.62s
Train Epoch: 477 	Average Loss: -8.7844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1831

Learning rate: 1.0423881397349057e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: -3.7005	Cost: 31.72s
Train Epoch: 478 [40960/90000 (45%)]	Loss: -9.3004	Cost: 9.42s
Train Epoch: 478 [81920/90000 (91%)]	Loss: -9.5263	Cost: 12.47s
Train Epoch: 478 	Average Loss: -8.7693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3881

Learning rate: 9.538574303348804e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: -3.3902	Cost: 31.32s
Train Epoch: 479 [40960/90000 (45%)]	Loss: -9.2164	Cost: 9.58s
Train Epoch: 479 [81920/90000 (91%)]	Loss: -9.4477	Cost: 11.93s
Train Epoch: 479 	Average Loss: -8.7468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3684

Learning rate: 8.692368930493404e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: -3.7818	Cost: 32.00s
Train Epoch: 480 [40960/90000 (45%)]	Loss: -9.2110	Cost: 10.00s
Train Epoch: 480 [81920/90000 (91%)]	Loss: -9.4441	Cost: 12.35s
Train Epoch: 480 	Average Loss: -8.7953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3119

Learning rate: 7.885298685522229e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: -3.8225	Cost: 31.92s
Train Epoch: 481 [40960/90000 (45%)]	Loss: -9.2888	Cost: 9.42s
Train Epoch: 481 [81920/90000 (91%)]	Loss: -9.4698	Cost: 12.33s
Train Epoch: 481 	Average Loss: -8.8340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5507

Learning rate: 7.117395430186407e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: -3.1581	Cost: 32.01s
Train Epoch: 482 [40960/90000 (45%)]	Loss: -9.3893	Cost: 9.43s
Train Epoch: 482 [81920/90000 (91%)]	Loss: -9.4292	Cost: 12.63s
Train Epoch: 482 	Average Loss: -8.7445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4861

Learning rate: 6.3886894799916e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: -3.9573	Cost: 31.94s
Train Epoch: 483 [40960/90000 (45%)]	Loss: -9.2795	Cost: 9.41s
Train Epoch: 483 [81920/90000 (91%)]	Loss: -9.6406	Cost: 12.48s
Train Epoch: 483 	Average Loss: -8.8333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4308

Learning rate: 5.699209603001072e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: -3.9617	Cost: 31.59s
Train Epoch: 484 [40960/90000 (45%)]	Loss: -9.2572	Cost: 9.41s
Train Epoch: 484 [81920/90000 (91%)]	Loss: -9.4765	Cost: 12.61s
Train Epoch: 484 	Average Loss: -8.7563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4983

Learning rate: 5.048983018699823e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: -4.3022	Cost: 32.26s
Train Epoch: 485 [40960/90000 (45%)]	Loss: -9.3674	Cost: 9.40s
Train Epoch: 485 [81920/90000 (91%)]	Loss: -9.5720	Cost: 12.37s
Train Epoch: 485 	Average Loss: -8.7631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3401

Learning rate: 4.43803539692e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: -3.8354	Cost: 31.68s
Train Epoch: 486 [40960/90000 (45%)]	Loss: -9.2690	Cost: 9.40s
Train Epoch: 486 [81920/90000 (91%)]	Loss: -9.4985	Cost: 12.14s
Train Epoch: 486 	Average Loss: -8.8218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5081

Learning rate: 3.8663908568274915e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: -4.1034	Cost: 31.28s
Train Epoch: 487 [40960/90000 (45%)]	Loss: -9.1824	Cost: 9.42s
Train Epoch: 487 [81920/90000 (91%)]	Loss: -9.4303	Cost: 12.63s
Train Epoch: 487 	Average Loss: -8.8235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4424

Learning rate: 3.334071965970128e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: -3.6241	Cost: 30.79s
Train Epoch: 488 [40960/90000 (45%)]	Loss: -9.2640	Cost: 9.41s
Train Epoch: 488 [81920/90000 (91%)]	Loss: -9.2255	Cost: 12.60s
Train Epoch: 488 	Average Loss: -8.7599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4344

Learning rate: 2.8410997393860634e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: -4.0229	Cost: 30.70s
Train Epoch: 489 [40960/90000 (45%)]	Loss: -9.2767	Cost: 9.41s
Train Epoch: 489 [81920/90000 (91%)]	Loss: -9.3686	Cost: 12.65s
Train Epoch: 489 	Average Loss: -8.7983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4754

Learning rate: 2.3874936387747717e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: -4.0734	Cost: 31.69s
Train Epoch: 490 [40960/90000 (45%)]	Loss: -9.2434	Cost: 9.41s
Train Epoch: 490 [81920/90000 (91%)]	Loss: -9.3978	Cost: 11.97s
Train Epoch: 490 	Average Loss: -8.7659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3095

Learning rate: 1.9732715717284395e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: -3.2457	Cost: 32.92s
Train Epoch: 491 [40960/90000 (45%)]	Loss: -9.0957	Cost: 9.33s
Train Epoch: 491 [81920/90000 (91%)]	Loss: -9.4265	Cost: 12.37s
Train Epoch: 491 	Average Loss: -8.7756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4154

Learning rate: 1.5984498910249766e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: -4.2912	Cost: 31.17s
Train Epoch: 492 [40960/90000 (45%)]	Loss: -9.2273	Cost: 9.36s
Train Epoch: 492 [81920/90000 (91%)]	Loss: -9.4834	Cost: 13.00s
Train Epoch: 492 	Average Loss: -8.8174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3004

Learning rate: 1.2630433939825314e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: -4.1109	Cost: 31.62s
Train Epoch: 493 [40960/90000 (45%)]	Loss: -9.2459	Cost: 9.38s
Train Epoch: 493 [81920/90000 (91%)]	Loss: -9.6225	Cost: 12.59s
Train Epoch: 493 	Average Loss: -8.7637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3609

Learning rate: 9.670653218752925e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: -4.3174	Cost: 31.05s
Train Epoch: 494 [40960/90000 (45%)]	Loss: -9.3687	Cost: 9.41s
Train Epoch: 494 [81920/90000 (91%)]	Loss: -9.3347	Cost: 11.99s
Train Epoch: 494 	Average Loss: -8.8178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5078

Learning rate: 7.105273594107945e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: -3.9034	Cost: 31.40s
Train Epoch: 495 [40960/90000 (45%)]	Loss: -9.2842	Cost: 9.42s
Train Epoch: 495 [81920/90000 (91%)]	Loss: -9.4472	Cost: 12.56s
Train Epoch: 495 	Average Loss: -8.7894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3371

Learning rate: 4.9343963426839946e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: -3.8249	Cost: 31.26s
Train Epoch: 496 [40960/90000 (45%)]	Loss: -9.2680	Cost: 9.40s
Train Epoch: 496 [81920/90000 (91%)]	Loss: -9.3485	Cost: 11.67s
Train Epoch: 496 	Average Loss: -8.7980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5422

Learning rate: 3.158107167000598e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: -3.6169	Cost: 31.23s
Train Epoch: 497 [40960/90000 (45%)]	Loss: -9.2902	Cost: 9.41s
Train Epoch: 497 [81920/90000 (91%)]	Loss: -9.4601	Cost: 12.10s
Train Epoch: 497 	Average Loss: -8.7778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3599

Learning rate: 1.776476191910346e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: -4.2818	Cost: 33.02s
Train Epoch: 498 [40960/90000 (45%)]	Loss: -9.2455	Cost: 9.40s
Train Epoch: 498 [81920/90000 (91%)]	Loss: -9.5697	Cost: 12.80s
Train Epoch: 498 	Average Loss: -8.8272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3912

Learning rate: 7.895579618388819e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: -3.9715	Cost: 31.23s
Train Epoch: 499 [40960/90000 (45%)]	Loss: -9.1318	Cost: 9.40s
Train Epoch: 499 [81920/90000 (91%)]	Loss: -9.1703	Cost: 12.56s
Train Epoch: 499 	Average Loss: -8.7875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4956

Learning rate: 1.973914386288465e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: -3.8783	Cost: 31.56s
Train Epoch: 500 [40960/90000 (45%)]	Loss: -9.3654	Cost: 9.40s
Train Epoch: 500 [81920/90000 (91%)]	Loss: -9.5073	Cost: 12.48s
Train Epoch: 500 	Average Loss: -8.8190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5226

Stopping timer.
Training time (including validation): 97756.64585828781 seconds
Saving model
Transfer learning by starting with alpha=0.6!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 35.7858	Cost: 31.61s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 13.4573	Cost: 9.43s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 10.9544	Cost: 12.45s
Train Epoch: 1 	Average Loss: 14.8818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2280

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.0001999980260856137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 10.7727	Cost: 32.31s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 9.1806	Cost: 9.53s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 8.0927	Cost: 12.42s
Train Epoch: 2 	Average Loss: 9.0786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4779

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 8.2649	Cost: 32.56s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 7.4785	Cost: 9.60s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 6.7706	Cost: 11.96s
Train Epoch: 3 	Average Loss: 7.4048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5366

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 7.2413	Cost: 32.04s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 6.5118	Cost: 9.48s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 5.9595	Cost: 12.23s
Train Epoch: 4 	Average Loss: 6.5320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9230

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892833004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 6.5830	Cost: 30.89s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 5.8640	Cost: 9.75s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 5.5603	Cost: 11.93s
Train Epoch: 5 	Average Loss: 5.9083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4295

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 5.9022	Cost: 32.01s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 5.3806	Cost: 9.76s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 4.8294	Cost: 11.58s
Train Epoch: 6 	Average Loss: 5.2504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8332

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 4.9919	Cost: 31.49s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 4.6603	Cost: 9.48s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 4.3752	Cost: 11.56s
Train Epoch: 7 	Average Loss: 4.6898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4051

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 4.8867	Cost: 30.81s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 4.1315	Cost: 9.51s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 4.0105	Cost: 11.57s
Train Epoch: 8 	Average Loss: 4.2218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2252

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019987369566060184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 4.3896	Cost: 31.36s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 3.6658	Cost: 9.48s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 3.6108	Cost: 11.84s
Train Epoch: 9 	Average Loss: 3.7354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7744

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019984015501089758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 4.2198	Cost: 31.02s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 3.2890	Cost: 9.46s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 3.0501	Cost: 12.13s
Train Epoch: 10 	Average Loss: 3.4260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6900

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 3.9526	Cost: 31.64s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 3.1699	Cost: 9.43s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 2.8785	Cost: 12.53s
Train Epoch: 11 	Average Loss: 3.2087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5237

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019976125063612257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 3.7966	Cost: 31.67s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 3.0426	Cost: 9.63s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 2.9538	Cost: 11.73s
Train Epoch: 12 	Average Loss: 3.0384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3055

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019971589002606144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 3.3768	Cost: 31.26s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 2.7618	Cost: 9.46s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 2.6639	Cost: 11.62s
Train Epoch: 13 	Average Loss: 2.7307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2016

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.00019966659280340303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 3.2803	Cost: 31.30s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 2.5248	Cost: 9.46s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 2.3835	Cost: 12.52s
Train Epoch: 14 	Average Loss: 2.6351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2632

Learning rate: 0.0001996133609143173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 3.3108	Cost: 32.49s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 2.6474	Cost: 9.46s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 2.2811	Cost: 12.67s
Train Epoch: 15 	Average Loss: 2.5588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1471

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 2.9297	Cost: 31.70s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 2.3119	Cost: 9.45s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 2.3990	Cost: 12.17s
Train Epoch: 16 	Average Loss: 2.4135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0350

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.00019949510169813006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 3.3267	Cost: 31.77s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 2.3147	Cost: 9.46s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 2.2766	Cost: 12.80s
Train Epoch: 17 	Average Loss: 2.3669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9999

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019943007903969992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 2.8500	Cost: 31.69s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 2.0647	Cost: 9.55s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 1.9482	Cost: 11.72s
Train Epoch: 18 	Average Loss: 2.2311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8960

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.00019936113105200088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 3.1141	Cost: 31.95s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 1.8171	Cost: 9.45s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 2.0519	Cost: 11.97s
Train Epoch: 19 	Average Loss: 2.0630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0451

Learning rate: 0.0001992882604569814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 3.0030	Cost: 31.98s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 1.9255	Cost: 9.45s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 1.7701	Cost: 11.93s
Train Epoch: 20 	Average Loss: 2.0316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8489

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019921147013144782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 2.7390	Cost: 33.08s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 1.9351	Cost: 9.43s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 1.8657	Cost: 12.23s
Train Epoch: 21 	Average Loss: 1.9868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1424

Learning rate: 0.00019913076310695068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 2.9838	Cost: 31.79s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 1.7493	Cost: 9.47s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 1.6525	Cost: 12.74s
Train Epoch: 22 	Average Loss: 1.9409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7446

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.00019904614256966512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 2.9173	Cost: 32.75s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 1.7309	Cost: 9.40s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 1.8896	Cost: 12.26s
Train Epoch: 23 	Average Loss: 1.8540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8800

Learning rate: 0.0001989576118602651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 2.9175	Cost: 31.59s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 1.5696	Cost: 9.47s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 1.6828	Cost: 12.13s
Train Epoch: 24 	Average Loss: 1.7982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8943

Learning rate: 0.0001988651744737914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 2.7267	Cost: 32.14s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 1.9899	Cost: 9.58s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 1.6592	Cost: 12.50s
Train Epoch: 25 	Average Loss: 1.9058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8346

Learning rate: 0.0001987688340595138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 2.9857	Cost: 32.23s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 1.7891	Cost: 9.46s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 1.7530	Cost: 12.02s
Train Epoch: 26 	Average Loss: 1.8232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7623

Learning rate: 0.00019866859442078683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 2.4854	Cost: 31.86s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 1.4847	Cost: 9.49s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 1.4908	Cost: 12.58s
Train Epoch: 27 	Average Loss: 1.6651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5273

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019856445951489985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 2.4657	Cost: 32.27s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 1.6458	Cost: 9.54s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 1.4974	Cost: 12.36s
Train Epoch: 28 	Average Loss: 1.5497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7182

Learning rate: 0.0001984564334529206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 2.4602	Cost: 32.39s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 1.2533	Cost: 9.54s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 1.2710	Cost: 12.01s
Train Epoch: 29 	Average Loss: 1.4957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5681

Learning rate: 0.00019834452049953302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 2.6910	Cost: 31.03s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 1.1608	Cost: 9.49s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 1.0519	Cost: 11.84s
Train Epoch: 30 	Average Loss: 1.3163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5129

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.00019822872507286893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 2.3524	Cost: 31.45s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 1.1533	Cost: 9.48s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 1.0257	Cost: 11.99s
Train Epoch: 31 	Average Loss: 1.3443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5383

Learning rate: 0.00019810905174433345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 2.7768	Cost: 31.37s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 1.4607	Cost: 9.48s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 1.2242	Cost: 12.03s
Train Epoch: 32 	Average Loss: 1.4723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5518

Learning rate: 0.00019798550523842474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 2.5752	Cost: 32.58s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 1.2452	Cost: 9.46s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 0.9607	Cost: 12.44s
Train Epoch: 33 	Average Loss: 1.3414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6245

Learning rate: 0.00019785809043254728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 2.5402	Cost: 33.53s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 1.1680	Cost: 9.42s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 1.0028	Cost: 12.92s
Train Epoch: 34 	Average Loss: 1.2412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4890

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019772681235681944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 2.7455	Cost: 32.50s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 1.1871	Cost: 9.42s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 0.9781	Cost: 12.81s
Train Epoch: 35 	Average Loss: 1.2263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5181

Learning rate: 0.00019759167619387482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 2.2577	Cost: 31.36s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 0.9906	Cost: 9.47s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 0.7851	Cost: 12.04s
Train Epoch: 36 	Average Loss: 1.0893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5315

Learning rate: 0.0001974526872786578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 2.3090	Cost: 33.61s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 0.9887	Cost: 9.43s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 0.7987	Cost: 12.28s
Train Epoch: 37 	Average Loss: 1.0730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4378

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.00019730985109821272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 2.4285	Cost: 31.41s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 0.8962	Cost: 9.46s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 1.1063	Cost: 11.86s
Train Epoch: 38 	Average Loss: 1.0567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3808

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.00019716317329146745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 2.3300	Cost: 32.20s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 0.6867	Cost: 9.46s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 0.6975	Cost: 11.77s
Train Epoch: 39 	Average Loss: 0.9491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4567

Learning rate: 0.00019701265964901062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 2.3437	Cost: 32.20s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 0.6995	Cost: 9.49s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 0.8617	Cost: 11.98s
Train Epoch: 40 	Average Loss: 0.9461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2681

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 2.0934	Cost: 31.30s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 0.6965	Cost: 9.48s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 0.8441	Cost: 11.68s
Train Epoch: 41 	Average Loss: 0.8558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4336

Learning rate: 0.00019670014877624353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 2.2699	Cost: 32.17s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 0.6865	Cost: 9.46s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 0.8109	Cost: 12.29s
Train Epoch: 42 	Average Loss: 0.9905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5146

Learning rate: 0.0001965381638833274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 2.6240	Cost: 31.50s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 0.8140	Cost: 9.46s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 0.8180	Cost: 12.16s
Train Epoch: 43 	Average Loss: 1.0699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4805

Learning rate: 0.000196372367829001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 2.4665	Cost: 32.41s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 0.5728	Cost: 9.48s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 0.7597	Cost: 12.36s
Train Epoch: 44 	Average Loss: 0.9556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5763

Learning rate: 0.00019620276715860861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 2.5852	Cost: 31.83s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 0.8094	Cost: 9.49s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 0.7589	Cost: 12.07s
Train Epoch: 45 	Average Loss: 0.8598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3243

Learning rate: 0.00019602936856769434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 2.3094	Cost: 31.07s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 0.4905	Cost: 9.51s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 0.5053	Cost: 13.33s
Train Epoch: 46 	Average Loss: 0.7516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2963

Learning rate: 0.00019585217890173763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 2.0497	Cost: 32.89s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 0.8283	Cost: 9.43s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 0.4308	Cost: 12.52s
Train Epoch: 47 	Average Loss: 0.7142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2741

Learning rate: 0.0001956712051558831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 1.7941	Cost: 32.07s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 0.6239	Cost: 9.47s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 0.2820	Cost: 12.06s
Train Epoch: 48 	Average Loss: 0.6776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1873

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 0.00019548645447466434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 2.2165	Cost: 31.67s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 0.2830	Cost: 9.48s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 0.5446	Cost: 11.87s
Train Epoch: 49 	Average Loss: 0.5695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2886

Learning rate: 0.00019529793415172192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 2.3819	Cost: 31.03s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 0.4200	Cost: 9.49s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 0.3457	Cost: 12.10s
Train Epoch: 50 	Average Loss: 0.6281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3712

Learning rate: 0.0001951056516295154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 1.8466	Cost: 30.90s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 0.4508	Cost: 9.44s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 0.3017	Cost: 12.35s
Train Epoch: 51 	Average Loss: 0.5664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4458

Learning rate: 0.0001949096144990295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 2.1637	Cost: 31.25s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 0.3337	Cost: 9.47s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 0.1628	Cost: 11.90s
Train Epoch: 52 	Average Loss: 0.5619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3457

Learning rate: 0.00019470983049947442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 2.3887	Cost: 31.36s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 0.2202	Cost: 9.48s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 0.3640	Cost: 12.64s
Train Epoch: 53 	Average Loss: 0.5318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2631

Learning rate: 0.00019450630751798048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 1.9367	Cost: 31.51s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 0.3184	Cost: 9.63s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 0.2485	Cost: 12.27s
Train Epoch: 54 	Average Loss: 0.4952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2150

Learning rate: 0.00019429905358928646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 2.0546	Cost: 32.16s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 0.2706	Cost: 9.49s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 0.3937	Cost: 12.29s
Train Epoch: 55 	Average Loss: 0.5441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2493

Learning rate: 0.00019408807689542257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 2.1732	Cost: 31.46s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 0.3933	Cost: 9.48s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 0.2244	Cost: 12.68s
Train Epoch: 56 	Average Loss: 0.5384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4555

Learning rate: 0.00019387338576538744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 2.3202	Cost: 31.93s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 0.3133	Cost: 9.46s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 0.2135	Cost: 11.89s
Train Epoch: 57 	Average Loss: 0.4649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3749

Learning rate: 0.00019365498867481926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 1.8832	Cost: 31.20s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 0.3943	Cost: 9.48s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 0.3442	Cost: 11.96s
Train Epoch: 58 	Average Loss: 0.4054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2025

Learning rate: 0.00019343289424566122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 2.2103	Cost: 31.43s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 0.1927	Cost: 9.46s
Train Epoch: 59 [81920/90000 (91%)]	Loss: -0.0318	Cost: 11.94s
Train Epoch: 59 	Average Loss: 0.4017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2748

Learning rate: 0.00019320711124582108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 2.2939	Cost: 30.21s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 0.3708	Cost: 9.47s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 0.2476	Cost: 12.59s
Train Epoch: 60 	Average Loss: 0.4911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3093

Learning rate: 0.00019297764858882514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 2.3045	Cost: 31.02s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 0.1988	Cost: 9.48s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 0.2195	Cost: 13.24s
Train Epoch: 61 	Average Loss: 0.3839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2462

Learning rate: 0.00019274451533346612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 1.9606	Cost: 31.23s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 0.2749	Cost: 9.49s
Train Epoch: 62 [81920/90000 (91%)]	Loss: -0.2695	Cost: 12.05s
Train Epoch: 62 	Average Loss: 0.3001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0943

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019250772068344577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 2.0685	Cost: 31.74s
Train Epoch: 63 [40960/90000 (45%)]	Loss: -0.0050	Cost: 9.49s
Train Epoch: 63 [81920/90000 (91%)]	Loss: -0.0333	Cost: 12.20s
Train Epoch: 63 	Average Loss: 0.2178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1471

Learning rate: 0.00019226727398701147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 1.9242	Cost: 31.32s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 0.2769	Cost: 9.48s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 0.0026	Cost: 11.91s
Train Epoch: 64 	Average Loss: 0.2165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2618

Learning rate: 0.00019202318473658702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 2.0269	Cost: 31.04s
Train Epoch: 65 [40960/90000 (45%)]	Loss: -0.0147	Cost: 9.44s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 0.1116	Cost: 11.84s
Train Epoch: 65 	Average Loss: 0.2084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1470

Learning rate: 0.0001917754625683981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 1.7620	Cost: 31.89s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 0.0474	Cost: 9.47s
Train Epoch: 66 [81920/90000 (91%)]	Loss: -0.2611	Cost: 11.94s
Train Epoch: 66 	Average Loss: 0.1077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0042

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.00019152411726209174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 1.8129	Cost: 31.95s
Train Epoch: 67 [40960/90000 (45%)]	Loss: -0.1176	Cost: 9.45s
Train Epoch: 67 [81920/90000 (91%)]	Loss: -0.2473	Cost: 13.05s
Train Epoch: 67 	Average Loss: 0.1021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1533

Learning rate: 0.00019126915874035028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 1.9896	Cost: 31.25s
Train Epoch: 68 [40960/90000 (45%)]	Loss: -0.3193	Cost: 9.50s
Train Epoch: 68 [81920/90000 (91%)]	Loss: -0.1518	Cost: 12.43s
Train Epoch: 68 	Average Loss: 0.0589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2864

Learning rate: 0.00019101059706849957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 1.8783	Cost: 32.26s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 0.2040	Cost: 9.53s
Train Epoch: 69 [81920/90000 (91%)]	Loss: -0.0133	Cost: 12.19s
Train Epoch: 69 	Average Loss: 0.2880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2654

Learning rate: 0.0001907484424541117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 2.3208	Cost: 32.15s
Train Epoch: 70 [40960/90000 (45%)]	Loss: -0.0539	Cost: 9.47s
Train Epoch: 70 [81920/90000 (91%)]	Loss: -0.2469	Cost: 12.57s
Train Epoch: 70 	Average Loss: 0.1653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1333

Learning rate: 0.00019048270524660196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 1.8436	Cost: 31.35s
Train Epoch: 71 [40960/90000 (45%)]	Loss: -0.1671	Cost: 9.47s
Train Epoch: 71 [81920/90000 (91%)]	Loss: -0.3045	Cost: 12.53s
Train Epoch: 71 	Average Loss: 0.0210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9785

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00019021339593682028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 1.8124	Cost: 31.39s
Train Epoch: 72 [40960/90000 (45%)]	Loss: -0.2673	Cost: 9.48s
Train Epoch: 72 [81920/90000 (91%)]	Loss: -0.3986	Cost: 11.75s
Train Epoch: 72 	Average Loss: -0.0294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3261

Learning rate: 0.0001899405251566371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 1.8004	Cost: 32.89s
Train Epoch: 73 [40960/90000 (45%)]	Loss: -0.2013	Cost: 9.46s
Train Epoch: 73 [81920/90000 (91%)]	Loss: -0.5467	Cost: 12.52s
Train Epoch: 73 	Average Loss: 0.0038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0175

Learning rate: 0.0001896641036785236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 2.0811	Cost: 31.43s
Train Epoch: 74 [40960/90000 (45%)]	Loss: -0.3195	Cost: 9.47s
Train Epoch: 74 [81920/90000 (91%)]	Loss: -0.1886	Cost: 12.16s
Train Epoch: 74 	Average Loss: 0.1145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0856

Learning rate: 0.00018938414241512636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 2.1356	Cost: 31.58s
Train Epoch: 75 [40960/90000 (45%)]	Loss: -0.4340	Cost: 9.48s
Train Epoch: 75 [81920/90000 (91%)]	Loss: -0.5109	Cost: 12.13s
Train Epoch: 75 	Average Loss: -0.0124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9655

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 0.00018910065241883677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 1.9963	Cost: 32.40s
Train Epoch: 76 [40960/90000 (45%)]	Loss: -0.4011	Cost: 9.46s
Train Epoch: 76 [81920/90000 (91%)]	Loss: -0.6397	Cost: 12.37s
Train Epoch: 76 	Average Loss: -0.1294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9781

Learning rate: 0.00018881364488135445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 1.7482	Cost: 30.99s
Train Epoch: 77 [40960/90000 (45%)]	Loss: -0.2525	Cost: 9.47s
Train Epoch: 77 [81920/90000 (91%)]	Loss: -0.5333	Cost: 11.58s
Train Epoch: 77 	Average Loss: -0.1553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9326

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Learning rate: 0.00018852313113324552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 1.9679	Cost: 31.31s
Train Epoch: 78 [40960/90000 (45%)]	Loss: -0.3935	Cost: 9.53s
Train Epoch: 78 [81920/90000 (91%)]	Loss: -0.6336	Cost: 11.79s
Train Epoch: 78 	Average Loss: -0.1939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8410

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Learning rate: 0.00018822912264349534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 1.8071	Cost: 31.33s
Train Epoch: 79 [40960/90000 (45%)]	Loss: -0.0952	Cost: 9.45s
Train Epoch: 79 [81920/90000 (91%)]	Loss: -0.2855	Cost: 13.26s
Train Epoch: 79 	Average Loss: -0.0702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9971

Learning rate: 0.00018793163101905563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 1.9948	Cost: 32.23s
Train Epoch: 80 [40960/90000 (45%)]	Loss: -0.2268	Cost: 9.48s
Train Epoch: 80 [81920/90000 (91%)]	Loss: -0.4690	Cost: 12.13s
Train Epoch: 80 	Average Loss: -0.1181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1415

Learning rate: 0.00018763066800438636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 1.7019	Cost: 31.28s
Train Epoch: 81 [40960/90000 (45%)]	Loss: -0.3309	Cost: 9.47s
Train Epoch: 81 [81920/90000 (91%)]	Loss: -0.4085	Cost: 12.21s
Train Epoch: 81 	Average Loss: -0.1801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0381

Learning rate: 0.000187326245480992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 1.8898	Cost: 31.78s
Train Epoch: 82 [40960/90000 (45%)]	Loss: -0.6412	Cost: 9.44s
Train Epoch: 82 [81920/90000 (91%)]	Loss: -0.5699	Cost: 12.41s
Train Epoch: 82 	Average Loss: -0.2901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8984

Learning rate: 0.00018701837546695256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 1.7770	Cost: 31.17s
Train Epoch: 83 [40960/90000 (45%)]	Loss: -0.3410	Cost: 9.47s
Train Epoch: 83 [81920/90000 (91%)]	Loss: -0.7727	Cost: 11.50s
Train Epoch: 83 	Average Loss: -0.2657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0996

Learning rate: 0.00018670707011644898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 1.4005	Cost: 30.85s
Train Epoch: 84 [40960/90000 (45%)]	Loss: -0.4757	Cost: 9.46s
Train Epoch: 84 [81920/90000 (91%)]	Loss: -0.7333	Cost: 12.24s
Train Epoch: 84 	Average Loss: -0.3319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0147

Learning rate: 0.0001863923417192835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 1.7532	Cost: 32.63s
Train Epoch: 85 [40960/90000 (45%)]	Loss: -0.5856	Cost: 9.48s
Train Epoch: 85 [81920/90000 (91%)]	Loss: -0.7110	Cost: 12.60s
Train Epoch: 85 	Average Loss: -0.3970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9494

Learning rate: 0.00018607420270039436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 1.9766	Cost: 32.19s
Train Epoch: 86 [40960/90000 (45%)]	Loss: -0.6645	Cost: 9.48s
Train Epoch: 86 [81920/90000 (91%)]	Loss: -0.5505	Cost: 12.32s
Train Epoch: 86 	Average Loss: -0.3840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9966

Learning rate: 0.00018575266561936523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 1.9450	Cost: 31.64s
Train Epoch: 87 [40960/90000 (45%)]	Loss: -0.6224	Cost: 9.49s
Train Epoch: 87 [81920/90000 (91%)]	Loss: -0.8085	Cost: 12.83s
Train Epoch: 87 	Average Loss: -0.3726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0113

Learning rate: 0.0001854277431699295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 1.6026	Cost: 31.29s
Train Epoch: 88 [40960/90000 (45%)]	Loss: -0.6183	Cost: 9.49s
Train Epoch: 88 [81920/90000 (91%)]	Loss: -0.8174	Cost: 11.41s
Train Epoch: 88 	Average Loss: -0.4422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8392

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 0.0001850994481794692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 1.3859	Cost: 33.34s
Train Epoch: 89 [40960/90000 (45%)]	Loss: -0.5231	Cost: 9.40s
Train Epoch: 89 [81920/90000 (91%)]	Loss: -0.6551	Cost: 12.65s
Train Epoch: 89 	Average Loss: -0.3697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9545

Learning rate: 0.0001847677936085083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 1.8156	Cost: 31.36s
Train Epoch: 90 [40960/90000 (45%)]	Loss: -0.5646	Cost: 9.47s
Train Epoch: 90 [81920/90000 (91%)]	Loss: -0.6261	Cost: 12.41s
Train Epoch: 90 	Average Loss: -0.4108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9709

Learning rate: 0.00018443279255020146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 2.4424	Cost: 30.83s
Train Epoch: 91 [40960/90000 (45%)]	Loss: -0.5518	Cost: 9.45s
Train Epoch: 91 [81920/90000 (91%)]	Loss: -0.8367	Cost: 13.32s
Train Epoch: 91 	Average Loss: -0.4624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8646

Learning rate: 0.00018409445822981687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 1.8776	Cost: 31.06s
Train Epoch: 92 [40960/90000 (45%)]	Loss: -0.7478	Cost: 9.52s
Train Epoch: 92 [81920/90000 (91%)]	Loss: -0.7081	Cost: 12.52s
Train Epoch: 92 	Average Loss: -0.4451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7468

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 0.00018375280400421414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 1.9302	Cost: 31.88s
Train Epoch: 93 [40960/90000 (45%)]	Loss: -0.7211	Cost: 9.44s
Train Epoch: 93 [81920/90000 (91%)]	Loss: -0.9031	Cost: 13.04s
Train Epoch: 93 	Average Loss: -0.4826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9310

Learning rate: 0.00018340784336131708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 1.8875	Cost: 33.24s
Train Epoch: 94 [40960/90000 (45%)]	Loss: -0.8063	Cost: 9.45s
Train Epoch: 94 [81920/90000 (91%)]	Loss: -1.0043	Cost: 11.93s
Train Epoch: 94 	Average Loss: -0.5934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8425

Learning rate: 0.00018305958991958124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 1.4973	Cost: 32.06s
Train Epoch: 95 [40960/90000 (45%)]	Loss: -0.9747	Cost: 9.48s
Train Epoch: 95 [81920/90000 (91%)]	Loss: -0.7665	Cost: 11.84s
Train Epoch: 95 	Average Loss: -0.6507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9731

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 1.9737	Cost: 31.55s
Train Epoch: 96 [40960/90000 (45%)]	Loss: -0.6263	Cost: 9.47s
Train Epoch: 96 [81920/90000 (91%)]	Loss: -0.9778	Cost: 13.38s
Train Epoch: 96 	Average Loss: -0.5871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1167

Learning rate: 0.0001823532597628427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 1.7592	Cost: 31.83s
Train Epoch: 97 [40960/90000 (45%)]	Loss: -0.6678	Cost: 9.55s
Train Epoch: 97 [81920/90000 (91%)]	Loss: -0.8436	Cost: 12.72s
Train Epoch: 97 	Average Loss: -0.5871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0205

Learning rate: 0.0001819952109325452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 1.5652	Cost: 31.03s
Train Epoch: 98 [40960/90000 (45%)]	Loss: -0.8165	Cost: 9.50s
Train Epoch: 98 [81920/90000 (91%)]	Loss: -1.0473	Cost: 11.95s
Train Epoch: 98 	Average Loss: -0.6987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7261

Saving model as e98_model.pt & e98_waveforms_supplementary.hdf5
Learning rate: 0.00018163392507171837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 1.7031	Cost: 32.40s
Train Epoch: 99 [40960/90000 (45%)]	Loss: -1.1456	Cost: 9.46s
Train Epoch: 99 [81920/90000 (91%)]	Loss: -1.0116	Cost: 11.81s
Train Epoch: 99 	Average Loss: -0.7263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8274

Learning rate: 0.00018126941644330935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 1.5293	Cost: 31.57s
Train Epoch: 100 [40960/90000 (45%)]	Loss: -0.6092	Cost: 9.48s
Train Epoch: 100 [81920/90000 (91%)]	Loss: -0.8859	Cost: 12.73s
Train Epoch: 100 	Average Loss: -0.4745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0618

Learning rate: 0.0001809016994374947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 2.0133	Cost: 31.98s
Train Epoch: 101 [40960/90000 (45%)]	Loss: -0.8057	Cost: 9.46s
Train Epoch: 101 [81920/90000 (91%)]	Loss: -0.9482	Cost: 12.02s
Train Epoch: 101 	Average Loss: -0.6410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9292

Learning rate: 0.00018053078857111214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 1.5364	Cost: 32.02s
Train Epoch: 102 [40960/90000 (45%)]	Loss: -1.0327	Cost: 9.50s
Train Epoch: 102 [81920/90000 (91%)]	Loss: -1.0698	Cost: 11.66s
Train Epoch: 102 	Average Loss: -0.8260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9172

Learning rate: 0.00018015669848708761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 1.6605	Cost: 31.60s
Train Epoch: 103 [40960/90000 (45%)]	Loss: -1.1830	Cost: 9.48s
Train Epoch: 103 [81920/90000 (91%)]	Loss: -0.9956	Cost: 11.57s
Train Epoch: 103 	Average Loss: -0.7688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9667

Learning rate: 0.00017977944395385705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 2.3763	Cost: 32.40s
Train Epoch: 104 [40960/90000 (45%)]	Loss: -0.7318	Cost: 9.49s
Train Epoch: 104 [81920/90000 (91%)]	Loss: -1.1986	Cost: 11.70s
Train Epoch: 104 	Average Loss: -0.5970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7731

Learning rate: 0.00017939903986478347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 1.3757	Cost: 32.87s
Train Epoch: 105 [40960/90000 (45%)]	Loss: -0.9397	Cost: 9.47s
Train Epoch: 105 [81920/90000 (91%)]	Loss: -1.2126	Cost: 12.13s
Train Epoch: 105 	Average Loss: -0.8290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7255

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00017901550123756898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 1.3471	Cost: 30.98s
Train Epoch: 106 [40960/90000 (45%)]	Loss: -1.0894	Cost: 9.45s
Train Epoch: 106 [81920/90000 (91%)]	Loss: -1.2635	Cost: 11.83s
Train Epoch: 106 	Average Loss: -0.8448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7304

Learning rate: 0.00017862884321366183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 1.4787	Cost: 31.45s
Train Epoch: 107 [40960/90000 (45%)]	Loss: -1.2247	Cost: 9.47s
Train Epoch: 107 [81920/90000 (91%)]	Loss: -1.3524	Cost: 11.69s
Train Epoch: 107 	Average Loss: -0.9532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9137

Learning rate: 0.00017823908105765875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 1.2394	Cost: 32.22s
Train Epoch: 108 [40960/90000 (45%)]	Loss: -1.1545	Cost: 9.44s
Train Epoch: 108 [81920/90000 (91%)]	Loss: -1.1015	Cost: 12.05s
Train Epoch: 108 	Average Loss: -0.8914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0101

Learning rate: 0.00017784623015670232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 1.8500	Cost: 31.97s
Train Epoch: 109 [40960/90000 (45%)]	Loss: -1.1734	Cost: 9.46s
Train Epoch: 109 [81920/90000 (91%)]	Loss: -1.3054	Cost: 11.96s
Train Epoch: 109 	Average Loss: -0.8632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8923

Learning rate: 0.00017745030601987337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 1.3742	Cost: 32.68s
Train Epoch: 110 [40960/90000 (45%)]	Loss: -1.1235	Cost: 9.47s
Train Epoch: 110 [81920/90000 (91%)]	Loss: -1.1823	Cost: 12.38s
Train Epoch: 110 	Average Loss: -0.9217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7745

Learning rate: 0.0001770513242775789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 1.1413	Cost: 32.13s
Train Epoch: 111 [40960/90000 (45%)]	Loss: -1.1420	Cost: 9.48s
Train Epoch: 111 [81920/90000 (91%)]	Loss: -1.4074	Cost: 13.02s
Train Epoch: 111 	Average Loss: -0.9054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8417

Learning rate: 0.00017664930068093498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 1.3842	Cost: 31.47s
Train Epoch: 112 [40960/90000 (45%)]	Loss: -1.3597	Cost: 9.46s
Train Epoch: 112 [81920/90000 (91%)]	Loss: -1.4470	Cost: 13.20s
Train Epoch: 112 	Average Loss: -1.0427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6408

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Learning rate: 0.0001762442511011448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 1.5840	Cost: 31.21s
Train Epoch: 113 [40960/90000 (45%)]	Loss: -1.2304	Cost: 9.47s
Train Epoch: 113 [81920/90000 (91%)]	Loss: -1.4277	Cost: 11.78s
Train Epoch: 113 	Average Loss: -1.1108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8047

Learning rate: 0.0001758361915288722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 1.4946	Cost: 32.86s
Train Epoch: 114 [40960/90000 (45%)]	Loss: -1.3038	Cost: 9.46s
Train Epoch: 114 [81920/90000 (91%)]	Loss: -1.5986	Cost: 13.16s
Train Epoch: 114 	Average Loss: -1.1615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6957

Learning rate: 0.0001754251380736104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 1.7619	Cost: 31.95s
Train Epoch: 115 [40960/90000 (45%)]	Loss: -1.3012	Cost: 9.43s
Train Epoch: 115 [81920/90000 (91%)]	Loss: -1.2908	Cost: 12.06s
Train Epoch: 115 	Average Loss: -1.0078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5592

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 1.4259	Cost: 32.47s
Train Epoch: 116 [40960/90000 (45%)]	Loss: -1.2396	Cost: 9.43s
Train Epoch: 116 [81920/90000 (91%)]	Loss: -1.5021	Cost: 12.66s
Train Epoch: 116 	Average Loss: -1.0789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8150

Learning rate: 0.00017459411454241822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 1.4906	Cost: 31.49s
Train Epoch: 117 [40960/90000 (45%)]	Loss: -1.1515	Cost: 9.47s
Train Epoch: 117 [81920/90000 (91%)]	Loss: -1.3928	Cost: 11.78s
Train Epoch: 117 	Average Loss: -1.0684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7768

Learning rate: 0.00017417417727387391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 1.3771	Cost: 31.69s
Train Epoch: 118 [40960/90000 (45%)]	Loss: -1.3321	Cost: 9.50s
Train Epoch: 118 [81920/90000 (91%)]	Loss: -1.5186	Cost: 12.04s
Train Epoch: 118 	Average Loss: -1.1633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5369

Saving model as e118_model.pt & e118_waveforms_supplementary.hdf5
Learning rate: 0.00017375131173581737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 1.9157	Cost: 31.21s
Train Epoch: 119 [40960/90000 (45%)]	Loss: -1.2309	Cost: 9.49s
Train Epoch: 119 [81920/90000 (91%)]	Loss: -1.5014	Cost: 11.81s
Train Epoch: 119 	Average Loss: -1.1594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6599

Learning rate: 0.000173325534622256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 1.4245	Cost: 31.42s
Train Epoch: 120 [40960/90000 (45%)]	Loss: -1.3282	Cost: 9.50s
Train Epoch: 120 [81920/90000 (91%)]	Loss: -1.1087	Cost: 12.16s
Train Epoch: 120 	Average Loss: -1.2243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7457

Learning rate: 0.00017289686274214115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 1.5881	Cost: 32.84s
Train Epoch: 121 [40960/90000 (45%)]	Loss: -1.4909	Cost: 9.51s
Train Epoch: 121 [81920/90000 (91%)]	Loss: -1.5966	Cost: 11.99s
Train Epoch: 121 	Average Loss: -1.1585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5883

Learning rate: 0.00017246531301870466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 1.4055	Cost: 31.02s
Train Epoch: 122 [40960/90000 (45%)]	Loss: -1.3686	Cost: 9.48s
Train Epoch: 122 [81920/90000 (91%)]	Loss: -1.7808	Cost: 12.10s
Train Epoch: 122 	Average Loss: -1.3126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5805

Learning rate: 0.00017203090248879067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 1.5727	Cost: 32.24s
Train Epoch: 123 [40960/90000 (45%)]	Loss: -1.3120	Cost: 9.48s
Train Epoch: 123 [81920/90000 (91%)]	Loss: -1.6865	Cost: 11.89s
Train Epoch: 123 	Average Loss: -1.3509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8038

Learning rate: 0.00017159364830218312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 1.1175	Cost: 32.24s
Train Epoch: 124 [40960/90000 (45%)]	Loss: -1.4822	Cost: 9.44s
Train Epoch: 124 [81920/90000 (91%)]	Loss: -1.6160	Cost: 12.19s
Train Epoch: 124 	Average Loss: -1.3290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7094

Learning rate: 0.00017115356772092854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 1.1988	Cost: 33.08s
Train Epoch: 125 [40960/90000 (45%)]	Loss: -1.7177	Cost: 9.50s
Train Epoch: 125 [81920/90000 (91%)]	Loss: -1.6999	Cost: 12.45s
Train Epoch: 125 	Average Loss: -1.3486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6937

Learning rate: 0.00017071067811865473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 1.4452	Cost: 31.45s
Train Epoch: 126 [40960/90000 (45%)]	Loss: -1.5477	Cost: 9.49s
Train Epoch: 126 [81920/90000 (91%)]	Loss: -1.2668	Cost: 11.96s
Train Epoch: 126 	Average Loss: -1.2575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7083

Learning rate: 0.00017026499697988493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 1.7974	Cost: 31.68s
Train Epoch: 127 [40960/90000 (45%)]	Loss: -1.6907	Cost: 9.52s
Train Epoch: 127 [81920/90000 (91%)]	Loss: -1.6915	Cost: 11.81s
Train Epoch: 127 	Average Loss: -1.2143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5608

Learning rate: 0.00016981654189934727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 1.4938	Cost: 32.53s
Train Epoch: 128 [40960/90000 (45%)]	Loss: -1.3444	Cost: 9.44s
Train Epoch: 128 [81920/90000 (91%)]	Loss: -1.7259	Cost: 12.82s
Train Epoch: 128 	Average Loss: -1.3584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5958

Learning rate: 0.0001693653305812805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 1.5658	Cost: 31.23s
Train Epoch: 129 [40960/90000 (45%)]	Loss: -1.8181	Cost: 9.54s
Train Epoch: 129 [81920/90000 (91%)]	Loss: -1.7594	Cost: 12.06s
Train Epoch: 129 	Average Loss: -1.4372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5206

Saving model as e129_model.pt & e129_waveforms_supplementary.hdf5
Learning rate: 0.00016891138083873484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 1.3780	Cost: 31.08s
Train Epoch: 130 [40960/90000 (45%)]	Loss: -1.9632	Cost: 9.49s
Train Epoch: 130 [81920/90000 (91%)]	Loss: -2.0586	Cost: 11.80s
Train Epoch: 130 	Average Loss: -1.5448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5038

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 0.00016845471059286887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 1.1545	Cost: 31.79s
Train Epoch: 131 [40960/90000 (45%)]	Loss: -1.8646	Cost: 9.47s
Train Epoch: 131 [81920/90000 (91%)]	Loss: -1.7237	Cost: 12.05s
Train Epoch: 131 	Average Loss: -1.4808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5448

Learning rate: 0.0001679953378722419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 1.2917	Cost: 31.26s
Train Epoch: 132 [40960/90000 (45%)]	Loss: -1.9774	Cost: 9.48s
Train Epoch: 132 [81920/90000 (91%)]	Loss: -1.8560	Cost: 11.90s
Train Epoch: 132 	Average Loss: -1.5317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6255

Learning rate: 0.00016753328081210242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 1.3458	Cost: 33.51s
Train Epoch: 133 [40960/90000 (45%)]	Loss: -1.5376	Cost: 9.40s
Train Epoch: 133 [81920/90000 (91%)]	Loss: -1.7925	Cost: 12.30s
Train Epoch: 133 	Average Loss: -1.3857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5388

Learning rate: 0.000167068557653672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 1.0308	Cost: 31.51s
Train Epoch: 134 [40960/90000 (45%)]	Loss: -1.6565	Cost: 9.48s
Train Epoch: 134 [81920/90000 (91%)]	Loss: -2.0711	Cost: 11.88s
Train Epoch: 134 	Average Loss: -1.4885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5285

Learning rate: 0.00016660118674342514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 1.1212	Cost: 30.89s
Train Epoch: 135 [40960/90000 (45%)]	Loss: -1.8102	Cost: 9.52s
Train Epoch: 135 [81920/90000 (91%)]	Loss: -2.0467	Cost: 11.90s
Train Epoch: 135 	Average Loss: -1.5920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3046

Saving model as e135_model.pt & e135_waveforms_supplementary.hdf5
Learning rate: 0.00016613118653236516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 1.0919	Cost: 31.46s
Train Epoch: 136 [40960/90000 (45%)]	Loss: -1.9972	Cost: 9.49s
Train Epoch: 136 [81920/90000 (91%)]	Loss: -1.8621	Cost: 11.83s
Train Epoch: 136 	Average Loss: -1.7050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4267

Learning rate: 0.0001656585755752956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 1.2560	Cost: 30.76s
Train Epoch: 137 [40960/90000 (45%)]	Loss: -1.9465	Cost: 9.51s
Train Epoch: 137 [81920/90000 (91%)]	Loss: -2.0118	Cost: 13.69s
Train Epoch: 137 	Average Loss: -1.5839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4846

Learning rate: 0.00016518337253008784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 1.4137	Cost: 31.84s
Train Epoch: 138 [40960/90000 (45%)]	Loss: -1.8080	Cost: 9.46s
Train Epoch: 138 [81920/90000 (91%)]	Loss: -2.1768	Cost: 12.37s
Train Epoch: 138 	Average Loss: -1.7324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3838

Learning rate: 0.0001647055961569444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 1.2637	Cost: 31.79s
Train Epoch: 139 [40960/90000 (45%)]	Loss: -2.0035	Cost: 9.47s
Train Epoch: 139 [81920/90000 (91%)]	Loss: -2.1265	Cost: 11.86s
Train Epoch: 139 	Average Loss: -1.7463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5758

Learning rate: 0.0001642252653176584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 1.4643	Cost: 32.51s
Train Epoch: 140 [40960/90000 (45%)]	Loss: -2.0862	Cost: 9.46s
Train Epoch: 140 [81920/90000 (91%)]	Loss: -2.1508	Cost: 12.57s
Train Epoch: 140 	Average Loss: -1.7536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5291

Learning rate: 0.00016374239897486894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 0.8838	Cost: 31.49s
Train Epoch: 141 [40960/90000 (45%)]	Loss: -2.3959	Cost: 9.50s
Train Epoch: 141 [81920/90000 (91%)]	Loss: -2.3875	Cost: 12.04s
Train Epoch: 141 	Average Loss: -1.9505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4797

Learning rate: 0.0001632570161913124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 1.2163	Cost: 31.72s
Train Epoch: 142 [40960/90000 (45%)]	Loss: -2.1013	Cost: 9.49s
Train Epoch: 142 [81920/90000 (91%)]	Loss: -2.0810	Cost: 13.21s
Train Epoch: 142 	Average Loss: -1.8486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5991

Learning rate: 0.00016276913612907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 1.2025	Cost: 32.17s
Train Epoch: 143 [40960/90000 (45%)]	Loss: -2.1996	Cost: 9.45s
Train Epoch: 143 [81920/90000 (91%)]	Loss: -2.2138	Cost: 12.56s
Train Epoch: 143 	Average Loss: -1.7174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5532

Learning rate: 0.00016227877804881122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 1.2925	Cost: 31.08s
Train Epoch: 144 [40960/90000 (45%)]	Loss: -1.9777	Cost: 9.46s
Train Epoch: 144 [81920/90000 (91%)]	Loss: -2.2018	Cost: 12.21s
Train Epoch: 144 	Average Loss: -1.7237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4081

Learning rate: 0.0001617859613090334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 1.7809	Cost: 31.42s
Train Epoch: 145 [40960/90000 (45%)]	Loss: -2.1676	Cost: 9.47s
Train Epoch: 145 [81920/90000 (91%)]	Loss: -2.3656	Cost: 12.25s
Train Epoch: 145 	Average Loss: -1.8739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3517

Learning rate: 0.00016129070536529763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 1.3674	Cost: 31.35s
Train Epoch: 146 [40960/90000 (45%)]	Loss: -2.2215	Cost: 9.48s
Train Epoch: 146 [81920/90000 (91%)]	Loss: -2.3682	Cost: 11.78s
Train Epoch: 146 	Average Loss: -1.9114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3248

Learning rate: 0.00016079302976946053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 1.0960	Cost: 33.44s
Train Epoch: 147 [40960/90000 (45%)]	Loss: -2.1928	Cost: 9.40s
Train Epoch: 147 [81920/90000 (91%)]	Loss: -2.1229	Cost: 12.98s
Train Epoch: 147 	Average Loss: -1.8696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4946

Learning rate: 0.00016029295416890245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 1.3384	Cost: 31.62s
Train Epoch: 148 [40960/90000 (45%)]	Loss: -2.0196	Cost: 9.41s
Train Epoch: 148 [81920/90000 (91%)]	Loss: -2.2979	Cost: 12.17s
Train Epoch: 148 	Average Loss: -1.7865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5949

Learning rate: 0.00015979049830575187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 1.4557	Cost: 33.81s
Train Epoch: 149 [40960/90000 (45%)]	Loss: -2.2326	Cost: 9.40s
Train Epoch: 149 [81920/90000 (91%)]	Loss: -2.3090	Cost: 12.50s
Train Epoch: 149 	Average Loss: -1.8842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4425

Learning rate: 0.00015928568201610592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 0.7936	Cost: 31.47s
Train Epoch: 150 [40960/90000 (45%)]	Loss: -2.3583	Cost: 9.47s
Train Epoch: 150 [81920/90000 (91%)]	Loss: -2.4932	Cost: 11.57s
Train Epoch: 150 	Average Loss: -1.9939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3460

Learning rate: 0.00015877852522924732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 1.1193	Cost: 31.22s
Train Epoch: 151 [40960/90000 (45%)]	Loss: -2.3230	Cost: 9.47s
Train Epoch: 151 [81920/90000 (91%)]	Loss: -2.2869	Cost: 12.09s
Train Epoch: 151 	Average Loss: -2.0158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4362

Learning rate: 0.00015826904796685762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 0.8994	Cost: 31.47s
Train Epoch: 152 [40960/90000 (45%)]	Loss: -2.3991	Cost: 9.49s
Train Epoch: 152 [81920/90000 (91%)]	Loss: -2.1569	Cost: 12.60s
Train Epoch: 152 	Average Loss: -1.9985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5060

Learning rate: 0.00015775727034222675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 1.2221	Cost: 31.63s
Train Epoch: 153 [40960/90000 (45%)]	Loss: -2.1472	Cost: 9.47s
Train Epoch: 153 [81920/90000 (91%)]	Loss: -2.5681	Cost: 12.20s
Train Epoch: 153 	Average Loss: -2.0334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4501

Learning rate: 0.00015724321255945907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 0.6671	Cost: 33.31s
Train Epoch: 154 [40960/90000 (45%)]	Loss: -2.5489	Cost: 9.42s
Train Epoch: 154 [81920/90000 (91%)]	Loss: -2.4488	Cost: 12.41s
Train Epoch: 154 	Average Loss: -2.1007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4313

Learning rate: 0.00015672689491267567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 1.0644	Cost: 32.45s
Train Epoch: 155 [40960/90000 (45%)]	Loss: -2.2927	Cost: 9.46s
Train Epoch: 155 [81920/90000 (91%)]	Loss: -2.2930	Cost: 11.65s
Train Epoch: 155 	Average Loss: -1.9945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7746

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 0.9629	Cost: 31.22s
Train Epoch: 156 [40960/90000 (45%)]	Loss: -2.2858	Cost: 9.48s
Train Epoch: 156 [81920/90000 (91%)]	Loss: -2.2697	Cost: 11.74s
Train Epoch: 156 	Average Loss: -2.0108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3428

Learning rate: 0.00015568756164881882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 0.9307	Cost: 31.42s
Train Epoch: 157 [40960/90000 (45%)]	Loss: -2.4471	Cost: 9.46s
Train Epoch: 157 [81920/90000 (91%)]	Loss: -2.5895	Cost: 11.91s
Train Epoch: 157 	Average Loss: -2.0588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3644

Learning rate: 0.00015516458706284303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 1.3279	Cost: 31.82s
Train Epoch: 158 [40960/90000 (45%)]	Loss: -2.2846	Cost: 9.50s
Train Epoch: 158 [81920/90000 (91%)]	Loss: -2.4474	Cost: 12.34s
Train Epoch: 158 	Average Loss: -1.9493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5060

Learning rate: 0.0001546394346734269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 0.8681	Cost: 32.79s
Train Epoch: 159 [40960/90000 (45%)]	Loss: -2.3206	Cost: 9.45s
Train Epoch: 159 [81920/90000 (91%)]	Loss: -2.3861	Cost: 13.44s
Train Epoch: 159 	Average Loss: -2.0007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4488

Learning rate: 0.00015411212521268755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 1.0618	Cost: 31.79s
Train Epoch: 160 [40960/90000 (45%)]	Loss: -2.4954	Cost: 9.46s
Train Epoch: 160 [81920/90000 (91%)]	Loss: -2.8127	Cost: 12.04s
Train Epoch: 160 	Average Loss: -2.1293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4157

Learning rate: 0.00015358267949789963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 1.0381	Cost: 32.16s
Train Epoch: 161 [40960/90000 (45%)]	Loss: -2.4034	Cost: 9.47s
Train Epoch: 161 [81920/90000 (91%)]	Loss: -2.6754	Cost: 12.04s
Train Epoch: 161 	Average Loss: -2.2067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4543

Learning rate: 0.00015305111843067339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 1.2530	Cost: 31.16s
Train Epoch: 162 [40960/90000 (45%)]	Loss: -2.7608	Cost: 9.51s
Train Epoch: 162 [81920/90000 (91%)]	Loss: -2.4988	Cost: 11.90s
Train Epoch: 162 	Average Loss: -2.2111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3779

Learning rate: 0.00015251746299612957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 1.2265	Cost: 32.05s
Train Epoch: 163 [40960/90000 (45%)]	Loss: -2.6257	Cost: 9.49s
Train Epoch: 163 [81920/90000 (91%)]	Loss: -2.5403	Cost: 12.95s
Train Epoch: 163 	Average Loss: -2.2001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1577

Saving model as e163_model.pt & e163_waveforms_supplementary.hdf5
Learning rate: 0.00015198173426207094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 1.1057	Cost: 31.84s
Train Epoch: 164 [40960/90000 (45%)]	Loss: -2.5498	Cost: 9.50s
Train Epoch: 164 [81920/90000 (91%)]	Loss: -2.8559	Cost: 11.79s
Train Epoch: 164 	Average Loss: -2.2662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4248

Learning rate: 0.00015144395337815067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 0.8046	Cost: 32.43s
Train Epoch: 165 [40960/90000 (45%)]	Loss: -2.6459	Cost: 9.45s
Train Epoch: 165 [81920/90000 (91%)]	Loss: -2.7257	Cost: 13.04s
Train Epoch: 165 	Average Loss: -2.4053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1276

Saving model as e165_model.pt & e165_waveforms_supplementary.hdf5
Learning rate: 0.00015090414157503714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 0.7931	Cost: 31.73s
Train Epoch: 166 [40960/90000 (45%)]	Loss: -2.5588	Cost: 9.45s
Train Epoch: 166 [81920/90000 (91%)]	Loss: -2.6611	Cost: 13.05s
Train Epoch: 166 	Average Loss: -2.3468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2694

Learning rate: 0.00015036232016357607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 1.0676	Cost: 31.73s
Train Epoch: 167 [40960/90000 (45%)]	Loss: -2.8643	Cost: 9.46s
Train Epoch: 167 [81920/90000 (91%)]	Loss: -2.9400	Cost: 13.36s
Train Epoch: 167 	Average Loss: -2.3455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3325

Learning rate: 0.00014981851053394907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 0.7593	Cost: 32.20s
Train Epoch: 168 [40960/90000 (45%)]	Loss: -2.6158	Cost: 9.47s
Train Epoch: 168 [81920/90000 (91%)]	Loss: -2.6655	Cost: 12.61s
Train Epoch: 168 	Average Loss: -2.3890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2402

Learning rate: 0.00014927273415482915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 0.9180	Cost: 31.22s
Train Epoch: 169 [40960/90000 (45%)]	Loss: -2.7142	Cost: 9.47s
Train Epoch: 169 [81920/90000 (91%)]	Loss: -2.9105	Cost: 11.78s
Train Epoch: 169 	Average Loss: -2.4218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2726

Learning rate: 0.00014872501257253323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 0.8279	Cost: 31.99s
Train Epoch: 170 [40960/90000 (45%)]	Loss: -2.8198	Cost: 9.43s
Train Epoch: 170 [81920/90000 (91%)]	Loss: -3.1480	Cost: 13.06s
Train Epoch: 170 	Average Loss: -2.5045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3235

Learning rate: 0.00014817536741017152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 0.6620	Cost: 30.91s
Train Epoch: 171 [40960/90000 (45%)]	Loss: -3.1465	Cost: 9.47s
Train Epoch: 171 [81920/90000 (91%)]	Loss: -2.9641	Cost: 11.75s
Train Epoch: 171 	Average Loss: -2.6186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3678

Learning rate: 0.0001476238203667939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 0.7440	Cost: 31.76s
Train Epoch: 172 [40960/90000 (45%)]	Loss: -2.6874	Cost: 9.46s
Train Epoch: 172 [81920/90000 (91%)]	Loss: -2.7053	Cost: 11.65s
Train Epoch: 172 	Average Loss: -2.4082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2019

Learning rate: 0.00014707039321653327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 0.9044	Cost: 31.55s
Train Epoch: 173 [40960/90000 (45%)]	Loss: -2.8987	Cost: 9.49s
Train Epoch: 173 [81920/90000 (91%)]	Loss: -2.7313	Cost: 12.92s
Train Epoch: 173 	Average Loss: -2.4698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2719

Learning rate: 0.00014651510780774586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 1.0035	Cost: 31.46s
Train Epoch: 174 [40960/90000 (45%)]	Loss: -2.7266	Cost: 9.48s
Train Epoch: 174 [81920/90000 (91%)]	Loss: -2.8133	Cost: 11.89s
Train Epoch: 174 	Average Loss: -2.4411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4387

Learning rate: 0.00014595798606214882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 0.8962	Cost: 31.49s
Train Epoch: 175 [40960/90000 (45%)]	Loss: -2.8598	Cost: 9.46s
Train Epoch: 175 [81920/90000 (91%)]	Loss: -3.0381	Cost: 12.40s
Train Epoch: 175 	Average Loss: -2.4693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2766

Learning rate: 0.00014539904997395468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 0.4127	Cost: 31.13s
Train Epoch: 176 [40960/90000 (45%)]	Loss: -2.8826	Cost: 9.48s
Train Epoch: 176 [81920/90000 (91%)]	Loss: -3.0529	Cost: 11.93s
Train Epoch: 176 	Average Loss: -2.5409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2057

Learning rate: 0.00014483832160900326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 0.8364	Cost: 31.43s
Train Epoch: 177 [40960/90000 (45%)]	Loss: -3.0450	Cost: 9.48s
Train Epoch: 177 [81920/90000 (91%)]	Loss: -3.0359	Cost: 11.87s
Train Epoch: 177 	Average Loss: -2.5850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3299

Learning rate: 0.00014427582310389016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 0.5848	Cost: 32.11s
Train Epoch: 178 [40960/90000 (45%)]	Loss: -3.0108	Cost: 9.49s
Train Epoch: 178 [81920/90000 (91%)]	Loss: -3.1874	Cost: 12.17s
Train Epoch: 178 	Average Loss: -2.6441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1454

Learning rate: 0.0001437115766650933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 0.8812	Cost: 32.75s
Train Epoch: 179 [40960/90000 (45%)]	Loss: -2.9232	Cost: 9.51s
Train Epoch: 179 [81920/90000 (91%)]	Loss: -3.1366	Cost: 12.30s
Train Epoch: 179 	Average Loss: -2.6842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2248

Learning rate: 0.0001431456045680959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 0.8085	Cost: 31.98s
Train Epoch: 180 [40960/90000 (45%)]	Loss: -2.9485	Cost: 9.49s
Train Epoch: 180 [81920/90000 (91%)]	Loss: -3.0754	Cost: 12.19s
Train Epoch: 180 	Average Loss: -2.7028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2124

Learning rate: 0.00014257792915650726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 0.5803	Cost: 31.01s
Train Epoch: 181 [40960/90000 (45%)]	Loss: -3.1095	Cost: 9.45s
Train Epoch: 181 [81920/90000 (91%)]	Loss: -3.2144	Cost: 12.64s
Train Epoch: 181 	Average Loss: -2.7867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2043

Learning rate: 0.0001420085728411806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 0.6385	Cost: 31.31s
Train Epoch: 182 [40960/90000 (45%)]	Loss: -3.1518	Cost: 9.48s
Train Epoch: 182 [81920/90000 (91%)]	Loss: -3.0636	Cost: 11.89s
Train Epoch: 182 	Average Loss: -2.7458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2619

Learning rate: 0.0001414375580993284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 0.8364	Cost: 32.53s
Train Epoch: 183 [40960/90000 (45%)]	Loss: -3.2153	Cost: 9.41s
Train Epoch: 183 [81920/90000 (91%)]	Loss: -3.0834	Cost: 11.91s
Train Epoch: 183 	Average Loss: -2.7386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1840

Learning rate: 0.00014086490747363488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 0.8096	Cost: 31.34s
Train Epoch: 184 [40960/90000 (45%)]	Loss: -3.1922	Cost: 9.48s
Train Epoch: 184 [81920/90000 (91%)]	Loss: -3.1098	Cost: 12.62s
Train Epoch: 184 	Average Loss: -2.7967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2640

Learning rate: 0.00014029064357136623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 0.8529	Cost: 32.89s
Train Epoch: 185 [40960/90000 (45%)]	Loss: -3.1834	Cost: 9.45s
Train Epoch: 185 [81920/90000 (91%)]	Loss: -3.1119	Cost: 12.40s
Train Epoch: 185 	Average Loss: -2.7279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1566

Learning rate: 0.00013971478906347803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 0.9085	Cost: 31.23s
Train Epoch: 186 [40960/90000 (45%)]	Loss: -3.2532	Cost: 9.49s
Train Epoch: 186 [81920/90000 (91%)]	Loss: -2.8793	Cost: 12.15s
Train Epoch: 186 	Average Loss: -2.7369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5253

Learning rate: 0.0001391373666837202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 0.8829	Cost: 31.20s
Train Epoch: 187 [40960/90000 (45%)]	Loss: -2.9352	Cost: 9.49s
Train Epoch: 187 [81920/90000 (91%)]	Loss: -2.9124	Cost: 12.56s
Train Epoch: 187 	Average Loss: -2.5566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3904

Learning rate: 0.0001385583992277396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 0.9555	Cost: 30.91s
Train Epoch: 188 [40960/90000 (45%)]	Loss: -3.1452	Cost: 9.47s
Train Epoch: 188 [81920/90000 (91%)]	Loss: -3.3219	Cost: 12.33s
Train Epoch: 188 	Average Loss: -2.6754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1522

Learning rate: 0.00013797790955218008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 0.8939	Cost: 31.67s
Train Epoch: 189 [40960/90000 (45%)]	Loss: -3.1179	Cost: 9.46s
Train Epoch: 189 [81920/90000 (91%)]	Loss: -3.2818	Cost: 11.90s
Train Epoch: 189 	Average Loss: -2.8005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1089

Saving model as e189_model.pt & e189_waveforms_supplementary.hdf5
Learning rate: 0.00013739592057378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 0.6123	Cost: 31.19s
Train Epoch: 190 [40960/90000 (45%)]	Loss: -3.2159	Cost: 9.48s
Train Epoch: 190 [81920/90000 (91%)]	Loss: -3.2866	Cost: 11.75s
Train Epoch: 190 	Average Loss: -2.7834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4389

Learning rate: 0.00013681245526846775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 0.9007	Cost: 30.70s
Train Epoch: 191 [40960/90000 (45%)]	Loss: -3.1887	Cost: 9.48s
Train Epoch: 191 [81920/90000 (91%)]	Loss: -3.2629	Cost: 11.86s
Train Epoch: 191 	Average Loss: -2.7736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1153

Learning rate: 0.00013622753667045454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 0.9053	Cost: 31.42s
Train Epoch: 192 [40960/90000 (45%)]	Loss: -3.4093	Cost: 9.48s
Train Epoch: 192 [81920/90000 (91%)]	Loss: -3.5566	Cost: 12.43s
Train Epoch: 192 	Average Loss: -3.0010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3049

Learning rate: 0.00013564118787132503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 0.8962	Cost: 31.06s
Train Epoch: 193 [40960/90000 (45%)]	Loss: -3.3980	Cost: 9.46s
Train Epoch: 193 [81920/90000 (91%)]	Loss: -3.5113	Cost: 11.72s
Train Epoch: 193 	Average Loss: -2.9963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1345

Learning rate: 0.00013505343201912587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 0.5690	Cost: 31.60s
Train Epoch: 194 [40960/90000 (45%)]	Loss: -3.4425	Cost: 9.46s
Train Epoch: 194 [81920/90000 (91%)]	Loss: -3.6020	Cost: 12.05s
Train Epoch: 194 	Average Loss: -3.0701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0557

Saving model as e194_model.pt & e194_waveforms_supplementary.hdf5
Learning rate: 0.0001344642923174517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 0.6733	Cost: 32.54s
Train Epoch: 195 [40960/90000 (45%)]	Loss: -3.5530	Cost: 9.47s
Train Epoch: 195 [81920/90000 (91%)]	Loss: -3.5346	Cost: 12.30s
Train Epoch: 195 	Average Loss: -3.0858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1437

Learning rate: 0.00013387379202452914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 0.5534	Cost: 31.30s
Train Epoch: 196 [40960/90000 (45%)]	Loss: -3.5865	Cost: 9.48s
Train Epoch: 196 [81920/90000 (91%)]	Loss: -3.7150	Cost: 11.90s
Train Epoch: 196 	Average Loss: -3.1439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1048

Learning rate: 0.00013328195445229865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 0.6484	Cost: 31.20s
Train Epoch: 197 [40960/90000 (45%)]	Loss: -3.8030	Cost: 9.49s
Train Epoch: 197 [81920/90000 (91%)]	Loss: -3.6134	Cost: 12.84s
Train Epoch: 197 	Average Loss: -3.1765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1103

Learning rate: 0.00013268880296549425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 0.5950	Cost: 32.46s
Train Epoch: 198 [40960/90000 (45%)]	Loss: -3.5202	Cost: 9.44s
Train Epoch: 198 [81920/90000 (91%)]	Loss: -3.5173	Cost: 12.68s
Train Epoch: 198 	Average Loss: -3.0686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1298

Learning rate: 0.00013209436098072093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 0.8825	Cost: 31.21s
Train Epoch: 199 [40960/90000 (45%)]	Loss: -3.6680	Cost: 9.46s
Train Epoch: 199 [81920/90000 (91%)]	Loss: -3.5047	Cost: 12.23s
Train Epoch: 199 	Average Loss: -3.0340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2048

Learning rate: 0.00013149865196553047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 0.5720	Cost: 30.93s
Train Epoch: 200 [40960/90000 (45%)]	Loss: -3.3503	Cost: 9.48s
Train Epoch: 200 [81920/90000 (91%)]	Loss: -3.6300	Cost: 12.49s
Train Epoch: 200 	Average Loss: -3.0050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1671

Learning rate: 0.00013090169943749474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 0.6058	Cost: 32.05s
Train Epoch: 201 [40960/90000 (45%)]	Loss: -3.7887	Cost: 9.46s
Train Epoch: 201 [81920/90000 (91%)]	Loss: -3.7953	Cost: 12.65s
Train Epoch: 201 	Average Loss: -3.1432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0238

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 0.0001303035269632774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 0.4587	Cost: 30.69s
Train Epoch: 202 [40960/90000 (45%)]	Loss: -3.4989	Cost: 9.45s
Train Epoch: 202 [81920/90000 (91%)]	Loss: -3.6718	Cost: 12.01s
Train Epoch: 202 	Average Loss: -3.2195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0650

Learning rate: 0.00012970415815770348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 1.0501	Cost: 32.55s
Train Epoch: 203 [40960/90000 (45%)]	Loss: -3.6886	Cost: 9.45s
Train Epoch: 203 [81920/90000 (91%)]	Loss: -3.4979	Cost: 11.91s
Train Epoch: 203 	Average Loss: -3.2172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1356

Learning rate: 0.00012910361668282719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 0.7482	Cost: 31.47s
Train Epoch: 204 [40960/90000 (45%)]	Loss: -3.6949	Cost: 9.48s
Train Epoch: 204 [81920/90000 (91%)]	Loss: -3.7479	Cost: 11.84s
Train Epoch: 204 	Average Loss: -3.2898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0179

Saving model as e204_model.pt & e204_waveforms_supplementary.hdf5
Learning rate: 0.0001285019262469976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 0.6268	Cost: 31.55s
Train Epoch: 205 [40960/90000 (45%)]	Loss: -3.6824	Cost: 9.48s
Train Epoch: 205 [81920/90000 (91%)]	Loss: -3.9022	Cost: 11.89s
Train Epoch: 205 	Average Loss: -3.3381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8480

Saving model as e205_model.pt & e205_waveforms_supplementary.hdf5
Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 0.5155	Cost: 32.25s
Train Epoch: 206 [40960/90000 (45%)]	Loss: -3.6065	Cost: 9.49s
Train Epoch: 206 [81920/90000 (91%)]	Loss: -3.6319	Cost: 12.39s
Train Epoch: 206 	Average Loss: -3.3591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9714

Learning rate: 0.00012729519355173254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 0.3469	Cost: 31.82s
Train Epoch: 207 [40960/90000 (45%)]	Loss: -3.6614	Cost: 9.48s
Train Epoch: 207 [81920/90000 (91%)]	Loss: -3.8935	Cost: 11.64s
Train Epoch: 207 	Average Loss: -3.3914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0934

Learning rate: 0.00012669019893203759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 0.3808	Cost: 31.45s
Train Epoch: 208 [40960/90000 (45%)]	Loss: -3.9112	Cost: 9.46s
Train Epoch: 208 [81920/90000 (91%)]	Loss: -3.8473	Cost: 12.57s
Train Epoch: 208 	Average Loss: -3.4065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9392

Learning rate: 0.0001260841506289897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 0.4074	Cost: 31.22s
Train Epoch: 209 [40960/90000 (45%)]	Loss: -3.7212	Cost: 9.46s
Train Epoch: 209 [81920/90000 (91%)]	Loss: -3.7773	Cost: 11.76s
Train Epoch: 209 	Average Loss: -3.3526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1084

Learning rate: 0.00012547707256833825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 0.6261	Cost: 32.53s
Train Epoch: 210 [40960/90000 (45%)]	Loss: -3.6670	Cost: 9.49s
Train Epoch: 210 [81920/90000 (91%)]	Loss: -3.8704	Cost: 11.47s
Train Epoch: 210 	Average Loss: -3.3339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8782

Learning rate: 0.00012486898871648549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 0.1552	Cost: 32.69s
Train Epoch: 211 [40960/90000 (45%)]	Loss: -4.0301	Cost: 9.42s
Train Epoch: 211 [81920/90000 (91%)]	Loss: -3.8581	Cost: 11.77s
Train Epoch: 211 	Average Loss: -3.4833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9699

Learning rate: 0.00012425992307954077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 0.2985	Cost: 32.83s
Train Epoch: 212 [40960/90000 (45%)]	Loss: -3.8023	Cost: 9.48s
Train Epoch: 212 [81920/90000 (91%)]	Loss: -4.0150	Cost: 12.44s
Train Epoch: 212 	Average Loss: -3.4762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8324

Saving model as e212_model.pt & e212_waveforms_supplementary.hdf5
Learning rate: 0.0001236498997023725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 0.6425	Cost: 31.77s
Train Epoch: 213 [40960/90000 (45%)]	Loss: -3.9191	Cost: 9.48s
Train Epoch: 213 [81920/90000 (91%)]	Loss: -3.9461	Cost: 11.97s
Train Epoch: 213 	Average Loss: -3.5250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9488

Learning rate: 0.00012303894266765908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 0.4485	Cost: 31.92s
Train Epoch: 214 [40960/90000 (45%)]	Loss: -3.9272	Cost: 9.47s
Train Epoch: 214 [81920/90000 (91%)]	Loss: -3.8695	Cost: 11.83s
Train Epoch: 214 	Average Loss: -3.4036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1387

Learning rate: 0.00012242707609493814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 0.7354	Cost: 32.61s
Train Epoch: 215 [40960/90000 (45%)]	Loss: -4.0110	Cost: 9.42s
Train Epoch: 215 [81920/90000 (91%)]	Loss: -4.1935	Cost: 12.26s
Train Epoch: 215 	Average Loss: -3.5373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9970

Learning rate: 0.0001218143241396543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 0.0962	Cost: 31.97s
Train Epoch: 216 [40960/90000 (45%)]	Loss: -3.9017	Cost: 9.46s
Train Epoch: 216 [81920/90000 (91%)]	Loss: -3.9632	Cost: 12.73s
Train Epoch: 216 	Average Loss: -3.5035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9573

Learning rate: 0.0001212007109922055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 0.1503	Cost: 31.40s
Train Epoch: 217 [40960/90000 (45%)]	Loss: -3.8000	Cost: 9.50s
Train Epoch: 217 [81920/90000 (91%)]	Loss: -4.0863	Cost: 12.07s
Train Epoch: 217 	Average Loss: -3.5571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8722

Learning rate: 0.00012058626087698816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 0.6431	Cost: 31.20s
Train Epoch: 218 [40960/90000 (45%)]	Loss: -4.0194	Cost: 9.42s
Train Epoch: 218 [81920/90000 (91%)]	Loss: -3.9945	Cost: 12.16s
Train Epoch: 218 	Average Loss: -3.5854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0185

Learning rate: 0.00011997099805144073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 0.6441	Cost: 32.75s
Train Epoch: 219 [40960/90000 (45%)]	Loss: -4.1972	Cost: 9.44s
Train Epoch: 219 [81920/90000 (91%)]	Loss: -4.0947	Cost: 12.31s
Train Epoch: 219 	Average Loss: -3.6166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8058

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 0.00011935494680508606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 0.0035	Cost: 31.04s
Train Epoch: 220 [40960/90000 (45%)]	Loss: -3.9621	Cost: 9.47s
Train Epoch: 220 [81920/90000 (91%)]	Loss: -4.0576	Cost: 12.51s
Train Epoch: 220 	Average Loss: -3.6931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7791

Saving model as e220_model.pt & e220_waveforms_supplementary.hdf5
Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 0.1678	Cost: 32.23s
Train Epoch: 221 [40960/90000 (45%)]	Loss: -3.9081	Cost: 9.46s
Train Epoch: 221 [81920/90000 (91%)]	Loss: -4.0423	Cost: 12.37s
Train Epoch: 221 	Average Loss: -3.6334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8591

Learning rate: 0.00011812057636271377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 0.6479	Cost: 33.19s
Train Epoch: 222 [40960/90000 (45%)]	Loss: -4.2580	Cost: 9.44s
Train Epoch: 222 [81920/90000 (91%)]	Loss: -4.1041	Cost: 12.33s
Train Epoch: 222 	Average Loss: -3.6719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6401

Learning rate: 0.00011750230589752765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 0.9878	Cost: 31.40s
Train Epoch: 223 [40960/90000 (45%)]	Loss: -2.3059	Cost: 9.47s
Train Epoch: 223 [81920/90000 (91%)]	Loss: -2.9005	Cost: 12.11s
Train Epoch: 223 	Average Loss: -2.2152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5123

Learning rate: 0.0001168833444712734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 0.8017	Cost: 31.01s
Train Epoch: 224 [40960/90000 (45%)]	Loss: -3.4389	Cost: 9.45s
Train Epoch: 224 [81920/90000 (91%)]	Loss: -3.7290	Cost: 12.03s
Train Epoch: 224 	Average Loss: -2.9648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0478

Learning rate: 0.00011626371651948839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 0.6406	Cost: 31.80s
Train Epoch: 225 [40960/90000 (45%)]	Loss: -4.1017	Cost: 9.45s
Train Epoch: 225 [81920/90000 (91%)]	Loss: -3.9136	Cost: 11.95s
Train Epoch: 225 	Average Loss: -3.5031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8727

Learning rate: 0.00011564344650402312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 0.2973	Cost: 31.07s
Train Epoch: 226 [40960/90000 (45%)]	Loss: -4.1791	Cost: 9.46s
Train Epoch: 226 [81920/90000 (91%)]	Loss: -4.1529	Cost: 11.60s
Train Epoch: 226 	Average Loss: -3.6501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8485

Learning rate: 0.00011502255891207573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 0.0264	Cost: 32.18s
Train Epoch: 227 [40960/90000 (45%)]	Loss: -4.2622	Cost: 9.44s
Train Epoch: 227 [81920/90000 (91%)]	Loss: -4.4049	Cost: 12.29s
Train Epoch: 227 	Average Loss: -3.7261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9085

Learning rate: 0.00011440107825522525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 0.1253	Cost: 31.55s
Train Epoch: 228 [40960/90000 (45%)]	Loss: -3.9754	Cost: 9.66s
Train Epoch: 228 [81920/90000 (91%)]	Loss: -4.3587	Cost: 11.85s
Train Epoch: 228 	Average Loss: -3.7340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9522

Learning rate: 0.00011377902906846383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 0.2435	Cost: 31.44s
Train Epoch: 229 [40960/90000 (45%)]	Loss: -4.1810	Cost: 9.49s
Train Epoch: 229 [81920/90000 (91%)]	Loss: -4.1495	Cost: 11.72s
Train Epoch: 229 	Average Loss: -3.7501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8306

Learning rate: 0.00011315643590922827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 0.2161	Cost: 31.04s
Train Epoch: 230 [40960/90000 (45%)]	Loss: -4.2244	Cost: 9.49s
Train Epoch: 230 [81920/90000 (91%)]	Loss: -4.3057	Cost: 12.10s
Train Epoch: 230 	Average Loss: -3.8095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8901

Learning rate: 0.00011253332335643043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 0.3491	Cost: 31.86s
Train Epoch: 231 [40960/90000 (45%)]	Loss: -4.3712	Cost: 9.48s
Train Epoch: 231 [81920/90000 (91%)]	Loss: -4.3197	Cost: 11.77s
Train Epoch: 231 	Average Loss: -3.8765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9232

Learning rate: 0.00011190971600948699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 0.2334	Cost: 31.82s
Train Epoch: 232 [40960/90000 (45%)]	Loss: -4.3393	Cost: 9.46s
Train Epoch: 232 [81920/90000 (91%)]	Loss: -4.4322	Cost: 12.20s
Train Epoch: 232 	Average Loss: -3.9149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7885

Learning rate: 0.00011128563848734816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 0.6299	Cost: 31.84s
Train Epoch: 233 [40960/90000 (45%)]	Loss: -4.4194	Cost: 9.48s
Train Epoch: 233 [81920/90000 (91%)]	Loss: -4.4972	Cost: 12.22s
Train Epoch: 233 	Average Loss: -3.9461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9137

Learning rate: 0.000110661115427526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 0.1915	Cost: 32.07s
Train Epoch: 234 [40960/90000 (45%)]	Loss: -4.5990	Cost: 9.53s
Train Epoch: 234 [81920/90000 (91%)]	Loss: -4.4778	Cost: 11.83s
Train Epoch: 234 	Average Loss: -4.0442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7228

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 0.00011003617148512149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: -0.0128	Cost: 31.35s
Train Epoch: 235 [40960/90000 (45%)]	Loss: -4.4146	Cost: 9.50s
Train Epoch: 235 [81920/90000 (91%)]	Loss: -4.5817	Cost: 11.62s
Train Epoch: 235 	Average Loss: -4.0569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9798

Learning rate: 0.00010941083133185143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 0.5091	Cost: 31.70s
Train Epoch: 236 [40960/90000 (45%)]	Loss: -4.4362	Cost: 9.45s
Train Epoch: 236 [81920/90000 (91%)]	Loss: -4.5368	Cost: 13.26s
Train Epoch: 236 	Average Loss: -4.0612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7261

Learning rate: 0.00010878511965507434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 0.2539	Cost: 32.63s
Train Epoch: 237 [40960/90000 (45%)]	Loss: -4.5419	Cost: 9.46s
Train Epoch: 237 [81920/90000 (91%)]	Loss: -4.3527	Cost: 12.27s
Train Epoch: 237 	Average Loss: -4.0353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9401

Learning rate: 0.00010815906115681577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: -0.1078	Cost: 31.10s
Train Epoch: 238 [40960/90000 (45%)]	Loss: -4.3460	Cost: 9.64s
Train Epoch: 238 [81920/90000 (91%)]	Loss: -4.5908	Cost: 11.50s
Train Epoch: 238 	Average Loss: -4.0629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7768

Learning rate: 0.00010753268055279328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 0.3332	Cost: 32.23s
Train Epoch: 239 [40960/90000 (45%)]	Loss: -4.4854	Cost: 9.46s
Train Epoch: 239 [81920/90000 (91%)]	Loss: -4.5980	Cost: 12.17s
Train Epoch: 239 	Average Loss: -4.0852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7697

Learning rate: 0.0001069060025714406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 0.4144	Cost: 32.91s
Train Epoch: 240 [40960/90000 (45%)]	Loss: -4.5249	Cost: 9.48s
Train Epoch: 240 [81920/90000 (91%)]	Loss: -4.6091	Cost: 12.60s
Train Epoch: 240 	Average Loss: -4.1160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7244

Learning rate: 0.00010627905195293134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: -0.1696	Cost: 32.49s
Train Epoch: 241 [40960/90000 (45%)]	Loss: -4.5158	Cost: 9.47s
Train Epoch: 241 [81920/90000 (91%)]	Loss: -4.5761	Cost: 12.91s
Train Epoch: 241 	Average Loss: -4.0882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7246

Learning rate: 0.00010565185344820243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 0.4010	Cost: 31.07s
Train Epoch: 242 [40960/90000 (45%)]	Loss: -4.7039	Cost: 9.47s
Train Epoch: 242 [81920/90000 (91%)]	Loss: -4.4712	Cost: 12.06s
Train Epoch: 242 	Average Loss: -4.1786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7137

Saving model as e242_model.pt & e242_waveforms_supplementary.hdf5
Learning rate: 0.00010502443181797694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 0.7593	Cost: 31.26s
Train Epoch: 243 [40960/90000 (45%)]	Loss: -4.5879	Cost: 9.48s
Train Epoch: 243 [81920/90000 (91%)]	Loss: -4.5169	Cost: 13.27s
Train Epoch: 243 	Average Loss: -4.1585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5734

Saving model as e243_model.pt & e243_waveforms_supplementary.hdf5
Learning rate: 0.00010439681183178646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 0.2658	Cost: 32.06s
Train Epoch: 244 [40960/90000 (45%)]	Loss: -4.5755	Cost: 9.46s
Train Epoch: 244 [81920/90000 (91%)]	Loss: -4.8346	Cost: 12.86s
Train Epoch: 244 	Average Loss: -4.1530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8014

Learning rate: 0.00010376901826699342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 0.3956	Cost: 32.32s
Train Epoch: 245 [40960/90000 (45%)]	Loss: -4.5859	Cost: 9.45s
Train Epoch: 245 [81920/90000 (91%)]	Loss: -4.6563	Cost: 12.38s
Train Epoch: 245 	Average Loss: -4.1600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9328

Learning rate: 0.0001031410759078128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 0.8199	Cost: 32.20s
Train Epoch: 246 [40960/90000 (45%)]	Loss: -4.5922	Cost: 9.46s
Train Epoch: 246 [81920/90000 (91%)]	Loss: -4.5938	Cost: 12.37s
Train Epoch: 246 	Average Loss: -4.1474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8449

Learning rate: 0.00010251300954433372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 0.2176	Cost: 32.20s
Train Epoch: 247 [40960/90000 (45%)]	Loss: -4.6430	Cost: 9.43s
Train Epoch: 247 [81920/90000 (91%)]	Loss: -4.8843	Cost: 12.59s
Train Epoch: 247 	Average Loss: -4.2634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6645

Learning rate: 0.0001018848439715408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 0.3797	Cost: 31.24s
Train Epoch: 248 [40960/90000 (45%)]	Loss: -4.6483	Cost: 9.45s
Train Epoch: 248 [81920/90000 (91%)]	Loss: -4.8493	Cost: 11.87s
Train Epoch: 248 	Average Loss: -4.3154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6854

Learning rate: 0.00010125660398833524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: -0.1873	Cost: 32.08s
Train Epoch: 249 [40960/90000 (45%)]	Loss: -4.8171	Cost: 9.47s
Train Epoch: 249 [81920/90000 (91%)]	Loss: -4.9129	Cost: 12.69s
Train Epoch: 249 	Average Loss: -4.2910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5690

Saving model as e249_model.pt & e249_waveforms_supplementary.hdf5
Learning rate: 0.00010062831439655587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 0.0910	Cost: 31.43s
Train Epoch: 250 [40960/90000 (45%)]	Loss: -4.9731	Cost: 9.47s
Train Epoch: 250 [81920/90000 (91%)]	Loss: -4.8403	Cost: 13.33s
Train Epoch: 250 	Average Loss: -4.3645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8520

Learning rate: 9.999999999999996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 0.1776	Cost: 32.27s
Train Epoch: 251 [40960/90000 (45%)]	Loss: -4.9314	Cost: 9.44s
Train Epoch: 251 [81920/90000 (91%)]	Loss: -4.7907	Cost: 12.95s
Train Epoch: 251 	Average Loss: -4.2975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6534

Learning rate: 9.937168560344407e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 0.4068	Cost: 31.92s
Train Epoch: 252 [40960/90000 (45%)]	Loss: -5.0229	Cost: 9.46s
Train Epoch: 252 [81920/90000 (91%)]	Loss: -4.8343	Cost: 11.62s
Train Epoch: 252 	Average Loss: -4.3534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8041

Learning rate: 9.87433960116647e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 0.2923	Cost: 31.71s
Train Epoch: 253 [40960/90000 (45%)]	Loss: -4.9347	Cost: 9.43s
Train Epoch: 253 [81920/90000 (91%)]	Loss: -5.1125	Cost: 12.79s
Train Epoch: 253 	Average Loss: -4.4061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7414

Learning rate: 9.811515602845915e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: -0.0544	Cost: 31.64s
Train Epoch: 254 [40960/90000 (45%)]	Loss: -4.8176	Cost: 9.47s
Train Epoch: 254 [81920/90000 (91%)]	Loss: -4.9821	Cost: 13.06s
Train Epoch: 254 	Average Loss: -4.3922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7512

Learning rate: 9.748699045566624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: -0.0814	Cost: 32.18s
Train Epoch: 255 [40960/90000 (45%)]	Loss: -4.9220	Cost: 9.64s
Train Epoch: 255 [81920/90000 (91%)]	Loss: -5.1271	Cost: 11.54s
Train Epoch: 255 	Average Loss: -4.4079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5733

Learning rate: 9.685892409218716e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: -0.1644	Cost: 32.19s
Train Epoch: 256 [40960/90000 (45%)]	Loss: -4.9806	Cost: 9.44s
Train Epoch: 256 [81920/90000 (91%)]	Loss: -5.1598	Cost: 12.40s
Train Epoch: 256 	Average Loss: -4.5117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7603

Learning rate: 9.623098173300653e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 0.5175	Cost: 33.03s
Train Epoch: 257 [40960/90000 (45%)]	Loss: -5.0246	Cost: 9.41s
Train Epoch: 257 [81920/90000 (91%)]	Loss: -5.0808	Cost: 13.10s
Train Epoch: 257 	Average Loss: -4.4643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8924

Learning rate: 9.560318816821353e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: -0.0758	Cost: 32.28s
Train Epoch: 258 [40960/90000 (45%)]	Loss: -4.8232	Cost: 9.44s
Train Epoch: 258 [81920/90000 (91%)]	Loss: -4.8245	Cost: 12.28s
Train Epoch: 258 	Average Loss: -4.4826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7562

Learning rate: 9.497556818202306e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 0.1959	Cost: 31.63s
Train Epoch: 259 [40960/90000 (45%)]	Loss: -4.9836	Cost: 9.47s
Train Epoch: 259 [81920/90000 (91%)]	Loss: -4.9888	Cost: 11.95s
Train Epoch: 259 	Average Loss: -4.4791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6988

Learning rate: 9.434814655179755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 0.3030	Cost: 30.87s
Train Epoch: 260 [40960/90000 (45%)]	Loss: -4.8581	Cost: 9.48s
Train Epoch: 260 [81920/90000 (91%)]	Loss: -5.0533	Cost: 13.06s
Train Epoch: 260 	Average Loss: -4.4364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7934

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: -0.0834	Cost: 31.38s
Train Epoch: 261 [40960/90000 (45%)]	Loss: -4.9550	Cost: 9.46s
Train Epoch: 261 [81920/90000 (91%)]	Loss: -4.8569	Cost: 11.70s
Train Epoch: 261 	Average Loss: -4.4128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6711

Learning rate: 9.309399742855944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: -0.0433	Cost: 31.74s
Train Epoch: 262 [40960/90000 (45%)]	Loss: -4.9507	Cost: 9.51s
Train Epoch: 262 [81920/90000 (91%)]	Loss: -5.1735	Cost: 12.02s
Train Epoch: 262 	Average Loss: -4.4963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7945

Learning rate: 9.246731944720672e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: -0.2020	Cost: 31.25s
Train Epoch: 263 [40960/90000 (45%)]	Loss: -5.1390	Cost: 9.50s
Train Epoch: 263 [81920/90000 (91%)]	Loss: -5.0636	Cost: 11.88s
Train Epoch: 263 	Average Loss: -4.4995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6829

Learning rate: 9.184093884318424e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 0.1865	Cost: 31.91s
Train Epoch: 264 [40960/90000 (45%)]	Loss: -5.0943	Cost: 9.47s
Train Epoch: 264 [81920/90000 (91%)]	Loss: -4.9098	Cost: 12.59s
Train Epoch: 264 	Average Loss: -4.5141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8793

Learning rate: 9.121488034492569e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 0.3785	Cost: 32.82s
Train Epoch: 265 [40960/90000 (45%)]	Loss: -5.2663	Cost: 9.56s
Train Epoch: 265 [81920/90000 (91%)]	Loss: -5.0795	Cost: 12.54s
Train Epoch: 265 	Average Loss: -4.6147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7576

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: -0.0686	Cost: 32.81s
Train Epoch: 266 [40960/90000 (45%)]	Loss: -5.1102	Cost: 9.65s
Train Epoch: 266 [81920/90000 (91%)]	Loss: -5.1967	Cost: 12.04s
Train Epoch: 266 	Average Loss: -4.6110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6975

Learning rate: 8.996382851487852e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: -0.4570	Cost: 32.28s
Train Epoch: 267 [40960/90000 (45%)]	Loss: -5.0600	Cost: 9.47s
Train Epoch: 267 [81920/90000 (91%)]	Loss: -5.2094	Cost: 12.36s
Train Epoch: 267 	Average Loss: -4.6291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6575

Learning rate: 8.9338884572474e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 0.4294	Cost: 31.93s
Train Epoch: 268 [40960/90000 (45%)]	Loss: -5.2716	Cost: 9.50s
Train Epoch: 268 [81920/90000 (91%)]	Loss: -5.2037	Cost: 12.37s
Train Epoch: 268 	Average Loss: -4.7129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5642

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Learning rate: 8.871436151265182e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: -0.2711	Cost: 31.27s
Train Epoch: 269 [40960/90000 (45%)]	Loss: -5.4903	Cost: 9.50s
Train Epoch: 269 [81920/90000 (91%)]	Loss: -5.1200	Cost: 12.34s
Train Epoch: 269 	Average Loss: -4.7681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6702

Learning rate: 8.809028399051304e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: -0.1171	Cost: 31.35s
Train Epoch: 270 [40960/90000 (45%)]	Loss: -5.4369	Cost: 9.49s
Train Epoch: 270 [81920/90000 (91%)]	Loss: -5.4225	Cost: 11.96s
Train Epoch: 270 	Average Loss: -4.8380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5913

Learning rate: 8.746667664356958e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 0.5843	Cost: 33.08s
Train Epoch: 271 [40960/90000 (45%)]	Loss: -5.2170	Cost: 9.44s
Train Epoch: 271 [81920/90000 (91%)]	Loss: -5.2143	Cost: 12.20s
Train Epoch: 271 	Average Loss: -4.7490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7242

Learning rate: 8.684356409077174e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: -0.0327	Cost: 32.07s
Train Epoch: 272 [40960/90000 (45%)]	Loss: -5.1559	Cost: 9.47s
Train Epoch: 272 [81920/90000 (91%)]	Loss: -5.0819	Cost: 12.83s
Train Epoch: 272 	Average Loss: -4.6252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7705

Learning rate: 8.622097093153619e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 0.1027	Cost: 31.93s
Train Epoch: 273 [40960/90000 (45%)]	Loss: -5.2006	Cost: 9.51s
Train Epoch: 273 [81920/90000 (91%)]	Loss: -5.3242	Cost: 12.34s
Train Epoch: 273 	Average Loss: -4.7422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5499

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 8.559892174477476e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: -0.3586	Cost: 30.86s
Train Epoch: 274 [40960/90000 (45%)]	Loss: -5.3435	Cost: 9.50s
Train Epoch: 274 [81920/90000 (91%)]	Loss: -5.6082	Cost: 12.53s
Train Epoch: 274 	Average Loss: -4.8954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6241

Learning rate: 8.497744108792427e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: -0.0393	Cost: 31.00s
Train Epoch: 275 [40960/90000 (45%)]	Loss: -5.4998	Cost: 9.47s
Train Epoch: 275 [81920/90000 (91%)]	Loss: -5.5906	Cost: 12.42s
Train Epoch: 275 	Average Loss: -4.8739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6554

Learning rate: 8.435655349597689e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: -0.4465	Cost: 31.81s
Train Epoch: 276 [40960/90000 (45%)]	Loss: -5.6575	Cost: 9.44s
Train Epoch: 276 [81920/90000 (91%)]	Loss: -5.4501	Cost: 12.04s
Train Epoch: 276 	Average Loss: -4.8875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5745

Learning rate: 8.373628348051162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: -0.1071	Cost: 32.13s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -5.5616	Cost: 9.47s
Train Epoch: 277 [81920/90000 (91%)]	Loss: -5.5159	Cost: 12.17s
Train Epoch: 277 	Average Loss: -4.8958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6188

Learning rate: 8.311665552872659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 0.2555	Cost: 31.56s
Train Epoch: 278 [40960/90000 (45%)]	Loss: -5.5768	Cost: 9.47s
Train Epoch: 278 [81920/90000 (91%)]	Loss: -5.5880	Cost: 12.20s
Train Epoch: 278 	Average Loss: -4.9951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4309

Saving model as e278_model.pt & e278_waveforms_supplementary.hdf5
Learning rate: 8.249769410247239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: -0.5393	Cost: 31.91s
Train Epoch: 279 [40960/90000 (45%)]	Loss: -5.7800	Cost: 9.45s
Train Epoch: 279 [81920/90000 (91%)]	Loss: -5.6986	Cost: 11.83s
Train Epoch: 279 	Average Loss: -5.1089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5399

Learning rate: 8.187942363728625e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: -0.1811	Cost: 32.12s
Train Epoch: 280 [40960/90000 (45%)]	Loss: -5.7606	Cost: 9.47s
Train Epoch: 280 [81920/90000 (91%)]	Loss: -5.4457	Cost: 11.78s
Train Epoch: 280 	Average Loss: -4.9752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5400

Learning rate: 8.126186854142752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: -0.3085	Cost: 31.34s
Train Epoch: 281 [40960/90000 (45%)]	Loss: -5.6086	Cost: 9.49s
Train Epoch: 281 [81920/90000 (91%)]	Loss: -5.5862	Cost: 11.89s
Train Epoch: 281 	Average Loss: -4.9656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4719

Learning rate: 8.064505319491398e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: -0.4085	Cost: 32.14s
Train Epoch: 282 [40960/90000 (45%)]	Loss: -5.4671	Cost: 9.69s
Train Epoch: 282 [81920/90000 (91%)]	Loss: -5.6923	Cost: 11.78s
Train Epoch: 282 	Average Loss: -5.0243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3697

Saving model as e282_model.pt & e282_waveforms_supplementary.hdf5
Learning rate: 8.002900194855929e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: -0.0512	Cost: 32.57s
Train Epoch: 283 [40960/90000 (45%)]	Loss: -5.6080	Cost: 9.48s
Train Epoch: 283 [81920/90000 (91%)]	Loss: -5.7885	Cost: 12.56s
Train Epoch: 283 	Average Loss: -5.1151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2554

Saving model as e283_model.pt & e283_waveforms_supplementary.hdf5
Learning rate: 7.941373912301183e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: -0.5785	Cost: 31.29s
Train Epoch: 284 [40960/90000 (45%)]	Loss: -5.7165	Cost: 9.46s
Train Epoch: 284 [81920/90000 (91%)]	Loss: -5.8662	Cost: 12.93s
Train Epoch: 284 	Average Loss: -5.1316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2319

Saving model as e284_model.pt & e284_waveforms_supplementary.hdf5
Learning rate: 7.879928900779452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: -0.1669	Cost: 31.85s
Train Epoch: 285 [40960/90000 (45%)]	Loss: -5.7984	Cost: 9.46s
Train Epoch: 285 [81920/90000 (91%)]	Loss: -5.8103	Cost: 12.46s
Train Epoch: 285 	Average Loss: -5.1614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5468

Learning rate: 7.818567586034573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: -0.6583	Cost: 31.83s
Train Epoch: 286 [40960/90000 (45%)]	Loss: -5.4268	Cost: 9.44s
Train Epoch: 286 [81920/90000 (91%)]	Loss: -5.6506	Cost: 13.00s
Train Epoch: 286 	Average Loss: -5.1177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5208

Learning rate: 7.757292390506185e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: -0.2206	Cost: 31.05s
Train Epoch: 287 [40960/90000 (45%)]	Loss: -5.6873	Cost: 9.47s
Train Epoch: 287 [81920/90000 (91%)]	Loss: -5.8066	Cost: 11.80s
Train Epoch: 287 	Average Loss: -5.1368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3418

Learning rate: 7.696105733234094e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: -0.0483	Cost: 32.06s
Train Epoch: 288 [40960/90000 (45%)]	Loss: -5.7408	Cost: 9.49s
Train Epoch: 288 [81920/90000 (91%)]	Loss: -5.7669	Cost: 13.16s
Train Epoch: 288 	Average Loss: -5.1453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6081

Learning rate: 7.635010029762752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: -0.4469	Cost: 31.74s
Train Epoch: 289 [40960/90000 (45%)]	Loss: -6.0301	Cost: 9.54s
Train Epoch: 289 [81920/90000 (91%)]	Loss: -5.7213	Cost: 12.19s
Train Epoch: 289 	Average Loss: -5.2748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4322

Learning rate: 7.574007692045924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: -0.2826	Cost: 31.57s
Train Epoch: 290 [40960/90000 (45%)]	Loss: -6.0065	Cost: 9.51s
Train Epoch: 290 [81920/90000 (91%)]	Loss: -5.8439	Cost: 12.00s
Train Epoch: 290 	Average Loss: -5.3055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3683

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: -0.2102	Cost: 31.26s
Train Epoch: 291 [40960/90000 (45%)]	Loss: -6.0758	Cost: 9.47s
Train Epoch: 291 [81920/90000 (91%)]	Loss: -5.9847	Cost: 13.39s
Train Epoch: 291 	Average Loss: -5.3888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3210

Learning rate: 7.452292743166178e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: -0.8996	Cost: 32.61s
Train Epoch: 292 [40960/90000 (45%)]	Loss: -5.8301	Cost: 9.44s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -5.7290	Cost: 12.04s
Train Epoch: 292 	Average Loss: -5.4110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3716

Learning rate: 7.391584937101029e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: -0.4914	Cost: 32.28s
Train Epoch: 293 [40960/90000 (45%)]	Loss: -5.8165	Cost: 9.42s
Train Epoch: 293 [81920/90000 (91%)]	Loss: -5.6236	Cost: 12.06s
Train Epoch: 293 	Average Loss: -5.2974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5362

Learning rate: 7.330980106796245e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: -0.1626	Cost: 32.12s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -5.8908	Cost: 9.44s
Train Epoch: 294 [81920/90000 (91%)]	Loss: -5.8466	Cost: 12.22s
Train Epoch: 294 	Average Loss: -5.3303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3183

Learning rate: 7.270480644826745e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: -0.2738	Cost: 31.37s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -5.9723	Cost: 9.44s
Train Epoch: 295 [81920/90000 (91%)]	Loss: -5.8614	Cost: 12.48s
Train Epoch: 295 	Average Loss: -5.3332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2274

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 7.210088939607704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: -0.2764	Cost: 31.10s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -6.0340	Cost: 9.47s
Train Epoch: 296 [81920/90000 (91%)]	Loss: -5.9085	Cost: 11.71s
Train Epoch: 296 	Average Loss: -5.3241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2822

Learning rate: 7.149807375300236e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: -0.5914	Cost: 31.53s
Train Epoch: 297 [40960/90000 (45%)]	Loss: -5.8568	Cost: 9.50s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -5.9158	Cost: 11.84s
Train Epoch: 297 	Average Loss: -5.4616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3828

Learning rate: 7.08963833171728e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: -0.5599	Cost: 31.64s
Train Epoch: 298 [40960/90000 (45%)]	Loss: -5.9173	Cost: 9.47s
Train Epoch: 298 [81920/90000 (91%)]	Loss: -5.8977	Cost: 12.24s
Train Epoch: 298 	Average Loss: -5.3979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4239

Learning rate: 7.029584184229648e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 0.3348	Cost: 31.60s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -5.8783	Cost: 9.48s
Train Epoch: 299 [81920/90000 (91%)]	Loss: -5.8119	Cost: 11.91s
Train Epoch: 299 	Average Loss: -5.4284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4600

Learning rate: 6.969647303672259e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: -0.5945	Cost: 32.29s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -6.0978	Cost: 9.50s
Train Epoch: 300 [81920/90000 (91%)]	Loss: -6.2474	Cost: 11.90s
Train Epoch: 300 	Average Loss: -5.5258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0791

Saving model as e300_model.pt & e300_waveforms_supplementary.hdf5
Learning rate: 6.909830056250523e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: -0.7573	Cost: 31.31s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -6.0488	Cost: 9.52s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -6.1695	Cost: 12.37s
Train Epoch: 301 	Average Loss: -5.5775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2354

Learning rate: 6.850134803446949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: -0.4533	Cost: 31.64s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -6.0852	Cost: 9.48s
Train Epoch: 302 [81920/90000 (91%)]	Loss: -6.2936	Cost: 12.43s
Train Epoch: 302 	Average Loss: -5.6153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4458

Learning rate: 6.790563901927903e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: -0.7289	Cost: 31.40s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -6.0202	Cost: 9.47s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -6.2650	Cost: 12.52s
Train Epoch: 303 	Average Loss: -5.6429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2462

Learning rate: 6.731119703450573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: -0.4589	Cost: 33.32s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -6.2801	Cost: 9.44s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -6.1552	Cost: 12.55s
Train Epoch: 304 	Average Loss: -5.6377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2777

Learning rate: 6.67180455477013e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: -0.2346	Cost: 31.22s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -6.3213	Cost: 9.47s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -6.3224	Cost: 11.87s
Train Epoch: 305 	Average Loss: -5.6242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1357

Learning rate: 6.612620797547083e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: -0.4034	Cost: 31.34s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -6.2068	Cost: 9.51s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -6.1821	Cost: 12.00s
Train Epoch: 306 	Average Loss: -5.6920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2510

Learning rate: 6.553570768254825e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 0.2334	Cost: 31.80s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -6.1890	Cost: 9.46s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -6.3784	Cost: 12.13s
Train Epoch: 307 	Average Loss: -5.5903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2254

Learning rate: 6.494656798087406e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: -0.0347	Cost: 32.64s
Train Epoch: 308 [40960/90000 (45%)]	Loss: -6.3055	Cost: 9.43s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -6.1795	Cost: 12.41s
Train Epoch: 308 	Average Loss: -5.5840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4774

Learning rate: 6.435881212867491e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: -0.4098	Cost: 31.60s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -6.3483	Cost: 9.47s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -6.3481	Cost: 12.52s
Train Epoch: 309 	Average Loss: -5.7213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3087

Learning rate: 6.377246332954541e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: -0.5904	Cost: 32.54s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -6.1641	Cost: 9.47s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -6.2559	Cost: 12.02s
Train Epoch: 310 	Average Loss: -5.7475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4926

Learning rate: 6.318754473153218e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: -0.9318	Cost: 32.25s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -6.3799	Cost: 9.43s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -6.3227	Cost: 12.43s
Train Epoch: 311 	Average Loss: -5.7471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2146

Learning rate: 6.260407942621994e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: -0.7143	Cost: 33.58s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -6.4697	Cost: 9.44s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -6.2957	Cost: 11.82s
Train Epoch: 312 	Average Loss: -5.8019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2824

Learning rate: 6.202209044781987e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: -0.5340	Cost: 31.41s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -6.4177	Cost: 9.48s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -6.3612	Cost: 11.96s
Train Epoch: 313 	Average Loss: -5.7324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1804

Learning rate: 6.144160077226032e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: -0.7319	Cost: 30.88s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -6.3085	Cost: 9.47s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -6.5440	Cost: 13.36s
Train Epoch: 314 	Average Loss: -5.8074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1650

Learning rate: 6.0862633316279744e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: -0.7325	Cost: 31.64s
Train Epoch: 315 [40960/90000 (45%)]	Loss: -6.4321	Cost: 9.47s
Train Epoch: 315 [81920/90000 (91%)]	Loss: -6.4494	Cost: 12.09s
Train Epoch: 315 	Average Loss: -5.8651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2304

Learning rate: 6.028521093652189e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: -0.3863	Cost: 32.03s
Train Epoch: 316 [40960/90000 (45%)]	Loss: -6.4404	Cost: 9.47s
Train Epoch: 316 [81920/90000 (91%)]	Loss: -6.5028	Cost: 12.01s
Train Epoch: 316 	Average Loss: -5.9001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0190

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 5.970935642863369e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: -0.9207	Cost: 31.37s
Train Epoch: 317 [40960/90000 (45%)]	Loss: -6.4550	Cost: 9.46s
Train Epoch: 317 [81920/90000 (91%)]	Loss: -6.3971	Cost: 12.06s
Train Epoch: 317 	Average Loss: -5.9095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2795

Learning rate: 5.9135092526365064e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: -0.7099	Cost: 31.55s
Train Epoch: 318 [40960/90000 (45%)]	Loss: -6.5912	Cost: 9.47s
Train Epoch: 318 [81920/90000 (91%)]	Loss: -6.5884	Cost: 12.61s
Train Epoch: 318 	Average Loss: -5.9529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2822

Learning rate: 5.8562441900671545e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: -0.7155	Cost: 31.77s
Train Epoch: 319 [40960/90000 (45%)]	Loss: -6.2066	Cost: 9.43s
Train Epoch: 319 [81920/90000 (91%)]	Loss: -6.5819	Cost: 11.72s
Train Epoch: 319 	Average Loss: -5.9734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2404

Learning rate: 5.799142715881933e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: -1.2663	Cost: 31.59s
Train Epoch: 320 [40960/90000 (45%)]	Loss: -6.2763	Cost: 9.47s
Train Epoch: 320 [81920/90000 (91%)]	Loss: -6.6284	Cost: 11.85s
Train Epoch: 320 	Average Loss: -5.9935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1379

Learning rate: 5.742207084349269e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: -0.4630	Cost: 32.85s
Train Epoch: 321 [40960/90000 (45%)]	Loss: -6.6063	Cost: 9.45s
Train Epoch: 321 [81920/90000 (91%)]	Loss: -6.4870	Cost: 12.91s
Train Epoch: 321 	Average Loss: -5.9988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1042

Learning rate: 5.68543954319041e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: -1.0743	Cost: 32.91s
Train Epoch: 322 [40960/90000 (45%)]	Loss: -6.5901	Cost: 9.49s
Train Epoch: 322 [81920/90000 (91%)]	Loss: -6.6742	Cost: 11.76s
Train Epoch: 322 	Average Loss: -6.0490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1247

Learning rate: 5.62884233349067e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: -0.4947	Cost: 32.48s
Train Epoch: 323 [40960/90000 (45%)]	Loss: -6.6956	Cost: 9.46s
Train Epoch: 323 [81920/90000 (91%)]	Loss: -6.7701	Cost: 11.88s
Train Epoch: 323 	Average Loss: -6.0459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2540

Learning rate: 5.572417689610984e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: -1.1028	Cost: 32.09s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -6.6266	Cost: 9.49s
Train Epoch: 324 [81920/90000 (91%)]	Loss: -6.3319	Cost: 12.44s
Train Epoch: 324 	Average Loss: -6.0260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5302

Learning rate: 5.516167839099677e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: -0.1774	Cost: 31.51s
Train Epoch: 325 [40960/90000 (45%)]	Loss: -6.3331	Cost: 9.44s
Train Epoch: 325 [81920/90000 (91%)]	Loss: -6.6139	Cost: 12.80s
Train Epoch: 325 	Average Loss: -5.7785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2053

Learning rate: 5.46009500260453e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: -0.7412	Cost: 31.97s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -6.4994	Cost: 9.47s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -6.4364	Cost: 12.47s
Train Epoch: 326 	Average Loss: -5.9966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2012

Learning rate: 5.4042013937851194e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: -0.7677	Cost: 31.88s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -6.7249	Cost: 9.48s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -6.3226	Cost: 12.11s
Train Epoch: 327 	Average Loss: -6.0718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1777

Learning rate: 5.3484892192254136e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: -0.4633	Cost: 32.50s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -6.7792	Cost: 9.42s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -6.3103	Cost: 12.26s
Train Epoch: 328 	Average Loss: -6.0514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0413

Learning rate: 5.292960678346675e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: -0.9140	Cost: 31.93s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -6.7980	Cost: 9.47s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -6.7326	Cost: 12.62s
Train Epoch: 329 	Average Loss: -6.1225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0380

Learning rate: 5.237617963320605e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: -0.8624	Cost: 32.68s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -6.8705	Cost: 9.52s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -6.7343	Cost: 12.24s
Train Epoch: 330 	Average Loss: -6.1964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1230

Learning rate: 5.182463258982848e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: -0.4969	Cost: 31.01s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -6.8438	Cost: 9.48s
Train Epoch: 331 [81920/90000 (91%)]	Loss: -6.8022	Cost: 11.83s
Train Epoch: 331 	Average Loss: -6.1503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0141

Saving model as e331_model.pt & e331_waveforms_supplementary.hdf5
Learning rate: 5.127498742746677e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: -0.5769	Cost: 31.47s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -6.8233	Cost: 9.51s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -6.6617	Cost: 11.99s
Train Epoch: 332 	Average Loss: -6.2254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8374

Saving model as e332_model.pt & e332_waveforms_supplementary.hdf5
Learning rate: 5.07272658451708e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: -0.9017	Cost: 31.76s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -6.7235	Cost: 9.61s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -6.9320	Cost: 12.43s
Train Epoch: 333 	Average Loss: -6.2844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0926

Learning rate: 5.01814894660509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: -0.5679	Cost: 31.73s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -6.7399	Cost: 9.51s
Train Epoch: 334 [81920/90000 (91%)]	Loss: -7.0887	Cost: 12.20s
Train Epoch: 334 	Average Loss: -6.2806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9350

Learning rate: 4.96376798364239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: -0.8733	Cost: 31.83s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -6.8724	Cost: 9.51s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -6.9968	Cost: 11.87s
Train Epoch: 335 	Average Loss: -6.3590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1166

Learning rate: 4.9095858424962844e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: -0.5206	Cost: 31.37s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -7.0017	Cost: 9.47s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -6.9435	Cost: 12.56s
Train Epoch: 336 	Average Loss: -6.3556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9512

Learning rate: 4.855604662184932e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: -0.6269	Cost: 32.05s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -6.9571	Cost: 9.46s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -7.1585	Cost: 12.61s
Train Epoch: 337 	Average Loss: -6.3906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0092

Learning rate: 4.801826573792905e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: -0.7095	Cost: 31.91s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -6.9884	Cost: 9.48s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -7.0125	Cost: 11.84s
Train Epoch: 338 	Average Loss: -6.4138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2073

Learning rate: 4.748253700387039e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: -1.0262	Cost: 32.49s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -6.8974	Cost: 9.47s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -7.0769	Cost: 12.02s
Train Epoch: 339 	Average Loss: -6.4166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1157

Learning rate: 4.694888156932659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: -0.5645	Cost: 31.11s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -7.1063	Cost: 9.46s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -7.0683	Cost: 11.67s
Train Epoch: 340 	Average Loss: -6.4305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9669

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: -0.7519	Cost: 31.04s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -7.0005	Cost: 9.48s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -6.9851	Cost: 11.95s
Train Epoch: 341 	Average Loss: -6.4386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9593

Learning rate: 4.5887874787312395e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: -0.9448	Cost: 31.63s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -7.0273	Cost: 9.48s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -7.1435	Cost: 12.32s
Train Epoch: 342 	Average Loss: -6.5246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8987

Learning rate: 4.536056532657307e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: -1.0407	Cost: 31.40s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -7.0589	Cost: 9.48s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -7.2004	Cost: 12.13s
Train Epoch: 343 	Average Loss: -6.4997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1774

Learning rate: 4.4835412937156955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: -1.0335	Cost: 33.80s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -7.2786	Cost: 9.52s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -7.2652	Cost: 12.37s
Train Epoch: 344 	Average Loss: -6.5687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0491

Learning rate: 4.431243835118117e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: -0.4722	Cost: 31.04s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -7.1606	Cost: 9.45s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -7.2592	Cost: 11.83s
Train Epoch: 345 	Average Loss: -6.5312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9740

Learning rate: 4.379166221478691e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: -1.0199	Cost: 31.88s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -7.2389	Cost: 9.53s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -7.2668	Cost: 12.10s
Train Epoch: 346 	Average Loss: -6.6760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7956

Saving model as e346_model.pt & e346_waveforms_supplementary.hdf5
Learning rate: 4.327310508732435e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: -1.1258	Cost: 31.49s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -7.3872	Cost: 9.54s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -7.2017	Cost: 11.94s
Train Epoch: 347 	Average Loss: -6.6743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9203

Learning rate: 4.275678744054088e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: -1.1837	Cost: 31.12s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -7.2299	Cost: 9.47s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -7.1980	Cost: 12.20s
Train Epoch: 348 	Average Loss: -6.6104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9732

Learning rate: 4.224272965777324e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: -0.9781	Cost: 32.49s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -7.0748	Cost: 9.45s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -7.3581	Cost: 12.44s
Train Epoch: 349 	Average Loss: -6.6892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8216

Learning rate: 4.173095203314239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: -0.8882	Cost: 32.98s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -7.3130	Cost: 9.39s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -7.4357	Cost: 12.70s
Train Epoch: 350 	Average Loss: -6.6932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8794

Learning rate: 4.1221474770752684e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: -1.4151	Cost: 32.45s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -7.2263	Cost: 9.46s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -7.2469	Cost: 12.10s
Train Epoch: 351 	Average Loss: -6.6995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9355

Learning rate: 4.071431798389406e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: -0.9861	Cost: 32.08s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -7.2173	Cost: 9.51s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -7.1803	Cost: 11.99s
Train Epoch: 352 	Average Loss: -6.6471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7997

Learning rate: 4.020950169424814e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: -1.3133	Cost: 31.73s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -7.2351	Cost: 9.52s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -7.4009	Cost: 11.70s
Train Epoch: 353 	Average Loss: -6.7821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8105

Learning rate: 3.970704583109751e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: -1.2780	Cost: 32.73s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -7.2740	Cost: 9.51s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -7.4149	Cost: 12.22s
Train Epoch: 354 	Average Loss: -6.7683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8139

Learning rate: 3.920697023053944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: -0.8134	Cost: 31.68s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -7.3915	Cost: 9.47s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -7.4172	Cost: 11.94s
Train Epoch: 355 	Average Loss: -6.7640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0714

Learning rate: 3.870929463470237e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: -1.3865	Cost: 31.17s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -7.4729	Cost: 9.47s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -7.2739	Cost: 12.59s
Train Epoch: 356 	Average Loss: -6.8210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7427

Saving model as e356_model.pt & e356_waveforms_supplementary.hdf5
Learning rate: 3.821403869096654e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: -0.4682	Cost: 32.64s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -7.5173	Cost: 9.48s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -7.3894	Cost: 12.26s
Train Epoch: 357 	Average Loss: -6.8069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0145

Learning rate: 3.772122195118876e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: -0.6911	Cost: 31.43s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -7.4809	Cost: 9.49s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -7.5892	Cost: 12.08s
Train Epoch: 358 	Average Loss: -6.8149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7954

Learning rate: 3.723086387092996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: -0.9933	Cost: 33.02s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -7.4248	Cost: 9.50s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -7.5507	Cost: 13.18s
Train Epoch: 359 	Average Loss: -6.8973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9151

Learning rate: 3.674298380868755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: -0.9966	Cost: 31.49s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -7.6537	Cost: 9.47s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -7.6266	Cost: 11.99s
Train Epoch: 360 	Average Loss: -6.9246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8222

Learning rate: 3.6257601025131026e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: -1.2036	Cost: 32.74s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -7.5231	Cost: 9.41s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -7.5103	Cost: 12.57s
Train Epoch: 361 	Average Loss: -6.9059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7643

Learning rate: 3.5774734682341595e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: -1.0739	Cost: 31.29s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -7.5113	Cost: 9.50s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -7.4446	Cost: 12.37s
Train Epoch: 362 	Average Loss: -6.9015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7606

Learning rate: 3.529440384305556e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: -0.9592	Cost: 32.24s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -7.4628	Cost: 9.53s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -7.4730	Cost: 12.17s
Train Epoch: 363 	Average Loss: -6.8815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7614

Learning rate: 3.481662746991211e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: -1.0103	Cost: 31.15s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -7.5308	Cost: 9.44s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -7.8258	Cost: 11.89s
Train Epoch: 364 	Average Loss: -6.9735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8721

Learning rate: 3.434142442470437e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: -1.1007	Cost: 32.01s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -7.6541	Cost: 9.47s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -7.6131	Cost: 12.27s
Train Epoch: 365 	Average Loss: -6.9170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9244

Learning rate: 3.3868813467634793e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: -1.1596	Cost: 31.77s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -7.6894	Cost: 9.46s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -7.7936	Cost: 11.86s
Train Epoch: 366 	Average Loss: -7.0037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7651

Learning rate: 3.339881325657484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: -1.2425	Cost: 33.17s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -7.8436	Cost: 9.53s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -7.7188	Cost: 12.48s
Train Epoch: 367 	Average Loss: -7.0829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9348

Learning rate: 3.2931442346328e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: -0.8782	Cost: 32.81s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -7.6306	Cost: 9.47s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -7.8118	Cost: 12.15s
Train Epoch: 368 	Average Loss: -7.1273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9049

Learning rate: 3.246671918789755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: -1.2818	Cost: 31.86s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -7.7436	Cost: 9.47s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -7.7390	Cost: 12.26s
Train Epoch: 369 	Average Loss: -7.1238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6961

Saving model as e369_model.pt & e369_waveforms_supplementary.hdf5
Learning rate: 3.200466212775808e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: -1.0073	Cost: 32.80s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -7.7457	Cost: 9.49s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -7.7283	Cost: 12.27s
Train Epoch: 370 	Average Loss: -7.1419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9236


Let us continue!
Stopping timer.
Training time (including validation): 133634.42519330978 seconds
Saving model
Transfer learning by starting with alpha=0.4!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 33.0138	Cost: 31.50s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 13.8031	Cost: 9.52s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 11.7566	Cost: 11.75s
Train Epoch: 1 	Average Loss: 15.2923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6068

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.0001999980260856137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 11.4536	Cost: 33.12s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 9.8834	Cost: 9.55s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 8.9848	Cost: 12.51s
Train Epoch: 2 	Average Loss: 9.9606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3117

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 9.3848	Cost: 31.95s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 8.1685	Cost: 9.52s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 7.9560	Cost: 12.38s
Train Epoch: 3 	Average Loss: 8.4231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6082

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 7.9635	Cost: 31.66s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 7.3632	Cost: 9.68s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 7.4345	Cost: 11.62s
Train Epoch: 4 	Average Loss: 7.4663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0534

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892833004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 7.4219	Cost: 31.79s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 6.6842	Cost: 9.62s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 6.5051	Cost: 11.48s
Train Epoch: 5 	Average Loss: 6.7716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5449

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 6.8631	Cost: 32.17s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 6.0460	Cost: 9.67s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 5.8442	Cost: 11.95s
Train Epoch: 6 	Average Loss: 6.2099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4248

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 6.7465	Cost: 32.19s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 5.5328	Cost: 10.01s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 5.5736	Cost: 12.11s
Train Epoch: 7 	Average Loss: 5.7488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2393

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 6.2197	Cost: 31.24s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 5.2321	Cost: 9.42s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 5.2678	Cost: 11.85s
Train Epoch: 8 	Average Loss: 5.4776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0054

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019987369566060184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 6.0058	Cost: 30.87s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 5.0443	Cost: 9.43s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 5.4536	Cost: 12.45s
Train Epoch: 9 	Average Loss: 5.2753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1354

Learning rate: 0.00019984015501089758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 6.1713	Cost: 30.84s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 5.0125	Cost: 9.43s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 4.9668	Cost: 11.81s
Train Epoch: 10 	Average Loss: 5.2024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9403

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 6.1035	Cost: 31.59s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 4.7318	Cost: 9.41s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 4.9513	Cost: 12.03s
Train Epoch: 11 	Average Loss: 4.9500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8956

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019976125063612257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 5.7744	Cost: 30.75s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 4.7112	Cost: 9.39s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 4.8043	Cost: 12.72s
Train Epoch: 12 	Average Loss: 4.8314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7614

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019971589002606144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 5.6457	Cost: 31.17s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 4.4495	Cost: 9.38s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 4.5084	Cost: 11.75s
Train Epoch: 13 	Average Loss: 4.6463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8583

Learning rate: 0.00019966659280340303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 5.4901	Cost: 31.57s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 4.4598	Cost: 9.36s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 4.5374	Cost: 12.62s
Train Epoch: 14 	Average Loss: 4.5357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6959

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001996133609143173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 5.4061	Cost: 31.13s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 4.3184	Cost: 9.36s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 4.5852	Cost: 11.82s
Train Epoch: 15 	Average Loss: 4.4895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7371

Learning rate: 0.00019955619646030805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 5.3213	Cost: 31.22s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 4.2557	Cost: 9.38s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 4.4205	Cost: 12.49s
Train Epoch: 16 	Average Loss: 4.4164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6909

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.00019949510169813006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 5.4381	Cost: 31.07s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 3.9789	Cost: 9.42s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 4.3818	Cost: 12.16s
Train Epoch: 17 	Average Loss: 4.3683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8188

Learning rate: 0.00019943007903969992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 5.4594	Cost: 30.89s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 4.1452	Cost: 9.40s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 4.1395	Cost: 12.47s
Train Epoch: 18 	Average Loss: 4.2755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7815

Learning rate: 0.00019936113105200088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 5.3609	Cost: 31.93s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 3.9371	Cost: 9.54s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 3.9589	Cost: 11.62s
Train Epoch: 19 	Average Loss: 4.1364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5445

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.0001992882604569814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 4.8991	Cost: 32.60s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 3.7176	Cost: 9.39s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 4.1608	Cost: 12.11s
Train Epoch: 20 	Average Loss: 3.9924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7208

Learning rate: 0.00019921147013144782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 4.9892	Cost: 32.49s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 3.6776	Cost: 9.35s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 3.6428	Cost: 12.51s
Train Epoch: 21 	Average Loss: 3.9400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4792

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.00019913076310695068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 5.0896	Cost: 31.10s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 3.6719	Cost: 9.40s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 3.9379	Cost: 11.84s
Train Epoch: 22 	Average Loss: 3.8804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6864

Learning rate: 0.00019904614256966512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 5.0847	Cost: 33.06s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 3.4595	Cost: 9.34s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 3.7999	Cost: 12.23s
Train Epoch: 23 	Average Loss: 3.8195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4294

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.0001989576118602651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 5.7848	Cost: 31.37s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 3.7409	Cost: 9.39s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 3.7924	Cost: 11.73s
Train Epoch: 24 	Average Loss: 3.8293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6243

Learning rate: 0.0001988651744737914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 5.1127	Cost: 32.21s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 3.5764	Cost: 9.39s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 3.6684	Cost: 12.19s
Train Epoch: 25 	Average Loss: 3.7986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6170

Learning rate: 0.0001987688340595138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 4.7996	Cost: 31.82s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 3.4429	Cost: 9.38s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 3.6639	Cost: 12.55s
Train Epoch: 26 	Average Loss: 3.6050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6063

Learning rate: 0.00019866859442078683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 5.1703	Cost: 31.58s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 3.4138	Cost: 9.54s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 3.5947	Cost: 11.42s
Train Epoch: 27 	Average Loss: 3.6679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5389

Learning rate: 0.00019856445951489985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 5.5031	Cost: 32.57s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 3.2995	Cost: 9.33s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 3.3705	Cost: 12.43s
Train Epoch: 28 	Average Loss: 3.6015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4859

Learning rate: 0.0001984564334529206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 5.3965	Cost: 31.97s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 3.0249	Cost: 9.38s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 3.4599	Cost: 12.77s
Train Epoch: 29 	Average Loss: 3.4842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5096

Learning rate: 0.00019834452049953302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 5.0308	Cost: 31.33s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 3.1356	Cost: 9.42s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 3.4907	Cost: 12.31s
Train Epoch: 30 	Average Loss: 3.4311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5604

Learning rate: 0.00019822872507286893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 5.1257	Cost: 31.87s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 3.2465	Cost: 9.37s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 3.1105	Cost: 12.54s
Train Epoch: 31 	Average Loss: 3.4451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5030

Learning rate: 0.00019810905174433345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 5.1602	Cost: 32.78s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 3.2995	Cost: 9.45s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 3.2622	Cost: 12.69s
Train Epoch: 32 	Average Loss: 3.4045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4619

Learning rate: 0.00019798550523842474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 5.3510	Cost: 31.31s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 3.2012	Cost: 9.40s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 3.3736	Cost: 12.54s
Train Epoch: 33 	Average Loss: 3.4227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4330

Learning rate: 0.00019785809043254728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 5.1960	Cost: 31.22s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 2.9571	Cost: 9.43s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 3.3474	Cost: 12.00s
Train Epoch: 34 	Average Loss: 3.3879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4213

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019772681235681944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 5.0043	Cost: 31.07s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 3.1316	Cost: 9.39s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 3.2411	Cost: 12.51s
Train Epoch: 35 	Average Loss: 3.3490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4691

Learning rate: 0.00019759167619387482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 5.0176	Cost: 32.60s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 3.0223	Cost: 9.38s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 3.1701	Cost: 12.37s
Train Epoch: 36 	Average Loss: 3.2822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4252

Learning rate: 0.0001974526872786578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 4.9630	Cost: 32.41s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 2.8011	Cost: 9.38s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 3.0936	Cost: 12.45s
Train Epoch: 37 	Average Loss: 3.1940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5182

Learning rate: 0.00019730985109821272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 4.9803	Cost: 31.32s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 2.9999	Cost: 9.41s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 3.1095	Cost: 11.76s
Train Epoch: 38 	Average Loss: 3.2376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3788

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.00019716317329146745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 4.7850	Cost: 32.18s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 2.8987	Cost: 9.36s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 3.1275	Cost: 12.14s
Train Epoch: 39 	Average Loss: 3.2125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4752

Learning rate: 0.00019701265964901062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 4.7987	Cost: 32.29s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 2.8860	Cost: 9.32s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 3.0434	Cost: 12.05s
Train Epoch: 40 	Average Loss: 3.1151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5003

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 4.8593	Cost: 31.30s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 2.9562	Cost: 9.41s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 3.0208	Cost: 11.84s
Train Epoch: 41 	Average Loss: 3.1278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4512

Learning rate: 0.00019670014877624353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 4.7504	Cost: 33.02s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 2.7745	Cost: 9.35s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 3.1084	Cost: 12.48s
Train Epoch: 42 	Average Loss: 3.1121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4168

Learning rate: 0.0001965381638833274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 4.8778	Cost: 31.93s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 2.7132	Cost: 10.04s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 2.9618	Cost: 11.47s
Train Epoch: 43 	Average Loss: 3.0066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3850

Learning rate: 0.000196372367829001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 5.1949	Cost: 31.81s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 2.5691	Cost: 9.42s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 2.7015	Cost: 12.68s
Train Epoch: 44 	Average Loss: 2.9423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6113

Learning rate: 0.00019620276715860861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 4.8527	Cost: 31.42s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 2.9028	Cost: 9.41s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 2.8583	Cost: 11.93s
Train Epoch: 45 	Average Loss: 2.9898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3186

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019602936856769434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 5.2866	Cost: 31.06s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 2.6411	Cost: 9.40s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 2.7024	Cost: 11.86s
Train Epoch: 46 	Average Loss: 2.9351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5614

Learning rate: 0.00019585217890173763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 5.3466	Cost: 33.15s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 2.5617	Cost: 9.40s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 2.7237	Cost: 12.45s
Train Epoch: 47 	Average Loss: 2.9292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4983

Learning rate: 0.0001956712051558831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 4.8067	Cost: 30.92s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 2.7101	Cost: 9.58s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 2.8472	Cost: 12.52s
Train Epoch: 48 	Average Loss: 2.9748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3351

Learning rate: 0.00019548645447466434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 5.1500	Cost: 30.61s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 2.8062	Cost: 9.40s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 2.7109	Cost: 12.12s
Train Epoch: 49 	Average Loss: 2.9419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5361

Learning rate: 0.00019529793415172192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 4.9193	Cost: 31.31s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 2.3533	Cost: 9.38s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 2.8507	Cost: 11.86s
Train Epoch: 50 	Average Loss: 2.9090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6638

Learning rate: 0.0001951056516295154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 4.9908	Cost: 32.40s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 2.5531	Cost: 9.38s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 2.9611	Cost: 12.17s
Train Epoch: 51 	Average Loss: 2.9115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5493

Learning rate: 0.0001949096144990295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 4.8951	Cost: 31.31s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 2.5588	Cost: 9.64s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 2.9048	Cost: 11.49s
Train Epoch: 52 	Average Loss: 2.9689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5018

Learning rate: 0.00019470983049947442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 5.0284	Cost: 32.34s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 2.4206	Cost: 9.39s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 2.6510	Cost: 12.22s
Train Epoch: 53 	Average Loss: 2.9097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3691

Learning rate: 0.00019450630751798048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 4.8554	Cost: 33.35s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 2.4722	Cost: 9.80s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 2.6838	Cost: 12.39s
Train Epoch: 54 	Average Loss: 2.8308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2574

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 0.00019429905358928646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 4.7773	Cost: 30.97s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 2.5387	Cost: 9.37s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 2.7430	Cost: 11.80s
Train Epoch: 55 	Average Loss: 2.7354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3107

Learning rate: 0.00019408807689542257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 5.1135	Cost: 30.82s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 2.5853	Cost: 9.40s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 2.5418	Cost: 12.43s
Train Epoch: 56 	Average Loss: 2.7241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4106

Learning rate: 0.00019387338576538744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 5.0715	Cost: 31.35s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 2.3061	Cost: 9.34s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 2.6861	Cost: 11.64s
Train Epoch: 57 	Average Loss: 2.7246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5931

Learning rate: 0.00019365498867481926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 5.4593	Cost: 32.46s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 2.4875	Cost: 9.36s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 2.5962	Cost: 12.43s
Train Epoch: 58 	Average Loss: 2.7025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5312

Learning rate: 0.00019343289424566122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 5.2720	Cost: 32.73s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 2.0312	Cost: 9.36s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 2.4077	Cost: 12.52s
Train Epoch: 59 	Average Loss: 2.4991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4566

Learning rate: 0.00019320711124582108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 4.9238	Cost: 31.58s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 2.2097	Cost: 9.39s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 2.4809	Cost: 11.83s
Train Epoch: 60 	Average Loss: 2.5702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4560

Learning rate: 0.00019297764858882514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 4.9161	Cost: 30.78s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 2.0905	Cost: 9.41s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 2.3706	Cost: 11.93s
Train Epoch: 61 	Average Loss: 2.5246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4659

Learning rate: 0.00019274451533346612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 4.6749	Cost: 32.20s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 2.0578	Cost: 10.08s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 2.3131	Cost: 11.48s
Train Epoch: 62 	Average Loss: 2.4276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5227

Learning rate: 0.00019250772068344577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 5.1907	Cost: 32.96s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 2.2318	Cost: 9.35s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 2.1212	Cost: 12.49s
Train Epoch: 63 	Average Loss: 2.4045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4982

Learning rate: 0.00019226727398701147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 4.7270	Cost: 30.67s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 2.0488	Cost: 9.42s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 2.1345	Cost: 12.42s
Train Epoch: 64 	Average Loss: 2.3142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3582

Learning rate: 0.00019202318473658702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 5.0577	Cost: 32.85s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 2.0214	Cost: 9.35s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 2.2206	Cost: 12.35s
Train Epoch: 65 	Average Loss: 2.4386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3972

Learning rate: 0.0001917754625683981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 4.7586	Cost: 31.09s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 1.9558	Cost: 9.39s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 2.2348	Cost: 12.27s
Train Epoch: 66 	Average Loss: 2.3909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4903

Learning rate: 0.00019152411726209174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 5.1710	Cost: 31.97s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 2.0087	Cost: 9.37s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 2.2629	Cost: 12.36s
Train Epoch: 67 	Average Loss: 2.3745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4117

Learning rate: 0.00019126915874035028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 4.9359	Cost: 31.49s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 2.0877	Cost: 9.34s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 2.2596	Cost: 12.06s
Train Epoch: 68 	Average Loss: 2.4124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4171

Learning rate: 0.00019101059706849957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 5.1752	Cost: 32.00s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 1.8548	Cost: 9.37s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 2.0972	Cost: 12.66s
Train Epoch: 69 	Average Loss: 2.3130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2986

Learning rate: 0.0001907484424541117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 4.9509	Cost: 32.57s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 1.9874	Cost: 9.40s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 2.2709	Cost: 12.91s
Train Epoch: 70 	Average Loss: 2.3335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4506

Learning rate: 0.00019048270524660196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 5.1167	Cost: 34.64s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 1.9275	Cost: 9.40s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 2.2681	Cost: 12.23s
Train Epoch: 71 	Average Loss: 2.3046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3842

Learning rate: 0.00019021339593682028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 4.7330	Cost: 31.77s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 2.0032	Cost: 9.41s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 1.9837	Cost: 12.83s
Train Epoch: 72 	Average Loss: 2.2725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4006

Learning rate: 0.0001899405251566371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 5.0956	Cost: 30.82s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 1.9167	Cost: 9.40s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 2.0342	Cost: 12.19s
Train Epoch: 73 	Average Loss: 2.2743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2294

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Learning rate: 0.0001896641036785236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 4.6476	Cost: 31.24s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 1.8399	Cost: 9.41s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 2.0325	Cost: 11.93s
Train Epoch: 74 	Average Loss: 2.1979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3955

Learning rate: 0.00018938414241512636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 4.9260	Cost: 30.93s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 1.9514	Cost: 9.42s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 2.0920	Cost: 11.74s
Train Epoch: 75 	Average Loss: 2.2271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4171

Learning rate: 0.00018910065241883677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 4.9521	Cost: 31.66s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 1.9852	Cost: 9.61s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 1.9985	Cost: 11.99s
Train Epoch: 76 	Average Loss: 2.2251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5982

Learning rate: 0.00018881364488135445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 5.0824	Cost: 30.78s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 1.9551	Cost: 9.44s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 1.7218	Cost: 12.78s
Train Epoch: 77 	Average Loss: 2.1236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3862

Learning rate: 0.00018852313113324552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 4.9974	Cost: 32.73s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 1.7823	Cost: 9.41s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 1.9673	Cost: 12.70s
Train Epoch: 78 	Average Loss: 2.1740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4090

Learning rate: 0.00018822912264349534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 5.3636	Cost: 31.56s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 1.6695	Cost: 9.41s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 1.9089	Cost: 12.29s
Train Epoch: 79 	Average Loss: 2.1000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3889

Learning rate: 0.00018793163101905563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 5.2030	Cost: 31.65s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 1.5296	Cost: 9.41s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 2.0177	Cost: 11.85s
Train Epoch: 80 	Average Loss: 2.0569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4233

Learning rate: 0.00018763066800438636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 5.0586	Cost: 31.91s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 1.7353	Cost: 9.39s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 2.0473	Cost: 12.14s
Train Epoch: 81 	Average Loss: 2.0670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4235

Learning rate: 0.000187326245480992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 4.9390	Cost: 32.32s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 1.8216	Cost: 9.38s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 1.7405	Cost: 12.59s
Train Epoch: 82 	Average Loss: 2.0255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3813

Learning rate: 0.00018701837546695256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 4.6244	Cost: 32.54s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 1.5054	Cost: 9.36s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 1.7198	Cost: 12.46s
Train Epoch: 83 	Average Loss: 1.8742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3661

Learning rate: 0.00018670707011644898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 4.8257	Cost: 31.26s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 1.5400	Cost: 9.41s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 1.7175	Cost: 12.03s
Train Epoch: 84 	Average Loss: 1.8812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4178

Learning rate: 0.0001863923417192835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 4.5140	Cost: 31.18s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 1.5164	Cost: 9.60s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 1.7562	Cost: 11.32s
Train Epoch: 85 	Average Loss: 1.9450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3881

Learning rate: 0.00018607420270039436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 4.9706	Cost: 31.79s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 1.5620	Cost: 9.38s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 1.3734	Cost: 12.40s
Train Epoch: 86 	Average Loss: 1.8883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3551

Learning rate: 0.00018575266561936523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 5.0360	Cost: 33.82s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 1.7531	Cost: 9.33s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 1.6492	Cost: 12.58s
Train Epoch: 87 	Average Loss: 1.9752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5733

Learning rate: 0.0001854277431699295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 4.9618	Cost: 32.51s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 1.7501	Cost: 9.53s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 1.6380	Cost: 11.94s
Train Epoch: 88 	Average Loss: 1.9477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4408

Learning rate: 0.0001850994481794692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 4.9319	Cost: 32.22s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 1.3991	Cost: 9.36s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 1.8254	Cost: 12.23s
Train Epoch: 89 	Average Loss: 1.8394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5231

Learning rate: 0.0001847677936085083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 4.7990	Cost: 32.09s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 1.5279	Cost: 9.42s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 1.4464	Cost: 12.35s
Train Epoch: 90 	Average Loss: 1.8157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4488

Learning rate: 0.00018443279255020146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 5.2279	Cost: 31.54s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 1.5487	Cost: 9.45s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 1.5281	Cost: 12.35s
Train Epoch: 91 	Average Loss: 1.9001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3586

Learning rate: 0.00018409445822981687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 4.8401	Cost: 31.19s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 1.3526	Cost: 9.40s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 1.6876	Cost: 11.83s
Train Epoch: 92 	Average Loss: 1.7873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3815

Learning rate: 0.00018375280400421414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 5.1390	Cost: 31.30s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 1.5232	Cost: 9.37s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 1.4932	Cost: 12.85s
Train Epoch: 93 	Average Loss: 1.7431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5260

Learning rate: 0.00018340784336131708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 4.7085	Cost: 32.32s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 1.5192	Cost: 9.39s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 1.4364	Cost: 11.64s
Train Epoch: 94 	Average Loss: 1.7191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4814

Learning rate: 0.00018305958991958124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 5.0155	Cost: 31.89s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 1.3071	Cost: 9.38s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 1.3220	Cost: 12.48s
Train Epoch: 95 	Average Loss: 1.7143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4190

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 4.6861	Cost: 31.06s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 1.0194	Cost: 9.41s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 1.5017	Cost: 11.87s
Train Epoch: 96 	Average Loss: 1.6171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4556

Learning rate: 0.0001823532597628427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 4.6470	Cost: 31.26s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 1.1973	Cost: 9.38s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 1.4866	Cost: 11.84s
Train Epoch: 97 	Average Loss: 1.6789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5656

Learning rate: 0.0001819952109325452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 5.0241	Cost: 30.79s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 1.3044	Cost: 9.33s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 1.5037	Cost: 12.70s
Train Epoch: 98 	Average Loss: 1.7554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3840

Learning rate: 0.00018163392507171837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 5.0593	Cost: 31.39s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 1.1273	Cost: 9.57s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 1.6893	Cost: 11.62s
Train Epoch: 99 	Average Loss: 1.7208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3608

Learning rate: 0.00018126941644330935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 5.3954	Cost: 32.12s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 1.3841	Cost: 9.37s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 1.7396	Cost: 12.48s
Train Epoch: 100 	Average Loss: 1.9515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5372

Learning rate: 0.0001809016994374947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 5.3640	Cost: 31.52s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 1.3785	Cost: 9.38s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 1.4349	Cost: 12.68s
Train Epoch: 101 	Average Loss: 1.7438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2715

Learning rate: 0.00018053078857111214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 4.8515	Cost: 32.11s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 1.2459	Cost: 9.35s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 1.3916	Cost: 13.02s
Train Epoch: 102 	Average Loss: 1.5827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5112

Learning rate: 0.00018015669848708761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 4.8220	Cost: 33.05s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 1.0622	Cost: 9.33s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 1.1176	Cost: 13.07s
Train Epoch: 103 	Average Loss: 1.4472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3550

Learning rate: 0.00017977944395385705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 4.8135	Cost: 31.20s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 0.8351	Cost: 9.38s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 1.2023	Cost: 12.11s
Train Epoch: 104 	Average Loss: 1.4623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2983

Learning rate: 0.00017939903986478347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 4.7286	Cost: 31.59s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 0.9716	Cost: 9.49s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 1.2843	Cost: 12.39s
Train Epoch: 105 	Average Loss: 1.4565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4919

Learning rate: 0.00017901550123756898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 4.9888	Cost: 31.37s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 0.9401	Cost: 9.39s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 1.4076	Cost: 12.10s
Train Epoch: 106 	Average Loss: 1.4198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4524

Learning rate: 0.00017862884321366183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 5.2532	Cost: 32.35s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 0.8933	Cost: 9.38s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 1.2386	Cost: 12.10s
Train Epoch: 107 	Average Loss: 1.5126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5805

Learning rate: 0.00017823908105765875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 5.1528	Cost: 32.21s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 1.0648	Cost: 9.39s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 1.1427	Cost: 12.14s
Train Epoch: 108 	Average Loss: 1.3923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4197

Learning rate: 0.00017784623015670232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 4.8339	Cost: 30.96s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 0.7927	Cost: 9.39s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 1.0946	Cost: 12.71s
Train Epoch: 109 	Average Loss: 1.2543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3262

Learning rate: 0.00017745030601987337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 5.1902	Cost: 32.18s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 0.9560	Cost: 9.52s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 0.8195	Cost: 12.32s
Train Epoch: 110 	Average Loss: 1.3205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1865

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 0.0001770513242775789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 5.1173	Cost: 32.35s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 1.0656	Cost: 9.37s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 0.8788	Cost: 12.51s
Train Epoch: 111 	Average Loss: 1.3222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3003

Learning rate: 0.00017664930068093498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 4.8598	Cost: 32.99s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 0.9757	Cost: 9.36s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 0.9947	Cost: 12.32s
Train Epoch: 112 	Average Loss: 1.3253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2781

Learning rate: 0.0001762442511011448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 4.9296	Cost: 31.47s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 0.6567	Cost: 9.39s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 0.9461	Cost: 12.66s
Train Epoch: 113 	Average Loss: 1.2428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4094

Learning rate: 0.0001758361915288722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 4.5064	Cost: 32.31s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 0.8532	Cost: 9.40s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 0.9519	Cost: 12.85s
Train Epoch: 114 	Average Loss: 1.1912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3750

Learning rate: 0.0001754251380736104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 4.8446	Cost: 32.11s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 0.6329	Cost: 9.36s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 0.9400	Cost: 12.23s
Train Epoch: 115 	Average Loss: 1.0832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5387

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 4.7282	Cost: 30.69s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 0.6922	Cost: 9.39s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 0.7548	Cost: 11.87s
Train Epoch: 116 	Average Loss: 1.1175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3164

Learning rate: 0.00017459411454241822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 4.9761	Cost: 31.30s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 0.5072	Cost: 9.38s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 0.9654	Cost: 11.97s
Train Epoch: 117 	Average Loss: 1.0935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4531

Learning rate: 0.00017417417727387391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 4.7414	Cost: 31.07s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 0.8414	Cost: 9.42s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 1.0535	Cost: 11.70s
Train Epoch: 118 	Average Loss: 1.2177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5253

Learning rate: 0.00017375131173581737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 4.8682	Cost: 32.10s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 0.7889	Cost: 9.43s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 0.7895	Cost: 12.18s
Train Epoch: 119 	Average Loss: 1.0925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4380

Learning rate: 0.000173325534622256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 4.5651	Cost: 33.52s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 0.4522	Cost: 9.41s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 1.0085	Cost: 12.93s
Train Epoch: 120 	Average Loss: 1.0359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6542

Learning rate: 0.00017289686274214115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 5.1552	Cost: 31.16s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 0.6167	Cost: 9.42s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 0.8204	Cost: 12.17s
Train Epoch: 121 	Average Loss: 1.0527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4575

Learning rate: 0.00017246531301870466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 5.0977	Cost: 32.78s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 0.6827	Cost: 9.37s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 1.0423	Cost: 12.61s
Train Epoch: 122 	Average Loss: 1.1212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5545

Learning rate: 0.00017203090248879067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 4.7984	Cost: 32.42s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 0.5660	Cost: 9.39s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 0.7988	Cost: 11.95s
Train Epoch: 123 	Average Loss: 1.0911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5265

Learning rate: 0.00017159364830218312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 5.1611	Cost: 30.99s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 0.4536	Cost: 9.36s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 0.5487	Cost: 12.44s
Train Epoch: 124 	Average Loss: 1.0642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4362

Learning rate: 0.00017115356772092854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 5.2876	Cost: 31.40s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 0.4973	Cost: 9.44s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 0.6388	Cost: 11.99s
Train Epoch: 125 	Average Loss: 0.9786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4580

Learning rate: 0.00017071067811865473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 5.1338	Cost: 30.97s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 0.4577	Cost: 9.43s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 0.7297	Cost: 11.96s
Train Epoch: 126 	Average Loss: 0.8924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4136

Learning rate: 0.00017026499697988493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 5.2766	Cost: 32.46s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 0.2335	Cost: 9.38s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 0.6252	Cost: 12.54s
Train Epoch: 127 	Average Loss: 0.9566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5941

Learning rate: 0.00016981654189934727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 4.8851	Cost: 31.85s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 0.5116	Cost: 9.91s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 0.6985	Cost: 11.38s
Train Epoch: 128 	Average Loss: 1.1053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7296

Learning rate: 0.0001693653305812805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 5.4748	Cost: 31.41s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 0.4656	Cost: 9.35s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 0.6455	Cost: 12.70s
Train Epoch: 129 	Average Loss: 1.0412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4142

Learning rate: 0.00016891138083873484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 4.9020	Cost: 32.09s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 0.4270	Cost: 9.44s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 0.6142	Cost: 12.68s
Train Epoch: 130 	Average Loss: 0.9103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6133

Learning rate: 0.00016845471059286887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 5.0280	Cost: 31.19s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 0.2516	Cost: 9.40s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 0.6309	Cost: 12.03s
Train Epoch: 131 	Average Loss: 0.8441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4382

Learning rate: 0.0001679953378722419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 4.5874	Cost: 31.66s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 0.3481	Cost: 9.39s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 0.4051	Cost: 12.01s
Train Epoch: 132 	Average Loss: 0.8240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5163

Learning rate: 0.00016753328081210242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 5.3103	Cost: 33.11s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 0.2578	Cost: 9.36s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 0.5694	Cost: 12.40s
Train Epoch: 133 	Average Loss: 0.8587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3939

Learning rate: 0.000167068557653672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 4.8924	Cost: 33.38s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 0.1995	Cost: 9.33s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 0.5571	Cost: 12.11s
Train Epoch: 134 	Average Loss: 0.7595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5049

Learning rate: 0.00016660118674342514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 4.5918	Cost: 32.54s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 0.5492	Cost: 9.33s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 0.2891	Cost: 12.20s
Train Epoch: 135 	Average Loss: 0.8055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6491

Learning rate: 0.00016613118653236516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 4.9173	Cost: 32.90s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 0.2145	Cost: 9.39s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 0.2442	Cost: 11.75s
Train Epoch: 136 	Average Loss: 0.6901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4802

Learning rate: 0.0001656585755752956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 5.2218	Cost: 31.01s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 0.0953	Cost: 9.43s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 0.5555	Cost: 11.95s
Train Epoch: 137 	Average Loss: 0.7979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6257

Learning rate: 0.00016518337253008784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 5.2041	Cost: 30.91s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 0.4548	Cost: 9.41s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 0.5574	Cost: 11.81s
Train Epoch: 138 	Average Loss: 0.8999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5547

Learning rate: 0.0001647055961569444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 5.0762	Cost: 32.44s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 0.4110	Cost: 9.31s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 0.6126	Cost: 12.23s
Train Epoch: 139 	Average Loss: 0.8674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6422

Learning rate: 0.0001642252653176584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 5.2268	Cost: 32.00s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 0.4017	Cost: 9.37s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 0.4630	Cost: 11.93s
Train Epoch: 140 	Average Loss: 0.7660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4383

Learning rate: 0.00016374239897486894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 4.8715	Cost: 32.65s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 0.2223	Cost: 9.37s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 0.3617	Cost: 12.68s
Train Epoch: 141 	Average Loss: 0.6466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4784

Learning rate: 0.0001632570161913124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 5.2813	Cost: 33.01s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 0.0171	Cost: 9.33s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 0.2165	Cost: 12.44s
Train Epoch: 142 	Average Loss: 0.5383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6139

Learning rate: 0.00016276913612907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 5.4617	Cost: 32.69s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 0.2685	Cost: 9.36s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 0.5147	Cost: 12.64s
Train Epoch: 143 	Average Loss: 0.6972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4567

Learning rate: 0.00016227877804881122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 4.8844	Cost: 32.98s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 0.0183	Cost: 9.55s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 0.3610	Cost: 11.93s
Train Epoch: 144 	Average Loss: 0.6697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5169

Learning rate: 0.0001617859613090334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 4.6939	Cost: 31.66s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 0.0277	Cost: 9.57s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 0.1214	Cost: 11.62s
Train Epoch: 145 	Average Loss: 0.5736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7335

Learning rate: 0.00016129070536529763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 4.9501	Cost: 31.25s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 0.0406	Cost: 9.63s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 0.2600	Cost: 11.53s
Train Epoch: 146 	Average Loss: 0.7178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5242

Learning rate: 0.00016079302976946053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 4.9344	Cost: 32.01s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 0.1002	Cost: 9.40s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 0.2622	Cost: 12.07s
Train Epoch: 147 	Average Loss: 0.6221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5255

Learning rate: 0.00016029295416890245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 4.7850	Cost: 31.71s
Train Epoch: 148 [40960/90000 (45%)]	Loss: -0.1604	Cost: 9.39s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 0.1040	Cost: 11.95s
Train Epoch: 148 	Average Loss: 0.4988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5517

Learning rate: 0.00015979049830575187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 5.1026	Cost: 31.41s
Train Epoch: 149 [40960/90000 (45%)]	Loss: -0.1774	Cost: 9.40s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 0.2634	Cost: 12.91s
Train Epoch: 149 	Average Loss: 0.4871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6597

Learning rate: 0.00015928568201610592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 4.4820	Cost: 32.14s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 0.0469	Cost: 9.34s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 0.2016	Cost: 12.52s
Train Epoch: 150 	Average Loss: 0.5379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6022

Learning rate: 0.00015877852522924732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 4.5831	Cost: 31.27s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 0.0354	Cost: 9.38s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 0.2314	Cost: 12.09s
Train Epoch: 151 	Average Loss: 0.6229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6551

Learning rate: 0.00015826904796685762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 4.8708	Cost: 32.42s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 0.0942	Cost: 9.37s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 0.0828	Cost: 12.38s
Train Epoch: 152 	Average Loss: 0.5953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6200

Learning rate: 0.00015775727034222675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 5.0940	Cost: 31.43s
Train Epoch: 153 [40960/90000 (45%)]	Loss: -0.1230	Cost: 9.39s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 0.1976	Cost: 12.31s
Train Epoch: 153 	Average Loss: 0.5659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6170

Learning rate: 0.00015724321255945907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 5.0830	Cost: 33.30s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 0.1278	Cost: 9.32s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 0.4418	Cost: 12.55s
Train Epoch: 154 	Average Loss: 0.6506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5920

Learning rate: 0.00015672689491267567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 4.5881	Cost: 32.11s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 0.2706	Cost: 9.40s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 0.2759	Cost: 11.93s
Train Epoch: 155 	Average Loss: 0.5725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5986

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 4.9672	Cost: 32.24s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 0.0494	Cost: 10.00s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 0.0298	Cost: 11.76s
Train Epoch: 156 	Average Loss: 0.5533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5763

Learning rate: 0.00015568756164881882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 5.0503	Cost: 31.12s
Train Epoch: 157 [40960/90000 (45%)]	Loss: -0.2922	Cost: 9.38s
Train Epoch: 157 [81920/90000 (91%)]	Loss: -0.0121	Cost: 12.04s
Train Epoch: 157 	Average Loss: 0.3713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6998

Learning rate: 0.00015516458706284303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 4.7330	Cost: 31.41s
Train Epoch: 158 [40960/90000 (45%)]	Loss: -0.2934	Cost: 9.43s
Train Epoch: 158 [81920/90000 (91%)]	Loss: -0.1531	Cost: 12.76s
Train Epoch: 158 	Average Loss: 0.3234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5772

Learning rate: 0.0001546394346734269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 5.1101	Cost: 31.43s
Train Epoch: 159 [40960/90000 (45%)]	Loss: -0.4224	Cost: 9.42s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 0.0490	Cost: 12.10s
Train Epoch: 159 	Average Loss: 0.2806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4822

Learning rate: 0.00015411212521268755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 4.8601	Cost: 30.46s
Train Epoch: 160 [40960/90000 (45%)]	Loss: -0.5623	Cost: 9.41s
Train Epoch: 160 [81920/90000 (91%)]	Loss: -0.1824	Cost: 11.67s
Train Epoch: 160 	Average Loss: 0.1674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6715

Learning rate: 0.00015358267949789963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 4.7390	Cost: 32.00s
Train Epoch: 161 [40960/90000 (45%)]	Loss: -0.4229	Cost: 9.36s
Train Epoch: 161 [81920/90000 (91%)]	Loss: -0.2409	Cost: 12.59s
Train Epoch: 161 	Average Loss: 0.0888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5651

Learning rate: 0.00015305111843067339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 4.1357	Cost: 31.57s
Train Epoch: 162 [40960/90000 (45%)]	Loss: -0.6595	Cost: 9.38s
Train Epoch: 162 [81920/90000 (91%)]	Loss: -0.1774	Cost: 12.09s
Train Epoch: 162 	Average Loss: 0.0953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5009

Learning rate: 0.00015251746299612957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 5.1385	Cost: 31.40s
Train Epoch: 163 [40960/90000 (45%)]	Loss: -0.5936	Cost: 9.38s
Train Epoch: 163 [81920/90000 (91%)]	Loss: -0.2837	Cost: 12.15s
Train Epoch: 163 	Average Loss: 0.1434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6453

Learning rate: 0.00015198173426207094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 4.6062	Cost: 31.19s
Train Epoch: 164 [40960/90000 (45%)]	Loss: -0.5963	Cost: 9.37s
Train Epoch: 164 [81920/90000 (91%)]	Loss: -0.3152	Cost: 12.70s
Train Epoch: 164 	Average Loss: 0.1406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5889

Learning rate: 0.00015144395337815067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 4.7230	Cost: 33.12s
Train Epoch: 165 [40960/90000 (45%)]	Loss: -0.6022	Cost: 9.35s
Train Epoch: 165 [81920/90000 (91%)]	Loss: -0.2662	Cost: 12.07s
Train Epoch: 165 	Average Loss: 0.0995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6769

Learning rate: 0.00015090414157503714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 5.0490	Cost: 31.53s
Train Epoch: 166 [40960/90000 (45%)]	Loss: -0.5664	Cost: 9.34s
Train Epoch: 166 [81920/90000 (91%)]	Loss: -0.4130	Cost: 12.27s
Train Epoch: 166 	Average Loss: -0.0293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6546

Learning rate: 0.00015036232016357607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 4.8654	Cost: 31.06s
Train Epoch: 167 [40960/90000 (45%)]	Loss: -0.4163	Cost: 9.43s
Train Epoch: 167 [81920/90000 (91%)]	Loss: -0.3615	Cost: 12.74s
Train Epoch: 167 	Average Loss: -0.0320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5032

Learning rate: 0.00014981851053394907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 4.5081	Cost: 32.41s
Train Epoch: 168 [40960/90000 (45%)]	Loss: -0.7155	Cost: 9.59s
Train Epoch: 168 [81920/90000 (91%)]	Loss: -0.5406	Cost: 12.19s
Train Epoch: 168 	Average Loss: -0.0828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6468

Learning rate: 0.00014927273415482915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 4.7552	Cost: 31.76s
Train Epoch: 169 [40960/90000 (45%)]	Loss: -0.6143	Cost: 9.44s
Train Epoch: 169 [81920/90000 (91%)]	Loss: -0.3460	Cost: 11.79s
Train Epoch: 169 	Average Loss: -0.0819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5140

Learning rate: 0.00014872501257253323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 4.6324	Cost: 31.12s
Train Epoch: 170 [40960/90000 (45%)]	Loss: -0.5262	Cost: 9.41s
Train Epoch: 170 [81920/90000 (91%)]	Loss: -0.4681	Cost: 11.72s
Train Epoch: 170 	Average Loss: -0.0045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6932

Learning rate: 0.00014817536741017152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 5.2486	Cost: 31.28s
Train Epoch: 171 [40960/90000 (45%)]	Loss: -0.5612	Cost: 9.39s
Train Epoch: 171 [81920/90000 (91%)]	Loss: -0.4575	Cost: 12.67s
Train Epoch: 171 	Average Loss: -0.0438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5212

Learning rate: 0.0001476238203667939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 4.8723	Cost: 31.95s
Train Epoch: 172 [40960/90000 (45%)]	Loss: -0.5972	Cost: 9.36s
Train Epoch: 172 [81920/90000 (91%)]	Loss: -0.4305	Cost: 12.38s
Train Epoch: 172 	Average Loss: -0.0819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4533

Learning rate: 0.00014707039321653327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 5.0033	Cost: 32.95s
Train Epoch: 173 [40960/90000 (45%)]	Loss: -0.6654	Cost: 9.32s
Train Epoch: 173 [81920/90000 (91%)]	Loss: -0.4641	Cost: 12.43s
Train Epoch: 173 	Average Loss: -0.0808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5917

Learning rate: 0.00014651510780774586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 4.7623	Cost: 31.30s
Train Epoch: 174 [40960/90000 (45%)]	Loss: -0.7394	Cost: 9.41s
Train Epoch: 174 [81920/90000 (91%)]	Loss: -0.5126	Cost: 12.41s
Train Epoch: 174 	Average Loss: -0.1326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5286

Learning rate: 0.00014595798606214882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 5.4602	Cost: 31.35s
Train Epoch: 175 [40960/90000 (45%)]	Loss: -0.7420	Cost: 9.38s
Train Epoch: 175 [81920/90000 (91%)]	Loss: -0.6612	Cost: 12.03s
Train Epoch: 175 	Average Loss: -0.0356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6433

Learning rate: 0.00014539904997395468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 5.1119	Cost: 32.02s
Train Epoch: 176 [40960/90000 (45%)]	Loss: -0.6947	Cost: 9.34s
Train Epoch: 176 [81920/90000 (91%)]	Loss: -0.4453	Cost: 12.48s
Train Epoch: 176 	Average Loss: -0.0573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8413

Learning rate: 0.00014483832160900326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 5.0215	Cost: 32.17s
Train Epoch: 177 [40960/90000 (45%)]	Loss: -0.2980	Cost: 9.33s
Train Epoch: 177 [81920/90000 (91%)]	Loss: -0.1054	Cost: 12.61s
Train Epoch: 177 	Average Loss: 0.2279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5792

Learning rate: 0.00014427582310389016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 4.6171	Cost: 32.95s
Train Epoch: 178 [40960/90000 (45%)]	Loss: -0.6176	Cost: 9.33s
Train Epoch: 178 [81920/90000 (91%)]	Loss: -0.5237	Cost: 12.26s
Train Epoch: 178 	Average Loss: -0.1038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5328

Learning rate: 0.0001437115766650933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 4.8733	Cost: 31.84s
Train Epoch: 179 [40960/90000 (45%)]	Loss: -0.6933	Cost: 9.38s
Train Epoch: 179 [81920/90000 (91%)]	Loss: -0.4346	Cost: 11.76s
Train Epoch: 179 	Average Loss: -0.1491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6830

Learning rate: 0.0001431456045680959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 4.8676	Cost: 31.28s
Train Epoch: 180 [40960/90000 (45%)]	Loss: -0.7492	Cost: 9.36s
Train Epoch: 180 [81920/90000 (91%)]	Loss: -0.5167	Cost: 11.67s
Train Epoch: 180 	Average Loss: -0.1180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7335

Learning rate: 0.00014257792915650726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 4.6458	Cost: 32.50s
Train Epoch: 181 [40960/90000 (45%)]	Loss: -0.9971	Cost: 9.34s
Train Epoch: 181 [81920/90000 (91%)]	Loss: -0.7648	Cost: 12.27s
Train Epoch: 181 	Average Loss: -0.2477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6138

Learning rate: 0.0001420085728411806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 4.9976	Cost: 31.69s
Train Epoch: 182 [40960/90000 (45%)]	Loss: -0.8969	Cost: 9.38s
Train Epoch: 182 [81920/90000 (91%)]	Loss: -0.7351	Cost: 11.92s
Train Epoch: 182 	Average Loss: -0.3181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5065

Learning rate: 0.0001414375580993284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 4.6580	Cost: 32.31s
Train Epoch: 183 [40960/90000 (45%)]	Loss: -0.9962	Cost: 9.37s
Train Epoch: 183 [81920/90000 (91%)]	Loss: -0.8954	Cost: 12.32s
Train Epoch: 183 	Average Loss: -0.4735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5450

Learning rate: 0.00014086490747363488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 4.8769	Cost: 32.67s
Train Epoch: 184 [40960/90000 (45%)]	Loss: -1.1315	Cost: 9.32s
Train Epoch: 184 [81920/90000 (91%)]	Loss: -0.7878	Cost: 12.60s
Train Epoch: 184 	Average Loss: -0.4899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7104

Learning rate: 0.00014029064357136623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 4.8207	Cost: 31.36s
Train Epoch: 185 [40960/90000 (45%)]	Loss: -0.8855	Cost: 9.37s
Train Epoch: 185 [81920/90000 (91%)]	Loss: -0.8441	Cost: 12.14s
Train Epoch: 185 	Average Loss: -0.4532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5460

Learning rate: 0.00013971478906347803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 4.9231	Cost: 33.10s
Train Epoch: 186 [40960/90000 (45%)]	Loss: -1.0036	Cost: 9.30s
Train Epoch: 186 [81920/90000 (91%)]	Loss: -0.8926	Cost: 12.63s
Train Epoch: 186 	Average Loss: -0.4042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7902

Learning rate: 0.0001391373666837202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 4.6918	Cost: 33.29s
Train Epoch: 187 [40960/90000 (45%)]	Loss: -0.9889	Cost: 9.32s
Train Epoch: 187 [81920/90000 (91%)]	Loss: -0.9258	Cost: 12.45s
Train Epoch: 187 	Average Loss: -0.3981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6885

Learning rate: 0.0001385583992277396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 4.6691	Cost: 31.94s
Train Epoch: 188 [40960/90000 (45%)]	Loss: -1.0117	Cost: 9.46s
Train Epoch: 188 [81920/90000 (91%)]	Loss: -0.9370	Cost: 12.01s
Train Epoch: 188 	Average Loss: -0.5022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7187

Learning rate: 0.00013797790955218008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 4.7741	Cost: 31.59s
Train Epoch: 189 [40960/90000 (45%)]	Loss: -1.0162	Cost: 9.42s
Train Epoch: 189 [81920/90000 (91%)]	Loss: -0.8082	Cost: 12.14s
Train Epoch: 189 	Average Loss: -0.5212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7703

Learning rate: 0.00013739592057378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 4.6900	Cost: 32.20s
Train Epoch: 190 [40960/90000 (45%)]	Loss: -1.2187	Cost: 9.35s
Train Epoch: 190 [81920/90000 (91%)]	Loss: -1.1416	Cost: 12.39s
Train Epoch: 190 	Average Loss: -0.5397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6816

Learning rate: 0.00013681245526846775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 4.7475	Cost: 31.70s
Train Epoch: 191 [40960/90000 (45%)]	Loss: -1.1981	Cost: 9.36s
Train Epoch: 191 [81920/90000 (91%)]	Loss: -1.0783	Cost: 12.17s
Train Epoch: 191 	Average Loss: -0.5544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5083

Learning rate: 0.00013622753667045454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 4.9782	Cost: 31.23s
Train Epoch: 192 [40960/90000 (45%)]	Loss: -1.2721	Cost: 9.39s
Train Epoch: 192 [81920/90000 (91%)]	Loss: -1.1472	Cost: 12.60s
Train Epoch: 192 	Average Loss: -0.6004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7353

Learning rate: 0.00013564118787132503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 4.6229	Cost: 32.87s
Train Epoch: 193 [40960/90000 (45%)]	Loss: -1.1143	Cost: 9.37s
Train Epoch: 193 [81920/90000 (91%)]	Loss: -1.0429	Cost: 12.60s
Train Epoch: 193 	Average Loss: -0.5434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5625

Learning rate: 0.00013505343201912587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 4.9850	Cost: 31.35s
Train Epoch: 194 [40960/90000 (45%)]	Loss: -1.0825	Cost: 9.57s
Train Epoch: 194 [81920/90000 (91%)]	Loss: -1.0434	Cost: 11.98s
Train Epoch: 194 	Average Loss: -0.5463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6699

Learning rate: 0.0001344642923174517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 4.6269	Cost: 32.46s
Train Epoch: 195 [40960/90000 (45%)]	Loss: -1.3326	Cost: 9.52s
Train Epoch: 195 [81920/90000 (91%)]	Loss: -1.1936	Cost: 12.41s
Train Epoch: 195 	Average Loss: -0.6468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4736

Learning rate: 0.00013387379202452914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 4.8451	Cost: 31.64s
Train Epoch: 196 [40960/90000 (45%)]	Loss: -1.3371	Cost: 9.37s
Train Epoch: 196 [81920/90000 (91%)]	Loss: -1.1714	Cost: 12.59s
Train Epoch: 196 	Average Loss: -0.6482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6039

Learning rate: 0.00013328195445229865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 4.3310	Cost: 34.42s
Train Epoch: 197 [40960/90000 (45%)]	Loss: -1.5421	Cost: 9.46s
Train Epoch: 197 [81920/90000 (91%)]	Loss: -1.1102	Cost: 12.50s
Train Epoch: 197 	Average Loss: -0.7646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7529

Learning rate: 0.00013268880296549425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 4.8957	Cost: 32.18s
Train Epoch: 198 [40960/90000 (45%)]	Loss: -1.0970	Cost: 9.56s
Train Epoch: 198 [81920/90000 (91%)]	Loss: -1.0357	Cost: 12.22s
Train Epoch: 198 	Average Loss: -0.5378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7708

Learning rate: 0.00013209436098072093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 4.8883	Cost: 31.00s
Train Epoch: 199 [40960/90000 (45%)]	Loss: -1.3590	Cost: 9.40s
Train Epoch: 199 [81920/90000 (91%)]	Loss: -1.0982	Cost: 12.54s
Train Epoch: 199 	Average Loss: -0.6257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6415

Learning rate: 0.00013149865196553047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 4.8738	Cost: 32.67s
Train Epoch: 200 [40960/90000 (45%)]	Loss: -1.4887	Cost: 9.37s
Train Epoch: 200 [81920/90000 (91%)]	Loss: -1.2658	Cost: 12.33s
Train Epoch: 200 	Average Loss: -0.7511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5957

Learning rate: 0.00013090169943749474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 4.4721	Cost: 32.64s
Train Epoch: 201 [40960/90000 (45%)]	Loss: -1.4910	Cost: 9.38s
Train Epoch: 201 [81920/90000 (91%)]	Loss: -1.3632	Cost: 12.43s
Train Epoch: 201 	Average Loss: -0.8020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5882

Learning rate: 0.0001303035269632774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 4.7783	Cost: 32.68s
Train Epoch: 202 [40960/90000 (45%)]	Loss: -1.4707	Cost: 9.33s
Train Epoch: 202 [81920/90000 (91%)]	Loss: -1.2944	Cost: 12.71s
Train Epoch: 202 	Average Loss: -0.7944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6200

Learning rate: 0.00012970415815770348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 4.7568	Cost: 32.58s
Train Epoch: 203 [40960/90000 (45%)]	Loss: -1.3492	Cost: 9.59s
Train Epoch: 203 [81920/90000 (91%)]	Loss: -1.3181	Cost: 12.26s
Train Epoch: 203 	Average Loss: -0.7931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7736

Learning rate: 0.00012910361668282719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 4.5753	Cost: 31.61s
Train Epoch: 204 [40960/90000 (45%)]	Loss: -1.4885	Cost: 9.39s
Train Epoch: 204 [81920/90000 (91%)]	Loss: -1.1669	Cost: 11.98s
Train Epoch: 204 	Average Loss: -0.8432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6268

Learning rate: 0.0001285019262469976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 4.5228	Cost: 31.71s
Train Epoch: 205 [40960/90000 (45%)]	Loss: -1.6215	Cost: 9.36s
Train Epoch: 205 [81920/90000 (91%)]	Loss: -1.2956	Cost: 12.19s
Train Epoch: 205 	Average Loss: -0.9742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6493

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 4.5154	Cost: 31.86s
Train Epoch: 206 [40960/90000 (45%)]	Loss: -1.6399	Cost: 9.37s
Train Epoch: 206 [81920/90000 (91%)]	Loss: -1.5642	Cost: 12.33s
Train Epoch: 206 	Average Loss: -0.9397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4602

Learning rate: 0.00012729519355173254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 4.9602	Cost: 31.10s
Train Epoch: 207 [40960/90000 (45%)]	Loss: -1.5384	Cost: 9.39s
Train Epoch: 207 [81920/90000 (91%)]	Loss: -1.4983	Cost: 12.44s
Train Epoch: 207 	Average Loss: -0.9124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6475

Learning rate: 0.00012669019893203759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 4.6605	Cost: 30.96s
Train Epoch: 208 [40960/90000 (45%)]	Loss: -1.6820	Cost: 9.35s
Train Epoch: 208 [81920/90000 (91%)]	Loss: -1.4396	Cost: 11.90s
Train Epoch: 208 	Average Loss: -0.9491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8290

Learning rate: 0.0001260841506289897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 4.5213	Cost: 33.90s
Train Epoch: 209 [40960/90000 (45%)]	Loss: -1.2623	Cost: 9.31s
Train Epoch: 209 [81920/90000 (91%)]	Loss: -1.3919	Cost: 12.38s
Train Epoch: 209 	Average Loss: -0.8441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6592

Learning rate: 0.00012547707256833825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 4.5910	Cost: 30.74s
Train Epoch: 210 [40960/90000 (45%)]	Loss: -1.8172	Cost: 9.39s
Train Epoch: 210 [81920/90000 (91%)]	Loss: -1.4079	Cost: 12.16s
Train Epoch: 210 	Average Loss: -1.0155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5560

Learning rate: 0.00012486898871648549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 4.7355	Cost: 32.45s
Train Epoch: 211 [40960/90000 (45%)]	Loss: -1.6399	Cost: 9.36s
Train Epoch: 211 [81920/90000 (91%)]	Loss: -1.5730	Cost: 12.15s
Train Epoch: 211 	Average Loss: -1.0702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6922

Learning rate: 0.00012425992307954077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 4.7152	Cost: 30.38s
Train Epoch: 212 [40960/90000 (45%)]	Loss: -1.7554	Cost: 9.41s
Train Epoch: 212 [81920/90000 (91%)]	Loss: -1.3339	Cost: 11.46s
Train Epoch: 212 	Average Loss: -1.0270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7918

Learning rate: 0.0001236498997023725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 4.1756	Cost: 32.16s
Train Epoch: 213 [40960/90000 (45%)]	Loss: -1.8417	Cost: 9.38s
Train Epoch: 213 [81920/90000 (91%)]	Loss: -1.6214	Cost: 12.37s
Train Epoch: 213 	Average Loss: -1.0593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7065

Learning rate: 0.00012303894266765908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 4.5427	Cost: 32.60s
Train Epoch: 214 [40960/90000 (45%)]	Loss: -1.7594	Cost: 9.36s
Train Epoch: 214 [81920/90000 (91%)]	Loss: -1.5532	Cost: 12.36s
Train Epoch: 214 	Average Loss: -1.1182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6320

Learning rate: 0.00012242707609493814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 4.8894	Cost: 31.93s
Train Epoch: 215 [40960/90000 (45%)]	Loss: -1.9656	Cost: 9.38s
Train Epoch: 215 [81920/90000 (91%)]	Loss: -1.5889	Cost: 12.64s
Train Epoch: 215 	Average Loss: -1.1563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6836

Learning rate: 0.0001218143241396543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 4.4477	Cost: 31.49s
Train Epoch: 216 [40960/90000 (45%)]	Loss: -1.7759	Cost: 9.40s
Train Epoch: 216 [81920/90000 (91%)]	Loss: -1.6773	Cost: 12.19s
Train Epoch: 216 	Average Loss: -1.1602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6566

Learning rate: 0.0001212007109922055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 4.4876	Cost: 32.45s
Train Epoch: 217 [40960/90000 (45%)]	Loss: -2.0376	Cost: 9.53s
Train Epoch: 217 [81920/90000 (91%)]	Loss: -1.6379	Cost: 11.95s
Train Epoch: 217 	Average Loss: -1.2039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7176

Learning rate: 0.00012058626087698816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 4.3793	Cost: 31.31s
Train Epoch: 218 [40960/90000 (45%)]	Loss: -1.8911	Cost: 9.42s
Train Epoch: 218 [81920/90000 (91%)]	Loss: -1.8400	Cost: 11.73s
Train Epoch: 218 	Average Loss: -1.2349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7587

Learning rate: 0.00011997099805144073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 4.7634	Cost: 32.39s
Train Epoch: 219 [40960/90000 (45%)]	Loss: -1.7990	Cost: 9.43s
Train Epoch: 219 [81920/90000 (91%)]	Loss: -1.5878	Cost: 12.01s
Train Epoch: 219 	Average Loss: -1.1731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7359

Learning rate: 0.00011935494680508606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 5.1604	Cost: 32.06s
Train Epoch: 220 [40960/90000 (45%)]	Loss: -1.8303	Cost: 9.37s
Train Epoch: 220 [81920/90000 (91%)]	Loss: -1.8170	Cost: 12.52s
Train Epoch: 220 	Average Loss: -1.1985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7534

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 5.3867	Cost: 31.80s
Train Epoch: 221 [40960/90000 (45%)]	Loss: -2.0551	Cost: 9.37s
Train Epoch: 221 [81920/90000 (91%)]	Loss: -1.9581	Cost: 12.83s
Train Epoch: 221 	Average Loss: -1.1792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6639

Learning rate: 0.00011812057636271377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 4.8169	Cost: 31.58s
Train Epoch: 222 [40960/90000 (45%)]	Loss: -1.9759	Cost: 9.56s
Train Epoch: 222 [81920/90000 (91%)]	Loss: -1.7624	Cost: 12.23s
Train Epoch: 222 	Average Loss: -1.2418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7919

Learning rate: 0.00011750230589752765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 4.6939	Cost: 34.10s
Train Epoch: 223 [40960/90000 (45%)]	Loss: -2.1609	Cost: 9.33s
Train Epoch: 223 [81920/90000 (91%)]	Loss: -1.9272	Cost: 12.39s
Train Epoch: 223 	Average Loss: -1.2991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5649

Learning rate: 0.0001168833444712734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 4.4940	Cost: 31.18s
Train Epoch: 224 [40960/90000 (45%)]	Loss: -2.2319	Cost: 9.37s
Train Epoch: 224 [81920/90000 (91%)]	Loss: -2.0120	Cost: 12.50s
Train Epoch: 224 	Average Loss: -1.3712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4609

Learning rate: 0.00011626371651948839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 4.2159	Cost: 33.28s
Train Epoch: 225 [40960/90000 (45%)]	Loss: -2.0966	Cost: 9.34s
Train Epoch: 225 [81920/90000 (91%)]	Loss: -1.6761	Cost: 12.74s
Train Epoch: 225 	Average Loss: -1.3570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6959

Learning rate: 0.00011564344650402312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 4.7164	Cost: 31.94s
Train Epoch: 226 [40960/90000 (45%)]	Loss: -1.9143	Cost: 9.39s
Train Epoch: 226 [81920/90000 (91%)]	Loss: -1.8736	Cost: 12.16s
Train Epoch: 226 	Average Loss: -1.3710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5536

Learning rate: 0.00011502255891207573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 4.6115	Cost: 31.79s
Train Epoch: 227 [40960/90000 (45%)]	Loss: -2.0488	Cost: 9.38s
Train Epoch: 227 [81920/90000 (91%)]	Loss: -2.0279	Cost: 11.81s
Train Epoch: 227 	Average Loss: -1.3711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7137

Learning rate: 0.00011440107825522525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 4.5375	Cost: 32.85s
Train Epoch: 228 [40960/90000 (45%)]	Loss: -2.0729	Cost: 9.32s
Train Epoch: 228 [81920/90000 (91%)]	Loss: -1.9054	Cost: 12.39s
Train Epoch: 228 	Average Loss: -1.3945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6730

Learning rate: 0.00011377902906846383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 4.4819	Cost: 31.34s
Train Epoch: 229 [40960/90000 (45%)]	Loss: -2.2162	Cost: 9.38s
Train Epoch: 229 [81920/90000 (91%)]	Loss: -1.8184	Cost: 12.37s
Train Epoch: 229 	Average Loss: -1.4140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6064

Learning rate: 0.00011315643590922827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 4.9139	Cost: 32.62s
Train Epoch: 230 [40960/90000 (45%)]	Loss: -2.0187	Cost: 9.35s
Train Epoch: 230 [81920/90000 (91%)]	Loss: -1.9959	Cost: 12.41s
Train Epoch: 230 	Average Loss: -1.4116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7254

Learning rate: 0.00011253332335643043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 4.9216	Cost: 32.36s
Train Epoch: 231 [40960/90000 (45%)]	Loss: -2.1985	Cost: 9.37s
Train Epoch: 231 [81920/90000 (91%)]	Loss: -1.9967	Cost: 12.43s
Train Epoch: 231 	Average Loss: -1.4045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6636

Learning rate: 0.00011190971600948699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 4.5455	Cost: 31.54s
Train Epoch: 232 [40960/90000 (45%)]	Loss: -2.2221	Cost: 9.34s
Train Epoch: 232 [81920/90000 (91%)]	Loss: -1.9313	Cost: 12.51s
Train Epoch: 232 	Average Loss: -1.4811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7263

Learning rate: 0.00011128563848734816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 4.6726	Cost: 32.66s
Train Epoch: 233 [40960/90000 (45%)]	Loss: -2.1110	Cost: 9.34s
Train Epoch: 233 [81920/90000 (91%)]	Loss: -1.9588	Cost: 12.39s
Train Epoch: 233 	Average Loss: -1.4294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7644

Learning rate: 0.000110661115427526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 4.4351	Cost: 32.71s
Train Epoch: 234 [40960/90000 (45%)]	Loss: -2.2549	Cost: 9.34s
Train Epoch: 234 [81920/90000 (91%)]	Loss: -1.9809	Cost: 12.57s
Train Epoch: 234 	Average Loss: -1.5485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6909

Learning rate: 0.00011003617148512149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 4.7885	Cost: 32.13s
Train Epoch: 235 [40960/90000 (45%)]	Loss: -1.9408	Cost: 9.38s
Train Epoch: 235 [81920/90000 (91%)]	Loss: -1.9552	Cost: 11.78s
Train Epoch: 235 	Average Loss: -1.5276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8642

Learning rate: 0.00010941083133185143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 4.3308	Cost: 33.19s
Train Epoch: 236 [40960/90000 (45%)]	Loss: -2.2210	Cost: 9.80s
Train Epoch: 236 [81920/90000 (91%)]	Loss: -2.0410	Cost: 12.28s
Train Epoch: 236 	Average Loss: -1.5443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6612

Learning rate: 0.00010878511965507434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 4.6472	Cost: 30.91s
Train Epoch: 237 [40960/90000 (45%)]	Loss: -2.3504	Cost: 9.42s
Train Epoch: 237 [81920/90000 (91%)]	Loss: -2.2926	Cost: 12.05s
Train Epoch: 237 	Average Loss: -1.6304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8058

Learning rate: 0.00010815906115681577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 4.4723	Cost: 31.34s
Train Epoch: 238 [40960/90000 (45%)]	Loss: -2.5494	Cost: 9.38s
Train Epoch: 238 [81920/90000 (91%)]	Loss: -2.3431	Cost: 11.75s
Train Epoch: 238 	Average Loss: -1.7584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8648

Learning rate: 0.00010753268055279328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 4.6987	Cost: 32.23s
Train Epoch: 239 [40960/90000 (45%)]	Loss: -2.5351	Cost: 9.44s
Train Epoch: 239 [81920/90000 (91%)]	Loss: -2.2428	Cost: 12.17s
Train Epoch: 239 	Average Loss: -1.7648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7592

Learning rate: 0.0001069060025714406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 4.8874	Cost: 30.97s
Train Epoch: 240 [40960/90000 (45%)]	Loss: -2.4548	Cost: 9.42s
Train Epoch: 240 [81920/90000 (91%)]	Loss: -2.2560	Cost: 12.41s
Train Epoch: 240 	Average Loss: -1.7257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6719

Learning rate: 0.00010627905195293134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 4.5083	Cost: 32.29s
Train Epoch: 241 [40960/90000 (45%)]	Loss: -2.5458	Cost: 9.42s
Train Epoch: 241 [81920/90000 (91%)]	Loss: -2.3045	Cost: 12.33s
Train Epoch: 241 	Average Loss: -1.7720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8526

Learning rate: 0.00010565185344820243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 4.6837	Cost: 33.49s
Train Epoch: 242 [40960/90000 (45%)]	Loss: -2.4822	Cost: 9.33s
Train Epoch: 242 [81920/90000 (91%)]	Loss: -2.3629	Cost: 12.38s
Train Epoch: 242 	Average Loss: -1.7931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7072

Learning rate: 0.00010502443181797694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 4.9551	Cost: 31.91s
Train Epoch: 243 [40960/90000 (45%)]	Loss: -2.6358	Cost: 9.46s
Train Epoch: 243 [81920/90000 (91%)]	Loss: -2.2484	Cost: 11.94s
Train Epoch: 243 	Average Loss: -1.8347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8999

Learning rate: 0.00010439681183178646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 4.4191	Cost: 31.73s
Train Epoch: 244 [40960/90000 (45%)]	Loss: -2.5548	Cost: 9.40s
Train Epoch: 244 [81920/90000 (91%)]	Loss: -2.2632	Cost: 12.42s
Train Epoch: 244 	Average Loss: -1.7459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7174

Learning rate: 0.00010376901826699342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 4.6607	Cost: 32.20s
Train Epoch: 245 [40960/90000 (45%)]	Loss: -2.5212	Cost: 9.37s
Train Epoch: 245 [81920/90000 (91%)]	Loss: -2.1626	Cost: 12.41s
Train Epoch: 245 	Average Loss: -1.8037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9404

Learning rate: 0.0001031410759078128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 4.8100	Cost: 32.15s
Train Epoch: 246 [40960/90000 (45%)]	Loss: -2.5944	Cost: 9.57s
Train Epoch: 246 [81920/90000 (91%)]	Loss: -2.6070	Cost: 11.53s
Train Epoch: 246 	Average Loss: -1.8734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8141

Learning rate: 0.00010251300954433372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 4.6293	Cost: 30.67s
Train Epoch: 247 [40960/90000 (45%)]	Loss: -2.6400	Cost: 9.40s
Train Epoch: 247 [81920/90000 (91%)]	Loss: -2.2371	Cost: 11.82s
Train Epoch: 247 	Average Loss: -1.7727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7945

Learning rate: 0.0001018848439715408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 5.0452	Cost: 32.68s
Train Epoch: 248 [40960/90000 (45%)]	Loss: -2.5019	Cost: 9.33s
Train Epoch: 248 [81920/90000 (91%)]	Loss: -2.3782	Cost: 12.72s
Train Epoch: 248 	Average Loss: -1.6802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8254

Learning rate: 0.00010125660398833524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 4.3991	Cost: 31.20s
Train Epoch: 249 [40960/90000 (45%)]	Loss: -2.5127	Cost: 9.40s
Train Epoch: 249 [81920/90000 (91%)]	Loss: -2.4699	Cost: 12.57s
Train Epoch: 249 	Average Loss: -1.8026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8138

Learning rate: 0.00010062831439655587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 4.7953	Cost: 32.98s
Train Epoch: 250 [40960/90000 (45%)]	Loss: -2.7503	Cost: 9.37s
Train Epoch: 250 [81920/90000 (91%)]	Loss: -2.6330	Cost: 12.24s
Train Epoch: 250 	Average Loss: -1.8149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9197

Learning rate: 9.999999999999996e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 4.3641	Cost: 31.18s
Train Epoch: 251 [40960/90000 (45%)]	Loss: -2.7154	Cost: 9.42s
Train Epoch: 251 [81920/90000 (91%)]	Loss: -2.6502	Cost: 12.26s
Train Epoch: 251 	Average Loss: -1.9245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7324

Learning rate: 9.937168560344407e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 4.3927	Cost: 31.51s
Train Epoch: 252 [40960/90000 (45%)]	Loss: -2.5263	Cost: 9.37s
Train Epoch: 252 [81920/90000 (91%)]	Loss: -2.6240	Cost: 12.00s
Train Epoch: 252 	Average Loss: -1.9896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8063

Learning rate: 9.87433960116647e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 4.4914	Cost: 32.55s
Train Epoch: 253 [40960/90000 (45%)]	Loss: -2.8068	Cost: 9.37s
Train Epoch: 253 [81920/90000 (91%)]	Loss: -2.7121	Cost: 12.36s
Train Epoch: 253 	Average Loss: -2.0007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8409

Learning rate: 9.811515602845915e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 4.5758	Cost: 32.57s
Train Epoch: 254 [40960/90000 (45%)]	Loss: -2.9182	Cost: 9.38s
Train Epoch: 254 [81920/90000 (91%)]	Loss: -2.6058	Cost: 12.24s
Train Epoch: 254 	Average Loss: -2.0761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7815

Learning rate: 9.748699045566624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 4.4528	Cost: 31.94s
Train Epoch: 255 [40960/90000 (45%)]	Loss: -2.8717	Cost: 9.43s
Train Epoch: 255 [81920/90000 (91%)]	Loss: -2.7752	Cost: 11.73s
Train Epoch: 255 	Average Loss: -2.1308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8509

Learning rate: 9.685892409218716e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 4.3674	Cost: 32.76s
Train Epoch: 256 [40960/90000 (45%)]	Loss: -2.8993	Cost: 9.34s
Train Epoch: 256 [81920/90000 (91%)]	Loss: -2.6179	Cost: 12.53s
Train Epoch: 256 	Average Loss: -2.1079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8678

Learning rate: 9.623098173300653e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 4.8834	Cost: 31.91s
Train Epoch: 257 [40960/90000 (45%)]	Loss: -2.7288	Cost: 9.59s
Train Epoch: 257 [81920/90000 (91%)]	Loss: -2.7213	Cost: 12.37s
Train Epoch: 257 	Average Loss: -2.0326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6592

Learning rate: 9.560318816821353e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 4.4930	Cost: 31.05s
Train Epoch: 258 [40960/90000 (45%)]	Loss: -2.7982	Cost: 9.40s
Train Epoch: 258 [81920/90000 (91%)]	Loss: -2.8127	Cost: 11.94s
Train Epoch: 258 	Average Loss: -2.0569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7429

Learning rate: 9.497556818202306e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 4.6847	Cost: 32.20s
Train Epoch: 259 [40960/90000 (45%)]	Loss: -2.9355	Cost: 9.40s
Train Epoch: 259 [81920/90000 (91%)]	Loss: -2.9329	Cost: 12.50s
Train Epoch: 259 	Average Loss: -2.1711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8393

Learning rate: 9.434814655179755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 4.2957	Cost: 32.13s
Train Epoch: 260 [40960/90000 (45%)]	Loss: -2.9112	Cost: 9.36s
Train Epoch: 260 [81920/90000 (91%)]	Loss: -2.9226	Cost: 11.91s
Train Epoch: 260 	Average Loss: -2.2557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9188

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 4.8544	Cost: 32.87s
Train Epoch: 261 [40960/90000 (45%)]	Loss: -3.1410	Cost: 9.38s
Train Epoch: 261 [81920/90000 (91%)]	Loss: -2.8603	Cost: 12.50s
Train Epoch: 261 	Average Loss: -2.2175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9085

Learning rate: 9.309399742855944e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 4.5587	Cost: 32.14s
Train Epoch: 262 [40960/90000 (45%)]	Loss: -3.0389	Cost: 9.38s
Train Epoch: 262 [81920/90000 (91%)]	Loss: -2.7192	Cost: 12.58s
Train Epoch: 262 	Average Loss: -2.0896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7424

Learning rate: 9.246731944720672e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 4.8266	Cost: 30.44s
Train Epoch: 263 [40960/90000 (45%)]	Loss: -3.0925	Cost: 9.39s
Train Epoch: 263 [81920/90000 (91%)]	Loss: -2.8487	Cost: 11.62s
Train Epoch: 263 	Average Loss: -2.2268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7708

Learning rate: 9.184093884318424e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 4.4608	Cost: 31.30s
Train Epoch: 264 [40960/90000 (45%)]	Loss: -3.2162	Cost: 9.39s
Train Epoch: 264 [81920/90000 (91%)]	Loss: -2.9357	Cost: 12.56s
Train Epoch: 264 	Average Loss: -2.3112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7972

Learning rate: 9.121488034492569e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 4.3673	Cost: 32.69s
Train Epoch: 265 [40960/90000 (45%)]	Loss: -3.1213	Cost: 9.34s
Train Epoch: 265 [81920/90000 (91%)]	Loss: -2.9408	Cost: 12.05s
Train Epoch: 265 	Average Loss: -2.3161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8263

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 4.4077	Cost: 31.45s
Train Epoch: 266 [40960/90000 (45%)]	Loss: -2.8577	Cost: 9.38s
Train Epoch: 266 [81920/90000 (91%)]	Loss: -2.9956	Cost: 12.20s
Train Epoch: 266 	Average Loss: -2.3160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7686

Learning rate: 8.996382851487852e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 4.4305	Cost: 32.39s
Train Epoch: 267 [40960/90000 (45%)]	Loss: -3.4356	Cost: 9.34s
Train Epoch: 267 [81920/90000 (91%)]	Loss: -2.9423	Cost: 12.68s
Train Epoch: 267 	Average Loss: -2.3924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7900

Learning rate: 8.9338884572474e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 4.9455	Cost: 32.37s
Train Epoch: 268 [40960/90000 (45%)]	Loss: -3.4099	Cost: 9.56s
Train Epoch: 268 [81920/90000 (91%)]	Loss: -3.0570	Cost: 12.17s
Train Epoch: 268 	Average Loss: -2.4236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5341

Learning rate: 8.871436151265182e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 4.3447	Cost: 31.76s
Train Epoch: 269 [40960/90000 (45%)]	Loss: -3.2889	Cost: 9.38s
Train Epoch: 269 [81920/90000 (91%)]	Loss: -2.9391	Cost: 12.40s
Train Epoch: 269 	Average Loss: -2.4718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6951

Learning rate: 8.809028399051304e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 4.5249	Cost: 30.62s
Train Epoch: 270 [40960/90000 (45%)]	Loss: -3.2052	Cost: 9.42s
Train Epoch: 270 [81920/90000 (91%)]	Loss: -3.0742	Cost: 12.01s
Train Epoch: 270 	Average Loss: -2.4595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9352

Learning rate: 8.746667664356958e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 4.0744	Cost: 32.12s
Train Epoch: 271 [40960/90000 (45%)]	Loss: -3.3151	Cost: 9.38s
Train Epoch: 271 [81920/90000 (91%)]	Loss: -2.8807	Cost: 12.35s
Train Epoch: 271 	Average Loss: -2.5095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8423

Learning rate: 8.684356409077174e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 4.3039	Cost: 33.18s
Train Epoch: 272 [40960/90000 (45%)]	Loss: -3.1153	Cost: 9.33s
Train Epoch: 272 [81920/90000 (91%)]	Loss: -3.1478	Cost: 12.55s
Train Epoch: 272 	Average Loss: -2.4808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7599

Learning rate: 8.622097093153619e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 4.0131	Cost: 32.47s
Train Epoch: 273 [40960/90000 (45%)]	Loss: -3.2323	Cost: 9.40s
Train Epoch: 273 [81920/90000 (91%)]	Loss: -3.2315	Cost: 12.71s
Train Epoch: 273 	Average Loss: -2.4902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8606

Learning rate: 8.559892174477476e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 4.4086	Cost: 32.95s
Train Epoch: 274 [40960/90000 (45%)]	Loss: -3.1464	Cost: 9.37s
Train Epoch: 274 [81920/90000 (91%)]	Loss: -3.3381	Cost: 12.01s
Train Epoch: 274 	Average Loss: -2.5480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6898

Learning rate: 8.497744108792427e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 4.7018	Cost: 32.13s
Train Epoch: 275 [40960/90000 (45%)]	Loss: -3.5136	Cost: 9.41s
Train Epoch: 275 [81920/90000 (91%)]	Loss: -3.0833	Cost: 11.97s
Train Epoch: 275 	Average Loss: -2.5342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6590

Learning rate: 8.435655349597689e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 4.2696	Cost: 32.64s
Train Epoch: 276 [40960/90000 (45%)]	Loss: -3.3428	Cost: 9.44s
Train Epoch: 276 [81920/90000 (91%)]	Loss: -3.2704	Cost: 11.92s
Train Epoch: 276 	Average Loss: -2.5483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7939

Learning rate: 8.373628348051162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 4.7024	Cost: 32.40s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -3.6191	Cost: 9.39s
Train Epoch: 277 [81920/90000 (91%)]	Loss: -3.0037	Cost: 12.13s
Train Epoch: 277 	Average Loss: -2.5566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8750

Learning rate: 8.311665552872659e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 4.1460	Cost: 31.66s
Train Epoch: 278 [40960/90000 (45%)]	Loss: -3.2295	Cost: 9.39s
Train Epoch: 278 [81920/90000 (91%)]	Loss: -3.0658	Cost: 11.96s
Train Epoch: 278 	Average Loss: -2.4783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6727

Learning rate: 8.249769410247239e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 4.3231	Cost: 33.17s
Train Epoch: 279 [40960/90000 (45%)]	Loss: -3.2604	Cost: 9.55s
Train Epoch: 279 [81920/90000 (91%)]	Loss: -3.2938	Cost: 12.11s
Train Epoch: 279 	Average Loss: -2.6168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6829

Learning rate: 8.187942363728625e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 4.5976	Cost: 31.91s
Train Epoch: 280 [40960/90000 (45%)]	Loss: -3.5864	Cost: 9.37s
Train Epoch: 280 [81920/90000 (91%)]	Loss: -3.2502	Cost: 11.80s
Train Epoch: 280 	Average Loss: -2.6350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8660

Learning rate: 8.126186854142752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 4.2901	Cost: 32.48s
Train Epoch: 281 [40960/90000 (45%)]	Loss: -3.4730	Cost: 9.33s
Train Epoch: 281 [81920/90000 (91%)]	Loss: -3.3531	Cost: 12.08s
Train Epoch: 281 	Average Loss: -2.7408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8939

Learning rate: 8.064505319491398e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 4.7720	Cost: 31.56s
Train Epoch: 282 [40960/90000 (45%)]	Loss: -3.5517	Cost: 9.40s
Train Epoch: 282 [81920/90000 (91%)]	Loss: -3.5521	Cost: 11.93s
Train Epoch: 282 	Average Loss: -2.7328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9321

Learning rate: 8.002900194855929e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 4.3186	Cost: 31.88s
Train Epoch: 283 [40960/90000 (45%)]	Loss: -3.4824	Cost: 9.37s
Train Epoch: 283 [81920/90000 (91%)]	Loss: -3.3414	Cost: 13.00s
Train Epoch: 283 	Average Loss: -2.6785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9854

Learning rate: 7.941373912301183e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 4.7127	Cost: 31.10s
Train Epoch: 284 [40960/90000 (45%)]	Loss: -3.3978	Cost: 9.36s
Train Epoch: 284 [81920/90000 (91%)]	Loss: -3.3877	Cost: 12.04s
Train Epoch: 284 	Average Loss: -2.6819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8209

Learning rate: 7.879928900779452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 4.4310	Cost: 31.23s
Train Epoch: 285 [40960/90000 (45%)]	Loss: -3.6329	Cost: 9.39s
Train Epoch: 285 [81920/90000 (91%)]	Loss: -3.6224	Cost: 12.05s
Train Epoch: 285 	Average Loss: -2.7406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8489

Learning rate: 7.818567586034573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 3.9660	Cost: 32.09s
Train Epoch: 286 [40960/90000 (45%)]	Loss: -3.7485	Cost: 9.38s
Train Epoch: 286 [81920/90000 (91%)]	Loss: -3.3712	Cost: 11.88s
Train Epoch: 286 	Average Loss: -2.8139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9196

Learning rate: 7.757292390506185e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 4.6849	Cost: 33.34s
Train Epoch: 287 [40960/90000 (45%)]	Loss: -3.7575	Cost: 9.34s
Train Epoch: 287 [81920/90000 (91%)]	Loss: -3.5232	Cost: 12.46s
Train Epoch: 287 	Average Loss: -2.7573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8852

Learning rate: 7.696105733234094e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 4.1687	Cost: 32.54s
Train Epoch: 288 [40960/90000 (45%)]	Loss: -3.7337	Cost: 9.34s
Train Epoch: 288 [81920/90000 (91%)]	Loss: -3.5858	Cost: 12.63s
Train Epoch: 288 	Average Loss: -2.9048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7538

Learning rate: 7.635010029762752e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 4.2602	Cost: 31.56s
Train Epoch: 289 [40960/90000 (45%)]	Loss: -3.7428	Cost: 9.39s
Train Epoch: 289 [81920/90000 (91%)]	Loss: -3.7144	Cost: 12.62s
Train Epoch: 289 	Average Loss: -2.9448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0083

Learning rate: 7.574007692045924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 4.0144	Cost: 31.55s
Train Epoch: 290 [40960/90000 (45%)]	Loss: -3.7802	Cost: 9.38s
Train Epoch: 290 [81920/90000 (91%)]	Loss: -3.6722	Cost: 12.22s
Train Epoch: 290 	Average Loss: -2.9557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9438

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 4.3138	Cost: 31.91s
Train Epoch: 291 [40960/90000 (45%)]	Loss: -3.6014	Cost: 9.38s
Train Epoch: 291 [81920/90000 (91%)]	Loss: -3.6243	Cost: 12.25s
Train Epoch: 291 	Average Loss: -2.8752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7864

Learning rate: 7.452292743166178e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 4.6273	Cost: 32.75s
Train Epoch: 292 [40960/90000 (45%)]	Loss: -3.8134	Cost: 9.34s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -3.3880	Cost: 12.25s
Train Epoch: 292 	Average Loss: -2.8908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9244

Learning rate: 7.391584937101029e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 4.6272	Cost: 31.18s
Train Epoch: 293 [40960/90000 (45%)]	Loss: -3.8191	Cost: 9.53s
Train Epoch: 293 [81920/90000 (91%)]	Loss: -3.5708	Cost: 12.28s
Train Epoch: 293 	Average Loss: -2.9287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0421

Learning rate: 7.330980106796245e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 4.4242	Cost: 33.19s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -3.7640	Cost: 9.30s
Train Epoch: 294 [81920/90000 (91%)]	Loss: -3.5273	Cost: 12.24s
Train Epoch: 294 	Average Loss: -2.8715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7701

Learning rate: 7.270480644826745e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 4.7757	Cost: 31.82s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -3.9143	Cost: 9.38s
Train Epoch: 295 [81920/90000 (91%)]	Loss: -3.6076	Cost: 11.93s
Train Epoch: 295 	Average Loss: -2.9313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9126

Learning rate: 7.210088939607704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 4.6828	Cost: 31.88s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -3.7781	Cost: 9.42s
Train Epoch: 296 [81920/90000 (91%)]	Loss: -3.6936	Cost: 11.95s
Train Epoch: 296 	Average Loss: -2.9624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9522

Learning rate: 7.149807375300236e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 4.1402	Cost: 31.23s
Train Epoch: 297 [40960/90000 (45%)]	Loss: -3.8973	Cost: 9.41s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -3.7350	Cost: 12.04s
Train Epoch: 297 	Average Loss: -3.0890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8459

Learning rate: 7.08963833171728e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 4.5167	Cost: 32.59s
Train Epoch: 298 [40960/90000 (45%)]	Loss: -3.8201	Cost: 9.39s
Train Epoch: 298 [81920/90000 (91%)]	Loss: -3.7817	Cost: 12.35s
Train Epoch: 298 	Average Loss: -3.0702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9817

Learning rate: 7.029584184229648e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 5.0225	Cost: 30.79s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -3.7968	Cost: 9.41s
Train Epoch: 299 [81920/90000 (91%)]	Loss: -3.9790	Cost: 12.21s
Train Epoch: 299 	Average Loss: -3.0733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8158

Learning rate: 6.969647303672259e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 4.0674	Cost: 32.37s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -3.8832	Cost: 9.38s
Train Epoch: 300 [81920/90000 (91%)]	Loss: -3.8494	Cost: 12.48s
Train Epoch: 300 	Average Loss: -3.1403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9433

Learning rate: 6.909830056250523e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 4.5456	Cost: 31.86s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -3.7041	Cost: 9.41s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -3.8407	Cost: 12.08s
Train Epoch: 301 	Average Loss: -3.1329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7699

Learning rate: 6.850134803446949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 4.5405	Cost: 31.27s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -4.0599	Cost: 9.40s
Train Epoch: 302 [81920/90000 (91%)]	Loss: -3.9140	Cost: 12.88s
Train Epoch: 302 	Average Loss: -3.2278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0269

Learning rate: 6.790563901927903e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 4.5939	Cost: 31.40s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -4.1197	Cost: 9.37s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -3.8640	Cost: 11.78s
Train Epoch: 303 	Average Loss: -3.3137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8895

Learning rate: 6.731119703450573e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 4.3909	Cost: 32.19s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -4.0662	Cost: 9.35s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -3.9055	Cost: 12.10s
Train Epoch: 304 	Average Loss: -3.3104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6805

Learning rate: 6.67180455477013e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 4.5142	Cost: 31.15s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -4.3584	Cost: 9.41s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -4.2306	Cost: 12.07s
Train Epoch: 305 	Average Loss: -3.3509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8471

Learning rate: 6.612620797547083e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 4.3267	Cost: 32.65s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -4.1131	Cost: 9.48s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -3.9970	Cost: 12.53s
Train Epoch: 306 	Average Loss: -3.4188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8196

Learning rate: 6.553570768254825e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 4.0664	Cost: 31.61s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -4.3584	Cost: 9.40s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -4.3907	Cost: 11.91s
Train Epoch: 307 	Average Loss: -3.4986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7423

Learning rate: 6.494656798087406e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 4.5742	Cost: 33.55s
Train Epoch: 308 [40960/90000 (45%)]	Loss: -4.3816	Cost: 9.33s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -4.2902	Cost: 12.33s
Train Epoch: 308 	Average Loss: -3.4280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8804

Learning rate: 6.435881212867491e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 4.6271	Cost: 32.69s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -4.3789	Cost: 9.35s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -4.1949	Cost: 12.92s
Train Epoch: 309 	Average Loss: -3.4590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9526

Learning rate: 6.377246332954541e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 4.5436	Cost: 32.38s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -4.2952	Cost: 9.36s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -4.1757	Cost: 12.70s
Train Epoch: 310 	Average Loss: -3.4455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0263

Learning rate: 6.318754473153218e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 4.8507	Cost: 33.34s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -4.3224	Cost: 9.37s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -4.0910	Cost: 12.53s
Train Epoch: 311 	Average Loss: -3.4598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8802

Learning rate: 6.260407942621994e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 4.1239	Cost: 32.19s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -4.5828	Cost: 9.54s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -4.2349	Cost: 12.08s
Train Epoch: 312 	Average Loss: -3.5093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7713

Learning rate: 6.202209044781987e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 4.9213	Cost: 31.17s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -4.5139	Cost: 9.41s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -4.1989	Cost: 12.92s
Train Epoch: 313 	Average Loss: -3.5597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6825

Learning rate: 6.144160077226032e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 4.1667	Cost: 31.19s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -4.4883	Cost: 9.39s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -4.3224	Cost: 12.66s
Train Epoch: 314 	Average Loss: -3.5898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0176

Learning rate: 6.0862633316279744e-05
