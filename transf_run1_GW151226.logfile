Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW151226_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW151226_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=1.0, mode='train', model_dir='models/GW151226_sample_uniform_100basis_all_mixed_prior_transfered/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=400, truncate_basis=100)
Waveform directory data/GW151226_sample_prior_basis/
Model directory models/GW151226_sample_uniform_100basis_all_mixed_prior_transfered/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Now, transfer learning from alpha=1.0!
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.6469	Cost: 26.70s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.6763	Cost: 8.71s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 20.2086	Cost: 10.69s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 19.6273	Cost: 7.27s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 19.1373	Cost: 17.60s
Train Epoch: 1 	Average Loss: 20.6837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9343

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 18.9021	Cost: 24.95s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 18.4080	Cost: 8.06s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 17.5767	Cost: 13.48s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 16.8828	Cost: 7.47s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 16.2936	Cost: 11.86s
Train Epoch: 2 	Average Loss: 17.4968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1866

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999998026079186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 16.0383	Cost: 25.89s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 15.6075	Cost: 6.10s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 15.2192	Cost: 12.34s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 14.9944	Cost: 9.05s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 14.8467	Cost: 10.29s
Train Epoch: 3 	Average Loss: 15.2432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6857

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019999995558678347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 14.6247	Cost: 26.40s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 14.3204	Cost: 12.11s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 14.1110	Cost: 6.40s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 13.9103	Cost: 6.41s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 13.5494	Cost: 10.19s
Train Epoch: 4 	Average Loss: 14.0148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5126

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.0001999999210431752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 13.4408	Cost: 30.01s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 13.3291	Cost: 12.05s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 13.0711	Cost: 15.02s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 12.7627	Cost: 7.82s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 12.8001	Cost: 11.77s
Train Epoch: 5 	Average Loss: 13.0742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7686

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019999987662997035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 12.6892	Cost: 32.50s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 12.6153	Cost: 7.38s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 12.5616	Cost: 18.53s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 12.2822	Cost: 12.99s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 12.1923	Cost: 8.09s
Train Epoch: 6 	Average Loss: 12.4640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1938

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019999982234717337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 12.2554	Cost: 30.38s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 12.0788	Cost: 8.49s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 12.0246	Cost: 21.20s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 11.7344	Cost: 14.77s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 11.8258	Cost: 10.96s
Train Epoch: 7 	Average Loss: 11.9818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7991

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 11.8527	Cost: 29.66s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 11.6951	Cost: 8.31s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 11.4682	Cost: 11.51s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 11.3278	Cost: 6.22s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 11.2804	Cost: 18.43s
Train Epoch: 8 	Average Loss: 11.4940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2846

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.0001999996841728254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 11.2089	Cost: 27.84s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 11.3527	Cost: 7.22s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 11.1617	Cost: 12.46s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 10.9670	Cost: 6.35s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 10.8451	Cost: 13.57s
Train Epoch: 9 	Average Loss: 11.1112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8913

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 10.9524	Cost: 33.05s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 10.7101	Cost: 8.84s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 10.6628	Cost: 9.81s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 10.5709	Cost: 8.52s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 10.5843	Cost: 7.33s
Train Epoch: 10 	Average Loss: 10.6705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4620

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019999950652018584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 10.5850	Cost: 31.08s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 10.4659	Cost: 6.33s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 10.3108	Cost: 11.53s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 10.4476	Cost: 6.29s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 10.0747	Cost: 13.59s
Train Epoch: 11 	Average Loss: 10.2900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1640

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019999940288952797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 10.1580	Cost: 33.26s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 10.1165	Cost: 9.09s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 9.9828	Cost: 9.32s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 9.9297	Cost: 5.99s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 9.8969	Cost: 10.73s
Train Epoch: 12 	Average Loss: 9.9585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8355

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019999928938932473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 9.6165	Cost: 40.39s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 9.7595	Cost: 11.24s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 9.6210	Cost: 15.14s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 9.6331	Cost: 10.36s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 9.4966	Cost: 9.46s
Train Epoch: 13 	Average Loss: 9.6544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5220

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.0001999991660195873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 9.4926	Cost: 31.11s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 9.5486	Cost: 6.38s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 9.2446	Cost: 14.65s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 9.2756	Cost: 15.22s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 9.1931	Cost: 15.11s
Train Epoch: 14 	Average Loss: 9.3515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1603

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 9.0487	Cost: 27.58s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 9.2133	Cost: 6.97s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 9.1623	Cost: 13.86s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 8.9979	Cost: 9.71s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 8.9643	Cost: 17.65s
Train Epoch: 15 	Average Loss: 9.0611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9826

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019999888967155963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 9.0016	Cost: 26.83s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 8.9328	Cost: 6.48s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 8.7813	Cost: 14.19s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 8.8796	Cost: 6.19s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 8.8091	Cost: 21.30s
Train Epoch: 16 	Average Loss: 8.8564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7137

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001999987366932966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 8.7270	Cost: 25.70s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 8.6255	Cost: 6.52s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 8.5326	Cost: 13.84s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 8.6451	Cost: 6.32s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 8.5533	Cost: 20.24s
Train Epoch: 17 	Average Loss: 8.6356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6160

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019999857384555393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 8.3941	Cost: 24.98s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 8.4703	Cost: 6.52s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 8.3852	Cost: 13.02s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 8.5326	Cost: 7.29s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 8.3983	Cost: 12.98s
Train Epoch: 18 	Average Loss: 8.4609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3694

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.0001999984011283477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 8.2084	Cost: 26.67s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 8.4823	Cost: 8.63s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 7.9908	Cost: 8.91s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 8.3813	Cost: 8.70s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 8.1963	Cost: 8.65s
Train Epoch: 19 	Average Loss: 8.2326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1768

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019999821854169497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 8.0348	Cost: 27.19s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 8.1354	Cost: 12.09s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 7.9127	Cost: 6.11s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 7.9000	Cost: 6.09s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 8.0200	Cost: 12.53s
Train Epoch: 20 	Average Loss: 8.0555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9250

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 7.9709	Cost: 29.00s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 8.0905	Cost: 14.54s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 7.7953	Cost: 8.36s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 7.8680	Cost: 8.09s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 7.9475	Cost: 10.13s
Train Epoch: 21 	Average Loss: 7.9045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8998

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 7.8576	Cost: 28.39s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 7.8582	Cost: 6.35s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 7.6724	Cost: 14.00s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 7.7471	Cost: 15.83s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 7.7375	Cost: 12.16s
Train Epoch: 22 	Average Loss: 7.7695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6986

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.00019999761156524272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 7.7592	Cost: 27.94s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 7.8680	Cost: 6.73s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 7.5793	Cost: 13.22s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 7.4306	Cost: 6.39s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 7.5870	Cost: 21.29s
Train Epoch: 23 	Average Loss: 7.6303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6443

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 7.6071	Cost: 26.57s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 7.7326	Cost: 6.61s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 7.3655	Cost: 13.58s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 7.2216	Cost: 8.20s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 7.3684	Cost: 21.79s
Train Epoch: 24 	Average Loss: 7.4511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3196

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.00019999715756739833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 7.4113	Cost: 24.68s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 7.5017	Cost: 6.69s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 7.2379	Cost: 14.69s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 7.2870	Cost: 8.41s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 7.2938	Cost: 9.95s
Train Epoch: 25 	Average Loss: 7.3475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1521

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.000199996915764479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 7.2551	Cost: 25.11s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 7.3479	Cost: 8.78s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 6.9284	Cost: 9.95s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 7.2104	Cost: 8.84s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 7.2942	Cost: 9.06s
Train Epoch: 26 	Average Loss: 7.1492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0439

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019999666409225975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 6.9809	Cost: 25.23s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 7.3226	Cost: 7.08s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 7.0953	Cost: 14.50s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 7.0569	Cost: 8.78s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 7.0071	Cost: 10.08s
Train Epoch: 27 	Average Loss: 7.1001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9163

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019999640255076543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 7.0091	Cost: 25.94s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 7.1169	Cost: 10.74s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 6.8996	Cost: 8.75s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 6.8312	Cost: 6.28s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 6.8501	Cost: 13.05s
Train Epoch: 28 	Average Loss: 6.9137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7798

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019999613114002186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 6.8616	Cost: 30.10s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 6.9445	Cost: 14.84s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 6.6549	Cost: 13.03s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 6.5802	Cost: 8.67s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 6.9376	Cost: 9.34s
Train Epoch: 29 	Average Loss: 6.7717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7268

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.0001999958498600558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 6.7385	Cost: 28.27s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 7.0136	Cost: 9.62s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 6.6477	Cost: 12.41s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 6.7380	Cost: 12.36s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 6.8437	Cost: 15.06s
Train Epoch: 30 	Average Loss: 6.7543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6160

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.000199995558710895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 6.7423	Cost: 28.91s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 6.6090	Cost: 8.48s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 6.4733	Cost: 13.76s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 6.5400	Cost: 6.12s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 6.5940	Cost: 22.04s
Train Epoch: 31 	Average Loss: 6.6054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5094

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 0.00019999525769256825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 6.5518	Cost: 28.47s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 6.6594	Cost: 7.35s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 6.5790	Cost: 14.82s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 6.3059	Cost: 6.51s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 6.3661	Cost: 14.93s
Train Epoch: 32 	Average Loss: 6.4772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4542

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.00019999494680510518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 6.3315	Cost: 27.76s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 6.4736	Cost: 9.01s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 6.3736	Cost: 8.92s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 6.2393	Cost: 6.10s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 6.2272	Cost: 10.70s
Train Epoch: 33 	Average Loss: 6.3966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3054

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019999462604853658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 6.3185	Cost: 30.24s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 6.3854	Cost: 6.32s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 6.3770	Cost: 13.15s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 6.3368	Cost: 8.51s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 6.1763	Cost: 7.77s
Train Epoch: 34 	Average Loss: 6.3264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2853

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019999429542289402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 6.2308	Cost: 35.19s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 6.3608	Cost: 6.22s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 6.0786	Cost: 12.43s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 6.1019	Cost: 5.91s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 6.0867	Cost: 11.41s
Train Epoch: 35 	Average Loss: 6.1799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1816

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.00019999395492821016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 6.3230	Cost: 31.27s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 6.3193	Cost: 6.36s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 5.9443	Cost: 15.41s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 6.0858	Cost: 6.08s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 6.2606	Cost: 8.42s
Train Epoch: 36 	Average Loss: 6.1424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0908

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.0001999936045645186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 6.0621	Cost: 37.94s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 6.1684	Cost: 7.78s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 6.0285	Cost: 15.56s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 6.2003	Cost: 11.07s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 6.0416	Cost: 11.87s
Train Epoch: 37 	Average Loss: 6.0328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0339

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.00019999324433185394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 5.9990	Cost: 28.68s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 5.9837	Cost: 6.50s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 5.8184	Cost: 12.85s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 5.9053	Cost: 6.51s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 5.9691	Cost: 20.02s
Train Epoch: 38 	Average Loss: 5.9538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0443

Learning rate: 0.0001999928742302517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 6.0310	Cost: 27.17s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 6.1191	Cost: 6.40s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 5.8318	Cost: 14.17s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 5.8053	Cost: 6.30s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 5.9983	Cost: 18.02s
Train Epoch: 39 	Average Loss: 5.8963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9607

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019999249425974844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 6.0667	Cost: 27.44s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 5.8358	Cost: 8.39s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 5.7656	Cost: 9.40s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 5.6177	Cost: 6.29s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 5.7418	Cost: 13.66s
Train Epoch: 40 	Average Loss: 5.7936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7461

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 5.6876	Cost: 28.25s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 5.8939	Cost: 6.25s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 5.8049	Cost: 13.47s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 5.7101	Cost: 8.50s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 5.8028	Cost: 8.91s
Train Epoch: 41 	Average Loss: 5.7726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6866

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019999170471218976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 5.6415	Cost: 28.83s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 5.8105	Cost: 6.13s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 5.5460	Cost: 12.72s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 5.5743	Cost: 6.08s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 5.6710	Cost: 9.72s
Train Epoch: 42 	Average Loss: 5.6243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6591

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.0001999912951352123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 5.8592	Cost: 33.31s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 5.7732	Cost: 14.77s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 5.6260	Cost: 13.41s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 5.6383	Cost: 9.08s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 5.8147	Cost: 8.66s
Train Epoch: 43 	Average Loss: 5.6784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6820

Learning rate: 0.00019999087568948966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 5.6391	Cost: 28.06s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 5.8368	Cost: 6.78s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 5.5251	Cost: 13.45s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 5.4701	Cost: 15.21s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 5.5368	Cost: 15.08s
Train Epoch: 44 	Average Loss: 5.5774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5181

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 0.0001999904463750632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 5.5494	Cost: 27.37s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 5.4853	Cost: 6.32s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 5.3987	Cost: 13.76s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 5.5693	Cost: 6.20s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 5.4314	Cost: 20.94s
Train Epoch: 45 	Average Loss: 5.5004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5391

Learning rate: 0.00019999000719197536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 5.4967	Cost: 27.31s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 5.4396	Cost: 6.25s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 5.5673	Cost: 13.76s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 5.2893	Cost: 6.32s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 5.3987	Cost: 21.64s
Train Epoch: 46 	Average Loss: 5.4518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4755

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 0.00019998955814026943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 5.2936	Cost: 25.76s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 5.5412	Cost: 6.42s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 5.8052	Cost: 12.98s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 5.3819	Cost: 6.19s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 5.3244	Cost: 14.67s
Train Epoch: 47 	Average Loss: 5.4124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5240

Learning rate: 0.00019998909921998973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 5.5759	Cost: 26.79s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 5.4049	Cost: 8.77s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 5.2483	Cost: 9.08s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 5.2815	Cost: 8.96s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 5.2004	Cost: 9.07s
Train Epoch: 48 	Average Loss: 5.3426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3259

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 0.0001999886304311816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 5.3345	Cost: 26.70s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 5.3302	Cost: 12.14s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 5.3104	Cost: 6.06s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 5.1617	Cost: 6.05s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 5.1969	Cost: 10.11s
Train Epoch: 49 	Average Loss: 5.2745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3207

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019998815177389132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 5.1429	Cost: 30.56s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 5.3828	Cost: 14.43s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 5.2633	Cost: 11.72s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 5.1554	Cost: 10.00s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 5.1355	Cost: 8.27s
Train Epoch: 50 	Average Loss: 5.2650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2951

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 5.3432	Cost: 29.99s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 5.3543	Cost: 6.47s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 5.1322	Cost: 16.71s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 5.1283	Cost: 15.73s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 5.1658	Cost: 9.02s
Train Epoch: 51 	Average Loss: 5.1904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0491

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019998716485405404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 5.2123	Cost: 27.27s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 5.2529	Cost: 6.35s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 5.0379	Cost: 14.23s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 5.0319	Cost: 7.33s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 5.1738	Cost: 19.88s
Train Epoch: 52 	Average Loss: 5.1304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2096

Learning rate: 0.0001999866565916045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 5.1988	Cost: 25.39s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 5.2453	Cost: 6.84s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 5.2367	Cost: 14.98s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 4.9873	Cost: 8.38s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 5.1146	Cost: 16.51s
Train Epoch: 53 	Average Loss: 5.0711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1119

Learning rate: 0.0001999861384608676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 5.1705	Cost: 26.25s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 5.2102	Cost: 8.68s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 5.0462	Cost: 9.28s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 5.0112	Cost: 7.60s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 5.0022	Cost: 9.77s
Train Epoch: 54 	Average Loss: 5.0834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9687

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 0.00019998561046189446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 4.9822	Cost: 26.78s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 5.0629	Cost: 6.08s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 4.9367	Cost: 15.71s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 4.9044	Cost: 8.74s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 5.0493	Cost: 10.02s
Train Epoch: 55 	Average Loss: 4.9982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0239

Learning rate: 0.00019998507259473718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 5.0912	Cost: 27.73s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 5.1344	Cost: 11.54s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 4.9673	Cost: 7.96s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 4.8775	Cost: 6.24s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 4.9359	Cost: 13.39s
Train Epoch: 56 	Average Loss: 4.9983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0746

Learning rate: 0.00019998452485944885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 4.9522	Cost: 28.87s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 5.0067	Cost: 13.78s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 4.9534	Cost: 16.04s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 4.8459	Cost: 6.21s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 4.8883	Cost: 11.78s
Train Epoch: 57 	Average Loss: 4.9378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9330

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 0.00019998396725608354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 4.9315	Cost: 31.17s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 4.9738	Cost: 10.24s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 4.8198	Cost: 15.86s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 4.9588	Cost: 15.47s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 4.9256	Cost: 9.88s
Train Epoch: 58 	Average Loss: 4.9405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0084

Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 4.9402	Cost: 35.94s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 4.9487	Cost: 7.09s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 4.9072	Cost: 13.47s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 4.7637	Cost: 16.45s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 4.7531	Cost: 12.88s
Train Epoch: 59 	Average Loss: 4.8603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9388

Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 4.8475	Cost: 27.88s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 4.8580	Cost: 8.99s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 4.9833	Cost: 11.45s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 4.6932	Cost: 6.15s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 4.6332	Cost: 21.09s
Train Epoch: 60 	Average Loss: 4.8186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8753

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 4.7746	Cost: 28.89s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 4.9481	Cost: 6.85s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 4.8112	Cost: 13.46s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 4.6123	Cost: 6.27s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 4.7359	Cost: 14.29s
Train Epoch: 61 	Average Loss: 4.7624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8329

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 4.9471	Cost: 28.89s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 4.7524	Cost: 8.81s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 4.7907	Cost: 9.39s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 4.5539	Cost: 8.53s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 4.7392	Cost: 5.91s
Train Epoch: 62 	Average Loss: 4.7286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7226

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019998103122006246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 4.8377	Cost: 26.26s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 4.9759	Cost: 6.22s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 4.6400	Cost: 11.43s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 4.6293	Cost: 7.11s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 4.5546	Cost: 10.64s
Train Epoch: 63 	Average Loss: 4.6877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8073

Learning rate: 0.00019998041440942506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 4.8798	Cost: 30.18s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 4.8041	Cost: 6.15s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 4.6956	Cost: 13.52s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 4.5336	Cost: 10.07s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 4.6136	Cost: 5.98s
Train Epoch: 64 	Average Loss: 4.6566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6301

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00019997978773111632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 4.6937	Cost: 31.81s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 4.7046	Cost: 6.42s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 4.6976	Cost: 18.19s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 4.4649	Cost: 14.02s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 4.5135	Cost: 11.74s
Train Epoch: 65 	Average Loss: 4.6321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6668

Learning rate: 0.00019997915118519813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 4.7427	Cost: 28.78s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 4.6507	Cost: 6.60s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 4.5086	Cost: 14.41s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 4.4948	Cost: 15.36s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 4.4950	Cost: 14.83s
Train Epoch: 66 	Average Loss: 4.5971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5926

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.0001999785047717333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 4.5556	Cost: 28.84s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 4.6195	Cost: 6.61s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 4.5370	Cost: 13.64s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 4.4997	Cost: 16.02s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 4.6069	Cost: 12.13s
Train Epoch: 67 	Average Loss: 4.5637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6025

Learning rate: 0.00019997784849078566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 4.6103	Cost: 27.03s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 4.5230	Cost: 6.53s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 4.5687	Cost: 13.42s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 4.6407	Cost: 6.12s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 4.4245	Cost: 21.67s
Train Epoch: 68 	Average Loss: 4.5626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5037

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 0.00019997718234242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 4.4752	Cost: 25.03s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 4.5693	Cost: 6.60s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 4.4523	Cost: 13.30s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 4.4825	Cost: 7.53s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 4.3887	Cost: 11.86s
Train Epoch: 69 	Average Loss: 4.4659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4507

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Learning rate: 0.00019997650632670199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 4.4646	Cost: 26.53s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 4.5348	Cost: 8.62s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 4.6055	Cost: 9.29s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 4.3850	Cost: 9.15s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 4.4636	Cost: 8.14s
Train Epoch: 70 	Average Loss: 4.4617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4751

Learning rate: 0.0001999758204436984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 4.4424	Cost: 27.61s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 4.4696	Cost: 12.16s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 4.4151	Cost: 6.28s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 4.2456	Cost: 6.09s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 4.5954	Cost: 10.32s
Train Epoch: 71 	Average Loss: 4.4449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5766

Learning rate: 0.00019997512469347695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 4.7052	Cost: 29.62s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 4.4212	Cost: 10.55s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 4.3355	Cost: 15.22s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 4.3540	Cost: 9.33s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 4.2490	Cost: 11.11s
Train Epoch: 72 	Average Loss: 4.4161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4103

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 0.00019997441907610624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 4.3687	Cost: 28.69s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 4.4302	Cost: 6.38s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 4.3694	Cost: 13.62s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 4.4188	Cost: 12.18s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 4.3738	Cost: 15.51s
Train Epoch: 73 	Average Loss: 4.3790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4110

Learning rate: 0.00019997370359165596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 4.6595	Cost: 27.26s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 4.3964	Cost: 6.45s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 4.2129	Cost: 13.55s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 4.1779	Cost: 6.14s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 4.5245	Cost: 22.37s
Train Epoch: 74 	Average Loss: 4.3319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3967

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.0001999729782401967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 4.4541	Cost: 26.77s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 4.3109	Cost: 6.57s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 4.3856	Cost: 13.71s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 4.2535	Cost: 7.09s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 4.2078	Cost: 22.01s
Train Epoch: 75 	Average Loss: 4.3185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2895

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 4.2307	Cost: 25.54s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 4.2411	Cost: 6.14s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 4.1764	Cost: 15.38s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 4.1679	Cost: 8.42s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 4.2492	Cost: 11.89s
Train Epoch: 76 	Average Loss: 4.2444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1795

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00019997149793653861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 4.3783	Cost: 26.23s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 4.3203	Cost: 8.69s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 4.1996	Cost: 9.64s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 4.1376	Cost: 7.76s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 4.2466	Cost: 9.87s
Train Epoch: 77 	Average Loss: 4.2430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3546

Learning rate: 0.00019997074298448586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 4.5572	Cost: 26.41s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 4.3355	Cost: 6.26s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 4.2785	Cost: 14.79s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 4.1256	Cost: 8.77s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 4.2134	Cost: 7.79s
Train Epoch: 78 	Average Loss: 4.2303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2458

Learning rate: 0.00019996997816571638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 4.1458	Cost: 31.14s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 4.2183	Cost: 6.23s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 4.0835	Cost: 14.77s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 4.2603	Cost: 8.48s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 4.2252	Cost: 8.34s
Train Epoch: 79 	Average Loss: 4.1602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3153

Learning rate: 0.00019996920348030559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 4.2238	Cost: 32.23s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 4.1433	Cost: 10.63s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 4.1554	Cost: 7.45s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 4.1792	Cost: 6.13s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 4.1406	Cost: 11.74s
Train Epoch: 80 	Average Loss: 4.1087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1784

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892832998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 4.0582	Cost: 33.11s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 4.2783	Cost: 12.17s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 4.0997	Cost: 6.43s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 4.0346	Cost: 11.97s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 4.2322	Cost: 5.75s
Train Epoch: 81 	Average Loss: 4.0881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1920

Learning rate: 0.00019996762450986697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 4.2468	Cost: 35.53s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 4.1653	Cost: 6.75s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 3.9571	Cost: 17.09s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 4.0765	Cost: 11.80s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 4.1386	Cost: 11.93s
Train Epoch: 82 	Average Loss: 4.0746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1322

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Learning rate: 0.00019996682022499498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 4.1258	Cost: 30.34s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 4.1148	Cost: 7.92s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 3.8867	Cost: 11.09s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 3.9078	Cost: 9.13s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 3.9732	Cost: 17.14s
Train Epoch: 83 	Average Loss: 4.0318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0850

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Learning rate: 0.0001999660060737934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 4.1299	Cost: 28.41s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 4.0222	Cost: 6.30s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 3.9500	Cost: 14.56s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 3.8292	Cost: 6.19s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 4.0140	Cost: 23.17s
Train Epoch: 84 	Average Loss: 3.9740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0628

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 0.00019996518205634255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 4.0575	Cost: 27.07s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 4.0813	Cost: 6.65s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 3.9715	Cost: 14.25s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 3.8308	Cost: 6.21s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 4.0750	Cost: 16.36s
Train Epoch: 85 	Average Loss: 3.9991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1477

Learning rate: 0.0001999643481727238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 4.0789	Cost: 26.44s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 3.9953	Cost: 8.76s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 3.8295	Cost: 9.57s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 3.8097	Cost: 8.26s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 3.9974	Cost: 5.97s
Train Epoch: 86 	Average Loss: 3.9642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1027

Learning rate: 0.0001999635044230194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 4.2089	Cost: 26.55s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 4.0459	Cost: 6.22s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 3.8476	Cost: 12.32s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 3.9052	Cost: 6.33s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 4.0018	Cost: 12.30s
Train Epoch: 87 	Average Loss: 3.9650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9873

Saving model as e87_model.pt & e87_waveforms_supplementary.hdf5
Learning rate: 0.00019996265080731267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 4.1645	Cost: 27.92s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 4.1115	Cost: 6.09s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 3.8114	Cost: 12.03s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 3.7984	Cost: 6.04s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 4.0604	Cost: 10.28s
Train Epoch: 88 	Average Loss: 3.9822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1631

Learning rate: 0.00019996178732568782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 4.2087	Cost: 35.38s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 4.1089	Cost: 15.05s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 3.7875	Cost: 10.12s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 3.8138	Cost: 11.96s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 3.9219	Cost: 5.84s
Train Epoch: 89 	Average Loss: 3.9245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9304

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 0.00019996091397823007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 3.9494	Cost: 29.73s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 3.8826	Cost: 6.37s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 3.7514	Cost: 17.89s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 3.9092	Cost: 14.68s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 4.0539	Cost: 14.31s
Train Epoch: 90 	Average Loss: 3.8548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9642

Learning rate: 0.00019996003076502562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 3.9587	Cost: 28.80s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 3.9398	Cost: 6.20s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 3.9274	Cost: 14.15s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 3.7621	Cost: 6.38s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 3.8521	Cost: 21.78s
Train Epoch: 91 	Average Loss: 3.8653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8749

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Learning rate: 0.0001999591376861617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 3.7665	Cost: 26.92s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 3.7839	Cost: 6.51s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 3.7807	Cost: 13.90s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 3.6801	Cost: 6.43s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 3.8404	Cost: 21.73s
Train Epoch: 92 	Average Loss: 3.7888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0552

Learning rate: 0.0001999582347417264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 3.9325	Cost: 26.41s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 3.8198	Cost: 7.83s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 3.7284	Cost: 9.12s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 3.7024	Cost: 7.67s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 3.7478	Cost: 13.35s
Train Epoch: 93 	Average Loss: 3.7918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8568

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 0.00019995732193180883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 3.8097	Cost: 27.04s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 3.9572	Cost: 6.25s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 3.6334	Cost: 13.30s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 3.6504	Cost: 8.69s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 3.8921	Cost: 8.88s
Train Epoch: 94 	Average Loss: 3.7669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8451

Saving model as e94_model.pt & e94_waveforms_supplementary.hdf5
Learning rate: 0.00019995639925649909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 3.8671	Cost: 27.67s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 3.7888	Cost: 6.08s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 3.7185	Cost: 11.98s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 3.6281	Cost: 6.02s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 3.7349	Cost: 9.83s
Train Epoch: 95 	Average Loss: 3.7446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7909

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00019995546671588827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 3.7571	Cost: 29.40s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 3.8264	Cost: 12.87s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 3.7035	Cost: 14.81s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 3.5994	Cost: 9.55s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 3.5654	Cost: 9.26s
Train Epoch: 96 	Average Loss: 3.6998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7903

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Learning rate: 0.0001999545243100684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 3.6280	Cost: 28.64s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 3.8886	Cost: 6.36s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 3.6383	Cost: 13.66s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 3.5816	Cost: 13.87s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 3.6769	Cost: 14.48s
Train Epoch: 97 	Average Loss: 3.6757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6743

Saving model as e97_model.pt & e97_waveforms_supplementary.hdf5
Learning rate: 0.00019995357203913245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 3.6326	Cost: 27.38s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 3.6601	Cost: 6.59s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 3.5843	Cost: 13.33s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 3.5245	Cost: 8.18s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 3.6592	Cost: 19.85s
Train Epoch: 98 	Average Loss: 3.6735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8198

Learning rate: 0.00019995260990317447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 3.8099	Cost: 26.33s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 3.7498	Cost: 6.60s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 3.5858	Cost: 13.62s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 3.6002	Cost: 6.38s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 3.5232	Cost: 16.18s
Train Epoch: 99 	Average Loss: 3.6813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6733

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Learning rate: 0.00019995163790228936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 3.6534	Cost: 25.69s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 3.6584	Cost: 8.62s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 3.5340	Cost: 9.12s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 3.5738	Cost: 7.41s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 3.7027	Cost: 12.67s
Train Epoch: 100 	Average Loss: 3.6425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7478

Learning rate: 0.0001999506560365731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 3.7434	Cost: 26.07s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 3.6749	Cost: 6.26s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 3.6698	Cost: 15.05s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 3.6128	Cost: 8.78s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 3.5475	Cost: 7.32s
Train Epoch: 101 	Average Loss: 3.5898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8171

Learning rate: 0.00019994966430612258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 3.7100	Cost: 28.53s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 3.7206	Cost: 6.46s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 3.7303	Cost: 13.75s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 3.6199	Cost: 8.68s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 3.5833	Cost: 10.30s
Train Epoch: 102 	Average Loss: 3.6101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6158

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00019994866271103568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 3.5750	Cost: 29.39s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 3.6260	Cost: 6.18s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 3.4514	Cost: 13.78s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 3.6548	Cost: 6.24s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 3.5118	Cost: 12.71s
Train Epoch: 103 	Average Loss: 3.5424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5796

Saving model as e103_model.pt & e103_waveforms_supplementary.hdf5
Learning rate: 0.0001999476512514112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 3.5040	Cost: 36.24s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 3.5678	Cost: 13.93s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 3.4418	Cost: 6.19s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 3.4188	Cost: 6.03s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 3.6243	Cost: 11.61s
Train Epoch: 104 	Average Loss: 3.5306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5821

Learning rate: 0.00019994662992734905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 3.5545	Cost: 34.29s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 3.8075	Cost: 8.37s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 3.5997	Cost: 12.00s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 3.5356	Cost: 7.76s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 3.4536	Cost: 19.94s
Train Epoch: 105 	Average Loss: 3.5455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6655

Learning rate: 0.00019994559873894998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 3.8513	Cost: 30.81s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 3.7097	Cost: 8.36s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 3.4680	Cost: 11.86s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 3.5165	Cost: 6.18s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 3.5929	Cost: 21.62s
Train Epoch: 106 	Average Loss: 3.5528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5432

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 0.00019994455768631577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 3.5530	Cost: 32.33s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 3.5252	Cost: 7.37s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 3.4150	Cost: 12.51s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 3.4744	Cost: 6.14s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 3.6969	Cost: 15.82s
Train Epoch: 107 	Average Loss: 3.5284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5741

Learning rate: 0.00019994350676954918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 3.6000	Cost: 29.92s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 3.5711	Cost: 8.68s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 3.3411	Cost: 9.88s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 3.4749	Cost: 8.56s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 3.4309	Cost: 6.02s
Train Epoch: 108 	Average Loss: 3.4920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5164

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Learning rate: 0.00019994244598875392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 3.4823	Cost: 28.17s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 3.4681	Cost: 6.17s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 3.4523	Cost: 12.03s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 3.7005	Cost: 6.69s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 3.3770	Cost: 11.58s
Train Epoch: 109 	Average Loss: 3.4503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5152

Saving model as e109_model.pt & e109_waveforms_supplementary.hdf5
Learning rate: 0.00019994137534403472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 3.5171	Cost: 29.20s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 3.5782	Cost: 12.12s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 3.2777	Cost: 6.07s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 3.4382	Cost: 6.06s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 3.3608	Cost: 11.41s
Train Epoch: 110 	Average Loss: 3.4219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5888

Learning rate: 0.00019994029483549723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 3.5281	Cost: 31.48s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 3.6352	Cost: 15.09s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 3.5380	Cost: 8.69s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 3.4537	Cost: 11.99s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 3.4242	Cost: 6.08s
Train Epoch: 111 	Average Loss: 3.4868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5094

Saving model as e111_model.pt & e111_waveforms_supplementary.hdf5
Learning rate: 0.00019993920446324803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 3.6241	Cost: 31.21s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 3.4138	Cost: 6.60s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 3.4256	Cost: 16.63s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 3.3693	Cost: 14.85s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 3.4771	Cost: 13.62s
Train Epoch: 112 	Average Loss: 3.4421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5372

Learning rate: 0.00019993810422739487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 3.4823	Cost: 27.27s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 3.5786	Cost: 6.30s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 3.3187	Cost: 14.06s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 3.3089	Cost: 6.08s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 3.4428	Cost: 21.22s
Train Epoch: 113 	Average Loss: 3.4211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4912

Saving model as e113_model.pt & e113_waveforms_supplementary.hdf5
Learning rate: 0.00019993699412804622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 3.3698	Cost: 26.19s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 3.4086	Cost: 6.40s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 3.2638	Cost: 13.52s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 3.3076	Cost: 6.18s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 3.4481	Cost: 21.65s
Train Epoch: 114 	Average Loss: 3.3617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5145

Learning rate: 0.00019993587416531166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 3.6738	Cost: 25.77s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 3.5056	Cost: 6.89s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 3.3352	Cost: 13.52s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 3.4447	Cost: 6.38s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 3.3545	Cost: 13.45s
Train Epoch: 115 	Average Loss: 3.4092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4132

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Learning rate: 0.00019993474433930176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 3.3887	Cost: 26.61s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 3.5219	Cost: 8.82s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 3.3772	Cost: 7.90s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 3.3717	Cost: 5.95s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 3.3176	Cost: 10.91s
Train Epoch: 116 	Average Loss: 3.3921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4144

Learning rate: 0.000199933604650128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 3.5927	Cost: 26.77s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 3.3869	Cost: 6.26s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 3.3335	Cost: 13.34s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 3.4198	Cost: 8.95s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 3.3674	Cost: 10.78s
Train Epoch: 117 	Average Loss: 3.3839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4461

Learning rate: 0.0001999324550979029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 3.4880	Cost: 27.07s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 3.5056	Cost: 6.15s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 3.2238	Cost: 12.35s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 3.2917	Cost: 6.30s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 3.2866	Cost: 11.52s
Train Epoch: 118 	Average Loss: 3.3559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4500

Learning rate: 0.00019993129568273988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 3.5920	Cost: 30.04s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 3.4247	Cost: 6.39s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 3.1910	Cost: 16.75s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 3.1685	Cost: 11.62s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 3.4529	Cost: 11.32s
Train Epoch: 119 	Average Loss: 3.3456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4708

Learning rate: 0.0001999301264047534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 3.5317	Cost: 29.19s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 3.3117	Cost: 6.49s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 3.1952	Cost: 15.97s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 3.3407	Cost: 15.37s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 3.3105	Cost: 11.47s
Train Epoch: 120 	Average Loss: 3.3142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3468

Saving model as e120_model.pt & e120_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 3.3843	Cost: 26.22s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 3.2683	Cost: 6.29s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 3.3620	Cost: 14.73s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 3.1657	Cost: 7.35s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 3.2110	Cost: 17.89s
Train Epoch: 121 	Average Loss: 3.3092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4751

Learning rate: 0.00019992775826077256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 3.4967	Cost: 25.67s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 3.3085	Cost: 6.26s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 3.2154	Cost: 14.68s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 3.2049	Cost: 7.51s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 3.2489	Cost: 12.82s
Train Epoch: 122 	Average Loss: 3.3072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4403

Learning rate: 0.00019992655939501196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 3.3466	Cost: 25.69s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 3.2362	Cost: 8.63s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 3.3827	Cost: 9.60s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 3.1674	Cost: 8.84s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 3.3270	Cost: 8.86s
Train Epoch: 123 	Average Loss: 3.2870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4284

Learning rate: 0.00019992535066689534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 3.2987	Cost: 27.66s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 3.2648	Cost: 11.98s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 3.1857	Cost: 6.02s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 3.2099	Cost: 6.07s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 3.3659	Cost: 11.53s
Train Epoch: 124 	Average Loss: 3.2523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3585

Learning rate: 0.00019992413207654198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 3.3025	Cost: 30.04s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 3.2387	Cost: 12.01s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 3.3341	Cost: 14.35s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 3.1790	Cost: 10.41s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 3.3333	Cost: 9.42s
Train Epoch: 125 	Average Loss: 3.2726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3276

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 3.4913	Cost: 29.07s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 3.2357	Cost: 6.08s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 3.2013	Cost: 16.45s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 3.2320	Cost: 15.48s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 3.1053	Cost: 10.21s
Train Epoch: 126 	Average Loss: 3.2583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3840

Learning rate: 0.0001999216653096072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 3.3180	Cost: 27.89s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 3.3762	Cost: 6.51s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 3.4117	Cost: 14.31s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 3.1076	Cost: 6.25s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 3.3295	Cost: 21.06s
Train Epoch: 127 	Average Loss: 3.2644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2570

Saving model as e127_model.pt & e127_waveforms_supplementary.hdf5
Learning rate: 0.00019992041713326917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 3.2629	Cost: 26.33s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 3.1247	Cost: 6.60s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 3.2550	Cost: 14.81s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 3.0872	Cost: 7.66s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 3.3008	Cost: 22.90s
Train Epoch: 128 	Average Loss: 3.2160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3519

Learning rate: 0.00019991915909518135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 3.4153	Cost: 25.48s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 3.1530	Cost: 5.94s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 3.0946	Cost: 15.17s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 3.0990	Cost: 6.82s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 3.1757	Cost: 14.01s
Train Epoch: 129 	Average Loss: 3.1912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2932

Learning rate: 0.0001999178911954679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 3.3252	Cost: 26.96s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 3.2084	Cost: 6.92s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 3.1834	Cost: 11.50s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 3.1422	Cost: 8.86s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 3.2186	Cost: 9.42s
Train Epoch: 130 	Average Loss: 3.1824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3596

Learning rate: 0.0001999166134342539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 3.3801	Cost: 26.14s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 3.1802	Cost: 6.23s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 3.0486	Cost: 13.11s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 3.0654	Cost: 6.21s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 3.1992	Cost: 15.33s
Train Epoch: 131 	Average Loss: 3.1647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2438

Saving model as e131_model.pt & e131_waveforms_supplementary.hdf5
Learning rate: 0.00019991532581166554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 3.2410	Cost: 27.08s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 3.2161	Cost: 6.11s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 3.2848	Cost: 14.77s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 3.1136	Cost: 6.28s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 3.2121	Cost: 10.39s
Train Epoch: 132 	Average Loss: 3.2217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3458

Learning rate: 0.00019991402832782987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 3.4268	Cost: 29.56s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 3.1734	Cost: 6.32s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 3.1260	Cost: 18.89s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 3.2019	Cost: 14.12s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 3.1522	Cost: 7.97s
Train Epoch: 133 	Average Loss: 3.1618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2211

Saving model as e133_model.pt & e133_waveforms_supplementary.hdf5
Learning rate: 0.00019991272098287494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 3.1994	Cost: 27.63s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 3.1960	Cost: 7.53s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 3.1334	Cost: 14.08s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 3.0082	Cost: 11.51s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 3.1084	Cost: 15.19s
Train Epoch: 134 	Average Loss: 3.1264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2357

Learning rate: 0.00019991140377692977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 3.2348	Cost: 26.92s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 3.2045	Cost: 8.09s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 3.0514	Cost: 15.09s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 3.0408	Cost: 7.40s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 3.1856	Cost: 13.12s
Train Epoch: 135 	Average Loss: 3.1179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2249

Learning rate: 0.0001999100767101244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 3.2175	Cost: 25.54s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 3.1778	Cost: 9.01s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 3.0819	Cost: 10.14s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 3.1094	Cost: 6.90s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 3.2594	Cost: 11.43s
Train Epoch: 136 	Average Loss: 3.1218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2006

Saving model as e136_model.pt & e136_waveforms_supplementary.hdf5
Learning rate: 0.00019990873978258976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 3.2368	Cost: 28.00s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 3.2106	Cost: 7.88s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 3.1477	Cost: 13.39s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 3.0533	Cost: 8.70s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 3.0668	Cost: 6.73s
Train Epoch: 137 	Average Loss: 3.1079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1952

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 0.0001999073929944578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 3.2279	Cost: 32.87s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 3.1596	Cost: 6.34s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 2.9144	Cost: 12.81s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 2.8612	Cost: 6.54s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 3.0286	Cost: 11.72s
Train Epoch: 138 	Average Loss: 3.0432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1028

Saving model as e138_model.pt & e138_waveforms_supplementary.hdf5
Learning rate: 0.00019990603634586154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 3.0625	Cost: 33.05s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 2.9850	Cost: 6.19s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 3.0379	Cost: 12.33s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 2.9739	Cost: 6.03s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 3.0290	Cost: 11.79s
Train Epoch: 139 	Average Loss: 3.0842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2945

Learning rate: 0.00019990466983693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 3.2059	Cost: 34.31s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 3.1465	Cost: 6.17s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 2.9477	Cost: 15.84s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 2.9581	Cost: 5.91s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 3.2035	Cost: 8.25s
Train Epoch: 140 	Average Loss: 3.0798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2500

Learning rate: 0.00019990329346781236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 3.1969	Cost: 35.36s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 3.1136	Cost: 7.12s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 2.9553	Cost: 16.92s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 2.9353	Cost: 10.16s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 3.1401	Cost: 11.85s
Train Epoch: 141 	Average Loss: 3.0583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1447

Learning rate: 0.00019990190723863022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 3.3154	Cost: 35.02s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 2.9692	Cost: 7.79s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 2.8481	Cost: 13.24s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 3.1228	Cost: 12.35s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 3.1195	Cost: 15.01s
Train Epoch: 142 	Average Loss: 3.0480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1636

Learning rate: 0.00019990051114952508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 3.2914	Cost: 29.11s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 2.9848	Cost: 8.92s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 2.9460	Cost: 11.94s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 3.0365	Cost: 6.10s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 2.9722	Cost: 21.89s
Train Epoch: 143 	Average Loss: 3.0345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1734

Learning rate: 0.0001998991052006348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 3.2003	Cost: 26.70s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 3.0941	Cost: 7.72s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 2.9374	Cost: 12.15s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 2.9466	Cost: 6.30s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 2.9642	Cost: 12.88s
Train Epoch: 144 	Average Loss: 3.0478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0792

Saving model as e144_model.pt & e144_waveforms_supplementary.hdf5
Learning rate: 0.0001998976893920981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 2.9239	Cost: 30.53s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 3.0292	Cost: 8.79s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 2.8756	Cost: 10.49s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 2.9047	Cost: 6.05s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 2.9749	Cost: 8.94s
Train Epoch: 145 	Average Loss: 3.0080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0976

Learning rate: 0.00019989626372405477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 3.0423	Cost: 28.50s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 3.1101	Cost: 6.21s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 3.0413	Cost: 13.00s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 2.8906	Cost: 8.62s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 2.9088	Cost: 8.39s
Train Epoch: 146 	Average Loss: 3.0117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0501

Saving model as e146_model.pt & e146_waveforms_supplementary.hdf5
Learning rate: 0.00019989482819664545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 3.0924	Cost: 29.63s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 2.9227	Cost: 12.05s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 2.8931	Cost: 6.23s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 2.8928	Cost: 6.07s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 3.0671	Cost: 10.96s
Train Epoch: 147 	Average Loss: 2.9929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1094

Learning rate: 0.00019989338281001189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 3.0605	Cost: 34.66s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 3.0669	Cost: 15.57s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 2.8387	Cost: 6.09s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 2.8201	Cost: 11.72s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 2.9543	Cost: 6.20s
Train Epoch: 148 	Average Loss: 3.0006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1026

Learning rate: 0.00019989192756429667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 3.1315	Cost: 31.01s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 2.9622	Cost: 6.39s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 2.8668	Cost: 14.65s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 2.9023	Cost: 14.97s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 2.9357	Cost: 14.93s
Train Epoch: 149 	Average Loss: 2.9673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0189

Saving model as e149_model.pt & e149_waveforms_supplementary.hdf5
Learning rate: 0.00019989046245964345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 3.0472	Cost: 27.75s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 2.9521	Cost: 6.77s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 2.7490	Cost: 13.40s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 2.9717	Cost: 6.20s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 3.0195	Cost: 21.75s
Train Epoch: 150 	Average Loss: 2.9529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0839

Learning rate: 0.00019988898749619688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 3.1078	Cost: 25.85s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 2.9387	Cost: 6.32s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 2.9899	Cost: 14.48s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 2.8688	Cost: 6.17s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 3.0278	Cost: 21.44s
Train Epoch: 151 	Average Loss: 2.9802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1152

Learning rate: 0.00019988750267410245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 3.1576	Cost: 24.77s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 3.0372	Cost: 6.01s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 2.7625	Cost: 12.87s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 2.8329	Cost: 6.33s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 2.8725	Cost: 13.98s
Train Epoch: 152 	Average Loss: 2.9391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9888

Saving model as e152_model.pt & e152_waveforms_supplementary.hdf5
Learning rate: 0.0001998860079935067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 2.9723	Cost: 25.71s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 2.8260	Cost: 8.90s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 2.8147	Cost: 9.79s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 2.9428	Cost: 8.56s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 2.9928	Cost: 7.90s
Train Epoch: 153 	Average Loss: 2.9192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0419

Learning rate: 0.00019988450345455726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 3.1427	Cost: 26.66s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 3.1510	Cost: 9.48s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 2.8271	Cost: 8.58s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 2.9165	Cost: 6.00s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 2.8587	Cost: 11.53s
Train Epoch: 154 	Average Loss: 2.9730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1032

Learning rate: 0.00019988298905740252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 3.0058	Cost: 28.77s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 2.9339	Cost: 13.12s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 2.7486	Cost: 14.40s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 2.8705	Cost: 8.79s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 2.9929	Cost: 9.78s
Train Epoch: 155 	Average Loss: 2.9094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0009

Learning rate: 0.000199881464802192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 3.0386	Cost: 29.23s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 2.8531	Cost: 6.14s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 2.8811	Cost: 14.24s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 2.8510	Cost: 14.64s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 2.8334	Cost: 12.58s
Train Epoch: 156 	Average Loss: 2.9061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9663

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Learning rate: 0.0001998799306890761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 2.9101	Cost: 28.71s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 2.8671	Cost: 6.25s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 2.7380	Cost: 13.59s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 2.8332	Cost: 8.52s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 2.9205	Cost: 18.37s
Train Epoch: 157 	Average Loss: 2.8785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0186

Learning rate: 0.00019987838671820622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 3.1887	Cost: 26.51s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 2.9480	Cost: 6.28s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 2.8429	Cost: 13.88s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 2.7774	Cost: 6.31s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 2.8347	Cost: 21.66s
Train Epoch: 158 	Average Loss: 2.8979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9901

Learning rate: 0.00019987683288973478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 3.0786	Cost: 26.08s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 3.0074	Cost: 6.49s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 2.7995	Cost: 13.10s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 2.7413	Cost: 6.35s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 3.0213	Cost: 13.75s
Train Epoch: 159 	Average Loss: 2.8715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0368

Learning rate: 0.00019987526920381513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 3.0130	Cost: 26.30s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 2.9339	Cost: 7.23s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 2.7814	Cost: 11.91s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 2.8883	Cost: 8.75s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 2.8464	Cost: 8.03s
Train Epoch: 160 	Average Loss: 2.8690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9733

Learning rate: 0.00019987369566060162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 2.9434	Cost: 26.76s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 2.8302	Cost: 6.06s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 2.7601	Cost: 12.13s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 2.7857	Cost: 5.99s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 2.7913	Cost: 12.02s
Train Epoch: 161 	Average Loss: 2.8353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9744

Learning rate: 0.0001998721122602495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 2.8868	Cost: 27.57s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 2.8248	Cost: 6.06s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 2.8262	Cost: 15.15s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 2.6960	Cost: 5.91s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 2.8617	Cost: 8.93s
Train Epoch: 162 	Average Loss: 2.8077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9982

Learning rate: 0.00019987051900291508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 3.0477	Cost: 30.09s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 2.8889	Cost: 14.16s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 2.7473	Cost: 14.08s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 2.6925	Cost: 11.29s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 2.8961	Cost: 6.61s
Train Epoch: 163 	Average Loss: 2.8371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0361

Learning rate: 0.00019986891588875562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 2.9222	Cost: 28.73s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 2.8385	Cost: 6.29s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 2.8142	Cost: 15.46s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 2.8037	Cost: 15.38s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 2.7719	Cost: 10.38s
Train Epoch: 164 	Average Loss: 2.8197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9374

Saving model as e164_model.pt & e164_waveforms_supplementary.hdf5
Learning rate: 0.0001998673029179293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 2.9434	Cost: 29.01s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 2.8549	Cost: 6.43s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 2.7755	Cost: 14.02s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 2.8468	Cost: 9.12s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 2.9502	Cost: 18.86s
Train Epoch: 165 	Average Loss: 2.8149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9381

Learning rate: 0.00019986568009059536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 2.9169	Cost: 26.76s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 2.8180	Cost: 6.32s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 2.5813	Cost: 14.34s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 2.6158	Cost: 6.17s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 2.7855	Cost: 21.43s
Train Epoch: 166 	Average Loss: 2.8083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9304

Saving model as e166_model.pt & e166_waveforms_supplementary.hdf5
Learning rate: 0.00019986404740691393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 2.9099	Cost: 26.74s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 2.7812	Cost: 7.81s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 2.7621	Cost: 9.64s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 2.6687	Cost: 6.27s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 2.9006	Cost: 13.99s
Train Epoch: 167 	Average Loss: 2.8084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9239

Saving model as e167_model.pt & e167_waveforms_supplementary.hdf5
Learning rate: 0.00019986240486704617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 2.9300	Cost: 27.34s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 3.0091	Cost: 6.37s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 2.6435	Cost: 12.97s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 2.7914	Cost: 8.49s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 2.7793	Cost: 8.97s
Train Epoch: 168 	Average Loss: 2.7833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0444

Learning rate: 0.00019986075247115415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 2.9705	Cost: 27.31s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 2.7749	Cost: 6.08s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 2.6885	Cost: 13.55s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 2.6100	Cost: 5.95s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 2.7753	Cost: 10.10s
Train Epoch: 169 	Average Loss: 2.7623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8987

Saving model as e169_model.pt & e169_waveforms_supplementary.hdf5
Learning rate: 0.00019985909021940103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 2.8784	Cost: 28.43s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 2.8421	Cost: 14.03s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 2.6482	Cost: 14.11s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 2.7380	Cost: 8.32s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 2.7192	Cost: 9.61s
Train Epoch: 170 	Average Loss: 2.7416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8813

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 0.0001998574181119508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 2.9825	Cost: 29.41s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 2.7252	Cost: 6.42s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 2.7079	Cost: 15.93s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 2.6447	Cost: 15.20s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 2.7522	Cost: 13.80s
Train Epoch: 171 	Average Loss: 2.7361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8617

Saving model as e171_model.pt & e171_waveforms_supplementary.hdf5
Learning rate: 0.00019985573614896853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 2.9618	Cost: 28.61s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 2.7896	Cost: 6.53s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 2.6317	Cost: 13.53s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 2.5780	Cost: 14.20s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 2.7788	Cost: 14.22s
Train Epoch: 172 	Average Loss: 2.7512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8893

Learning rate: 0.00019985404433062024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 2.9500	Cost: 26.68s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 2.6803	Cost: 6.49s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 2.7003	Cost: 13.57s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 2.5832	Cost: 6.60s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 2.7241	Cost: 21.03s
Train Epoch: 173 	Average Loss: 2.7041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8703

Learning rate: 0.00019985234265707287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 3.0088	Cost: 26.85s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 2.8090	Cost: 6.10s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 2.6297	Cost: 12.73s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 2.6421	Cost: 7.01s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 2.7804	Cost: 14.46s
Train Epoch: 174 	Average Loss: 2.7526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8137

Saving model as e174_model.pt & e174_waveforms_supplementary.hdf5
Learning rate: 0.00019985063112849436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 2.8129	Cost: 26.25s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 2.6520	Cost: 8.63s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 2.6219	Cost: 9.12s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 2.6442	Cost: 9.03s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 2.9179	Cost: 8.92s
Train Epoch: 175 	Average Loss: 2.7103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8579

Learning rate: 0.00019984890974505368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 2.8854	Cost: 26.98s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 2.8302	Cost: 7.04s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 2.5417	Cost: 9.78s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 2.6771	Cost: 6.31s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 2.8181	Cost: 13.55s
Train Epoch: 176 	Average Loss: 2.7172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8802

Learning rate: 0.00019984717850692066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 2.8317	Cost: 33.71s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 2.6977	Cost: 6.37s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 2.6120	Cost: 12.17s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 2.5596	Cost: 12.24s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 2.6382	Cost: 6.98s
Train Epoch: 177 	Average Loss: 2.6922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8838

Learning rate: 0.00019984543741426617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 2.8637	Cost: 28.74s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 2.6469	Cost: 6.53s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 2.6645	Cost: 18.91s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 2.5067	Cost: 15.54s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 2.6631	Cost: 6.34s
Train Epoch: 178 	Average Loss: 2.6609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8167

Learning rate: 0.0001998436864672621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 2.7734	Cost: 26.88s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 2.6253	Cost: 6.47s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 2.5764	Cost: 19.63s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 2.5426	Cost: 8.54s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 2.6245	Cost: 17.92s
Train Epoch: 179 	Average Loss: 2.6578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7668

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Learning rate: 0.00019984192566608125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 2.9927	Cost: 27.61s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 2.5062	Cost: 8.87s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 2.5602	Cost: 19.80s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 2.5707	Cost: 6.16s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 2.6958	Cost: 17.81s
Train Epoch: 180 	Average Loss: 2.6375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8741

Learning rate: 0.00019984015501089739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 3.0702	Cost: 27.60s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 2.6195	Cost: 7.92s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 2.6157	Cost: 10.61s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 2.5344	Cost: 6.69s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 2.6111	Cost: 13.22s
Train Epoch: 181 	Average Loss: 2.6788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8557

Learning rate: 0.00019983837450188524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 2.8932	Cost: 26.80s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 2.7145	Cost: 6.22s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 2.6088	Cost: 14.93s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 2.4981	Cost: 8.82s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 2.6467	Cost: 10.86s
Train Epoch: 182 	Average Loss: 2.6365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7560

Saving model as e182_model.pt & e182_waveforms_supplementary.hdf5
Learning rate: 0.0001998365841392206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 2.8078	Cost: 27.71s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 2.5062	Cost: 11.05s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 2.5142	Cost: 8.53s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 2.5459	Cost: 6.27s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 2.5449	Cost: 12.68s
Train Epoch: 183 	Average Loss: 2.5795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7907

Learning rate: 0.00019983478392308012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 2.7904	Cost: 28.98s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 2.6072	Cost: 16.22s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 2.5557	Cost: 13.22s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 2.5619	Cost: 8.05s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 2.5883	Cost: 9.99s
Train Epoch: 184 	Average Loss: 2.6217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7722

Learning rate: 0.0001998329738536415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 2.7325	Cost: 30.95s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 2.6609	Cost: 10.25s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 2.5373	Cost: 11.22s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 2.4517	Cost: 10.43s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 2.5644	Cost: 16.51s
Train Epoch: 185 	Average Loss: 2.5588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7811

Learning rate: 0.00019983115393108338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 2.7552	Cost: 34.64s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 2.6057	Cost: 7.76s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 2.3761	Cost: 12.85s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 2.4639	Cost: 6.41s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 2.7248	Cost: 21.07s
Train Epoch: 186 	Average Loss: 2.5968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7510

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Learning rate: 0.0001998293241555854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 2.6873	Cost: 29.36s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 2.6136	Cost: 8.83s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 2.5071	Cost: 12.35s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 2.4411	Cost: 6.22s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 2.5633	Cost: 21.96s
Train Epoch: 187 	Average Loss: 2.5664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8489

Learning rate: 0.0001998274845273281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 2.8092	Cost: 27.96s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 2.7170	Cost: 6.62s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 2.4806	Cost: 14.22s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 2.4945	Cost: 6.24s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 2.6691	Cost: 13.73s
Train Epoch: 188 	Average Loss: 2.5781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7349

Saving model as e188_model.pt & e188_waveforms_supplementary.hdf5
Learning rate: 0.00019982563504649309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 2.6803	Cost: 28.79s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 2.6383	Cost: 9.34s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 2.4702	Cost: 10.06s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 2.3873	Cost: 8.65s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 2.5869	Cost: 6.97s
Train Epoch: 189 	Average Loss: 2.5394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7482

Learning rate: 0.00019982377571326284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 2.7453	Cost: 31.02s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 2.5361	Cost: 6.16s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 2.4738	Cost: 13.82s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 2.5658	Cost: 6.05s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 2.5153	Cost: 13.21s
Train Epoch: 190 	Average Loss: 2.5451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7366

Learning rate: 0.00019982190652782097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 2.8288	Cost: 29.88s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 2.4436	Cost: 7.06s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 2.3397	Cost: 16.63s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 2.4858	Cost: 6.00s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 2.5913	Cost: 8.62s
Train Epoch: 191 	Average Loss: 2.5233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7134

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Learning rate: 0.0001998200274903519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 2.6041	Cost: 40.85s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 2.5837	Cost: 15.09s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 2.3988	Cost: 12.03s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 2.4208	Cost: 9.12s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 2.5568	Cost: 8.94s
Train Epoch: 192 	Average Loss: 2.5308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7188

Learning rate: 0.00019981813860104106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 2.7477	Cost: 38.87s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 2.5114	Cost: 6.31s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 2.4405	Cost: 17.21s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 2.4247	Cost: 15.71s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 2.5377	Cost: 12.88s
Train Epoch: 193 	Average Loss: 2.5219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7012

Saving model as e193_model.pt & e193_waveforms_supplementary.hdf5
Learning rate: 0.0001998162398600749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 2.6588	Cost: 28.63s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 2.4888	Cost: 6.96s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 2.4626	Cost: 13.73s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 2.4448	Cost: 10.36s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 2.4609	Cost: 17.19s
Train Epoch: 194 	Average Loss: 2.4952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6782

Saving model as e194_model.pt & e194_waveforms_supplementary.hdf5
Learning rate: 0.00019981433126764085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 2.6300	Cost: 26.02s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 2.6159	Cost: 6.51s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 2.4648	Cost: 14.68s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 2.3882	Cost: 6.24s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 2.4876	Cost: 21.53s
Train Epoch: 195 	Average Loss: 2.5166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6760

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Learning rate: 0.00019981241282392723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 2.6007	Cost: 26.02s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 2.5118	Cost: 6.24s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 2.4496	Cost: 14.38s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 2.4660	Cost: 6.29s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 2.4153	Cost: 18.88s
Train Epoch: 196 	Average Loss: 2.4674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6425

Saving model as e196_model.pt & e196_waveforms_supplementary.hdf5
Learning rate: 0.0001998104845291234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 2.6811	Cost: 25.74s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 2.4156	Cost: 6.28s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 2.3091	Cost: 12.71s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 2.3285	Cost: 6.36s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 2.4226	Cost: 14.33s
Train Epoch: 197 	Average Loss: 2.4510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6076

Saving model as e197_model.pt & e197_waveforms_supplementary.hdf5
Learning rate: 0.00019980854638341968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 2.5532	Cost: 26.32s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 2.3747	Cost: 8.20s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 2.2969	Cost: 10.80s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 2.3277	Cost: 8.42s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 2.3518	Cost: 8.14s
Train Epoch: 198 	Average Loss: 2.4287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6321

Learning rate: 0.00019980659838700736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 2.6675	Cost: 27.27s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 2.5461	Cost: 12.04s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 2.3509	Cost: 6.35s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 2.4635	Cost: 6.12s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 2.5201	Cost: 11.91s
Train Epoch: 199 	Average Loss: 2.4723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6370

Learning rate: 0.0001998046405400787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 2.6222	Cost: 28.99s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 2.4474	Cost: 14.88s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 2.3344	Cost: 8.14s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 2.3690	Cost: 6.01s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 2.4153	Cost: 11.81s
Train Epoch: 200 	Average Loss: 2.4372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6659

Learning rate: 0.00019980267284282693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 2.6931	Cost: 29.27s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 2.4777	Cost: 6.35s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 2.3446	Cost: 16.33s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 2.4445	Cost: 15.69s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 2.4867	Cost: 14.20s
Train Epoch: 201 	Average Loss: 2.4315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5530

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 0.00019980069529544622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 2.6046	Cost: 28.62s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 2.3631	Cost: 6.75s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 2.2891	Cost: 13.28s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 2.2533	Cost: 12.17s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 2.3497	Cost: 15.28s
Train Epoch: 202 	Average Loss: 2.4086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5399

Saving model as e202_model.pt & e202_waveforms_supplementary.hdf5
Learning rate: 0.0001997987078981318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 2.6738	Cost: 27.58s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 2.4141	Cost: 6.22s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 2.4247	Cost: 14.38s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 2.4172	Cost: 6.13s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 2.4308	Cost: 21.48s
Train Epoch: 203 	Average Loss: 2.4237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5760

Learning rate: 0.00019979671065107978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 2.5190	Cost: 26.98s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 2.5248	Cost: 6.73s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 2.4111	Cost: 13.26s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 2.3528	Cost: 6.39s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 2.2785	Cost: 13.92s
Train Epoch: 204 	Average Loss: 2.3709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5770

Learning rate: 0.0001997947035544873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 2.7010	Cost: 27.30s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 2.4508	Cost: 6.80s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 2.2315	Cost: 11.30s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 2.3276	Cost: 8.89s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 2.3367	Cost: 9.27s
Train Epoch: 205 	Average Loss: 2.3762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5664

Learning rate: 0.00019979268660855247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 2.4266	Cost: 27.71s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 2.4083	Cost: 12.09s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 2.3148	Cost: 6.11s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 2.2638	Cost: 6.05s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 2.3830	Cost: 11.09s
Train Epoch: 206 	Average Loss: 2.3827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5313

Saving model as e206_model.pt & e206_waveforms_supplementary.hdf5
Learning rate: 0.00019979065981347432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 2.5643	Cost: 29.69s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 2.3894	Cost: 14.91s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 2.2941	Cost: 9.08s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 2.0938	Cost: 8.45s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 2.3439	Cost: 9.57s
Train Epoch: 207 	Average Loss: 2.3425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5976

Learning rate: 0.0001997886231694529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 2.6208	Cost: 28.70s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 2.4800	Cost: 6.21s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 2.1988	Cost: 15.13s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 2.0881	Cost: 15.23s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 2.2765	Cost: 13.90s
Train Epoch: 208 	Average Loss: 2.3424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5709

Learning rate: 0.0001997865766766892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 2.5987	Cost: 28.11s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 2.3660	Cost: 6.41s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 2.2033	Cost: 13.85s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 2.1154	Cost: 6.14s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 2.3891	Cost: 21.88s
Train Epoch: 209 	Average Loss: 2.2953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5416

Learning rate: 0.00019978452033538524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 2.5366	Cost: 27.11s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 2.2860	Cost: 6.43s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 2.3429	Cost: 14.10s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 2.2449	Cost: 6.19s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 2.3117	Cost: 19.95s
Train Epoch: 210 	Average Loss: 2.3289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5656

Learning rate: 0.00019978245414574395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 2.6322	Cost: 26.70s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 2.2680	Cost: 8.81s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 2.1772	Cost: 8.38s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 2.2753	Cost: 6.11s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 2.2593	Cost: 10.34s
Train Epoch: 211 	Average Loss: 2.3067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5119

Saving model as e211_model.pt & e211_waveforms_supplementary.hdf5
Learning rate: 0.00019978037810796924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 2.6149	Cost: 26.60s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 2.2789	Cost: 6.28s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 2.1120	Cost: 13.24s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 2.1995	Cost: 8.96s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 2.2375	Cost: 10.53s
Train Epoch: 212 	Average Loss: 2.2991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5321

Learning rate: 0.000199778292222266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 2.5560	Cost: 27.68s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 2.3402	Cost: 6.17s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 2.1794	Cost: 12.69s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 2.1988	Cost: 6.34s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 2.2887	Cost: 11.19s
Train Epoch: 213 	Average Loss: 2.2885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5023

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Learning rate: 0.00019977619648884015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 2.5483	Cost: 25.99s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 2.2887	Cost: 6.16s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 2.1986	Cost: 10.71s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 2.1556	Cost: 6.67s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 2.3754	Cost: 12.09s
Train Epoch: 214 	Average Loss: 2.2799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5154

Learning rate: 0.0001997740909078985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 2.6447	Cost: 26.14s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 2.2175	Cost: 6.20s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 2.2150	Cost: 11.83s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 2.0926	Cost: 5.90s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 2.3863	Cost: 10.99s
Train Epoch: 215 	Average Loss: 2.2881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4856

Saving model as e215_model.pt & e215_waveforms_supplementary.hdf5
Learning rate: 0.0001997719754796489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 2.4742	Cost: 25.48s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 2.2864	Cost: 6.69s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 2.1619	Cost: 11.16s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 2.1982	Cost: 5.89s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 2.2392	Cost: 9.58s
Train Epoch: 216 	Average Loss: 2.2657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4764

Saving model as e216_model.pt & e216_waveforms_supplementary.hdf5
Learning rate: 0.00019976985020430003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 2.5850	Cost: 25.46s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 2.1958	Cost: 6.08s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 2.1354	Cost: 12.58s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 2.0944	Cost: 6.28s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 2.2696	Cost: 9.31s
Train Epoch: 217 	Average Loss: 2.2304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4168

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 0.00019976771508206176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 2.3600	Cost: 26.10s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 2.2771	Cost: 6.01s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 2.1641	Cost: 12.63s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 2.2835	Cost: 6.01s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 2.0929	Cost: 12.38s
Train Epoch: 218 	Average Loss: 2.2706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5047

Learning rate: 0.00019976557011314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 2.4433	Cost: 25.38s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 2.3928	Cost: 5.99s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 2.2629	Cost: 10.60s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 2.2148	Cost: 6.16s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 2.1901	Cost: 9.58s
Train Epoch: 219 	Average Loss: 2.2640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4783

Learning rate: 0.00019976341529776072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 2.4978	Cost: 28.54s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 2.2274	Cost: 6.23s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 2.1296	Cost: 11.54s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 2.1312	Cost: 6.00s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 2.1287	Cost: 9.73s
Train Epoch: 220 	Average Loss: 2.1975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4047

Saving model as e220_model.pt & e220_waveforms_supplementary.hdf5
Learning rate: 0.00019976125063612233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 2.4498	Cost: 32.35s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 2.2577	Cost: 11.79s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 2.1841	Cost: 6.23s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 2.1560	Cost: 12.01s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 2.1055	Cost: 5.69s
Train Epoch: 221 	Average Loss: 2.2063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4915

Learning rate: 0.00019975907612844327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 2.3655	Cost: 27.91s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 2.1675	Cost: 7.94s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 2.1293	Cost: 11.62s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 2.1070	Cost: 5.99s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 2.1864	Cost: 20.62s
Train Epoch: 222 	Average Loss: 2.1788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3985

Saving model as e222_model.pt & e222_waveforms_supplementary.hdf5
Learning rate: 0.00019975689177493812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 2.3717	Cost: 25.53s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 2.2495	Cost: 8.08s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 2.1535	Cost: 11.96s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 2.0664	Cost: 7.06s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 2.1544	Cost: 11.06s
Train Epoch: 223 	Average Loss: 2.1500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4549

Learning rate: 0.00019975469757582245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 2.5168	Cost: 27.27s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 2.2308	Cost: 7.14s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 2.0286	Cost: 11.10s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 2.1032	Cost: 8.75s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 2.0690	Cost: 8.80s
Train Epoch: 224 	Average Loss: 2.1635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3971

Saving model as e224_model.pt & e224_waveforms_supplementary.hdf5
Learning rate: 0.00019975249353131286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 2.4716	Cost: 28.15s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 2.2072	Cost: 7.98s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 2.0680	Cost: 9.88s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 2.0327	Cost: 5.98s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 2.0407	Cost: 9.40s
Train Epoch: 225 	Average Loss: 2.1516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3687

Saving model as e225_model.pt & e225_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 2.3600	Cost: 25.95s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 2.1662	Cost: 6.17s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 1.9333	Cost: 15.97s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 2.1195	Cost: 5.93s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 2.1778	Cost: 5.77s
Train Epoch: 226 	Average Loss: 2.1433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3930

Learning rate: 0.0001997480559069829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 2.3658	Cost: 29.51s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 2.1292	Cost: 6.53s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 2.0790	Cost: 16.24s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 2.0317	Cost: 11.71s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 2.1300	Cost: 11.77s
Train Epoch: 227 	Average Loss: 2.1130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3306

Saving model as e227_model.pt & e227_waveforms_supplementary.hdf5
Learning rate: 0.00019974582232760058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 2.3933	Cost: 26.63s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 2.1420	Cost: 6.00s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 2.0401	Cost: 13.17s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 2.1143	Cost: 7.38s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 2.1420	Cost: 18.69s
Train Epoch: 228 	Average Loss: 2.1259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3553

Learning rate: 0.0001997435789037002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 2.2520	Cost: 25.52s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 2.1562	Cost: 6.01s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 2.0486	Cost: 12.27s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 2.0217	Cost: 6.09s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 2.0122	Cost: 13.05s
Train Epoch: 229 	Average Loss: 2.0909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3333

Learning rate: 0.0001997413256355033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 2.4482	Cost: 29.02s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 2.1841	Cost: 7.46s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 2.0418	Cost: 11.43s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 2.0265	Cost: 8.55s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 2.0429	Cost: 7.95s
Train Epoch: 230 	Average Loss: 2.0848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3948

Learning rate: 0.0001997390625232322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 2.3410	Cost: 30.15s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 2.1102	Cost: 12.11s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 2.0086	Cost: 6.20s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 2.0929	Cost: 6.06s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 2.0948	Cost: 9.25s
Train Epoch: 231 	Average Loss: 2.0748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3813

Learning rate: 0.00019973678956711026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 2.2121	Cost: 27.99s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 2.1339	Cost: 8.24s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 1.9635	Cost: 15.38s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 1.9925	Cost: 12.51s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 2.0196	Cost: 11.79s
Train Epoch: 232 	Average Loss: 2.0705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3456

Learning rate: 0.00019973450676736185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 2.3289	Cost: 26.53s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 2.2145	Cost: 8.21s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 1.9658	Cost: 11.51s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 2.0232	Cost: 6.14s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 1.8625	Cost: 20.87s
Train Epoch: 233 	Average Loss: 2.0546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2924

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Learning rate: 0.00019973221412421225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 2.4063	Cost: 24.96s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 2.0788	Cost: 6.14s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 1.9192	Cost: 14.00s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 2.0407	Cost: 7.48s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 2.0246	Cost: 10.99s
Train Epoch: 234 	Average Loss: 2.0578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2999

Learning rate: 0.0001997299116378877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 2.3993	Cost: 25.73s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 2.0517	Cost: 6.22s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 1.9950	Cost: 12.62s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 1.9737	Cost: 8.78s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 1.9686	Cost: 9.85s
Train Epoch: 235 	Average Loss: 2.0297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3799

Learning rate: 0.0001997275993086155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 2.3981	Cost: 27.51s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 1.9954	Cost: 7.61s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 1.8246	Cost: 10.79s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 2.0370	Cost: 6.04s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 2.0708	Cost: 9.48s
Train Epoch: 236 	Average Loss: 2.0167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3460

Learning rate: 0.0001997252771366239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 2.4018	Cost: 28.62s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 2.0267	Cost: 15.07s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 2.0234	Cost: 6.93s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 2.0047	Cost: 11.99s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 2.0116	Cost: 5.74s
Train Epoch: 237 	Average Loss: 2.0286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3005

Learning rate: 0.000199722945122142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 2.3067	Cost: 27.47s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 1.9769	Cost: 6.01s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 1.8792	Cost: 17.02s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 1.9070	Cost: 14.36s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 1.9552	Cost: 14.73s
Train Epoch: 238 	Average Loss: 1.9716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2989

Learning rate: 0.0001997206032654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 2.3178	Cost: 26.44s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 2.0823	Cost: 6.05s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 1.9770	Cost: 14.01s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 2.0038	Cost: 5.95s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 2.0061	Cost: 20.94s
Train Epoch: 239 	Average Loss: 1.9812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2144

Saving model as e239_model.pt & e239_waveforms_supplementary.hdf5
Learning rate: 0.00019971825156662903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 2.3161	Cost: 25.87s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 1.9252	Cost: 6.79s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 1.9518	Cost: 12.76s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 1.9449	Cost: 6.16s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 1.9899	Cost: 20.14s
Train Epoch: 240 	Average Loss: 1.9690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3089

Learning rate: 0.00019971589002606117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 2.3339	Cost: 25.91s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 1.9358	Cost: 6.30s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 1.7871	Cost: 13.13s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 1.9235	Cost: 6.15s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 2.0141	Cost: 12.83s
Train Epoch: 241 	Average Loss: 1.9575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3537

Learning rate: 0.00019971351864392958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 2.4510	Cost: 25.07s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 2.0162	Cost: 8.49s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 1.8092	Cost: 10.95s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 1.9188	Cost: 8.60s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 1.8425	Cost: 7.42s
Train Epoch: 242 	Average Loss: 1.9636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2468

Learning rate: 0.00019971113742046817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 2.4782	Cost: 26.67s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 1.9858	Cost: 6.38s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 1.9281	Cost: 11.63s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 1.9613	Cost: 6.01s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 1.8836	Cost: 9.69s
Train Epoch: 243 	Average Loss: 1.9831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2867

Learning rate: 0.00019970874635591207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 2.2330	Cost: 28.58s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 1.9903	Cost: 6.41s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 1.8290	Cost: 16.43s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 1.8992	Cost: 12.43s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 1.9302	Cost: 11.73s
Train Epoch: 244 	Average Loss: 1.9043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2175

Learning rate: 0.00019970634545049727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 2.1552	Cost: 28.01s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 1.8429	Cost: 7.72s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 1.7457	Cost: 11.26s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 1.8543	Cost: 6.17s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 1.8715	Cost: 19.63s
Train Epoch: 245 	Average Loss: 1.8838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2055

Saving model as e245_model.pt & e245_waveforms_supplementary.hdf5
Learning rate: 0.0001997039347044607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 2.2102	Cost: 28.32s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 1.8764	Cost: 7.70s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 1.7108	Cost: 11.60s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 1.8123	Cost: 6.11s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 1.7605	Cost: 16.68s
Train Epoch: 246 	Average Loss: 1.8545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2858

Learning rate: 0.00019970151411804023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 2.1435	Cost: 27.82s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 1.7865	Cost: 9.11s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 1.9058	Cost: 9.97s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 1.8464	Cost: 8.05s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 1.8161	Cost: 6.27s
Train Epoch: 247 	Average Loss: 1.8662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2405

Learning rate: 0.00019969908369147485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 2.1716	Cost: 28.99s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 1.9573	Cost: 6.29s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 1.8761	Cost: 14.92s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 1.7829	Cost: 8.53s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 1.8830	Cost: 8.30s
Train Epoch: 248 	Average Loss: 1.8793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2313

Learning rate: 0.00019969664342500438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 2.1398	Cost: 27.46s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 1.8673	Cost: 10.32s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 1.7086	Cost: 8.09s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 1.7615	Cost: 6.07s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 1.8186	Cost: 11.96s
Train Epoch: 249 	Average Loss: 1.8586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1738

Saving model as e249_model.pt & e249_waveforms_supplementary.hdf5
Learning rate: 0.00019969419331886966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 2.2442	Cost: 27.73s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 1.8909	Cost: 15.69s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 1.7680	Cost: 7.06s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 1.7043	Cost: 8.25s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 1.7559	Cost: 9.79s
Train Epoch: 250 	Average Loss: 1.8068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1501

Saving model as e250_model.pt & e250_waveforms_supplementary.hdf5
Learning rate: 0.0001996917333733126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 2.1885	Cost: 27.70s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 1.8921	Cost: 7.89s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 1.7471	Cost: 12.33s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 1.7791	Cost: 15.06s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 1.6919	Cost: 12.64s
Train Epoch: 251 	Average Loss: 1.8086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1265

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Learning rate: 0.00019968926358857587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 2.1100	Cost: 25.98s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 1.8031	Cost: 8.19s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 1.8428	Cost: 11.82s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 1.7688	Cost: 7.14s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 1.7177	Cost: 12.92s
Train Epoch: 252 	Average Loss: 1.7993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1605

Learning rate: 0.00019968678396490325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 2.3533	Cost: 25.22s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 1.8718	Cost: 8.55s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 1.6478	Cost: 9.26s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 1.7327	Cost: 8.72s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 1.6950	Cost: 7.49s
Train Epoch: 253 	Average Loss: 1.8141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1437

Learning rate: 0.00019968429450253954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 2.1367	Cost: 26.38s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 1.7813	Cost: 6.05s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 1.6707	Cost: 12.82s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 1.7902	Cost: 6.09s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 1.7530	Cost: 12.48s
Train Epoch: 254 	Average Loss: 1.7742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2126

Learning rate: 0.0001996817952017304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 2.0902	Cost: 26.63s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 1.8319	Cost: 6.13s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 1.6385	Cost: 12.66s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 1.6249	Cost: 6.04s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 1.6907	Cost: 9.01s
Train Epoch: 255 	Average Loss: 1.7624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2016

Learning rate: 0.00019967928606272244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 2.2234	Cost: 31.66s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 1.7245	Cost: 14.98s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 1.5826	Cost: 14.11s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 1.5569	Cost: 10.96s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 1.6340	Cost: 5.77s
Train Epoch: 256 	Average Loss: 1.7167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0747

Saving model as e256_model.pt & e256_waveforms_supplementary.hdf5
Learning rate: 0.0001996767670857634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 1.9730	Cost: 27.51s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 1.7771	Cost: 6.14s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 1.6191	Cost: 16.36s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 1.5966	Cost: 12.63s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 1.5354	Cost: 10.91s
Train Epoch: 257 	Average Loss: 1.7054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1176

Learning rate: 0.00019967423827110182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 2.1122	Cost: 26.35s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 1.6714	Cost: 6.01s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 1.5423	Cost: 13.91s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 1.6063	Cost: 10.20s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 1.6214	Cost: 16.11s
Train Epoch: 258 	Average Loss: 1.7127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0462

Saving model as e258_model.pt & e258_waveforms_supplementary.hdf5
Learning rate: 0.00019967169961898734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 2.0276	Cost: 25.61s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 1.7255	Cost: 6.04s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 1.6460	Cost: 13.40s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 1.7104	Cost: 6.21s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 1.5625	Cost: 20.44s
Train Epoch: 259 	Average Loss: 1.6921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0534

Learning rate: 0.00019966915112967047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 2.0283	Cost: 25.50s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 1.6971	Cost: 6.06s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 1.6279	Cost: 13.47s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 1.6103	Cost: 6.05s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 1.5989	Cost: 13.35s
Train Epoch: 260 	Average Loss: 1.6662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0660

Learning rate: 0.00019966659280340273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 2.0313	Cost: 26.77s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 1.5773	Cost: 7.97s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 1.5389	Cost: 11.41s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 1.5976	Cost: 8.39s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 1.6465	Cost: 8.55s
Train Epoch: 261 	Average Loss: 1.6529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0922

Learning rate: 0.00019966402464043667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 2.0758	Cost: 25.56s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 1.7487	Cost: 6.06s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 1.5944	Cost: 11.57s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 1.5621	Cost: 6.22s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 1.5385	Cost: 10.40s
Train Epoch: 262 	Average Loss: 1.6651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0775

Learning rate: 0.00019966144664102572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 1.9257	Cost: 37.04s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 1.5817	Cost: 8.62s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 1.4967	Cost: 12.77s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 1.5104	Cost: 7.68s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 1.6291	Cost: 5.83s
Train Epoch: 263 	Average Loss: 1.6119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0392

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Learning rate: 0.00019965885880542434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 2.0575	Cost: 30.53s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 1.5985	Cost: 6.83s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 1.4528	Cost: 15.88s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 1.4775	Cost: 14.07s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 1.4925	Cost: 11.91s
Train Epoch: 264 	Average Loss: 1.5887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0144

Saving model as e264_model.pt & e264_waveforms_supplementary.hdf5
Learning rate: 0.00019965626113388794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 1.9728	Cost: 29.80s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 1.4900	Cost: 6.12s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 1.3532	Cost: 17.71s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 1.5833	Cost: 14.61s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 1.5578	Cost: 12.18s
Train Epoch: 265 	Average Loss: 1.5507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9792

Saving model as e265_model.pt & e265_waveforms_supplementary.hdf5
Learning rate: 0.00019965365362667288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 2.0076	Cost: 28.33s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 1.5811	Cost: 6.04s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 1.5193	Cost: 14.79s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 1.4994	Cost: 14.92s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 1.4128	Cost: 13.43s
Train Epoch: 266 	Average Loss: 1.5660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0122

Learning rate: 0.0001996510362840365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 1.9733	Cost: 27.17s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 1.5984	Cost: 6.48s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 1.4141	Cost: 13.09s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 1.4397	Cost: 6.04s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 1.5760	Cost: 16.29s
Train Epoch: 267 	Average Loss: 1.5825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9983

Learning rate: 0.00019964840910623716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 2.2031	Cost: 25.73s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 1.5669	Cost: 8.64s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 1.4990	Cost: 8.99s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 1.5027	Cost: 7.23s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 1.3582	Cost: 6.91s
Train Epoch: 268 	Average Loss: 1.5469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9587

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Learning rate: 0.00019964577209353413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 1.9254	Cost: 26.40s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 1.5791	Cost: 6.07s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 1.4053	Cost: 12.17s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 1.3473	Cost: 8.60s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 1.3135	Cost: 8.29s
Train Epoch: 269 	Average Loss: 1.5047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9319

Saving model as e269_model.pt & e269_waveforms_supplementary.hdf5
Learning rate: 0.00019964312524618766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 1.9518	Cost: 29.32s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 1.5187	Cost: 7.41s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 1.4697	Cost: 10.90s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 1.5105	Cost: 6.09s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 1.4497	Cost: 9.73s
Train Epoch: 270 	Average Loss: 1.5455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9940

Learning rate: 0.000199640468564459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 1.8584	Cost: 33.05s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 1.4597	Cost: 6.45s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 1.3804	Cost: 17.01s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 1.5138	Cost: 10.59s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 1.3442	Cost: 11.75s
Train Epoch: 271 	Average Loss: 1.5012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9013

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 0.00019963780204861037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 1.8830	Cost: 26.36s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 1.4203	Cost: 8.15s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 1.3853	Cost: 11.26s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 1.4991	Cost: 6.08s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 1.5025	Cost: 20.23s
Train Epoch: 272 	Average Loss: 1.4765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9599

Learning rate: 0.0001996351256989049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 1.9036	Cost: 25.19s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 1.4512	Cost: 5.98s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 1.3553	Cost: 13.86s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 1.3699	Cost: 7.63s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 1.4007	Cost: 11.00s
Train Epoch: 273 	Average Loss: 1.4806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8502

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 0.0001996324395156068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 1.8812	Cost: 27.86s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 1.4898	Cost: 6.19s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 1.2923	Cost: 12.78s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 1.5072	Cost: 8.36s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 1.4954	Cost: 8.51s
Train Epoch: 274 	Average Loss: 1.4717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8540

Learning rate: 0.00019962974349898107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 1.9740	Cost: 28.26s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 1.3246	Cost: 10.07s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 1.4881	Cost: 8.02s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 1.5279	Cost: 6.12s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 1.5069	Cost: 10.34s
Train Epoch: 275 	Average Loss: 1.4242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9476

Learning rate: 0.0001996270376492939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 1.9445	Cost: 29.40s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 1.3343	Cost: 6.26s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 1.2241	Cost: 14.93s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 1.4044	Cost: 5.95s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 1.2369	Cost: 8.42s
Train Epoch: 276 	Average Loss: 1.4240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8629

Learning rate: 0.00019962432196681234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 1.8294	Cost: 28.85s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 1.4404	Cost: 6.53s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 1.2841	Cost: 16.98s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 1.3281	Cost: 12.33s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 1.3048	Cost: 10.61s
Train Epoch: 277 	Average Loss: 1.3895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8218

Saving model as e277_model.pt & e277_waveforms_supplementary.hdf5
Learning rate: 0.00019962159645180437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 1.7142	Cost: 28.01s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 1.4350	Cost: 6.72s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 1.3087	Cost: 16.86s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 1.4249	Cost: 14.81s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 1.3355	Cost: 14.45s
Train Epoch: 278 	Average Loss: 1.4077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9092

Learning rate: 0.00019961886110453903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 1.8557	Cost: 26.56s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 1.3974	Cost: 6.01s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 1.2034	Cost: 13.45s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 1.3215	Cost: 5.98s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 1.2888	Cost: 20.90s
Train Epoch: 279 	Average Loss: 1.3781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8535

Learning rate: 0.00019961611592528625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 1.7567	Cost: 26.60s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 1.3084	Cost: 6.69s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 1.1769	Cost: 12.67s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 1.2966	Cost: 6.08s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 1.2545	Cost: 15.15s
Train Epoch: 280 	Average Loss: 1.3503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9103

Learning rate: 0.000199613360914317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 1.9698	Cost: 26.06s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 1.3667	Cost: 8.58s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 1.2106	Cost: 9.41s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 1.2445	Cost: 8.59s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 1.2862	Cost: 6.70s
Train Epoch: 281 	Average Loss: 1.3689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8261

Learning rate: 0.00019961059607190318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 1.7252	Cost: 28.69s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 1.2625	Cost: 6.28s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 1.1599	Cost: 12.63s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 1.3475	Cost: 6.12s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 1.3120	Cost: 11.20s
Train Epoch: 282 	Average Loss: 1.3093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8490

Learning rate: 0.00019960782139831766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 1.7744	Cost: 36.70s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 1.3019	Cost: 6.08s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 1.3081	Cost: 12.02s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 1.3812	Cost: 5.93s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 1.2629	Cost: 10.54s
Train Epoch: 283 	Average Loss: 1.3609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8171

Saving model as e283_model.pt & e283_waveforms_supplementary.hdf5
Learning rate: 0.00019960503689383428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 1.8181	Cost: 34.72s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 1.2524	Cost: 14.95s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 1.1971	Cost: 11.23s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 1.2837	Cost: 11.78s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 1.2284	Cost: 5.67s
Train Epoch: 284 	Average Loss: 1.3218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7852

Saving model as e284_model.pt & e284_waveforms_supplementary.hdf5
Learning rate: 0.0001996022425587279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 1.7440	Cost: 32.21s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 1.3539	Cost: 6.44s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 1.2199	Cost: 17.34s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 1.2806	Cost: 14.45s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 1.3237	Cost: 12.03s
Train Epoch: 285 	Average Loss: 1.2887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8400

Learning rate: 0.0001995994383932743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 1.7781	Cost: 29.36s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 1.1879	Cost: 7.88s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 1.0736	Cost: 11.49s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 1.3108	Cost: 6.24s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 1.2373	Cost: 19.55s
Train Epoch: 286 	Average Loss: 1.2781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7938

Learning rate: 0.0001995966243977502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 1.7317	Cost: 29.03s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 1.2415	Cost: 7.46s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 1.0083	Cost: 13.19s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 1.1902	Cost: 6.24s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 1.2193	Cost: 13.50s
Train Epoch: 287 	Average Loss: 1.2076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7345

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Learning rate: 0.0001995938005724334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 1.7478	Cost: 27.28s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 1.1544	Cost: 8.69s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 0.9815	Cost: 10.90s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 1.1352	Cost: 6.24s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 1.0503	Cost: 13.41s
Train Epoch: 288 	Average Loss: 1.1786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6995

Saving model as e288_model.pt & e288_waveforms_supplementary.hdf5
Learning rate: 0.00019959096691760252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 1.7746	Cost: 26.85s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 1.2192	Cost: 6.05s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 1.0415	Cost: 14.80s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 1.1345	Cost: 8.82s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 1.2034	Cost: 10.29s
Train Epoch: 289 	Average Loss: 1.2200
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7505

Learning rate: 0.00019958812343353726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 1.7513	Cost: 27.74s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 1.2083	Cost: 12.13s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 1.0822	Cost: 6.86s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 1.2868	Cost: 6.08s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 1.1387	Cost: 12.49s
Train Epoch: 290 	Average Loss: 1.1933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7213

Learning rate: 0.0001995852701205183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 1.6349	Cost: 27.33s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 1.2154	Cost: 9.01s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 1.1013	Cost: 14.89s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 1.1447	Cost: 10.96s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 1.1050	Cost: 9.98s
Train Epoch: 291 	Average Loss: 1.1693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6719

Saving model as e291_model.pt & e291_waveforms_supplementary.hdf5
Learning rate: 0.0001995824069788272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 1.5883	Cost: 26.45s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 1.1673	Cost: 6.02s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 1.1063	Cost: 14.27s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 1.1834	Cost: 15.68s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 1.0835	Cost: 12.09s
Train Epoch: 292 	Average Loss: 1.1766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7224

Learning rate: 0.00019957953400874656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 1.5954	Cost: 25.39s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 1.0911	Cost: 6.15s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 0.9984	Cost: 13.01s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 1.0793	Cost: 6.12s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 1.0970	Cost: 12.40s
Train Epoch: 293 	Average Loss: 1.1498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7153

Learning rate: 0.00019957665121055995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 1.7516	Cost: 26.27s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 1.0727	Cost: 8.64s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 1.1207	Cost: 10.77s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 1.1548	Cost: 8.50s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 1.0568	Cost: 7.65s
Train Epoch: 294 	Average Loss: 1.1805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7409

Learning rate: 0.00019957375858455185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 1.6564	Cost: 27.40s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 1.1559	Cost: 10.97s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 0.9115	Cost: 6.14s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 1.0950	Cost: 6.14s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 1.0411	Cost: 10.01s
Train Epoch: 295 	Average Loss: 1.1455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7286

Learning rate: 0.00019957085613100776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 1.6316	Cost: 29.04s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 1.0244	Cost: 15.79s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 1.0116	Cost: 8.23s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 1.0663	Cost: 10.77s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 0.9961	Cost: 5.76s
Train Epoch: 296 	Average Loss: 1.1040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7015

Learning rate: 0.00019956794385021415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 1.8262	Cost: 30.96s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 1.0951	Cost: 6.25s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 0.9693	Cost: 16.88s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 0.9597	Cost: 12.67s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 1.0100	Cost: 9.89s
Train Epoch: 297 	Average Loss: 1.0958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6631

Saving model as e297_model.pt & e297_waveforms_supplementary.hdf5
Learning rate: 0.00019956502174245846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 1.7618	Cost: 26.04s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 1.0567	Cost: 6.59s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 1.0216	Cost: 12.87s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 1.0909	Cost: 6.21s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 1.1106	Cost: 19.90s
Train Epoch: 298 	Average Loss: 1.1063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6985

Learning rate: 0.0001995620898080291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 1.6128	Cost: 25.45s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 1.0878	Cost: 6.06s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 1.0018	Cost: 12.70s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 1.0780	Cost: 6.08s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 1.0808	Cost: 13.09s
Train Epoch: 299 	Average Loss: 1.0641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7123

Learning rate: 0.00019955914804721542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 1.6304	Cost: 29.52s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 1.0654	Cost: 8.87s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 0.9788	Cost: 9.67s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 1.1441	Cost: 7.93s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 1.1023	Cost: 6.56s
Train Epoch: 300 	Average Loss: 1.0917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6658

Learning rate: 0.00019955619646030775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 1.6675	Cost: 28.98s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 1.0647	Cost: 6.18s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 1.0082	Cost: 13.75s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 0.9869	Cost: 8.51s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 0.9733	Cost: 8.22s
Train Epoch: 301 	Average Loss: 1.0457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6294

Saving model as e301_model.pt & e301_waveforms_supplementary.hdf5
Learning rate: 0.0001995532350475974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 1.5623	Cost: 28.28s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 0.9697	Cost: 7.90s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 0.8956	Cost: 10.48s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 0.8922	Cost: 6.13s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 0.9123	Cost: 9.89s
Train Epoch: 302 	Average Loss: 1.0080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7169

Learning rate: 0.00019955026380937669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 1.6373	Cost: 34.11s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 1.0009	Cost: 11.28s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 0.9054	Cost: 15.11s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 1.0288	Cost: 10.43s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 0.9967	Cost: 9.33s
Train Epoch: 303 	Average Loss: 1.0327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6551

Learning rate: 0.00019954728274593884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 1.5851	Cost: 41.28s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 0.9534	Cost: 6.15s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 0.9036	Cost: 16.98s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 1.0578	Cost: 10.73s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 1.1902	Cost: 11.65s
Train Epoch: 304 	Average Loss: 1.0544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8060

Learning rate: 0.00019954429185757805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 1.9391	Cost: 32.71s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 1.1461	Cost: 7.85s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 0.9120	Cost: 12.79s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 1.1033	Cost: 6.02s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 1.0349	Cost: 20.75s
Train Epoch: 305 	Average Loss: 1.1021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7159

Learning rate: 0.00019954129114458955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 1.7887	Cost: 29.93s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 0.9754	Cost: 7.92s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 0.8679	Cost: 14.14s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 0.9022	Cost: 6.08s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 0.9608	Cost: 20.01s
Train Epoch: 306 	Average Loss: 0.9943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7376

Learning rate: 0.00019953828060726943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 1.8631	Cost: 24.65s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 0.9842	Cost: 6.41s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 0.8128	Cost: 19.89s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 0.8415	Cost: 6.42s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 1.0685	Cost: 13.76s
Train Epoch: 307 	Average Loss: 1.0256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7999

Learning rate: 0.00019953526024591494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 1.7392	Cost: 26.13s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 1.0492	Cost: 8.55s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 0.9055	Cost: 9.51s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 0.8067	Cost: 8.84s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 0.8989	Cost: 9.35s
Train Epoch: 308 	Average Loss: 1.0193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6815

Learning rate: 0.00019953223006082406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 1.6738	Cost: 27.20s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 1.0055	Cost: 6.02s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 0.8536	Cost: 12.44s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 0.8458	Cost: 6.06s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 0.9060	Cost: 15.12s
Train Epoch: 309 	Average Loss: 0.9473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6634

Learning rate: 0.00019952919005229592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 1.7095	Cost: 26.48s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 0.7969	Cost: 6.20s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 0.7650	Cost: 14.02s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 0.8051	Cost: 5.91s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 0.8487	Cost: 9.49s
Train Epoch: 310 	Average Loss: 0.9458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6000

Saving model as e310_model.pt & e310_waveforms_supplementary.hdf5
Learning rate: 0.00019952614022063054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 1.5801	Cost: 28.56s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 0.8285	Cost: 15.06s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 0.8002	Cost: 9.32s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 0.8405	Cost: 11.85s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 0.8484	Cost: 5.93s
Train Epoch: 311 	Average Loss: 0.9287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5798

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Learning rate: 0.00019952308056612892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 1.5447	Cost: 29.29s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 0.8446	Cost: 6.21s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 0.8196	Cost: 17.01s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 0.8039	Cost: 15.11s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 0.8952	Cost: 12.91s
Train Epoch: 312 	Average Loss: 0.9030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6433

Learning rate: 0.00019952001108909304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 1.7876	Cost: 27.66s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 0.9579	Cost: 6.96s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 0.8048	Cost: 12.67s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 0.6990	Cost: 11.13s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 0.7800	Cost: 16.21s
Train Epoch: 313 	Average Loss: 0.8823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5021

Saving model as e313_model.pt & e313_waveforms_supplementary.hdf5
Learning rate: 0.00019951693178982586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 1.4018	Cost: 26.34s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 0.7807	Cost: 6.29s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 0.7469	Cost: 13.51s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 0.7697	Cost: 6.20s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 0.7679	Cost: 20.16s
Train Epoch: 314 	Average Loss: 0.8299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5561

Learning rate: 0.00019951384266863126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 1.6089	Cost: 25.18s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 0.8159	Cost: 6.16s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 0.7138	Cost: 13.25s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 0.7028	Cost: 6.10s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 0.7198	Cost: 13.01s
Train Epoch: 315 	Average Loss: 0.8091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5497

Learning rate: 0.00019951074372581416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 1.3760	Cost: 26.03s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 0.6612	Cost: 8.52s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 0.5901	Cost: 10.91s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 0.6862	Cost: 7.29s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 0.6884	Cost: 7.51s
Train Epoch: 316 	Average Loss: 0.7769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5208

Learning rate: 0.00019950763496168037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 1.5249	Cost: 25.25s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 0.7134	Cost: 5.98s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 0.7100	Cost: 11.60s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 0.7074	Cost: 8.22s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 0.6771	Cost: 9.24s
Train Epoch: 317 	Average Loss: 0.7808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4867

Saving model as e317_model.pt & e317_waveforms_supplementary.hdf5
Learning rate: 0.00019950451637653678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 1.5906	Cost: 26.64s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 0.7706	Cost: 8.14s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 0.6119	Cost: 10.05s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 0.6224	Cost: 6.04s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 0.7671	Cost: 9.84s
Train Epoch: 318 	Average Loss: 0.7606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4993

Learning rate: 0.00019950138797069118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 1.5619	Cost: 28.91s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 0.7295	Cost: 6.23s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 0.6534	Cost: 16.41s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 0.7066	Cost: 12.00s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 0.6019	Cost: 11.79s
Train Epoch: 319 	Average Loss: 0.7426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4074

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Learning rate: 0.00019949824974445222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 1.4141	Cost: 28.65s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 0.6355	Cost: 6.49s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 0.6062	Cost: 12.29s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 0.6374	Cost: 13.35s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 0.6497	Cost: 14.85s
Train Epoch: 320 	Average Loss: 0.7346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4580

Learning rate: 0.00019949510169812976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 1.5097	Cost: 27.70s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 0.6997	Cost: 8.20s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 0.6488	Cost: 11.48s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 0.6068	Cost: 6.05s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 0.5504	Cost: 12.36s
Train Epoch: 321 	Average Loss: 0.7045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3762

Saving model as e321_model.pt & e321_waveforms_supplementary.hdf5
Learning rate: 0.00019949194383203438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 1.3516	Cost: 28.22s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 0.7405	Cost: 9.16s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 0.6159	Cost: 9.41s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 0.5793	Cost: 6.48s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 0.6186	Cost: 11.16s
Train Epoch: 322 	Average Loss: 0.6871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3880

Learning rate: 0.00019948877614647787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 1.3735	Cost: 28.23s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 0.6866	Cost: 7.00s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 0.6475	Cost: 12.58s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 0.4946	Cost: 8.57s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 0.5916	Cost: 8.45s
Train Epoch: 323 	Average Loss: 0.6518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4508

Learning rate: 0.0001994855986417728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 1.4021	Cost: 26.70s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 0.5052	Cost: 10.14s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 0.5102	Cost: 8.94s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 0.4889	Cost: 6.36s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 0.5908	Cost: 11.58s
Train Epoch: 324 	Average Loss: 0.6256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3935

Learning rate: 0.0001994824113182328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 1.3685	Cost: 28.61s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 0.6068	Cost: 15.44s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 0.5163	Cost: 10.25s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 0.6015	Cost: 10.97s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 0.5941	Cost: 5.93s
Train Epoch: 325 	Average Loss: 0.6333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2799

Saving model as e325_model.pt & e325_waveforms_supplementary.hdf5
Learning rate: 0.00019947921417617242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 1.3034	Cost: 27.87s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 0.6465	Cost: 6.19s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 0.5408	Cost: 18.06s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 0.4071	Cost: 11.03s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 0.5760	Cost: 5.98s
Train Epoch: 326 	Average Loss: 0.5940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3724

Learning rate: 0.0001994760072159072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 1.3553	Cost: 26.43s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 0.6334	Cost: 6.18s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 0.4546	Cost: 13.50s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 0.4769	Cost: 6.17s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 0.4127	Cost: 20.48s
Train Epoch: 327 	Average Loss: 0.5698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3402

Learning rate: 0.00019947279043775368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 1.3420	Cost: 26.77s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 0.5110	Cost: 7.55s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 0.4703	Cost: 9.92s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 0.5750	Cost: 6.15s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 0.5181	Cost: 13.06s
Train Epoch: 328 	Average Loss: 0.5725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2525

Saving model as e328_model.pt & e328_waveforms_supplementary.hdf5
Learning rate: 0.00019946956384202932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 1.1974	Cost: 26.65s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 0.4635	Cost: 6.03s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 0.4206	Cost: 13.60s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 0.4615	Cost: 8.29s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 0.5023	Cost: 8.47s
Train Epoch: 329 	Average Loss: 0.5366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4026

Learning rate: 0.00019946632742905265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 1.3278	Cost: 26.91s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 0.4713	Cost: 5.96s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 0.4109	Cost: 12.16s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 0.4328	Cost: 5.95s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 0.4389	Cost: 9.45s
Train Epoch: 330 	Average Loss: 0.5563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2843

Learning rate: 0.000199463081199143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 1.5136	Cost: 28.20s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 0.4858	Cost: 13.47s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 0.4974	Cost: 14.71s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 0.4887	Cost: 11.83s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 0.4850	Cost: 5.68s
Train Epoch: 331 	Average Loss: 0.5041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3366

Learning rate: 0.0001994598251526208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 1.2850	Cost: 27.56s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 0.5007	Cost: 6.38s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 0.4349	Cost: 17.01s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 0.2943	Cost: 14.91s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 0.3966	Cost: 11.77s
Train Epoch: 332 	Average Loss: 0.5115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2853

Learning rate: 0.00019945655928980737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 1.3339	Cost: 25.49s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 0.4372	Cost: 6.11s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 0.4905	Cost: 13.39s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 0.4659	Cost: 6.21s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 0.5223	Cost: 20.73s
Train Epoch: 333 	Average Loss: 0.5438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2787

Learning rate: 0.0001994532836110251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 1.0516	Cost: 27.59s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 0.4834	Cost: 6.14s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 0.3685	Cost: 13.07s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 0.3221	Cost: 6.06s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 0.3793	Cost: 12.97s
Train Epoch: 334 	Average Loss: 0.4519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2513

Saving model as e334_model.pt & e334_waveforms_supplementary.hdf5
Learning rate: 0.00019944999811659725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 1.2424	Cost: 29.25s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 0.4439	Cost: 8.71s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 0.2716	Cost: 9.25s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 0.3262	Cost: 8.54s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 0.4001	Cost: 7.70s
Train Epoch: 335 	Average Loss: 0.4431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2950

Learning rate: 0.00019944670280684805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 1.2866	Cost: 27.29s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 0.3933	Cost: 9.45s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 0.3013	Cost: 7.40s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 0.2689	Cost: 6.13s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 0.2788	Cost: 9.89s
Train Epoch: 336 	Average Loss: 0.4049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2263

Saving model as e336_model.pt & e336_waveforms_supplementary.hdf5
Learning rate: 0.00019944339768210285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 1.2099	Cost: 31.84s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 0.3245	Cost: 11.27s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 0.4324	Cost: 6.99s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 0.3076	Cost: 11.53s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 0.3983	Cost: 5.98s
Train Epoch: 337 	Average Loss: 0.4194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2292

Learning rate: 0.0001994400827426877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 1.3287	Cost: 34.36s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 0.4670	Cost: 7.54s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 0.3427	Cost: 12.92s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 0.2979	Cost: 8.43s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 0.3121	Cost: 17.89s
Train Epoch: 338 	Average Loss: 0.4051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1737

Saving model as e338_model.pt & e338_waveforms_supplementary.hdf5
Learning rate: 0.0001994367579889299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 1.3782	Cost: 29.45s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 0.2462	Cost: 8.04s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 0.2063	Cost: 12.13s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 0.2900	Cost: 6.42s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 0.5466	Cost: 16.07s
Train Epoch: 339 	Average Loss: 0.3659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3019

Learning rate: 0.0001994334234211575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 1.2417	Cost: 26.39s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 0.4928	Cost: 8.62s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 0.2841	Cost: 9.74s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 0.4006	Cost: 6.29s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 0.3415	Cost: 13.12s
Train Epoch: 340 	Average Loss: 0.4533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1691

Saving model as e340_model.pt & e340_waveforms_supplementary.hdf5
Learning rate: 0.00019943007903969968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 1.1909	Cost: 25.79s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 0.3248	Cost: 6.04s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 0.3549	Cost: 14.57s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 0.2161	Cost: 8.77s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 0.2594	Cost: 10.50s
Train Epoch: 341 	Average Loss: 0.3290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1182

Saving model as e341_model.pt & e341_waveforms_supplementary.hdf5
Learning rate: 0.00019942672484488645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 1.0990	Cost: 25.70s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 0.2638	Cost: 6.00s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 0.1860	Cost: 12.61s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 0.1644	Cost: 6.11s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 0.1842	Cost: 13.10s
Train Epoch: 342 	Average Loss: 0.3019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1973

Learning rate: 0.0001994233608370489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 1.1553	Cost: 27.47s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 0.2059	Cost: 13.16s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 0.1198	Cost: 5.99s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 0.2288	Cost: 12.14s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 0.2747	Cost: 6.08s
Train Epoch: 343 	Average Loss: 0.2671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0850

Saving model as e343_model.pt & e343_waveforms_supplementary.hdf5
Learning rate: 0.00019941998701651908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 1.0015	Cost: 27.84s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 0.1108	Cost: 6.44s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 0.1612	Cost: 16.43s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 0.1679	Cost: 14.19s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 0.2193	Cost: 6.07s
Train Epoch: 344 	Average Loss: 0.2377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0468

Saving model as e344_model.pt & e344_waveforms_supplementary.hdf5
Learning rate: 0.00019941660338362987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 0.9512	Cost: 26.96s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 0.3649	Cost: 6.06s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 0.0387	Cost: 13.08s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 0.1624	Cost: 14.40s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 0.2174	Cost: 13.94s
Train Epoch: 345 	Average Loss: 0.2538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1465

Learning rate: 0.0001994132099387153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 1.2390	Cost: 27.36s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 0.2386	Cost: 6.04s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 0.1879	Cost: 13.52s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 0.1198	Cost: 6.15s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 0.2265	Cost: 21.08s
Train Epoch: 346 	Average Loss: 0.2667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1402

Learning rate: 0.00019940980668211027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 0.9227	Cost: 25.70s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 0.1864	Cost: 6.71s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 0.0277	Cost: 12.66s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 0.1038	Cost: 6.31s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 0.1226	Cost: 12.48s
Train Epoch: 347 	Average Loss: 0.2009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0824

Learning rate: 0.00019940639361415064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 1.1887	Cost: 25.78s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 0.1343	Cost: 8.95s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 0.1349	Cost: 9.40s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 0.0892	Cost: 9.02s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 0.1727	Cost: 7.23s
Train Epoch: 348 	Average Loss: 0.1957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0606

Learning rate: 0.00019940297073517331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 0.9942	Cost: 26.18s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 0.1653	Cost: 12.03s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 0.0130	Cost: 6.16s
Train Epoch: 349 [61440/90000 (68%)]	Loss: -0.0056	Cost: 6.20s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 0.0907	Cost: 10.66s
Train Epoch: 349 	Average Loss: 0.1679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0917

Learning rate: 0.00019939953804551608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 1.0314	Cost: 28.60s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 0.0037	Cost: 14.67s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 0.0409	Cost: 6.82s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 0.0346	Cost: 12.05s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 0.1759	Cost: 5.75s
Train Epoch: 350 	Average Loss: 0.1722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1257

Learning rate: 0.00019939609554551777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 0.9999	Cost: 29.63s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 0.1375	Cost: 6.48s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -0.0115	Cost: 17.76s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 0.0274	Cost: 13.74s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 0.2081	Cost: 11.84s
Train Epoch: 351 	Average Loss: 0.1640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0985

Learning rate: 0.0001993926432355181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 1.1835	Cost: 25.90s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 0.0605	Cost: 6.03s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -0.0057	Cost: 13.83s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 0.0126	Cost: 6.96s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 0.0816	Cost: 19.66s
Train Epoch: 352 	Average Loss: 0.1417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9874

Saving model as e352_model.pt & e352_waveforms_supplementary.hdf5
Learning rate: 0.00019938918111585784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 1.1311	Cost: 27.06s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 0.0614	Cost: 6.52s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -0.0466	Cost: 13.40s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 0.1057	Cost: 6.03s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 0.0341	Cost: 20.66s
Train Epoch: 353 	Average Loss: 0.1152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0090

Learning rate: 0.00019938570918687863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 1.0129	Cost: 27.31s
Train Epoch: 354 [20480/90000 (23%)]	Loss: -0.0117	Cost: 5.99s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 0.0923	Cost: 13.22s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 0.0550	Cost: 6.00s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 0.0937	Cost: 14.27s
Train Epoch: 354 	Average Loss: 0.0947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0239

Learning rate: 0.0001993822274489232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 0.9546	Cost: 28.67s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 0.0552	Cost: 8.57s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -0.1306	Cost: 9.80s
Train Epoch: 355 [61440/90000 (68%)]	Loss: -0.0393	Cost: 7.47s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -0.0132	Cost: 7.01s
Train Epoch: 355 	Average Loss: 0.1141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0148

Learning rate: 0.00019937873590233516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 1.0233	Cost: 26.54s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 0.0103	Cost: 6.23s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -0.0840	Cost: 12.28s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 0.0294	Cost: 8.14s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 0.1071	Cost: 9.91s
Train Epoch: 356 	Average Loss: 0.1185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0218

Learning rate: 0.0001993752345474591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 1.0958	Cost: 28.64s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 0.1192	Cost: 6.46s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -0.0458	Cost: 12.02s
Train Epoch: 357 [61440/90000 (68%)]	Loss: -0.0167	Cost: 6.09s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -0.0429	Cost: 10.33s
Train Epoch: 357 	Average Loss: 0.1080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9965

Learning rate: 0.0001993717233846406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 0.9729	Cost: 42.70s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 0.0216	Cost: 9.80s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -0.1593	Cost: 7.39s
Train Epoch: 358 [61440/90000 (68%)]	Loss: -0.0437	Cost: 12.07s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -0.0315	Cost: 5.86s
Train Epoch: 358 	Average Loss: 0.0417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9550

Saving model as e358_model.pt & e358_waveforms_supplementary.hdf5
Learning rate: 0.0001993682024142262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 0.9869	Cost: 36.87s
Train Epoch: 359 [20480/90000 (23%)]	Loss: -0.1060	Cost: 6.14s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -0.1696	Cost: 17.32s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 0.0028	Cost: 11.00s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -0.0523	Cost: 10.18s
Train Epoch: 359 	Average Loss: 0.0159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8961

Saving model as e359_model.pt & e359_waveforms_supplementary.hdf5
Learning rate: 0.00019936467163656337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 0.8349	Cost: 35.13s
Train Epoch: 360 [20480/90000 (23%)]	Loss: -0.1366	Cost: 7.18s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -0.1921	Cost: 13.08s
Train Epoch: 360 [61440/90000 (68%)]	Loss: -0.0553	Cost: 14.36s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -0.1245	Cost: 13.61s
Train Epoch: 360 	Average Loss: -0.0299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9062

Learning rate: 0.00019936113105200064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 0.8206	Cost: 25.92s
Train Epoch: 361 [20480/90000 (23%)]	Loss: -0.0560	Cost: 8.25s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -0.2013	Cost: 11.65s
Train Epoch: 361 [61440/90000 (68%)]	Loss: -0.0713	Cost: 7.35s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -0.0907	Cost: 10.47s
Train Epoch: 361 	Average Loss: -0.0640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9543

Learning rate: 0.00019935758066088742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 1.0544	Cost: 25.32s
Train Epoch: 362 [20480/90000 (23%)]	Loss: -0.1119	Cost: 6.17s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -0.2454	Cost: 12.97s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 0.0690	Cost: 8.69s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -0.1192	Cost: 10.63s
Train Epoch: 362 	Average Loss: -0.0058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9622

Learning rate: 0.00019935402046357414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 1.0511	Cost: 28.07s
Train Epoch: 363 [20480/90000 (23%)]	Loss: -0.0892	Cost: 11.04s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -0.1604	Cost: 6.45s
Train Epoch: 363 [61440/90000 (68%)]	Loss: -0.2638	Cost: 6.15s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -0.0949	Cost: 10.76s
Train Epoch: 363 	Average Loss: -0.0198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9790

Learning rate: 0.00019935045046041218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 1.0644	Cost: 27.22s
Train Epoch: 364 [20480/90000 (23%)]	Loss: -0.1005	Cost: 10.82s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -0.2671	Cost: 6.22s
Train Epoch: 364 [61440/90000 (68%)]	Loss: -0.0575	Cost: 11.99s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -0.0937	Cost: 5.76s
Train Epoch: 364 	Average Loss: -0.0323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9950

Learning rate: 0.00019934687065175386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 1.0867	Cost: 27.09s
Train Epoch: 365 [20480/90000 (23%)]	Loss: -0.1029	Cost: 6.36s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -0.2631	Cost: 16.64s
Train Epoch: 365 [61440/90000 (68%)]	Loss: -0.2594	Cost: 12.96s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -0.2678	Cost: 11.89s
Train Epoch: 365 	Average Loss: -0.0847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8244

Saving model as e365_model.pt & e365_waveforms_supplementary.hdf5
Learning rate: 0.00019934328103795248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 0.7907	Cost: 27.53s
Train Epoch: 366 [20480/90000 (23%)]	Loss: -0.1766	Cost: 6.75s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -0.2245	Cost: 14.96s
Train Epoch: 366 [61440/90000 (68%)]	Loss: -0.1999	Cost: 15.09s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -0.2210	Cost: 14.87s
Train Epoch: 366 	Average Loss: -0.1195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7983

Saving model as e366_model.pt & e366_waveforms_supplementary.hdf5
Learning rate: 0.00019933968161936236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 0.8195	Cost: 26.76s
Train Epoch: 367 [20480/90000 (23%)]	Loss: -0.1084	Cost: 6.85s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -0.3027	Cost: 12.99s
Train Epoch: 367 [61440/90000 (68%)]	Loss: -0.1983	Cost: 9.33s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -0.2325	Cost: 16.24s
Train Epoch: 367 	Average Loss: -0.1558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8865

Learning rate: 0.00019933607239633875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 0.7387	Cost: 26.24s
Train Epoch: 368 [20480/90000 (23%)]	Loss: -0.1499	Cost: 6.76s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -0.2661	Cost: 12.67s
Train Epoch: 368 [61440/90000 (68%)]	Loss: -0.1791	Cost: 6.02s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -0.2295	Cost: 15.84s
Train Epoch: 368 	Average Loss: -0.1615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7465

Saving model as e368_model.pt & e368_waveforms_supplementary.hdf5
Learning rate: 0.00019933245336923783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 0.8832	Cost: 25.15s
Train Epoch: 369 [20480/90000 (23%)]	Loss: -0.2410	Cost: 8.57s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -0.4764	Cost: 8.47s
Train Epoch: 369 [61440/90000 (68%)]	Loss: -0.3054	Cost: 6.58s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -0.2489	Cost: 11.54s
Train Epoch: 369 	Average Loss: -0.1692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8252

Learning rate: 0.0001993288245384168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 0.8246	Cost: 26.31s
Train Epoch: 370 [20480/90000 (23%)]	Loss: -0.1879	Cost: 6.30s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -0.3974	Cost: 11.41s
Train Epoch: 370 [61440/90000 (68%)]	Loss: -0.3448	Cost: 8.60s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -0.2161	Cost: 8.62s
Train Epoch: 370 	Average Loss: -0.1981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8302

Learning rate: 0.00019932518590423377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 0.6393	Cost: 30.05s
Train Epoch: 371 [20480/90000 (23%)]	Loss: -0.2154	Cost: 8.60s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -0.3371	Cost: 10.02s
Train Epoch: 371 [61440/90000 (68%)]	Loss: -0.2873	Cost: 6.08s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -0.2372	Cost: 9.51s
Train Epoch: 371 	Average Loss: -0.2160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8463

Learning rate: 0.00019932153746704794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 0.7504	Cost: 43.71s
Train Epoch: 372 [20480/90000 (23%)]	Loss: -0.2958	Cost: 14.83s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -0.3146	Cost: 7.90s
Train Epoch: 372 [61440/90000 (68%)]	Loss: -0.2182	Cost: 12.07s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -0.2614	Cost: 6.00s
Train Epoch: 372 	Average Loss: -0.1903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8186

Learning rate: 0.00019931787922721937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 0.7270	Cost: 29.68s
Train Epoch: 373 [20480/90000 (23%)]	Loss: -0.1916	Cost: 6.57s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -0.4656	Cost: 17.85s
Train Epoch: 373 [61440/90000 (68%)]	Loss: -0.2542	Cost: 13.87s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -0.2786	Cost: 11.48s
Train Epoch: 373 	Average Loss: -0.2205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7582

Learning rate: 0.00019931421118510906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 0.6712	Cost: 28.27s
Train Epoch: 374 [20480/90000 (23%)]	Loss: -0.2892	Cost: 8.14s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -0.4193	Cost: 11.18s
Train Epoch: 374 [61440/90000 (68%)]	Loss: -0.3243	Cost: 7.30s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -0.3534	Cost: 18.57s
Train Epoch: 374 	Average Loss: -0.2481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7664

Learning rate: 0.0001993105333410791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 0.6300	Cost: 28.48s
Train Epoch: 375 [20480/90000 (23%)]	Loss: -0.3194	Cost: 7.91s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -0.4736	Cost: 12.18s
Train Epoch: 375 [61440/90000 (68%)]	Loss: -0.3370	Cost: 6.37s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -0.3475	Cost: 20.65s
Train Epoch: 375 	Average Loss: -0.2756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7765

Learning rate: 0.00019930684569549248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 0.7332	Cost: 27.13s
Train Epoch: 376 [20480/90000 (23%)]	Loss: -0.3108	Cost: 7.80s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -0.4849	Cost: 12.59s
Train Epoch: 376 [61440/90000 (68%)]	Loss: -0.3229	Cost: 6.29s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -0.3067	Cost: 13.61s
Train Epoch: 376 	Average Loss: -0.2955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7009

Saving model as e376_model.pt & e376_waveforms_supplementary.hdf5
Learning rate: 0.0001993031482487131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 0.6991	Cost: 26.61s
Train Epoch: 377 [20480/90000 (23%)]	Loss: -0.3630	Cost: 9.31s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -0.4193	Cost: 9.65s
Train Epoch: 377 [61440/90000 (68%)]	Loss: -0.3878	Cost: 6.69s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -0.3181	Cost: 12.71s
Train Epoch: 377 	Average Loss: -0.3061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6857

Saving model as e377_model.pt & e377_waveforms_supplementary.hdf5
Learning rate: 0.0001992994410011059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 0.5815	Cost: 26.17s
Train Epoch: 378 [20480/90000 (23%)]	Loss: -0.3753	Cost: 6.82s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -0.5563	Cost: 14.18s
Train Epoch: 378 [61440/90000 (68%)]	Loss: -0.4557	Cost: 8.59s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -0.3842	Cost: 10.62s
Train Epoch: 378 	Average Loss: -0.3340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6880

Learning rate: 0.00019929572395303678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 0.7714	Cost: 27.26s
Train Epoch: 379 [20480/90000 (23%)]	Loss: -0.2069	Cost: 12.04s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -0.5046	Cost: 6.09s
Train Epoch: 379 [61440/90000 (68%)]	Loss: -0.4051	Cost: 6.12s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -0.4703	Cost: 12.12s
Train Epoch: 379 	Average Loss: -0.2493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8033

Learning rate: 0.0001992919971048726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 0.7933	Cost: 27.87s
Train Epoch: 380 [20480/90000 (23%)]	Loss: -0.0594	Cost: 6.23s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -0.2418	Cost: 16.30s
Train Epoch: 380 [61440/90000 (68%)]	Loss: -0.2642	Cost: 11.95s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -0.3494	Cost: 7.44s
Train Epoch: 380 	Average Loss: -0.1081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8175

Learning rate: 0.0001992882604569812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 0.8796	Cost: 27.18s
Train Epoch: 381 [20480/90000 (23%)]	Loss: -0.3689	Cost: 6.06s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -0.5397	Cost: 13.15s
Train Epoch: 381 [61440/90000 (68%)]	Loss: -0.5537	Cost: 6.04s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -0.4594	Cost: 21.08s
Train Epoch: 381 	Average Loss: -0.3445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7334

Learning rate: 0.00019928451400973133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 0.6043	Cost: 26.41s
Train Epoch: 382 [20480/90000 (23%)]	Loss: -0.4412	Cost: 6.20s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -0.4839	Cost: 13.37s
Train Epoch: 382 [61440/90000 (68%)]	Loss: -0.4321	Cost: 6.47s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -0.3479	Cost: 12.37s
Train Epoch: 382 	Average Loss: -0.3202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7833

Learning rate: 0.0001992807577634928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 0.6435	Cost: 26.46s
Train Epoch: 383 [20480/90000 (23%)]	Loss: -0.2163	Cost: 8.74s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -0.6059	Cost: 9.77s
Train Epoch: 383 [61440/90000 (68%)]	Loss: -0.5647	Cost: 8.48s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -0.3813	Cost: 7.55s
Train Epoch: 383 	Average Loss: -0.3776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6538

Saving model as e383_model.pt & e383_waveforms_supplementary.hdf5
Learning rate: 0.00019927699171863632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 0.7255	Cost: 25.45s
Train Epoch: 384 [20480/90000 (23%)]	Loss: -0.3739	Cost: 6.26s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -0.6274	Cost: 12.47s
Train Epoch: 384 [61440/90000 (68%)]	Loss: -0.4514	Cost: 6.12s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -0.4497	Cost: 12.91s
Train Epoch: 384 	Average Loss: -0.3973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6789

Learning rate: 0.00019927321587553357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 0.6518	Cost: 27.77s
Train Epoch: 385 [20480/90000 (23%)]	Loss: -0.5385	Cost: 9.51s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -0.7337	Cost: 9.09s
Train Epoch: 385 [61440/90000 (68%)]	Loss: -0.5429	Cost: 6.09s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -0.4985	Cost: 12.09s
Train Epoch: 385 	Average Loss: -0.4409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7468

Learning rate: 0.00019926943023455717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 0.8296	Cost: 29.44s
Train Epoch: 386 [20480/90000 (23%)]	Loss: -0.3756	Cost: 14.90s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -0.5424	Cost: 11.71s
Train Epoch: 386 [61440/90000 (68%)]	Loss: -0.5279	Cost: 11.88s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -0.5496	Cost: 5.92s
Train Epoch: 386 	Average Loss: -0.4498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6693

Learning rate: 0.00019926563479608086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 0.8289	Cost: 29.34s
Train Epoch: 387 [20480/90000 (23%)]	Loss: -0.3920	Cost: 6.32s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -0.5619	Cost: 16.69s
Train Epoch: 387 [61440/90000 (68%)]	Loss: -0.6060	Cost: 12.90s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -0.5500	Cost: 11.81s
Train Epoch: 387 	Average Loss: -0.4527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5426

Saving model as e387_model.pt & e387_waveforms_supplementary.hdf5
Learning rate: 0.00019926182956047912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 0.6499	Cost: 26.68s
Train Epoch: 388 [20480/90000 (23%)]	Loss: -0.5636	Cost: 6.03s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -0.6267	Cost: 13.97s
Train Epoch: 388 [61440/90000 (68%)]	Loss: -0.8300	Cost: 14.30s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -0.5908	Cost: 14.28s
Train Epoch: 388 	Average Loss: -0.5194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5712

Learning rate: 0.00019925801452812757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 0.4221	Cost: 25.58s
Train Epoch: 389 [20480/90000 (23%)]	Loss: -0.4765	Cost: 6.08s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -0.6510	Cost: 13.83s
Train Epoch: 389 [61440/90000 (68%)]	Loss: -0.6262	Cost: 6.03s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -0.6084	Cost: 21.07s
Train Epoch: 389 	Average Loss: -0.4743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6219

Learning rate: 0.00019925418969940278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 0.6215	Cost: 24.66s
Train Epoch: 390 [20480/90000 (23%)]	Loss: -0.4557	Cost: 6.01s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -0.6756	Cost: 13.42s
Train Epoch: 390 [61440/90000 (68%)]	Loss: -0.6109	Cost: 6.08s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -0.6018	Cost: 12.71s
Train Epoch: 390 	Average Loss: -0.4948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5847

Learning rate: 0.00019925035507468219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 0.4920	Cost: 27.29s
Train Epoch: 391 [20480/90000 (23%)]	Loss: -0.4826	Cost: 8.69s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -0.7145	Cost: 9.21s
Train Epoch: 391 [61440/90000 (68%)]	Loss: -0.7573	Cost: 8.48s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -0.7393	Cost: 8.37s
Train Epoch: 391 	Average Loss: -0.5999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5468

Learning rate: 0.00019924651065434423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 0.6653	Cost: 29.21s
Train Epoch: 392 [20480/90000 (23%)]	Loss: -0.6781	Cost: 12.16s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -0.8602	Cost: 6.28s
Train Epoch: 392 [61440/90000 (68%)]	Loss: -0.7539	Cost: 6.12s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -0.7055	Cost: 9.20s
Train Epoch: 392 	Average Loss: -0.5949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5853

Learning rate: 0.0001992426564387684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 0.5810	Cost: 32.15s
Train Epoch: 393 [20480/90000 (23%)]	Loss: -0.6556	Cost: 15.97s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -0.8080	Cost: 7.29s
Train Epoch: 393 [61440/90000 (68%)]	Loss: -0.8110	Cost: 11.98s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -0.6354	Cost: 5.74s
Train Epoch: 393 	Average Loss: -0.6230
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6045

Learning rate: 0.00019923879242833502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 0.7168	Cost: 36.00s
Train Epoch: 394 [20480/90000 (23%)]	Loss: -0.7167	Cost: 6.19s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -0.8223	Cost: 16.17s
Train Epoch: 394 [61440/90000 (68%)]	Loss: -0.7666	Cost: 15.03s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -0.6911	Cost: 10.64s
Train Epoch: 394 	Average Loss: -0.6222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4809

Saving model as e394_model.pt & e394_waveforms_supplementary.hdf5
Learning rate: 0.00019923491862342552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 0.5090	Cost: 27.65s
Train Epoch: 395 [20480/90000 (23%)]	Loss: -0.6428	Cost: 8.25s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -0.9184	Cost: 11.03s
Train Epoch: 395 [61440/90000 (68%)]	Loss: -0.7433	Cost: 6.09s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -0.6682	Cost: 20.78s
Train Epoch: 395 	Average Loss: -0.6150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6012

Learning rate: 0.0001992310350244222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 0.6573	Cost: 24.66s
Train Epoch: 396 [20480/90000 (23%)]	Loss: -0.5382	Cost: 7.18s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -0.8002	Cost: 13.29s
Train Epoch: 396 [61440/90000 (68%)]	Loss: -0.7039	Cost: 7.31s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -0.6435	Cost: 11.24s
Train Epoch: 396 	Average Loss: -0.5681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5408

Learning rate: 0.0001992271416317084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 0.4159	Cost: 25.24s
Train Epoch: 397 [20480/90000 (23%)]	Loss: -0.7018	Cost: 6.18s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -0.7271	Cost: 13.46s
Train Epoch: 397 [61440/90000 (68%)]	Loss: -0.7263	Cost: 8.60s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -0.7993	Cost: 8.34s
Train Epoch: 397 	Average Loss: -0.6168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5267

Learning rate: 0.0001992232384456683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 0.4174	Cost: 28.30s
Train Epoch: 398 [20480/90000 (23%)]	Loss: -0.7556	Cost: 10.04s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -0.8685	Cost: 6.25s
Train Epoch: 398 [61440/90000 (68%)]	Loss: -0.9327	Cost: 6.05s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -0.7940	Cost: 9.51s
Train Epoch: 398 	Average Loss: -0.6853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4466

Saving model as e398_model.pt & e398_waveforms_supplementary.hdf5
Learning rate: 0.00019921932546668718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 0.3271	Cost: 27.84s
Train Epoch: 399 [20480/90000 (23%)]	Loss: -0.8584	Cost: 8.13s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -0.8836	Cost: 11.28s
Train Epoch: 399 [61440/90000 (68%)]	Loss: -0.9649	Cost: 9.48s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -0.7570	Cost: 5.76s
Train Epoch: 399 	Average Loss: -0.7586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4410

Saving model as e399_model.pt & e399_waveforms_supplementary.hdf5
Learning rate: 0.00019921540269515121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 0.2938	Cost: 28.33s
Train Epoch: 400 [20480/90000 (23%)]	Loss: -0.8317	Cost: 6.30s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -0.9930	Cost: 16.75s
Train Epoch: 400 [61440/90000 (68%)]	Loss: -0.9209	Cost: 11.68s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -0.8047	Cost: 11.87s
Train Epoch: 400 	Average Loss: -0.7961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4189

Saving model as e400_model.pt & e400_waveforms_supplementary.hdf5
Stopping timer.
Training time (including validation): 47648.85914158821 seconds
Saving model
Transfer learning by starting with alpha=0.8!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 124.7446	Cost: 23.80s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 73.4592	Cost: 7.56s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 49.7458	Cost: 9.85s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 39.2744	Cost: 8.48s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 32.1956	Cost: 8.26s
Train Epoch: 1 	Average Loss: 57.8148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 33.8866

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 31.0922	Cost: 25.86s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 24.7581	Cost: 10.71s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.6315	Cost: 6.06s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 17.4969	Cost: 5.97s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 16.3059	Cost: 6.05s
Train Epoch: 2 	Average Loss: 21.2766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2835

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 15.2306	Cost: 28.74s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 14.1992	Cost: 8.12s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 11.5460	Cost: 14.95s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 10.8326	Cost: 14.23s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 10.7996	Cost: 8.61s
Train Epoch: 3 	Average Loss: 12.5633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6106

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 10.2663	Cost: 29.64s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 9.2112	Cost: 6.18s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 8.8740	Cost: 10.65s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 8.3691	Cost: 6.12s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 7.7417	Cost: 16.21s
Train Epoch: 4 	Average Loss: 9.1569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0790

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 8.4857	Cost: 23.79s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 8.3942	Cost: 8.85s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 7.3644	Cost: 7.48s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 7.0643	Cost: 6.04s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 6.8231	Cost: 9.04s
Train Epoch: 5 	Average Loss: 7.5819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5280

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 6.5191	Cost: 23.79s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 6.5289	Cost: 6.22s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 6.4416	Cost: 10.36s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 5.9239	Cost: 8.58s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 6.3149	Cost: 9.44s
Train Epoch: 6 	Average Loss: 6.4707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7815

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 5.8044	Cost: 23.79s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 5.9023	Cost: 8.17s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 5.3005	Cost: 10.27s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 5.3389	Cost: 6.20s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 5.3888	Cost: 8.59s
Train Epoch: 7 	Average Loss: 5.6810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8902

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 4.9028	Cost: 25.40s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 5.0994	Cost: 6.27s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 4.7980	Cost: 13.31s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 5.2334	Cost: 14.90s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 5.1375	Cost: 12.11s
Train Epoch: 8 	Average Loss: 5.2767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7050

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 4.8775	Cost: 24.18s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 4.4315	Cost: 6.51s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 4.4288	Cost: 10.28s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 4.3091	Cost: 6.49s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 4.3096	Cost: 16.97s
Train Epoch: 9 	Average Loss: 4.7884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2539

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 4.6889	Cost: 23.40s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 4.3085	Cost: 6.17s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 4.1618	Cost: 10.32s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 4.2133	Cost: 6.10s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 4.2594	Cost: 11.50s
Train Epoch: 10 	Average Loss: 4.4174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7855

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 4.2525	Cost: 26.13s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 4.1832	Cost: 7.53s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 4.2512	Cost: 9.64s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 3.9853	Cost: 8.41s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 3.8283	Cost: 8.24s
Train Epoch: 11 	Average Loss: 4.1855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4540

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 4.4505	Cost: 27.58s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 3.9498	Cost: 6.96s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 3.7991	Cost: 10.97s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 3.8077	Cost: 5.92s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 3.3920	Cost: 8.57s
Train Epoch: 12 	Average Loss: 3.8742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3057

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 4.0808	Cost: 30.25s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 3.3810	Cost: 6.19s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 3.4281	Cost: 13.40s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 3.7530	Cost: 14.67s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 3.4243	Cost: 12.85s
Train Epoch: 13 	Average Loss: 3.7221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3247

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 3.9245	Cost: 28.19s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 3.4417	Cost: 6.45s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 3.1378	Cost: 10.46s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 3.1934	Cost: 6.08s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 3.4020	Cost: 18.20s
Train Epoch: 14 	Average Loss: 3.5043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8849

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 3.2115	Cost: 28.36s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 3.3000	Cost: 6.27s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 3.1515	Cost: 11.60s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 3.4217	Cost: 6.35s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 2.8586	Cost: 12.41s
Train Epoch: 15 	Average Loss: 3.3521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7690

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 3.4034	Cost: 23.68s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 3.0386	Cost: 7.44s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 3.0564	Cost: 9.44s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 2.9472	Cost: 8.61s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 2.9809	Cost: 8.51s
Train Epoch: 16 	Average Loss: 3.2368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8880

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 3.5350	Cost: 25.63s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 2.8834	Cost: 7.15s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 2.8148	Cost: 11.04s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 2.8795	Cost: 6.09s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 2.8184	Cost: 9.65s
Train Epoch: 17 	Average Loss: 3.1285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9512

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 3.2930	Cost: 25.98s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 2.8001	Cost: 6.07s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 2.7988	Cost: 16.45s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 2.8570	Cost: 13.00s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 2.7889	Cost: 11.93s
Train Epoch: 18 	Average Loss: 3.0089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5031

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 3.0434	Cost: 23.93s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 2.3611	Cost: 6.13s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 2.5313	Cost: 9.78s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 2.8421	Cost: 6.20s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 2.5075	Cost: 18.43s
Train Epoch: 19 	Average Loss: 2.7430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1685

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 2.8143	Cost: 23.94s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 2.9875	Cost: 6.18s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 2.5940	Cost: 10.62s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 2.4814	Cost: 6.08s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 2.9983	Cost: 11.80s
Train Epoch: 20 	Average Loss: 2.7630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2565

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 2.8364	Cost: 23.21s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 2.1970	Cost: 6.31s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 2.1755	Cost: 10.33s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 2.4703	Cost: 8.63s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 2.2960	Cost: 8.35s
Train Epoch: 21 	Average Loss: 2.5531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1377

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 2.5689	Cost: 24.97s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 2.4063	Cost: 11.34s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 2.1906	Cost: 7.08s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 2.4679	Cost: 6.11s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 2.2092	Cost: 6.04s
Train Epoch: 22 	Average Loss: 2.4850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8855

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 2.2294	Cost: 30.81s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 2.2915	Cost: 6.18s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 2.2288	Cost: 14.10s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 2.2196	Cost: 14.73s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 2.0651	Cost: 11.85s
Train Epoch: 23 	Average Loss: 2.3605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9680

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 2.3894	Cost: 29.61s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 2.2639	Cost: 7.13s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 2.2445	Cost: 9.98s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 2.0922	Cost: 6.16s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 2.1530	Cost: 14.60s
Train Epoch: 24 	Average Loss: 2.3386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0886

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 2.5564	Cost: 24.24s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 2.1443	Cost: 8.84s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 1.9823	Cost: 8.97s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 2.3051	Cost: 5.99s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 2.2144	Cost: 10.10s
Train Epoch: 25 	Average Loss: 2.2949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7613

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 2.3883	Cost: 24.40s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 2.0009	Cost: 6.72s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 2.0021	Cost: 11.54s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 1.9053	Cost: 8.80s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 1.9391	Cost: 9.94s
Train Epoch: 26 	Average Loss: 2.1758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5804

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 2.1572	Cost: 25.70s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 1.8077	Cost: 10.36s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 1.4071	Cost: 7.78s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 1.9471	Cost: 6.13s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 1.7639	Cost: 8.32s
Train Epoch: 27 	Average Loss: 2.0757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5149

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 2.4401	Cost: 25.84s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 1.7749	Cost: 6.32s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 1.5830	Cost: 14.99s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 1.8869	Cost: 14.09s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 1.5421	Cost: 10.43s
Train Epoch: 28 	Average Loss: 2.0361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6424

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 2.1536	Cost: 24.23s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 1.7114	Cost: 6.40s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 1.4899	Cost: 9.59s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 1.9383	Cost: 6.24s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 1.6210	Cost: 14.18s
Train Epoch: 29 	Average Loss: 1.9704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5914

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 2.1101	Cost: 23.42s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 1.7247	Cost: 8.62s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 1.6296	Cost: 8.57s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 1.5506	Cost: 8.40s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 1.7739	Cost: 7.52s
Train Epoch: 30 	Average Loss: 1.8876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6339

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 1.8796	Cost: 25.25s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 1.5534	Cost: 8.18s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 1.4518	Cost: 10.02s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 1.6917	Cost: 6.13s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 1.6029	Cost: 6.37s
Train Epoch: 31 	Average Loss: 1.8447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4438

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 2.1094	Cost: 28.20s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 1.6377	Cost: 6.17s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 1.2910	Cost: 15.39s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 1.9278	Cost: 14.66s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 1.4208	Cost: 13.02s
Train Epoch: 32 	Average Loss: 1.7342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2962

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 2.3849	Cost: 26.87s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 1.3384	Cost: 7.14s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 1.4612	Cost: 8.98s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 2.0331	Cost: 11.16s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 1.6753	Cost: 14.82s
Train Epoch: 33 	Average Loss: 1.7408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5129

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 1.6831	Cost: 28.79s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 1.5504	Cost: 6.16s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 1.3123	Cost: 10.63s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 1.5381	Cost: 6.14s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 1.4125	Cost: 17.21s
Train Epoch: 34 	Average Loss: 1.7021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1797

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 1.4575	Cost: 23.72s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 1.1833	Cost: 6.69s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 1.2204	Cost: 10.96s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 1.3178	Cost: 6.15s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 1.2451	Cost: 11.85s
Train Epoch: 35 	Average Loss: 1.5231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0639

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 1.3770	Cost: 24.64s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 1.4552	Cost: 6.56s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 1.1516	Cost: 10.21s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 1.5553	Cost: 9.00s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 1.2845	Cost: 9.96s
Train Epoch: 36 	Average Loss: 1.4530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1637

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 1.8200	Cost: 24.44s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 1.3162	Cost: 10.16s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 1.3121	Cost: 8.21s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 1.5732	Cost: 6.09s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 1.1130	Cost: 6.04s
Train Epoch: 37 	Average Loss: 1.4685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1995

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 1.8080	Cost: 28.68s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 1.2573	Cost: 15.32s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 1.3904	Cost: 12.15s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 1.3951	Cost: 11.82s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 0.9429	Cost: 5.71s
Train Epoch: 38 	Average Loss: 1.4329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1960

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 1.8855	Cost: 25.32s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 0.8856	Cost: 6.55s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 1.2208	Cost: 9.18s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 1.3313	Cost: 11.08s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 1.1491	Cost: 14.87s
Train Epoch: 39 	Average Loss: 1.4209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9764

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 1.3778	Cost: 22.80s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 0.9452	Cost: 6.36s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 0.8899	Cost: 10.17s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 1.2857	Cost: 6.09s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 1.1144	Cost: 11.65s
Train Epoch: 40 	Average Loss: 1.3234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4078

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 1.4433	Cost: 25.18s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 1.1994	Cost: 6.22s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 1.2152	Cost: 10.25s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 1.0757	Cost: 8.56s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 1.1827	Cost: 8.29s
Train Epoch: 41 	Average Loss: 1.2831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9726

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 1.5315	Cost: 28.20s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 0.8660	Cost: 12.16s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 0.8385	Cost: 6.29s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 1.0011	Cost: 6.13s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 0.8835	Cost: 5.87s
Train Epoch: 42 	Average Loss: 1.2347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0914

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 1.5303	Cost: 25.31s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 1.0444	Cost: 13.84s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 0.8118	Cost: 14.96s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 1.1340	Cost: 5.93s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 0.9354	Cost: 11.90s
Train Epoch: 43 	Average Loss: 1.1489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9825

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 1.2022	Cost: 24.52s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 0.5790	Cost: 6.30s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 0.7527	Cost: 10.21s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 0.9820	Cost: 6.33s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 0.7947	Cost: 12.88s
Train Epoch: 44 	Average Loss: 1.0720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8691

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 1.6794	Cost: 25.12s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 0.7361	Cost: 8.65s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 1.2392	Cost: 8.61s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 1.1441	Cost: 8.43s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 0.9885	Cost: 8.73s
Train Epoch: 45 	Average Loss: 1.0770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8844

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 1.3692	Cost: 23.77s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 0.8909	Cost: 8.23s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 0.7802	Cost: 10.10s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 1.0440	Cost: 6.05s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 0.7946	Cost: 5.78s
Train Epoch: 46 	Average Loss: 1.0278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7844

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 1.4100	Cost: 28.44s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 0.5401	Cost: 12.98s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 0.8658	Cost: 14.40s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 0.7242	Cost: 12.77s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 0.6172	Cost: 5.66s
Train Epoch: 47 	Average Loss: 0.9768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9390

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 1.5397	Cost: 24.04s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 0.5335	Cost: 6.45s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 0.9454	Cost: 9.43s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 1.2008	Cost: 7.40s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 0.5146	Cost: 16.99s
Train Epoch: 48 	Average Loss: 0.9219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9040

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 1.2542	Cost: 25.92s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 0.3614	Cost: 6.03s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 0.7979	Cost: 9.84s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 0.6616	Cost: 6.10s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 0.8827	Cost: 11.66s
Train Epoch: 49 	Average Loss: 0.8049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6214

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 0.7328	Cost: 24.96s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 0.5719	Cost: 6.05s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 0.6552	Cost: 10.41s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 0.9326	Cost: 8.57s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 0.7193	Cost: 8.34s
Train Epoch: 50 	Average Loss: 0.8255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7165

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 1.0680	Cost: 25.90s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 0.5399	Cost: 6.35s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 0.2260	Cost: 11.99s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 0.5928	Cost: 6.14s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 0.4702	Cost: 10.42s
Train Epoch: 51 	Average Loss: 0.7719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7920

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 1.4527	Cost: 25.67s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 0.4615	Cost: 6.83s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 1.0910	Cost: 15.39s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 0.9007	Cost: 12.92s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 0.5661	Cost: 6.94s
Train Epoch: 52 	Average Loss: 0.7956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6252

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 1.3231	Cost: 23.30s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 0.2064	Cost: 6.31s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 0.4176	Cost: 9.71s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 0.2695	Cost: 6.06s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 0.4379	Cost: 15.85s
Train Epoch: 53 	Average Loss: 0.6639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6785

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 0.9689	Cost: 23.69s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 0.4651	Cost: 8.90s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 0.4641	Cost: 8.82s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 0.4516	Cost: 7.77s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 0.5516	Cost: 6.43s
Train Epoch: 54 	Average Loss: 0.7748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6572

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 1.3192	Cost: 24.23s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 0.2755	Cost: 6.27s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 0.5624	Cost: 9.11s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 0.3832	Cost: 6.07s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 0.3940	Cost: 10.25s
Train Epoch: 55 	Average Loss: 0.6482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5377

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 0.9550	Cost: 28.30s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 0.2390	Cost: 6.08s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 0.1839	Cost: 12.11s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 0.3563	Cost: 6.10s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 0.3978	Cost: 8.58s
Train Epoch: 56 	Average Loss: 0.5475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6633

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 0.8437	Cost: 29.11s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 0.2894	Cost: 6.69s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 0.2962	Cost: 15.80s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 0.4977	Cost: 14.23s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 0.3169	Cost: 9.57s
Train Epoch: 57 	Average Loss: 0.5524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5501

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 0.9344	Cost: 26.57s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 0.4688	Cost: 7.11s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 0.4257	Cost: 9.03s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 0.0635	Cost: 6.22s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 0.4417	Cost: 17.87s
Train Epoch: 58 	Average Loss: 0.4930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5796

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 0.6726	Cost: 27.29s
Train Epoch: 59 [20480/90000 (23%)]	Loss: -0.0124	Cost: 6.49s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 0.0294	Cost: 11.05s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 0.3121	Cost: 6.36s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 0.2652	Cost: 13.42s
Train Epoch: 59 	Average Loss: 0.4154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5228

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 0.8122	Cost: 24.40s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 0.1296	Cost: 8.92s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 0.2766	Cost: 8.81s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 0.2656	Cost: 6.00s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 0.3668	Cost: 9.19s
Train Epoch: 60 	Average Loss: 0.4379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5846

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 1.0383	Cost: 25.21s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 0.1624	Cost: 6.58s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 0.1234	Cost: 9.77s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 0.3945	Cost: 9.21s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 0.2881	Cost: 10.41s
Train Epoch: 61 	Average Loss: 0.4005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7385

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 1.0260	Cost: 24.59s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 0.2421	Cost: 6.07s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 0.1040	Cost: 12.07s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 0.5073	Cost: 5.86s
Train Epoch: 62 [81920/90000 (91%)]	Loss: -0.1591	Cost: 6.03s
Train Epoch: 62 	Average Loss: 0.4004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7101

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 0.7919	Cost: 26.01s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 0.1574	Cost: 6.09s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 0.2093	Cost: 13.10s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 0.0046	Cost: 14.44s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 0.3585	Cost: 12.27s
Train Epoch: 63 	Average Loss: 0.3367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6306

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 0.9279	Cost: 23.37s
Train Epoch: 64 [20480/90000 (23%)]	Loss: -0.0185	Cost: 6.60s
Train Epoch: 64 [40960/90000 (45%)]	Loss: -0.1309	Cost: 9.23s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 0.2559	Cost: 6.11s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 0.2393	Cost: 19.03s
Train Epoch: 64 	Average Loss: 0.3080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4619

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 0.7687	Cost: 22.35s
Train Epoch: 65 [20480/90000 (23%)]	Loss: -0.0020	Cost: 6.17s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 0.1270	Cost: 11.64s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 0.6553	Cost: 6.09s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 0.2504	Cost: 12.36s
Train Epoch: 65 	Average Loss: 0.3053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2099

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 0.3562	Cost: 24.79s
Train Epoch: 66 [20480/90000 (23%)]	Loss: -0.1382	Cost: 8.79s
Train Epoch: 66 [40960/90000 (45%)]	Loss: -0.0355	Cost: 8.79s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 0.1130	Cost: 8.52s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 0.1770	Cost: 8.28s
Train Epoch: 66 	Average Loss: 0.2131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2132

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 1.2026	Cost: 26.95s
Train Epoch: 67 [20480/90000 (23%)]	Loss: -0.1787	Cost: 12.31s
Train Epoch: 67 [40960/90000 (45%)]	Loss: -0.0823	Cost: 6.25s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 0.0724	Cost: 6.11s
Train Epoch: 67 [81920/90000 (91%)]	Loss: -0.0142	Cost: 6.54s
Train Epoch: 67 	Average Loss: 0.1794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3887

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 0.6876	Cost: 44.06s
Train Epoch: 68 [20480/90000 (23%)]	Loss: -0.1883	Cost: 14.47s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 0.1341	Cost: 12.15s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 0.1309	Cost: 11.91s
Train Epoch: 68 [81920/90000 (91%)]	Loss: -0.1494	Cost: 5.84s
Train Epoch: 68 	Average Loss: 0.1023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2198

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 0.7352	Cost: 28.24s
Train Epoch: 69 [20480/90000 (23%)]	Loss: -0.2999	Cost: 6.85s
Train Epoch: 69 [40960/90000 (45%)]	Loss: -0.1434	Cost: 9.80s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 0.0845	Cost: 6.09s
Train Epoch: 69 [81920/90000 (91%)]	Loss: -0.1776	Cost: 15.81s
Train Epoch: 69 	Average Loss: 0.1054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3867

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 0.3126	Cost: 23.72s
Train Epoch: 70 [20480/90000 (23%)]	Loss: -0.1109	Cost: 8.85s
Train Epoch: 70 [40960/90000 (45%)]	Loss: -0.3939	Cost: 7.65s
Train Epoch: 70 [61440/90000 (68%)]	Loss: -0.3133	Cost: 6.02s
Train Epoch: 70 [81920/90000 (91%)]	Loss: -0.2730	Cost: 11.99s
Train Epoch: 70 	Average Loss: 0.0203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3451

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 1.1550	Cost: 23.70s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 0.1129	Cost: 6.15s
Train Epoch: 71 [40960/90000 (45%)]	Loss: -0.2044	Cost: 11.26s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 0.2677	Cost: 8.61s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 0.0334	Cost: 9.37s
Train Epoch: 71 	Average Loss: 0.1724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3463

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 0.6912	Cost: 25.04s
Train Epoch: 72 [20480/90000 (23%)]	Loss: -0.2285	Cost: 7.13s
Train Epoch: 72 [40960/90000 (45%)]	Loss: -0.1465	Cost: 11.07s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 0.1326	Cost: 6.07s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 0.0208	Cost: 9.23s
Train Epoch: 72 	Average Loss: 0.1553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3494

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 0.9917	Cost: 26.21s
Train Epoch: 73 [20480/90000 (23%)]	Loss: -0.3572	Cost: 6.07s
Train Epoch: 73 [40960/90000 (45%)]	Loss: -0.3555	Cost: 15.66s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 0.2997	Cost: 15.92s
Train Epoch: 73 [81920/90000 (91%)]	Loss: -0.3302	Cost: 6.56s
Train Epoch: 73 	Average Loss: 0.0511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2119

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 0.8978	Cost: 23.66s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 0.0048	Cost: 6.11s
Train Epoch: 74 [40960/90000 (45%)]	Loss: -0.2883	Cost: 9.86s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 0.0581	Cost: 6.07s
Train Epoch: 74 [81920/90000 (91%)]	Loss: -0.1925	Cost: 10.17s
Train Epoch: 74 	Average Loss: -0.0761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0732

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 0.7341	Cost: 24.97s
Train Epoch: 75 [20480/90000 (23%)]	Loss: -0.1673	Cost: 8.81s
Train Epoch: 75 [40960/90000 (45%)]	Loss: -0.3451	Cost: 8.66s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 0.0217	Cost: 7.52s
Train Epoch: 75 [81920/90000 (91%)]	Loss: -0.5486	Cost: 5.68s
Train Epoch: 75 	Average Loss: -0.0527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2618

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 0.6414	Cost: 23.18s
Train Epoch: 76 [20480/90000 (23%)]	Loss: -0.1115	Cost: 6.16s
Train Epoch: 76 [40960/90000 (45%)]	Loss: -0.2599	Cost: 8.83s
Train Epoch: 76 [61440/90000 (68%)]	Loss: -0.1537	Cost: 6.19s
Train Epoch: 76 [81920/90000 (91%)]	Loss: -0.3511	Cost: 8.79s
Train Epoch: 76 	Average Loss: -0.1345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1866

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 0.3294	Cost: 28.05s
Train Epoch: 77 [20480/90000 (23%)]	Loss: -0.3096	Cost: 14.83s
Train Epoch: 77 [40960/90000 (45%)]	Loss: -0.4945	Cost: 8.61s
Train Epoch: 77 [61440/90000 (68%)]	Loss: -0.1270	Cost: 10.54s
Train Epoch: 77 [81920/90000 (91%)]	Loss: -0.0742	Cost: 5.91s
Train Epoch: 77 	Average Loss: -0.0944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3152

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 0.8735	Cost: 39.40s
Train Epoch: 78 [20480/90000 (23%)]	Loss: -0.3398	Cost: 6.18s
Train Epoch: 78 [40960/90000 (45%)]	Loss: -0.1398	Cost: 14.00s
Train Epoch: 78 [61440/90000 (68%)]	Loss: -0.2493	Cost: 13.85s
Train Epoch: 78 [81920/90000 (91%)]	Loss: -0.2259	Cost: 11.81s
Train Epoch: 78 	Average Loss: -0.0523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0748

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 0.3116	Cost: 27.60s
Train Epoch: 79 [20480/90000 (23%)]	Loss: -0.4277	Cost: 7.31s
Train Epoch: 79 [40960/90000 (45%)]	Loss: -0.4150	Cost: 9.61s
Train Epoch: 79 [61440/90000 (68%)]	Loss: -0.4553	Cost: 6.22s
Train Epoch: 79 [81920/90000 (91%)]	Loss: -0.5702	Cost: 18.54s
Train Epoch: 79 	Average Loss: -0.1772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2483

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 0.2494	Cost: 24.36s
Train Epoch: 80 [20480/90000 (23%)]	Loss: -0.3611	Cost: 6.16s
Train Epoch: 80 [40960/90000 (45%)]	Loss: -0.5324	Cost: 10.34s
Train Epoch: 80 [61440/90000 (68%)]	Loss: -0.2885	Cost: 6.11s
Train Epoch: 80 [81920/90000 (91%)]	Loss: -0.5298	Cost: 12.04s
Train Epoch: 80 	Average Loss: -0.2484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0067

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 0.7787	Cost: 23.44s
Train Epoch: 81 [20480/90000 (23%)]	Loss: -0.4610	Cost: 6.21s
Train Epoch: 81 [40960/90000 (45%)]	Loss: -0.6629	Cost: 9.32s
Train Epoch: 81 [61440/90000 (68%)]	Loss: -0.2759	Cost: 9.25s
Train Epoch: 81 [81920/90000 (91%)]	Loss: -0.2846	Cost: 10.22s
Train Epoch: 81 	Average Loss: -0.2537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0311

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 0.3770	Cost: 26.21s
Train Epoch: 82 [20480/90000 (23%)]	Loss: -0.7789	Cost: 8.87s
Train Epoch: 82 [40960/90000 (45%)]	Loss: -0.4418	Cost: 9.45s
Train Epoch: 82 [61440/90000 (68%)]	Loss: -0.4898	Cost: 6.10s
Train Epoch: 82 [81920/90000 (91%)]	Loss: -0.6415	Cost: 7.24s
Train Epoch: 82 	Average Loss: -0.2349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9576

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 0.6059	Cost: 25.73s
Train Epoch: 83 [20480/90000 (23%)]	Loss: -0.6914	Cost: 14.88s
Train Epoch: 83 [40960/90000 (45%)]	Loss: -0.5934	Cost: 11.17s
Train Epoch: 83 [61440/90000 (68%)]	Loss: -0.4613	Cost: 11.36s
Train Epoch: 83 [81920/90000 (91%)]	Loss: -0.6506	Cost: 5.71s
Train Epoch: 83 	Average Loss: -0.3513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8475

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 0.5202	Cost: 26.57s
Train Epoch: 84 [20480/90000 (23%)]	Loss: -0.7544	Cost: 6.37s
Train Epoch: 84 [40960/90000 (45%)]	Loss: -0.6391	Cost: 13.24s
Train Epoch: 84 [61440/90000 (68%)]	Loss: -0.3847	Cost: 14.35s
Train Epoch: 84 [81920/90000 (91%)]	Loss: -0.7128	Cost: 14.52s
Train Epoch: 84 	Average Loss: -0.3636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3857

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 0.3469	Cost: 23.67s
Train Epoch: 85 [20480/90000 (23%)]	Loss: -0.5373	Cost: 6.72s
Train Epoch: 85 [40960/90000 (45%)]	Loss: -0.6066	Cost: 9.34s
Train Epoch: 85 [61440/90000 (68%)]	Loss: -0.4396	Cost: 6.04s
Train Epoch: 85 [81920/90000 (91%)]	Loss: -0.4755	Cost: 10.78s
Train Epoch: 85 	Average Loss: -0.3754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9866

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 0.2373	Cost: 26.62s
Train Epoch: 86 [20480/90000 (23%)]	Loss: -0.8618	Cost: 8.66s
Train Epoch: 86 [40960/90000 (45%)]	Loss: -0.8270	Cost: 8.84s
Train Epoch: 86 [61440/90000 (68%)]	Loss: -0.2479	Cost: 8.64s
Train Epoch: 86 [81920/90000 (91%)]	Loss: -0.6720	Cost: 8.36s
Train Epoch: 86 	Average Loss: -0.4741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6867

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 0.0409	Cost: 27.33s
Train Epoch: 87 [20480/90000 (23%)]	Loss: -0.9776	Cost: 10.72s
Train Epoch: 87 [40960/90000 (45%)]	Loss: -1.1287	Cost: 6.21s
Train Epoch: 87 [61440/90000 (68%)]	Loss: -0.5593	Cost: 6.08s
Train Epoch: 87 [81920/90000 (91%)]	Loss: -0.7232	Cost: 10.03s
Train Epoch: 87 	Average Loss: -0.5771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9776

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 0.1829	Cost: 30.85s
Train Epoch: 88 [20480/90000 (23%)]	Loss: -0.3712	Cost: 6.35s
Train Epoch: 88 [40960/90000 (45%)]	Loss: -0.6739	Cost: 14.47s
Train Epoch: 88 [61440/90000 (68%)]	Loss: -0.4550	Cost: 13.54s
Train Epoch: 88 [81920/90000 (91%)]	Loss: -0.8374	Cost: 11.83s
Train Epoch: 88 	Average Loss: -0.4963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8273

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 0.4705	Cost: 29.74s
Train Epoch: 89 [20480/90000 (23%)]	Loss: -0.9157	Cost: 6.41s
Train Epoch: 89 [40960/90000 (45%)]	Loss: -0.8493	Cost: 10.19s
Train Epoch: 89 [61440/90000 (68%)]	Loss: -0.6224	Cost: 6.11s
Train Epoch: 89 [81920/90000 (91%)]	Loss: -0.4762	Cost: 18.90s
Train Epoch: 89 	Average Loss: -0.5672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9017

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 0.4851	Cost: 25.34s
Train Epoch: 90 [20480/90000 (23%)]	Loss: -0.9843	Cost: 8.06s
Train Epoch: 90 [40960/90000 (45%)]	Loss: -0.8331	Cost: 10.80s
Train Epoch: 90 [61440/90000 (68%)]	Loss: -0.4698	Cost: 6.18s
Train Epoch: 90 [81920/90000 (91%)]	Loss: -0.8090	Cost: 12.00s
Train Epoch: 90 	Average Loss: -0.6173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7055

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: -0.0241	Cost: 23.99s
Train Epoch: 91 [20480/90000 (23%)]	Loss: -1.0768	Cost: 7.95s
Train Epoch: 91 [40960/90000 (45%)]	Loss: -1.0782	Cost: 8.87s
Train Epoch: 91 [61440/90000 (68%)]	Loss: -0.3014	Cost: 8.99s
Train Epoch: 91 [81920/90000 (91%)]	Loss: -0.7999	Cost: 8.92s
Train Epoch: 91 	Average Loss: -0.6527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7831

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 0.1426	Cost: 26.47s
Train Epoch: 92 [20480/90000 (23%)]	Loss: -1.2360	Cost: 11.41s
Train Epoch: 92 [40960/90000 (45%)]	Loss: -0.7790	Cost: 6.92s
Train Epoch: 92 [61440/90000 (68%)]	Loss: -0.4693	Cost: 6.08s
Train Epoch: 92 [81920/90000 (91%)]	Loss: -0.9324	Cost: 8.52s
Train Epoch: 92 	Average Loss: -0.6144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8189

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 0.0670	Cost: 26.10s
Train Epoch: 93 [20480/90000 (23%)]	Loss: -0.9608	Cost: 14.83s
Train Epoch: 93 [40960/90000 (45%)]	Loss: -0.7929	Cost: 13.27s
Train Epoch: 93 [61440/90000 (68%)]	Loss: -0.7742	Cost: 11.78s
Train Epoch: 93 [81920/90000 (91%)]	Loss: -0.5972	Cost: 5.69s
Train Epoch: 93 	Average Loss: -0.6443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6751

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 0.3565	Cost: 25.61s
Train Epoch: 94 [20480/90000 (23%)]	Loss: -1.0775	Cost: 6.42s
Train Epoch: 94 [40960/90000 (45%)]	Loss: -1.1894	Cost: 9.46s
Train Epoch: 94 [61440/90000 (68%)]	Loss: -0.6459	Cost: 15.53s
Train Epoch: 94 [81920/90000 (91%)]	Loss: -0.9315	Cost: 14.21s
Train Epoch: 94 	Average Loss: -0.7017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9335

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 0.2381	Cost: 23.17s
Train Epoch: 95 [20480/90000 (23%)]	Loss: -1.1933	Cost: 6.14s
Train Epoch: 95 [40960/90000 (45%)]	Loss: -1.0520	Cost: 10.13s
Train Epoch: 95 [61440/90000 (68%)]	Loss: -0.8556	Cost: 6.12s
Train Epoch: 95 [81920/90000 (91%)]	Loss: -0.9538	Cost: 11.50s
Train Epoch: 95 	Average Loss: -0.7216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6494

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 0.2985	Cost: 25.10s
Train Epoch: 96 [20480/90000 (23%)]	Loss: -0.8998	Cost: 8.53s
Train Epoch: 96 [40960/90000 (45%)]	Loss: -1.2418	Cost: 8.65s
Train Epoch: 96 [61440/90000 (68%)]	Loss: -0.8012	Cost: 8.43s
Train Epoch: 96 [81920/90000 (91%)]	Loss: -0.8734	Cost: 8.23s
Train Epoch: 96 	Average Loss: -0.7507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6137

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 0.1683	Cost: 30.07s
Train Epoch: 97 [20480/90000 (23%)]	Loss: -1.2220	Cost: 6.99s
Train Epoch: 97 [40960/90000 (45%)]	Loss: -1.0314	Cost: 9.71s
Train Epoch: 97 [61440/90000 (68%)]	Loss: -0.8850	Cost: 5.88s
Train Epoch: 97 [81920/90000 (91%)]	Loss: -0.8881	Cost: 11.47s
Train Epoch: 97 	Average Loss: -0.7803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8341

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 0.1290	Cost: 31.37s
Train Epoch: 98 [20480/90000 (23%)]	Loss: -1.0512	Cost: 14.89s
Train Epoch: 98 [40960/90000 (45%)]	Loss: -0.9585	Cost: 6.24s
Train Epoch: 98 [61440/90000 (68%)]	Loss: -1.0292	Cost: 11.82s
Train Epoch: 98 [81920/90000 (91%)]	Loss: -1.1817	Cost: 5.69s
Train Epoch: 98 	Average Loss: -0.8838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6394

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 0.0006	Cost: 32.69s
Train Epoch: 99 [20480/90000 (23%)]	Loss: -1.3164	Cost: 6.17s
Train Epoch: 99 [40960/90000 (45%)]	Loss: -1.1201	Cost: 10.61s
Train Epoch: 99 [61440/90000 (68%)]	Loss: -0.9325	Cost: 5.99s
Train Epoch: 99 [81920/90000 (91%)]	Loss: -1.2035	Cost: 17.11s
Train Epoch: 99 	Average Loss: -0.9170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6202

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 0.2700	Cost: 23.40s
Train Epoch: 100 [20480/90000 (23%)]	Loss: -1.1300	Cost: 8.81s
Train Epoch: 100 [40960/90000 (45%)]	Loss: -1.2699	Cost: 7.18s
Train Epoch: 100 [61440/90000 (68%)]	Loss: -0.9306	Cost: 6.83s
Train Epoch: 100 [81920/90000 (91%)]	Loss: -1.2662	Cost: 10.44s
Train Epoch: 100 	Average Loss: -0.9268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5862

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: -0.1010	Cost: 23.31s
Train Epoch: 101 [20480/90000 (23%)]	Loss: -1.3422	Cost: 6.88s
Train Epoch: 101 [40960/90000 (45%)]	Loss: -1.2289	Cost: 9.43s
Train Epoch: 101 [61440/90000 (68%)]	Loss: -1.1999	Cost: 8.96s
Train Epoch: 101 [81920/90000 (91%)]	Loss: -1.2070	Cost: 8.94s
Train Epoch: 101 	Average Loss: -0.9316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7851

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 0.0599	Cost: 26.47s
Train Epoch: 102 [20480/90000 (23%)]	Loss: -1.3861	Cost: 12.16s
Train Epoch: 102 [40960/90000 (45%)]	Loss: -1.2463	Cost: 6.21s
Train Epoch: 102 [61440/90000 (68%)]	Loss: -1.0645	Cost: 6.13s
Train Epoch: 102 [81920/90000 (91%)]	Loss: -1.2104	Cost: 8.35s
Train Epoch: 102 	Average Loss: -0.9829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5625

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: -0.2717	Cost: 25.64s
Train Epoch: 103 [20480/90000 (23%)]	Loss: -1.1969	Cost: 14.84s
Train Epoch: 103 [40960/90000 (45%)]	Loss: -1.4684	Cost: 6.95s
Train Epoch: 103 [61440/90000 (68%)]	Loss: -0.9882	Cost: 11.82s
Train Epoch: 103 [81920/90000 (91%)]	Loss: -1.4498	Cost: 5.97s
Train Epoch: 103 	Average Loss: -0.9925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5595

Saving model as e103_model.pt & e103_waveforms_supplementary.hdf5
Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 0.2094	Cost: 25.59s
Train Epoch: 104 [20480/90000 (23%)]	Loss: -1.3390	Cost: 6.19s
Train Epoch: 104 [40960/90000 (45%)]	Loss: -1.4636	Cost: 13.49s
Train Epoch: 104 [61440/90000 (68%)]	Loss: -1.0449	Cost: 14.99s
Train Epoch: 104 [81920/90000 (91%)]	Loss: -0.8228	Cost: 13.64s
Train Epoch: 104 	Average Loss: -0.9359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6655

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 0.1796	Cost: 23.28s
Train Epoch: 105 [20480/90000 (23%)]	Loss: -1.2287	Cost: 6.58s
Train Epoch: 105 [40960/90000 (45%)]	Loss: -1.0817	Cost: 9.45s
Train Epoch: 105 [61440/90000 (68%)]	Loss: -1.0745	Cost: 6.07s
Train Epoch: 105 [81920/90000 (91%)]	Loss: -1.1987	Cost: 10.82s
Train Epoch: 105 	Average Loss: -0.9749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4592

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 0.0477	Cost: 24.07s
Train Epoch: 106 [20480/90000 (23%)]	Loss: -1.3209	Cost: 8.44s
Train Epoch: 106 [40960/90000 (45%)]	Loss: -1.2068	Cost: 8.62s
Train Epoch: 106 [61440/90000 (68%)]	Loss: -1.3772	Cost: 8.51s
Train Epoch: 106 [81920/90000 (91%)]	Loss: -1.4569	Cost: 8.25s
Train Epoch: 106 	Average Loss: -1.0633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5200

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 0.3857	Cost: 28.41s
Train Epoch: 107 [20480/90000 (23%)]	Loss: -1.4111	Cost: 8.67s
Train Epoch: 107 [40960/90000 (45%)]	Loss: -1.5261	Cost: 9.49s
Train Epoch: 107 [61440/90000 (68%)]	Loss: -1.1947	Cost: 5.94s
Train Epoch: 107 [81920/90000 (91%)]	Loss: -1.2558	Cost: 5.77s
Train Epoch: 107 	Average Loss: -1.1456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6149

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 0.0443	Cost: 28.17s
Train Epoch: 108 [20480/90000 (23%)]	Loss: -1.5593	Cost: 7.11s
Train Epoch: 108 [40960/90000 (45%)]	Loss: -1.4193	Cost: 9.85s
Train Epoch: 108 [61440/90000 (68%)]	Loss: -1.2199	Cost: 9.41s
Train Epoch: 108 [81920/90000 (91%)]	Loss: -1.3064	Cost: 15.30s
Train Epoch: 108 	Average Loss: -1.1057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3748

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: -0.1869	Cost: 22.76s
Train Epoch: 109 [20480/90000 (23%)]	Loss: -1.1207	Cost: 7.07s
Train Epoch: 109 [40960/90000 (45%)]	Loss: -1.5216	Cost: 13.43s
Train Epoch: 109 [61440/90000 (68%)]	Loss: -0.9798	Cost: 7.08s
Train Epoch: 109 [81920/90000 (91%)]	Loss: -1.5462	Cost: 11.85s
Train Epoch: 109 	Average Loss: -1.1592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7017

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 0.1954	Cost: 25.31s
Train Epoch: 110 [20480/90000 (23%)]	Loss: -1.5798	Cost: 7.33s
Train Epoch: 110 [40960/90000 (45%)]	Loss: -1.6714	Cost: 9.58s
Train Epoch: 110 [61440/90000 (68%)]	Loss: -1.1113	Cost: 8.85s
Train Epoch: 110 [81920/90000 (91%)]	Loss: -1.4827	Cost: 8.98s
Train Epoch: 110 	Average Loss: -1.2138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4751

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: -0.2540	Cost: 26.09s
Train Epoch: 111 [20480/90000 (23%)]	Loss: -1.7441	Cost: 12.09s
Train Epoch: 111 [40960/90000 (45%)]	Loss: -1.4422	Cost: 6.17s
Train Epoch: 111 [61440/90000 (68%)]	Loss: -1.5656	Cost: 6.06s
Train Epoch: 111 [81920/90000 (91%)]	Loss: -1.4409	Cost: 9.75s
Train Epoch: 111 	Average Loss: -1.2763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5559

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: -0.2181	Cost: 28.90s
Train Epoch: 112 [20480/90000 (23%)]	Loss: -1.7293	Cost: 14.46s
Train Epoch: 112 [40960/90000 (45%)]	Loss: -1.3422	Cost: 13.30s
Train Epoch: 112 [61440/90000 (68%)]	Loss: -1.2941	Cost: 9.70s
Train Epoch: 112 [81920/90000 (91%)]	Loss: -1.4664	Cost: 5.63s
Train Epoch: 112 	Average Loss: -1.2736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5471

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 0.1042	Cost: 25.53s
Train Epoch: 113 [20480/90000 (23%)]	Loss: -1.4796	Cost: 6.52s
Train Epoch: 113 [40960/90000 (45%)]	Loss: -1.7418	Cost: 12.60s
Train Epoch: 113 [61440/90000 (68%)]	Loss: -1.2165	Cost: 14.70s
Train Epoch: 113 [81920/90000 (91%)]	Loss: -1.6723	Cost: 14.66s
Train Epoch: 113 	Average Loss: -1.2430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3329

Saving model as e113_model.pt & e113_waveforms_supplementary.hdf5
Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: -0.0246	Cost: 23.09s
Train Epoch: 114 [20480/90000 (23%)]	Loss: -1.6937	Cost: 6.51s
Train Epoch: 114 [40960/90000 (45%)]	Loss: -1.5139	Cost: 9.86s
Train Epoch: 114 [61440/90000 (68%)]	Loss: -1.2921	Cost: 6.12s
Train Epoch: 114 [81920/90000 (91%)]	Loss: -1.5576	Cost: 17.53s
Train Epoch: 114 	Average Loss: -1.3136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3344

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 0.0551	Cost: 25.27s
Train Epoch: 115 [20480/90000 (23%)]	Loss: -1.4496	Cost: 8.65s
Train Epoch: 115 [40960/90000 (45%)]	Loss: -1.6483	Cost: 7.69s
Train Epoch: 115 [61440/90000 (68%)]	Loss: -1.4775	Cost: 6.11s
Train Epoch: 115 [81920/90000 (91%)]	Loss: -1.6966	Cost: 12.39s
Train Epoch: 115 	Average Loss: -1.3498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5487

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: -0.1370	Cost: 25.06s
Train Epoch: 116 [20480/90000 (23%)]	Loss: -1.4845	Cost: 6.25s
Train Epoch: 116 [40960/90000 (45%)]	Loss: -1.6245	Cost: 8.69s
Train Epoch: 116 [61440/90000 (68%)]	Loss: -1.3166	Cost: 7.53s
Train Epoch: 116 [81920/90000 (91%)]	Loss: -1.6172	Cost: 8.96s
Train Epoch: 116 	Average Loss: -1.3209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2925

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: -0.3266	Cost: 31.75s
Train Epoch: 117 [20480/90000 (23%)]	Loss: -1.9778	Cost: 10.02s
Train Epoch: 117 [40960/90000 (45%)]	Loss: -1.8625	Cost: 8.27s
Train Epoch: 117 [61440/90000 (68%)]	Loss: -1.5246	Cost: 6.17s
Train Epoch: 117 [81920/90000 (91%)]	Loss: -1.7668	Cost: 7.74s
Train Epoch: 117 	Average Loss: -1.4550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4123

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: -0.7158	Cost: 31.67s
Train Epoch: 118 [20480/90000 (23%)]	Loss: -1.7249	Cost: 7.96s
Train Epoch: 118 [40960/90000 (45%)]	Loss: -1.8944	Cost: 15.39s
Train Epoch: 118 [61440/90000 (68%)]	Loss: -1.5994	Cost: 11.04s
Train Epoch: 118 [81920/90000 (91%)]	Loss: -1.7354	Cost: 11.79s
Train Epoch: 118 	Average Loss: -1.4864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1996

Saving model as e118_model.pt & e118_waveforms_supplementary.hdf5
Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: -0.6031	Cost: 26.21s
Train Epoch: 119 [20480/90000 (23%)]	Loss: -2.0144	Cost: 8.19s
Train Epoch: 119 [40960/90000 (45%)]	Loss: -1.4312	Cost: 11.90s
Train Epoch: 119 [61440/90000 (68%)]	Loss: -1.7976	Cost: 10.08s
Train Epoch: 119 [81920/90000 (91%)]	Loss: -1.7670	Cost: 16.01s
Train Epoch: 119 	Average Loss: -1.4926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4352

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 0.1206	Cost: 23.21s
Train Epoch: 120 [20480/90000 (23%)]	Loss: -1.6286	Cost: 6.01s
Train Epoch: 120 [40960/90000 (45%)]	Loss: -1.7344	Cost: 10.70s
Train Epoch: 120 [61440/90000 (68%)]	Loss: -1.6650	Cost: 7.25s
Train Epoch: 120 [81920/90000 (91%)]	Loss: -1.5679	Cost: 10.18s
Train Epoch: 120 	Average Loss: -1.4443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4843

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: -0.2655	Cost: 25.75s
Train Epoch: 121 [20480/90000 (23%)]	Loss: -1.9116	Cost: 6.35s
Train Epoch: 121 [40960/90000 (45%)]	Loss: -1.8551	Cost: 10.80s
Train Epoch: 121 [61440/90000 (68%)]	Loss: -1.6530	Cost: 8.93s
Train Epoch: 121 [81920/90000 (91%)]	Loss: -1.8351	Cost: 9.94s
Train Epoch: 121 	Average Loss: -1.4794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6614

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: -0.2979	Cost: 24.49s
Train Epoch: 122 [20480/90000 (23%)]	Loss: -2.1071	Cost: 11.60s
Train Epoch: 122 [40960/90000 (45%)]	Loss: -2.0317	Cost: 7.54s
Train Epoch: 122 [61440/90000 (68%)]	Loss: -1.5117	Cost: 6.00s
Train Epoch: 122 [81920/90000 (91%)]	Loss: -1.9111	Cost: 5.67s
Train Epoch: 122 	Average Loss: -1.4990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6325

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: -0.4605	Cost: 26.36s
Train Epoch: 123 [20480/90000 (23%)]	Loss: -2.2407	Cost: 13.44s
Train Epoch: 123 [40960/90000 (45%)]	Loss: -1.9937	Cost: 14.68s
Train Epoch: 123 [61440/90000 (68%)]	Loss: -1.5840	Cost: 11.74s
Train Epoch: 123 [81920/90000 (91%)]	Loss: -1.6669	Cost: 5.61s
Train Epoch: 123 	Average Loss: -1.5763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2715

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: -0.0630	Cost: 25.75s
Train Epoch: 124 [20480/90000 (23%)]	Loss: -1.8750	Cost: 6.35s
Train Epoch: 124 [40960/90000 (45%)]	Loss: -1.9374	Cost: 13.32s
Train Epoch: 124 [61440/90000 (68%)]	Loss: -1.3859	Cost: 14.75s
Train Epoch: 124 [81920/90000 (91%)]	Loss: -1.8460	Cost: 14.02s
Train Epoch: 124 	Average Loss: -1.5905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2757

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: -0.1297	Cost: 25.03s
Train Epoch: 125 [20480/90000 (23%)]	Loss: -2.0320	Cost: 6.19s
Train Epoch: 125 [40960/90000 (45%)]	Loss: -1.8506	Cost: 10.10s
Train Epoch: 125 [61440/90000 (68%)]	Loss: -1.6805	Cost: 6.18s
Train Epoch: 125 [81920/90000 (91%)]	Loss: -1.8554	Cost: 18.17s
Train Epoch: 125 	Average Loss: -1.6073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3051

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: -0.5959	Cost: 24.85s
Train Epoch: 126 [20480/90000 (23%)]	Loss: -1.9106	Cost: 6.09s
Train Epoch: 126 [40960/90000 (45%)]	Loss: -2.0152	Cost: 10.13s
Train Epoch: 126 [61440/90000 (68%)]	Loss: -1.5541	Cost: 6.09s
Train Epoch: 126 [81920/90000 (91%)]	Loss: -2.2088	Cost: 11.72s
Train Epoch: 126 	Average Loss: -1.6452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2701

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: -0.6363	Cost: 25.53s
Train Epoch: 127 [20480/90000 (23%)]	Loss: -2.2382	Cost: 8.06s
Train Epoch: 127 [40960/90000 (45%)]	Loss: -2.0258	Cost: 9.20s
Train Epoch: 127 [61440/90000 (68%)]	Loss: -1.6875	Cost: 8.80s
Train Epoch: 127 [81920/90000 (91%)]	Loss: -1.9195	Cost: 8.41s
Train Epoch: 127 	Average Loss: -1.7321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2101

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: -0.4203	Cost: 25.75s
Train Epoch: 128 [20480/90000 (23%)]	Loss: -1.9488	Cost: 10.55s
Train Epoch: 128 [40960/90000 (45%)]	Loss: -1.9737	Cost: 7.98s
Train Epoch: 128 [61440/90000 (68%)]	Loss: -1.7490	Cost: 6.19s
Train Epoch: 128 [81920/90000 (91%)]	Loss: -2.2777	Cost: 6.86s
Train Epoch: 128 	Average Loss: -1.6717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1554

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: -0.1683	Cost: 26.84s
Train Epoch: 129 [20480/90000 (23%)]	Loss: -2.0808	Cost: 14.52s
Train Epoch: 129 [40960/90000 (45%)]	Loss: -1.9023	Cost: 13.00s
Train Epoch: 129 [61440/90000 (68%)]	Loss: -1.8944	Cost: 6.01s
Train Epoch: 129 [81920/90000 (91%)]	Loss: -2.0684	Cost: 11.89s
Train Epoch: 129 	Average Loss: -1.6855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0727

Saving model as e129_model.pt & e129_waveforms_supplementary.hdf5
Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: -0.8076	Cost: 24.60s
Train Epoch: 130 [20480/90000 (23%)]	Loss: -2.1360	Cost: 6.50s
Train Epoch: 130 [40960/90000 (45%)]	Loss: -1.9247	Cost: 11.07s
Train Epoch: 130 [61440/90000 (68%)]	Loss: -1.7622	Cost: 13.33s
Train Epoch: 130 [81920/90000 (91%)]	Loss: -2.0150	Cost: 14.99s
Train Epoch: 130 	Average Loss: -1.7065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0541

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: -0.2821	Cost: 24.01s
Train Epoch: 131 [20480/90000 (23%)]	Loss: -2.2605	Cost: 6.31s
Train Epoch: 131 [40960/90000 (45%)]	Loss: -2.0685	Cost: 9.80s
Train Epoch: 131 [61440/90000 (68%)]	Loss: -1.8109	Cost: 6.74s
Train Epoch: 131 [81920/90000 (91%)]	Loss: -2.2518	Cost: 11.88s
Train Epoch: 131 	Average Loss: -1.8249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0688

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: -0.6625	Cost: 23.49s
Train Epoch: 132 [20480/90000 (23%)]	Loss: -2.1705	Cost: 8.57s
Train Epoch: 132 [40960/90000 (45%)]	Loss: -2.1044	Cost: 8.81s
Train Epoch: 132 [61440/90000 (68%)]	Loss: -1.6169	Cost: 8.45s
Train Epoch: 132 [81920/90000 (91%)]	Loss: -2.2131	Cost: 8.47s
Train Epoch: 132 	Average Loss: -1.8888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0068

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: -0.7924	Cost: 23.79s
Train Epoch: 133 [20480/90000 (23%)]	Loss: -2.2092	Cost: 12.10s
Train Epoch: 133 [40960/90000 (45%)]	Loss: -2.1248	Cost: 6.16s
Train Epoch: 133 [61440/90000 (68%)]	Loss: -1.7890	Cost: 6.18s
Train Epoch: 133 [81920/90000 (91%)]	Loss: -2.1709	Cost: 5.83s
Train Epoch: 133 	Average Loss: -1.9096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0132

Saving model as e133_model.pt & e133_waveforms_supplementary.hdf5
Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: -0.4623	Cost: 27.05s
Train Epoch: 134 [20480/90000 (23%)]	Loss: -2.3004	Cost: 15.13s
Train Epoch: 134 [40960/90000 (45%)]	Loss: -2.2783	Cost: 11.42s
Train Epoch: 134 [61440/90000 (68%)]	Loss: -1.9935	Cost: 10.60s
Train Epoch: 134 [81920/90000 (91%)]	Loss: -1.9542	Cost: 5.74s
Train Epoch: 134 	Average Loss: -1.9474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0175

Saving model as e134_model.pt & e134_waveforms_supplementary.hdf5
Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: -0.8087	Cost: 26.36s
Train Epoch: 135 [20480/90000 (23%)]	Loss: -2.3716	Cost: 6.19s
Train Epoch: 135 [40960/90000 (45%)]	Loss: -2.0744	Cost: 13.90s
Train Epoch: 135 [61440/90000 (68%)]	Loss: -1.8908	Cost: 14.77s
Train Epoch: 135 [81920/90000 (91%)]	Loss: -2.2471	Cost: 11.83s
Train Epoch: 135 	Average Loss: -1.9695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1305

Saving model as e135_model.pt & e135_waveforms_supplementary.hdf5
Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: -0.2148	Cost: 23.60s
Train Epoch: 136 [20480/90000 (23%)]	Loss: -2.1984	Cost: 6.51s
Train Epoch: 136 [40960/90000 (45%)]	Loss: -2.2957	Cost: 9.98s
Train Epoch: 136 [61440/90000 (68%)]	Loss: -2.1617	Cost: 6.00s
Train Epoch: 136 [81920/90000 (91%)]	Loss: -2.2641	Cost: 13.05s
Train Epoch: 136 	Average Loss: -1.9948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0089

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: -0.8500	Cost: 24.67s
Train Epoch: 137 [20480/90000 (23%)]	Loss: -2.2280	Cost: 8.69s
Train Epoch: 137 [40960/90000 (45%)]	Loss: -1.8700	Cost: 8.84s
Train Epoch: 137 [61440/90000 (68%)]	Loss: -1.8759	Cost: 8.69s
Train Epoch: 137 [81920/90000 (91%)]	Loss: -2.1554	Cost: 8.37s
Train Epoch: 137 	Average Loss: -1.9417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0310

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: -0.4626	Cost: 27.20s
Train Epoch: 138 [20480/90000 (23%)]	Loss: -2.0868	Cost: 6.38s
Train Epoch: 138 [40960/90000 (45%)]	Loss: -2.5209	Cost: 12.39s
Train Epoch: 138 [61440/90000 (68%)]	Loss: -1.9178	Cost: 5.95s
Train Epoch: 138 [81920/90000 (91%)]	Loss: -2.4850	Cost: 10.39s
Train Epoch: 138 	Average Loss: -2.0019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0730

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: -0.8320	Cost: 35.93s
Train Epoch: 139 [20480/90000 (23%)]	Loss: -2.0890	Cost: 13.30s
Train Epoch: 139 [40960/90000 (45%)]	Loss: -2.2792	Cost: 14.94s
Train Epoch: 139 [61440/90000 (68%)]	Loss: -2.1094	Cost: 7.93s
Train Epoch: 139 [81920/90000 (91%)]	Loss: -2.0608	Cost: 9.74s
Train Epoch: 139 	Average Loss: -2.0528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0238

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: -0.4983	Cost: 32.66s
Train Epoch: 140 [20480/90000 (23%)]	Loss: -2.4655	Cost: 8.70s
Train Epoch: 140 [40960/90000 (45%)]	Loss: -2.3282	Cost: 9.92s
Train Epoch: 140 [61440/90000 (68%)]	Loss: -2.2459	Cost: 6.17s
Train Epoch: 140 [81920/90000 (91%)]	Loss: -2.5331	Cost: 19.47s
Train Epoch: 140 	Average Loss: -2.0698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0127

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: -0.9111	Cost: 23.55s
Train Epoch: 141 [20480/90000 (23%)]	Loss: -2.4493	Cost: 6.84s
Train Epoch: 141 [40960/90000 (45%)]	Loss: -2.3747	Cost: 13.23s
Train Epoch: 141 [61440/90000 (68%)]	Loss: -2.0494	Cost: 6.57s
Train Epoch: 141 [81920/90000 (91%)]	Loss: -2.4010	Cost: 12.48s
Train Epoch: 141 	Average Loss: -2.0858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2781

Saving model as e141_model.pt & e141_waveforms_supplementary.hdf5
Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: -0.4636	Cost: 25.17s
Train Epoch: 142 [20480/90000 (23%)]	Loss: -2.2367	Cost: 7.55s
Train Epoch: 142 [40960/90000 (45%)]	Loss: -2.5544	Cost: 9.16s
Train Epoch: 142 [61440/90000 (68%)]	Loss: -2.0474	Cost: 8.82s
Train Epoch: 142 [81920/90000 (91%)]	Loss: -2.3981	Cost: 10.58s
Train Epoch: 142 	Average Loss: -2.1100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2844

Saving model as e142_model.pt & e142_waveforms_supplementary.hdf5
Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: -1.0362	Cost: 26.91s
Train Epoch: 143 [20480/90000 (23%)]	Loss: -2.6562	Cost: 7.86s
Train Epoch: 143 [40960/90000 (45%)]	Loss: -2.2228	Cost: 9.23s
Train Epoch: 143 [61440/90000 (68%)]	Loss: -2.1573	Cost: 5.90s
Train Epoch: 143 [81920/90000 (91%)]	Loss: -2.6570	Cost: 9.99s
Train Epoch: 143 	Average Loss: -2.2027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1800

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: -0.6118	Cost: 25.83s
Train Epoch: 144 [20480/90000 (23%)]	Loss: -2.8345	Cost: 10.86s
Train Epoch: 144 [40960/90000 (45%)]	Loss: -2.4471	Cost: 6.28s
Train Epoch: 144 [61440/90000 (68%)]	Loss: -2.3995	Cost: 12.02s
Train Epoch: 144 [81920/90000 (91%)]	Loss: -2.4699	Cost: 5.76s
Train Epoch: 144 	Average Loss: -2.2327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1216

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: -0.6608	Cost: 25.06s
Train Epoch: 145 [20480/90000 (23%)]	Loss: -2.4840	Cost: 6.16s
Train Epoch: 145 [40960/90000 (45%)]	Loss: -2.6232	Cost: 9.58s
Train Epoch: 145 [61440/90000 (68%)]	Loss: -2.3170	Cost: 9.34s
Train Epoch: 145 [81920/90000 (91%)]	Loss: -2.1272	Cost: 15.30s
Train Epoch: 145 	Average Loss: -2.2371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0550

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: -0.6295	Cost: 24.28s
Train Epoch: 146 [20480/90000 (23%)]	Loss: -2.6928	Cost: 6.54s
Train Epoch: 146 [40960/90000 (45%)]	Loss: -2.6089	Cost: 8.79s
Train Epoch: 146 [61440/90000 (68%)]	Loss: -2.1320	Cost: 6.25s
Train Epoch: 146 [81920/90000 (91%)]	Loss: -2.4879	Cost: 10.83s
Train Epoch: 146 	Average Loss: -2.2203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1846

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: -0.8859	Cost: 25.70s
Train Epoch: 147 [20480/90000 (23%)]	Loss: -2.6425	Cost: 6.27s
Train Epoch: 147 [40960/90000 (45%)]	Loss: -2.6689	Cost: 10.00s
Train Epoch: 147 [61440/90000 (68%)]	Loss: -1.9428	Cost: 8.57s
Train Epoch: 147 [81920/90000 (91%)]	Loss: -2.6826	Cost: 8.26s
Train Epoch: 147 	Average Loss: -2.2491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2038

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: -0.6206	Cost: 25.66s
Train Epoch: 148 [20480/90000 (23%)]	Loss: -2.6483	Cost: 10.26s
Train Epoch: 148 [40960/90000 (45%)]	Loss: -2.9041	Cost: 8.13s
Train Epoch: 148 [61440/90000 (68%)]	Loss: -2.2523	Cost: 6.09s
Train Epoch: 148 [81920/90000 (91%)]	Loss: -2.4914	Cost: 7.32s
Train Epoch: 148 	Average Loss: -2.2599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1174

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: -1.0140	Cost: 25.35s
Train Epoch: 149 [20480/90000 (23%)]	Loss: -2.6235	Cost: 6.31s
Train Epoch: 149 [40960/90000 (45%)]	Loss: -2.6011	Cost: 14.15s
Train Epoch: 149 [61440/90000 (68%)]	Loss: -2.2301	Cost: 14.78s
Train Epoch: 149 [81920/90000 (91%)]	Loss: -2.3315	Cost: 5.99s
Train Epoch: 149 	Average Loss: -2.2687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1969

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: -0.7778	Cost: 23.48s
Train Epoch: 150 [20480/90000 (23%)]	Loss: -2.5241	Cost: 6.33s
Train Epoch: 150 [40960/90000 (45%)]	Loss: -2.3164	Cost: 9.75s
Train Epoch: 150 [61440/90000 (68%)]	Loss: -2.3447	Cost: 6.19s
Train Epoch: 150 [81920/90000 (91%)]	Loss: -2.4415	Cost: 10.49s
Train Epoch: 150 	Average Loss: -2.2539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3527

Saving model as e150_model.pt & e150_waveforms_supplementary.hdf5
Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: -0.9649	Cost: 25.67s
Train Epoch: 151 [20480/90000 (23%)]	Loss: -2.6177	Cost: 8.66s
Train Epoch: 151 [40960/90000 (45%)]	Loss: -2.6170	Cost: 8.66s
Train Epoch: 151 [61440/90000 (68%)]	Loss: -2.1739	Cost: 8.42s
Train Epoch: 151 [81920/90000 (91%)]	Loss: -2.4765	Cost: 8.35s
Train Epoch: 151 	Average Loss: -2.3058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3922

Saving model as e151_model.pt & e151_waveforms_supplementary.hdf5
Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: -0.7111	Cost: 25.28s
Train Epoch: 152 [20480/90000 (23%)]	Loss: -2.9349	Cost: 12.10s
Train Epoch: 152 [40960/90000 (45%)]	Loss: -2.6418	Cost: 6.23s
Train Epoch: 152 [61440/90000 (68%)]	Loss: -2.6235	Cost: 6.04s
Train Epoch: 152 [81920/90000 (91%)]	Loss: -2.5883	Cost: 5.80s
Train Epoch: 152 	Average Loss: -2.3466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4591

Saving model as e152_model.pt & e152_waveforms_supplementary.hdf5
Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: -0.8784	Cost: 27.84s
Train Epoch: 153 [20480/90000 (23%)]	Loss: -2.8960	Cost: 13.61s
Train Epoch: 153 [40960/90000 (45%)]	Loss: -2.7303	Cost: 14.78s
Train Epoch: 153 [61440/90000 (68%)]	Loss: -2.4589	Cost: 11.79s
Train Epoch: 153 [81920/90000 (91%)]	Loss: -2.6720	Cost: 5.72s
Train Epoch: 153 	Average Loss: -2.4342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4175

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: -0.8444	Cost: 26.60s
Train Epoch: 154 [20480/90000 (23%)]	Loss: -2.7435	Cost: 6.18s
Train Epoch: 154 [40960/90000 (45%)]	Loss: -2.7789	Cost: 9.38s
Train Epoch: 154 [61440/90000 (68%)]	Loss: -2.3383	Cost: 15.11s
Train Epoch: 154 [81920/90000 (91%)]	Loss: -2.5714	Cost: 12.75s
Train Epoch: 154 	Average Loss: -2.3754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3903

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: -0.8311	Cost: 24.66s
Train Epoch: 155 [20480/90000 (23%)]	Loss: -2.7479	Cost: 6.14s
Train Epoch: 155 [40960/90000 (45%)]	Loss: -2.8502	Cost: 10.16s
Train Epoch: 155 [61440/90000 (68%)]	Loss: -2.2901	Cost: 6.16s
Train Epoch: 155 [81920/90000 (91%)]	Loss: -2.7917	Cost: 11.12s
Train Epoch: 155 	Average Loss: -2.5469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3854

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: -1.1102	Cost: 28.51s
Train Epoch: 156 [20480/90000 (23%)]	Loss: -2.9895	Cost: 6.09s
Train Epoch: 156 [40960/90000 (45%)]	Loss: -2.6138	Cost: 11.14s
Train Epoch: 156 [61440/90000 (68%)]	Loss: -2.5387	Cost: 8.43s
Train Epoch: 156 [81920/90000 (91%)]	Loss: -2.9043	Cost: 8.41s
Train Epoch: 156 	Average Loss: -2.5971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4195

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: -1.0667	Cost: 25.10s
Train Epoch: 157 [20480/90000 (23%)]	Loss: -2.9350	Cost: 12.47s
Train Epoch: 157 [40960/90000 (45%)]	Loss: -3.1434	Cost: 6.17s
Train Epoch: 157 [61440/90000 (68%)]	Loss: -2.7443	Cost: 6.04s
Train Epoch: 157 [81920/90000 (91%)]	Loss: -2.8818	Cost: 9.39s
Train Epoch: 157 	Average Loss: -2.6027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5244

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: -0.8176	Cost: 28.65s
Train Epoch: 158 [20480/90000 (23%)]	Loss: -2.9328	Cost: 15.25s
Train Epoch: 158 [40960/90000 (45%)]	Loss: -3.0660	Cost: 9.86s
Train Epoch: 158 [61440/90000 (68%)]	Loss: -2.7432	Cost: 12.05s
Train Epoch: 158 [81920/90000 (91%)]	Loss: -2.9367	Cost: 6.00s
Train Epoch: 158 	Average Loss: -2.6181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4516

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: -1.1106	Cost: 24.39s
Train Epoch: 159 [20480/90000 (23%)]	Loss: -2.9589	Cost: 6.28s
Train Epoch: 159 [40960/90000 (45%)]	Loss: -2.9437	Cost: 9.53s
Train Epoch: 159 [61440/90000 (68%)]	Loss: -2.7403	Cost: 14.36s
Train Epoch: 159 [81920/90000 (91%)]	Loss: -2.6702	Cost: 14.00s
Train Epoch: 159 	Average Loss: -2.6246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3617

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: -0.9180	Cost: 25.52s
Train Epoch: 160 [20480/90000 (23%)]	Loss: -3.2458	Cost: 6.12s
Train Epoch: 160 [40960/90000 (45%)]	Loss: -2.9731	Cost: 10.28s
Train Epoch: 160 [61440/90000 (68%)]	Loss: -2.6342	Cost: 6.22s
Train Epoch: 160 [81920/90000 (91%)]	Loss: -2.7691	Cost: 11.32s
Train Epoch: 160 	Average Loss: -2.6066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1892

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: -0.9343	Cost: 25.04s
Train Epoch: 161 [20480/90000 (23%)]	Loss: -3.2888	Cost: 8.72s
Train Epoch: 161 [40960/90000 (45%)]	Loss: -2.8172	Cost: 9.62s
Train Epoch: 161 [61440/90000 (68%)]	Loss: -2.1176	Cost: 8.52s
Train Epoch: 161 [81920/90000 (91%)]	Loss: -2.7847	Cost: 8.16s
Train Epoch: 161 	Average Loss: -2.4706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1658

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: -0.8658	Cost: 27.02s
Train Epoch: 162 [20480/90000 (23%)]	Loss: -2.8066	Cost: 12.13s
Train Epoch: 162 [40960/90000 (45%)]	Loss: -3.0810	Cost: 6.19s
Train Epoch: 162 [61440/90000 (68%)]	Loss: -2.1792	Cost: 6.08s
Train Epoch: 162 [81920/90000 (91%)]	Loss: -3.1753	Cost: 6.03s
Train Epoch: 162 	Average Loss: -2.5397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5520

Saving model as e162_model.pt & e162_waveforms_supplementary.hdf5
Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: -0.6965	Cost: 30.70s
Train Epoch: 163 [20480/90000 (23%)]	Loss: -2.8459	Cost: 14.87s
Train Epoch: 163 [40960/90000 (45%)]	Loss: -3.0908	Cost: 14.76s
Train Epoch: 163 [61440/90000 (68%)]	Loss: -2.6708	Cost: 7.88s
Train Epoch: 163 [81920/90000 (91%)]	Loss: -3.1164	Cost: 5.95s
Train Epoch: 163 	Average Loss: -2.6875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5257

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: -1.2122	Cost: 27.83s
Train Epoch: 164 [20480/90000 (23%)]	Loss: -3.2260	Cost: 6.21s
Train Epoch: 164 [40960/90000 (45%)]	Loss: -3.2896	Cost: 9.07s
Train Epoch: 164 [61440/90000 (68%)]	Loss: -2.6907	Cost: 9.13s
Train Epoch: 164 [81920/90000 (91%)]	Loss: -3.0123	Cost: 15.44s
Train Epoch: 164 	Average Loss: -2.7580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5571

Saving model as e164_model.pt & e164_waveforms_supplementary.hdf5
Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: -0.6748	Cost: 27.70s
Train Epoch: 165 [20480/90000 (23%)]	Loss: -3.1044	Cost: 6.14s
Train Epoch: 165 [40960/90000 (45%)]	Loss: -2.6465	Cost: 10.46s
Train Epoch: 165 [61440/90000 (68%)]	Loss: -2.5990	Cost: 6.15s
Train Epoch: 165 [81920/90000 (91%)]	Loss: -2.9796	Cost: 11.43s
Train Epoch: 165 	Average Loss: -2.7212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5855

Saving model as e165_model.pt & e165_waveforms_supplementary.hdf5
Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: -1.2056	Cost: 28.98s
Train Epoch: 166 [20480/90000 (23%)]	Loss: -3.0679	Cost: 8.22s
Train Epoch: 166 [40960/90000 (45%)]	Loss: -3.2467	Cost: 8.81s
Train Epoch: 166 [61440/90000 (68%)]	Loss: -2.5830	Cost: 8.45s
Train Epoch: 166 [81920/90000 (91%)]	Loss: -3.1269	Cost: 8.30s
Train Epoch: 166 	Average Loss: -2.8224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4228

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: -1.0012	Cost: 24.74s
Train Epoch: 167 [20480/90000 (23%)]	Loss: -3.3072	Cost: 11.71s
Train Epoch: 167 [40960/90000 (45%)]	Loss: -2.8256	Cost: 6.69s
Train Epoch: 167 [61440/90000 (68%)]	Loss: -2.6655	Cost: 6.13s
Train Epoch: 167 [81920/90000 (91%)]	Loss: -2.7784	Cost: 9.64s
Train Epoch: 167 	Average Loss: -2.7594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4632

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: -1.1725	Cost: 25.15s
Train Epoch: 168 [20480/90000 (23%)]	Loss: -2.9674	Cost: 12.23s
Train Epoch: 168 [40960/90000 (45%)]	Loss: -2.9873	Cost: 14.83s
Train Epoch: 168 [61440/90000 (68%)]	Loss: -2.7602	Cost: 7.63s
Train Epoch: 168 [81920/90000 (91%)]	Loss: -3.2709	Cost: 11.97s
Train Epoch: 168 	Average Loss: -2.8412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6314

Saving model as e168_model.pt & e168_waveforms_supplementary.hdf5
Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: -1.0620	Cost: 23.91s
Train Epoch: 169 [20480/90000 (23%)]	Loss: -3.3712	Cost: 6.32s
Train Epoch: 169 [40960/90000 (45%)]	Loss: -3.1026	Cost: 9.31s
Train Epoch: 169 [61440/90000 (68%)]	Loss: -3.0531	Cost: 6.63s
Train Epoch: 169 [81920/90000 (91%)]	Loss: -3.3015	Cost: 17.63s
Train Epoch: 169 	Average Loss: -2.9555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5732

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: -1.3239	Cost: 24.89s
Train Epoch: 170 [20480/90000 (23%)]	Loss: -3.4320	Cost: 8.80s
Train Epoch: 170 [40960/90000 (45%)]	Loss: -2.8351	Cost: 8.74s
Train Epoch: 170 [61440/90000 (68%)]	Loss: -2.7369	Cost: 6.95s
Train Epoch: 170 [81920/90000 (91%)]	Loss: -3.3604	Cost: 5.88s
Train Epoch: 170 	Average Loss: -2.9428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6607

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: -1.7568	Cost: 26.33s
Train Epoch: 171 [20480/90000 (23%)]	Loss: -3.4370	Cost: 6.23s
Train Epoch: 171 [40960/90000 (45%)]	Loss: -3.3717	Cost: 9.14s
Train Epoch: 171 [61440/90000 (68%)]	Loss: -2.9213	Cost: 8.28s
Train Epoch: 171 [81920/90000 (91%)]	Loss: -3.0639	Cost: 8.44s
Train Epoch: 171 	Average Loss: -2.9802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5451

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: -1.0466	Cost: 26.20s
Train Epoch: 172 [20480/90000 (23%)]	Loss: -3.4497	Cost: 6.17s
Train Epoch: 172 [40960/90000 (45%)]	Loss: -3.1258	Cost: 13.94s
Train Epoch: 172 [61440/90000 (68%)]	Loss: -2.6171	Cost: 6.07s
Train Epoch: 172 [81920/90000 (91%)]	Loss: -3.0573	Cost: 5.83s
Train Epoch: 172 	Average Loss: -2.8848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5427

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: -1.3327	Cost: 26.72s
Train Epoch: 173 [20480/90000 (23%)]	Loss: -3.5917	Cost: 6.31s
Train Epoch: 173 [40960/90000 (45%)]	Loss: -3.0013	Cost: 14.06s
Train Epoch: 173 [61440/90000 (68%)]	Loss: -2.7388	Cost: 13.93s
Train Epoch: 173 [81920/90000 (91%)]	Loss: -3.2042	Cost: 11.81s
Train Epoch: 173 	Average Loss: -2.8940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4359

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: -1.3282	Cost: 25.45s
Train Epoch: 174 [20480/90000 (23%)]	Loss: -3.3015	Cost: 6.22s
Train Epoch: 174 [40960/90000 (45%)]	Loss: -3.3481	Cost: 9.55s
Train Epoch: 174 [61440/90000 (68%)]	Loss: -2.8468	Cost: 6.00s
Train Epoch: 174 [81920/90000 (91%)]	Loss: -2.9267	Cost: 19.87s
Train Epoch: 174 	Average Loss: -2.9332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4325

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: -1.3738	Cost: 26.89s
Train Epoch: 175 [20480/90000 (23%)]	Loss: -3.2450	Cost: 8.46s
Train Epoch: 175 [40960/90000 (45%)]	Loss: -3.1275	Cost: 7.18s
Train Epoch: 175 [61440/90000 (68%)]	Loss: -3.0998	Cost: 6.18s
Train Epoch: 175 [81920/90000 (91%)]	Loss: -3.2776	Cost: 11.56s
Train Epoch: 175 	Average Loss: -2.9478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6626

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: -1.2775	Cost: 28.78s
Train Epoch: 176 [20480/90000 (23%)]	Loss: -3.5440	Cost: 7.10s
Train Epoch: 176 [40960/90000 (45%)]	Loss: -3.2724	Cost: 10.84s
Train Epoch: 176 [61440/90000 (68%)]	Loss: -2.7796	Cost: 8.40s
Train Epoch: 176 [81920/90000 (91%)]	Loss: -3.3147	Cost: 8.40s
Train Epoch: 176 	Average Loss: -3.0473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7271

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: -1.6245	Cost: 27.19s
Train Epoch: 177 [20480/90000 (23%)]	Loss: -3.3769	Cost: 11.39s
Train Epoch: 177 [40960/90000 (45%)]	Loss: -3.2304	Cost: 7.55s
Train Epoch: 177 [61440/90000 (68%)]	Loss: -3.0716	Cost: 6.18s
Train Epoch: 177 [81920/90000 (91%)]	Loss: -3.3348	Cost: 5.82s
Train Epoch: 177 	Average Loss: -3.1038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5128

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: -1.5082	Cost: 28.79s
Train Epoch: 178 [20480/90000 (23%)]	Loss: -3.3335	Cost: 12.58s
Train Epoch: 178 [40960/90000 (45%)]	Loss: -3.2470	Cost: 15.13s
Train Epoch: 178 [61440/90000 (68%)]	Loss: -2.9346	Cost: 9.35s
Train Epoch: 178 [81920/90000 (91%)]	Loss: -3.6159	Cost: 9.38s
Train Epoch: 178 	Average Loss: -2.9934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5169

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: -1.0806	Cost: 30.48s
Train Epoch: 179 [20480/90000 (23%)]	Loss: -3.3113	Cost: 8.60s
Train Epoch: 179 [40960/90000 (45%)]	Loss: -3.4109	Cost: 10.56s
Train Epoch: 179 [61440/90000 (68%)]	Loss: -3.0105	Cost: 6.10s
Train Epoch: 179 [81920/90000 (91%)]	Loss: -3.2728	Cost: 17.08s
Train Epoch: 179 	Average Loss: -2.9730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5737

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: -1.5493	Cost: 24.16s
Train Epoch: 180 [20480/90000 (23%)]	Loss: -3.3174	Cost: 8.83s
Train Epoch: 180 [40960/90000 (45%)]	Loss: -3.4443	Cost: 8.78s
Train Epoch: 180 [61440/90000 (68%)]	Loss: -2.9261	Cost: 8.97s
Train Epoch: 180 [81920/90000 (91%)]	Loss: -3.5817	Cost: 8.20s
Train Epoch: 180 	Average Loss: -3.1026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6011

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: -1.4558	Cost: 26.01s
Train Epoch: 181 [20480/90000 (23%)]	Loss: -3.7451	Cost: 9.58s
Train Epoch: 181 [40960/90000 (45%)]	Loss: -3.6303	Cost: 7.11s
Train Epoch: 181 [61440/90000 (68%)]	Loss: -3.1687	Cost: 6.36s
Train Epoch: 181 [81920/90000 (91%)]	Loss: -3.2087	Cost: 9.94s
Train Epoch: 181 	Average Loss: -3.1586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6381

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: -1.2167	Cost: 26.70s
Train Epoch: 182 [20480/90000 (23%)]	Loss: -3.5404	Cost: 10.51s
Train Epoch: 182 [40960/90000 (45%)]	Loss: -3.4127	Cost: 6.63s
Train Epoch: 182 [61440/90000 (68%)]	Loss: -3.3638	Cost: 11.78s
Train Epoch: 182 [81920/90000 (91%)]	Loss: -3.6068	Cost: 5.74s
Train Epoch: 182 	Average Loss: -3.1671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6791

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: -1.0824	Cost: 26.80s
Train Epoch: 183 [20480/90000 (23%)]	Loss: -3.7369	Cost: 6.11s
Train Epoch: 183 [40960/90000 (45%)]	Loss: -3.8418	Cost: 12.12s
Train Epoch: 183 [61440/90000 (68%)]	Loss: -3.2549	Cost: 14.88s
Train Epoch: 183 [81920/90000 (91%)]	Loss: -3.3111	Cost: 14.22s
Train Epoch: 183 	Average Loss: -3.2110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6964

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: -0.9485	Cost: 23.73s
Train Epoch: 184 [20480/90000 (23%)]	Loss: -3.3996	Cost: 6.20s
Train Epoch: 184 [40960/90000 (45%)]	Loss: -3.7764	Cost: 10.48s
Train Epoch: 184 [61440/90000 (68%)]	Loss: -3.1437	Cost: 6.07s
Train Epoch: 184 [81920/90000 (91%)]	Loss: -3.2173	Cost: 13.51s
Train Epoch: 184 	Average Loss: -3.0902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8201

Saving model as e184_model.pt & e184_waveforms_supplementary.hdf5
Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: -1.5257	Cost: 27.59s
Train Epoch: 185 [20480/90000 (23%)]	Loss: -3.5324	Cost: 8.83s
Train Epoch: 185 [40960/90000 (45%)]	Loss: -4.1236	Cost: 8.75s
Train Epoch: 185 [61440/90000 (68%)]	Loss: -3.3667	Cost: 8.30s
Train Epoch: 185 [81920/90000 (91%)]	Loss: -3.9019	Cost: 5.93s
Train Epoch: 185 	Average Loss: -3.2876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7864

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: -1.3489	Cost: 24.95s
Train Epoch: 186 [20480/90000 (23%)]	Loss: -3.6861	Cost: 6.51s
Train Epoch: 186 [40960/90000 (45%)]	Loss: -3.7742	Cost: 10.93s
Train Epoch: 186 [61440/90000 (68%)]	Loss: -3.4123	Cost: 6.30s
Train Epoch: 186 [81920/90000 (91%)]	Loss: -3.4431	Cost: 11.41s
Train Epoch: 186 	Average Loss: -3.2952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7107

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: -1.2197	Cost: 32.18s
Train Epoch: 187 [20480/90000 (23%)]	Loss: -3.9947	Cost: 6.06s
Train Epoch: 187 [40960/90000 (45%)]	Loss: -3.8608	Cost: 13.89s
Train Epoch: 187 [61440/90000 (68%)]	Loss: -3.2574	Cost: 5.85s
Train Epoch: 187 [81920/90000 (91%)]	Loss: -3.6172	Cost: 7.10s
Train Epoch: 187 	Average Loss: -3.3300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7205

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: -1.3013	Cost: 47.70s
Train Epoch: 188 [20480/90000 (23%)]	Loss: -3.7335	Cost: 14.30s
Train Epoch: 188 [40960/90000 (45%)]	Loss: -3.9546	Cost: 13.95s
Train Epoch: 188 [61440/90000 (68%)]	Loss: -3.5020	Cost: 11.82s
Train Epoch: 188 [81920/90000 (91%)]	Loss: -3.6617	Cost: 5.87s
Train Epoch: 188 	Average Loss: -3.3765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7404

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: -1.3255	Cost: 27.80s
Train Epoch: 189 [20480/90000 (23%)]	Loss: -3.7088	Cost: 6.68s
Train Epoch: 189 [40960/90000 (45%)]	Loss: -3.9575	Cost: 9.53s
Train Epoch: 189 [61440/90000 (68%)]	Loss: -3.6060	Cost: 6.03s
Train Epoch: 189 [81920/90000 (91%)]	Loss: -3.8752	Cost: 17.80s
Train Epoch: 189 	Average Loss: -3.4124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9393

Saving model as e189_model.pt & e189_waveforms_supplementary.hdf5
Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: -1.6645	Cost: 25.29s
Train Epoch: 190 [20480/90000 (23%)]	Loss: -3.9912	Cost: 6.38s
Train Epoch: 190 [40960/90000 (45%)]	Loss: -3.6983	Cost: 9.49s
Train Epoch: 190 [61440/90000 (68%)]	Loss: -3.2487	Cost: 6.31s
Train Epoch: 190 [81920/90000 (91%)]	Loss: -3.5033	Cost: 11.80s
Train Epoch: 190 	Average Loss: -3.3752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8140

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: -1.5958	Cost: 25.30s
Train Epoch: 191 [20480/90000 (23%)]	Loss: -3.8446	Cost: 6.21s
Train Epoch: 191 [40960/90000 (45%)]	Loss: -3.5555	Cost: 9.87s
Train Epoch: 191 [61440/90000 (68%)]	Loss: -3.5061	Cost: 9.10s
Train Epoch: 191 [81920/90000 (91%)]	Loss: -3.7644	Cost: 11.12s
Train Epoch: 191 	Average Loss: -3.3822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0177

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: -1.6897	Cost: 24.02s
Train Epoch: 192 [20480/90000 (23%)]	Loss: -3.8450	Cost: 11.48s
Train Epoch: 192 [40960/90000 (45%)]	Loss: -4.0199	Cost: 6.73s
Train Epoch: 192 [61440/90000 (68%)]	Loss: -3.6319	Cost: 6.22s
Train Epoch: 192 [81920/90000 (91%)]	Loss: -3.3723	Cost: 6.47s
Train Epoch: 192 	Average Loss: -3.4223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8026

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: -2.1161	Cost: 26.01s
Train Epoch: 193 [20480/90000 (23%)]	Loss: -3.9877	Cost: 6.33s
Train Epoch: 193 [40960/90000 (45%)]	Loss: -3.6879	Cost: 16.13s
Train Epoch: 193 [61440/90000 (68%)]	Loss: -3.5343	Cost: 14.42s
Train Epoch: 193 [81920/90000 (91%)]	Loss: -3.7350	Cost: 9.58s
Train Epoch: 193 	Average Loss: -3.4992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0387

Saving model as e193_model.pt & e193_waveforms_supplementary.hdf5
Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: -1.5599	Cost: 23.88s
Train Epoch: 194 [20480/90000 (23%)]	Loss: -4.2364	Cost: 6.11s
Train Epoch: 194 [40960/90000 (45%)]	Loss: -3.9819	Cost: 9.93s
Train Epoch: 194 [61440/90000 (68%)]	Loss: -3.8087	Cost: 6.08s
Train Epoch: 194 [81920/90000 (91%)]	Loss: -3.7291	Cost: 17.74s
Train Epoch: 194 	Average Loss: -3.5459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9495

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: -1.4520	Cost: 23.69s
Train Epoch: 195 [20480/90000 (23%)]	Loss: -4.0886	Cost: 6.06s
Train Epoch: 195 [40960/90000 (45%)]	Loss: -4.0857	Cost: 9.49s
Train Epoch: 195 [61440/90000 (68%)]	Loss: -3.6209	Cost: 6.20s
Train Epoch: 195 [81920/90000 (91%)]	Loss: -3.5500	Cost: 11.24s
Train Epoch: 195 	Average Loss: -3.5571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0011

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: -1.2406	Cost: 28.06s
Train Epoch: 196 [20480/90000 (23%)]	Loss: -3.9738	Cost: 6.29s
Train Epoch: 196 [40960/90000 (45%)]	Loss: -3.9986	Cost: 11.95s
Train Epoch: 196 [61440/90000 (68%)]	Loss: -3.6521	Cost: 8.46s
Train Epoch: 196 [81920/90000 (91%)]	Loss: -3.8324	Cost: 8.28s
Train Epoch: 196 	Average Loss: -3.5526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9926

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: -1.4132	Cost: 26.52s
Train Epoch: 197 [20480/90000 (23%)]	Loss: -4.1202	Cost: 8.23s
Train Epoch: 197 [40960/90000 (45%)]	Loss: -4.2359	Cost: 10.08s
Train Epoch: 197 [61440/90000 (68%)]	Loss: -3.9964	Cost: 5.96s
Train Epoch: 197 [81920/90000 (91%)]	Loss: -3.7590	Cost: 5.70s
Train Epoch: 197 	Average Loss: -3.6173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8789

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: -1.7981	Cost: 41.57s
Train Epoch: 198 [20480/90000 (23%)]	Loss: -3.8575	Cost: 6.14s
Train Epoch: 198 [40960/90000 (45%)]	Loss: -3.8865	Cost: 15.09s
Train Epoch: 198 [61440/90000 (68%)]	Loss: -3.2021	Cost: 12.80s
Train Epoch: 198 [81920/90000 (91%)]	Loss: -3.8457	Cost: 11.86s
Train Epoch: 198 	Average Loss: -3.4933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9972

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: -1.5320	Cost: 32.70s
Train Epoch: 199 [20480/90000 (23%)]	Loss: -4.1517	Cost: 8.85s
Train Epoch: 199 [40960/90000 (45%)]	Loss: -3.9981	Cost: 11.46s
Train Epoch: 199 [61440/90000 (68%)]	Loss: -3.6675	Cost: 6.13s
Train Epoch: 199 [81920/90000 (91%)]	Loss: -4.2603	Cost: 19.83s
Train Epoch: 199 	Average Loss: -3.6215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1493

Saving model as e199_model.pt & e199_waveforms_supplementary.hdf5
Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: -1.5675	Cost: 23.73s
Train Epoch: 200 [20480/90000 (23%)]	Loss: -4.1797	Cost: 8.04s
Train Epoch: 200 [40960/90000 (45%)]	Loss: -4.1822	Cost: 11.03s
Train Epoch: 200 [61440/90000 (68%)]	Loss: -3.7763	Cost: 6.34s
Train Epoch: 200 [81920/90000 (91%)]	Loss: -3.8368	Cost: 10.85s
Train Epoch: 200 	Average Loss: -3.7047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0091

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: -1.8760	Cost: 23.95s
Train Epoch: 201 [20480/90000 (23%)]	Loss: -4.4181	Cost: 6.13s
Train Epoch: 201 [40960/90000 (45%)]	Loss: -4.0877	Cost: 10.73s
Train Epoch: 201 [61440/90000 (68%)]	Loss: -3.9540	Cost: 8.73s
Train Epoch: 201 [81920/90000 (91%)]	Loss: -4.0603	Cost: 8.92s
Train Epoch: 201 	Average Loss: -3.7815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1851

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: -1.4012	Cost: 24.88s
Train Epoch: 202 [20480/90000 (23%)]	Loss: -4.3429	Cost: 11.95s
Train Epoch: 202 [40960/90000 (45%)]	Loss: -4.2388	Cost: 6.15s
Train Epoch: 202 [61440/90000 (68%)]	Loss: -3.8406	Cost: 6.11s
Train Epoch: 202 [81920/90000 (91%)]	Loss: -4.0015	Cost: 8.79s
Train Epoch: 202 	Average Loss: -3.7265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1242

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: -1.7926	Cost: 29.00s
Train Epoch: 203 [20480/90000 (23%)]	Loss: -4.4972	Cost: 11.39s
Train Epoch: 203 [40960/90000 (45%)]	Loss: -3.9973	Cost: 7.20s
Train Epoch: 203 [61440/90000 (68%)]	Loss: -4.0549	Cost: 10.92s
Train Epoch: 203 [81920/90000 (91%)]	Loss: -4.2129	Cost: 5.74s
Train Epoch: 203 	Average Loss: -3.8331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1284

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: -1.3632	Cost: 27.52s
Train Epoch: 204 [20480/90000 (23%)]	Loss: -3.9800	Cost: 6.20s
Train Epoch: 204 [40960/90000 (45%)]	Loss: -4.5635	Cost: 10.16s
Train Epoch: 204 [61440/90000 (68%)]	Loss: -3.8718	Cost: 15.17s
Train Epoch: 204 [81920/90000 (91%)]	Loss: -3.8593	Cost: 14.76s
Train Epoch: 204 	Average Loss: -3.7465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0264

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: -1.8756	Cost: 24.71s
Train Epoch: 205 [20480/90000 (23%)]	Loss: -4.0705	Cost: 6.10s
Train Epoch: 205 [40960/90000 (45%)]	Loss: -4.3469	Cost: 10.17s
Train Epoch: 205 [61440/90000 (68%)]	Loss: -3.8962	Cost: 6.09s
Train Epoch: 205 [81920/90000 (91%)]	Loss: -4.1168	Cost: 11.66s
Train Epoch: 205 	Average Loss: -3.8235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1649

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: -1.4667	Cost: 28.78s
Train Epoch: 206 [20480/90000 (23%)]	Loss: -4.3959	Cost: 8.69s
Train Epoch: 206 [40960/90000 (45%)]	Loss: -4.2099	Cost: 8.69s
Train Epoch: 206 [61440/90000 (68%)]	Loss: -4.0993	Cost: 8.47s
Train Epoch: 206 [81920/90000 (91%)]	Loss: -4.0105	Cost: 8.32s
Train Epoch: 206 	Average Loss: -3.8171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1974

Saving model as e206_model.pt & e206_waveforms_supplementary.hdf5
Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: -1.7759	Cost: 27.91s
Train Epoch: 207 [20480/90000 (23%)]	Loss: -4.0837	Cost: 10.89s
Train Epoch: 207 [40960/90000 (45%)]	Loss: -4.4514	Cost: 6.12s
Train Epoch: 207 [61440/90000 (68%)]	Loss: -3.7626	Cost: 6.43s
Train Epoch: 207 [81920/90000 (91%)]	Loss: -4.2515	Cost: 5.89s
Train Epoch: 207 	Average Loss: -3.8250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0464

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: -1.6425	Cost: 29.36s
Train Epoch: 208 [20480/90000 (23%)]	Loss: -4.1686	Cost: 12.47s
Train Epoch: 208 [40960/90000 (45%)]	Loss: -4.2829	Cost: 15.10s
Train Epoch: 208 [61440/90000 (68%)]	Loss: -4.1710	Cost: 9.11s
Train Epoch: 208 [81920/90000 (91%)]	Loss: -4.2616	Cost: 9.58s
Train Epoch: 208 	Average Loss: -3.8934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0865

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: -2.0243	Cost: 24.97s
Train Epoch: 209 [20480/90000 (23%)]	Loss: -4.5270	Cost: 8.27s
Train Epoch: 209 [40960/90000 (45%)]	Loss: -4.3117	Cost: 11.35s
Train Epoch: 209 [61440/90000 (68%)]	Loss: -4.2615	Cost: 6.88s
Train Epoch: 209 [81920/90000 (91%)]	Loss: -4.1873	Cost: 13.48s
Train Epoch: 209 	Average Loss: -3.9757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1634

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: -1.3464	Cost: 24.35s
Train Epoch: 210 [20480/90000 (23%)]	Loss: -4.3679	Cost: 8.62s
Train Epoch: 210 [40960/90000 (45%)]	Loss: -4.5381	Cost: 8.92s
Train Epoch: 210 [61440/90000 (68%)]	Loss: -3.8269	Cost: 9.19s
Train Epoch: 210 [81920/90000 (91%)]	Loss: -4.3984	Cost: 7.35s
Train Epoch: 210 	Average Loss: -3.8820
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1670

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: -1.4540	Cost: 23.26s
Train Epoch: 211 [20480/90000 (23%)]	Loss: -4.4518	Cost: 6.34s
Train Epoch: 211 [40960/90000 (45%)]	Loss: -4.4918	Cost: 8.69s
Train Epoch: 211 [61440/90000 (68%)]	Loss: -4.3124	Cost: 6.12s
Train Epoch: 211 [81920/90000 (91%)]	Loss: -4.0368	Cost: 8.44s
Train Epoch: 211 	Average Loss: -3.9690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0861

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: -1.3171	Cost: 25.29s
Train Epoch: 212 [20480/90000 (23%)]	Loss: -4.7002	Cost: 6.22s
Train Epoch: 212 [40960/90000 (45%)]	Loss: -4.3123	Cost: 11.57s
Train Epoch: 212 [61440/90000 (68%)]	Loss: -4.2987	Cost: 9.21s
Train Epoch: 212 [81920/90000 (91%)]	Loss: -4.1804	Cost: 6.23s
Train Epoch: 212 	Average Loss: -3.9107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2646

Saving model as e212_model.pt & e212_waveforms_supplementary.hdf5
Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: -1.6671	Cost: 25.75s
Train Epoch: 213 [20480/90000 (23%)]	Loss: -4.2356	Cost: 6.27s
Train Epoch: 213 [40960/90000 (45%)]	Loss: -4.6294	Cost: 14.23s
Train Epoch: 213 [61440/90000 (68%)]	Loss: -4.2091	Cost: 13.84s
Train Epoch: 213 [81920/90000 (91%)]	Loss: -4.4700	Cost: 11.80s
Train Epoch: 213 	Average Loss: -4.0483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1639

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: -1.8433	Cost: 23.27s
Train Epoch: 214 [20480/90000 (23%)]	Loss: -4.6527	Cost: 6.17s
Train Epoch: 214 [40960/90000 (45%)]	Loss: -4.4206	Cost: 9.86s
Train Epoch: 214 [61440/90000 (68%)]	Loss: -3.9537	Cost: 6.16s
Train Epoch: 214 [81920/90000 (91%)]	Loss: -4.5088	Cost: 10.82s
Train Epoch: 214 	Average Loss: -4.0942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3342

Saving model as e214_model.pt & e214_waveforms_supplementary.hdf5
Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: -1.9333	Cost: 23.97s
Train Epoch: 215 [20480/90000 (23%)]	Loss: -4.6181	Cost: 8.33s
Train Epoch: 215 [40960/90000 (45%)]	Loss: -4.8028	Cost: 8.86s
Train Epoch: 215 [61440/90000 (68%)]	Loss: -4.2441	Cost: 8.60s
Train Epoch: 215 [81920/90000 (91%)]	Loss: -4.4214	Cost: 8.30s
Train Epoch: 215 	Average Loss: -4.0948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4223

Saving model as e215_model.pt & e215_waveforms_supplementary.hdf5
Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: -1.6624	Cost: 29.65s
Train Epoch: 216 [20480/90000 (23%)]	Loss: -4.6287	Cost: 12.13s
Train Epoch: 216 [40960/90000 (45%)]	Loss: -4.5129	Cost: 6.72s
Train Epoch: 216 [61440/90000 (68%)]	Loss: -4.3487	Cost: 6.04s
Train Epoch: 216 [81920/90000 (91%)]	Loss: -4.4126	Cost: 5.74s
Train Epoch: 216 	Average Loss: -4.1416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4164

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: -1.6992	Cost: 31.60s
Train Epoch: 217 [20480/90000 (23%)]	Loss: -4.5312	Cost: 10.29s
Train Epoch: 217 [40960/90000 (45%)]	Loss: -4.3368	Cost: 14.97s
Train Epoch: 217 [61440/90000 (68%)]	Loss: -4.0768	Cost: 9.07s
Train Epoch: 217 [81920/90000 (91%)]	Loss: -4.1974	Cost: 11.84s
Train Epoch: 217 	Average Loss: -4.1148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2322

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: -1.8536	Cost: 29.83s
Train Epoch: 218 [20480/90000 (23%)]	Loss: -4.4211	Cost: 7.88s
Train Epoch: 218 [40960/90000 (45%)]	Loss: -4.4986	Cost: 12.98s
Train Epoch: 218 [61440/90000 (68%)]	Loss: -4.0947	Cost: 6.11s
Train Epoch: 218 [81920/90000 (91%)]	Loss: -4.5093	Cost: 20.37s
Train Epoch: 218 	Average Loss: -4.1074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4154

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: -1.7201	Cost: 23.56s
Train Epoch: 219 [20480/90000 (23%)]	Loss: -4.4767	Cost: 7.98s
Train Epoch: 219 [40960/90000 (45%)]	Loss: -4.6336	Cost: 7.85s
Train Epoch: 219 [61440/90000 (68%)]	Loss: -4.2351	Cost: 7.73s
Train Epoch: 219 [81920/90000 (91%)]	Loss: -4.4384	Cost: 10.89s
Train Epoch: 219 	Average Loss: -4.1982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3118

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: -1.4750	Cost: 25.55s
Train Epoch: 220 [20480/90000 (23%)]	Loss: -4.8465	Cost: 6.21s
Train Epoch: 220 [40960/90000 (45%)]	Loss: -4.6968	Cost: 11.19s
Train Epoch: 220 [61440/90000 (68%)]	Loss: -4.1885	Cost: 9.18s
Train Epoch: 220 [81920/90000 (91%)]	Loss: -4.4720	Cost: 8.93s
Train Epoch: 220 	Average Loss: -4.1952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3892

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: -1.8273	Cost: 26.03s
Train Epoch: 221 [20480/90000 (23%)]	Loss: -4.5135	Cost: 6.23s
Train Epoch: 221 [40960/90000 (45%)]	Loss: -4.8142	Cost: 12.26s
Train Epoch: 221 [61440/90000 (68%)]	Loss: -4.3558	Cost: 6.06s
Train Epoch: 221 [81920/90000 (91%)]	Loss: -4.5807	Cost: 7.02s
Train Epoch: 221 	Average Loss: -4.2391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3420

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: -1.4829	Cost: 25.73s
Train Epoch: 222 [20480/90000 (23%)]	Loss: -4.7013	Cost: 8.62s
Train Epoch: 222 [40960/90000 (45%)]	Loss: -4.9726	Cost: 15.48s
Train Epoch: 222 [61440/90000 (68%)]	Loss: -4.3939	Cost: 12.49s
Train Epoch: 222 [81920/90000 (91%)]	Loss: -4.5598	Cost: 9.37s
Train Epoch: 222 	Average Loss: -4.2837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5185

Saving model as e222_model.pt & e222_waveforms_supplementary.hdf5
Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: -2.2440	Cost: 24.79s
Train Epoch: 223 [20480/90000 (23%)]	Loss: -4.7339	Cost: 6.12s
Train Epoch: 223 [40960/90000 (45%)]	Loss: -4.9367	Cost: 9.97s
Train Epoch: 223 [61440/90000 (68%)]	Loss: -4.1377	Cost: 8.20s
Train Epoch: 223 [81920/90000 (91%)]	Loss: -4.5626	Cost: 16.21s
Train Epoch: 223 	Average Loss: -4.1947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2951

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: -1.9198	Cost: 26.15s
Train Epoch: 224 [20480/90000 (23%)]	Loss: -4.7051	Cost: 6.03s
Train Epoch: 224 [40960/90000 (45%)]	Loss: -4.5901	Cost: 10.54s
Train Epoch: 224 [61440/90000 (68%)]	Loss: -4.1761	Cost: 6.06s
Train Epoch: 224 [81920/90000 (91%)]	Loss: -4.2704	Cost: 12.23s
Train Epoch: 224 	Average Loss: -4.2577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2385

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: -1.6668	Cost: 25.44s
Train Epoch: 225 [20480/90000 (23%)]	Loss: -4.7348	Cost: 8.03s
Train Epoch: 225 [40960/90000 (45%)]	Loss: -4.8474	Cost: 8.87s
Train Epoch: 225 [61440/90000 (68%)]	Loss: -4.4906	Cost: 8.60s
Train Epoch: 225 [81920/90000 (91%)]	Loss: -4.6965	Cost: 8.40s
Train Epoch: 225 	Average Loss: -4.1934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5045

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: -2.2164	Cost: 33.42s
Train Epoch: 226 [20480/90000 (23%)]	Loss: -4.7041	Cost: 12.01s
Train Epoch: 226 [40960/90000 (45%)]	Loss: -4.7438	Cost: 6.28s
Train Epoch: 226 [61440/90000 (68%)]	Loss: -4.2877	Cost: 6.10s
Train Epoch: 226 [81920/90000 (91%)]	Loss: -4.5682	Cost: 6.36s
Train Epoch: 226 	Average Loss: -4.2867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4389

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: -2.1970	Cost: 25.45s
Train Epoch: 227 [20480/90000 (23%)]	Loss: -4.9411	Cost: 14.55s
Train Epoch: 227 [40960/90000 (45%)]	Loss: -4.4632	Cost: 14.44s
Train Epoch: 227 [61440/90000 (68%)]	Loss: -4.1838	Cost: 5.93s
Train Epoch: 227 [81920/90000 (91%)]	Loss: -4.6403	Cost: 10.15s
Train Epoch: 227 	Average Loss: -4.2953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2560

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: -1.7693	Cost: 23.39s
Train Epoch: 228 [20480/90000 (23%)]	Loss: -4.6477	Cost: 6.13s
Train Epoch: 228 [40960/90000 (45%)]	Loss: -4.8400	Cost: 11.18s
Train Epoch: 228 [61440/90000 (68%)]	Loss: -4.5460	Cost: 6.21s
Train Epoch: 228 [81920/90000 (91%)]	Loss: -4.7286	Cost: 12.15s
Train Epoch: 228 	Average Loss: -4.3813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4846

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: -1.9327	Cost: 25.82s
Train Epoch: 229 [20480/90000 (23%)]	Loss: -4.8399	Cost: 8.53s
Train Epoch: 229 [40960/90000 (45%)]	Loss: -4.9671	Cost: 8.95s
Train Epoch: 229 [61440/90000 (68%)]	Loss: -4.5415	Cost: 8.49s
Train Epoch: 229 [81920/90000 (91%)]	Loss: -4.9390	Cost: 8.83s
Train Epoch: 229 	Average Loss: -4.4611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4628

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: -2.3290	Cost: 26.48s
Train Epoch: 230 [20480/90000 (23%)]	Loss: -4.7680	Cost: 11.07s
Train Epoch: 230 [40960/90000 (45%)]	Loss: -4.7657	Cost: 6.34s
Train Epoch: 230 [61440/90000 (68%)]	Loss: -4.6638	Cost: 6.34s
Train Epoch: 230 [81920/90000 (91%)]	Loss: -4.9076	Cost: 5.95s
Train Epoch: 230 	Average Loss: -4.4467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6076

Saving model as e230_model.pt & e230_waveforms_supplementary.hdf5
Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: -2.2619	Cost: 26.85s
Train Epoch: 231 [20480/90000 (23%)]	Loss: -4.9459	Cost: 15.10s
Train Epoch: 231 [40960/90000 (45%)]	Loss: -5.0893	Cost: 8.92s
Train Epoch: 231 [61440/90000 (68%)]	Loss: -4.6187	Cost: 9.88s
Train Epoch: 231 [81920/90000 (91%)]	Loss: -4.8755	Cost: 5.95s
Train Epoch: 231 	Average Loss: -4.5093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5711

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: -2.5293	Cost: 27.11s
Train Epoch: 232 [20480/90000 (23%)]	Loss: -5.1456	Cost: 6.31s
Train Epoch: 232 [40960/90000 (45%)]	Loss: -5.0281	Cost: 13.87s
Train Epoch: 232 [61440/90000 (68%)]	Loss: -4.5174	Cost: 15.12s
Train Epoch: 232 [81920/90000 (91%)]	Loss: -4.4660	Cost: 14.44s
Train Epoch: 232 	Average Loss: -4.4894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5409

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: -2.4153	Cost: 22.77s
Train Epoch: 233 [20480/90000 (23%)]	Loss: -4.9165	Cost: 6.28s
Train Epoch: 233 [40960/90000 (45%)]	Loss: -5.1207	Cost: 10.22s
Train Epoch: 233 [61440/90000 (68%)]	Loss: -4.5715	Cost: 6.09s
Train Epoch: 233 [81920/90000 (91%)]	Loss: -4.5623	Cost: 13.60s
Train Epoch: 233 	Average Loss: -4.4686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7326

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: -2.3516	Cost: 27.75s
Train Epoch: 234 [20480/90000 (23%)]	Loss: -4.9643	Cost: 8.59s
Train Epoch: 234 [40960/90000 (45%)]	Loss: -4.9425	Cost: 8.68s
Train Epoch: 234 [61440/90000 (68%)]	Loss: -4.5989	Cost: 5.91s
Train Epoch: 234 [81920/90000 (91%)]	Loss: -5.1145	Cost: 8.91s
Train Epoch: 234 	Average Loss: -4.5567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6205

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: -1.9208	Cost: 28.21s
Train Epoch: 235 [20480/90000 (23%)]	Loss: -4.9261	Cost: 6.31s
Train Epoch: 235 [40960/90000 (45%)]	Loss: -4.6882	Cost: 11.99s
Train Epoch: 235 [61440/90000 (68%)]	Loss: -4.4837	Cost: 8.66s
Train Epoch: 235 [81920/90000 (91%)]	Loss: -4.6203	Cost: 8.26s
Train Epoch: 235 	Average Loss: -4.5695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7060

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: -2.1685	Cost: 27.28s
Train Epoch: 236 [20480/90000 (23%)]	Loss: -5.1003	Cost: 6.30s
Train Epoch: 236 [40960/90000 (45%)]	Loss: -5.0528	Cost: 12.37s
Train Epoch: 236 [61440/90000 (68%)]	Loss: -4.5272	Cost: 6.03s
Train Epoch: 236 [81920/90000 (91%)]	Loss: -5.1608	Cost: 5.80s
Train Epoch: 236 	Average Loss: -4.6170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6687

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: -2.1609	Cost: 35.67s
Train Epoch: 237 [20480/90000 (23%)]	Loss: -5.2756	Cost: 14.26s
Train Epoch: 237 [40960/90000 (45%)]	Loss: -4.8806	Cost: 14.01s
Train Epoch: 237 [61440/90000 (68%)]	Loss: -4.3544	Cost: 11.87s
Train Epoch: 237 [81920/90000 (91%)]	Loss: -5.0020	Cost: 5.78s
Train Epoch: 237 	Average Loss: -4.6130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6359

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: -2.0854	Cost: 38.36s
Train Epoch: 238 [20480/90000 (23%)]	Loss: -5.0175	Cost: 6.19s
Train Epoch: 238 [40960/90000 (45%)]	Loss: -5.1454	Cost: 10.58s
Train Epoch: 238 [61440/90000 (68%)]	Loss: -4.7515	Cost: 15.07s
Train Epoch: 238 [81920/90000 (91%)]	Loss: -4.9713	Cost: 13.99s
Train Epoch: 238 	Average Loss: -4.6227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4759

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: -2.1385	Cost: 24.38s
Train Epoch: 239 [20480/90000 (23%)]	Loss: -4.8525	Cost: 8.31s
Train Epoch: 239 [40960/90000 (45%)]	Loss: -4.9904	Cost: 12.00s
Train Epoch: 239 [61440/90000 (68%)]	Loss: -4.5424	Cost: 6.25s
Train Epoch: 239 [81920/90000 (91%)]	Loss: -5.0303	Cost: 11.42s
Train Epoch: 239 	Average Loss: -4.6507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7155

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: -2.5265	Cost: 24.07s
Train Epoch: 240 [20480/90000 (23%)]	Loss: -5.0836	Cost: 6.16s
Train Epoch: 240 [40960/90000 (45%)]	Loss: -5.2703	Cost: 10.49s
Train Epoch: 240 [61440/90000 (68%)]	Loss: -4.6015	Cost: 8.52s
Train Epoch: 240 [81920/90000 (91%)]	Loss: -4.7844	Cost: 8.60s
Train Epoch: 240 	Average Loss: -4.6460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6354

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: -2.0393	Cost: 26.47s
Train Epoch: 241 [20480/90000 (23%)]	Loss: -5.2656	Cost: 6.15s
Train Epoch: 241 [40960/90000 (45%)]	Loss: -5.1047	Cost: 12.16s
Train Epoch: 241 [61440/90000 (68%)]	Loss: -4.5954	Cost: 6.00s
Train Epoch: 241 [81920/90000 (91%)]	Loss: -5.4044	Cost: 8.89s
Train Epoch: 241 	Average Loss: -4.6909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6472

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: -2.0671	Cost: 26.43s
Train Epoch: 242 [20480/90000 (23%)]	Loss: -5.1236	Cost: 7.40s
Train Epoch: 242 [40960/90000 (45%)]	Loss: -4.9476	Cost: 16.17s
Train Epoch: 242 [61440/90000 (68%)]	Loss: -4.6704	Cost: 10.79s
Train Epoch: 242 [81920/90000 (91%)]	Loss: -4.8845	Cost: 11.80s
Train Epoch: 242 	Average Loss: -4.7119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7005

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: -2.0130	Cost: 24.35s
Train Epoch: 243 [20480/90000 (23%)]	Loss: -5.0983	Cost: 6.18s
Train Epoch: 243 [40960/90000 (45%)]	Loss: -5.0248	Cost: 9.83s
Train Epoch: 243 [61440/90000 (68%)]	Loss: -4.4292	Cost: 6.09s
Train Epoch: 243 [81920/90000 (91%)]	Loss: -4.9466	Cost: 19.37s
Train Epoch: 243 	Average Loss: -4.6863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5751

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: -2.5731	Cost: 27.31s
Train Epoch: 244 [20480/90000 (23%)]	Loss: -5.3995	Cost: 6.10s
Train Epoch: 244 [40960/90000 (45%)]	Loss: -5.1176	Cost: 10.65s
Train Epoch: 244 [61440/90000 (68%)]	Loss: -4.5645	Cost: 6.16s
Train Epoch: 244 [81920/90000 (91%)]	Loss: -4.9498	Cost: 11.83s
Train Epoch: 244 	Average Loss: -4.6339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7082

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: -2.1597	Cost: 26.51s
Train Epoch: 245 [20480/90000 (23%)]	Loss: -5.1581	Cost: 6.28s
Train Epoch: 245 [40960/90000 (45%)]	Loss: -5.0427	Cost: 10.16s
Train Epoch: 245 [61440/90000 (68%)]	Loss: -4.7147	Cost: 8.61s
Train Epoch: 245 [81920/90000 (91%)]	Loss: -5.3302	Cost: 8.25s
Train Epoch: 245 	Average Loss: -4.7729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6489

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: -2.3003	Cost: 26.22s
Train Epoch: 246 [20480/90000 (23%)]	Loss: -5.1528	Cost: 7.02s
Train Epoch: 246 [40960/90000 (45%)]	Loss: -5.2204	Cost: 11.29s
Train Epoch: 246 [61440/90000 (68%)]	Loss: -4.8786	Cost: 6.12s
Train Epoch: 246 [81920/90000 (91%)]	Loss: -5.2646	Cost: 10.05s
Train Epoch: 246 	Average Loss: -4.8190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8307

Saving model as e246_model.pt & e246_waveforms_supplementary.hdf5
Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: -2.3841	Cost: 26.48s
Train Epoch: 247 [20480/90000 (23%)]	Loss: -5.3295	Cost: 6.63s
Train Epoch: 247 [40960/90000 (45%)]	Loss: -5.4211	Cost: 14.89s
Train Epoch: 247 [61440/90000 (68%)]	Loss: -4.8713	Cost: 13.60s
Train Epoch: 247 [81920/90000 (91%)]	Loss: -4.7831	Cost: 9.18s
Train Epoch: 247 	Average Loss: -4.8422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7809

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: -2.0279	Cost: 24.49s
Train Epoch: 248 [20480/90000 (23%)]	Loss: -5.2009	Cost: 6.16s
Train Epoch: 248 [40960/90000 (45%)]	Loss: -5.2012	Cost: 11.88s
Train Epoch: 248 [61440/90000 (68%)]	Loss: -4.9924	Cost: 6.49s
Train Epoch: 248 [81920/90000 (91%)]	Loss: -5.3184	Cost: 19.47s
Train Epoch: 248 	Average Loss: -4.8286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8180

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: -2.5581	Cost: 23.44s
Train Epoch: 249 [20480/90000 (23%)]	Loss: -4.9357	Cost: 6.06s
Train Epoch: 249 [40960/90000 (45%)]	Loss: -5.3350	Cost: 9.51s
Train Epoch: 249 [61440/90000 (68%)]	Loss: -5.1414	Cost: 6.35s
Train Epoch: 249 [81920/90000 (91%)]	Loss: -5.0273	Cost: 11.02s
Train Epoch: 249 	Average Loss: -4.7426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9159

Saving model as e249_model.pt & e249_waveforms_supplementary.hdf5
Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: -2.5368	Cost: 24.75s
Train Epoch: 250 [20480/90000 (23%)]	Loss: -5.3383	Cost: 6.04s
Train Epoch: 250 [40960/90000 (45%)]	Loss: -5.1874	Cost: 10.29s
Train Epoch: 250 [61440/90000 (68%)]	Loss: -4.8137	Cost: 7.83s
Train Epoch: 250 [81920/90000 (91%)]	Loss: -5.0677	Cost: 8.80s
Train Epoch: 250 	Average Loss: -4.8366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8287

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: -2.1807	Cost: 27.24s
Train Epoch: 251 [20480/90000 (23%)]	Loss: -5.1861	Cost: 6.16s
Train Epoch: 251 [40960/90000 (45%)]	Loss: -5.2493	Cost: 14.00s
Train Epoch: 251 [61440/90000 (68%)]	Loss: -4.9940	Cost: 5.87s
Train Epoch: 251 [81920/90000 (91%)]	Loss: -5.5665	Cost: 6.80s
Train Epoch: 251 	Average Loss: -4.9209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8811

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: -2.5944	Cost: 27.30s
Train Epoch: 252 [20480/90000 (23%)]	Loss: -5.5888	Cost: 6.40s
Train Epoch: 252 [40960/90000 (45%)]	Loss: -5.2609	Cost: 15.74s
Train Epoch: 252 [61440/90000 (68%)]	Loss: -4.8238	Cost: 12.66s
Train Epoch: 252 [81920/90000 (91%)]	Loss: -5.3644	Cost: 10.32s
Train Epoch: 252 	Average Loss: -4.9237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7765

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: -2.4800	Cost: 26.49s
Train Epoch: 253 [20480/90000 (23%)]	Loss: -5.1562	Cost: 7.08s
Train Epoch: 253 [40960/90000 (45%)]	Loss: -5.5398	Cost: 9.86s
Train Epoch: 253 [61440/90000 (68%)]	Loss: -5.0088	Cost: 6.14s
Train Epoch: 253 [81920/90000 (91%)]	Loss: -5.1430	Cost: 17.68s
Train Epoch: 253 	Average Loss: -4.9656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9434

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: -2.5869	Cost: 24.99s
Train Epoch: 254 [20480/90000 (23%)]	Loss: -5.7614	Cost: 6.16s
Train Epoch: 254 [40960/90000 (45%)]	Loss: -5.3533	Cost: 10.36s
Train Epoch: 254 [61440/90000 (68%)]	Loss: -4.8268	Cost: 6.26s
Train Epoch: 254 [81920/90000 (91%)]	Loss: -5.0999	Cost: 11.78s
Train Epoch: 254 	Average Loss: -5.0075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9006

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: -2.0786	Cost: 23.43s
Train Epoch: 255 [20480/90000 (23%)]	Loss: -5.4100	Cost: 6.30s
Train Epoch: 255 [40960/90000 (45%)]	Loss: -5.4506	Cost: 11.01s
Train Epoch: 255 [61440/90000 (68%)]	Loss: -5.2044	Cost: 8.88s
Train Epoch: 255 [81920/90000 (91%)]	Loss: -5.7041	Cost: 9.11s
Train Epoch: 255 	Average Loss: -5.0137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9393

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: -2.5077	Cost: 24.15s
Train Epoch: 256 [20480/90000 (23%)]	Loss: -5.1527	Cost: 10.44s
Train Epoch: 256 [40960/90000 (45%)]	Loss: -5.6240	Cost: 8.22s
Train Epoch: 256 [61440/90000 (68%)]	Loss: -5.3155	Cost: 6.12s
Train Epoch: 256 [81920/90000 (91%)]	Loss: -5.3529	Cost: 5.99s
Train Epoch: 256 	Average Loss: -5.0919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8207

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: -2.6599	Cost: 25.76s
Train Epoch: 257 [20480/90000 (23%)]	Loss: -5.2309	Cost: 6.34s
Train Epoch: 257 [40960/90000 (45%)]	Loss: -5.6052	Cost: 16.96s
Train Epoch: 257 [61440/90000 (68%)]	Loss: -5.0865	Cost: 12.85s
Train Epoch: 257 [81920/90000 (91%)]	Loss: -5.5138	Cost: 9.98s
Train Epoch: 257 	Average Loss: -5.0374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7103

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: -2.3057	Cost: 23.98s
Train Epoch: 258 [20480/90000 (23%)]	Loss: -5.7059	Cost: 6.46s
Train Epoch: 258 [40960/90000 (45%)]	Loss: -5.5875	Cost: 9.38s
Train Epoch: 258 [61440/90000 (68%)]	Loss: -5.4062	Cost: 6.03s
Train Epoch: 258 [81920/90000 (91%)]	Loss: -5.5553	Cost: 11.96s
Train Epoch: 258 	Average Loss: -5.0990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8836

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: -2.3064	Cost: 24.16s
Train Epoch: 259 [20480/90000 (23%)]	Loss: -5.4842	Cost: 8.71s
Train Epoch: 259 [40960/90000 (45%)]	Loss: -5.5831	Cost: 8.66s
Train Epoch: 259 [61440/90000 (68%)]	Loss: -5.1828	Cost: 8.43s
Train Epoch: 259 [81920/90000 (91%)]	Loss: -5.6432	Cost: 8.25s
Train Epoch: 259 	Average Loss: -5.1104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8571

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: -2.0941	Cost: 27.14s
Train Epoch: 260 [20480/90000 (23%)]	Loss: -5.5972	Cost: 11.14s
Train Epoch: 260 [40960/90000 (45%)]	Loss: -5.5018	Cost: 7.17s
Train Epoch: 260 [61440/90000 (68%)]	Loss: -5.4125	Cost: 6.24s
Train Epoch: 260 [81920/90000 (91%)]	Loss: -5.5146	Cost: 5.83s
Train Epoch: 260 	Average Loss: -5.1227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0340

Saving model as e260_model.pt & e260_waveforms_supplementary.hdf5
Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: -2.7841	Cost: 40.66s
Train Epoch: 261 [20480/90000 (23%)]	Loss: -5.7716	Cost: 12.93s
Train Epoch: 261 [40960/90000 (45%)]	Loss: -5.6562	Cost: 6.18s
Train Epoch: 261 [61440/90000 (68%)]	Loss: -5.3401	Cost: 11.92s
Train Epoch: 261 [81920/90000 (91%)]	Loss: -5.7195	Cost: 5.77s
Train Epoch: 261 	Average Loss: -5.1556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1090

Saving model as e261_model.pt & e261_waveforms_supplementary.hdf5
Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: -2.3377	Cost: 39.21s
Train Epoch: 262 [20480/90000 (23%)]	Loss: -5.6956	Cost: 6.15s
Train Epoch: 262 [40960/90000 (45%)]	Loss: -5.6249	Cost: 13.22s
Train Epoch: 262 [61440/90000 (68%)]	Loss: -5.1090	Cost: 14.81s
Train Epoch: 262 [81920/90000 (91%)]	Loss: -5.4752	Cost: 14.29s
Train Epoch: 262 	Average Loss: -5.1853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0007

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: -2.7174	Cost: 31.60s
Train Epoch: 263 [20480/90000 (23%)]	Loss: -5.7269	Cost: 6.30s
Train Epoch: 263 [40960/90000 (45%)]	Loss: -5.5486	Cost: 11.20s
Train Epoch: 263 [61440/90000 (68%)]	Loss: -5.1844	Cost: 6.05s
Train Epoch: 263 [81920/90000 (91%)]	Loss: -5.4537	Cost: 20.22s
Train Epoch: 263 	Average Loss: -5.2093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1025

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: -2.2926	Cost: 23.04s
Train Epoch: 264 [20480/90000 (23%)]	Loss: -5.8454	Cost: 7.29s
Train Epoch: 264 [40960/90000 (45%)]	Loss: -5.9491	Cost: 13.66s
Train Epoch: 264 [61440/90000 (68%)]	Loss: -5.2953	Cost: 6.85s
Train Epoch: 264 [81920/90000 (91%)]	Loss: -5.4057	Cost: 13.30s
Train Epoch: 264 	Average Loss: -5.2436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0341

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: -2.6511	Cost: 25.70s
Train Epoch: 265 [20480/90000 (23%)]	Loss: -5.8939	Cost: 6.14s
Train Epoch: 265 [40960/90000 (45%)]	Loss: -5.4908	Cost: 10.97s
Train Epoch: 265 [61440/90000 (68%)]	Loss: -5.1079	Cost: 8.51s
Train Epoch: 265 [81920/90000 (91%)]	Loss: -5.6303	Cost: 8.83s
Train Epoch: 265 	Average Loss: -5.2600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0747

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: -2.7293	Cost: 23.81s
Train Epoch: 266 [20480/90000 (23%)]	Loss: -5.3105	Cost: 7.26s
Train Epoch: 266 [40960/90000 (45%)]	Loss: -5.6310	Cost: 11.09s
Train Epoch: 266 [61440/90000 (68%)]	Loss: -5.3903	Cost: 6.05s
Train Epoch: 266 [81920/90000 (91%)]	Loss: -5.6256	Cost: 5.98s
Train Epoch: 266 	Average Loss: -5.2764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0852

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: -2.2077	Cost: 27.18s
Train Epoch: 267 [20480/90000 (23%)]	Loss: -5.9375	Cost: 6.50s
Train Epoch: 267 [40960/90000 (45%)]	Loss: -5.5998	Cost: 13.24s
Train Epoch: 267 [61440/90000 (68%)]	Loss: -5.4780	Cost: 14.39s
Train Epoch: 267 [81920/90000 (91%)]	Loss: -5.7078	Cost: 11.43s
Train Epoch: 267 	Average Loss: -5.3318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9564

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: -2.8109	Cost: 24.05s
Train Epoch: 268 [20480/90000 (23%)]	Loss: -6.0346	Cost: 6.19s
Train Epoch: 268 [40960/90000 (45%)]	Loss: -5.4566	Cost: 9.34s
Train Epoch: 268 [61440/90000 (68%)]	Loss: -5.4473	Cost: 6.09s
Train Epoch: 268 [81920/90000 (91%)]	Loss: -5.8070	Cost: 12.36s
Train Epoch: 268 	Average Loss: -5.3438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1778

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: -2.3717	Cost: 28.51s
Train Epoch: 269 [20480/90000 (23%)]	Loss: -5.8770	Cost: 8.71s
Train Epoch: 269 [40960/90000 (45%)]	Loss: -5.8978	Cost: 9.01s
Train Epoch: 269 [61440/90000 (68%)]	Loss: -5.4057	Cost: 8.07s
Train Epoch: 269 [81920/90000 (91%)]	Loss: -5.8066	Cost: 5.89s
Train Epoch: 269 	Average Loss: -5.3935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2065

Saving model as e269_model.pt & e269_waveforms_supplementary.hdf5
Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: -2.6850	Cost: 28.38s
Train Epoch: 270 [20480/90000 (23%)]	Loss: -5.8054	Cost: 6.20s
Train Epoch: 270 [40960/90000 (45%)]	Loss: -5.4815	Cost: 11.87s
Train Epoch: 270 [61440/90000 (68%)]	Loss: -5.7690	Cost: 8.54s
Train Epoch: 270 [81920/90000 (91%)]	Loss: -5.9264	Cost: 8.75s
Train Epoch: 270 	Average Loss: -5.4006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2036

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: -2.6024	Cost: 26.90s
Train Epoch: 271 [20480/90000 (23%)]	Loss: -5.8496	Cost: 6.28s
Train Epoch: 271 [40960/90000 (45%)]	Loss: -5.6930	Cost: 11.75s
Train Epoch: 271 [61440/90000 (68%)]	Loss: -5.2558	Cost: 9.19s
Train Epoch: 271 [81920/90000 (91%)]	Loss: -5.6140	Cost: 5.86s
Train Epoch: 271 	Average Loss: -5.3877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0870

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: -2.8372	Cost: 30.20s
Train Epoch: 272 [20480/90000 (23%)]	Loss: -6.0064	Cost: 6.57s
Train Epoch: 272 [40960/90000 (45%)]	Loss: -5.8810	Cost: 9.63s
Train Epoch: 272 [61440/90000 (68%)]	Loss: -5.4374	Cost: 6.14s
Train Epoch: 272 [81920/90000 (91%)]	Loss: -5.8652	Cost: 14.13s
Train Epoch: 272 	Average Loss: -5.4405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1813

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: -2.6231	Cost: 24.37s
Train Epoch: 273 [20480/90000 (23%)]	Loss: -5.8619	Cost: 8.79s
Train Epoch: 273 [40960/90000 (45%)]	Loss: -5.9263	Cost: 8.36s
Train Epoch: 273 [61440/90000 (68%)]	Loss: -5.4307	Cost: 6.02s
Train Epoch: 273 [81920/90000 (91%)]	Loss: -5.7805	Cost: 10.27s
Train Epoch: 273 	Average Loss: -5.5002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1937

Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: -2.3124	Cost: 24.52s
Train Epoch: 274 [20480/90000 (23%)]	Loss: -5.9380	Cost: 6.12s
Train Epoch: 274 [40960/90000 (45%)]	Loss: -5.7581	Cost: 12.16s
Train Epoch: 274 [61440/90000 (68%)]	Loss: -5.7612	Cost: 8.92s
Train Epoch: 274 [81920/90000 (91%)]	Loss: -5.6733	Cost: 9.90s
Train Epoch: 274 	Average Loss: -5.4659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0686

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: -2.3754	Cost: 24.18s
Train Epoch: 275 [20480/90000 (23%)]	Loss: -6.1606	Cost: 9.62s
Train Epoch: 275 [40960/90000 (45%)]	Loss: -5.8585	Cost: 9.34s
Train Epoch: 275 [61440/90000 (68%)]	Loss: -5.4718	Cost: 5.97s
Train Epoch: 275 [81920/90000 (91%)]	Loss: -6.0582	Cost: 5.84s
Train Epoch: 275 	Average Loss: -5.5372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3223

Saving model as e275_model.pt & e275_waveforms_supplementary.hdf5
Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: -2.3790	Cost: 26.50s
Train Epoch: 276 [20480/90000 (23%)]	Loss: -6.2047	Cost: 14.93s
Train Epoch: 276 [40960/90000 (45%)]	Loss: -6.0258	Cost: 12.26s
Train Epoch: 276 [61440/90000 (68%)]	Loss: -5.9399	Cost: 10.92s
Train Epoch: 276 [81920/90000 (91%)]	Loss: -6.1141	Cost: 6.19s
Train Epoch: 276 	Average Loss: -5.5534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2624

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: -3.1613	Cost: 25.59s
Train Epoch: 277 [20480/90000 (23%)]	Loss: -6.1314	Cost: 6.30s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -5.7766	Cost: 12.53s
Train Epoch: 277 [61440/90000 (68%)]	Loss: -5.6529	Cost: 14.69s
Train Epoch: 277 [81920/90000 (91%)]	Loss: -5.8028	Cost: 15.39s
Train Epoch: 277 	Average Loss: -5.5581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1422

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: -2.9172	Cost: 24.03s
Train Epoch: 278 [20480/90000 (23%)]	Loss: -6.0174	Cost: 6.41s
Train Epoch: 278 [40960/90000 (45%)]	Loss: -5.8071	Cost: 9.51s
Train Epoch: 278 [61440/90000 (68%)]	Loss: -5.8214	Cost: 6.07s
Train Epoch: 278 [81920/90000 (91%)]	Loss: -6.0506	Cost: 14.62s
Train Epoch: 278 	Average Loss: -5.5358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1220

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: -2.4469	Cost: 24.10s
Train Epoch: 279 [20480/90000 (23%)]	Loss: -5.9196	Cost: 8.70s
Train Epoch: 279 [40960/90000 (45%)]	Loss: -6.1528	Cost: 8.93s
Train Epoch: 279 [61440/90000 (68%)]	Loss: -5.6252	Cost: 8.29s
Train Epoch: 279 [81920/90000 (91%)]	Loss: -5.7620	Cost: 5.58s
Train Epoch: 279 	Average Loss: -5.5859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2958

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: -2.6662	Cost: 26.44s
Train Epoch: 280 [20480/90000 (23%)]	Loss: -5.9485	Cost: 6.10s
Train Epoch: 280 [40960/90000 (45%)]	Loss: -5.9951	Cost: 11.72s
Train Epoch: 280 [61440/90000 (68%)]	Loss: -5.7091	Cost: 6.15s
Train Epoch: 280 [81920/90000 (91%)]	Loss: -6.1234	Cost: 11.56s
Train Epoch: 280 	Average Loss: -5.5827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1286

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: -3.1320	Cost: 26.57s
Train Epoch: 281 [20480/90000 (23%)]	Loss: -6.1883	Cost: 13.26s
Train Epoch: 281 [40960/90000 (45%)]	Loss: -5.9907	Cost: 6.14s
Train Epoch: 281 [61440/90000 (68%)]	Loss: -5.7789	Cost: 11.94s
Train Epoch: 281 [81920/90000 (91%)]	Loss: -6.1926	Cost: 5.98s
Train Epoch: 281 	Average Loss: -5.6323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2693

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: -2.3886	Cost: 37.30s
Train Epoch: 282 [20480/90000 (23%)]	Loss: -6.0600	Cost: 6.35s
Train Epoch: 282 [40960/90000 (45%)]	Loss: -5.9765	Cost: 12.26s
Train Epoch: 282 [61440/90000 (68%)]	Loss: -5.9543	Cost: 14.54s
Train Epoch: 282 [81920/90000 (91%)]	Loss: -6.0087	Cost: 14.10s
Train Epoch: 282 	Average Loss: -5.6960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2428

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: -3.1045	Cost: 26.61s
Train Epoch: 283 [20480/90000 (23%)]	Loss: -6.3273	Cost: 6.90s
Train Epoch: 283 [40960/90000 (45%)]	Loss: -6.1844	Cost: 10.27s
Train Epoch: 283 [61440/90000 (68%)]	Loss: -5.7950	Cost: 6.18s
Train Epoch: 283 [81920/90000 (91%)]	Loss: -6.1167	Cost: 18.18s
Train Epoch: 283 	Average Loss: -5.6818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3694

Saving model as e283_model.pt & e283_waveforms_supplementary.hdf5
Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: -2.5287	Cost: 24.55s
Train Epoch: 284 [20480/90000 (23%)]	Loss: -6.4012	Cost: 6.32s
Train Epoch: 284 [40960/90000 (45%)]	Loss: -6.0884	Cost: 10.18s
Train Epoch: 284 [61440/90000 (68%)]	Loss: -5.9109	Cost: 6.38s
Train Epoch: 284 [81920/90000 (91%)]	Loss: -5.9630	Cost: 11.86s
Train Epoch: 284 	Average Loss: -5.6873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4278

Saving model as e284_model.pt & e284_waveforms_supplementary.hdf5
Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: -2.6801	Cost: 24.81s
Train Epoch: 285 [20480/90000 (23%)]	Loss: -6.1998	Cost: 6.45s
Train Epoch: 285 [40960/90000 (45%)]	Loss: -6.1155	Cost: 11.91s
Train Epoch: 285 [61440/90000 (68%)]	Loss: -5.7157	Cost: 8.96s
Train Epoch: 285 [81920/90000 (91%)]	Loss: -6.1725	Cost: 9.64s
Train Epoch: 285 	Average Loss: -5.7202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4271

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: -2.7788	Cost: 25.55s
Train Epoch: 286 [20480/90000 (23%)]	Loss: -6.0089	Cost: 9.48s
Train Epoch: 286 [40960/90000 (45%)]	Loss: -6.2438	Cost: 8.81s
Train Epoch: 286 [61440/90000 (68%)]	Loss: -5.8723	Cost: 6.30s
Train Epoch: 286 [81920/90000 (91%)]	Loss: -6.3350	Cost: 8.47s
Train Epoch: 286 	Average Loss: -5.7215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3236

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: -2.8549	Cost: 28.22s
Train Epoch: 287 [20480/90000 (23%)]	Loss: -6.0671	Cost: 6.18s
Train Epoch: 287 [40960/90000 (45%)]	Loss: -6.2030	Cost: 15.89s
Train Epoch: 287 [61440/90000 (68%)]	Loss: -5.9968	Cost: 14.98s
Train Epoch: 287 [81920/90000 (91%)]	Loss: -5.9792	Cost: 9.16s
Train Epoch: 287 	Average Loss: -5.7219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2340

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: -3.1270	Cost: 24.43s
Train Epoch: 288 [20480/90000 (23%)]	Loss: -6.4660	Cost: 6.14s
Train Epoch: 288 [40960/90000 (45%)]	Loss: -6.2747	Cost: 10.97s
Train Epoch: 288 [61440/90000 (68%)]	Loss: -5.8940	Cost: 6.25s
Train Epoch: 288 [81920/90000 (91%)]	Loss: -6.4154	Cost: 19.45s
Train Epoch: 288 	Average Loss: -5.7733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3509

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: -3.2026	Cost: 23.13s
Train Epoch: 289 [20480/90000 (23%)]	Loss: -6.5221	Cost: 6.61s
Train Epoch: 289 [40960/90000 (45%)]	Loss: -6.3216	Cost: 10.25s
Train Epoch: 289 [61440/90000 (68%)]	Loss: -5.8455	Cost: 6.40s
Train Epoch: 289 [81920/90000 (91%)]	Loss: -6.3820	Cost: 11.11s
Train Epoch: 289 	Average Loss: -5.8228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3995

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: -3.2992	Cost: 24.58s
Train Epoch: 290 [20480/90000 (23%)]	Loss: -6.3744	Cost: 6.27s
Train Epoch: 290 [40960/90000 (45%)]	Loss: -6.2361	Cost: 10.26s
Train Epoch: 290 [61440/90000 (68%)]	Loss: -5.8082	Cost: 8.64s
Train Epoch: 290 [81920/90000 (91%)]	Loss: -6.1161	Cost: 8.26s
Train Epoch: 290 	Average Loss: -5.8393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3222

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: -3.2739	Cost: 24.78s
Train Epoch: 291 [20480/90000 (23%)]	Loss: -6.1419	Cost: 11.36s
Train Epoch: 291 [40960/90000 (45%)]	Loss: -6.3922	Cost: 6.92s
Train Epoch: 291 [61440/90000 (68%)]	Loss: -5.9960	Cost: 6.23s
Train Epoch: 291 [81920/90000 (91%)]	Loss: -6.1106	Cost: 6.82s
Train Epoch: 291 	Average Loss: -5.8133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3556

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: -2.6752	Cost: 25.25s
Train Epoch: 292 [20480/90000 (23%)]	Loss: -6.1870	Cost: 14.48s
Train Epoch: 292 [40960/90000 (45%)]	Loss: -6.4536	Cost: 15.58s
Train Epoch: 292 [61440/90000 (68%)]	Loss: -6.1388	Cost: 9.89s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -6.3653	Cost: 5.93s
Train Epoch: 292 	Average Loss: -5.8729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4066

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: -2.8905	Cost: 25.46s
Train Epoch: 293 [20480/90000 (23%)]	Loss: -6.1543	Cost: 6.14s
Train Epoch: 293 [40960/90000 (45%)]	Loss: -6.3087	Cost: 14.19s
Train Epoch: 293 [61440/90000 (68%)]	Loss: -5.9133	Cost: 15.22s
Train Epoch: 293 [81920/90000 (91%)]	Loss: -6.3795	Cost: 12.57s
Train Epoch: 293 	Average Loss: -5.9045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4048

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: -3.0128	Cost: 26.24s
Train Epoch: 294 [20480/90000 (23%)]	Loss: -6.2773	Cost: 6.25s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -6.4756	Cost: 14.50s
Train Epoch: 294 [61440/90000 (68%)]	Loss: -5.9538	Cost: 14.96s
Train Epoch: 294 [81920/90000 (91%)]	Loss: -6.4271	Cost: 14.94s
Train Epoch: 294 	Average Loss: -5.9053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4319

Saving model as e294_model.pt & e294_waveforms_supplementary.hdf5
Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: -2.8142	Cost: 25.27s
Train Epoch: 295 [20480/90000 (23%)]	Loss: -6.2547	Cost: 6.51s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -6.1729	Cost: 9.46s
Train Epoch: 295 [61440/90000 (68%)]	Loss: -6.0384	Cost: 14.15s
Train Epoch: 295 [81920/90000 (91%)]	Loss: -6.3572	Cost: 14.77s
Train Epoch: 295 	Average Loss: -5.9180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4696

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: -2.6980	Cost: 26.11s
Train Epoch: 296 [20480/90000 (23%)]	Loss: -6.4532	Cost: 7.14s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -6.2420	Cost: 9.47s
Train Epoch: 296 [61440/90000 (68%)]	Loss: -6.1976	Cost: 6.05s
Train Epoch: 296 [81920/90000 (91%)]	Loss: -6.1403	Cost: 13.94s
Train Epoch: 296 	Average Loss: -5.8998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3945

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: -2.7268	Cost: 25.88s
Train Epoch: 297 [20480/90000 (23%)]	Loss: -6.4666	Cost: 8.78s
Train Epoch: 297 [40960/90000 (45%)]	Loss: -6.4185	Cost: 9.43s
Train Epoch: 297 [61440/90000 (68%)]	Loss: -5.8990	Cost: 8.38s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -6.4734	Cost: 5.61s
Train Epoch: 297 	Average Loss: -5.9268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6307

Saving model as e297_model.pt & e297_waveforms_supplementary.hdf5
Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: -3.1118	Cost: 25.58s
Train Epoch: 298 [20480/90000 (23%)]	Loss: -6.5195	Cost: 6.30s
Train Epoch: 298 [40960/90000 (45%)]	Loss: -6.2972	Cost: 8.68s
Train Epoch: 298 [61440/90000 (68%)]	Loss: -5.8990	Cost: 6.73s
Train Epoch: 298 [81920/90000 (91%)]	Loss: -6.2050	Cost: 10.17s
Train Epoch: 298 	Average Loss: -5.8886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3941

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: -3.2039	Cost: 25.14s
Train Epoch: 299 [20480/90000 (23%)]	Loss: -6.5637	Cost: 8.41s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -6.3844	Cost: 9.99s
Train Epoch: 299 [61440/90000 (68%)]	Loss: -6.2657	Cost: 5.97s
Train Epoch: 299 [81920/90000 (91%)]	Loss: -6.1266	Cost: 8.28s
Train Epoch: 299 	Average Loss: -6.0070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5269

Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: -3.1313	Cost: 25.71s
Train Epoch: 300 [20480/90000 (23%)]	Loss: -6.3099	Cost: 6.62s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -6.4059	Cost: 13.28s
Train Epoch: 300 [61440/90000 (68%)]	Loss: -6.0865	Cost: 15.26s
Train Epoch: 300 [81920/90000 (91%)]	Loss: -6.2651	Cost: 6.29s
Train Epoch: 300 	Average Loss: -5.9877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5321

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: -3.3769	Cost: 24.18s
Train Epoch: 301 [20480/90000 (23%)]	Loss: -6.6941	Cost: 6.22s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -6.4412	Cost: 9.67s
Train Epoch: 301 [61440/90000 (68%)]	Loss: -6.1717	Cost: 6.13s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -6.2166	Cost: 12.93s
Train Epoch: 301 	Average Loss: -6.0356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6340

Saving model as e301_model.pt & e301_waveforms_supplementary.hdf5
Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: -2.9594	Cost: 23.47s
Train Epoch: 302 [20480/90000 (23%)]	Loss: -6.7512	Cost: 8.62s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -6.6531	Cost: 8.70s
Train Epoch: 302 [61440/90000 (68%)]	Loss: -6.2884	Cost: 7.20s
Train Epoch: 302 [81920/90000 (91%)]	Loss: -6.5684	Cost: 5.60s
Train Epoch: 302 	Average Loss: -6.0510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6658

Saving model as e302_model.pt & e302_waveforms_supplementary.hdf5
Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: -3.0355	Cost: 23.69s
Train Epoch: 303 [20480/90000 (23%)]	Loss: -6.7765	Cost: 6.11s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -6.2820	Cost: 8.73s
Train Epoch: 303 [61440/90000 (68%)]	Loss: -6.2307	Cost: 6.04s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -6.5771	Cost: 8.36s
Train Epoch: 303 	Average Loss: -6.0693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6421

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: -3.6848	Cost: 25.24s
Train Epoch: 304 [20480/90000 (23%)]	Loss: -6.4447	Cost: 6.07s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -6.2417	Cost: 8.82s
Train Epoch: 304 [61440/90000 (68%)]	Loss: -6.1624	Cost: 5.97s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -6.2521	Cost: 7.70s
Train Epoch: 304 	Average Loss: -6.0683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5936

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: -3.4201	Cost: 23.09s
Train Epoch: 305 [20480/90000 (23%)]	Loss: -6.5019	Cost: 6.16s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -6.6465	Cost: 9.24s
Train Epoch: 305 [61440/90000 (68%)]	Loss: -6.3177	Cost: 6.15s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -6.7333	Cost: 9.73s
Train Epoch: 305 	Average Loss: -6.1428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4538

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: -3.1542	Cost: 22.77s
Train Epoch: 306 [20480/90000 (23%)]	Loss: -6.6004	Cost: 6.20s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -6.7830	Cost: 8.51s
Train Epoch: 306 [61440/90000 (68%)]	Loss: -6.2056	Cost: 6.13s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -6.5984	Cost: 10.59s
Train Epoch: 306 	Average Loss: -6.1306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5734

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: -2.8187	Cost: 24.05s
Train Epoch: 307 [20480/90000 (23%)]	Loss: -6.5119	Cost: 6.15s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -6.6230	Cost: 10.02s
Train Epoch: 307 [61440/90000 (68%)]	Loss: -6.2334	Cost: 5.93s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -6.5366	Cost: 8.44s
Train Epoch: 307 	Average Loss: -6.1324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6816

Saving model as e307_model.pt & e307_waveforms_supplementary.hdf5
Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: -3.7548	Cost: 22.81s
Train Epoch: 308 [20480/90000 (23%)]	Loss: -6.6326	Cost: 6.18s
Train Epoch: 308 [40960/90000 (45%)]	Loss: -6.5547	Cost: 9.05s
Train Epoch: 308 [61440/90000 (68%)]	Loss: -6.0976	Cost: 6.24s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -6.7495	Cost: 7.15s
Train Epoch: 308 	Average Loss: -6.1687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5323

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: -3.3311	Cost: 23.54s
Train Epoch: 309 [20480/90000 (23%)]	Loss: -6.5665	Cost: 6.30s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -6.6232	Cost: 8.46s
Train Epoch: 309 [61440/90000 (68%)]	Loss: -6.1214	Cost: 6.09s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -6.6302	Cost: 7.76s
Train Epoch: 309 	Average Loss: -6.1731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6800

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: -2.9295	Cost: 31.09s
Train Epoch: 310 [20480/90000 (23%)]	Loss: -6.8816	Cost: 7.00s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -6.8115	Cost: 10.60s
Train Epoch: 310 [61440/90000 (68%)]	Loss: -6.3966	Cost: 10.01s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -6.5839	Cost: 5.93s
Train Epoch: 310 	Average Loss: -6.1777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7149

Saving model as e310_model.pt & e310_waveforms_supplementary.hdf5
Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: -2.2652	Cost: 29.77s
Train Epoch: 311 [20480/90000 (23%)]	Loss: -6.7191	Cost: 6.26s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -6.8033	Cost: 15.70s
Train Epoch: 311 [61440/90000 (68%)]	Loss: -6.3050	Cost: 12.70s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -6.8091	Cost: 9.06s
Train Epoch: 311 	Average Loss: -6.2317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6790

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: -3.2948	Cost: 23.71s
Train Epoch: 312 [20480/90000 (23%)]	Loss: -6.5276	Cost: 8.24s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -6.5942	Cost: 10.55s
Train Epoch: 312 [61440/90000 (68%)]	Loss: -6.3329	Cost: 6.79s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -6.8324	Cost: 18.61s
Train Epoch: 312 	Average Loss: -6.2446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5748

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: -2.7853	Cost: 23.77s
Train Epoch: 313 [20480/90000 (23%)]	Loss: -6.7428	Cost: 6.14s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -6.7058	Cost: 9.74s
Train Epoch: 313 [61440/90000 (68%)]	Loss: -6.4854	Cost: 7.50s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -6.5648	Cost: 11.73s
Train Epoch: 313 	Average Loss: -6.2042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6261

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: -3.4557	Cost: 23.40s
Train Epoch: 314 [20480/90000 (23%)]	Loss: -6.4531	Cost: 6.10s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -6.9067	Cost: 8.87s
Train Epoch: 314 [61440/90000 (68%)]	Loss: -6.5219	Cost: 7.14s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -6.5939	Cost: 9.29s
Train Epoch: 314 	Average Loss: -6.2287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6061

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: -3.4817	Cost: 25.68s
Train Epoch: 315 [20480/90000 (23%)]	Loss: -6.6803	Cost: 6.15s
Train Epoch: 315 [40960/90000 (45%)]	Loss: -6.6878	Cost: 13.40s
Train Epoch: 315 [61440/90000 (68%)]	Loss: -6.2077	Cost: 6.84s
Train Epoch: 315 [81920/90000 (91%)]	Loss: -6.5398	Cost: 5.91s
Train Epoch: 315 	Average Loss: -6.2512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5155

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: -2.7972	Cost: 27.67s
Train Epoch: 316 [20480/90000 (23%)]	Loss: -6.3840	Cost: 6.73s
Train Epoch: 316 [40960/90000 (45%)]	Loss: -6.7699	Cost: 9.20s
Train Epoch: 316 [61440/90000 (68%)]	Loss: -6.3853	Cost: 14.88s
Train Epoch: 316 [81920/90000 (91%)]	Loss: -6.8142	Cost: 13.91s
Train Epoch: 316 	Average Loss: -6.2798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6571

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: -3.4269	Cost: 26.30s
Train Epoch: 317 [20480/90000 (23%)]	Loss: -7.0330	Cost: 7.04s
Train Epoch: 317 [40960/90000 (45%)]	Loss: -6.8802	Cost: 10.10s
Train Epoch: 317 [61440/90000 (68%)]	Loss: -6.6137	Cost: 6.07s
Train Epoch: 317 [81920/90000 (91%)]	Loss: -6.9969	Cost: 11.14s
Train Epoch: 317 	Average Loss: -6.3245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5320

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: -3.3086	Cost: 26.97s
Train Epoch: 318 [20480/90000 (23%)]	Loss: -6.6943	Cost: 8.72s
Train Epoch: 318 [40960/90000 (45%)]	Loss: -6.7445	Cost: 8.90s
Train Epoch: 318 [61440/90000 (68%)]	Loss: -6.4217	Cost: 8.63s
Train Epoch: 318 [81920/90000 (91%)]	Loss: -6.6868	Cost: 7.47s
Train Epoch: 318 	Average Loss: -6.3173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7002

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: -3.5380	Cost: 24.81s
Train Epoch: 319 [20480/90000 (23%)]	Loss: -6.8124	Cost: 12.13s
Train Epoch: 319 [40960/90000 (45%)]	Loss: -7.0034	Cost: 6.14s
Train Epoch: 319 [61440/90000 (68%)]	Loss: -6.6021	Cost: 6.13s
Train Epoch: 319 [81920/90000 (91%)]	Loss: -6.5602	Cost: 9.09s
Train Epoch: 319 	Average Loss: -6.3429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7404

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: -3.6306	Cost: 25.79s
Train Epoch: 320 [20480/90000 (23%)]	Loss: -6.7166	Cost: 6.25s
Train Epoch: 320 [40960/90000 (45%)]	Loss: -6.7783	Cost: 14.34s
Train Epoch: 320 [61440/90000 (68%)]	Loss: -6.3704	Cost: 14.17s
Train Epoch: 320 [81920/90000 (91%)]	Loss: -6.6790	Cost: 5.99s
Train Epoch: 320 	Average Loss: -6.3584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7675

Saving model as e320_model.pt & e320_waveforms_supplementary.hdf5
Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: -3.4663	Cost: 24.41s
Train Epoch: 321 [20480/90000 (23%)]	Loss: -7.1127	Cost: 6.17s
Train Epoch: 321 [40960/90000 (45%)]	Loss: -6.8858	Cost: 9.97s
Train Epoch: 321 [61440/90000 (68%)]	Loss: -6.5801	Cost: 6.15s
Train Epoch: 321 [81920/90000 (91%)]	Loss: -6.9553	Cost: 10.65s
Train Epoch: 321 	Average Loss: -6.3924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7581

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: -3.5276	Cost: 24.85s
Train Epoch: 322 [20480/90000 (23%)]	Loss: -6.8723	Cost: 8.29s
Train Epoch: 322 [40960/90000 (45%)]	Loss: -6.8620	Cost: 10.03s
Train Epoch: 322 [61440/90000 (68%)]	Loss: -6.6859	Cost: 8.61s
Train Epoch: 322 [81920/90000 (91%)]	Loss: -6.4881	Cost: 8.24s
Train Epoch: 322 	Average Loss: -6.3631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7588

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: -3.0423	Cost: 28.24s
Train Epoch: 323 [20480/90000 (23%)]	Loss: -7.0672	Cost: 11.04s
Train Epoch: 323 [40960/90000 (45%)]	Loss: -6.9465	Cost: 6.98s
Train Epoch: 323 [61440/90000 (68%)]	Loss: -6.4733	Cost: 5.94s
Train Epoch: 323 [81920/90000 (91%)]	Loss: -6.6730	Cost: 7.87s
Train Epoch: 323 	Average Loss: -6.3699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7173

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: -3.5634	Cost: 28.27s
Train Epoch: 324 [20480/90000 (23%)]	Loss: -6.8027	Cost: 6.25s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -6.8350	Cost: 15.10s
Train Epoch: 324 [61440/90000 (68%)]	Loss: -6.4515	Cost: 15.22s
Train Epoch: 324 [81920/90000 (91%)]	Loss: -7.0453	Cost: 9.53s
Train Epoch: 324 	Average Loss: -6.4239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7033

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: -3.7444	Cost: 32.19s
Train Epoch: 325 [20480/90000 (23%)]	Loss: -7.1098	Cost: 6.19s
Train Epoch: 325 [40960/90000 (45%)]	Loss: -7.0673	Cost: 10.52s
Train Epoch: 325 [61440/90000 (68%)]	Loss: -6.6495	Cost: 6.01s
Train Epoch: 325 [81920/90000 (91%)]	Loss: -6.8333	Cost: 18.56s
Train Epoch: 325 	Average Loss: -6.4177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9186

Saving model as e325_model.pt & e325_waveforms_supplementary.hdf5
Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: -3.3806	Cost: 29.05s
Train Epoch: 326 [20480/90000 (23%)]	Loss: -7.0227	Cost: 6.34s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -6.9859	Cost: 11.18s
Train Epoch: 326 [61440/90000 (68%)]	Loss: -6.5588	Cost: 6.38s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -6.6507	Cost: 14.90s
Train Epoch: 326 	Average Loss: -6.4640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8341

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: -3.1470	Cost: 24.41s
Train Epoch: 327 [20480/90000 (23%)]	Loss: -7.0639	Cost: 8.81s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -6.9424	Cost: 9.02s
Train Epoch: 327 [61440/90000 (68%)]	Loss: -6.3547	Cost: 6.93s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -6.8688	Cost: 6.78s
Train Epoch: 327 	Average Loss: -6.4209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7524

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: -3.7388	Cost: 24.98s
Train Epoch: 328 [20480/90000 (23%)]	Loss: -6.9542	Cost: 6.12s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -7.0707	Cost: 10.51s
Train Epoch: 328 [61440/90000 (68%)]	Loss: -6.3954	Cost: 8.75s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -6.5762	Cost: 11.69s
Train Epoch: 328 	Average Loss: -6.4466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8655

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: -2.9692	Cost: 24.11s
Train Epoch: 329 [20480/90000 (23%)]	Loss: -6.8178	Cost: 9.16s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -6.9443	Cost: 9.20s
Train Epoch: 329 [61440/90000 (68%)]	Loss: -6.3763	Cost: 6.01s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -6.8156	Cost: 5.76s
Train Epoch: 329 	Average Loss: -6.4637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8792

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: -3.6122	Cost: 25.35s
Train Epoch: 330 [20480/90000 (23%)]	Loss: -7.0046	Cost: 10.89s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -6.7829	Cost: 15.37s
Train Epoch: 330 [61440/90000 (68%)]	Loss: -6.4984	Cost: 13.89s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -7.1031	Cost: 5.64s
Train Epoch: 330 	Average Loss: -6.4991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8181

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: -2.6011	Cost: 25.71s
Train Epoch: 331 [20480/90000 (23%)]	Loss: -6.9345	Cost: 6.30s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -6.7967	Cost: 9.92s
Train Epoch: 331 [61440/90000 (68%)]	Loss: -6.4308	Cost: 15.27s
Train Epoch: 331 [81920/90000 (91%)]	Loss: -6.8858	Cost: 14.31s
Train Epoch: 331 	Average Loss: -6.4407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7593

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: -3.4213	Cost: 23.72s
Train Epoch: 332 [20480/90000 (23%)]	Loss: -6.9061	Cost: 6.45s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -7.0575	Cost: 10.07s
Train Epoch: 332 [61440/90000 (68%)]	Loss: -6.6403	Cost: 6.27s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -6.7626	Cost: 19.33s
Train Epoch: 332 	Average Loss: -6.4750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8064

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: -3.6636	Cost: 25.34s
Train Epoch: 333 [20480/90000 (23%)]	Loss: -7.0181	Cost: 6.05s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -6.9083	Cost: 9.51s
Train Epoch: 333 [61440/90000 (68%)]	Loss: -6.8262	Cost: 6.12s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -6.6931	Cost: 11.97s
Train Epoch: 333 	Average Loss: -6.5218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8752

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: -3.5103	Cost: 25.34s
Train Epoch: 334 [20480/90000 (23%)]	Loss: -7.0105	Cost: 6.13s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -7.0087	Cost: 10.51s
Train Epoch: 334 [61440/90000 (68%)]	Loss: -6.5548	Cost: 8.65s
Train Epoch: 334 [81920/90000 (91%)]	Loss: -6.7158	Cost: 8.34s
Train Epoch: 334 	Average Loss: -6.5412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7645

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: -3.3128	Cost: 27.47s
Train Epoch: 335 [20480/90000 (23%)]	Loss: -7.2514	Cost: 6.52s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -7.2013	Cost: 11.79s
Train Epoch: 335 [61440/90000 (68%)]	Loss: -6.6038	Cost: 6.19s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -6.7400	Cost: 11.04s
Train Epoch: 335 	Average Loss: -6.5305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9610

Saving model as e335_model.pt & e335_waveforms_supplementary.hdf5
Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: -3.0135	Cost: 25.48s
Train Epoch: 336 [20480/90000 (23%)]	Loss: -6.9500	Cost: 13.41s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -6.8743	Cost: 14.67s
Train Epoch: 336 [61440/90000 (68%)]	Loss: -6.9018	Cost: 6.78s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -7.0307	Cost: 11.11s
Train Epoch: 336 	Average Loss: -6.5270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8528

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: -3.2924	Cost: 23.51s
Train Epoch: 337 [20480/90000 (23%)]	Loss: -6.7837	Cost: 6.31s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -7.4150	Cost: 9.24s
Train Epoch: 337 [61440/90000 (68%)]	Loss: -6.6559	Cost: 6.56s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -6.9384	Cost: 20.10s
Train Epoch: 337 	Average Loss: -6.5565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9503

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: -3.5961	Cost: 24.94s
Train Epoch: 338 [20480/90000 (23%)]	Loss: -7.0116	Cost: 6.39s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -7.0302	Cost: 9.89s
Train Epoch: 338 [61440/90000 (68%)]	Loss: -6.6919	Cost: 6.41s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -6.9474	Cost: 10.89s
Train Epoch: 338 	Average Loss: -6.5962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0632

Saving model as e338_model.pt & e338_waveforms_supplementary.hdf5
Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: -3.6369	Cost: 24.59s
Train Epoch: 339 [20480/90000 (23%)]	Loss: -7.0925	Cost: 6.27s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -7.2358	Cost: 12.06s
Train Epoch: 339 [61440/90000 (68%)]	Loss: -6.6377	Cost: 8.81s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -7.1394	Cost: 8.95s
Train Epoch: 339 	Average Loss: -6.6163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9625

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: -3.0534	Cost: 27.82s
Train Epoch: 340 [20480/90000 (23%)]	Loss: -6.9706	Cost: 10.81s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -6.9439	Cost: 6.24s
Train Epoch: 340 [61440/90000 (68%)]	Loss: -6.7510	Cost: 6.12s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -7.1107	Cost: 6.16s
Train Epoch: 340 	Average Loss: -6.5787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9940

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: -3.0883	Cost: 32.90s
Train Epoch: 341 [20480/90000 (23%)]	Loss: -7.0623	Cost: 15.64s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -7.0818	Cost: 10.24s
Train Epoch: 341 [61440/90000 (68%)]	Loss: -6.6007	Cost: 11.80s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -6.8907	Cost: 5.89s
Train Epoch: 341 	Average Loss: -6.6267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0115

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: -3.4397	Cost: 29.45s
Train Epoch: 342 [20480/90000 (23%)]	Loss: -7.1093	Cost: 6.64s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -7.2606	Cost: 9.63s
Train Epoch: 342 [61440/90000 (68%)]	Loss: -6.6331	Cost: 10.16s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -6.8612	Cost: 14.93s
Train Epoch: 342 	Average Loss: -6.5778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7107

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: -2.8189	Cost: 25.93s
Train Epoch: 343 [20480/90000 (23%)]	Loss: -7.2210	Cost: 7.48s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -7.0791	Cost: 9.62s
Train Epoch: 343 [61440/90000 (68%)]	Loss: -6.7367	Cost: 6.27s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -7.1383	Cost: 11.73s
Train Epoch: 343 	Average Loss: -6.5213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8876

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: -3.2364	Cost: 24.42s
Train Epoch: 344 [20480/90000 (23%)]	Loss: -7.0925	Cost: 8.57s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -7.1677	Cost: 8.84s
Train Epoch: 344 [61440/90000 (68%)]	Loss: -6.7370	Cost: 8.93s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -6.9912	Cost: 7.83s
Train Epoch: 344 	Average Loss: -6.6648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9731

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: -3.3721	Cost: 23.45s
Train Epoch: 345 [20480/90000 (23%)]	Loss: -6.8596	Cost: 6.08s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -6.9802	Cost: 9.18s
Train Epoch: 345 [61440/90000 (68%)]	Loss: -7.0092	Cost: 6.06s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -7.0361	Cost: 8.44s
Train Epoch: 345 	Average Loss: -6.6658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8786

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: -3.0891	Cost: 27.82s
Train Epoch: 346 [20480/90000 (23%)]	Loss: -7.0506	Cost: 6.06s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -7.0276	Cost: 13.22s
Train Epoch: 346 [61440/90000 (68%)]	Loss: -6.8237	Cost: 5.87s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -7.1259	Cost: 7.75s
Train Epoch: 346 	Average Loss: -6.6980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9108

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: -3.2359	Cost: 28.12s
Train Epoch: 347 [20480/90000 (23%)]	Loss: -7.0835	Cost: 6.17s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -7.1897	Cost: 13.34s
Train Epoch: 347 [61440/90000 (68%)]	Loss: -6.6969	Cost: 14.70s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -6.9086	Cost: 11.86s
Train Epoch: 347 	Average Loss: -6.6343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9507

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: -3.7340	Cost: 26.93s
Train Epoch: 348 [20480/90000 (23%)]	Loss: -7.1687	Cost: 6.81s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -7.4329	Cost: 9.53s
Train Epoch: 348 [61440/90000 (68%)]	Loss: -6.6571	Cost: 6.06s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -6.9646	Cost: 17.55s
Train Epoch: 348 	Average Loss: -6.6969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8166

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: -3.2895	Cost: 25.70s
Train Epoch: 349 [20480/90000 (23%)]	Loss: -7.2853	Cost: 6.71s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -7.2139	Cost: 11.09s
Train Epoch: 349 [61440/90000 (68%)]	Loss: -6.9941	Cost: 6.41s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -7.2167	Cost: 11.16s
Train Epoch: 349 	Average Loss: -6.7046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9141

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: -3.0980	Cost: 25.44s
Train Epoch: 350 [20480/90000 (23%)]	Loss: -7.0541	Cost: 7.85s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -7.2072	Cost: 10.56s
Train Epoch: 350 [61440/90000 (68%)]	Loss: -6.8486	Cost: 8.57s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -7.0742	Cost: 9.02s
Train Epoch: 350 	Average Loss: -6.6969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0029

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: -3.5810	Cost: 24.18s
Train Epoch: 351 [20480/90000 (23%)]	Loss: -7.2328	Cost: 6.44s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -7.0557	Cost: 9.92s
Train Epoch: 351 [61440/90000 (68%)]	Loss: -6.7186	Cost: 6.05s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -7.2948	Cost: 11.22s
Train Epoch: 351 	Average Loss: -6.7702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8967

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: -3.4906	Cost: 29.05s
Train Epoch: 352 [20480/90000 (23%)]	Loss: -7.0969	Cost: 14.97s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -7.3099	Cost: 12.89s
Train Epoch: 352 [61440/90000 (68%)]	Loss: -6.8090	Cost: 7.09s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -7.0306	Cost: 6.25s
Train Epoch: 352 	Average Loss: -6.7676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9568

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: -3.5902	Cost: 25.60s
Train Epoch: 353 [20480/90000 (23%)]	Loss: -7.0496	Cost: 6.08s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -7.3570	Cost: 12.10s
Train Epoch: 353 [61440/90000 (68%)]	Loss: -6.8917	Cost: 14.72s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -7.4353	Cost: 15.13s
Train Epoch: 353 	Average Loss: -6.7620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0547

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: -3.6284	Cost: 25.16s
Train Epoch: 354 [20480/90000 (23%)]	Loss: -7.1366	Cost: 6.17s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -7.4408	Cost: 10.49s
Train Epoch: 354 [61440/90000 (68%)]	Loss: -6.8803	Cost: 6.05s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -7.5148	Cost: 19.33s
Train Epoch: 354 	Average Loss: -6.7999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9068

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: -3.5423	Cost: 23.01s
Train Epoch: 355 [20480/90000 (23%)]	Loss: -7.0856	Cost: 6.14s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -7.3771	Cost: 9.82s
Train Epoch: 355 [61440/90000 (68%)]	Loss: -7.0186	Cost: 6.14s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -7.2192	Cost: 11.70s
Train Epoch: 355 	Average Loss: -6.8283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8738

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: -3.4736	Cost: 24.71s
Train Epoch: 356 [20480/90000 (23%)]	Loss: -7.3209	Cost: 6.43s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -7.0666	Cost: 9.45s
Train Epoch: 356 [61440/90000 (68%)]	Loss: -6.8823	Cost: 8.00s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -7.1388	Cost: 8.63s
Train Epoch: 356 	Average Loss: -6.7693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9416

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: -3.3223	Cost: 28.54s
Train Epoch: 357 [20480/90000 (23%)]	Loss: -7.0240	Cost: 7.30s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -7.2505	Cost: 11.09s
Train Epoch: 357 [61440/90000 (68%)]	Loss: -6.7291	Cost: 6.21s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -7.4114	Cost: 6.69s
Train Epoch: 357 	Average Loss: -6.7790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9953

Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: -3.3814	Cost: 27.11s
Train Epoch: 358 [20480/90000 (23%)]	Loss: -7.2217	Cost: 9.04s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -7.4242	Cost: 14.65s
Train Epoch: 358 [61440/90000 (68%)]	Loss: -7.0632	Cost: 13.71s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -7.1749	Cost: 9.77s
Train Epoch: 358 	Average Loss: -6.8290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0162

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: -3.4463	Cost: 30.15s
Train Epoch: 359 [20480/90000 (23%)]	Loss: -7.1219	Cost: 8.18s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -7.5108	Cost: 10.73s
Train Epoch: 359 [61440/90000 (68%)]	Loss: -6.8402	Cost: 9.15s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -7.3230	Cost: 17.01s
Train Epoch: 359 	Average Loss: -6.8051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9671

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: -3.8205	Cost: 23.02s
Train Epoch: 360 [20480/90000 (23%)]	Loss: -7.2961	Cost: 6.17s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -7.2871	Cost: 11.27s
Train Epoch: 360 [61440/90000 (68%)]	Loss: -7.1887	Cost: 7.39s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -7.4557	Cost: 11.33s
Train Epoch: 360 	Average Loss: -6.8190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9818

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: -3.5207	Cost: 25.84s
Train Epoch: 361 [20480/90000 (23%)]	Loss: -7.5620	Cost: 6.08s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -7.3440	Cost: 11.40s
Train Epoch: 361 [61440/90000 (68%)]	Loss: -7.0931	Cost: 8.30s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -7.1937	Cost: 9.00s
Train Epoch: 361 	Average Loss: -6.8277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0496

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: -3.2829	Cost: 27.29s
Train Epoch: 362 [20480/90000 (23%)]	Loss: -7.2572	Cost: 9.23s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -7.4396	Cost: 7.27s
Train Epoch: 362 [61440/90000 (68%)]	Loss: -6.8713	Cost: 5.95s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -7.4935	Cost: 10.12s
Train Epoch: 362 	Average Loss: -6.7962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9761

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: -3.2443	Cost: 26.52s
Train Epoch: 363 [20480/90000 (23%)]	Loss: -7.2925	Cost: 14.47s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -7.5251	Cost: 11.07s
Train Epoch: 363 [61440/90000 (68%)]	Loss: -6.7765	Cost: 8.89s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -7.1848	Cost: 5.74s
Train Epoch: 363 	Average Loss: -6.8497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9072

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: -3.5872	Cost: 26.20s
Train Epoch: 364 [20480/90000 (23%)]	Loss: -7.3355	Cost: 6.20s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -7.4758	Cost: 12.91s
Train Epoch: 364 [61440/90000 (68%)]	Loss: -6.8166	Cost: 14.91s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -7.1475	Cost: 13.75s
Train Epoch: 364 	Average Loss: -6.8282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0857

Saving model as e364_model.pt & e364_waveforms_supplementary.hdf5
Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: -3.3490	Cost: 24.37s
Train Epoch: 365 [20480/90000 (23%)]	Loss: -7.3565	Cost: 6.12s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -7.0623	Cost: 10.00s
Train Epoch: 365 [61440/90000 (68%)]	Loss: -7.1807	Cost: 6.02s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -7.1581	Cost: 20.04s
Train Epoch: 365 	Average Loss: -6.8603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0811

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: -3.6700	Cost: 24.54s
Train Epoch: 366 [20480/90000 (23%)]	Loss: -7.4055	Cost: 6.09s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -7.2908	Cost: 10.47s
Train Epoch: 366 [61440/90000 (68%)]	Loss: -6.8944	Cost: 6.08s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -7.4102	Cost: 11.85s
Train Epoch: 366 	Average Loss: -6.8490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1187

Saving model as e366_model.pt & e366_waveforms_supplementary.hdf5
Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: -3.4868	Cost: 25.30s
Train Epoch: 367 [20480/90000 (23%)]	Loss: -7.2918	Cost: 7.08s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -7.5640	Cost: 9.07s
Train Epoch: 367 [61440/90000 (68%)]	Loss: -6.9027	Cost: 8.55s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -7.3036	Cost: 8.35s
Train Epoch: 367 	Average Loss: -6.9118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0760

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: -3.3448	Cost: 24.59s
Train Epoch: 368 [20480/90000 (23%)]	Loss: -7.5375	Cost: 11.58s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -7.6593	Cost: 7.06s
Train Epoch: 368 [61440/90000 (68%)]	Loss: -7.1827	Cost: 6.03s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -7.4815	Cost: 7.51s
Train Epoch: 368 	Average Loss: -6.9174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1259

Saving model as e368_model.pt & e368_waveforms_supplementary.hdf5
Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: -3.6120	Cost: 26.65s
Train Epoch: 369 [20480/90000 (23%)]	Loss: -7.3760	Cost: 12.22s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -7.3588	Cost: 14.75s
Train Epoch: 369 [61440/90000 (68%)]	Loss: -7.1114	Cost: 8.23s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -7.3814	Cost: 11.30s
Train Epoch: 369 	Average Loss: -6.9049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0223

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: -3.5764	Cost: 23.74s
Train Epoch: 370 [20480/90000 (23%)]	Loss: -7.3036	Cost: 6.26s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -7.3300	Cost: 9.47s
Train Epoch: 370 [61440/90000 (68%)]	Loss: -7.1216	Cost: 6.12s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -6.8768	Cost: 19.35s
Train Epoch: 370 	Average Loss: -6.9340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9885

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: -3.5351	Cost: 24.06s
Train Epoch: 371 [20480/90000 (23%)]	Loss: -7.3357	Cost: 8.82s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -7.5528	Cost: 7.90s
Train Epoch: 371 [61440/90000 (68%)]	Loss: -7.2583	Cost: 5.96s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -7.6206	Cost: 7.57s
Train Epoch: 371 	Average Loss: -6.8785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9864

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: -3.7242	Cost: 25.50s
Train Epoch: 372 [20480/90000 (23%)]	Loss: -7.4164	Cost: 6.45s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -7.4391	Cost: 11.06s
Train Epoch: 372 [61440/90000 (68%)]	Loss: -7.0873	Cost: 8.72s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -7.2800	Cost: 8.38s
Train Epoch: 372 	Average Loss: -6.9011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1156

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: -3.8785	Cost: 24.53s
Train Epoch: 373 [20480/90000 (23%)]	Loss: -7.3689	Cost: 6.27s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -7.2790	Cost: 12.41s
Train Epoch: 373 [61440/90000 (68%)]	Loss: -7.1591	Cost: 6.29s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -7.4761	Cost: 5.97s
Train Epoch: 373 	Average Loss: -6.9547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1763

Saving model as e373_model.pt & e373_waveforms_supplementary.hdf5
Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: -3.9397	Cost: 28.44s
Train Epoch: 374 [20480/90000 (23%)]	Loss: -7.2107	Cost: 8.97s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -7.4460	Cost: 15.05s
Train Epoch: 374 [61440/90000 (68%)]	Loss: -7.0399	Cost: 14.45s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -7.4013	Cost: 7.58s
Train Epoch: 374 	Average Loss: -6.9139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9882

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: -3.4068	Cost: 28.10s
Train Epoch: 375 [20480/90000 (23%)]	Loss: -7.3223	Cost: 6.80s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -7.4332	Cost: 9.35s
Train Epoch: 375 [61440/90000 (68%)]	Loss: -6.9156	Cost: 6.07s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -7.5629	Cost: 18.48s
Train Epoch: 375 	Average Loss: -6.9099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0758

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: -3.5122	Cost: 26.63s
Train Epoch: 376 [20480/90000 (23%)]	Loss: -7.2848	Cost: 8.02s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -7.1831	Cost: 9.89s
Train Epoch: 376 [61440/90000 (68%)]	Loss: -7.0956	Cost: 6.18s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -6.9448	Cost: 11.80s
Train Epoch: 376 	Average Loss: -6.9107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9184

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: -3.8080	Cost: 24.73s
Train Epoch: 377 [20480/90000 (23%)]	Loss: -7.3833	Cost: 8.58s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -7.2697	Cost: 9.08s
Train Epoch: 377 [61440/90000 (68%)]	Loss: -6.8617	Cost: 8.92s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -7.3800	Cost: 8.94s
Train Epoch: 377 	Average Loss: -6.9215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9292

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: -3.5304	Cost: 27.80s
Train Epoch: 378 [20480/90000 (23%)]	Loss: -7.2189	Cost: 6.96s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -7.6522	Cost: 8.77s
Train Epoch: 378 [61440/90000 (68%)]	Loss: -7.1105	Cost: 5.96s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -7.3100	Cost: 8.89s
Train Epoch: 378 	Average Loss: -6.9346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9412

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: -3.8409	Cost: 25.26s
Train Epoch: 379 [20480/90000 (23%)]	Loss: -7.7081	Cost: 10.27s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -7.7083	Cost: 7.16s
Train Epoch: 379 [61440/90000 (68%)]	Loss: -7.0530	Cost: 10.92s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -7.3765	Cost: 5.76s
Train Epoch: 379 	Average Loss: -6.9633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1139

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: -4.0075	Cost: 28.21s
Train Epoch: 380 [20480/90000 (23%)]	Loss: -7.7586	Cost: 6.06s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -7.5838	Cost: 12.85s
Train Epoch: 380 [61440/90000 (68%)]	Loss: -7.2954	Cost: 14.90s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -7.4096	Cost: 13.17s
Train Epoch: 380 	Average Loss: -6.9443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0905

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: -3.3043	Cost: 24.22s
Train Epoch: 381 [20480/90000 (23%)]	Loss: -7.2394	Cost: 6.16s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -7.4443	Cost: 9.93s
Train Epoch: 381 [61440/90000 (68%)]	Loss: -7.1377	Cost: 6.09s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -7.5153	Cost: 11.24s
Train Epoch: 381 	Average Loss: -6.9554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1672

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: -3.3170	Cost: 24.48s
Train Epoch: 382 [20480/90000 (23%)]	Loss: -7.2461	Cost: 8.23s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -7.5821	Cost: 8.58s
Train Epoch: 382 [61440/90000 (68%)]	Loss: -6.9466	Cost: 8.48s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -7.3296	Cost: 8.33s
Train Epoch: 382 	Average Loss: -6.9320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9705

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: -3.8688	Cost: 28.38s
Train Epoch: 383 [20480/90000 (23%)]	Loss: -7.3894	Cost: 11.40s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -7.4332	Cost: 6.31s
Train Epoch: 383 [61440/90000 (68%)]	Loss: -7.0476	Cost: 6.24s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -7.4392	Cost: 5.81s
Train Epoch: 383 	Average Loss: -6.9559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0924

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: -3.6349	Cost: 26.06s
Train Epoch: 384 [20480/90000 (23%)]	Loss: -7.3693	Cost: 13.09s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -7.6035	Cost: 15.61s
Train Epoch: 384 [61440/90000 (68%)]	Loss: -6.8628	Cost: 5.97s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -7.6655	Cost: 11.96s
Train Epoch: 384 	Average Loss: -6.9563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8857

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: -3.6305	Cost: 24.12s
Train Epoch: 385 [20480/90000 (23%)]	Loss: -7.5748	Cost: 6.30s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -7.5924	Cost: 10.39s
Train Epoch: 385 [61440/90000 (68%)]	Loss: -7.1870	Cost: 6.16s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -7.3298	Cost: 19.82s
Train Epoch: 385 	Average Loss: -6.9248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0650

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: -3.5386	Cost: 24.62s
Train Epoch: 386 [20480/90000 (23%)]	Loss: -7.5941	Cost: 6.13s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -7.4294	Cost: 10.40s
Train Epoch: 386 [61440/90000 (68%)]	Loss: -6.7800	Cost: 6.24s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -7.3744	Cost: 11.98s
Train Epoch: 386 	Average Loss: -6.9630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0930

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: -3.4200	Cost: 23.16s
Train Epoch: 387 [20480/90000 (23%)]	Loss: -7.5570	Cost: 6.22s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -7.4687	Cost: 9.00s
Train Epoch: 387 [61440/90000 (68%)]	Loss: -7.0027	Cost: 8.18s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -7.2849	Cost: 8.28s
Train Epoch: 387 	Average Loss: -6.9581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9833

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: -3.7304	Cost: 25.32s
Train Epoch: 388 [20480/90000 (23%)]	Loss: -7.3401	Cost: 6.24s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -7.5113	Cost: 12.88s
Train Epoch: 388 [61440/90000 (68%)]	Loss: -7.1018	Cost: 6.09s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -7.4691	Cost: 6.01s
Train Epoch: 388 	Average Loss: -6.9508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9450

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: -3.6685	Cost: 29.01s
Train Epoch: 389 [20480/90000 (23%)]	Loss: -7.3899	Cost: 6.25s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -7.6726	Cost: 9.62s
Train Epoch: 389 [61440/90000 (68%)]	Loss: -7.2587	Cost: 14.35s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -7.2079	Cost: 14.98s
Train Epoch: 389 	Average Loss: -6.9447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1427

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: -3.6539	Cost: 26.81s
Train Epoch: 390 [20480/90000 (23%)]	Loss: -7.5541	Cost: 6.71s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -7.3990	Cost: 10.30s
Train Epoch: 390 [61440/90000 (68%)]	Loss: -7.1415	Cost: 6.12s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -7.0900	Cost: 10.53s
Train Epoch: 390 	Average Loss: -6.9550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2301

Saving model as e390_model.pt & e390_waveforms_supplementary.hdf5
Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: -3.2448	Cost: 24.37s
Train Epoch: 391 [20480/90000 (23%)]	Loss: -7.5031	Cost: 8.70s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -7.4754	Cost: 8.62s
Train Epoch: 391 [61440/90000 (68%)]	Loss: -6.9651	Cost: 8.31s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -7.4804	Cost: 5.79s
Train Epoch: 391 	Average Loss: -6.9642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1883

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: -3.8546	Cost: 25.13s
Train Epoch: 392 [20480/90000 (23%)]	Loss: -7.4921	Cost: 6.37s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -7.4547	Cost: 10.16s
Train Epoch: 392 [61440/90000 (68%)]	Loss: -7.3104	Cost: 6.73s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -7.4495	Cost: 11.40s
Train Epoch: 392 	Average Loss: -6.9569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1413

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: -3.6658	Cost: 24.51s
Train Epoch: 393 [20480/90000 (23%)]	Loss: -7.3662	Cost: 6.41s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -6.8997	Cost: 12.19s
Train Epoch: 393 [61440/90000 (68%)]	Loss: -7.3115	Cost: 6.21s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -7.4255	Cost: 7.73s
Train Epoch: 393 	Average Loss: -6.9636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2034

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: -2.9119	Cost: 26.64s
Train Epoch: 394 [20480/90000 (23%)]	Loss: -7.6601	Cost: 6.35s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -7.5156	Cost: 13.31s
Train Epoch: 394 [61440/90000 (68%)]	Loss: -6.9042	Cost: 15.22s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -7.3735	Cost: 6.82s
Train Epoch: 394 	Average Loss: -6.9612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9873

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: -3.0341	Cost: 24.02s
Train Epoch: 395 [20480/90000 (23%)]	Loss: -7.5638	Cost: 6.54s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -7.4045	Cost: 9.70s
Train Epoch: 395 [61440/90000 (68%)]	Loss: -7.1472	Cost: 6.03s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -7.5352	Cost: 13.61s
Train Epoch: 395 	Average Loss: -6.9386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1132

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: -3.6995	Cost: 23.91s
Train Epoch: 396 [20480/90000 (23%)]	Loss: -7.5473	Cost: 8.78s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -7.1761	Cost: 8.83s
Train Epoch: 396 [61440/90000 (68%)]	Loss: -7.0187	Cost: 7.56s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -7.4851	Cost: 5.87s
Train Epoch: 396 	Average Loss: -6.9649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2077

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: -3.6407	Cost: 24.46s
Train Epoch: 397 [20480/90000 (23%)]	Loss: -7.3578	Cost: 6.18s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -7.4283	Cost: 11.63s
Train Epoch: 397 [61440/90000 (68%)]	Loss: -7.1681	Cost: 6.60s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -7.4061	Cost: 10.43s
Train Epoch: 397 	Average Loss: -6.9903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3136

Saving model as e397_model.pt & e397_waveforms_supplementary.hdf5
Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: -3.7377	Cost: 27.74s
Train Epoch: 398 [20480/90000 (23%)]	Loss: -7.0553	Cost: 6.10s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -7.2823	Cost: 11.91s
Train Epoch: 398 [61440/90000 (68%)]	Loss: -7.0740	Cost: 5.99s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -7.3460	Cost: 9.21s
Train Epoch: 398 	Average Loss: -7.0179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1369

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: -3.5977	Cost: 37.54s
Train Epoch: 399 [20480/90000 (23%)]	Loss: -7.6126	Cost: 15.06s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -7.5564	Cost: 13.21s
Train Epoch: 399 [61440/90000 (68%)]	Loss: -7.0910	Cost: 11.55s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -7.5017	Cost: 5.84s
Train Epoch: 399 	Average Loss: -6.9569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9051

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: -3.8354	Cost: 28.51s
Train Epoch: 400 [20480/90000 (23%)]	Loss: -7.4557	Cost: 6.77s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -7.2385	Cost: 9.00s
Train Epoch: 400 [61440/90000 (68%)]	Loss: -7.4725	Cost: 12.34s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -7.2533	Cost: 14.97s
Train Epoch: 400 	Average Loss: -6.9307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0005

Stopping timer.
Training time (including validation): 92625.90986394882 seconds
Saving model
Transfer learning by starting with alpha=0.6!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 37.1154	Cost: 24.84s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 13.5798	Cost: 6.04s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 11.0814	Cost: 10.77s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 9.5434	Cost: 6.01s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 8.9866	Cost: 10.56s
Train Epoch: 1 	Average Loss: 12.6288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1500

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 8.2587	Cost: 24.06s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 7.1454	Cost: 6.28s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 6.7246	Cost: 12.49s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 6.6212	Cost: 6.04s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 6.2173	Cost: 6.82s
Train Epoch: 2 	Average Loss: 7.0887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2872

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 6.3664	Cost: 35.53s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 5.9790	Cost: 15.35s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 5.7893	Cost: 14.35s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 5.3509	Cost: 8.96s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 5.8090	Cost: 5.76s
Train Epoch: 3 	Average Loss: 5.8909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5253

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 5.6538	Cost: 28.90s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 5.2496	Cost: 6.15s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 5.1956	Cost: 13.30s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 5.4816	Cost: 14.76s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 5.4712	Cost: 11.30s
Train Epoch: 4 	Average Loss: 5.3854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1692

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 5.3785	Cost: 26.41s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 5.2283	Cost: 6.15s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 4.7054	Cost: 11.17s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 4.8636	Cost: 13.30s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 4.9275	Cost: 14.76s
Train Epoch: 5 	Average Loss: 5.0734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9624

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 5.1179	Cost: 24.40s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 4.6568	Cost: 6.17s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 4.7185	Cost: 9.73s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 4.4993	Cost: 6.09s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 5.1605	Cost: 11.66s
Train Epoch: 6 	Average Loss: 4.8255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7716

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 5.0667	Cost: 28.89s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 4.4510	Cost: 8.59s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 4.4973	Cost: 8.96s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 4.5171	Cost: 8.75s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 4.8123	Cost: 6.66s
Train Epoch: 7 	Average Loss: 4.6604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7501

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 4.6767	Cost: 26.77s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 4.4533	Cost: 6.08s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 4.6141	Cost: 8.96s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 4.5161	Cost: 6.30s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 4.4192	Cost: 9.75s
Train Epoch: 8 	Average Loss: 4.5482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5550

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 4.5604	Cost: 26.11s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 4.0892	Cost: 6.15s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 4.2519	Cost: 12.17s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 4.2229	Cost: 6.17s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 4.4729	Cost: 6.99s
Train Epoch: 9 	Average Loss: 4.4185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5116

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 4.4052	Cost: 26.72s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 4.0885	Cost: 6.19s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 4.4424	Cost: 14.83s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 3.8075	Cost: 13.99s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 4.6406	Cost: 5.95s
Train Epoch: 10 	Average Loss: 4.3084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4702

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 4.9530	Cost: 23.60s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 3.8994	Cost: 6.31s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 4.1694	Cost: 8.80s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 3.7463	Cost: 6.45s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 4.4876	Cost: 18.81s
Train Epoch: 11 	Average Loss: 4.2187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2785

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 4.4171	Cost: 24.36s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 3.8099	Cost: 6.58s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 4.0301	Cost: 8.95s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 4.0965	Cost: 6.32s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 4.1535	Cost: 10.62s
Train Epoch: 12 	Average Loss: 4.0793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2639

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 4.2635	Cost: 23.93s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 3.9025	Cost: 6.12s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 3.8204	Cost: 10.13s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 3.5564	Cost: 8.47s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 4.2727	Cost: 8.25s
Train Epoch: 13 	Average Loss: 4.0392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1870

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 4.1814	Cost: 25.74s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 3.5875	Cost: 6.05s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 3.7374	Cost: 11.96s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 3.4668	Cost: 5.90s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 4.1646	Cost: 7.73s
Train Epoch: 14 	Average Loss: 3.8779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1557

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 3.8829	Cost: 28.10s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 3.5741	Cost: 6.13s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 3.9526	Cost: 13.22s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 3.3842	Cost: 14.69s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 4.0600	Cost: 13.44s
Train Epoch: 15 	Average Loss: 3.8261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1757

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 4.2609	Cost: 28.57s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 3.3063	Cost: 6.20s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 3.9471	Cost: 10.21s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 3.4860	Cost: 6.03s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 3.6184	Cost: 18.61s
Train Epoch: 16 	Average Loss: 3.7813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1021

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 4.2526	Cost: 26.61s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 3.4506	Cost: 8.37s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 3.1856	Cost: 10.63s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 3.1864	Cost: 6.14s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 3.7405	Cost: 11.88s
Train Epoch: 17 	Average Loss: 3.7019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9754

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 4.0434	Cost: 24.46s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 3.4604	Cost: 8.76s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 3.2125	Cost: 9.07s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 3.4569	Cost: 6.70s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 3.8821	Cost: 9.93s
Train Epoch: 18 	Average Loss: 3.6359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0904

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 3.6745	Cost: 23.98s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 3.5069	Cost: 6.34s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 3.6942	Cost: 9.79s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 3.2464	Cost: 8.97s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 3.7043	Cost: 8.96s
Train Epoch: 19 	Average Loss: 3.5520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1974

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 4.0679	Cost: 25.24s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 3.1362	Cost: 8.14s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 3.4213	Cost: 10.12s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 3.3172	Cost: 6.05s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 3.9102	Cost: 5.69s
Train Epoch: 20 	Average Loss: 3.6132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1306

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 4.1731	Cost: 26.43s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 3.6206	Cost: 14.36s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 3.5415	Cost: 15.11s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 3.3106	Cost: 10.53s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 3.7140	Cost: 5.76s
Train Epoch: 21 	Average Loss: 3.5911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1820

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 4.5530	Cost: 26.38s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 2.9334	Cost: 6.15s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 3.3361	Cost: 13.10s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 2.9521	Cost: 15.10s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 3.6552	Cost: 14.71s
Train Epoch: 22 	Average Loss: 3.4121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9105

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 3.9374	Cost: 24.60s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 3.0593	Cost: 6.37s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 3.2780	Cost: 11.19s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 2.9317	Cost: 5.97s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 3.2797	Cost: 20.11s
Train Epoch: 23 	Average Loss: 3.2822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9871

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 3.9953	Cost: 25.38s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 2.6598	Cost: 6.07s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 3.2062	Cost: 10.89s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 2.8045	Cost: 6.08s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 3.3377	Cost: 13.00s
Train Epoch: 24 	Average Loss: 3.2835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8116

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 3.8725	Cost: 24.82s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 3.3504	Cost: 6.96s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 2.9811	Cost: 9.50s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 3.0623	Cost: 8.48s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 3.3785	Cost: 8.29s
Train Epoch: 25 	Average Loss: 3.2413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8892

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 3.9643	Cost: 28.92s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 2.8156	Cost: 6.14s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 2.8597	Cost: 12.07s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 2.7575	Cost: 5.99s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 3.3714	Cost: 7.46s
Train Epoch: 26 	Average Loss: 3.2348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8228

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 3.6420	Cost: 27.17s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 2.6757	Cost: 9.51s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 3.2208	Cost: 15.17s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 2.9457	Cost: 9.92s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 3.2080	Cost: 10.87s
Train Epoch: 27 	Average Loss: 3.0831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7169

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 3.9679	Cost: 25.74s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 3.2181	Cost: 8.35s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 2.6111	Cost: 10.60s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 2.6033	Cost: 15.23s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 3.1754	Cost: 12.88s
Train Epoch: 28 	Average Loss: 3.0675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8647

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 3.8006	Cost: 24.53s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 2.1965	Cost: 6.28s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 2.9841	Cost: 13.43s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 2.8684	Cost: 6.13s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 3.1753	Cost: 20.34s
Train Epoch: 29 	Average Loss: 2.9843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8218

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 3.7444	Cost: 24.45s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 2.5753	Cost: 6.01s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 2.6647	Cost: 8.88s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 2.9016	Cost: 6.11s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 3.2781	Cost: 11.54s
Train Epoch: 30 	Average Loss: 2.9225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6035

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 3.6370	Cost: 25.80s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 2.5196	Cost: 6.90s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 2.6566	Cost: 9.73s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 2.6829	Cost: 8.36s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 2.9623	Cost: 8.23s
Train Epoch: 31 	Average Loss: 2.9794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9456

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 3.5382	Cost: 25.85s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 2.6358	Cost: 5.99s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 2.5077	Cost: 11.97s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 2.3138	Cost: 5.88s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 2.6451	Cost: 5.90s
Train Epoch: 32 	Average Loss: 2.9251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6161

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 3.6442	Cost: 28.45s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 2.6465	Cost: 5.98s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 2.6843	Cost: 16.10s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 2.4512	Cost: 13.61s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 2.7534	Cost: 10.07s
Train Epoch: 33 	Average Loss: 2.7659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5261

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 3.7568	Cost: 27.99s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 2.3812	Cost: 6.17s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 2.7488	Cost: 8.47s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 2.5496	Cost: 15.01s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 3.3460	Cost: 14.62s
Train Epoch: 34 	Average Loss: 2.7901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7431

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 3.5709	Cost: 24.39s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 2.5969	Cost: 6.15s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 2.7160	Cost: 9.17s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 2.3486	Cost: 6.17s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 3.1055	Cost: 10.41s
Train Epoch: 35 	Average Loss: 2.8665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8284

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 3.9052	Cost: 26.77s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 2.3528	Cost: 6.94s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 2.4147	Cost: 9.22s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 2.3748	Cost: 8.60s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 2.8668	Cost: 8.23s
Train Epoch: 36 	Average Loss: 2.7024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7000

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 3.7228	Cost: 25.92s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 2.1516	Cost: 12.23s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 2.5021	Cost: 6.32s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 2.1426	Cost: 6.03s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 2.7706	Cost: 6.22s
Train Epoch: 37 	Average Loss: 2.6470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3498

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 3.4232	Cost: 26.90s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 1.9983	Cost: 12.02s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 2.1918	Cost: 14.75s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 2.3868	Cost: 7.75s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 2.7990	Cost: 11.44s
Train Epoch: 38 	Average Loss: 2.6286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5969

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 3.7290	Cost: 23.97s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 2.3051	Cost: 6.34s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 2.5045	Cost: 9.53s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 2.0544	Cost: 6.07s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 2.6710	Cost: 19.33s
Train Epoch: 39 	Average Loss: 2.5873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3828

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 3.5412	Cost: 26.35s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 2.1399	Cost: 6.17s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 2.8686	Cost: 11.17s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 2.3255	Cost: 6.16s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 2.6396	Cost: 15.83s
Train Epoch: 40 	Average Loss: 2.5535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5961

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 3.5989	Cost: 23.69s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 2.4490	Cost: 8.60s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 2.2487	Cost: 8.66s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 2.0554	Cost: 8.33s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 2.4734	Cost: 5.66s
Train Epoch: 41 	Average Loss: 2.6007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6586

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 3.3673	Cost: 24.02s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 1.9526	Cost: 6.18s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 2.8481	Cost: 8.51s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 2.1018	Cost: 6.52s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 2.8033	Cost: 9.55s
Train Epoch: 42 	Average Loss: 2.5978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6207

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 3.4610	Cost: 25.33s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 2.1118	Cost: 6.19s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 2.3595	Cost: 13.21s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 2.1387	Cost: 5.92s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 2.4196	Cost: 5.91s
Train Epoch: 43 	Average Loss: 2.4447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5186

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 3.7304	Cost: 32.39s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 2.2338	Cost: 6.15s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 2.2481	Cost: 13.90s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 2.2940	Cost: 14.81s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 2.3486	Cost: 12.88s
Train Epoch: 44 	Average Loss: 2.5022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4560

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 3.4358	Cost: 27.72s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 2.0800	Cost: 6.39s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 2.4168	Cost: 9.55s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 2.4383	Cost: 6.08s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 2.6270	Cost: 14.47s
Train Epoch: 45 	Average Loss: 2.4967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5124

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 3.2896	Cost: 25.20s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 1.9070	Cost: 8.93s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 2.2082	Cost: 8.98s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 1.9802	Cost: 6.24s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 2.2029	Cost: 7.46s
Train Epoch: 46 	Average Loss: 2.4086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6758

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 3.3769	Cost: 25.34s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 1.9276	Cost: 5.99s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 2.4289	Cost: 12.03s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 1.9593	Cost: 8.98s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 2.2601	Cost: 11.94s
Train Epoch: 47 	Average Loss: 2.3529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5999

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 3.4609	Cost: 25.21s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 2.3218	Cost: 12.25s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 2.2547	Cost: 6.22s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 1.9974	Cost: 6.24s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 2.4147	Cost: 7.88s
Train Epoch: 48 	Average Loss: 2.4592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6640

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 3.0164	Cost: 28.18s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 2.2536	Cost: 11.29s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 2.1665	Cost: 14.93s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 1.9058	Cost: 13.70s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 2.6314	Cost: 6.11s
Train Epoch: 49 	Average Loss: 2.3305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4791

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 3.4451	Cost: 24.61s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 2.1023	Cost: 6.33s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 2.3153	Cost: 10.35s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 2.1127	Cost: 11.20s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 2.1999	Cost: 14.84s
Train Epoch: 50 	Average Loss: 2.3102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4351

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 3.4206	Cost: 23.66s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 1.7057	Cost: 6.32s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 1.9296	Cost: 10.85s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 1.7707	Cost: 6.18s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 2.2703	Cost: 12.77s
Train Epoch: 51 	Average Loss: 2.1949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3786

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 3.2728	Cost: 24.43s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 1.8192	Cost: 7.88s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 2.1161	Cost: 8.70s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 1.7741	Cost: 8.49s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 2.1054	Cost: 8.38s
Train Epoch: 52 	Average Loss: 2.1592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3640

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 3.4893	Cost: 26.79s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 1.6403	Cost: 12.26s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 1.5213	Cost: 6.30s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 1.9355	Cost: 6.06s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 2.3847	Cost: 5.74s
Train Epoch: 53 	Average Loss: 2.2085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3352

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 3.6193	Cost: 27.72s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 1.7323	Cost: 14.56s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 1.9094	Cost: 13.95s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 1.6631	Cost: 5.92s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 2.1392	Cost: 11.95s
Train Epoch: 54 	Average Loss: 2.1227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3242

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 3.5344	Cost: 28.27s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 1.4404	Cost: 8.46s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 2.2260	Cost: 11.23s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 1.6345	Cost: 6.14s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 2.2465	Cost: 21.07s
Train Epoch: 55 	Average Loss: 2.1366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5078

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 3.2917	Cost: 24.29s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 2.0409	Cost: 6.07s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 2.1112	Cost: 13.21s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 1.3457	Cost: 7.51s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 2.0484	Cost: 13.78s
Train Epoch: 56 	Average Loss: 2.0899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3216

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 3.2672	Cost: 25.26s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 1.5945	Cost: 6.83s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 1.6105	Cost: 9.76s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 1.6239	Cost: 8.78s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 2.0942	Cost: 8.91s
Train Epoch: 57 	Average Loss: 2.0933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3725

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 2.9879	Cost: 24.43s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 1.6155	Cost: 11.62s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 1.6477	Cost: 7.43s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 1.2374	Cost: 6.28s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 2.4477	Cost: 5.71s
Train Epoch: 58 	Average Loss: 2.0424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3876

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 3.2526	Cost: 28.66s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 1.7037	Cost: 14.87s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 2.0712	Cost: 9.71s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 1.7818	Cost: 10.26s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 1.9904	Cost: 5.99s
Train Epoch: 59 	Average Loss: 1.9813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3539

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 3.2101	Cost: 26.47s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 1.6591	Cost: 6.17s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 1.5222	Cost: 12.91s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 1.4754	Cost: 15.02s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 1.7534	Cost: 12.43s
Train Epoch: 60 	Average Loss: 1.9375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2464

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 3.2941	Cost: 25.29s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 1.6314	Cost: 6.16s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 2.0799	Cost: 10.26s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 1.3989	Cost: 6.89s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 2.1567	Cost: 19.23s
Train Epoch: 61 	Average Loss: 1.9631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2735

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 3.3443	Cost: 25.35s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 1.5645	Cost: 6.23s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 1.3105	Cost: 9.15s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 1.3635	Cost: 6.11s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 1.8537	Cost: 10.83s
Train Epoch: 62 	Average Loss: 1.8481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3183

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 2.9997	Cost: 25.43s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 1.3063	Cost: 8.04s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 2.0148	Cost: 9.20s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 1.3957	Cost: 8.60s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 1.9917	Cost: 8.53s
Train Epoch: 63 	Average Loss: 1.9175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5220

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 3.5390	Cost: 27.70s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 1.4423	Cost: 12.12s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 1.8065	Cost: 6.47s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 1.2765	Cost: 6.04s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 1.9268	Cost: 5.80s
Train Epoch: 64 	Average Loss: 1.8720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4251

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 3.1998	Cost: 26.25s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 1.1607	Cost: 10.48s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 1.5004	Cost: 15.24s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 1.1871	Cost: 9.15s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 1.6755	Cost: 9.27s
Train Epoch: 65 	Average Loss: 1.8205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3697

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 3.2564	Cost: 23.89s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 1.4922	Cost: 6.50s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 1.5285	Cost: 9.66s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 1.2475	Cost: 5.95s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 1.8286	Cost: 19.94s
Train Epoch: 66 	Average Loss: 1.7902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3758

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 3.6326	Cost: 23.47s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 1.1240	Cost: 6.44s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 1.4662	Cost: 9.79s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 1.2878	Cost: 6.26s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 1.7927	Cost: 12.22s
Train Epoch: 67 	Average Loss: 1.7927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1937

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 2.9945	Cost: 24.12s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 1.2376	Cost: 8.73s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 1.8424	Cost: 8.97s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 1.6313	Cost: 7.93s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 1.8882	Cost: 5.73s
Train Epoch: 68 	Average Loss: 1.8596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3390

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 3.6169	Cost: 27.00s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 1.7851	Cost: 6.00s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 1.9116	Cost: 8.78s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 1.6210	Cost: 5.91s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 1.7046	Cost: 10.01s
Train Epoch: 69 	Average Loss: 1.7998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3813

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 3.1031	Cost: 30.47s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 1.4249	Cost: 5.96s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 1.6910	Cost: 14.38s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 1.3055	Cost: 6.90s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 1.9660	Cost: 5.99s
Train Epoch: 70 	Average Loss: 1.7842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2983

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 3.1512	Cost: 33.26s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 1.6388	Cost: 6.49s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 1.3297	Cost: 9.30s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 1.5067	Cost: 10.24s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 1.6799	Cost: 14.66s
Train Epoch: 71 	Average Loss: 1.7547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3918

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 3.1314	Cost: 27.49s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 1.3891	Cost: 6.28s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 1.1594	Cost: 10.64s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 1.1968	Cost: 6.37s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 1.9717	Cost: 10.83s
Train Epoch: 72 	Average Loss: 1.6778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3054

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 2.9545	Cost: 24.49s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 1.1026	Cost: 8.96s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 1.5838	Cost: 9.04s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 1.1609	Cost: 8.77s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 1.4768	Cost: 7.19s
Train Epoch: 73 	Average Loss: 1.6202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3564

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 3.3383	Cost: 24.35s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 0.8220	Cost: 6.06s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 1.5331	Cost: 9.15s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 1.1726	Cost: 6.29s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 1.3990	Cost: 14.89s
Train Epoch: 74 	Average Loss: 1.5723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0649

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 2.8730	Cost: 25.62s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 1.2449	Cost: 6.26s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 1.0442	Cost: 12.04s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 1.3686	Cost: 5.96s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 1.5394	Cost: 6.08s
Train Epoch: 75 	Average Loss: 1.5388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1330

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 2.8688	Cost: 26.41s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 1.4569	Cost: 8.13s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 1.5557	Cost: 15.18s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 0.7823	Cost: 14.16s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 1.3062	Cost: 8.39s
Train Epoch: 76 	Average Loss: 1.4689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1478

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 2.9220	Cost: 26.80s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 0.8996	Cost: 6.19s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 0.9114	Cost: 16.29s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 1.3002	Cost: 14.81s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 1.6198	Cost: 13.90s
Train Epoch: 77 	Average Loss: 1.5917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3244

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 3.0936	Cost: 24.32s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 1.0935	Cost: 6.39s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 1.2337	Cost: 10.23s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 0.9066	Cost: 6.01s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 1.3529	Cost: 19.87s
Train Epoch: 78 	Average Loss: 1.4156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2390

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 3.1734	Cost: 24.66s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 1.2326	Cost: 6.05s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 1.1023	Cost: 9.75s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 0.8655	Cost: 6.08s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 1.5666	Cost: 11.47s
Train Epoch: 79 	Average Loss: 1.4309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0508

Saving model as e79_model.pt & e79_waveforms_supplementary.hdf5
Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 3.0245	Cost: 28.62s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 0.7735	Cost: 7.57s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 1.2775	Cost: 9.85s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 1.0886	Cost: 8.43s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 1.8089	Cost: 8.37s
Train Epoch: 80 	Average Loss: 1.3482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0546

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 2.9626	Cost: 32.67s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 0.9603	Cost: 10.74s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 0.8448	Cost: 6.29s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 0.9657	Cost: 6.06s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 1.6347	Cost: 5.87s
Train Epoch: 81 	Average Loss: 1.3173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0078

Saving model as e81_model.pt & e81_waveforms_supplementary.hdf5
Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 2.9713	Cost: 27.39s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 1.0242	Cost: 15.48s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 0.9212	Cost: 12.77s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 0.6876	Cost: 9.28s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 1.5733	Cost: 8.55s
Train Epoch: 82 	Average Loss: 1.3458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2707

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 3.1576	Cost: 32.81s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 1.0208	Cost: 7.15s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 1.2349	Cost: 10.57s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 0.8618	Cost: 6.01s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 1.1916	Cost: 19.08s
Train Epoch: 83 	Average Loss: 1.3431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3313

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 3.2212	Cost: 23.26s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 0.6995	Cost: 6.22s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 0.8781	Cost: 16.01s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 0.7273	Cost: 6.61s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 1.4014	Cost: 16.14s
Train Epoch: 84 	Average Loss: 1.2267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1332

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 3.1103	Cost: 25.71s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 1.1636	Cost: 6.07s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 0.6057	Cost: 10.35s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 0.6912	Cost: 8.69s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 1.4630	Cost: 8.91s
Train Epoch: 85 	Average Loss: 1.2742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2683

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 3.4344	Cost: 27.58s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 0.9970	Cost: 10.72s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 1.0088	Cost: 6.03s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 0.9628	Cost: 5.96s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 1.1663	Cost: 9.48s
Train Epoch: 86 	Average Loss: 1.2230
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9713

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 2.9033	Cost: 30.16s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 0.5230	Cost: 11.96s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 0.6389	Cost: 8.68s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 1.0064	Cost: 9.37s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 1.1536	Cost: 5.88s
Train Epoch: 87 	Average Loss: 1.1682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0552

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 2.7128	Cost: 30.35s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 0.5350	Cost: 6.00s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 0.9336	Cost: 16.22s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 0.9844	Cost: 11.63s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 1.4877	Cost: 11.77s
Train Epoch: 88 	Average Loss: 1.2180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2842

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 2.9527	Cost: 25.07s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 0.3780	Cost: 6.21s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 0.9460	Cost: 9.72s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 1.0154	Cost: 6.03s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 1.2125	Cost: 17.24s
Train Epoch: 89 	Average Loss: 1.1760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2316

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 3.2339	Cost: 28.32s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 0.6815	Cost: 8.69s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 0.6619	Cost: 7.77s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 0.4093	Cost: 6.13s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 1.0990	Cost: 9.52s
Train Epoch: 90 	Average Loss: 1.0612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2091

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 2.7834	Cost: 29.34s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 0.6253	Cost: 7.00s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 0.9216	Cost: 9.10s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 1.0013	Cost: 8.49s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 1.4940	Cost: 8.36s
Train Epoch: 91 	Average Loss: 1.1730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1601

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 3.3100	Cost: 28.40s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 0.5782	Cost: 8.71s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 0.9512	Cost: 9.66s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 0.5922	Cost: 6.11s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 1.1457	Cost: 11.98s
Train Epoch: 92 	Average Loss: 1.2299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0454

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 3.1302	Cost: 24.82s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 0.8006	Cost: 10.49s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 0.9258	Cost: 15.59s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 0.6327	Cost: 8.71s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 1.2837	Cost: 10.15s
Train Epoch: 93 	Average Loss: 1.0979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2065

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 3.4603	Cost: 24.55s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 0.7041	Cost: 6.38s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 0.9797	Cost: 8.99s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 0.8186	Cost: 6.13s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 0.9344	Cost: 20.97s
Train Epoch: 94 	Average Loss: 1.0891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3628

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 3.3006	Cost: 24.91s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 0.7687	Cost: 6.33s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 0.9269	Cost: 9.25s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 0.7882	Cost: 6.48s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 1.0134	Cost: 11.77s
Train Epoch: 95 	Average Loss: 1.1179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2795

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 3.2251	Cost: 24.19s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 0.8642	Cost: 6.34s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 0.8873	Cost: 8.50s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 0.9291	Cost: 8.83s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 0.7282	Cost: 8.27s
Train Epoch: 96 	Average Loss: 1.0588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1733

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 3.1518	Cost: 26.86s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 0.7102	Cost: 6.59s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 0.7630	Cost: 9.62s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 0.7236	Cost: 9.88s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 0.9270	Cost: 5.93s
Train Epoch: 97 	Average Loss: 1.0775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1145

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 2.9497	Cost: 29.08s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 0.4843	Cost: 6.18s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 0.7282	Cost: 9.92s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 0.6680	Cost: 6.02s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 1.0922	Cost: 17.92s
Train Epoch: 98 	Average Loss: 1.0058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1246

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 2.6262	Cost: 27.22s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 0.5042	Cost: 6.14s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 0.8647	Cost: 10.49s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 0.6537	Cost: 6.37s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 0.9004	Cost: 11.04s
Train Epoch: 99 	Average Loss: 0.9757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0195

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 2.3561	Cost: 24.33s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 0.2509	Cost: 6.34s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 0.3768	Cost: 11.20s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 0.6929	Cost: 8.64s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 0.8321	Cost: 8.87s
Train Epoch: 100 	Average Loss: 0.8762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2855

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 2.7271	Cost: 25.71s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 0.2714	Cost: 9.33s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 0.4730	Cost: 9.10s
Train Epoch: 101 [61440/90000 (68%)]	Loss: -0.1855	Cost: 6.09s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 0.8653	Cost: 6.66s
Train Epoch: 101 	Average Loss: 0.8326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0611

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 3.3297	Cost: 26.86s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 0.5236	Cost: 6.07s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 0.4833	Cost: 13.85s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 0.3511	Cost: 14.83s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 0.8239	Cost: 9.54s
Train Epoch: 102 	Average Loss: 0.8223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0231

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 2.4523	Cost: 23.92s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 0.6837	Cost: 6.42s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 0.9962	Cost: 10.01s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 0.7393	Cost: 6.15s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 1.0016	Cost: 12.19s
Train Epoch: 103 	Average Loss: 1.0838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3418

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 3.2502	Cost: 23.35s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 0.4932	Cost: 8.65s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 0.6933	Cost: 8.90s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 0.6330	Cost: 8.92s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 1.2824	Cost: 7.16s
Train Epoch: 104 	Average Loss: 1.0176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0704

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 3.5100	Cost: 23.43s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 0.9127	Cost: 6.44s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 0.4320	Cost: 8.29s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 0.4742	Cost: 6.11s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 1.2777	Cost: 8.98s
Train Epoch: 105 	Average Loss: 1.0392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0286

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 3.0947	Cost: 26.61s
Train Epoch: 106 [20480/90000 (23%)]	Loss: -0.0582	Cost: 10.45s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 0.8484	Cost: 6.23s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 0.4691	Cost: 12.01s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 0.8757	Cost: 6.00s
Train Epoch: 106 	Average Loss: 0.8867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8278

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 2.8938	Cost: 35.51s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 0.1390	Cost: 6.14s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 0.6238	Cost: 14.02s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 0.0133	Cost: 15.00s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 0.5288	Cost: 14.10s
Train Epoch: 107 	Average Loss: 0.7603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9691

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 2.7192	Cost: 28.20s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 0.3238	Cost: 6.53s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 0.3375	Cost: 9.89s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 0.4958	Cost: 6.08s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 0.9403	Cost: 18.45s
Train Epoch: 108 	Average Loss: 0.7423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1109

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 2.7844	Cost: 24.29s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 0.3515	Cost: 6.29s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 0.6622	Cost: 12.35s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 0.2847	Cost: 7.65s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 0.8665	Cost: 10.27s
Train Epoch: 109 	Average Loss: 0.7993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0698

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 2.9109	Cost: 25.37s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 0.3820	Cost: 6.14s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 0.5728	Cost: 11.44s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 0.2290	Cost: 8.60s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 0.8009	Cost: 8.26s
Train Epoch: 110 	Average Loss: 0.6877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0465

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 2.5867	Cost: 25.25s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 0.2955	Cost: 7.25s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 0.1984	Cost: 10.99s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 0.4808	Cost: 6.14s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 0.6509	Cost: 5.80s
Train Epoch: 111 	Average Loss: 0.6536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9946

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 3.0467	Cost: 27.49s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 0.3305	Cost: 6.31s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 0.0404	Cost: 14.46s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 0.1582	Cost: 14.60s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 0.7851	Cost: 10.89s
Train Epoch: 112 	Average Loss: 0.5949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8528

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 2.9240	Cost: 26.82s
Train Epoch: 113 [20480/90000 (23%)]	Loss: -0.0235	Cost: 6.19s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 0.3431	Cost: 9.54s
Train Epoch: 113 [61440/90000 (68%)]	Loss: -0.0316	Cost: 8.29s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 0.8408	Cost: 15.72s
Train Epoch: 113 	Average Loss: 0.6260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1486

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 2.7865	Cost: 26.51s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 0.0376	Cost: 6.53s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 0.2478	Cost: 9.69s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 0.1450	Cost: 6.09s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 0.5639	Cost: 10.59s
Train Epoch: 114 	Average Loss: 0.5649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8924

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 2.2956	Cost: 26.95s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 0.0161	Cost: 8.11s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 0.2515	Cost: 9.01s
Train Epoch: 115 [61440/90000 (68%)]	Loss: -0.2822	Cost: 8.64s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 0.6128	Cost: 8.30s
Train Epoch: 115 	Average Loss: 0.5196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7677

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 3.2556	Cost: 24.14s
Train Epoch: 116 [20480/90000 (23%)]	Loss: -0.2109	Cost: 12.23s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 0.2000	Cost: 6.15s
Train Epoch: 116 [61440/90000 (68%)]	Loss: -0.3796	Cost: 6.06s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 0.3025	Cost: 9.08s
Train Epoch: 116 	Average Loss: 0.4174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1128

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 2.8682	Cost: 26.51s
Train Epoch: 117 [20480/90000 (23%)]	Loss: -0.0574	Cost: 6.35s
Train Epoch: 117 [40960/90000 (45%)]	Loss: -0.0319	Cost: 12.66s
Train Epoch: 117 [61440/90000 (68%)]	Loss: -0.5122	Cost: 15.27s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 0.6484	Cost: 6.87s
Train Epoch: 117 	Average Loss: 0.3804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1285

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 3.0005	Cost: 24.60s
Train Epoch: 118 [20480/90000 (23%)]	Loss: -0.1667	Cost: 6.16s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 0.1291	Cost: 9.51s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 0.1348	Cost: 6.13s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 0.5652	Cost: 10.82s
Train Epoch: 118 	Average Loss: 0.5204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8424

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 2.8775	Cost: 24.18s
Train Epoch: 119 [20480/90000 (23%)]	Loss: -0.0848	Cost: 8.84s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 0.3975	Cost: 9.13s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 0.1702	Cost: 8.66s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 0.6460	Cost: 6.39s
Train Epoch: 119 	Average Loss: 0.4455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7996

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 2.8051	Cost: 24.61s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 0.2242	Cost: 6.13s
Train Epoch: 120 [40960/90000 (45%)]	Loss: -0.0136	Cost: 11.80s
Train Epoch: 120 [61440/90000 (68%)]	Loss: -0.1408	Cost: 6.03s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 0.2829	Cost: 10.55s
Train Epoch: 120 	Average Loss: 0.3840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9712

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 2.4024	Cost: 27.85s
Train Epoch: 121 [20480/90000 (23%)]	Loss: -0.1598	Cost: 13.75s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 0.0527	Cost: 6.59s
Train Epoch: 121 [61440/90000 (68%)]	Loss: -0.0495	Cost: 11.53s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 0.1490	Cost: 5.90s
Train Epoch: 121 	Average Loss: 0.2944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9455

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 3.1622	Cost: 35.77s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 0.0757	Cost: 6.17s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 0.0588	Cost: 9.01s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 0.0687	Cost: 9.02s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 0.4052	Cost: 14.71s
Train Epoch: 122 	Average Loss: 0.4627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9605

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 3.2789	Cost: 27.86s
Train Epoch: 123 [20480/90000 (23%)]	Loss: -0.1280	Cost: 6.81s
Train Epoch: 123 [40960/90000 (45%)]	Loss: -0.0608	Cost: 9.81s
Train Epoch: 123 [61440/90000 (68%)]	Loss: -0.1413	Cost: 6.42s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 0.0571	Cost: 12.97s
Train Epoch: 123 	Average Loss: 0.4489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7647

Saving model as e123_model.pt & e123_waveforms_supplementary.hdf5
Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 2.1718	Cost: 25.38s
Train Epoch: 124 [20480/90000 (23%)]	Loss: -0.1544	Cost: 8.97s
Train Epoch: 124 [40960/90000 (45%)]	Loss: -0.3469	Cost: 8.86s
Train Epoch: 124 [61440/90000 (68%)]	Loss: -0.1332	Cost: 5.95s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 0.6523	Cost: 8.95s
Train Epoch: 124 	Average Loss: 0.2955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8860

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 2.9094	Cost: 24.00s
Train Epoch: 125 [20480/90000 (23%)]	Loss: -0.1316	Cost: 6.13s
Train Epoch: 125 [40960/90000 (45%)]	Loss: -0.1289	Cost: 10.18s
Train Epoch: 125 [61440/90000 (68%)]	Loss: -0.2238	Cost: 8.94s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 0.3218	Cost: 8.68s
Train Epoch: 125 	Average Loss: 0.3878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8334

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 2.4369	Cost: 25.21s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 0.2537	Cost: 12.22s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 0.2469	Cost: 6.23s
Train Epoch: 126 [61440/90000 (68%)]	Loss: -0.0265	Cost: 6.08s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 0.6317	Cost: 6.00s
Train Epoch: 126 	Average Loss: 0.4797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8424

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 2.4081	Cost: 29.89s
Train Epoch: 127 [20480/90000 (23%)]	Loss: -0.4569	Cost: 15.05s
Train Epoch: 127 [40960/90000 (45%)]	Loss: -0.0711	Cost: 7.07s
Train Epoch: 127 [61440/90000 (68%)]	Loss: -0.4823	Cost: 11.80s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 0.2920	Cost: 6.00s
Train Epoch: 127 	Average Loss: 0.2570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7206

Saving model as e127_model.pt & e127_waveforms_supplementary.hdf5
Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 2.8828	Cost: 28.07s
Train Epoch: 128 [20480/90000 (23%)]	Loss: -0.1523	Cost: 6.19s
Train Epoch: 128 [40960/90000 (45%)]	Loss: -0.1444	Cost: 14.55s
Train Epoch: 128 [61440/90000 (68%)]	Loss: -0.2228	Cost: 15.82s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 0.5469	Cost: 10.16s
Train Epoch: 128 	Average Loss: 0.2627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7150

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 2.9078	Cost: 24.95s
Train Epoch: 129 [20480/90000 (23%)]	Loss: -0.2146	Cost: 6.45s
Train Epoch: 129 [40960/90000 (45%)]	Loss: -0.2930	Cost: 10.45s
Train Epoch: 129 [61440/90000 (68%)]	Loss: -0.0955	Cost: 6.09s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 0.1293	Cost: 19.47s
Train Epoch: 129 	Average Loss: 0.2232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8239

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 2.7488	Cost: 22.93s
Train Epoch: 130 [20480/90000 (23%)]	Loss: -0.2465	Cost: 6.22s
Train Epoch: 130 [40960/90000 (45%)]	Loss: -0.0770	Cost: 9.92s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 0.0427	Cost: 6.14s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 0.3111	Cost: 13.02s
Train Epoch: 130 	Average Loss: 0.2072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9671

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 2.9918	Cost: 28.95s
Train Epoch: 131 [20480/90000 (23%)]	Loss: -0.7459	Cost: 8.71s
Train Epoch: 131 [40960/90000 (45%)]	Loss: -0.1017	Cost: 8.76s
Train Epoch: 131 [61440/90000 (68%)]	Loss: -0.5913	Cost: 8.26s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 0.0399	Cost: 5.76s
Train Epoch: 131 	Average Loss: 0.2143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8973

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 2.2591	Cost: 25.36s
Train Epoch: 132 [20480/90000 (23%)]	Loss: -0.2539	Cost: 6.22s
Train Epoch: 132 [40960/90000 (45%)]	Loss: -0.2664	Cost: 9.76s
Train Epoch: 132 [61440/90000 (68%)]	Loss: -0.4834	Cost: 7.16s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 0.2382	Cost: 9.84s
Train Epoch: 132 	Average Loss: 0.1706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7778

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 2.2411	Cost: 26.75s
Train Epoch: 133 [20480/90000 (23%)]	Loss: -0.3146	Cost: 6.12s
Train Epoch: 133 [40960/90000 (45%)]	Loss: -0.2984	Cost: 12.33s
Train Epoch: 133 [61440/90000 (68%)]	Loss: -0.1719	Cost: 6.13s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 0.2590	Cost: 5.87s
Train Epoch: 133 	Average Loss: 0.0657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7955

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 2.8343	Cost: 25.60s
Train Epoch: 134 [20480/90000 (23%)]	Loss: -0.4430	Cost: 6.78s
Train Epoch: 134 [40960/90000 (45%)]	Loss: -0.0142	Cost: 15.39s
Train Epoch: 134 [61440/90000 (68%)]	Loss: -0.4769	Cost: 12.78s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 0.1067	Cost: 6.71s
Train Epoch: 134 	Average Loss: 0.0939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7217

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 2.7426	Cost: 23.90s
Train Epoch: 135 [20480/90000 (23%)]	Loss: -0.5854	Cost: 6.55s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 0.0582	Cost: 8.66s
Train Epoch: 135 [61440/90000 (68%)]	Loss: -0.2846	Cost: 6.16s
Train Epoch: 135 [81920/90000 (91%)]	Loss: -0.1676	Cost: 11.29s
Train Epoch: 135 	Average Loss: 0.1777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8152

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 1.9790	Cost: 23.76s
Train Epoch: 136 [20480/90000 (23%)]	Loss: -0.4925	Cost: 5.99s
Train Epoch: 136 [40960/90000 (45%)]	Loss: -0.2275	Cost: 8.74s
Train Epoch: 136 [61440/90000 (68%)]	Loss: -0.1322	Cost: 8.62s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 0.3019	Cost: 8.22s
Train Epoch: 136 	Average Loss: 0.1643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8375

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 2.7923	Cost: 28.20s
Train Epoch: 137 [20480/90000 (23%)]	Loss: -0.5340	Cost: 6.17s
Train Epoch: 137 [40960/90000 (45%)]	Loss: -0.1055	Cost: 12.13s
Train Epoch: 137 [61440/90000 (68%)]	Loss: -0.3374	Cost: 5.88s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 0.0423	Cost: 6.94s
Train Epoch: 137 	Average Loss: 0.0720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6382

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 2.2683	Cost: 28.05s
Train Epoch: 138 [20480/90000 (23%)]	Loss: -0.8563	Cost: 7.50s
Train Epoch: 138 [40960/90000 (45%)]	Loss: -0.3073	Cost: 15.42s
Train Epoch: 138 [61440/90000 (68%)]	Loss: -0.3618	Cost: 14.42s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 0.0592	Cost: 8.46s
Train Epoch: 138 	Average Loss: -0.0875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6192

Saving model as e138_model.pt & e138_waveforms_supplementary.hdf5
Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 2.3590	Cost: 27.84s
Train Epoch: 139 [20480/90000 (23%)]	Loss: -0.6375	Cost: 6.34s
Train Epoch: 139 [40960/90000 (45%)]	Loss: -0.5120	Cost: 9.26s
Train Epoch: 139 [61440/90000 (68%)]	Loss: -0.3790	Cost: 13.20s
Train Epoch: 139 [81920/90000 (91%)]	Loss: -0.0644	Cost: 14.71s
Train Epoch: 139 	Average Loss: -0.1325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8593

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 2.7783	Cost: 27.54s
Train Epoch: 140 [20480/90000 (23%)]	Loss: -0.2837	Cost: 6.21s
Train Epoch: 140 [40960/90000 (45%)]	Loss: -0.5114	Cost: 10.55s
Train Epoch: 140 [61440/90000 (68%)]	Loss: -0.3481	Cost: 6.21s
Train Epoch: 140 [81920/90000 (91%)]	Loss: -0.2420	Cost: 10.83s
Train Epoch: 140 	Average Loss: -0.0180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8113

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 2.8299	Cost: 25.17s
Train Epoch: 141 [20480/90000 (23%)]	Loss: -0.7581	Cost: 8.98s
Train Epoch: 141 [40960/90000 (45%)]	Loss: -0.6694	Cost: 8.96s
Train Epoch: 141 [61440/90000 (68%)]	Loss: -0.7101	Cost: 7.82s
Train Epoch: 141 [81920/90000 (91%)]	Loss: -0.1742	Cost: 5.97s
Train Epoch: 141 	Average Loss: -0.1558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7002

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 2.4322	Cost: 24.59s
Train Epoch: 142 [20480/90000 (23%)]	Loss: -0.5215	Cost: 6.36s
Train Epoch: 142 [40960/90000 (45%)]	Loss: -0.5223	Cost: 9.70s
Train Epoch: 142 [61440/90000 (68%)]	Loss: -0.7025	Cost: 9.23s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 0.1888	Cost: 10.14s
Train Epoch: 142 	Average Loss: -0.1580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7374

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 2.5789	Cost: 24.82s
Train Epoch: 143 [20480/90000 (23%)]	Loss: -0.7235	Cost: 8.23s
Train Epoch: 143 [40960/90000 (45%)]	Loss: -0.5764	Cost: 10.06s
Train Epoch: 143 [61440/90000 (68%)]	Loss: -0.6290	Cost: 5.93s
Train Epoch: 143 [81920/90000 (91%)]	Loss: -0.1756	Cost: 5.62s
Train Epoch: 143 	Average Loss: -0.1576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7320

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 2.0494	Cost: 28.31s
Train Epoch: 144 [20480/90000 (23%)]	Loss: -0.8947	Cost: 13.68s
Train Epoch: 144 [40960/90000 (45%)]	Loss: -0.3605	Cost: 14.39s
Train Epoch: 144 [61440/90000 (68%)]	Loss: -0.3911	Cost: 11.94s
Train Epoch: 144 [81920/90000 (91%)]	Loss: -0.1245	Cost: 5.72s
Train Epoch: 144 	Average Loss: -0.1392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6515

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 2.5138	Cost: 26.92s
Train Epoch: 145 [20480/90000 (23%)]	Loss: -0.6894	Cost: 6.03s
Train Epoch: 145 [40960/90000 (45%)]	Loss: -0.4035	Cost: 13.54s
Train Epoch: 145 [61440/90000 (68%)]	Loss: -0.6049	Cost: 14.59s
Train Epoch: 145 [81920/90000 (91%)]	Loss: -0.3045	Cost: 14.26s
Train Epoch: 145 	Average Loss: -0.0604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6172

Saving model as e145_model.pt & e145_waveforms_supplementary.hdf5
Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 2.6104	Cost: 24.92s
Train Epoch: 146 [20480/90000 (23%)]	Loss: -0.6131	Cost: 6.17s
Train Epoch: 146 [40960/90000 (45%)]	Loss: -0.2583	Cost: 9.30s
Train Epoch: 146 [61440/90000 (68%)]	Loss: -0.5707	Cost: 6.01s
Train Epoch: 146 [81920/90000 (91%)]	Loss: -0.1166	Cost: 11.98s
Train Epoch: 146 	Average Loss: -0.1019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6540

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 2.8395	Cost: 26.04s
Train Epoch: 147 [20480/90000 (23%)]	Loss: -0.6874	Cost: 8.51s
Train Epoch: 147 [40960/90000 (45%)]	Loss: -0.4418	Cost: 8.64s
Train Epoch: 147 [61440/90000 (68%)]	Loss: -0.4331	Cost: 8.48s
Train Epoch: 147 [81920/90000 (91%)]	Loss: -0.0839	Cost: 6.98s
Train Epoch: 147 	Average Loss: -0.1052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5687

Saving model as e147_model.pt & e147_waveforms_supplementary.hdf5
Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 2.6131	Cost: 26.19s
Train Epoch: 148 [20480/90000 (23%)]	Loss: -0.6762	Cost: 7.81s
Train Epoch: 148 [40960/90000 (45%)]	Loss: -0.4542	Cost: 6.26s
Train Epoch: 148 [61440/90000 (68%)]	Loss: -0.7211	Cost: 6.02s
Train Epoch: 148 [81920/90000 (91%)]	Loss: -0.1859	Cost: 7.20s
Train Epoch: 148 	Average Loss: -0.1896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5395

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 3.1889	Cost: 30.74s
Train Epoch: 149 [20480/90000 (23%)]	Loss: -0.8725	Cost: 13.53s
Train Epoch: 149 [40960/90000 (45%)]	Loss: -0.7825	Cost: 6.06s
Train Epoch: 149 [61440/90000 (68%)]	Loss: -0.8697	Cost: 10.65s
Train Epoch: 149 [81920/90000 (91%)]	Loss: -0.5096	Cost: 7.21s
Train Epoch: 149 	Average Loss: -0.3151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7129

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 2.5455	Cost: 35.43s
Train Epoch: 150 [20480/90000 (23%)]	Loss: -0.6107	Cost: 6.30s
Train Epoch: 150 [40960/90000 (45%)]	Loss: -0.4370	Cost: 16.22s
Train Epoch: 150 [61440/90000 (68%)]	Loss: -0.7701	Cost: 12.01s
Train Epoch: 150 [81920/90000 (91%)]	Loss: -0.2652	Cost: 11.87s
Train Epoch: 150 	Average Loss: -0.2627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6534

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 2.3853	Cost: 34.00s
Train Epoch: 151 [20480/90000 (23%)]	Loss: -0.4866	Cost: 6.43s
Train Epoch: 151 [40960/90000 (45%)]	Loss: -0.4043	Cost: 11.15s
Train Epoch: 151 [61440/90000 (68%)]	Loss: -0.8602	Cost: 8.95s
Train Epoch: 151 [81920/90000 (91%)]	Loss: -0.3792	Cost: 15.32s
Train Epoch: 151 	Average Loss: -0.3593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5102

Saving model as e151_model.pt & e151_waveforms_supplementary.hdf5
Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 2.4813	Cost: 23.81s
Train Epoch: 152 [20480/90000 (23%)]	Loss: -0.8128	Cost: 8.39s
Train Epoch: 152 [40960/90000 (45%)]	Loss: -0.3419	Cost: 15.04s
Train Epoch: 152 [61440/90000 (68%)]	Loss: -0.7184	Cost: 6.15s
Train Epoch: 152 [81920/90000 (91%)]	Loss: -0.2186	Cost: 19.10s
Train Epoch: 152 	Average Loss: -0.3444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6238

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 2.2276	Cost: 23.73s
Train Epoch: 153 [20480/90000 (23%)]	Loss: -0.9539	Cost: 7.56s
Train Epoch: 153 [40960/90000 (45%)]	Loss: -0.7146	Cost: 8.90s
Train Epoch: 153 [61440/90000 (68%)]	Loss: -1.2649	Cost: 6.95s
Train Epoch: 153 [81920/90000 (91%)]	Loss: -0.4317	Cost: 10.13s
Train Epoch: 153 	Average Loss: -0.3928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8509

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 2.2092	Cost: 26.46s
Train Epoch: 154 [20480/90000 (23%)]	Loss: -0.7448	Cost: 6.04s
Train Epoch: 154 [40960/90000 (45%)]	Loss: -0.7037	Cost: 10.06s
Train Epoch: 154 [61440/90000 (68%)]	Loss: -1.0371	Cost: 8.43s
Train Epoch: 154 [81920/90000 (91%)]	Loss: -0.4307	Cost: 8.86s
Train Epoch: 154 	Average Loss: -0.3951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5427

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 2.1458	Cost: 26.66s
Train Epoch: 155 [20480/90000 (23%)]	Loss: -0.8776	Cost: 12.01s
Train Epoch: 155 [40960/90000 (45%)]	Loss: -0.6844	Cost: 6.20s
Train Epoch: 155 [61440/90000 (68%)]	Loss: -1.1102	Cost: 5.97s
Train Epoch: 155 [81920/90000 (91%)]	Loss: -0.5193	Cost: 6.18s
Train Epoch: 155 	Average Loss: -0.5034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7352

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 3.1036	Cost: 27.60s
Train Epoch: 156 [20480/90000 (23%)]	Loss: -0.9741	Cost: 14.74s
Train Epoch: 156 [40960/90000 (45%)]	Loss: -0.9307	Cost: 12.77s
Train Epoch: 156 [61440/90000 (68%)]	Loss: -0.5957	Cost: 7.86s
Train Epoch: 156 [81920/90000 (91%)]	Loss: -0.3738	Cost: 5.75s
Train Epoch: 156 	Average Loss: -0.2683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5096

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 2.1731	Cost: 28.60s
Train Epoch: 157 [20480/90000 (23%)]	Loss: -1.0370	Cost: 8.19s
Train Epoch: 157 [40960/90000 (45%)]	Loss: -0.3299	Cost: 15.17s
Train Epoch: 157 [61440/90000 (68%)]	Loss: -0.5614	Cost: 14.31s
Train Epoch: 157 [81920/90000 (91%)]	Loss: -0.4491	Cost: 8.13s
Train Epoch: 157 	Average Loss: -0.3124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5005

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 2.4404	Cost: 26.37s
Train Epoch: 158 [20480/90000 (23%)]	Loss: -0.7613	Cost: 6.14s
Train Epoch: 158 [40960/90000 (45%)]	Loss: -0.7668	Cost: 8.84s
Train Epoch: 158 [61440/90000 (68%)]	Loss: -0.9438	Cost: 15.03s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 0.0160	Cost: 14.10s
Train Epoch: 158 	Average Loss: -0.4262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5077

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 2.4865	Cost: 26.18s
Train Epoch: 159 [20480/90000 (23%)]	Loss: -1.3390	Cost: 6.20s
Train Epoch: 159 [40960/90000 (45%)]	Loss: -1.1023	Cost: 9.17s
Train Epoch: 159 [61440/90000 (68%)]	Loss: -1.0572	Cost: 6.19s
Train Epoch: 159 [81920/90000 (91%)]	Loss: -0.1784	Cost: 11.62s
Train Epoch: 159 	Average Loss: -0.4662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5293

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 2.0755	Cost: 28.60s
Train Epoch: 160 [20480/90000 (23%)]	Loss: -1.3364	Cost: 8.56s
Train Epoch: 160 [40960/90000 (45%)]	Loss: -1.0281	Cost: 8.69s
Train Epoch: 160 [61440/90000 (68%)]	Loss: -1.0525	Cost: 8.55s
Train Epoch: 160 [81920/90000 (91%)]	Loss: -0.2533	Cost: 6.99s
Train Epoch: 160 	Average Loss: -0.5772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4735

Saving model as e160_model.pt & e160_waveforms_supplementary.hdf5
Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 2.1324	Cost: 28.42s
Train Epoch: 161 [20480/90000 (23%)]	Loss: -1.0041	Cost: 6.13s
Train Epoch: 161 [40960/90000 (45%)]	Loss: -0.8107	Cost: 10.38s
Train Epoch: 161 [61440/90000 (68%)]	Loss: -1.4694	Cost: 6.92s
Train Epoch: 161 [81920/90000 (91%)]	Loss: -0.6087	Cost: 9.40s
Train Epoch: 161 	Average Loss: -0.5503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3263

Saving model as e161_model.pt & e161_waveforms_supplementary.hdf5
Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 2.7237	Cost: 32.08s
Train Epoch: 162 [20480/90000 (23%)]	Loss: -0.9328	Cost: 10.59s
Train Epoch: 162 [40960/90000 (45%)]	Loss: -0.8681	Cost: 6.21s
Train Epoch: 162 [61440/90000 (68%)]	Loss: -0.9846	Cost: 6.07s
Train Epoch: 162 [81920/90000 (91%)]	Loss: -0.0937	Cost: 5.79s
Train Epoch: 162 	Average Loss: -0.5890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5034

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 2.0111	Cost: 27.79s
Train Epoch: 163 [20480/90000 (23%)]	Loss: -1.0360	Cost: 15.24s
Train Epoch: 163 [40960/90000 (45%)]	Loss: -1.0097	Cost: 13.09s
Train Epoch: 163 [61440/90000 (68%)]	Loss: -0.9191	Cost: 8.77s
Train Epoch: 163 [81920/90000 (91%)]	Loss: -0.6650	Cost: 9.12s
Train Epoch: 163 	Average Loss: -0.6704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5052

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 2.2855	Cost: 27.42s
Train Epoch: 164 [20480/90000 (23%)]	Loss: -1.4788	Cost: 6.20s
Train Epoch: 164 [40960/90000 (45%)]	Loss: -1.3612	Cost: 11.46s
Train Epoch: 164 [61440/90000 (68%)]	Loss: -1.1398	Cost: 9.20s
Train Epoch: 164 [81920/90000 (91%)]	Loss: -0.4612	Cost: 18.98s
Train Epoch: 164 	Average Loss: -0.7400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1160

Saving model as e164_model.pt & e164_waveforms_supplementary.hdf5
Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 1.7339	Cost: 23.01s
Train Epoch: 165 [20480/90000 (23%)]	Loss: -1.3419	Cost: 6.00s
Train Epoch: 165 [40960/90000 (45%)]	Loss: -1.4023	Cost: 8.98s
Train Epoch: 165 [61440/90000 (68%)]	Loss: -0.9869	Cost: 6.22s
Train Epoch: 165 [81920/90000 (91%)]	Loss: -0.8390	Cost: 11.91s
Train Epoch: 165 	Average Loss: -0.8355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2119

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 1.8189	Cost: 25.59s
Train Epoch: 166 [20480/90000 (23%)]	Loss: -1.4423	Cost: 6.06s
Train Epoch: 166 [40960/90000 (45%)]	Loss: -1.0376	Cost: 12.32s
Train Epoch: 166 [61440/90000 (68%)]	Loss: -1.4732	Cost: 8.39s
Train Epoch: 166 [81920/90000 (91%)]	Loss: -1.0605	Cost: 8.24s
Train Epoch: 166 	Average Loss: -0.7951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4354

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 2.3216	Cost: 24.99s
Train Epoch: 167 [20480/90000 (23%)]	Loss: -1.5099	Cost: 6.12s
Train Epoch: 167 [40960/90000 (45%)]	Loss: -1.1080	Cost: 12.06s
Train Epoch: 167 [61440/90000 (68%)]	Loss: -1.3032	Cost: 6.00s
Train Epoch: 167 [81920/90000 (91%)]	Loss: -1.0399	Cost: 5.95s
Train Epoch: 167 	Average Loss: -0.8454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4711

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 2.1814	Cost: 28.76s
Train Epoch: 168 [20480/90000 (23%)]	Loss: -1.6565	Cost: 6.23s
Train Epoch: 168 [40960/90000 (45%)]	Loss: -1.2921	Cost: 13.24s
Train Epoch: 168 [61440/90000 (68%)]	Loss: -1.3638	Cost: 14.93s
Train Epoch: 168 [81920/90000 (91%)]	Loss: -1.0326	Cost: 11.65s
Train Epoch: 168 	Average Loss: -0.8296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4628

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 1.8126	Cost: 27.11s
Train Epoch: 169 [20480/90000 (23%)]	Loss: -1.3701	Cost: 6.53s
Train Epoch: 169 [40960/90000 (45%)]	Loss: -1.1765	Cost: 9.17s
Train Epoch: 169 [61440/90000 (68%)]	Loss: -1.4098	Cost: 6.03s
Train Epoch: 169 [81920/90000 (91%)]	Loss: -0.9573	Cost: 17.98s
Train Epoch: 169 	Average Loss: -0.8634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3957

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 2.3918	Cost: 26.66s
Train Epoch: 170 [20480/90000 (23%)]	Loss: -1.7058	Cost: 6.21s
Train Epoch: 170 [40960/90000 (45%)]	Loss: -1.4308	Cost: 9.95s
Train Epoch: 170 [61440/90000 (68%)]	Loss: -1.4848	Cost: 6.24s
Train Epoch: 170 [81920/90000 (91%)]	Loss: -1.1267	Cost: 11.16s
Train Epoch: 170 	Average Loss: -0.9291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2076

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 1.5601	Cost: 23.85s
Train Epoch: 171 [20480/90000 (23%)]	Loss: -1.2830	Cost: 9.05s
Train Epoch: 171 [40960/90000 (45%)]	Loss: -0.8954	Cost: 9.04s
Train Epoch: 171 [61440/90000 (68%)]	Loss: -1.2852	Cost: 8.77s
Train Epoch: 171 [81920/90000 (91%)]	Loss: -0.7964	Cost: 8.06s
Train Epoch: 171 	Average Loss: -0.8654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2759

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 2.6110	Cost: 24.45s
Train Epoch: 172 [20480/90000 (23%)]	Loss: -1.5772	Cost: 6.06s
Train Epoch: 172 [40960/90000 (45%)]	Loss: -0.8951	Cost: 10.84s
Train Epoch: 172 [61440/90000 (68%)]	Loss: -1.4522	Cost: 6.14s
Train Epoch: 172 [81920/90000 (91%)]	Loss: -1.0931	Cost: 14.87s
Train Epoch: 172 	Average Loss: -0.8954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5464

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 2.0514	Cost: 26.14s
Train Epoch: 173 [20480/90000 (23%)]	Loss: -1.6063	Cost: 6.12s
Train Epoch: 173 [40960/90000 (45%)]	Loss: -0.8847	Cost: 11.92s
Train Epoch: 173 [61440/90000 (68%)]	Loss: -1.4737	Cost: 5.92s
Train Epoch: 173 [81920/90000 (91%)]	Loss: -1.1183	Cost: 6.10s
Train Epoch: 173 	Average Loss: -1.0018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2789

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 1.8671	Cost: 26.21s
Train Epoch: 174 [20480/90000 (23%)]	Loss: -1.5090	Cost: 6.22s
Train Epoch: 174 [40960/90000 (45%)]	Loss: -1.0819	Cost: 13.34s
Train Epoch: 174 [61440/90000 (68%)]	Loss: -1.3541	Cost: 14.88s
Train Epoch: 174 [81920/90000 (91%)]	Loss: -0.6795	Cost: 11.66s
Train Epoch: 174 	Average Loss: -0.9277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4529

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 2.4150	Cost: 24.37s
Train Epoch: 175 [20480/90000 (23%)]	Loss: -1.7003	Cost: 6.18s
Train Epoch: 175 [40960/90000 (45%)]	Loss: -1.4136	Cost: 10.31s
Train Epoch: 175 [61440/90000 (68%)]	Loss: -1.4297	Cost: 6.07s
Train Epoch: 175 [81920/90000 (91%)]	Loss: -0.7385	Cost: 18.77s
Train Epoch: 175 	Average Loss: -0.9559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3818

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 2.1820	Cost: 26.48s
Train Epoch: 176 [20480/90000 (23%)]	Loss: -1.1173	Cost: 6.64s
Train Epoch: 176 [40960/90000 (45%)]	Loss: -1.4041	Cost: 8.66s
Train Epoch: 176 [61440/90000 (68%)]	Loss: -1.7750	Cost: 6.11s
Train Epoch: 176 [81920/90000 (91%)]	Loss: -0.9715	Cost: 11.26s
Train Epoch: 176 	Average Loss: -0.9743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3786

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 2.0945	Cost: 29.60s
Train Epoch: 177 [20480/90000 (23%)]	Loss: -1.3954	Cost: 6.03s
Train Epoch: 177 [40960/90000 (45%)]	Loss: -1.3258	Cost: 11.78s
Train Epoch: 177 [61440/90000 (68%)]	Loss: -1.4433	Cost: 8.34s
Train Epoch: 177 [81920/90000 (91%)]	Loss: -1.0583	Cost: 8.25s
Train Epoch: 177 	Average Loss: -1.0471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4004

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 2.2924	Cost: 27.49s
Train Epoch: 178 [20480/90000 (23%)]	Loss: -1.6926	Cost: 11.37s
Train Epoch: 178 [40960/90000 (45%)]	Loss: -1.4482	Cost: 6.11s
Train Epoch: 178 [61440/90000 (68%)]	Loss: -1.7625	Cost: 6.04s
Train Epoch: 178 [81920/90000 (91%)]	Loss: -1.0467	Cost: 6.67s
Train Epoch: 178 	Average Loss: -1.0537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3219

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 1.9608	Cost: 25.97s
Train Epoch: 179 [20480/90000 (23%)]	Loss: -1.4727	Cost: 9.63s
Train Epoch: 179 [40960/90000 (45%)]	Loss: -1.5028	Cost: 14.80s
Train Epoch: 179 [61440/90000 (68%)]	Loss: -1.3854	Cost: 10.13s
Train Epoch: 179 [81920/90000 (91%)]	Loss: -0.8537	Cost: 11.93s
Train Epoch: 179 	Average Loss: -1.0153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2998

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 1.7923	Cost: 25.23s
Train Epoch: 180 [20480/90000 (23%)]	Loss: -1.5230	Cost: 6.20s
Train Epoch: 180 [40960/90000 (45%)]	Loss: -1.2613	Cost: 9.48s
Train Epoch: 180 [61440/90000 (68%)]	Loss: -1.4777	Cost: 5.95s
Train Epoch: 180 [81920/90000 (91%)]	Loss: -1.0860	Cost: 18.77s
Train Epoch: 180 	Average Loss: -1.1126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1990

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 2.1005	Cost: 23.53s
Train Epoch: 181 [20480/90000 (23%)]	Loss: -1.7485	Cost: 6.17s
Train Epoch: 181 [40960/90000 (45%)]	Loss: -1.5238	Cost: 9.17s
Train Epoch: 181 [61440/90000 (68%)]	Loss: -1.9271	Cost: 6.08s
Train Epoch: 181 [81920/90000 (91%)]	Loss: -1.2904	Cost: 11.08s
Train Epoch: 181 	Average Loss: -1.1745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2378

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 1.8236	Cost: 23.88s
Train Epoch: 182 [20480/90000 (23%)]	Loss: -1.3678	Cost: 6.31s
Train Epoch: 182 [40960/90000 (45%)]	Loss: -1.3248	Cost: 8.40s
Train Epoch: 182 [61440/90000 (68%)]	Loss: -1.4637	Cost: 7.43s
Train Epoch: 182 [81920/90000 (91%)]	Loss: -0.9525	Cost: 8.77s
Train Epoch: 182 	Average Loss: -1.0444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2408

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 1.7133	Cost: 26.74s
Train Epoch: 183 [20480/90000 (23%)]	Loss: -1.7254	Cost: 6.19s
Train Epoch: 183 [40960/90000 (45%)]	Loss: -1.4067	Cost: 12.26s
Train Epoch: 183 [61440/90000 (68%)]	Loss: -1.6406	Cost: 6.05s
Train Epoch: 183 [81920/90000 (91%)]	Loss: -1.2714	Cost: 5.88s
Train Epoch: 183 	Average Loss: -1.2114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1262

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 2.1779	Cost: 28.48s
Train Epoch: 184 [20480/90000 (23%)]	Loss: -1.8316	Cost: 6.81s
Train Epoch: 184 [40960/90000 (45%)]	Loss: -1.2489	Cost: 12.39s
Train Epoch: 184 [61440/90000 (68%)]	Loss: -1.7178	Cost: 15.15s
Train Epoch: 184 [81920/90000 (91%)]	Loss: -1.3676	Cost: 11.12s
Train Epoch: 184 	Average Loss: -1.2315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0909

Saving model as e184_model.pt & e184_waveforms_supplementary.hdf5
Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 1.9541	Cost: 24.85s
Train Epoch: 185 [20480/90000 (23%)]	Loss: -1.7834	Cost: 8.32s
Train Epoch: 185 [40960/90000 (45%)]	Loss: -1.6793	Cost: 10.84s
Train Epoch: 185 [61440/90000 (68%)]	Loss: -1.7299	Cost: 7.13s
Train Epoch: 185 [81920/90000 (91%)]	Loss: -1.6662	Cost: 10.89s
Train Epoch: 185 	Average Loss: -1.1919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2660

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 1.5754	Cost: 24.99s
Train Epoch: 186 [20480/90000 (23%)]	Loss: -2.0583	Cost: 8.62s
Train Epoch: 186 [40960/90000 (45%)]	Loss: -1.6872	Cost: 8.57s
Train Epoch: 186 [61440/90000 (68%)]	Loss: -1.9531	Cost: 8.52s
Train Epoch: 186 [81920/90000 (91%)]	Loss: -1.5877	Cost: 8.88s
Train Epoch: 186 	Average Loss: -1.3334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2405

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 2.1208	Cost: 25.83s
Train Epoch: 187 [20480/90000 (23%)]	Loss: -1.8054	Cost: 12.04s
Train Epoch: 187 [40960/90000 (45%)]	Loss: -1.2376	Cost: 6.19s
Train Epoch: 187 [61440/90000 (68%)]	Loss: -1.5131	Cost: 6.16s
Train Epoch: 187 [81920/90000 (91%)]	Loss: -1.3637	Cost: 5.71s
Train Epoch: 187 	Average Loss: -1.2390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2786

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 2.2710	Cost: 27.37s
Train Epoch: 188 [20480/90000 (23%)]	Loss: -1.8117	Cost: 14.19s
Train Epoch: 188 [40960/90000 (45%)]	Loss: -1.7580	Cost: 14.58s
Train Epoch: 188 [61440/90000 (68%)]	Loss: -1.8167	Cost: 11.14s
Train Epoch: 188 [81920/90000 (91%)]	Loss: -1.3343	Cost: 5.72s
Train Epoch: 188 	Average Loss: -1.3045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2442

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 2.1305	Cost: 26.60s
Train Epoch: 189 [20480/90000 (23%)]	Loss: -2.0497	Cost: 6.10s
Train Epoch: 189 [40960/90000 (45%)]	Loss: -1.4215	Cost: 13.40s
Train Epoch: 189 [61440/90000 (68%)]	Loss: -1.9073	Cost: 15.13s
Train Epoch: 189 [81920/90000 (91%)]	Loss: -1.2197	Cost: 14.46s
Train Epoch: 189 	Average Loss: -1.3304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1574

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 2.2865	Cost: 24.46s
Train Epoch: 190 [20480/90000 (23%)]	Loss: -1.9190	Cost: 6.32s
Train Epoch: 190 [40960/90000 (45%)]	Loss: -1.4900	Cost: 9.35s
Train Epoch: 190 [61440/90000 (68%)]	Loss: -1.7465	Cost: 6.13s
Train Epoch: 190 [81920/90000 (91%)]	Loss: -1.1825	Cost: 10.92s
Train Epoch: 190 	Average Loss: -1.2943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1725

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 2.1898	Cost: 25.55s
Train Epoch: 191 [20480/90000 (23%)]	Loss: -2.1692	Cost: 7.31s
Train Epoch: 191 [40960/90000 (45%)]	Loss: -1.8032	Cost: 8.89s
Train Epoch: 191 [61440/90000 (68%)]	Loss: -2.2544	Cost: 8.45s
Train Epoch: 191 [81920/90000 (91%)]	Loss: -1.2767	Cost: 8.32s
Train Epoch: 191 	Average Loss: -1.3756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3281

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 1.3357	Cost: 26.82s
Train Epoch: 192 [20480/90000 (23%)]	Loss: -2.0242	Cost: 12.20s
Train Epoch: 192 [40960/90000 (45%)]	Loss: -1.6929	Cost: 6.27s
Train Epoch: 192 [61440/90000 (68%)]	Loss: -1.5712	Cost: 6.18s
Train Epoch: 192 [81920/90000 (91%)]	Loss: -1.8769	Cost: 5.85s
Train Epoch: 192 	Average Loss: -1.3895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1252

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 2.2177	Cost: 26.40s
Train Epoch: 193 [20480/90000 (23%)]	Loss: -1.9551	Cost: 6.89s
Train Epoch: 193 [40960/90000 (45%)]	Loss: -1.8490	Cost: 15.74s
Train Epoch: 193 [61440/90000 (68%)]	Loss: -2.0387	Cost: 12.74s
Train Epoch: 193 [81920/90000 (91%)]	Loss: -1.7862	Cost: 6.01s
Train Epoch: 193 	Average Loss: -1.4711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0158

Saving model as e193_model.pt & e193_waveforms_supplementary.hdf5
Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 1.8766	Cost: 24.17s
Train Epoch: 194 [20480/90000 (23%)]	Loss: -1.8465	Cost: 6.39s
Train Epoch: 194 [40960/90000 (45%)]	Loss: -1.7132	Cost: 9.42s
Train Epoch: 194 [61440/90000 (68%)]	Loss: -1.7954	Cost: 6.23s
Train Epoch: 194 [81920/90000 (91%)]	Loss: -1.2809	Cost: 11.76s
Train Epoch: 194 	Average Loss: -1.3643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3684

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 2.2216	Cost: 24.25s
Train Epoch: 195 [20480/90000 (23%)]	Loss: -1.7968	Cost: 8.84s
Train Epoch: 195 [40960/90000 (45%)]	Loss: -1.4856	Cost: 8.80s
Train Epoch: 195 [61440/90000 (68%)]	Loss: -1.7666	Cost: 8.43s
Train Epoch: 195 [81920/90000 (91%)]	Loss: -1.2661	Cost: 6.01s
Train Epoch: 195 	Average Loss: -1.1180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4247

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 2.0073	Cost: 23.49s
Train Epoch: 196 [20480/90000 (23%)]	Loss: -1.7549	Cost: 6.42s
Train Epoch: 196 [40960/90000 (45%)]	Loss: -1.6356	Cost: 8.22s
Train Epoch: 196 [61440/90000 (68%)]	Loss: -2.2625	Cost: 6.13s
Train Epoch: 196 [81920/90000 (91%)]	Loss: -1.6468	Cost: 8.75s
Train Epoch: 196 	Average Loss: -1.3460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2112

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 2.3205	Cost: 26.06s
Train Epoch: 197 [20480/90000 (23%)]	Loss: -2.0776	Cost: 6.20s
Train Epoch: 197 [40960/90000 (45%)]	Loss: -1.5834	Cost: 12.77s
Train Epoch: 197 [61440/90000 (68%)]	Loss: -1.8096	Cost: 7.98s
Train Epoch: 197 [81920/90000 (91%)]	Loss: -1.5283	Cost: 6.08s
Train Epoch: 197 	Average Loss: -1.3729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0278

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 1.9387	Cost: 28.95s
Train Epoch: 198 [20480/90000 (23%)]	Loss: -2.0193	Cost: 6.32s
Train Epoch: 198 [40960/90000 (45%)]	Loss: -1.7891	Cost: 8.78s
Train Epoch: 198 [61440/90000 (68%)]	Loss: -1.9767	Cost: 15.12s
Train Epoch: 198 [81920/90000 (91%)]	Loss: -1.6323	Cost: 14.73s
Train Epoch: 198 	Average Loss: -1.5103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0190

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 2.2514	Cost: 27.68s
Train Epoch: 199 [20480/90000 (23%)]	Loss: -2.2209	Cost: 6.47s
Train Epoch: 199 [40960/90000 (45%)]	Loss: -1.8224	Cost: 10.20s
Train Epoch: 199 [61440/90000 (68%)]	Loss: -2.4041	Cost: 6.05s
Train Epoch: 199 [81920/90000 (91%)]	Loss: -1.8464	Cost: 15.32s
Train Epoch: 199 	Average Loss: -1.5243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4731

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 2.1161	Cost: 26.11s
Train Epoch: 200 [20480/90000 (23%)]	Loss: -2.3303	Cost: 8.95s
Train Epoch: 200 [40960/90000 (45%)]	Loss: -1.8466	Cost: 8.42s
Train Epoch: 200 [61440/90000 (68%)]	Loss: -2.2036	Cost: 6.10s
Train Epoch: 200 [81920/90000 (91%)]	Loss: -1.3991	Cost: 11.02s
Train Epoch: 200 	Average Loss: -1.6071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2350

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 2.2026	Cost: 26.08s
Train Epoch: 201 [20480/90000 (23%)]	Loss: -2.0377	Cost: 6.06s
Train Epoch: 201 [40960/90000 (45%)]	Loss: -1.9063	Cost: 10.59s
Train Epoch: 201 [61440/90000 (68%)]	Loss: -2.0361	Cost: 8.89s
Train Epoch: 201 [81920/90000 (91%)]	Loss: -1.6565	Cost: 10.38s
Train Epoch: 201 	Average Loss: -1.5603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1422

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 2.1133	Cost: 24.70s
Train Epoch: 202 [20480/90000 (23%)]	Loss: -2.0565	Cost: 10.44s
Train Epoch: 202 [40960/90000 (45%)]	Loss: -1.7153	Cost: 7.83s
Train Epoch: 202 [61440/90000 (68%)]	Loss: -2.2704	Cost: 6.02s
Train Epoch: 202 [81920/90000 (91%)]	Loss: -1.7808	Cost: 5.66s
Train Epoch: 202 	Average Loss: -1.6742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1369

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 1.2176	Cost: 26.17s
Train Epoch: 203 [20480/90000 (23%)]	Loss: -2.1265	Cost: 14.34s
Train Epoch: 203 [40960/90000 (45%)]	Loss: -2.3041	Cost: 13.96s
Train Epoch: 203 [61440/90000 (68%)]	Loss: -2.1790	Cost: 11.58s
Train Epoch: 203 [81920/90000 (91%)]	Loss: -1.5526	Cost: 5.69s
Train Epoch: 203 	Average Loss: -1.7445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1796

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 1.5621	Cost: 27.06s
Train Epoch: 204 [20480/90000 (23%)]	Loss: -2.0139	Cost: 6.12s
Train Epoch: 204 [40960/90000 (45%)]	Loss: -2.1930	Cost: 12.13s
Train Epoch: 204 [61440/90000 (68%)]	Loss: -2.4383	Cost: 15.21s
Train Epoch: 204 [81920/90000 (91%)]	Loss: -1.6742	Cost: 14.52s
Train Epoch: 204 	Average Loss: -1.7643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1140

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 1.9690	Cost: 24.44s
Train Epoch: 205 [20480/90000 (23%)]	Loss: -2.7450	Cost: 6.30s
Train Epoch: 205 [40960/90000 (45%)]	Loss: -1.9556	Cost: 9.22s
Train Epoch: 205 [61440/90000 (68%)]	Loss: -2.4800	Cost: 6.04s
Train Epoch: 205 [81920/90000 (91%)]	Loss: -1.5663	Cost: 16.75s
Train Epoch: 205 	Average Loss: -1.7720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9456

Saving model as e205_model.pt & e205_waveforms_supplementary.hdf5
Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 1.9008	Cost: 26.11s
Train Epoch: 206 [20480/90000 (23%)]	Loss: -2.2191	Cost: 6.28s
Train Epoch: 206 [40960/90000 (45%)]	Loss: -1.9296	Cost: 9.45s
Train Epoch: 206 [61440/90000 (68%)]	Loss: -2.4121	Cost: 6.12s
Train Epoch: 206 [81920/90000 (91%)]	Loss: -1.8394	Cost: 11.60s
Train Epoch: 206 	Average Loss: -1.6995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1955

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 1.6468	Cost: 30.56s
Train Epoch: 207 [20480/90000 (23%)]	Loss: -2.4987	Cost: 6.72s
Train Epoch: 207 [40960/90000 (45%)]	Loss: -2.0190	Cost: 10.68s
Train Epoch: 207 [61440/90000 (68%)]	Loss: -2.5979	Cost: 8.59s
Train Epoch: 207 [81920/90000 (91%)]	Loss: -1.9953	Cost: 8.38s
Train Epoch: 207 	Average Loss: -1.7497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2156

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 1.5778	Cost: 29.42s
Train Epoch: 208 [20480/90000 (23%)]	Loss: -2.6500	Cost: 7.90s
Train Epoch: 208 [40960/90000 (45%)]	Loss: -2.0845	Cost: 6.33s
Train Epoch: 208 [61440/90000 (68%)]	Loss: -2.4095	Cost: 6.13s
Train Epoch: 208 [81920/90000 (91%)]	Loss: -1.7790	Cost: 8.82s
Train Epoch: 208 	Average Loss: -1.7874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0994

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 2.1243	Cost: 29.45s
Train Epoch: 209 [20480/90000 (23%)]	Loss: -2.3805	Cost: 14.99s
Train Epoch: 209 [40960/90000 (45%)]	Loss: -2.1094	Cost: 10.82s
Train Epoch: 209 [61440/90000 (68%)]	Loss: -2.5389	Cost: 10.03s
Train Epoch: 209 [81920/90000 (91%)]	Loss: -1.7879	Cost: 6.00s
Train Epoch: 209 	Average Loss: -1.7257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0693

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 1.4878	Cost: 25.44s
Train Epoch: 210 [20480/90000 (23%)]	Loss: -2.5432	Cost: 6.12s
Train Epoch: 210 [40960/90000 (45%)]	Loss: -2.2827	Cost: 10.14s
Train Epoch: 210 [61440/90000 (68%)]	Loss: -2.6906	Cost: 14.64s
Train Epoch: 210 [81920/90000 (91%)]	Loss: -2.1766	Cost: 15.06s
Train Epoch: 210 	Average Loss: -1.8188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0787

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 1.7347	Cost: 25.16s
Train Epoch: 211 [20480/90000 (23%)]	Loss: -2.1202	Cost: 6.23s
Train Epoch: 211 [40960/90000 (45%)]	Loss: -1.8606	Cost: 9.52s
Train Epoch: 211 [61440/90000 (68%)]	Loss: -2.3030	Cost: 5.97s
Train Epoch: 211 [81920/90000 (91%)]	Loss: -1.6665	Cost: 13.03s
Train Epoch: 211 	Average Loss: -1.6619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1421

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 1.6481	Cost: 23.41s
Train Epoch: 212 [20480/90000 (23%)]	Loss: -2.4652	Cost: 8.69s
Train Epoch: 212 [40960/90000 (45%)]	Loss: -1.7548	Cost: 8.67s
Train Epoch: 212 [61440/90000 (68%)]	Loss: -2.5342	Cost: 8.05s
Train Epoch: 212 [81920/90000 (91%)]	Loss: -1.9082	Cost: 5.65s
Train Epoch: 212 	Average Loss: -1.8047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0307

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 1.7776	Cost: 25.61s
Train Epoch: 213 [20480/90000 (23%)]	Loss: -2.6778	Cost: 6.07s
Train Epoch: 213 [40960/90000 (45%)]	Loss: -2.1921	Cost: 11.25s
Train Epoch: 213 [61440/90000 (68%)]	Loss: -2.6080	Cost: 5.93s
Train Epoch: 213 [81920/90000 (91%)]	Loss: -2.3669	Cost: 10.73s
Train Epoch: 213 	Average Loss: -1.9527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8103

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 1.3840	Cost: 26.47s
Train Epoch: 214 [20480/90000 (23%)]	Loss: -2.9557	Cost: 6.00s
Train Epoch: 214 [40960/90000 (45%)]	Loss: -2.1624	Cost: 11.82s
Train Epoch: 214 [61440/90000 (68%)]	Loss: -2.7147	Cost: 5.85s
Train Epoch: 214 [81920/90000 (91%)]	Loss: -2.0629	Cost: 5.80s
Train Epoch: 214 	Average Loss: -2.0093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9872

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 1.6217	Cost: 45.03s
Train Epoch: 215 [20480/90000 (23%)]	Loss: -2.5226	Cost: 14.75s
Train Epoch: 215 [40960/90000 (45%)]	Loss: -2.1748	Cost: 14.59s
Train Epoch: 215 [61440/90000 (68%)]	Loss: -2.6408	Cost: 9.72s
Train Epoch: 215 [81920/90000 (91%)]	Loss: -2.1745	Cost: 5.85s
Train Epoch: 215 	Average Loss: -2.0637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9810

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 1.3543	Cost: 32.92s
Train Epoch: 216 [20480/90000 (23%)]	Loss: -2.3253	Cost: 6.28s
Train Epoch: 216 [40960/90000 (45%)]	Loss: -2.2454	Cost: 10.01s
Train Epoch: 216 [61440/90000 (68%)]	Loss: -2.7388	Cost: 6.07s
Train Epoch: 216 [81920/90000 (91%)]	Loss: -2.3398	Cost: 16.74s
Train Epoch: 216 	Average Loss: -2.0327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9591

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 1.9522	Cost: 24.36s
Train Epoch: 217 [20480/90000 (23%)]	Loss: -2.8501	Cost: 8.38s
Train Epoch: 217 [40960/90000 (45%)]	Loss: -2.4087	Cost: 6.80s
Train Epoch: 217 [61440/90000 (68%)]	Loss: -2.5146	Cost: 6.38s
Train Epoch: 217 [81920/90000 (91%)]	Loss: -2.0256	Cost: 11.57s
Train Epoch: 217 	Average Loss: -2.0683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7997

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 1.1540	Cost: 23.76s
Train Epoch: 218 [20480/90000 (23%)]	Loss: -2.5717	Cost: 8.03s
Train Epoch: 218 [40960/90000 (45%)]	Loss: -1.9499	Cost: 9.10s
Train Epoch: 218 [61440/90000 (68%)]	Loss: -2.3192	Cost: 8.91s
Train Epoch: 218 [81920/90000 (91%)]	Loss: -2.0838	Cost: 8.65s
Train Epoch: 218 	Average Loss: -1.7343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1103

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 2.0413	Cost: 26.02s
Train Epoch: 219 [20480/90000 (23%)]	Loss: -2.5743	Cost: 11.47s
Train Epoch: 219 [40960/90000 (45%)]	Loss: -2.2806	Cost: 6.33s
Train Epoch: 219 [61440/90000 (68%)]	Loss: -1.8977	Cost: 6.21s
Train Epoch: 219 [81920/90000 (91%)]	Loss: -1.8272	Cost: 7.62s
Train Epoch: 219 	Average Loss: -1.9600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8289

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 1.3814	Cost: 30.05s
Train Epoch: 220 [20480/90000 (23%)]	Loss: -2.9505	Cost: 10.32s
Train Epoch: 220 [40960/90000 (45%)]	Loss: -2.4090	Cost: 9.46s
Train Epoch: 220 [61440/90000 (68%)]	Loss: -2.5799	Cost: 8.69s
Train Epoch: 220 [81920/90000 (91%)]	Loss: -2.4543	Cost: 6.03s
Train Epoch: 220 	Average Loss: -2.1713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0563

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 1.4348	Cost: 27.41s
Train Epoch: 221 [20480/90000 (23%)]	Loss: -3.0162	Cost: 6.17s
Train Epoch: 221 [40960/90000 (45%)]	Loss: -2.2346	Cost: 13.00s
Train Epoch: 221 [61440/90000 (68%)]	Loss: -2.9661	Cost: 15.04s
Train Epoch: 221 [81920/90000 (91%)]	Loss: -2.2273	Cost: 10.78s
Train Epoch: 221 	Average Loss: -2.1717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8093

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 1.2362	Cost: 24.62s
Train Epoch: 222 [20480/90000 (23%)]	Loss: -2.6327	Cost: 6.16s
Train Epoch: 222 [40960/90000 (45%)]	Loss: -2.6754	Cost: 8.98s
Train Epoch: 222 [61440/90000 (68%)]	Loss: -2.9246	Cost: 6.13s
Train Epoch: 222 [81920/90000 (91%)]	Loss: -2.3805	Cost: 11.00s
Train Epoch: 222 	Average Loss: -2.2552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7693

Saving model as e222_model.pt & e222_waveforms_supplementary.hdf5
Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 2.0389	Cost: 25.72s
Train Epoch: 223 [20480/90000 (23%)]	Loss: -2.6529	Cost: 8.24s
Train Epoch: 223 [40960/90000 (45%)]	Loss: -2.5964	Cost: 9.05s
Train Epoch: 223 [61440/90000 (68%)]	Loss: -2.9232	Cost: 8.57s
Train Epoch: 223 [81920/90000 (91%)]	Loss: -1.8536	Cost: 8.29s
Train Epoch: 223 	Average Loss: -2.0705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7738

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 1.5085	Cost: 25.59s
Train Epoch: 224 [20480/90000 (23%)]	Loss: -2.8611	Cost: 12.22s
Train Epoch: 224 [40960/90000 (45%)]	Loss: -2.3596	Cost: 6.27s
Train Epoch: 224 [61440/90000 (68%)]	Loss: -2.8553	Cost: 6.26s
Train Epoch: 224 [81920/90000 (91%)]	Loss: -2.2350	Cost: 6.40s
Train Epoch: 224 	Average Loss: -2.1798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9628

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 1.8843	Cost: 25.85s
Train Epoch: 225 [20480/90000 (23%)]	Loss: -2.7729	Cost: 6.19s
Train Epoch: 225 [40960/90000 (45%)]	Loss: -2.5393	Cost: 13.39s
Train Epoch: 225 [61440/90000 (68%)]	Loss: -2.5423	Cost: 15.57s
Train Epoch: 225 [81920/90000 (91%)]	Loss: -2.2057	Cost: 7.33s
Train Epoch: 225 	Average Loss: -2.0574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0929

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 2.0183	Cost: 23.78s
Train Epoch: 226 [20480/90000 (23%)]	Loss: -2.7157	Cost: 6.16s
Train Epoch: 226 [40960/90000 (45%)]	Loss: -2.4440	Cost: 9.83s
Train Epoch: 226 [61440/90000 (68%)]	Loss: -2.4384	Cost: 6.31s
Train Epoch: 226 [81920/90000 (91%)]	Loss: -2.4854	Cost: 10.61s
Train Epoch: 226 	Average Loss: -2.1184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9274

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 0.9456	Cost: 24.13s
Train Epoch: 227 [20480/90000 (23%)]	Loss: -2.9734	Cost: 7.27s
Train Epoch: 227 [40960/90000 (45%)]	Loss: -2.9611	Cost: 9.25s
Train Epoch: 227 [61440/90000 (68%)]	Loss: -2.8704	Cost: 8.57s
Train Epoch: 227 [81920/90000 (91%)]	Loss: -2.4176	Cost: 8.29s
Train Epoch: 227 	Average Loss: -2.2780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9618

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 1.0718	Cost: 25.54s
Train Epoch: 228 [20480/90000 (23%)]	Loss: -2.5679	Cost: 6.14s
Train Epoch: 228 [40960/90000 (45%)]	Loss: -2.5695	Cost: 12.12s
Train Epoch: 228 [61440/90000 (68%)]	Loss: -2.8348	Cost: 6.03s
Train Epoch: 228 [81920/90000 (91%)]	Loss: -2.9182	Cost: 6.16s
Train Epoch: 228 	Average Loss: -2.3200
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7901

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 1.7862	Cost: 32.35s
Train Epoch: 229 [20480/90000 (23%)]	Loss: -2.3617	Cost: 6.20s
Train Epoch: 229 [40960/90000 (45%)]	Loss: -2.3058	Cost: 11.57s
Train Epoch: 229 [61440/90000 (68%)]	Loss: -2.6282	Cost: 14.83s
Train Epoch: 229 [81920/90000 (91%)]	Loss: -2.3979	Cost: 14.69s
Train Epoch: 229 	Average Loss: -2.2516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9512

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 1.6178	Cost: 27.78s
Train Epoch: 230 [20480/90000 (23%)]	Loss: -2.6838	Cost: 6.77s
Train Epoch: 230 [40960/90000 (45%)]	Loss: -2.9887	Cost: 9.77s
Train Epoch: 230 [61440/90000 (68%)]	Loss: -2.9942	Cost: 6.06s
Train Epoch: 230 [81920/90000 (91%)]	Loss: -2.1610	Cost: 18.17s
Train Epoch: 230 	Average Loss: -2.2859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8011

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 1.4512	Cost: 27.65s
Train Epoch: 231 [20480/90000 (23%)]	Loss: -2.7992	Cost: 6.82s
Train Epoch: 231 [40960/90000 (45%)]	Loss: -2.7345	Cost: 10.77s
Train Epoch: 231 [61440/90000 (68%)]	Loss: -2.8187	Cost: 6.26s
Train Epoch: 231 [81920/90000 (91%)]	Loss: -2.6673	Cost: 11.87s
Train Epoch: 231 	Average Loss: -2.3239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7527

Saving model as e231_model.pt & e231_waveforms_supplementary.hdf5
Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 1.1010	Cost: 25.32s
Train Epoch: 232 [20480/90000 (23%)]	Loss: -2.8713	Cost: 7.73s
Train Epoch: 232 [40960/90000 (45%)]	Loss: -3.0256	Cost: 9.36s
Train Epoch: 232 [61440/90000 (68%)]	Loss: -3.3379	Cost: 8.67s
Train Epoch: 232 [81920/90000 (91%)]	Loss: -2.7468	Cost: 8.97s
Train Epoch: 232 	Average Loss: -2.4311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8655

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 1.9996	Cost: 26.28s
Train Epoch: 233 [20480/90000 (23%)]	Loss: -3.0382	Cost: 10.39s
Train Epoch: 233 [40960/90000 (45%)]	Loss: -2.8978	Cost: 7.66s
Train Epoch: 233 [61440/90000 (68%)]	Loss: -3.2735	Cost: 6.17s
Train Epoch: 233 [81920/90000 (91%)]	Loss: -2.7954	Cost: 7.78s
Train Epoch: 233 	Average Loss: -2.3948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8735

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 1.8073	Cost: 26.67s
Train Epoch: 234 [20480/90000 (23%)]	Loss: -2.8044	Cost: 6.51s
Train Epoch: 234 [40960/90000 (45%)]	Loss: -2.8208	Cost: 11.45s
Train Epoch: 234 [61440/90000 (68%)]	Loss: -2.6825	Cost: 15.17s
Train Epoch: 234 [81920/90000 (91%)]	Loss: -2.5196	Cost: 13.82s
Train Epoch: 234 	Average Loss: -2.3740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8524

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 1.5033	Cost: 26.19s
Train Epoch: 235 [20480/90000 (23%)]	Loss: -3.2107	Cost: 6.21s
Train Epoch: 235 [40960/90000 (45%)]	Loss: -2.6920	Cost: 11.26s
Train Epoch: 235 [61440/90000 (68%)]	Loss: -2.9794	Cost: 5.95s
Train Epoch: 235 [81920/90000 (91%)]	Loss: -2.8417	Cost: 20.04s
Train Epoch: 235 	Average Loss: -2.4871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7658

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 1.5996	Cost: 23.62s
Train Epoch: 236 [20480/90000 (23%)]	Loss: -2.9395	Cost: 6.10s
Train Epoch: 236 [40960/90000 (45%)]	Loss: -3.2944	Cost: 10.38s
Train Epoch: 236 [61440/90000 (68%)]	Loss: -3.3301	Cost: 6.30s
Train Epoch: 236 [81920/90000 (91%)]	Loss: -2.3525	Cost: 11.12s
Train Epoch: 236 	Average Loss: -2.4195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7839

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 1.8645	Cost: 26.41s
Train Epoch: 237 [20480/90000 (23%)]	Loss: -3.2795	Cost: 7.17s
Train Epoch: 237 [40960/90000 (45%)]	Loss: -2.7946	Cost: 9.05s
Train Epoch: 237 [61440/90000 (68%)]	Loss: -3.2861	Cost: 8.50s
Train Epoch: 237 [81920/90000 (91%)]	Loss: -2.7070	Cost: 8.28s
Train Epoch: 237 	Average Loss: -2.4953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6818

Saving model as e237_model.pt & e237_waveforms_supplementary.hdf5
Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 1.5423	Cost: 30.89s
Train Epoch: 238 [20480/90000 (23%)]	Loss: -3.5400	Cost: 12.04s
Train Epoch: 238 [40960/90000 (45%)]	Loss: -2.7046	Cost: 6.13s
Train Epoch: 238 [61440/90000 (68%)]	Loss: -2.8147	Cost: 6.06s
Train Epoch: 238 [81920/90000 (91%)]	Loss: -2.5939	Cost: 6.68s
Train Epoch: 238 	Average Loss: -2.5381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8522

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 1.9660	Cost: 31.13s
Train Epoch: 239 [20480/90000 (23%)]	Loss: -3.1291	Cost: 14.36s
Train Epoch: 239 [40960/90000 (45%)]	Loss: -2.6883	Cost: 14.09s
Train Epoch: 239 [61440/90000 (68%)]	Loss: -3.0922	Cost: 11.83s
Train Epoch: 239 [81920/90000 (91%)]	Loss: -2.6772	Cost: 5.73s
Train Epoch: 239 	Average Loss: -2.5350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8349

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 1.7336	Cost: 35.54s
Train Epoch: 240 [20480/90000 (23%)]	Loss: -2.8856	Cost: 6.35s
Train Epoch: 240 [40960/90000 (45%)]	Loss: -3.4238	Cost: 14.54s
Train Epoch: 240 [61440/90000 (68%)]	Loss: -3.3425	Cost: 14.90s
Train Epoch: 240 [81920/90000 (91%)]	Loss: -2.7030	Cost: 13.07s
Train Epoch: 240 	Average Loss: -2.6280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7042

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 1.5100	Cost: 25.06s
Train Epoch: 241 [20480/90000 (23%)]	Loss: -3.2691	Cost: 8.66s
Train Epoch: 241 [40960/90000 (45%)]	Loss: -2.9580	Cost: 14.80s
Train Epoch: 241 [61440/90000 (68%)]	Loss: -3.3006	Cost: 6.62s
Train Epoch: 241 [81920/90000 (91%)]	Loss: -2.7370	Cost: 14.31s
Train Epoch: 241 	Average Loss: -2.6515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7217

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 1.4891	Cost: 24.02s
Train Epoch: 242 [20480/90000 (23%)]	Loss: -3.5217	Cost: 8.59s
Train Epoch: 242 [40960/90000 (45%)]	Loss: -2.7013	Cost: 9.10s
Train Epoch: 242 [61440/90000 (68%)]	Loss: -3.5991	Cost: 8.92s
Train Epoch: 242 [81920/90000 (91%)]	Loss: -2.6338	Cost: 8.61s
Train Epoch: 242 	Average Loss: -2.6718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7714

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 1.7213	Cost: 27.11s
Train Epoch: 243 [20480/90000 (23%)]	Loss: -3.3871	Cost: 10.56s
Train Epoch: 243 [40960/90000 (45%)]	Loss: -3.0165	Cost: 6.14s
Train Epoch: 243 [61440/90000 (68%)]	Loss: -3.1247	Cost: 6.21s
Train Epoch: 243 [81920/90000 (91%)]	Loss: -2.8503	Cost: 7.22s
Train Epoch: 243 	Average Loss: -2.6466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8520

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 0.8918	Cost: 31.16s
Train Epoch: 244 [20480/90000 (23%)]	Loss: -3.4468	Cost: 12.03s
Train Epoch: 244 [40960/90000 (45%)]	Loss: -3.2966	Cost: 9.23s
Train Epoch: 244 [61440/90000 (68%)]	Loss: -3.0738	Cost: 9.15s
Train Epoch: 244 [81920/90000 (91%)]	Loss: -2.8494	Cost: 5.75s
Train Epoch: 244 	Average Loss: -2.6267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9075

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 1.6240	Cost: 26.52s
Train Epoch: 245 [20480/90000 (23%)]	Loss: -3.2435	Cost: 6.22s
Train Epoch: 245 [40960/90000 (45%)]	Loss: -3.0509	Cost: 13.97s
Train Epoch: 245 [61440/90000 (68%)]	Loss: -3.4796	Cost: 14.54s
Train Epoch: 245 [81920/90000 (91%)]	Loss: -2.7591	Cost: 14.25s
Train Epoch: 245 	Average Loss: -2.7277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6723

Saving model as e245_model.pt & e245_waveforms_supplementary.hdf5
Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 1.1483	Cost: 24.01s
Train Epoch: 246 [20480/90000 (23%)]	Loss: -3.4883	Cost: 6.24s
Train Epoch: 246 [40960/90000 (45%)]	Loss: -3.3599	Cost: 9.28s
Train Epoch: 246 [61440/90000 (68%)]	Loss: -3.3246	Cost: 6.19s
Train Epoch: 246 [81920/90000 (91%)]	Loss: -3.0262	Cost: 18.51s
Train Epoch: 246 	Average Loss: -2.7378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8154

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 1.4954	Cost: 24.92s
Train Epoch: 247 [20480/90000 (23%)]	Loss: -3.4629	Cost: 6.31s
Train Epoch: 247 [40960/90000 (45%)]	Loss: -3.3684	Cost: 8.40s
Train Epoch: 247 [61440/90000 (68%)]	Loss: -3.2551	Cost: 6.24s
Train Epoch: 247 [81920/90000 (91%)]	Loss: -2.8825	Cost: 10.46s
Train Epoch: 247 	Average Loss: -2.7825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6780

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 1.4180	Cost: 26.21s
Train Epoch: 248 [20480/90000 (23%)]	Loss: -3.4206	Cost: 6.05s
Train Epoch: 248 [40960/90000 (45%)]	Loss: -3.1966	Cost: 9.84s
Train Epoch: 248 [61440/90000 (68%)]	Loss: -3.0496	Cost: 8.50s
Train Epoch: 248 [81920/90000 (91%)]	Loss: -3.0615	Cost: 8.30s
Train Epoch: 248 	Average Loss: -2.7669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6251

Saving model as e248_model.pt & e248_waveforms_supplementary.hdf5
Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 1.2287	Cost: 28.94s
Train Epoch: 249 [20480/90000 (23%)]	Loss: -3.8690	Cost: 11.99s
Train Epoch: 249 [40960/90000 (45%)]	Loss: -3.2703	Cost: 6.23s
Train Epoch: 249 [61440/90000 (68%)]	Loss: -3.2987	Cost: 6.12s
Train Epoch: 249 [81920/90000 (91%)]	Loss: -3.2986	Cost: 5.64s
Train Epoch: 249 	Average Loss: -2.8827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8605

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 1.6468	Cost: 25.78s
Train Epoch: 250 [20480/90000 (23%)]	Loss: -3.3506	Cost: 12.32s
Train Epoch: 250 [40960/90000 (45%)]	Loss: -3.2804	Cost: 15.28s
Train Epoch: 250 [61440/90000 (68%)]	Loss: -3.2889	Cost: 6.86s
Train Epoch: 250 [81920/90000 (91%)]	Loss: -2.8016	Cost: 11.62s
Train Epoch: 250 	Average Loss: -2.7983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6366

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 1.5661	Cost: 23.72s
Train Epoch: 251 [20480/90000 (23%)]	Loss: -3.3824	Cost: 6.37s
Train Epoch: 251 [40960/90000 (45%)]	Loss: -3.5157	Cost: 9.34s
Train Epoch: 251 [61440/90000 (68%)]	Loss: -3.3696	Cost: 6.17s
Train Epoch: 251 [81920/90000 (91%)]	Loss: -2.9672	Cost: 20.85s
Train Epoch: 251 	Average Loss: -2.9153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5746

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 1.8718	Cost: 23.71s
Train Epoch: 252 [20480/90000 (23%)]	Loss: -3.7453	Cost: 6.40s
Train Epoch: 252 [40960/90000 (45%)]	Loss: -3.0731	Cost: 9.95s
Train Epoch: 252 [61440/90000 (68%)]	Loss: -3.5560	Cost: 6.20s
Train Epoch: 252 [81920/90000 (91%)]	Loss: -3.2729	Cost: 12.18s
Train Epoch: 252 	Average Loss: -2.9536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7611

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 1.2410	Cost: 24.45s
Train Epoch: 253 [20480/90000 (23%)]	Loss: -3.6187	Cost: 8.68s
Train Epoch: 253 [40960/90000 (45%)]	Loss: -3.9113	Cost: 8.93s
Train Epoch: 253 [61440/90000 (68%)]	Loss: -3.5087	Cost: 8.53s
Train Epoch: 253 [81920/90000 (91%)]	Loss: -2.9424	Cost: 6.56s
Train Epoch: 253 	Average Loss: -3.0198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7107

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 1.0323	Cost: 27.89s
Train Epoch: 254 [20480/90000 (23%)]	Loss: -3.8207	Cost: 9.74s
Train Epoch: 254 [40960/90000 (45%)]	Loss: -3.2914	Cost: 6.20s
Train Epoch: 254 [61440/90000 (68%)]	Loss: -3.6575	Cost: 6.25s
Train Epoch: 254 [81920/90000 (91%)]	Loss: -3.0925	Cost: 6.00s
Train Epoch: 254 	Average Loss: -3.0155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6034

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 1.4565	Cost: 41.17s
Train Epoch: 255 [20480/90000 (23%)]	Loss: -3.8730	Cost: 9.92s
Train Epoch: 255 [40960/90000 (45%)]	Loss: -3.4364	Cost: 7.59s
Train Epoch: 255 [61440/90000 (68%)]	Loss: -3.6701	Cost: 10.92s
Train Epoch: 255 [81920/90000 (91%)]	Loss: -3.1342	Cost: 5.86s
Train Epoch: 255 	Average Loss: -3.0145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6405

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 1.4012	Cost: 28.66s
Train Epoch: 256 [20480/90000 (23%)]	Loss: -3.8733	Cost: 7.84s
Train Epoch: 256 [40960/90000 (45%)]	Loss: -3.5008	Cost: 8.61s
Train Epoch: 256 [61440/90000 (68%)]	Loss: -3.5540	Cost: 6.10s
Train Epoch: 256 [81920/90000 (91%)]	Loss: -3.6644	Cost: 9.46s
Train Epoch: 256 	Average Loss: -3.0654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6185

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 1.3541	Cost: 25.10s
Train Epoch: 257 [20480/90000 (23%)]	Loss: -3.5825	Cost: 8.70s
Train Epoch: 257 [40960/90000 (45%)]	Loss: -3.5824	Cost: 9.13s
Train Epoch: 257 [61440/90000 (68%)]	Loss: -3.7457	Cost: 9.28s
Train Epoch: 257 [81920/90000 (91%)]	Loss: -3.4694	Cost: 9.03s
Train Epoch: 257 	Average Loss: -3.0698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5781

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 1.3923	Cost: 26.92s
Train Epoch: 258 [20480/90000 (23%)]	Loss: -4.1658	Cost: 8.73s
Train Epoch: 258 [40960/90000 (45%)]	Loss: -3.7795	Cost: 6.28s
Train Epoch: 258 [61440/90000 (68%)]	Loss: -3.7113	Cost: 6.19s
Train Epoch: 258 [81920/90000 (91%)]	Loss: -3.3012	Cost: 6.30s
Train Epoch: 258 	Average Loss: -3.1908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5720

Saving model as e258_model.pt & e258_waveforms_supplementary.hdf5
Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 1.6867	Cost: 26.02s
Train Epoch: 259 [20480/90000 (23%)]	Loss: -3.8369	Cost: 11.38s
Train Epoch: 259 [40960/90000 (45%)]	Loss: -3.6197	Cost: 7.96s
Train Epoch: 259 [61440/90000 (68%)]	Loss: -3.8997	Cost: 10.13s
Train Epoch: 259 [81920/90000 (91%)]	Loss: -3.3868	Cost: 5.77s
Train Epoch: 259 	Average Loss: -3.1778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5355

Saving model as e259_model.pt & e259_waveforms_supplementary.hdf5
Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 0.9340	Cost: 27.89s
Train Epoch: 260 [20480/90000 (23%)]	Loss: -3.9466	Cost: 6.20s
Train Epoch: 260 [40960/90000 (45%)]	Loss: -3.5862	Cost: 13.41s
Train Epoch: 260 [61440/90000 (68%)]	Loss: -3.9120	Cost: 14.67s
Train Epoch: 260 [81920/90000 (91%)]	Loss: -3.2904	Cost: 11.77s
Train Epoch: 260 	Average Loss: -3.2860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5309

Saving model as e260_model.pt & e260_waveforms_supplementary.hdf5
Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 1.4683	Cost: 25.50s
Train Epoch: 261 [20480/90000 (23%)]	Loss: -4.1398	Cost: 6.13s
Train Epoch: 261 [40960/90000 (45%)]	Loss: -3.5483	Cost: 10.09s
Train Epoch: 261 [61440/90000 (68%)]	Loss: -3.9022	Cost: 6.03s
Train Epoch: 261 [81920/90000 (91%)]	Loss: -3.3372	Cost: 19.27s
Train Epoch: 261 	Average Loss: -3.1550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5881

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 1.4283	Cost: 26.65s
Train Epoch: 262 [20480/90000 (23%)]	Loss: -3.6545	Cost: 6.09s
Train Epoch: 262 [40960/90000 (45%)]	Loss: -3.5604	Cost: 9.93s
Train Epoch: 262 [61440/90000 (68%)]	Loss: -3.8284	Cost: 6.08s
Train Epoch: 262 [81920/90000 (91%)]	Loss: -3.3461	Cost: 10.88s
Train Epoch: 262 	Average Loss: -3.2128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5484

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 1.4979	Cost: 29.54s
Train Epoch: 263 [20480/90000 (23%)]	Loss: -3.9750	Cost: 8.07s
Train Epoch: 263 [40960/90000 (45%)]	Loss: -3.4595	Cost: 9.30s
Train Epoch: 263 [61440/90000 (68%)]	Loss: -3.8183	Cost: 8.35s
Train Epoch: 263 [81920/90000 (91%)]	Loss: -3.5706	Cost: 8.29s
Train Epoch: 263 	Average Loss: -3.2655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6250

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 0.6886	Cost: 26.13s
Train Epoch: 264 [20480/90000 (23%)]	Loss: -3.6714	Cost: 8.56s
Train Epoch: 264 [40960/90000 (45%)]	Loss: -3.9267	Cost: 9.68s
Train Epoch: 264 [61440/90000 (68%)]	Loss: -4.2053	Cost: 5.98s
Train Epoch: 264 [81920/90000 (91%)]	Loss: -3.3764	Cost: 6.65s
Train Epoch: 264 	Average Loss: -3.2300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5822

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 1.2432	Cost: 26.55s
Train Epoch: 265 [20480/90000 (23%)]	Loss: -3.8840	Cost: 6.12s
Train Epoch: 265 [40960/90000 (45%)]	Loss: -3.5912	Cost: 13.38s
Train Epoch: 265 [61440/90000 (68%)]	Loss: -3.8928	Cost: 14.74s
Train Epoch: 265 [81920/90000 (91%)]	Loss: -3.4220	Cost: 11.53s
Train Epoch: 265 	Average Loss: -3.2740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6759

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 1.1658	Cost: 23.90s
Train Epoch: 266 [20480/90000 (23%)]	Loss: -4.1639	Cost: 6.27s
Train Epoch: 266 [40960/90000 (45%)]	Loss: -3.8184	Cost: 9.52s
Train Epoch: 266 [61440/90000 (68%)]	Loss: -4.1056	Cost: 5.99s
Train Epoch: 266 [81920/90000 (91%)]	Loss: -3.2766	Cost: 18.12s
Train Epoch: 266 	Average Loss: -3.3340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4989

Saving model as e266_model.pt & e266_waveforms_supplementary.hdf5
Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 1.3928	Cost: 24.08s
Train Epoch: 267 [20480/90000 (23%)]	Loss: -4.1483	Cost: 6.25s
Train Epoch: 267 [40960/90000 (45%)]	Loss: -4.0136	Cost: 9.58s
Train Epoch: 267 [61440/90000 (68%)]	Loss: -4.1990	Cost: 6.18s
Train Epoch: 267 [81920/90000 (91%)]	Loss: -3.6822	Cost: 11.04s
Train Epoch: 267 	Average Loss: -3.3800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8031

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 1.1160	Cost: 24.08s
Train Epoch: 268 [20480/90000 (23%)]	Loss: -3.9878	Cost: 8.55s
Train Epoch: 268 [40960/90000 (45%)]	Loss: -3.6585	Cost: 8.91s
Train Epoch: 268 [61440/90000 (68%)]	Loss: -3.9904	Cost: 8.47s
Train Epoch: 268 [81920/90000 (91%)]	Loss: -3.3926	Cost: 8.27s
Train Epoch: 268 	Average Loss: -3.3704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7747

Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 1.3340	Cost: 28.67s
Train Epoch: 269 [20480/90000 (23%)]	Loss: -3.6322	Cost: 6.84s
Train Epoch: 269 [40960/90000 (45%)]	Loss: -3.6871	Cost: 11.38s
Train Epoch: 269 [61440/90000 (68%)]	Loss: -3.9618	Cost: 6.06s
Train Epoch: 269 [81920/90000 (91%)]	Loss: -3.6049	Cost: 8.02s
Train Epoch: 269 	Average Loss: -3.2564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8147

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 1.7536	Cost: 38.81s
Train Epoch: 270 [20480/90000 (23%)]	Loss: -4.0828	Cost: 13.27s
Train Epoch: 270 [40960/90000 (45%)]	Loss: -4.0081	Cost: 15.27s
Train Epoch: 270 [61440/90000 (68%)]	Loss: -3.7127	Cost: 11.54s
Train Epoch: 270 [81920/90000 (91%)]	Loss: -3.3944	Cost: 5.89s
Train Epoch: 270 	Average Loss: -3.3291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7637

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 0.9160	Cost: 28.33s
Train Epoch: 271 [20480/90000 (23%)]	Loss: -3.6304	Cost: 6.47s
Train Epoch: 271 [40960/90000 (45%)]	Loss: -3.8026	Cost: 9.00s
Train Epoch: 271 [61440/90000 (68%)]	Loss: -4.1220	Cost: 15.06s
Train Epoch: 271 [81920/90000 (91%)]	Loss: -3.5878	Cost: 14.96s
Train Epoch: 271 	Average Loss: -3.3999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6416

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 1.3504	Cost: 27.76s
Train Epoch: 272 [20480/90000 (23%)]	Loss: -4.3138	Cost: 6.39s
Train Epoch: 272 [40960/90000 (45%)]	Loss: -3.5152	Cost: 10.69s
Train Epoch: 272 [61440/90000 (68%)]	Loss: -4.0704	Cost: 6.11s
Train Epoch: 272 [81920/90000 (91%)]	Loss: -3.7621	Cost: 12.25s
Train Epoch: 272 	Average Loss: -3.4065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5894

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 0.7055	Cost: 25.87s
Train Epoch: 273 [20480/90000 (23%)]	Loss: -4.1175	Cost: 8.83s
Train Epoch: 273 [40960/90000 (45%)]	Loss: -3.9559	Cost: 8.56s
Train Epoch: 273 [61440/90000 (68%)]	Loss: -4.1417	Cost: 8.59s
Train Epoch: 273 [81920/90000 (91%)]	Loss: -3.6672	Cost: 6.70s
Train Epoch: 273 	Average Loss: -3.4923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3368

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 0.8801	Cost: 24.62s
Train Epoch: 274 [20480/90000 (23%)]	Loss: -4.1377	Cost: 6.40s
Train Epoch: 274 [40960/90000 (45%)]	Loss: -3.7060	Cost: 10.29s
Train Epoch: 274 [61440/90000 (68%)]	Loss: -4.3755	Cost: 6.01s
Train Epoch: 274 [81920/90000 (91%)]	Loss: -3.7129	Cost: 11.26s
Train Epoch: 274 	Average Loss: -3.5152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3576

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 1.0864	Cost: 27.34s
Train Epoch: 275 [20480/90000 (23%)]	Loss: -4.4747	Cost: 6.21s
Train Epoch: 275 [40960/90000 (45%)]	Loss: -4.1944	Cost: 12.19s
Train Epoch: 275 [61440/90000 (68%)]	Loss: -4.2618	Cost: 6.10s
Train Epoch: 275 [81920/90000 (91%)]	Loss: -3.9083	Cost: 9.61s
Train Epoch: 275 	Average Loss: -3.5324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2994

Saving model as e275_model.pt & e275_waveforms_supplementary.hdf5
Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 0.8593	Cost: 26.13s
Train Epoch: 276 [20480/90000 (23%)]	Loss: -4.2023	Cost: 6.06s
Train Epoch: 276 [40960/90000 (45%)]	Loss: -4.0657	Cost: 12.58s
Train Epoch: 276 [61440/90000 (68%)]	Loss: -4.2544	Cost: 15.06s
Train Epoch: 276 [81920/90000 (91%)]	Loss: -4.0435	Cost: 10.93s
Train Epoch: 276 	Average Loss: -3.5890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2735

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 0.9529	Cost: 24.62s
Train Epoch: 277 [20480/90000 (23%)]	Loss: -4.4005	Cost: 6.20s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -4.5213	Cost: 10.33s
Train Epoch: 277 [61440/90000 (68%)]	Loss: -4.2563	Cost: 6.00s
Train Epoch: 277 [81920/90000 (91%)]	Loss: -3.7877	Cost: 13.79s
Train Epoch: 277 	Average Loss: -3.6895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3432

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 0.7033	Cost: 24.27s
Train Epoch: 278 [20480/90000 (23%)]	Loss: -4.3192	Cost: 8.63s
Train Epoch: 278 [40960/90000 (45%)]	Loss: -4.0910	Cost: 8.78s
Train Epoch: 278 [61440/90000 (68%)]	Loss: -4.4244	Cost: 7.09s
Train Epoch: 278 [81920/90000 (91%)]	Loss: -3.7641	Cost: 6.65s
Train Epoch: 278 	Average Loss: -3.6799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2534

Saving model as e278_model.pt & e278_waveforms_supplementary.hdf5
Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 1.5319	Cost: 24.55s
Train Epoch: 279 [20480/90000 (23%)]	Loss: -4.4744	Cost: 6.18s
Train Epoch: 279 [40960/90000 (45%)]	Loss: -4.1171	Cost: 8.58s
Train Epoch: 279 [61440/90000 (68%)]	Loss: -4.4957	Cost: 6.91s
Train Epoch: 279 [81920/90000 (91%)]	Loss: -3.8593	Cost: 9.23s
Train Epoch: 279 	Average Loss: -3.6391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2863

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 1.4381	Cost: 30.07s
Train Epoch: 280 [20480/90000 (23%)]	Loss: -4.3765	Cost: 6.30s
Train Epoch: 280 [40960/90000 (45%)]	Loss: -4.0946	Cost: 12.02s
Train Epoch: 280 [61440/90000 (68%)]	Loss: -4.1455	Cost: 5.94s
Train Epoch: 280 [81920/90000 (91%)]	Loss: -3.5408	Cost: 6.79s
Train Epoch: 280 	Average Loss: -3.6673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1835

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 1.1900	Cost: 36.50s
Train Epoch: 281 [20480/90000 (23%)]	Loss: -4.4554	Cost: 14.83s
Train Epoch: 281 [40960/90000 (45%)]	Loss: -4.2455	Cost: 13.76s
Train Epoch: 281 [61440/90000 (68%)]	Loss: -4.4068	Cost: 9.88s
Train Epoch: 281 [81920/90000 (91%)]	Loss: -3.9456	Cost: 5.87s
Train Epoch: 281 	Average Loss: -3.7550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1267

Saving model as e281_model.pt & e281_waveforms_supplementary.hdf5
Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 0.5955	Cost: 30.93s
Train Epoch: 282 [20480/90000 (23%)]	Loss: -4.6942	Cost: 6.19s
Train Epoch: 282 [40960/90000 (45%)]	Loss: -4.2836	Cost: 14.38s
Train Epoch: 282 [61440/90000 (68%)]	Loss: -4.5672	Cost: 14.76s
Train Epoch: 282 [81920/90000 (91%)]	Loss: -4.1696	Cost: 13.70s
Train Epoch: 282 	Average Loss: -3.7827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2970

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 0.6182	Cost: 27.04s
Train Epoch: 283 [20480/90000 (23%)]	Loss: -4.6961	Cost: 6.78s
Train Epoch: 283 [40960/90000 (45%)]	Loss: -4.3704	Cost: 9.23s
Train Epoch: 283 [61440/90000 (68%)]	Loss: -4.5038	Cost: 6.06s
Train Epoch: 283 [81920/90000 (91%)]	Loss: -3.9408	Cost: 17.85s
Train Epoch: 283 	Average Loss: -3.6975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3987

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 1.1442	Cost: 26.50s
Train Epoch: 284 [20480/90000 (23%)]	Loss: -4.5686	Cost: 6.80s
Train Epoch: 284 [40960/90000 (45%)]	Loss: -4.3830	Cost: 12.57s
Train Epoch: 284 [61440/90000 (68%)]	Loss: -4.1670	Cost: 6.24s
Train Epoch: 284 [81920/90000 (91%)]	Loss: -4.1151	Cost: 14.81s
Train Epoch: 284 	Average Loss: -3.7775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4253

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 0.7834	Cost: 23.86s
Train Epoch: 285 [20480/90000 (23%)]	Loss: -4.5423	Cost: 7.78s
Train Epoch: 285 [40960/90000 (45%)]	Loss: -4.2644	Cost: 9.15s
Train Epoch: 285 [61440/90000 (68%)]	Loss: -4.6277	Cost: 9.18s
Train Epoch: 285 [81920/90000 (91%)]	Loss: -3.9076	Cost: 8.62s
Train Epoch: 285 	Average Loss: -3.7970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1703

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 0.4643	Cost: 27.26s
Train Epoch: 286 [20480/90000 (23%)]	Loss: -4.6933	Cost: 10.48s
Train Epoch: 286 [40960/90000 (45%)]	Loss: -4.3422	Cost: 6.07s
Train Epoch: 286 [61440/90000 (68%)]	Loss: -4.5061	Cost: 6.01s
Train Epoch: 286 [81920/90000 (91%)]	Loss: -3.9671	Cost: 7.76s
Train Epoch: 286 	Average Loss: -3.7854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2346

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 0.5756	Cost: 26.54s
Train Epoch: 287 [20480/90000 (23%)]	Loss: -4.8214	Cost: 14.46s
Train Epoch: 287 [40960/90000 (45%)]	Loss: -4.5405	Cost: 8.01s
Train Epoch: 287 [61440/90000 (68%)]	Loss: -4.5470	Cost: 9.95s
Train Epoch: 287 [81920/90000 (91%)]	Loss: -4.2482	Cost: 5.90s
Train Epoch: 287 	Average Loss: -3.8339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4233

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 1.0337	Cost: 26.57s
Train Epoch: 288 [20480/90000 (23%)]	Loss: -4.7659	Cost: 6.10s
Train Epoch: 288 [40960/90000 (45%)]	Loss: -4.5221	Cost: 12.86s
Train Epoch: 288 [61440/90000 (68%)]	Loss: -4.8109	Cost: 15.34s
Train Epoch: 288 [81920/90000 (91%)]	Loss: -4.0621	Cost: 11.41s
Train Epoch: 288 	Average Loss: -3.8063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2005

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 0.8877	Cost: 24.53s
Train Epoch: 289 [20480/90000 (23%)]	Loss: -4.6067	Cost: 6.17s
Train Epoch: 289 [40960/90000 (45%)]	Loss: -4.3947	Cost: 9.51s
Train Epoch: 289 [61440/90000 (68%)]	Loss: -4.4801	Cost: 6.05s
Train Epoch: 289 [81920/90000 (91%)]	Loss: -4.0656	Cost: 11.45s
Train Epoch: 289 	Average Loss: -3.8744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4413

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 0.7230	Cost: 25.20s
Train Epoch: 290 [20480/90000 (23%)]	Loss: -4.3766	Cost: 7.94s
Train Epoch: 290 [40960/90000 (45%)]	Loss: -4.2661	Cost: 8.90s
Train Epoch: 290 [61440/90000 (68%)]	Loss: -4.8076	Cost: 8.53s
Train Epoch: 290 [81920/90000 (91%)]	Loss: -3.8919	Cost: 8.40s
Train Epoch: 290 	Average Loss: -3.8629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1426

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 0.8391	Cost: 30.04s
Train Epoch: 291 [20480/90000 (23%)]	Loss: -4.9481	Cost: 10.34s
Train Epoch: 291 [40960/90000 (45%)]	Loss: -4.3254	Cost: 6.22s
Train Epoch: 291 [61440/90000 (68%)]	Loss: -4.3620	Cost: 6.09s
Train Epoch: 291 [81920/90000 (91%)]	Loss: -4.2494	Cost: 5.83s
Train Epoch: 291 	Average Loss: -3.9267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1161

Saving model as e291_model.pt & e291_waveforms_supplementary.hdf5
Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 0.6765	Cost: 27.50s
Train Epoch: 292 [20480/90000 (23%)]	Loss: -4.4526	Cost: 15.18s
Train Epoch: 292 [40960/90000 (45%)]	Loss: -4.2716	Cost: 10.06s
Train Epoch: 292 [61440/90000 (68%)]	Loss: -4.6069	Cost: 8.17s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -4.1014	Cost: 9.78s
Train Epoch: 292 	Average Loss: -3.9250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0400

Saving model as e292_model.pt & e292_waveforms_supplementary.hdf5
Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 0.5351	Cost: 24.71s
Train Epoch: 293 [20480/90000 (23%)]	Loss: -4.9080	Cost: 6.16s
Train Epoch: 293 [40960/90000 (45%)]	Loss: -4.6012	Cost: 8.88s
Train Epoch: 293 [61440/90000 (68%)]	Loss: -4.6981	Cost: 12.40s
Train Epoch: 293 [81920/90000 (91%)]	Loss: -3.8831	Cost: 15.19s
Train Epoch: 293 	Average Loss: -3.9821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2725

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 1.2111	Cost: 24.15s
Train Epoch: 294 [20480/90000 (23%)]	Loss: -5.0408	Cost: 6.28s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -4.6421	Cost: 10.94s
Train Epoch: 294 [61440/90000 (68%)]	Loss: -4.8185	Cost: 6.16s
Train Epoch: 294 [81920/90000 (91%)]	Loss: -4.2395	Cost: 12.05s
Train Epoch: 294 	Average Loss: -4.0385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2774

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 0.5902	Cost: 23.70s
Train Epoch: 295 [20480/90000 (23%)]	Loss: -4.7655	Cost: 8.81s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -5.0335	Cost: 8.82s
Train Epoch: 295 [61440/90000 (68%)]	Loss: -4.4493	Cost: 8.57s
Train Epoch: 295 [81920/90000 (91%)]	Loss: -4.3486	Cost: 8.00s
Train Epoch: 295 	Average Loss: -3.9894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0285

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 0.8294	Cost: 24.31s
Train Epoch: 296 [20480/90000 (23%)]	Loss: -4.8492	Cost: 12.13s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -4.6327	Cost: 6.18s
Train Epoch: 296 [61440/90000 (68%)]	Loss: -4.8325	Cost: 6.22s
Train Epoch: 296 [81920/90000 (91%)]	Loss: -3.9791	Cost: 5.82s
Train Epoch: 296 	Average Loss: -4.1002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1538

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 0.9146	Cost: 27.24s
Train Epoch: 297 [20480/90000 (23%)]	Loss: -4.9204	Cost: 9.57s
Train Epoch: 297 [40960/90000 (45%)]	Loss: -4.5440	Cost: 15.34s
Train Epoch: 297 [61440/90000 (68%)]	Loss: -4.6611	Cost: 14.41s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -4.0304	Cost: 6.72s
Train Epoch: 297 	Average Loss: -4.0272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1134

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 1.1370	Cost: 27.99s
Train Epoch: 298 [20480/90000 (23%)]	Loss: -4.8443	Cost: 6.36s
Train Epoch: 298 [40960/90000 (45%)]	Loss: -4.6369	Cost: 9.16s
Train Epoch: 298 [61440/90000 (68%)]	Loss: -4.6939	Cost: 6.02s
Train Epoch: 298 [81920/90000 (91%)]	Loss: -4.0472	Cost: 17.30s
Train Epoch: 298 	Average Loss: -4.0537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1209

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 0.6552	Cost: 28.57s
Train Epoch: 299 [20480/90000 (23%)]	Loss: -5.1183	Cost: 6.16s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -4.6180	Cost: 11.35s
Train Epoch: 299 [61440/90000 (68%)]	Loss: -4.6058	Cost: 6.34s
Train Epoch: 299 [81920/90000 (91%)]	Loss: -4.3207	Cost: 14.13s
Train Epoch: 299 	Average Loss: -4.0814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0449

Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 0.9404	Cost: 24.88s
Train Epoch: 300 [20480/90000 (23%)]	Loss: -4.7200	Cost: 8.92s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -4.6124	Cost: 8.87s
Train Epoch: 300 [61440/90000 (68%)]	Loss: -5.0126	Cost: 8.63s
Train Epoch: 300 [81920/90000 (91%)]	Loss: -4.1538	Cost: 6.19s
Train Epoch: 300 	Average Loss: -4.1485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1977

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 1.0532	Cost: 26.33s
Train Epoch: 301 [20480/90000 (23%)]	Loss: -4.8718	Cost: 6.18s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -4.5587	Cost: 10.24s
Train Epoch: 301 [61440/90000 (68%)]	Loss: -4.9438	Cost: 7.80s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -4.0683	Cost: 12.39s
Train Epoch: 301 	Average Loss: -4.1180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2323

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 0.2129	Cost: 24.76s
Train Epoch: 302 [20480/90000 (23%)]	Loss: -5.1505	Cost: 6.06s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -4.4572	Cost: 11.95s
Train Epoch: 302 [61440/90000 (68%)]	Loss: -4.7093	Cost: 6.03s
Train Epoch: 302 [81920/90000 (91%)]	Loss: -4.3890	Cost: 6.07s
Train Epoch: 302 	Average Loss: -4.1678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2732

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 1.0402	Cost: 26.40s
Train Epoch: 303 [20480/90000 (23%)]	Loss: -4.8785	Cost: 6.21s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -4.8506	Cost: 12.88s
Train Epoch: 303 [61440/90000 (68%)]	Loss: -4.6388	Cost: 14.34s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -4.5377	Cost: 14.13s
Train Epoch: 303 	Average Loss: -4.1473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1404

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 0.9983	Cost: 23.80s
Train Epoch: 304 [20480/90000 (23%)]	Loss: -5.0384	Cost: 6.44s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -4.8372	Cost: 10.20s
Train Epoch: 304 [61440/90000 (68%)]	Loss: -5.2664	Cost: 5.98s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -4.1786	Cost: 19.54s
Train Epoch: 304 	Average Loss: -4.1638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2336

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 0.7744	Cost: 24.45s
Train Epoch: 305 [20480/90000 (23%)]	Loss: -4.9536	Cost: 6.12s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -4.7209	Cost: 10.87s
Train Epoch: 305 [61440/90000 (68%)]	Loss: -5.2359	Cost: 6.18s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -4.4710	Cost: 13.23s
Train Epoch: 305 	Average Loss: -4.2099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3173

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 0.6881	Cost: 24.69s
Train Epoch: 306 [20480/90000 (23%)]	Loss: -4.8439	Cost: 6.87s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -4.7377	Cost: 9.08s
Train Epoch: 306 [61440/90000 (68%)]	Loss: -5.0260	Cost: 8.56s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -4.1539	Cost: 8.26s
Train Epoch: 306 	Average Loss: -4.2649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1903

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 0.6441	Cost: 28.22s
Train Epoch: 307 [20480/90000 (23%)]	Loss: -5.1724	Cost: 6.94s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -4.5870	Cost: 11.31s
Train Epoch: 307 [61440/90000 (68%)]	Loss: -4.9466	Cost: 6.03s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -4.3511	Cost: 6.07s
Train Epoch: 307 	Average Loss: -4.2673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1400

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 0.1825	Cost: 26.54s
Train Epoch: 308 [20480/90000 (23%)]	Loss: -4.6490	Cost: 6.71s
Train Epoch: 308 [40960/90000 (45%)]	Loss: -4.7871	Cost: 15.01s
Train Epoch: 308 [61440/90000 (68%)]	Loss: -4.6377	Cost: 12.91s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -4.4873	Cost: 10.11s
Train Epoch: 308 	Average Loss: -4.2883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1423

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 0.5672	Cost: 24.00s
Train Epoch: 309 [20480/90000 (23%)]	Loss: -4.9675	Cost: 6.19s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -4.8118	Cost: 11.40s
Train Epoch: 309 [61440/90000 (68%)]	Loss: -4.9201	Cost: 6.23s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -4.5288	Cost: 16.12s
Train Epoch: 309 	Average Loss: -4.2936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2452

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 0.7759	Cost: 24.07s
Train Epoch: 310 [20480/90000 (23%)]	Loss: -5.0176	Cost: 8.58s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -4.7868	Cost: 8.58s
Train Epoch: 310 [61440/90000 (68%)]	Loss: -5.0835	Cost: 8.43s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -4.6344	Cost: 6.95s
Train Epoch: 310 	Average Loss: -4.3203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7922

Saving model as e310_model.pt & e310_waveforms_supplementary.hdf5
Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 0.9809	Cost: 24.60s
Train Epoch: 311 [20480/90000 (23%)]	Loss: -4.9955	Cost: 6.16s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -5.0113	Cost: 8.99s
Train Epoch: 311 [61440/90000 (68%)]	Loss: -5.3086	Cost: 6.05s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -4.5384	Cost: 8.65s
Train Epoch: 311 	Average Loss: -4.3105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1274

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 0.3947	Cost: 27.44s
Train Epoch: 312 [20480/90000 (23%)]	Loss: -5.5021	Cost: 6.03s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -5.3329	Cost: 14.39s
Train Epoch: 312 [61440/90000 (68%)]	Loss: -5.1067	Cost: 6.02s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -4.7752	Cost: 5.88s
Train Epoch: 312 	Average Loss: -4.3400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1475

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 0.9864	Cost: 28.39s
Train Epoch: 313 [20480/90000 (23%)]	Loss: -4.8867	Cost: 6.05s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -4.8907	Cost: 13.50s
Train Epoch: 313 [61440/90000 (68%)]	Loss: -5.2484	Cost: 14.84s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -4.9100	Cost: 12.68s
Train Epoch: 313 	Average Loss: -4.4315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2132

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 1.0321	Cost: 28.09s
Train Epoch: 314 [20480/90000 (23%)]	Loss: -5.1005	Cost: 6.70s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -4.6818	Cost: 9.71s
Train Epoch: 314 [61440/90000 (68%)]	Loss: -5.1209	Cost: 6.12s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -4.5997	Cost: 18.23s
Train Epoch: 314 	Average Loss: -4.4091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0976

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 0.7967	Cost: 26.91s
Train Epoch: 315 [20480/90000 (23%)]	Loss: -5.2724	Cost: 6.70s
Train Epoch: 315 [40960/90000 (45%)]	Loss: -5.2245	Cost: 10.29s
Train Epoch: 315 [61440/90000 (68%)]	Loss: -5.2219	Cost: 6.27s
Train Epoch: 315 [81920/90000 (91%)]	Loss: -4.8764	Cost: 11.32s
Train Epoch: 315 	Average Loss: -4.3904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9601

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 0.3577	Cost: 23.76s
Train Epoch: 316 [20480/90000 (23%)]	Loss: -5.2919	Cost: 8.76s
Train Epoch: 316 [40960/90000 (45%)]	Loss: -5.0309	Cost: 9.06s
Train Epoch: 316 [61440/90000 (68%)]	Loss: -4.9529	Cost: 8.94s
Train Epoch: 316 [81920/90000 (91%)]	Loss: -4.7897	Cost: 7.98s
Train Epoch: 316 	Average Loss: -4.5025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0607

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 0.8832	Cost: 26.44s
Train Epoch: 317 [20480/90000 (23%)]	Loss: -4.8813	Cost: 6.05s
Train Epoch: 317 [40960/90000 (45%)]	Loss: -5.0951	Cost: 9.62s
Train Epoch: 317 [61440/90000 (68%)]	Loss: -5.2687	Cost: 6.08s
Train Epoch: 317 [81920/90000 (91%)]	Loss: -4.7774	Cost: 7.89s
Train Epoch: 317 	Average Loss: -4.4498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9884

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 0.9356	Cost: 27.88s
Train Epoch: 318 [20480/90000 (23%)]	Loss: -4.9882	Cost: 6.68s
Train Epoch: 318 [40960/90000 (45%)]	Loss: -5.3206	Cost: 13.03s
Train Epoch: 318 [61440/90000 (68%)]	Loss: -5.3737	Cost: 7.66s
Train Epoch: 318 [81920/90000 (91%)]	Loss: -4.8114	Cost: 5.73s
Train Epoch: 318 	Average Loss: -4.4654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1465

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 0.1656	Cost: 27.68s
Train Epoch: 319 [20480/90000 (23%)]	Loss: -4.9476	Cost: 6.19s
Train Epoch: 319 [40960/90000 (45%)]	Loss: -5.1839	Cost: 13.18s
Train Epoch: 319 [61440/90000 (68%)]	Loss: -5.2486	Cost: 15.15s
Train Epoch: 319 [81920/90000 (91%)]	Loss: -4.6887	Cost: 10.64s
Train Epoch: 319 	Average Loss: -4.5130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0602

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 1.1191	Cost: 26.40s
Train Epoch: 320 [20480/90000 (23%)]	Loss: -5.4182	Cost: 6.14s
Train Epoch: 320 [40960/90000 (45%)]	Loss: -5.3521	Cost: 10.53s
Train Epoch: 320 [61440/90000 (68%)]	Loss: -5.2748	Cost: 6.01s
Train Epoch: 320 [81920/90000 (91%)]	Loss: -4.7006	Cost: 18.72s
Train Epoch: 320 	Average Loss: -4.5347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2213

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 0.4585	Cost: 24.61s
Train Epoch: 321 [20480/90000 (23%)]	Loss: -5.0216	Cost: 8.78s
Train Epoch: 321 [40960/90000 (45%)]	Loss: -5.2221	Cost: 8.73s
Train Epoch: 321 [61440/90000 (68%)]	Loss: -4.9533	Cost: 6.46s
Train Epoch: 321 [81920/90000 (91%)]	Loss: -4.5861	Cost: 6.07s
Train Epoch: 321 	Average Loss: -4.5684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1175

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 1.4294	Cost: 26.29s
Train Epoch: 322 [20480/90000 (23%)]	Loss: -5.5133	Cost: 6.21s
Train Epoch: 322 [40960/90000 (45%)]	Loss: -5.0874	Cost: 8.43s
Train Epoch: 322 [61440/90000 (68%)]	Loss: -5.3430	Cost: 7.68s
Train Epoch: 322 [81920/90000 (91%)]	Loss: -4.4143	Cost: 8.30s
Train Epoch: 322 	Average Loss: -4.5425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1230

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 0.5900	Cost: 26.54s
Train Epoch: 323 [20480/90000 (23%)]	Loss: -5.5259	Cost: 6.15s
Train Epoch: 323 [40960/90000 (45%)]	Loss: -5.3623	Cost: 12.07s
Train Epoch: 323 [61440/90000 (68%)]	Loss: -5.3464	Cost: 5.95s
Train Epoch: 323 [81920/90000 (91%)]	Loss: -4.5414	Cost: 9.94s
Train Epoch: 323 	Average Loss: -4.5607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8813

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 1.1043	Cost: 26.77s
Train Epoch: 324 [20480/90000 (23%)]	Loss: -5.4559	Cost: 8.08s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -5.5299	Cost: 15.19s
Train Epoch: 324 [61440/90000 (68%)]	Loss: -5.0812	Cost: 11.25s
Train Epoch: 324 [81920/90000 (91%)]	Loss: -4.7884	Cost: 11.77s
Train Epoch: 324 	Average Loss: -4.5677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0418

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 0.7358	Cost: 24.39s
Train Epoch: 325 [20480/90000 (23%)]	Loss: -5.3725	Cost: 6.49s
Train Epoch: 325 [40960/90000 (45%)]	Loss: -5.3251	Cost: 9.50s
Train Epoch: 325 [61440/90000 (68%)]	Loss: -5.4211	Cost: 8.63s
Train Epoch: 325 [81920/90000 (91%)]	Loss: -4.7344	Cost: 16.86s
Train Epoch: 325 	Average Loss: -4.6466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8860

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 0.5616	Cost: 24.11s
Train Epoch: 326 [20480/90000 (23%)]	Loss: -5.6737	Cost: 6.36s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -5.4483	Cost: 9.50s
Train Epoch: 326 [61440/90000 (68%)]	Loss: -5.4034	Cost: 6.16s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -4.9035	Cost: 13.88s
Train Epoch: 326 	Average Loss: -4.6237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9572

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 0.7090	Cost: 24.00s
Train Epoch: 327 [20480/90000 (23%)]	Loss: -5.4809	Cost: 8.73s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -5.2974	Cost: 8.47s
Train Epoch: 327 [61440/90000 (68%)]	Loss: -5.4924	Cost: 6.02s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -4.9180	Cost: 6.25s
Train Epoch: 327 	Average Loss: -4.6567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0029

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 0.8501	Cost: 26.97s
Train Epoch: 328 [20480/90000 (23%)]	Loss: -5.1588	Cost: 6.07s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -5.2467	Cost: 8.85s
Train Epoch: 328 [61440/90000 (68%)]	Loss: -5.6325	Cost: 7.68s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -4.7585	Cost: 8.29s
Train Epoch: 328 	Average Loss: -4.7024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0397

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 0.7391	Cost: 27.42s
Train Epoch: 329 [20480/90000 (23%)]	Loss: -5.3217	Cost: 7.78s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -5.4404	Cost: 7.56s
Train Epoch: 329 [61440/90000 (68%)]	Loss: -5.6393	Cost: 11.96s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -5.0723	Cost: 5.95s
Train Epoch: 329 	Average Loss: -4.7430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9735

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 0.6593	Cost: 27.99s
Train Epoch: 330 [20480/90000 (23%)]	Loss: -5.4101	Cost: 6.39s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -5.4155	Cost: 9.83s
Train Epoch: 330 [61440/90000 (68%)]	Loss: -5.5892	Cost: 6.24s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -4.8089	Cost: 12.73s
Train Epoch: 330 	Average Loss: -4.7079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9734

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 0.7925	Cost: 23.95s
Train Epoch: 331 [20480/90000 (23%)]	Loss: -5.7099	Cost: 8.99s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -5.5263	Cost: 9.06s
Train Epoch: 331 [61440/90000 (68%)]	Loss: -5.7383	Cost: 8.88s
Train Epoch: 331 [81920/90000 (91%)]	Loss: -5.0273	Cost: 6.42s
Train Epoch: 331 	Average Loss: -4.7579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0003

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 0.7661	Cost: 24.78s
Train Epoch: 332 [20480/90000 (23%)]	Loss: -5.6633	Cost: 6.20s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -5.3243	Cost: 9.43s
Train Epoch: 332 [61440/90000 (68%)]	Loss: -5.4167	Cost: 7.51s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -4.9950	Cost: 13.08s
Train Epoch: 332 	Average Loss: -4.7586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9654

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 0.8681	Cost: 24.42s
Train Epoch: 333 [20480/90000 (23%)]	Loss: -5.0108	Cost: 12.01s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -5.5689	Cost: 6.02s
Train Epoch: 333 [61440/90000 (68%)]	Loss: -5.5117	Cost: 6.09s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -5.2324	Cost: 6.03s
Train Epoch: 333 	Average Loss: -4.7420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9281

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 0.6364	Cost: 26.56s
Train Epoch: 334 [20480/90000 (23%)]	Loss: -5.4325	Cost: 7.65s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -5.7656	Cost: 14.44s
Train Epoch: 334 [61440/90000 (68%)]	Loss: -5.2795	Cost: 14.33s
Train Epoch: 334 [81920/90000 (91%)]	Loss: -4.9844	Cost: 9.65s
Train Epoch: 334 	Average Loss: -4.8184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8575

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 0.5636	Cost: 23.55s
Train Epoch: 335 [20480/90000 (23%)]	Loss: -5.8533	Cost: 6.38s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -5.2065	Cost: 9.58s
Train Epoch: 335 [61440/90000 (68%)]	Loss: -5.4417	Cost: 6.02s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -5.2284	Cost: 16.73s
Train Epoch: 335 	Average Loss: -4.7755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6989

Saving model as e335_model.pt & e335_waveforms_supplementary.hdf5
Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 0.8135	Cost: 24.29s
Train Epoch: 336 [20480/90000 (23%)]	Loss: -5.3684	Cost: 6.07s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -5.3748	Cost: 9.11s
Train Epoch: 336 [61440/90000 (68%)]	Loss: -5.5041	Cost: 6.15s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -4.9881	Cost: 10.96s
Train Epoch: 336 	Average Loss: -4.8180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0252

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 0.4966	Cost: 29.28s
Train Epoch: 337 [20480/90000 (23%)]	Loss: -5.7641	Cost: 6.04s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -5.5250	Cost: 11.27s
Train Epoch: 337 [61440/90000 (68%)]	Loss: -5.5029	Cost: 8.44s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -5.0178	Cost: 8.34s
Train Epoch: 337 	Average Loss: -4.8340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8643

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 0.8354	Cost: 28.11s
Train Epoch: 338 [20480/90000 (23%)]	Loss: -5.3941	Cost: 11.96s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -5.1782	Cost: 6.31s
Train Epoch: 338 [61440/90000 (68%)]	Loss: -5.7398	Cost: 6.27s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -5.1914	Cost: 5.84s
Train Epoch: 338 	Average Loss: -4.8189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8486

Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 1.0426	Cost: 25.23s
Train Epoch: 339 [20480/90000 (23%)]	Loss: -5.5960	Cost: 12.61s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -5.3923	Cost: 15.38s
Train Epoch: 339 [61440/90000 (68%)]	Loss: -5.8018	Cost: 9.82s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -5.0661	Cost: 8.86s
Train Epoch: 339 	Average Loss: -4.8049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7994

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 0.4475	Cost: 25.12s
Train Epoch: 340 [20480/90000 (23%)]	Loss: -5.9199	Cost: 6.38s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -5.4552	Cost: 9.18s
Train Epoch: 340 [61440/90000 (68%)]	Loss: -5.8182	Cost: 14.18s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -5.0197	Cost: 14.12s
Train Epoch: 340 	Average Loss: -4.8753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7524

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 1.0735	Cost: 23.76s
Train Epoch: 341 [20480/90000 (23%)]	Loss: -5.8613	Cost: 6.08s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -5.5585	Cost: 10.84s
Train Epoch: 341 [61440/90000 (68%)]	Loss: -5.8951	Cost: 6.21s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -4.6521	Cost: 12.25s
Train Epoch: 341 	Average Loss: -4.8395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9684

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 0.3126	Cost: 24.31s
Train Epoch: 342 [20480/90000 (23%)]	Loss: -5.6606	Cost: 8.63s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -5.4442	Cost: 8.86s
Train Epoch: 342 [61440/90000 (68%)]	Loss: -5.7113	Cost: 7.90s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -5.0287	Cost: 5.72s
Train Epoch: 342 	Average Loss: -4.9193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9078

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 0.7088	Cost: 23.24s
Train Epoch: 343 [20480/90000 (23%)]	Loss: -5.8793	Cost: 6.20s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -5.4657	Cost: 8.63s
Train Epoch: 343 [61440/90000 (68%)]	Loss: -5.8347	Cost: 6.08s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -5.1713	Cost: 8.86s
Train Epoch: 343 	Average Loss: -4.9259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9090

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 0.4027	Cost: 28.82s
Train Epoch: 344 [20480/90000 (23%)]	Loss: -5.6244	Cost: 14.42s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -5.5707	Cost: 7.88s
Train Epoch: 344 [61440/90000 (68%)]	Loss: -5.7602	Cost: 11.94s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -5.1460	Cost: 5.73s
Train Epoch: 344 	Average Loss: -4.9316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8436

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 0.3692	Cost: 43.49s
Train Epoch: 345 [20480/90000 (23%)]	Loss: -5.6704	Cost: 6.26s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -5.7457	Cost: 9.25s
Train Epoch: 345 [61440/90000 (68%)]	Loss: -6.0416	Cost: 14.67s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -5.2132	Cost: 14.85s
Train Epoch: 345 	Average Loss: -4.8880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7964

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: -0.0056	Cost: 28.33s
Train Epoch: 346 [20480/90000 (23%)]	Loss: -6.1899	Cost: 6.30s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -5.3116	Cost: 10.57s
Train Epoch: 346 [61440/90000 (68%)]	Loss: -5.5526	Cost: 6.52s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -5.0988	Cost: 18.31s
Train Epoch: 346 	Average Loss: -4.9567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8660

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 0.2473	Cost: 30.05s
Train Epoch: 347 [20480/90000 (23%)]	Loss: -5.8793	Cost: 6.65s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -5.0982	Cost: 14.10s
Train Epoch: 347 [61440/90000 (68%)]	Loss: -5.6402	Cost: 6.04s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -4.8747	Cost: 16.59s
Train Epoch: 347 	Average Loss: -4.9173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9214

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 0.4075	Cost: 24.22s
Train Epoch: 348 [20480/90000 (23%)]	Loss: -5.8370	Cost: 8.94s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -5.4588	Cost: 9.14s
Train Epoch: 348 [61440/90000 (68%)]	Loss: -5.5334	Cost: 8.74s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -5.4028	Cost: 6.84s
Train Epoch: 348 	Average Loss: -4.9527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9858

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 0.5585	Cost: 23.31s
Train Epoch: 349 [20480/90000 (23%)]	Loss: -5.8848	Cost: 6.25s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -5.7987	Cost: 8.62s
Train Epoch: 349 [61440/90000 (68%)]	Loss: -5.4373	Cost: 6.60s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -5.0379	Cost: 13.53s
Train Epoch: 349 	Average Loss: -4.9956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7500

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 0.5043	Cost: 27.72s
Train Epoch: 350 [20480/90000 (23%)]	Loss: -6.1255	Cost: 8.19s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -5.6234	Cost: 10.08s
Train Epoch: 350 [61440/90000 (68%)]	Loss: -5.6554	Cost: 5.96s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -5.2772	Cost: 6.26s
Train Epoch: 350 	Average Loss: -4.9782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8993

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 0.3238	Cost: 27.32s
Train Epoch: 351 [20480/90000 (23%)]	Loss: -5.8381	Cost: 15.04s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -5.7410	Cost: 13.88s
Train Epoch: 351 [61440/90000 (68%)]	Loss: -5.8457	Cost: 8.91s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -5.3378	Cost: 5.61s
Train Epoch: 351 	Average Loss: -4.9564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7863

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: -0.0193	Cost: 26.65s
Train Epoch: 352 [20480/90000 (23%)]	Loss: -5.8955	Cost: 6.11s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -5.4909	Cost: 13.86s
Train Epoch: 352 [61440/90000 (68%)]	Loss: -5.6909	Cost: 14.87s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -5.3748	Cost: 11.98s
Train Epoch: 352 	Average Loss: -5.0545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8387

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 0.0791	Cost: 23.29s
Train Epoch: 353 [20480/90000 (23%)]	Loss: -5.9069	Cost: 6.39s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -5.6364	Cost: 9.60s
Train Epoch: 353 [61440/90000 (68%)]	Loss: -5.7830	Cost: 6.03s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -5.2420	Cost: 19.20s
Train Epoch: 353 	Average Loss: -4.9788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9947

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 1.0287	Cost: 24.91s
Train Epoch: 354 [20480/90000 (23%)]	Loss: -5.9788	Cost: 7.78s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -5.6465	Cost: 6.31s
Train Epoch: 354 [61440/90000 (68%)]	Loss: -6.1447	Cost: 6.20s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -5.5417	Cost: 10.26s
Train Epoch: 354 	Average Loss: -4.9986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7536

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 0.5718	Cost: 25.68s
Train Epoch: 355 [20480/90000 (23%)]	Loss: -5.8608	Cost: 6.06s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -5.6214	Cost: 10.55s
Train Epoch: 355 [61440/90000 (68%)]	Loss: -5.6947	Cost: 8.45s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -5.4288	Cost: 8.35s
Train Epoch: 355 	Average Loss: -5.0913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7914

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 0.8061	Cost: 27.46s
Train Epoch: 356 [20480/90000 (23%)]	Loss: -5.6910	Cost: 10.32s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -5.7220	Cost: 7.88s
Train Epoch: 356 [61440/90000 (68%)]	Loss: -5.6205	Cost: 6.10s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -5.0965	Cost: 5.91s
Train Epoch: 356 	Average Loss: -5.0807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9123

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: -0.3048	Cost: 26.37s
Train Epoch: 357 [20480/90000 (23%)]	Loss: -5.8654	Cost: 11.26s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -5.4077	Cost: 15.57s
Train Epoch: 357 [61440/90000 (68%)]	Loss: -5.9869	Cost: 7.87s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -5.0242	Cost: 11.11s
Train Epoch: 357 	Average Loss: -5.0206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7778

Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 0.5290	Cost: 24.00s
Train Epoch: 358 [20480/90000 (23%)]	Loss: -6.1510	Cost: 6.41s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -5.6910	Cost: 8.65s
Train Epoch: 358 [61440/90000 (68%)]	Loss: -5.8854	Cost: 6.43s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -5.2801	Cost: 17.07s
Train Epoch: 358 	Average Loss: -5.0313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7999

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 0.4990	Cost: 23.74s
Train Epoch: 359 [20480/90000 (23%)]	Loss: -5.8235	Cost: 9.13s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -5.5425	Cost: 7.75s
Train Epoch: 359 [61440/90000 (68%)]	Loss: -5.7776	Cost: 6.16s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -5.5354	Cost: 6.89s
Train Epoch: 359 	Average Loss: -5.1077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7280

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: -0.0969	Cost: 24.09s
Train Epoch: 360 [20480/90000 (23%)]	Loss: -6.1629	Cost: 6.07s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -5.8385	Cost: 8.48s
Train Epoch: 360 [61440/90000 (68%)]	Loss: -5.7980	Cost: 7.39s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -5.4485	Cost: 8.59s
Train Epoch: 360 	Average Loss: -5.1148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8831

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 0.4942	Cost: 25.98s
Train Epoch: 361 [20480/90000 (23%)]	Loss: -6.0885	Cost: 6.12s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -5.9053	Cost: 12.82s
Train Epoch: 361 [61440/90000 (68%)]	Loss: -5.9167	Cost: 6.10s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -5.2395	Cost: 5.99s
Train Epoch: 361 	Average Loss: -5.1786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8206

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 0.5814	Cost: 42.02s
Train Epoch: 362 [20480/90000 (23%)]	Loss: -5.7163	Cost: 15.02s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -5.7464	Cost: 14.71s
Train Epoch: 362 [61440/90000 (68%)]	Loss: -6.1514	Cost: 10.27s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -5.3906	Cost: 5.72s
Train Epoch: 362 	Average Loss: -5.0814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8612

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 0.3512	Cost: 27.67s
Train Epoch: 363 [20480/90000 (23%)]	Loss: -5.8419	Cost: 6.08s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -5.6150	Cost: 13.81s
Train Epoch: 363 [61440/90000 (68%)]	Loss: -5.4804	Cost: 15.36s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -5.4877	Cost: 13.03s
Train Epoch: 363 	Average Loss: -5.1723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7286

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: -0.1377	Cost: 26.42s
Train Epoch: 364 [20480/90000 (23%)]	Loss: -6.0816	Cost: 6.22s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -6.1538	Cost: 9.38s
Train Epoch: 364 [61440/90000 (68%)]	Loss: -6.0651	Cost: 5.99s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -5.5582	Cost: 18.95s
Train Epoch: 364 	Average Loss: -5.2177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9106

Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 0.1690	Cost: 28.04s
Train Epoch: 365 [20480/90000 (23%)]	Loss: -5.9733	Cost: 6.89s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -5.9930	Cost: 8.97s
Train Epoch: 365 [61440/90000 (68%)]	Loss: -5.6117	Cost: 6.43s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -5.5371	Cost: 10.76s
Train Epoch: 365 	Average Loss: -5.1748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7777

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: -0.0747	Cost: 30.10s
Train Epoch: 366 [20480/90000 (23%)]	Loss: -6.0988	Cost: 6.10s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -5.5044	Cost: 11.74s
Train Epoch: 366 [61440/90000 (68%)]	Loss: -6.0710	Cost: 8.46s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -5.4383	Cost: 8.33s
Train Epoch: 366 	Average Loss: -5.1761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7676

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 0.6237	Cost: 26.63s
Train Epoch: 367 [20480/90000 (23%)]	Loss: -5.9785	Cost: 12.25s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -5.9413	Cost: 6.20s
Train Epoch: 367 [61440/90000 (68%)]	Loss: -6.0244	Cost: 6.25s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -5.2244	Cost: 9.26s
Train Epoch: 367 	Average Loss: -5.1970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6553

Saving model as e367_model.pt & e367_waveforms_supplementary.hdf5
Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 0.2197	Cost: 25.68s
Train Epoch: 368 [20480/90000 (23%)]	Loss: -5.9650	Cost: 14.39s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -5.6172	Cost: 14.16s
Train Epoch: 368 [61440/90000 (68%)]	Loss: -6.2225	Cost: 12.06s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -5.6097	Cost: 6.00s
Train Epoch: 368 	Average Loss: -5.2026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7238

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 0.9174	Cost: 25.65s
Train Epoch: 369 [20480/90000 (23%)]	Loss: -6.3348	Cost: 6.14s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -5.7694	Cost: 10.97s
Train Epoch: 369 [61440/90000 (68%)]	Loss: -6.0251	Cost: 15.82s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -5.4225	Cost: 11.03s
Train Epoch: 369 	Average Loss: -5.1826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7473

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 0.4163	Cost: 23.78s
Train Epoch: 370 [20480/90000 (23%)]	Loss: -6.0255	Cost: 6.19s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -5.9816	Cost: 10.16s
Train Epoch: 370 [61440/90000 (68%)]	Loss: -5.8490	Cost: 6.26s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -5.6341	Cost: 10.46s
Train Epoch: 370 	Average Loss: -5.2048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7126

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 0.2237	Cost: 24.96s
Train Epoch: 371 [20480/90000 (23%)]	Loss: -5.6465	Cost: 7.38s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -5.7528	Cost: 9.43s
Train Epoch: 371 [61440/90000 (68%)]	Loss: -5.9883	Cost: 8.47s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -5.4183	Cost: 8.24s
Train Epoch: 371 	Average Loss: -5.1752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7270

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 0.5602	Cost: 27.87s
Train Epoch: 372 [20480/90000 (23%)]	Loss: -5.9049	Cost: 10.45s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -5.9449	Cost: 6.27s
Train Epoch: 372 [61440/90000 (68%)]	Loss: -5.8795	Cost: 6.10s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -5.5685	Cost: 10.25s
Train Epoch: 372 	Average Loss: -5.2771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6437

Saving model as e372_model.pt & e372_waveforms_supplementary.hdf5
Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 0.5369	Cost: 27.48s
Train Epoch: 373 [20480/90000 (23%)]	Loss: -6.0720	Cost: 14.99s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -5.8665	Cost: 11.95s
Train Epoch: 373 [61440/90000 (68%)]	Loss: -5.8603	Cost: 9.68s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -5.5553	Cost: 5.93s
Train Epoch: 373 	Average Loss: -5.2186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7000

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 0.4114	Cost: 29.56s
Train Epoch: 374 [20480/90000 (23%)]	Loss: -6.2346	Cost: 6.19s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -5.9507	Cost: 8.98s
Train Epoch: 374 [61440/90000 (68%)]	Loss: -5.7702	Cost: 10.30s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -5.5784	Cost: 14.78s
Train Epoch: 374 	Average Loss: -5.2086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7845

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 0.3372	Cost: 27.63s
Train Epoch: 375 [20480/90000 (23%)]	Loss: -6.0666	Cost: 6.46s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -5.6646	Cost: 10.29s
Train Epoch: 375 [61440/90000 (68%)]	Loss: -5.9127	Cost: 6.14s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -5.0847	Cost: 12.73s
Train Epoch: 375 	Average Loss: -5.1864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7315

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 0.0608	Cost: 24.19s
Train Epoch: 376 [20480/90000 (23%)]	Loss: -6.2846	Cost: 8.83s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -5.8245	Cost: 9.29s
Train Epoch: 376 [61440/90000 (68%)]	Loss: -5.7064	Cost: 7.77s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -5.6124	Cost: 6.98s
Train Epoch: 376 	Average Loss: -5.2209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6880

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 0.3945	Cost: 24.40s
Train Epoch: 377 [20480/90000 (23%)]	Loss: -6.1075	Cost: 6.18s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -5.5781	Cost: 9.71s
Train Epoch: 377 [61440/90000 (68%)]	Loss: -5.9915	Cost: 9.06s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -5.5170	Cost: 12.44s
Train Epoch: 377 	Average Loss: -5.2319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8922

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 0.0462	Cost: 27.82s
Train Epoch: 378 [20480/90000 (23%)]	Loss: -6.0144	Cost: 11.13s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -5.8740	Cost: 6.55s
Train Epoch: 378 [61440/90000 (68%)]	Loss: -6.1716	Cost: 6.38s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -5.4285	Cost: 5.91s
Train Epoch: 378 	Average Loss: -5.2874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8378

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 0.8252	Cost: 29.41s
Train Epoch: 379 [20480/90000 (23%)]	Loss: -6.0996	Cost: 11.96s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -5.6651	Cost: 7.54s
Train Epoch: 379 [61440/90000 (68%)]	Loss: -5.6616	Cost: 10.65s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -5.5186	Cost: 5.94s
Train Epoch: 379 	Average Loss: -5.2444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8789

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 0.5599	Cost: 27.21s
Train Epoch: 380 [20480/90000 (23%)]	Loss: -6.0706	Cost: 6.24s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -5.9280	Cost: 14.67s
Train Epoch: 380 [61440/90000 (68%)]	Loss: -6.0340	Cost: 15.22s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -5.5185	Cost: 12.28s
Train Epoch: 380 	Average Loss: -5.2975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8729

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 0.1122	Cost: 24.44s
Train Epoch: 381 [20480/90000 (23%)]	Loss: -6.4398	Cost: 6.34s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -6.0216	Cost: 9.09s
Train Epoch: 381 [61440/90000 (68%)]	Loss: -5.8866	Cost: 9.22s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -5.4527	Cost: 14.81s
Train Epoch: 381 	Average Loss: -5.3118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6143

Saving model as e381_model.pt & e381_waveforms_supplementary.hdf5
Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 0.7654	Cost: 25.51s
Train Epoch: 382 [20480/90000 (23%)]	Loss: -6.0437	Cost: 6.29s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -5.9810	Cost: 10.73s
Train Epoch: 382 [61440/90000 (68%)]	Loss: -6.0559	Cost: 6.13s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -5.3565	Cost: 16.10s
Train Epoch: 382 	Average Loss: -5.2381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7735

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 0.3804	Cost: 25.00s
Train Epoch: 383 [20480/90000 (23%)]	Loss: -6.4370	Cost: 8.72s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -6.2038	Cost: 8.90s
Train Epoch: 383 [61440/90000 (68%)]	Loss: -6.2647	Cost: 7.95s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -5.2966	Cost: 5.70s
Train Epoch: 383 	Average Loss: -5.2666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6706

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 0.2687	Cost: 30.19s
Train Epoch: 384 [20480/90000 (23%)]	Loss: -6.3041	Cost: 6.02s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -5.8823	Cost: 11.04s
Train Epoch: 384 [61440/90000 (68%)]	Loss: -5.9857	Cost: 8.49s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -4.9033	Cost: 8.31s
Train Epoch: 384 	Average Loss: -5.2662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8998

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 0.7188	Cost: 29.60s
Train Epoch: 385 [20480/90000 (23%)]	Loss: -6.1368	Cost: 7.15s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -5.6482	Cost: 11.43s
Train Epoch: 385 [61440/90000 (68%)]	Loss: -5.8156	Cost: 6.20s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -5.5238	Cost: 5.87s
Train Epoch: 385 	Average Loss: -5.3163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6924

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 0.5028	Cost: 26.96s
Train Epoch: 386 [20480/90000 (23%)]	Loss: -5.8528	Cost: 6.95s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -6.0277	Cost: 15.57s
Train Epoch: 386 [61440/90000 (68%)]	Loss: -5.7240	Cost: 12.06s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -5.5561	Cost: 7.60s
Train Epoch: 386 	Average Loss: -5.2659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8241

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 0.4922	Cost: 24.26s
Train Epoch: 387 [20480/90000 (23%)]	Loss: -6.0922	Cost: 6.40s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -6.1379	Cost: 9.33s
Train Epoch: 387 [61440/90000 (68%)]	Loss: -5.9571	Cost: 6.93s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -5.8734	Cost: 12.37s
Train Epoch: 387 	Average Loss: -5.2856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6441

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 0.9899	Cost: 25.59s
Train Epoch: 388 [20480/90000 (23%)]	Loss: -6.2081	Cost: 7.66s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -5.9585	Cost: 9.84s
Train Epoch: 388 [61440/90000 (68%)]	Loss: -6.2704	Cost: 8.40s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -5.5941	Cost: 8.55s
Train Epoch: 388 	Average Loss: -5.2965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8010

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 0.1237	Cost: 26.39s
Train Epoch: 389 [20480/90000 (23%)]	Loss: -6.0891	Cost: 12.13s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -6.0383	Cost: 6.28s
Train Epoch: 389 [61440/90000 (68%)]	Loss: -5.9425	Cost: 6.17s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -5.8148	Cost: 6.03s
Train Epoch: 389 	Average Loss: -5.3179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7022

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 0.7863	Cost: 29.04s
Train Epoch: 390 [20480/90000 (23%)]	Loss: -6.0705	Cost: 10.26s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -5.7555	Cost: 15.09s
Train Epoch: 390 [61440/90000 (68%)]	Loss: -6.2158	Cost: 14.65s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -5.4572	Cost: 5.85s
Train Epoch: 390 	Average Loss: -5.2712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6333

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: -0.0106	Cost: 27.53s
Train Epoch: 391 [20480/90000 (23%)]	Loss: -6.1913	Cost: 6.38s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -5.8949	Cost: 8.88s
Train Epoch: 391 [61440/90000 (68%)]	Loss: -6.2726	Cost: 10.34s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -5.6023	Cost: 14.96s
Train Epoch: 391 	Average Loss: -5.3065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8074

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 0.9811	Cost: 27.62s
Train Epoch: 392 [20480/90000 (23%)]	Loss: -5.9139	Cost: 6.27s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -5.6616	Cost: 11.17s
Train Epoch: 392 [61440/90000 (68%)]	Loss: -5.8692	Cost: 6.46s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -5.3733	Cost: 10.94s
Train Epoch: 392 	Average Loss: -5.2516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8152

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 0.4318	Cost: 24.67s
Train Epoch: 393 [20480/90000 (23%)]	Loss: -6.3252	Cost: 8.21s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -5.9282	Cost: 9.47s
Train Epoch: 393 [61440/90000 (68%)]	Loss: -5.8532	Cost: 8.68s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -5.9142	Cost: 8.45s
Train Epoch: 393 	Average Loss: -5.2527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7296

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 0.1496	Cost: 24.56s
Train Epoch: 394 [20480/90000 (23%)]	Loss: -5.8605	Cost: 7.90s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -6.0641	Cost: 10.40s
Train Epoch: 394 [61440/90000 (68%)]	Loss: -5.9693	Cost: 6.41s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -5.8030	Cost: 7.56s
Train Epoch: 394 	Average Loss: -5.2822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6311

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 1.2003	Cost: 23.75s
Train Epoch: 395 [20480/90000 (23%)]	Loss: -6.2196	Cost: 6.26s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -5.8277	Cost: 8.57s
Train Epoch: 395 [61440/90000 (68%)]	Loss: -6.2439	Cost: 6.04s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -5.6301	Cost: 9.31s
Train Epoch: 395 	Average Loss: -5.3063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6370

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 0.6081	Cost: 24.52s
Train Epoch: 396 [20480/90000 (23%)]	Loss: -6.1436	Cost: 6.26s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -6.0426	Cost: 10.42s
Train Epoch: 396 [61440/90000 (68%)]	Loss: -6.0226	Cost: 6.13s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -5.7983	Cost: 7.51s
Train Epoch: 396 	Average Loss: -5.2676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7233

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 0.6562	Cost: 23.95s
Train Epoch: 397 [20480/90000 (23%)]	Loss: -6.0985	Cost: 6.50s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -5.9430	Cost: 7.97s
Train Epoch: 397 [61440/90000 (68%)]	Loss: -5.7572	Cost: 6.01s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -5.4526	Cost: 7.97s
Train Epoch: 397 	Average Loss: -5.2788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7867

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 0.3570	Cost: 24.70s
Train Epoch: 398 [20480/90000 (23%)]	Loss: -6.3235	Cost: 6.33s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -6.1519	Cost: 8.58s
Train Epoch: 398 [61440/90000 (68%)]	Loss: -6.0057	Cost: 6.30s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -5.5519	Cost: 7.48s
Train Epoch: 398 	Average Loss: -5.2916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8012

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 0.0579	Cost: 24.89s
Train Epoch: 399 [20480/90000 (23%)]	Loss: -6.1568	Cost: 6.15s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -5.7472	Cost: 11.23s
Train Epoch: 399 [61440/90000 (68%)]	Loss: -6.1768	Cost: 6.03s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -5.6632	Cost: 12.29s
Train Epoch: 399 	Average Loss: -5.3040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7488

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 1.1770	Cost: 23.40s
Train Epoch: 400 [20480/90000 (23%)]	Loss: -5.8321	Cost: 6.34s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -5.7495	Cost: 10.47s
Train Epoch: 400 [61440/90000 (68%)]	Loss: -6.1075	Cost: 6.29s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -5.5565	Cost: 12.41s
Train Epoch: 400 	Average Loss: -5.2514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7313

Stopping timer.
Training time (including validation): 137700.2345097065 seconds
Saving model
Transfer learning by starting with alpha=0.4!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 36.6475	Cost: 26.00s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 17.4634	Cost: 6.59s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 14.7576	Cost: 13.36s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 12.9342	Cost: 6.41s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 13.0058	Cost: 13.16s
Train Epoch: 1 	Average Loss: 16.1467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3831

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 12.3936	Cost: 30.22s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 12.0375	Cost: 14.65s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 11.2171	Cost: 8.34s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 11.0770	Cost: 10.20s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 11.1906	Cost: 6.16s
Train Epoch: 2 	Average Loss: 11.6148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0806

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 11.2193	Cost: 29.27s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 10.8544	Cost: 6.42s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 10.4646	Cost: 13.34s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 10.7029	Cost: 15.19s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 10.4129	Cost: 11.75s
Train Epoch: 3 	Average Loss: 10.6930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4953

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 10.4057	Cost: 28.64s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 10.2103	Cost: 6.12s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 10.1491	Cost: 14.95s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 10.1976	Cost: 13.94s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 9.7949	Cost: 10.35s
Train Epoch: 4 	Average Loss: 10.1715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1860

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 9.8223	Cost: 28.39s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 9.8692	Cost: 6.23s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 9.7056	Cost: 15.96s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 9.9356	Cost: 12.98s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 9.5187	Cost: 9.47s
Train Epoch: 5 	Average Loss: 9.6911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7617

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 9.5689	Cost: 27.58s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 9.7126	Cost: 6.48s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 9.2563	Cost: 15.14s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 9.2018	Cost: 15.94s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 9.3970	Cost: 14.33s
Train Epoch: 6 	Average Loss: 9.4692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4909

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 9.6160	Cost: 28.02s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 9.2027	Cost: 6.18s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 8.8947	Cost: 16.00s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 8.9381	Cost: 12.79s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 9.0453	Cost: 10.30s
Train Epoch: 7 	Average Loss: 9.2609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5658

Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 9.5201	Cost: 26.59s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 9.0549	Cost: 6.69s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 9.4227	Cost: 10.70s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 8.9723	Cost: 13.68s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 8.8781	Cost: 14.99s
Train Epoch: 8 	Average Loss: 9.1882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6002

Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 9.1332	Cost: 23.74s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 9.1983	Cost: 6.55s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 8.7308	Cost: 9.43s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 9.1590	Cost: 7.87s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 8.8976	Cost: 20.09s
Train Epoch: 9 	Average Loss: 9.0545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2784

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 9.3424	Cost: 25.52s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 8.8529	Cost: 6.44s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 9.0564	Cost: 10.19s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 8.6887	Cost: 6.09s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 8.8123	Cost: 19.85s
Train Epoch: 10 	Average Loss: 8.9528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5015

Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 9.0250	Cost: 24.08s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 8.8234	Cost: 6.53s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 8.7143	Cost: 9.23s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 8.7913	Cost: 6.17s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 9.0051	Cost: 10.09s
Train Epoch: 11 	Average Loss: 8.8120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0890

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 8.9743	Cost: 23.34s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 8.6542	Cost: 8.70s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 8.7438	Cost: 8.84s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 8.5601	Cost: 6.36s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 8.5422	Cost: 6.40s
Train Epoch: 12 	Average Loss: 8.7374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2399

Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 9.1541	Cost: 23.81s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 8.4450	Cost: 6.21s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 8.2223	Cost: 9.76s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 8.4230	Cost: 7.13s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 8.6552	Cost: 10.41s
Train Epoch: 13 	Average Loss: 8.6206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3934

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 9.1369	Cost: 25.55s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 8.4843	Cost: 6.12s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 8.1602	Cost: 11.84s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 8.2060	Cost: 6.04s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 8.5458	Cost: 5.92s
Train Epoch: 14 	Average Loss: 8.6002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1677

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 9.2742	Cost: 44.97s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 8.2694	Cost: 15.62s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 8.2997	Cost: 12.15s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 8.5436	Cost: 5.91s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 8.3193	Cost: 5.89s
Train Epoch: 15 	Average Loss: 8.6128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1421

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 9.0699	Cost: 44.10s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 8.3200	Cost: 16.02s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 8.0452	Cost: 15.49s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 7.9651	Cost: 7.31s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 8.2944	Cost: 6.21s
Train Epoch: 16 	Average Loss: 8.4165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1759

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 9.2741	Cost: 34.55s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 8.3289	Cost: 13.07s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 7.8970	Cost: 15.09s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 8.1292	Cost: 11.81s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 8.6175	Cost: 5.90s
Train Epoch: 17 	Average Loss: 8.4243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1707

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 9.0257	Cost: 34.58s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 8.3986	Cost: 8.26s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 7.8496	Cost: 15.12s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 8.0601	Cost: 14.68s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 8.2207	Cost: 7.69s
Train Epoch: 18 	Average Loss: 8.3113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9451

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 9.1152	Cost: 31.23s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 8.1794	Cost: 6.04s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 7.9973	Cost: 16.07s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 8.0337	Cost: 14.88s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 7.8372	Cost: 8.83s
Train Epoch: 19 	Average Loss: 8.2062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0923

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 9.0764	Cost: 28.75s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 7.9884	Cost: 6.22s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 8.0052	Cost: 15.37s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 7.4419	Cost: 14.85s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 8.0814	Cost: 11.91s
Train Epoch: 20 	Average Loss: 8.1038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1139

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 9.3175	Cost: 29.29s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 8.2044	Cost: 6.18s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 7.8054	Cost: 15.70s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 7.3511	Cost: 15.43s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 7.9988	Cost: 12.63s
Train Epoch: 21 	Average Loss: 8.0724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0363

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 9.1573	Cost: 30.27s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 7.8456	Cost: 6.27s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 8.0363	Cost: 14.43s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 7.8781	Cost: 15.37s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 8.4512	Cost: 12.73s
Train Epoch: 22 	Average Loss: 8.0419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0532

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 8.5098	Cost: 26.50s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 8.2092	Cost: 6.17s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 7.9076	Cost: 14.35s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 7.7360	Cost: 15.88s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 7.6035	Cost: 12.02s
Train Epoch: 23 	Average Loss: 8.0022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9019

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 8.9430	Cost: 27.80s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 7.8228	Cost: 6.07s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 7.7157	Cost: 15.15s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 7.5241	Cost: 13.99s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 7.6852	Cost: 9.58s
Train Epoch: 24 	Average Loss: 7.9176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9621

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 8.6720	Cost: 27.12s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 7.7094	Cost: 6.33s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 7.8594	Cost: 15.08s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 7.6389	Cost: 15.74s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 8.0202	Cost: 12.15s
Train Epoch: 25 	Average Loss: 7.8755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9466

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 8.3673	Cost: 26.21s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 7.9375	Cost: 6.33s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 7.5874	Cost: 13.98s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 7.3821	Cost: 15.88s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 8.2745	Cost: 13.02s
Train Epoch: 26 	Average Loss: 7.8717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0504

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 9.0166	Cost: 27.83s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 7.7549	Cost: 6.43s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 7.8787	Cost: 11.04s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 7.0615	Cost: 16.10s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 7.5916	Cost: 12.52s
Train Epoch: 27 	Average Loss: 7.8687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0470

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 8.9712	Cost: 27.48s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 7.6663	Cost: 6.62s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 7.8176	Cost: 10.11s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 7.4803	Cost: 14.28s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 7.6396	Cost: 15.01s
Train Epoch: 28 	Average Loss: 7.8150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1150

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 8.4824	Cost: 27.73s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 7.8925	Cost: 6.55s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 7.3140	Cost: 10.62s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 7.5461	Cost: 15.86s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 7.6282	Cost: 13.40s
Train Epoch: 29 	Average Loss: 7.7055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0773

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 8.5463	Cost: 28.29s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 7.6845	Cost: 6.45s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 7.3516	Cost: 14.93s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 7.5631	Cost: 15.89s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 7.4341	Cost: 13.09s
Train Epoch: 30 	Average Loss: 7.6080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0827

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 8.6503	Cost: 29.82s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 7.3066	Cost: 6.20s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 7.3389	Cost: 13.91s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 7.1758	Cost: 16.01s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 7.6573	Cost: 11.93s
Train Epoch: 31 	Average Loss: 7.5882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9816

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 8.7715	Cost: 27.52s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 7.1355	Cost: 6.48s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 7.1834	Cost: 12.00s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 7.2564	Cost: 15.43s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 7.1769	Cost: 12.14s
Train Epoch: 32 	Average Loss: 7.5391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8646

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 8.5277	Cost: 28.58s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 7.4173	Cost: 6.16s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 6.8735	Cost: 12.84s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 7.1993	Cost: 15.87s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 7.4971	Cost: 10.18s
Train Epoch: 33 	Average Loss: 7.4716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8656

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 8.7975	Cost: 27.78s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 7.7471	Cost: 6.46s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 7.2401	Cost: 14.91s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 7.1814	Cost: 16.09s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 7.6333	Cost: 11.12s
Train Epoch: 34 	Average Loss: 7.5262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9845

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 8.8957	Cost: 26.01s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 7.5422	Cost: 6.51s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 7.3926	Cost: 13.13s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 6.9063	Cost: 15.51s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 7.3339	Cost: 13.32s
Train Epoch: 35 	Average Loss: 7.4405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9007

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 8.5618	Cost: 28.87s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 7.3420	Cost: 6.27s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 7.3868	Cost: 14.94s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 7.4310	Cost: 14.85s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 7.5961	Cost: 10.08s
Train Epoch: 36 	Average Loss: 7.4351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8046

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 8.5228	Cost: 29.56s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 7.3719	Cost: 6.08s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 7.4497	Cost: 15.19s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 7.1939	Cost: 13.89s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 7.2858	Cost: 11.04s
Train Epoch: 37 	Average Loss: 7.4070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8605

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 9.6023	Cost: 28.66s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 7.3762	Cost: 6.23s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 6.8902	Cost: 10.83s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 7.3005	Cost: 15.45s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 7.0240	Cost: 12.83s
Train Epoch: 38 	Average Loss: 7.3773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0556

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 8.7949	Cost: 26.01s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 7.3063	Cost: 6.49s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 6.7794	Cost: 9.89s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 7.0376	Cost: 10.26s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 7.0712	Cost: 15.95s
Train Epoch: 39 	Average Loss: 7.2930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9057

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 8.3269	Cost: 25.52s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 7.0217	Cost: 6.59s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 7.1467	Cost: 10.02s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 6.7595	Cost: 6.04s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 7.3171	Cost: 16.34s
Train Epoch: 40 	Average Loss: 7.3232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0530

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 8.5926	Cost: 23.36s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 7.1472	Cost: 6.21s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 7.5284	Cost: 9.07s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 7.1446	Cost: 6.24s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 7.3894	Cost: 10.45s
Train Epoch: 41 	Average Loss: 7.5121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0513

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 8.6877	Cost: 25.96s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 7.4877	Cost: 6.51s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 7.1570	Cost: 10.18s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 6.7844	Cost: 8.38s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 7.0457	Cost: 9.30s
Train Epoch: 42 	Average Loss: 7.3725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0649

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 8.4839	Cost: 25.41s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 7.1067	Cost: 6.14s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 6.8441	Cost: 8.50s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 7.1251	Cost: 6.02s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 7.1313	Cost: 9.00s
Train Epoch: 43 	Average Loss: 7.2854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9758

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 8.7506	Cost: 32.31s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 7.2052	Cost: 6.55s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 6.6853	Cost: 12.16s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 6.9388	Cost: 5.95s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 6.8464	Cost: 8.29s
Train Epoch: 44 	Average Loss: 7.2220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7894

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 8.5202	Cost: 29.36s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 6.8787	Cost: 15.17s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 6.8283	Cost: 9.87s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 6.8163	Cost: 8.91s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 7.2102	Cost: 5.99s
Train Epoch: 45 	Average Loss: 7.1355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9085

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 8.4917	Cost: 25.36s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 6.6128	Cost: 6.16s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 6.9462	Cost: 16.22s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 6.7377	Cost: 11.86s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 7.1025	Cost: 11.79s
Train Epoch: 46 	Average Loss: 7.0702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8411

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 8.6506	Cost: 25.74s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 7.1292	Cost: 6.21s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 6.6947	Cost: 10.50s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 6.8107	Cost: 6.02s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 6.9789	Cost: 19.81s
Train Epoch: 47 	Average Loss: 7.1063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8689

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 8.5305	Cost: 24.98s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 7.0936	Cost: 6.34s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 6.7912	Cost: 9.83s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 6.5245	Cost: 6.10s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 6.6778	Cost: 19.02s
Train Epoch: 48 	Average Loss: 6.9990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7568

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 8.5329	Cost: 24.20s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 6.5151	Cost: 6.23s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 6.3886	Cost: 9.66s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 6.4565	Cost: 6.04s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 6.7937	Cost: 19.37s
Train Epoch: 49 	Average Loss: 6.9466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0410

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 8.2680	Cost: 23.68s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 6.8714	Cost: 8.66s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 6.5358	Cost: 13.37s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 6.5378	Cost: 6.43s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 6.8643	Cost: 20.00s
Train Epoch: 50 	Average Loss: 6.9239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7944

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 8.5660	Cost: 23.31s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 6.5738	Cost: 6.45s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 6.4259	Cost: 9.08s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 6.5932	Cost: 6.57s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 6.8180	Cost: 12.15s
Train Epoch: 51 	Average Loss: 6.8411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9414

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 8.5446	Cost: 24.82s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 6.7487	Cost: 8.78s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 6.5795	Cost: 8.77s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 6.4860	Cost: 8.36s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 6.7113	Cost: 6.32s
Train Epoch: 52 	Average Loss: 6.8299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0228

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 8.2725	Cost: 23.93s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 6.5166	Cost: 6.72s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 6.8731	Cost: 9.07s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 6.3671	Cost: 8.71s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 6.8736	Cost: 8.55s
Train Epoch: 53 	Average Loss: 6.8532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7550

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 8.5677	Cost: 24.40s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 6.7509	Cost: 11.32s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 6.5565	Cost: 6.37s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 6.6353	Cost: 6.12s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 6.9685	Cost: 7.79s
Train Epoch: 54 	Average Loss: 6.9199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9587

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 8.0869	Cost: 29.67s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 6.7371	Cost: 9.89s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 6.6051	Cost: 11.12s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 6.6635	Cost: 6.97s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 6.6900	Cost: 6.14s
Train Epoch: 55 	Average Loss: 6.8363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0642

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 8.3221	Cost: 31.98s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 6.5411	Cost: 15.08s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 6.5086	Cost: 15.37s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 6.2879	Cost: 9.57s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 6.5457	Cost: 5.96s
Train Epoch: 56 	Average Loss: 6.7026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6353

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 7.9435	Cost: 29.50s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 6.5746	Cost: 15.97s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 6.3693	Cost: 15.01s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 6.1830	Cost: 7.97s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 6.4731	Cost: 5.94s
Train Epoch: 57 	Average Loss: 6.7698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8120

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 8.3505	Cost: 31.37s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 6.8621	Cost: 12.19s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 6.2214	Cost: 15.10s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 6.0455	Cost: 12.67s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 6.5633	Cost: 6.05s
Train Epoch: 58 	Average Loss: 6.6822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7645

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 8.1617	Cost: 26.80s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 6.6863	Cost: 6.21s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 6.2871	Cost: 15.09s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 6.1007	Cost: 14.71s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 6.6123	Cost: 9.90s
Train Epoch: 59 	Average Loss: 6.5681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7687

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 8.8590	Cost: 29.85s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 6.3614	Cost: 6.17s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 6.5926	Cost: 15.37s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 6.2579	Cost: 15.76s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 6.3578	Cost: 9.18s
Train Epoch: 60 	Average Loss: 6.6428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9886

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 8.4186	Cost: 30.93s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 6.6300	Cost: 6.17s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 6.1910	Cost: 16.17s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 6.1156	Cost: 15.10s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 6.5310	Cost: 8.72s
Train Epoch: 61 	Average Loss: 6.6715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9308

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 8.4626	Cost: 28.05s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 6.3648	Cost: 6.33s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 6.1522	Cost: 15.38s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 6.0630	Cost: 12.83s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 6.2167	Cost: 11.97s
Train Epoch: 62 	Average Loss: 6.5001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9309

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 8.3291	Cost: 27.85s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 6.3327	Cost: 5.99s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 6.2057	Cost: 14.46s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 5.9184	Cost: 14.97s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 6.4273	Cost: 11.05s
Train Epoch: 63 	Average Loss: 6.5187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9703

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 8.3022	Cost: 26.27s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 6.5378	Cost: 6.36s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 6.3898	Cost: 10.66s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 5.7633	Cost: 14.29s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 6.6133	Cost: 15.00s
Train Epoch: 64 	Average Loss: 6.5669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0031

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 8.7872	Cost: 24.39s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 6.3336	Cost: 6.49s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 6.2767	Cost: 9.02s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 5.7434	Cost: 11.69s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 6.4617	Cost: 15.86s
Train Epoch: 65 	Average Loss: 6.4518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6541

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 8.1082	Cost: 25.97s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 6.0751	Cost: 6.63s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 6.2948	Cost: 9.39s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 5.7049	Cost: 8.28s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 6.0630	Cost: 17.15s
Train Epoch: 66 	Average Loss: 6.3930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7234

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 8.2587	Cost: 28.11s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 5.8956	Cost: 6.25s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 5.6861	Cost: 9.77s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 5.8684	Cost: 6.05s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 6.3973	Cost: 18.14s
Train Epoch: 67 	Average Loss: 6.3858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0002

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 8.1988	Cost: 23.75s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 6.0125	Cost: 6.39s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 6.0662	Cost: 9.13s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 5.6654	Cost: 6.22s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 6.2742	Cost: 9.97s
Train Epoch: 68 	Average Loss: 6.4118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0661

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 8.5944	Cost: 24.55s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 6.2676	Cost: 8.83s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 5.9307	Cost: 7.79s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 6.0061	Cost: 6.08s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 6.0948	Cost: 9.28s
Train Epoch: 69 	Average Loss: 6.3871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8097

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 8.5949	Cost: 23.92s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 5.9209	Cost: 6.05s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 6.0155	Cost: 10.25s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 5.6374	Cost: 8.34s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 5.9978	Cost: 8.74s
Train Epoch: 70 	Average Loss: 6.3244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9144

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 8.7750	Cost: 25.80s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 6.0359	Cost: 9.92s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 5.7754	Cost: 6.07s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 5.5113	Cost: 6.04s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 6.2141	Cost: 7.58s
Train Epoch: 71 	Average Loss: 6.3031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9485

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 8.0150	Cost: 40.40s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 6.2847	Cost: 11.66s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 5.8194	Cost: 6.27s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 6.0953	Cost: 11.69s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 6.2939	Cost: 5.89s
Train Epoch: 72 	Average Loss: 6.3602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8772

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 8.4026	Cost: 42.99s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 5.7296	Cost: 6.17s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 5.8454	Cost: 15.86s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 5.5850	Cost: 14.73s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 5.9238	Cost: 10.47s
Train Epoch: 73 	Average Loss: 6.2661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9590

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 8.8126	Cost: 34.51s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 6.0337	Cost: 6.22s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 6.0493	Cost: 15.76s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 5.4451	Cost: 14.59s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 6.1082	Cost: 9.27s
Train Epoch: 74 	Average Loss: 6.2166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0293

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 8.7275	Cost: 29.06s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 5.7220	Cost: 6.18s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 6.0643	Cost: 15.07s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 5.6639	Cost: 14.58s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 6.0397	Cost: 10.12s
Train Epoch: 75 	Average Loss: 6.2304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9251

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 8.4959	Cost: 29.20s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 6.3710	Cost: 6.07s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 6.4936	Cost: 16.23s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 5.5609	Cost: 14.21s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 6.0461	Cost: 10.99s
Train Epoch: 76 	Average Loss: 6.2423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8732

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 9.0804	Cost: 27.17s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 6.1845	Cost: 6.36s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 5.5060	Cost: 15.14s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 5.6876	Cost: 15.52s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 6.1983	Cost: 14.14s
Train Epoch: 77 	Average Loss: 6.3261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7747

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 8.2158	Cost: 29.36s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 6.2009	Cost: 6.21s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 5.8485	Cost: 15.13s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 5.9067	Cost: 14.03s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 6.3346	Cost: 12.00s
Train Epoch: 78 	Average Loss: 6.2048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9629

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 8.8488	Cost: 27.97s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 5.8595	Cost: 6.18s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 5.7193	Cost: 14.71s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 5.7723	Cost: 15.16s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 6.0135	Cost: 11.00s
Train Epoch: 79 	Average Loss: 6.1895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0054

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 8.5014	Cost: 26.25s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 6.0672	Cost: 6.44s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 5.8849	Cost: 10.03s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 5.3031	Cost: 15.63s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 6.0840	Cost: 14.40s
Train Epoch: 80 	Average Loss: 6.0738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0903

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 8.5888	Cost: 24.81s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 5.6930	Cost: 6.39s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 5.9665	Cost: 10.61s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 5.6513	Cost: 12.22s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 6.1283	Cost: 15.16s
Train Epoch: 81 	Average Loss: 6.1439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8852

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 8.6013	Cost: 24.61s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 6.1761	Cost: 6.56s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 5.7314	Cost: 9.34s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 5.6312	Cost: 10.25s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 5.9304	Cost: 17.95s
Train Epoch: 82 	Average Loss: 6.0836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8906

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 8.2622	Cost: 27.88s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 5.7798	Cost: 6.60s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 5.6514	Cost: 10.30s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 5.6168	Cost: 9.57s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 5.8018	Cost: 16.82s
Train Epoch: 83 	Average Loss: 5.9483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8685

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 8.3805	Cost: 27.32s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 5.9910	Cost: 6.59s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 5.4853	Cost: 10.72s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 5.5672	Cost: 14.37s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 5.8688	Cost: 13.83s
Train Epoch: 84 	Average Loss: 6.0173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8728

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 8.5072	Cost: 26.66s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 5.7127	Cost: 6.43s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 5.5291	Cost: 10.38s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 5.5510	Cost: 13.27s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 5.9358	Cost: 15.13s
Train Epoch: 85 	Average Loss: 6.0103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9682

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 8.0623	Cost: 27.22s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 5.7902	Cost: 6.55s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 5.6609	Cost: 10.60s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 5.7940	Cost: 15.84s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 5.9538	Cost: 15.49s
Train Epoch: 86 	Average Loss: 5.9691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8797

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 8.3920	Cost: 27.22s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 5.7787	Cost: 6.46s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 5.5811	Cost: 15.05s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 5.7563	Cost: 15.87s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 6.2115	Cost: 13.97s
Train Epoch: 87 	Average Loss: 6.0093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0326

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 8.2391	Cost: 27.19s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 5.7858	Cost: 6.30s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 5.8491	Cost: 16.83s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 5.1867	Cost: 15.69s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 5.7246	Cost: 13.10s
Train Epoch: 88 	Average Loss: 6.0057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9181

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 8.4924	Cost: 30.98s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 5.7248	Cost: 6.69s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 5.3987	Cost: 15.62s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 5.1268	Cost: 15.88s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 5.3305	Cost: 10.86s
Train Epoch: 89 	Average Loss: 5.8491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9822

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 7.8999	Cost: 34.46s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 5.3433	Cost: 6.98s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 5.6978	Cost: 15.06s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 5.4111	Cost: 15.81s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 5.3063	Cost: 12.18s
Train Epoch: 90 	Average Loss: 5.8193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8397

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 8.1068	Cost: 35.90s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 5.6814	Cost: 6.28s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 5.8640	Cost: 16.67s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 5.3229	Cost: 14.90s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 5.8365	Cost: 8.75s
Train Epoch: 91 	Average Loss: 5.8153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9297

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 8.4067	Cost: 33.59s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 5.7866	Cost: 6.15s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 5.4361	Cost: 16.08s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 5.2384	Cost: 15.18s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 5.7076	Cost: 8.60s
Train Epoch: 92 	Average Loss: 5.7750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9516

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 9.1253	Cost: 29.92s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 5.4939	Cost: 6.16s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 5.3100	Cost: 14.32s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 5.2082	Cost: 15.52s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 5.6199	Cost: 11.02s
Train Epoch: 93 	Average Loss: 5.7595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9267

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 7.9387	Cost: 27.87s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 5.3028	Cost: 6.26s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 5.3026	Cost: 10.95s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 5.2827	Cost: 15.15s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 5.7534	Cost: 14.33s
Train Epoch: 94 	Average Loss: 5.8349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0081

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 8.4931	Cost: 25.03s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 5.8018	Cost: 6.69s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 5.6457	Cost: 9.99s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 5.3847	Cost: 6.44s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 5.8099	Cost: 17.67s
Train Epoch: 95 	Average Loss: 5.8720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9206

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 8.6344	Cost: 23.94s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 5.4986	Cost: 6.33s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 5.1369	Cost: 9.40s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 5.5844	Cost: 6.17s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 5.5073	Cost: 11.04s
Train Epoch: 96 	Average Loss: 5.7614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0875

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 8.3839	Cost: 25.30s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 5.6242	Cost: 8.76s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 5.3830	Cost: 8.76s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 5.2780	Cost: 8.36s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 5.4995	Cost: 5.90s
Train Epoch: 97 	Average Loss: 5.8470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7414

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 8.3238	Cost: 27.20s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 5.6734	Cost: 6.27s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 5.2519	Cost: 9.04s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 5.3275	Cost: 8.46s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 5.4205	Cost: 8.59s
Train Epoch: 98 	Average Loss: 5.7371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8369

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 8.3740	Cost: 34.80s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 5.7938	Cost: 6.36s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 5.5486	Cost: 11.46s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 5.2056	Cost: 6.09s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 5.6820	Cost: 12.74s
Train Epoch: 99 	Average Loss: 5.7215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9653

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 8.6707	Cost: 29.11s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 5.1618	Cost: 7.06s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 5.1141	Cost: 11.60s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 5.0914	Cost: 6.06s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 5.4055	Cost: 12.89s
Train Epoch: 100 	Average Loss: 5.5752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8126

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 8.6944	Cost: 30.55s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 5.6635	Cost: 14.44s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 5.4150	Cost: 10.48s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 5.2654	Cost: 8.12s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 5.2277	Cost: 6.02s
Train Epoch: 101 	Average Loss: 5.6478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8224

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 8.0384	Cost: 29.48s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 5.3612	Cost: 9.46s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 5.2437	Cost: 16.05s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 4.9128	Cost: 13.19s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 5.3011	Cost: 7.77s
Train Epoch: 102 	Average Loss: 5.5076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6023

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 8.3562	Cost: 30.50s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 5.1369	Cost: 6.24s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 5.5385	Cost: 16.62s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 4.7579	Cost: 11.73s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 5.0262	Cost: 11.92s
Train Epoch: 103 	Average Loss: 5.4191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9106

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 8.3183	Cost: 30.74s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 5.3504	Cost: 6.94s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 5.1385	Cost: 11.03s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 4.8323	Cost: 15.52s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 5.1247	Cost: 14.68s
Train Epoch: 104 	Average Loss: 5.4618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0270

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 7.8622	Cost: 38.36s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 5.1644	Cost: 6.24s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 5.2485	Cost: 15.99s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 4.6582	Cost: 14.27s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 5.0432	Cost: 9.58s
Train Epoch: 105 	Average Loss: 5.4387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0619

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 7.8590	Cost: 35.43s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 5.0889	Cost: 6.25s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 5.2945	Cost: 10.97s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 5.0081	Cost: 12.84s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 5.3641	Cost: 15.22s
Train Epoch: 106 	Average Loss: 5.5229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8489

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 8.2096	Cost: 35.65s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 5.3007	Cost: 6.91s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 4.6368	Cost: 12.07s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 4.3058	Cost: 8.37s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 4.8568	Cost: 17.50s
Train Epoch: 107 	Average Loss: 5.3490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9376

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 8.3830	Cost: 29.84s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 5.0742	Cost: 9.28s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 4.7507	Cost: 11.08s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 5.0996	Cost: 9.99s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 4.9681	Cost: 16.22s
Train Epoch: 108 	Average Loss: 5.3864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7343

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 8.1311	Cost: 38.05s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 5.0011	Cost: 6.28s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 4.8637	Cost: 16.25s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 4.6011	Cost: 14.85s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 5.2415	Cost: 13.80s
Train Epoch: 109 	Average Loss: 5.2747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0261

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 8.2260	Cost: 33.11s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 4.8116	Cost: 6.41s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 4.9044	Cost: 16.14s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 4.6718	Cost: 14.97s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 4.9818	Cost: 11.75s
Train Epoch: 110 	Average Loss: 5.3120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7997

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 8.2521	Cost: 32.32s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 4.9126	Cost: 6.09s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 4.9694	Cost: 16.13s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 4.8849	Cost: 15.29s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 5.0353	Cost: 8.21s
Train Epoch: 111 	Average Loss: 5.2646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8156

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 8.0070	Cost: 28.57s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 4.9213	Cost: 6.07s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 4.8246	Cost: 15.52s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 4.4023	Cost: 14.95s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 4.8674	Cost: 10.49s
Train Epoch: 112 	Average Loss: 5.1849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9763

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 8.2270	Cost: 29.78s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 5.2203	Cost: 6.31s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 4.9054	Cost: 16.03s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 4.4243	Cost: 14.93s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 5.0386	Cost: 9.12s
Train Epoch: 113 	Average Loss: 5.2075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9730

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 8.2859	Cost: 29.91s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 4.8767	Cost: 6.22s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 4.9600	Cost: 16.06s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 4.8802	Cost: 11.88s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 4.8199	Cost: 12.09s
Train Epoch: 114 	Average Loss: 5.2501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8208

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 8.6412	Cost: 27.77s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 5.1288	Cost: 6.19s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 5.1895	Cost: 15.32s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 4.7004	Cost: 14.89s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 5.0404	Cost: 11.22s
Train Epoch: 115 	Average Loss: 5.3760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9613

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 8.5881	Cost: 28.02s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 4.8750	Cost: 6.40s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 5.5193	Cost: 14.79s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 4.6265	Cost: 15.75s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 5.0312	Cost: 12.95s
Train Epoch: 116 	Average Loss: 5.3669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9844

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 8.1514	Cost: 26.98s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 5.1858	Cost: 6.25s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 4.8900	Cost: 14.84s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 4.4406	Cost: 15.77s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 5.0896	Cost: 14.11s
Train Epoch: 117 	Average Loss: 5.1655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7598

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 8.1367	Cost: 36.42s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 5.0968	Cost: 6.50s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 4.6115	Cost: 16.32s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 4.5052	Cost: 15.10s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 4.8974	Cost: 8.44s
Train Epoch: 118 	Average Loss: 5.1983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9070

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 8.5458	Cost: 33.85s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 4.8542	Cost: 6.30s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 4.5161	Cost: 11.13s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 4.6348	Cost: 8.53s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 5.2054	Cost: 18.03s
Train Epoch: 119 	Average Loss: 5.1419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9141

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 8.3825	Cost: 35.06s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 4.7356	Cost: 6.90s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 4.7663	Cost: 14.70s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 4.2524	Cost: 15.76s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 4.6928	Cost: 12.79s
Train Epoch: 120 	Average Loss: 5.1415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8903

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 8.2740	Cost: 38.34s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 4.9984	Cost: 6.07s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 4.7357	Cost: 15.07s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 4.3242	Cost: 15.65s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 4.7337	Cost: 13.84s
Train Epoch: 121 	Average Loss: 5.0550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9824

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 8.0977	Cost: 31.91s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 4.9064	Cost: 6.19s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 4.5436	Cost: 13.78s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 4.5059	Cost: 15.04s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 4.6580	Cost: 14.58s
Train Epoch: 122 	Average Loss: 4.9925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7844

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 8.2964	Cost: 26.87s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 4.7985	Cost: 6.43s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 4.9676	Cost: 9.51s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 4.5084	Cost: 13.34s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 4.5944	Cost: 14.83s
Train Epoch: 123 	Average Loss: 5.1025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8156

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 8.4566	Cost: 24.59s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 4.7814	Cost: 6.54s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 4.7596	Cost: 9.87s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 4.3474	Cost: 6.26s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 4.4987	Cost: 17.55s
Train Epoch: 124 	Average Loss: 5.0256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8583

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 8.5879	Cost: 24.56s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 4.5991	Cost: 6.10s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 4.5345	Cost: 9.44s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 4.5716	Cost: 6.62s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 4.7172	Cost: 12.32s
Train Epoch: 125 	Average Loss: 5.0053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9222

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 8.7015	Cost: 27.53s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 4.9047	Cost: 7.77s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 4.3794	Cost: 8.79s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 4.4380	Cost: 8.37s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 4.5930	Cost: 8.27s
Train Epoch: 126 	Average Loss: 4.8886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9984

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 8.1698	Cost: 30.88s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 4.8698	Cost: 6.92s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 4.9191	Cost: 11.15s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 4.5284	Cost: 6.12s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 4.8640	Cost: 13.11s
Train Epoch: 127 	Average Loss: 4.9420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1226

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 7.9730	Cost: 26.60s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 4.5710	Cost: 6.51s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 4.2970	Cost: 14.21s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 4.1943	Cost: 6.05s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 4.3415	Cost: 11.41s
Train Epoch: 128 	Average Loss: 4.8224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9077

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 8.1629	Cost: 30.28s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 4.8680	Cost: 15.36s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 4.5306	Cost: 8.80s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 4.2028	Cost: 10.75s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 4.7159	Cost: 6.13s
Train Epoch: 129 	Average Loss: 4.8171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9034

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 8.4838	Cost: 29.78s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 4.6227	Cost: 6.03s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 4.4801	Cost: 15.38s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 3.9077	Cost: 13.07s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 4.3430	Cost: 12.01s
Train Epoch: 130 	Average Loss: 4.8114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9584

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 8.1736	Cost: 26.37s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 4.2586	Cost: 6.30s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 4.4850	Cost: 13.00s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 3.9194	Cost: 15.55s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 4.5463	Cost: 14.99s
Train Epoch: 131 	Average Loss: 4.7792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9035

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 8.3429	Cost: 26.88s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 4.4995	Cost: 6.72s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 4.3996	Cost: 14.23s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 4.3182	Cost: 15.72s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 4.8786	Cost: 14.92s
Train Epoch: 132 	Average Loss: 4.8104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8898

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 8.1347	Cost: 30.11s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 4.9142	Cost: 7.82s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 4.2917	Cost: 10.79s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 4.5033	Cost: 10.17s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 4.3973	Cost: 17.50s
Train Epoch: 133 	Average Loss: 4.9004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9520

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 8.0054	Cost: 28.19s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 4.3618	Cost: 8.83s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 4.1988	Cost: 10.76s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 3.9550	Cost: 6.17s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 4.2868	Cost: 20.25s
Train Epoch: 134 	Average Loss: 4.7037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0084

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 8.3261	Cost: 34.08s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 4.8015	Cost: 8.50s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 4.2320	Cost: 12.39s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 4.1253	Cost: 15.68s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 4.4672	Cost: 15.01s
Train Epoch: 135 	Average Loss: 4.6101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8874

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 8.2494	Cost: 29.31s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 4.1273	Cost: 8.56s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 4.5544	Cost: 10.02s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 3.9320	Cost: 15.32s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 4.7389	Cost: 15.57s
Train Epoch: 136 	Average Loss: 4.6993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9297

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 8.4508	Cost: 37.89s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 4.4123	Cost: 6.23s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 4.3022	Cost: 16.48s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 4.0413	Cost: 14.93s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 4.1548	Cost: 10.92s
Train Epoch: 137 	Average Loss: 4.6915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9417

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 8.0392	Cost: 33.71s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 3.9795	Cost: 6.14s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 4.0011	Cost: 15.42s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 3.9384	Cost: 14.90s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 4.1276	Cost: 9.46s
Train Epoch: 138 	Average Loss: 4.5961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9647

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 8.1560	Cost: 31.56s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 4.3938	Cost: 6.05s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 4.0213	Cost: 13.89s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 3.8778	Cost: 14.53s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 4.0453	Cost: 11.55s
Train Epoch: 139 	Average Loss: 4.5397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9498

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 8.1825	Cost: 29.91s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 4.4744	Cost: 6.31s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 3.8160	Cost: 15.70s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 4.0984	Cost: 15.18s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 4.2396	Cost: 13.59s
Train Epoch: 140 	Average Loss: 4.5470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0323

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 8.2965	Cost: 25.58s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 4.3401	Cost: 6.80s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 4.0921	Cost: 9.30s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 3.7812	Cost: 10.33s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 4.0317	Cost: 14.97s
Train Epoch: 141 	Average Loss: 4.5370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9470

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 8.5546	Cost: 24.19s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 4.4171	Cost: 6.41s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 4.0032	Cost: 9.70s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 3.9274	Cost: 6.19s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 3.8311	Cost: 19.30s
Train Epoch: 142 	Average Loss: 4.4914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0024

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 8.1418	Cost: 23.64s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 4.1961	Cost: 6.63s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 4.2906	Cost: 10.15s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 3.9490	Cost: 6.32s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 4.3182	Cost: 12.18s
Train Epoch: 143 	Average Loss: 4.4802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0053

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 7.9148	Cost: 27.12s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 4.4443	Cost: 8.77s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 4.0540	Cost: 8.70s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 4.0627	Cost: 8.38s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 4.0754	Cost: 8.45s
Train Epoch: 144 	Average Loss: 4.4395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9114

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 8.5959	Cost: 27.90s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 4.4002	Cost: 6.25s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 4.0859	Cost: 10.05s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 3.5865	Cost: 6.05s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 4.1241	Cost: 12.40s
Train Epoch: 145 	Average Loss: 4.4263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9998

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 7.8951	Cost: 29.56s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 4.1986	Cost: 12.25s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 3.7767	Cost: 6.72s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 3.6616	Cost: 6.18s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 4.0056	Cost: 12.44s
Train Epoch: 146 	Average Loss: 4.4381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1346

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 8.2423	Cost: 29.11s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 4.3479	Cost: 9.37s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 3.7906	Cost: 11.22s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 3.8610	Cost: 7.40s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 4.1292	Cost: 6.10s
Train Epoch: 147 	Average Loss: 4.4673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0444

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 8.3991	Cost: 31.08s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 4.2525	Cost: 14.43s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 3.8803	Cost: 14.07s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 3.5837	Cost: 11.82s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 4.0880	Cost: 5.98s
Train Epoch: 148 	Average Loss: 4.3593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8780

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 7.6670	Cost: 30.21s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 4.3909	Cost: 9.34s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 4.1123	Cost: 15.40s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 3.8369	Cost: 12.87s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 4.2611	Cost: 8.90s
Train Epoch: 149 	Average Loss: 4.3552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9750

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 8.6378	Cost: 28.78s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 4.3160	Cost: 6.28s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 3.6723	Cost: 17.34s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 3.4479	Cost: 10.95s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 3.9080	Cost: 11.01s
Train Epoch: 150 	Average Loss: 4.3234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8211

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 8.0459	Cost: 30.74s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 3.4956	Cost: 6.40s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 3.6687	Cost: 14.79s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 3.6194	Cost: 15.16s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 3.9084	Cost: 14.47s
Train Epoch: 151 	Average Loss: 4.2187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9083

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 8.1964	Cost: 36.10s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 3.5756	Cost: 6.58s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 3.8229	Cost: 11.57s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 3.8078	Cost: 12.05s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 4.0392	Cost: 14.37s
Train Epoch: 152 	Average Loss: 4.1895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8445

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 8.6028	Cost: 29.94s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 3.9350	Cost: 8.38s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 3.7953	Cost: 12.12s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 3.5058	Cost: 15.48s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 4.0902	Cost: 15.15s
Train Epoch: 153 	Average Loss: 4.2127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9418

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 7.8430	Cost: 34.25s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 3.8490	Cost: 7.00s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 3.9736	Cost: 12.12s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 3.5048	Cost: 15.69s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 4.3168	Cost: 14.81s
Train Epoch: 154 	Average Loss: 4.1786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0692

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 8.4620	Cost: 41.82s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 3.9381	Cost: 6.12s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 3.8693	Cost: 16.46s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 3.4123	Cost: 15.11s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 3.8723	Cost: 9.40s
Train Epoch: 155 	Average Loss: 4.2716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9275

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 8.4256	Cost: 30.59s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 4.3288	Cost: 6.15s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 3.6895	Cost: 16.07s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 3.3546	Cost: 14.91s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 4.0839	Cost: 8.80s
Train Epoch: 156 	Average Loss: 4.2438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0593

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 8.0099	Cost: 30.54s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 3.7679	Cost: 6.12s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 3.8074	Cost: 16.41s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 3.8370	Cost: 14.15s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 4.2908	Cost: 9.84s
Train Epoch: 157 	Average Loss: 4.2257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1230

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 8.2755	Cost: 29.42s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 3.9072	Cost: 6.20s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 3.4836	Cost: 15.13s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 3.1740	Cost: 15.31s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 3.6452	Cost: 10.61s
Train Epoch: 158 	Average Loss: 4.1338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9178

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 8.1638	Cost: 28.89s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 3.9377	Cost: 6.26s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 3.3799	Cost: 15.08s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 3.7229	Cost: 14.03s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 4.1498	Cost: 12.08s
Train Epoch: 159 	Average Loss: 4.1404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1058

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 8.5186	Cost: 29.92s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 3.7360	Cost: 6.13s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 3.6422	Cost: 16.44s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 3.5974	Cost: 12.13s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 3.5030	Cost: 10.93s
Train Epoch: 160 	Average Loss: 4.1213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8014

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 8.2933	Cost: 30.01s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 3.4708	Cost: 6.28s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 3.5876	Cost: 15.95s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 3.7326	Cost: 15.40s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 3.9751	Cost: 12.31s
Train Epoch: 161 	Average Loss: 4.1026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0164

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 8.3505	Cost: 31.32s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 3.6167	Cost: 6.34s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 3.8080	Cost: 14.13s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 2.9433	Cost: 15.73s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 3.8897	Cost: 14.75s
Train Epoch: 162 	Average Loss: 4.0160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8769

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 7.9667	Cost: 31.04s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 3.3720	Cost: 7.94s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 3.7712	Cost: 14.31s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 3.4491	Cost: 15.68s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 3.7893	Cost: 14.79s
Train Epoch: 163 	Average Loss: 3.9419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0412

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 8.1516	Cost: 34.04s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 3.8706	Cost: 6.20s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 3.3725	Cost: 11.39s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 3.2670	Cost: 15.28s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 3.8239	Cost: 15.73s
Train Epoch: 164 	Average Loss: 3.9468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9004

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 8.4912	Cost: 33.42s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 3.7678	Cost: 6.46s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 3.4375	Cost: 11.00s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 3.4602	Cost: 13.54s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 3.6793	Cost: 14.66s
Train Epoch: 165 	Average Loss: 3.9791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9026

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 8.0954	Cost: 31.47s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 3.5817	Cost: 6.39s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 3.4422	Cost: 10.95s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 3.3151	Cost: 6.29s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 3.5912	Cost: 18.17s
Train Epoch: 166 	Average Loss: 3.8535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0297

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 8.0235	Cost: 30.30s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 3.4302	Cost: 6.87s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 3.5166	Cost: 12.03s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 3.0029	Cost: 9.10s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 3.8147	Cost: 17.53s
Train Epoch: 167 	Average Loss: 3.8437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0423

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 8.1683	Cost: 35.26s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 3.5282	Cost: 6.39s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 3.5412	Cost: 15.23s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 3.3062	Cost: 15.15s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 3.7882	Cost: 14.74s
Train Epoch: 168 	Average Loss: 3.8481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0976

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 8.0266	Cost: 32.10s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 3.2291	Cost: 6.57s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 3.0241	Cost: 15.99s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 3.5406	Cost: 15.19s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 3.9101	Cost: 13.27s
Train Epoch: 169 	Average Loss: 3.8204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8621

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 8.1155	Cost: 31.77s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 3.5076	Cost: 6.14s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 3.1893	Cost: 15.15s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 3.4721	Cost: 14.64s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 3.5206	Cost: 14.50s
Train Epoch: 170 	Average Loss: 3.7905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9680

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 8.5289	Cost: 25.83s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 3.4589	Cost: 6.41s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 3.3597	Cost: 10.91s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 3.4270	Cost: 10.13s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 3.6144	Cost: 16.08s
Train Epoch: 171 	Average Loss: 3.8721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0518

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 7.9091	Cost: 25.81s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 3.4086	Cost: 6.48s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 3.2223	Cost: 11.33s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 3.1841	Cost: 6.15s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 3.4269	Cost: 20.90s
Train Epoch: 172 	Average Loss: 3.7633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7826

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 8.3538	Cost: 23.55s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 3.3030	Cost: 6.45s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 3.3360	Cost: 9.26s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 3.1781	Cost: 6.22s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 3.4039	Cost: 18.13s
Train Epoch: 173 	Average Loss: 3.6753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7219

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 8.4059	Cost: 24.25s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 3.7706	Cost: 6.43s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 3.0569	Cost: 10.12s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 2.8224	Cost: 6.29s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 3.4420	Cost: 12.05s
Train Epoch: 174 	Average Loss: 3.6170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8888

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 8.0862	Cost: 27.61s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 3.4011	Cost: 8.76s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 3.0671	Cost: 8.72s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 2.9481	Cost: 8.48s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 3.5649	Cost: 7.36s
Train Epoch: 175 	Average Loss: 3.6516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9972

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 7.8129	Cost: 26.45s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 3.1416	Cost: 6.27s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 2.9921	Cost: 8.94s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 2.9791	Cost: 7.81s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 3.2420	Cost: 9.11s
Train Epoch: 176 	Average Loss: 3.7078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0329

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 7.8746	Cost: 32.90s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 3.3316	Cost: 8.73s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 3.2066	Cost: 7.49s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 2.9175	Cost: 6.27s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 3.6045	Cost: 10.82s
Train Epoch: 177 	Average Loss: 3.5996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1172

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 8.1664	Cost: 27.95s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 3.2028	Cost: 7.02s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 3.2960	Cost: 12.91s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 2.8334	Cost: 6.15s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 3.3621	Cost: 10.07s
Train Epoch: 178 	Average Loss: 3.5225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8978

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 8.0209	Cost: 31.40s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 3.4904	Cost: 15.53s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 2.9575	Cost: 10.37s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 2.6620	Cost: 10.76s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 3.2021	Cost: 6.05s
Train Epoch: 179 	Average Loss: 3.6171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0236

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 8.5689	Cost: 28.22s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 3.4783	Cost: 6.23s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 3.0680	Cost: 15.24s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 2.7316	Cost: 14.55s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 3.0841	Cost: 10.62s
Train Epoch: 180 	Average Loss: 3.5296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0711

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 8.0582	Cost: 27.84s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 3.3496	Cost: 6.13s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 3.2913	Cost: 16.75s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 3.0110	Cost: 13.08s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 3.5207	Cost: 11.20s
Train Epoch: 181 	Average Loss: 3.7599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1247

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 8.5913	Cost: 26.33s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 3.7243	Cost: 6.50s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 2.9430	Cost: 12.25s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 2.8326	Cost: 16.09s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 2.9148	Cost: 14.82s
Train Epoch: 182 	Average Loss: 3.6262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2145

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 8.5201	Cost: 25.93s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 3.0654	Cost: 6.78s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 2.9697	Cost: 11.14s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 2.7272	Cost: 14.19s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 3.1766	Cost: 15.28s
Train Epoch: 183 	Average Loss: 3.4919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0420

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 7.8947	Cost: 26.26s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 2.8847	Cost: 7.90s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 2.7151	Cost: 13.75s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 2.6454	Cost: 15.72s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 3.2295	Cost: 15.09s
Train Epoch: 184 	Average Loss: 3.4047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0891

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 7.8748	Cost: 31.31s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 2.9950	Cost: 7.69s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 2.6586	Cost: 15.54s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 2.6854	Cost: 15.87s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 2.9095	Cost: 12.75s
Train Epoch: 185 	Average Loss: 3.3427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9864

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 8.4025	Cost: 33.83s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 2.9065	Cost: 6.91s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 2.7532	Cost: 10.65s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 2.6900	Cost: 8.53s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 3.2188	Cost: 16.88s
Train Epoch: 186 	Average Loss: 3.3479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0658

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 8.2246	Cost: 31.04s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 3.1232	Cost: 8.76s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 3.0649	Cost: 9.65s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 2.3310	Cost: 6.43s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 2.8391	Cost: 18.78s
Train Epoch: 187 	Average Loss: 3.2546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0791

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 8.2342	Cost: 35.11s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 3.1882	Cost: 7.44s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 2.8748	Cost: 11.99s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 2.2746	Cost: 15.30s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 3.0853	Cost: 15.33s
Train Epoch: 188 	Average Loss: 3.3078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9411

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 8.0087	Cost: 32.51s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 3.1983	Cost: 7.03s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 2.6307	Cost: 10.63s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 2.4625	Cost: 11.25s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 2.8362	Cost: 14.91s
Train Epoch: 189 	Average Loss: 3.2411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9799

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 8.1567	Cost: 32.25s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 2.9463	Cost: 6.61s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 2.9330	Cost: 12.31s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 2.8382	Cost: 11.29s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 3.0838	Cost: 15.84s
Train Epoch: 190 	Average Loss: 3.2661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9437

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 8.6156	Cost: 35.55s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 3.1411	Cost: 6.45s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 2.8376	Cost: 11.73s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 2.9500	Cost: 6.16s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 3.0812	Cost: 19.51s
Train Epoch: 191 	Average Loss: 3.3369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1712

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 8.7129	Cost: 30.22s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 3.2018	Cost: 6.46s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 2.5599	Cost: 12.75s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 2.6320	Cost: 8.53s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 3.0109	Cost: 17.97s
Train Epoch: 192 	Average Loss: 3.2790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1100

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 8.1360	Cost: 31.77s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 3.3463	Cost: 6.62s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 2.7911	Cost: 11.80s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 2.5930	Cost: 12.14s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 2.8941	Cost: 15.08s
Train Epoch: 193 	Average Loss: 3.3548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9727

Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 7.8548	Cost: 30.71s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 2.9047	Cost: 6.58s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 2.5822	Cost: 11.93s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 2.7226	Cost: 10.29s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 2.8292	Cost: 15.83s
Train Epoch: 194 	Average Loss: 3.1591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0406

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 8.1248	Cost: 31.63s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 2.9035	Cost: 6.31s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 2.5294	Cost: 11.68s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 2.2410	Cost: 8.39s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 2.9801	Cost: 17.00s
Train Epoch: 195 	Average Loss: 3.2155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9716

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 8.0140	Cost: 32.01s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 2.9992	Cost: 8.36s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 2.9446	Cost: 9.82s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 2.5253	Cost: 10.38s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 2.9457	Cost: 15.77s
Train Epoch: 196 	Average Loss: 3.2930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0549

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 8.0194	Cost: 34.13s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 2.8710	Cost: 7.22s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 2.3281	Cost: 10.89s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 2.0426	Cost: 10.56s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 3.1669	Cost: 15.71s
Train Epoch: 197 	Average Loss: 3.1985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0334

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 8.3135	Cost: 37.67s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 3.3265	Cost: 7.04s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 3.2770	Cost: 15.39s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 2.9257	Cost: 15.66s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 2.9557	Cost: 9.11s
Train Epoch: 198 	Average Loss: 3.5771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1364

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 8.4804	Cost: 35.55s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 3.1275	Cost: 6.35s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 2.6699	Cost: 15.39s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 2.5612	Cost: 15.53s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 2.8366	Cost: 8.96s
Train Epoch: 199 	Average Loss: 3.3545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0107

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 8.5404	Cost: 33.00s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 2.7745	Cost: 6.11s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 2.6455	Cost: 15.08s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 2.7012	Cost: 15.03s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 2.8611	Cost: 9.79s
Train Epoch: 200 	Average Loss: 3.1913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1001

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 8.5820	Cost: 30.77s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 2.4862	Cost: 6.05s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 2.1683	Cost: 15.02s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 2.1977	Cost: 15.57s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 2.5896	Cost: 9.90s
Train Epoch: 201 	Average Loss: 3.0003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0020

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 8.0203	Cost: 28.40s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 2.5642	Cost: 6.31s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 2.5125	Cost: 14.56s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 2.3109	Cost: 15.65s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 2.7431	Cost: 14.79s
Train Epoch: 202 	Average Loss: 3.0248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9822

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 7.9058	Cost: 24.07s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 2.5937	Cost: 6.66s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 2.5262	Cost: 9.13s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 2.4234	Cost: 6.26s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 2.6083	Cost: 19.65s
Train Epoch: 203 	Average Loss: 2.9669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9893

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 8.1593	Cost: 24.79s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 2.6927	Cost: 6.48s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 2.6425	Cost: 10.69s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 2.6070	Cost: 6.31s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 3.1946	Cost: 20.26s
Train Epoch: 204 	Average Loss: 2.9876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0464

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 8.1187	Cost: 22.98s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 2.7303	Cost: 6.38s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 2.7504	Cost: 9.80s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 2.3952	Cost: 6.34s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 2.4339	Cost: 11.18s
Train Epoch: 205 	Average Loss: 3.0528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1704

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 8.0059	Cost: 26.77s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 2.4938	Cost: 8.86s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 2.2990	Cost: 8.70s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 2.3232	Cost: 8.86s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 2.7589	Cost: 8.43s
Train Epoch: 206 	Average Loss: 3.0031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0693

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 8.2481	Cost: 24.32s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 2.6774	Cost: 6.32s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 2.5957	Cost: 9.52s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 2.3294	Cost: 5.99s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 2.6046	Cost: 11.22s
Train Epoch: 207 	Average Loss: 2.9966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2325

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 8.1656	Cost: 30.24s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 2.2016	Cost: 12.26s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 2.2122	Cost: 6.55s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 1.8813	Cost: 6.31s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 2.3283	Cost: 9.08s
Train Epoch: 208 	Average Loss: 2.8521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0701

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 7.9339	Cost: 29.11s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 2.5967	Cost: 12.95s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 2.1284	Cost: 6.30s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 1.8932	Cost: 10.19s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 3.1007	Cost: 8.36s
Train Epoch: 209 	Average Loss: 2.8606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2212

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 8.0050	Cost: 27.26s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 2.5159	Cost: 6.76s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 2.1114	Cost: 16.19s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 1.9852	Cost: 15.44s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 2.1000	Cost: 11.44s
Train Epoch: 210 	Average Loss: 2.7377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0176

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 8.0700	Cost: 29.72s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 2.3522	Cost: 8.03s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 2.1443	Cost: 10.57s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 2.4798	Cost: 15.64s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 2.6434	Cost: 14.64s
Train Epoch: 211 	Average Loss: 2.9091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2274

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 8.3821	Cost: 33.48s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 2.3719	Cost: 7.02s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 2.1385	Cost: 11.90s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 2.0600	Cost: 10.25s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 2.4919	Cost: 15.92s
Train Epoch: 212 	Average Loss: 2.8721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1188

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 8.2123	Cost: 33.78s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 2.3956	Cost: 6.75s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 2.0413	Cost: 11.21s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 2.2883	Cost: 10.38s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 2.3497	Cost: 15.70s
Train Epoch: 213 	Average Loss: 2.7096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0490

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 8.5533	Cost: 35.19s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 2.2265	Cost: 6.44s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 2.1849	Cost: 11.15s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 1.9936	Cost: 9.62s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 2.8371	Cost: 15.47s
Train Epoch: 214 	Average Loss: 2.8199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2471

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 8.7111	Cost: 31.81s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 2.3847	Cost: 7.33s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 1.9068	Cost: 11.64s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 1.8793	Cost: 6.72s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 2.2332	Cost: 19.57s
Train Epoch: 215 	Average Loss: 2.7402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9603

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 8.3405	Cost: 34.94s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 2.3143	Cost: 6.70s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 2.0668	Cost: 11.86s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 1.5670	Cost: 6.20s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 1.9089	Cost: 20.84s
Train Epoch: 216 	Average Loss: 2.6195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1051

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 7.9302	Cost: 30.24s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 2.3537	Cost: 6.71s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 1.6993	Cost: 12.03s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 1.7261	Cost: 6.21s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 2.4141	Cost: 20.91s
Train Epoch: 217 	Average Loss: 2.5603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9510

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 8.5688	Cost: 33.34s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 2.2310	Cost: 6.45s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 1.6899	Cost: 11.88s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 1.7009	Cost: 13.21s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 2.3026	Cost: 14.58s
Train Epoch: 218 	Average Loss: 2.5182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0638

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 8.2705	Cost: 34.48s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 2.0612	Cost: 6.52s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 2.0640	Cost: 14.17s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 1.5575	Cost: 15.02s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 2.0585	Cost: 15.09s
Train Epoch: 219 	Average Loss: 2.4449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1168

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 8.5898	Cost: 32.93s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 2.0227	Cost: 6.31s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 1.9352	Cost: 11.56s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 1.7991	Cost: 15.72s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 2.3161	Cost: 14.88s
Train Epoch: 220 	Average Loss: 2.4867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0826

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 8.6864	Cost: 29.75s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 1.9507	Cost: 6.61s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 1.5519	Cost: 10.37s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 1.5002	Cost: 11.92s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 2.2423	Cost: 15.03s
Train Epoch: 221 	Average Loss: 2.4510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9351

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 8.5704	Cost: 25.30s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 2.0021	Cost: 6.57s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 1.7539	Cost: 10.62s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 1.4912	Cost: 6.12s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 2.0287	Cost: 19.85s
Train Epoch: 222 	Average Loss: 2.4995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1944

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 8.0268	Cost: 25.10s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 1.8982	Cost: 6.43s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 1.9253	Cost: 10.59s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 1.7855	Cost: 6.50s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 2.1633	Cost: 11.88s
Train Epoch: 223 	Average Loss: 2.5240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1396

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 8.4028	Cost: 27.53s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 2.0052	Cost: 8.85s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 1.8608	Cost: 8.71s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 1.2863	Cost: 8.58s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 2.1984	Cost: 8.07s
Train Epoch: 224 	Average Loss: 2.5142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1089

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 7.6739	Cost: 27.18s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 1.9874	Cost: 6.30s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 1.9826	Cost: 9.80s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 1.5315	Cost: 6.55s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 2.0740	Cost: 11.00s
Train Epoch: 225 	Average Loss: 2.3603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9286

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 8.4254	Cost: 33.01s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 1.5151	Cost: 11.16s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 1.4928	Cost: 6.44s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 1.4775	Cost: 6.39s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 2.0701	Cost: 10.94s
Train Epoch: 226 	Average Loss: 2.2564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0133

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 7.7334	Cost: 28.10s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 1.8507	Cost: 9.91s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 1.3961	Cost: 7.89s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 1.4866	Cost: 10.39s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 1.7107	Cost: 7.76s
Train Epoch: 227 	Average Loss: 2.2674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9876

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 7.7293	Cost: 25.38s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 1.7757	Cost: 6.79s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 1.5759	Cost: 15.53s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 1.4753	Cost: 15.77s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 1.8933	Cost: 12.92s
Train Epoch: 228 	Average Loss: 2.2327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2372

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 8.4471	Cost: 30.80s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 2.5337	Cost: 7.11s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 1.8039	Cost: 17.11s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 1.8519	Cost: 12.05s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 2.0711	Cost: 11.57s
Train Epoch: 229 	Average Loss: 2.6868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0698

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 8.6249	Cost: 34.02s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 2.1374	Cost: 6.95s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 2.0339	Cost: 10.79s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 1.7939	Cost: 13.01s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 2.1267	Cost: 14.99s
Train Epoch: 230 	Average Loss: 2.5875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1143

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 8.1689	Cost: 38.75s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 2.0308	Cost: 6.19s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 1.4989	Cost: 16.26s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 1.5463	Cost: 15.72s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 1.8566	Cost: 11.77s
Train Epoch: 231 	Average Loss: 2.2988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1583

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 8.3699	Cost: 35.14s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 2.0432	Cost: 6.23s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 2.0056	Cost: 15.89s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 1.3496	Cost: 15.05s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 2.1773	Cost: 11.53s
Train Epoch: 232 	Average Loss: 2.3318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9268

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 7.4534	Cost: 31.85s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 1.7766	Cost: 6.06s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 1.4346	Cost: 15.24s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 1.1216	Cost: 15.40s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 1.6586	Cost: 9.21s
Train Epoch: 233 	Average Loss: 2.1413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0841

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 8.5337	Cost: 31.13s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 1.5128	Cost: 6.11s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 1.2726	Cost: 14.35s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 1.1159	Cost: 14.92s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 2.2123	Cost: 10.48s
Train Epoch: 234 	Average Loss: 2.1581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1807

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 7.8090	Cost: 28.41s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 1.3934	Cost: 6.23s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 1.7334	Cost: 14.75s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 1.2026	Cost: 15.14s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 2.0690	Cost: 13.58s
Train Epoch: 235 	Average Loss: 2.0945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9817

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 8.0997	Cost: 27.60s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 1.4965	Cost: 6.40s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 1.1414	Cost: 14.14s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 0.9681	Cost: 15.19s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 1.6481	Cost: 15.52s
Train Epoch: 236 	Average Loss: 2.0080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0826

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 8.1939	Cost: 28.44s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 1.3886	Cost: 6.25s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 1.3554	Cost: 12.17s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 1.5122	Cost: 15.40s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 2.1227	Cost: 15.93s
Train Epoch: 237 	Average Loss: 2.0709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2685

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 7.8896	Cost: 29.38s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 1.6771	Cost: 6.42s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 0.9865	Cost: 13.66s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 1.1746	Cost: 15.80s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 1.4675	Cost: 15.12s
Train Epoch: 238 	Average Loss: 2.0229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0806

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 7.9179	Cost: 29.55s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 1.4925	Cost: 6.26s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 1.2651	Cost: 12.35s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 1.4896	Cost: 16.12s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 1.8683	Cost: 13.26s
Train Epoch: 239 	Average Loss: 1.9304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9342

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 8.0406	Cost: 27.88s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 1.4038	Cost: 6.36s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 1.1250	Cost: 15.99s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 1.1500	Cost: 15.80s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 1.6257	Cost: 12.97s
Train Epoch: 240 	Average Loss: 1.9449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3976

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 8.2957	Cost: 25.47s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 1.5429	Cost: 6.32s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 1.3405	Cost: 10.62s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 1.0468	Cost: 14.61s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 1.6119	Cost: 15.57s
Train Epoch: 241 	Average Loss: 1.9959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0013

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 7.6748	Cost: 26.07s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 1.4670	Cost: 6.48s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 1.3263	Cost: 10.77s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 1.5728	Cost: 11.58s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 1.4374	Cost: 15.71s
Train Epoch: 242 	Average Loss: 1.9508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3567

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 8.0977	Cost: 26.08s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 1.3234	Cost: 6.58s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 1.1009	Cost: 9.97s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 0.6057	Cost: 10.49s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 1.4478	Cost: 15.93s
Train Epoch: 243 	Average Loss: 1.8763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0475

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 8.5444	Cost: 26.71s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 1.1261	Cost: 6.64s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 1.2569	Cost: 8.56s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 1.0818	Cost: 9.46s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 1.3643	Cost: 16.01s
Train Epoch: 244 	Average Loss: 1.8930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2642

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 8.0623	Cost: 28.58s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 1.2615	Cost: 6.43s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 1.0933	Cost: 15.40s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 0.8907	Cost: 15.72s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 1.2944	Cost: 14.39s
Train Epoch: 245 	Average Loss: 1.8024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2785

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 8.0927	Cost: 29.02s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 1.2743	Cost: 6.17s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 1.0435	Cost: 15.68s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 0.9153	Cost: 13.93s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 1.5075	Cost: 10.25s
Train Epoch: 246 	Average Loss: 1.7555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3534

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 8.0911	Cost: 26.78s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 1.2950	Cost: 6.36s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 1.4967	Cost: 9.37s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 1.3997	Cost: 14.16s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 1.4373	Cost: 14.36s
Train Epoch: 247 	Average Loss: 1.8529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2429

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 8.7827	Cost: 25.75s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 1.6460	Cost: 6.56s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 1.1353	Cost: 9.01s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 0.9598	Cost: 10.46s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 1.4386	Cost: 15.72s
Train Epoch: 248 	Average Loss: 1.8392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0961

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 8.4217	Cost: 23.76s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 0.9271	Cost: 6.41s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 0.9596	Cost: 9.58s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 0.6709	Cost: 6.06s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 1.3349	Cost: 17.57s
Train Epoch: 249 	Average Loss: 1.7911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1475

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 7.6164	Cost: 23.41s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 1.0352	Cost: 6.84s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 0.9266	Cost: 9.90s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 0.8396	Cost: 6.22s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 1.3010	Cost: 11.47s
Train Epoch: 250 	Average Loss: 1.7520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1470

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 8.1562	Cost: 23.73s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 1.4130	Cost: 8.79s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 0.9933	Cost: 8.87s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 0.8602	Cost: 6.65s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 1.4615	Cost: 6.18s
Train Epoch: 251 	Average Loss: 1.6677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1711

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 8.0799	Cost: 23.95s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 1.2466	Cost: 6.11s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 1.4164	Cost: 9.25s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 1.4845	Cost: 7.11s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 1.9482	Cost: 11.55s
Train Epoch: 252 	Average Loss: 2.0225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2133

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 8.2694	Cost: 27.03s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 1.3481	Cost: 11.72s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 1.3689	Cost: 6.12s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 1.0215	Cost: 6.14s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 0.9349	Cost: 6.22s
Train Epoch: 253 	Average Loss: 1.8271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0435

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 8.4648	Cost: 37.49s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 1.1725	Cost: 10.68s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 1.1105	Cost: 7.13s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 0.6059	Cost: 11.06s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 1.2044	Cost: 5.97s
Train Epoch: 254 	Average Loss: 1.6891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2114

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 8.1414	Cost: 49.83s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 1.1743	Cost: 11.85s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 1.4299	Cost: 12.06s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 1.0565	Cost: 6.05s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 1.3469	Cost: 5.97s
Train Epoch: 255 	Average Loss: 1.6579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1445

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 8.3684	Cost: 35.72s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 1.0305	Cost: 6.64s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 1.4969	Cost: 16.48s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 0.8549	Cost: 15.12s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 1.1091	Cost: 9.62s
Train Epoch: 256 	Average Loss: 1.6001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0577

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 8.2189	Cost: 42.14s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 0.6405	Cost: 15.51s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 0.9306	Cost: 14.95s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 0.7499	Cost: 9.00s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 1.0575	Cost: 6.30s
Train Epoch: 257 	Average Loss: 1.5009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1494

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 8.2727	Cost: 32.37s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 1.1742	Cost: 12.95s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 0.9776	Cost: 14.78s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 0.5599	Cost: 12.30s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 0.9732	Cost: 6.36s
Train Epoch: 258 	Average Loss: 1.5246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3167

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 7.9197	Cost: 41.61s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 1.2411	Cost: 15.37s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 0.4545	Cost: 11.87s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 0.6350	Cost: 7.12s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 0.7829	Cost: 6.52s
Train Epoch: 259 	Average Loss: 1.4302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1994

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 8.0738	Cost: 30.65s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 1.1273	Cost: 15.73s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 0.8089	Cost: 10.30s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 0.4541	Cost: 10.62s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 1.1820	Cost: 5.93s
Train Epoch: 260 	Average Loss: 1.3742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0669

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 8.5895	Cost: 28.64s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 0.9824	Cost: 10.37s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 0.6494	Cost: 15.74s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 0.2248	Cost: 13.81s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 0.6147	Cost: 6.03s
Train Epoch: 261 	Average Loss: 1.3533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1146

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 7.8965	Cost: 30.67s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 1.0940	Cost: 6.22s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 0.7821	Cost: 16.11s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 0.2499	Cost: 15.19s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 0.8829	Cost: 8.80s
Train Epoch: 262 	Average Loss: 1.3577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1784

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 7.9134	Cost: 29.07s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 0.8532	Cost: 6.23s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 0.6930	Cost: 16.42s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 0.1536	Cost: 13.72s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 0.8523	Cost: 10.29s
Train Epoch: 263 	Average Loss: 1.3509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3704

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 8.3927	Cost: 28.54s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 0.4806	Cost: 6.21s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 0.4706	Cost: 12.39s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 0.4616	Cost: 15.29s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 1.3108	Cost: 13.63s
Train Epoch: 264 	Average Loss: 1.2755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1869

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 8.4203	Cost: 29.33s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 0.8056	Cost: 6.27s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 0.5210	Cost: 16.51s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 0.4213	Cost: 11.76s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 0.8090	Cost: 11.84s
Train Epoch: 265 	Average Loss: 1.3225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1793

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 8.3008	Cost: 26.85s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 0.7539	Cost: 6.29s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 0.1724	Cost: 12.97s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 0.3236	Cost: 15.75s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 0.5492	Cost: 15.03s
Train Epoch: 266 	Average Loss: 1.2472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2370

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 8.6569	Cost: 26.63s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 0.4705	Cost: 7.14s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 0.5251	Cost: 11.62s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 0.7185	Cost: 15.29s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 0.7222	Cost: 15.48s
Train Epoch: 267 	Average Loss: 1.2038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2854

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 7.6842	Cost: 25.17s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 0.9690	Cost: 7.93s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 0.2910	Cost: 13.06s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 0.2141	Cost: 15.72s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 0.3549	Cost: 15.02s
Train Epoch: 268 	Average Loss: 1.2852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1900

Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 8.7425	Cost: 29.82s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 0.6053	Cost: 8.86s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 0.2320	Cost: 16.02s
Train Epoch: 269 [61440/90000 (68%)]	Loss: -0.2510	Cost: 15.21s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 0.9867	Cost: 13.36s
Train Epoch: 269 	Average Loss: 1.1215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1644

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 7.6799	Cost: 34.77s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 0.5646	Cost: 6.22s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 0.3843	Cost: 12.25s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 0.0197	Cost: 13.81s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 0.7555	Cost: 14.42s
Train Epoch: 270 	Average Loss: 1.1496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2415

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 7.9453	Cost: 36.78s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 0.6909	Cost: 6.22s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 0.5477	Cost: 16.51s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 0.3707	Cost: 14.85s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 0.7529	Cost: 11.81s
Train Epoch: 271 	Average Loss: 1.1421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9504

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 7.7917	Cost: 32.30s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 0.6430	Cost: 6.08s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 0.5406	Cost: 16.22s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 0.4448	Cost: 14.80s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 0.6356	Cost: 8.95s
Train Epoch: 272 	Average Loss: 1.1312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0800

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 8.1258	Cost: 31.41s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 0.7280	Cost: 6.03s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 0.2525	Cost: 16.05s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 0.0687	Cost: 15.30s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 0.4639	Cost: 9.12s
Train Epoch: 273 	Average Loss: 1.0628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1425

Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 8.4738	Cost: 28.97s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 0.3926	Cost: 6.08s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 0.7561	Cost: 16.07s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 0.1825	Cost: 14.79s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 0.4670	Cost: 11.85s
Train Epoch: 274 	Average Loss: 1.0502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0097

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 8.6589	Cost: 29.26s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 0.5479	Cost: 6.29s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 0.3975	Cost: 16.12s
Train Epoch: 275 [61440/90000 (68%)]	Loss: -0.3018	Cost: 15.53s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 0.5829	Cost: 13.07s
Train Epoch: 275 	Average Loss: 0.9927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0693

Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 7.9140	Cost: 26.60s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 0.5492	Cost: 6.29s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 0.2824	Cost: 10.08s
Train Epoch: 276 [61440/90000 (68%)]	Loss: -0.2991	Cost: 15.61s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 0.4560	Cost: 14.37s
Train Epoch: 276 	Average Loss: 0.9966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0669

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 7.8899	Cost: 26.68s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 0.6500	Cost: 6.44s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -0.0169	Cost: 9.76s
Train Epoch: 277 [61440/90000 (68%)]	Loss: -0.2006	Cost: 8.26s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 0.8198	Cost: 16.04s
Train Epoch: 277 	Average Loss: 0.9432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0381

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 7.8339	Cost: 24.36s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 0.3637	Cost: 6.50s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 0.3386	Cost: 9.15s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 0.1558	Cost: 6.30s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 0.6530	Cost: 17.94s
Train Epoch: 278 	Average Loss: 0.9540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4211

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 7.7083	Cost: 24.61s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 0.4599	Cost: 6.43s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 0.1042	Cost: 9.91s
Train Epoch: 279 [61440/90000 (68%)]	Loss: -0.4176	Cost: 6.58s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 0.4078	Cost: 18.05s
Train Epoch: 279 	Average Loss: 0.9228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1840

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 8.2229	Cost: 24.04s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 0.1893	Cost: 6.36s
Train Epoch: 280 [40960/90000 (45%)]	Loss: -0.3733	Cost: 9.86s
Train Epoch: 280 [61440/90000 (68%)]	Loss: -0.0444	Cost: 6.39s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 0.4222	Cost: 12.26s
Train Epoch: 280 	Average Loss: 0.8788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8963

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 7.5212	Cost: 28.02s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 0.2465	Cost: 8.42s
Train Epoch: 281 [40960/90000 (45%)]	Loss: -0.1920	Cost: 8.69s
Train Epoch: 281 [61440/90000 (68%)]	Loss: -0.2023	Cost: 8.33s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 0.4189	Cost: 8.30s
Train Epoch: 281 	Average Loss: 0.8951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3156

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 8.1243	Cost: 30.83s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 0.6288	Cost: 6.34s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 0.0892	Cost: 11.71s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 0.0571	Cost: 6.10s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 0.4597	Cost: 13.93s
Train Epoch: 282 	Average Loss: 0.9019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1503

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 7.9795	Cost: 27.65s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 0.3143	Cost: 6.45s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 0.2659	Cost: 14.04s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 0.1999	Cost: 6.03s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 0.2599	Cost: 13.42s
Train Epoch: 283 	Average Loss: 0.8442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1978

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 8.3446	Cost: 30.32s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 0.2914	Cost: 15.33s
Train Epoch: 284 [40960/90000 (45%)]	Loss: -0.0135	Cost: 10.69s
Train Epoch: 284 [61440/90000 (68%)]	Loss: -0.0848	Cost: 8.59s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 0.4188	Cost: 6.05s
Train Epoch: 284 	Average Loss: 0.8648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1831

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 7.7443	Cost: 29.44s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 0.0148	Cost: 9.36s
Train Epoch: 285 [40960/90000 (45%)]	Loss: -0.1567	Cost: 16.15s
Train Epoch: 285 [61440/90000 (68%)]	Loss: -0.2149	Cost: 14.41s
Train Epoch: 285 [81920/90000 (91%)]	Loss: -0.0423	Cost: 6.69s
Train Epoch: 285 	Average Loss: 0.7663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4108

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 7.9958	Cost: 27.54s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 0.0624	Cost: 6.67s
Train Epoch: 286 [40960/90000 (45%)]	Loss: -0.0598	Cost: 20.12s
Train Epoch: 286 [61440/90000 (68%)]	Loss: -0.2610	Cost: 8.96s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 0.0893	Cost: 9.18s
Train Epoch: 286 	Average Loss: 0.7320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3309

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 8.0651	Cost: 24.84s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 0.3643	Cost: 8.96s
Train Epoch: 287 [40960/90000 (45%)]	Loss: -0.1297	Cost: 12.00s
Train Epoch: 287 [61440/90000 (68%)]	Loss: -0.1777	Cost: 11.22s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 0.3370	Cost: 16.04s
Train Epoch: 287 	Average Loss: 0.7152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2266

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 8.3626	Cost: 26.02s
Train Epoch: 288 [20480/90000 (23%)]	Loss: -0.0358	Cost: 6.48s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 0.0726	Cost: 11.09s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 0.0928	Cost: 6.29s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 0.4665	Cost: 21.39s
Train Epoch: 288 	Average Loss: 0.7739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3400

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 8.5865	Cost: 24.27s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 0.2457	Cost: 6.50s
Train Epoch: 289 [40960/90000 (45%)]	Loss: -0.0805	Cost: 9.59s
Train Epoch: 289 [61440/90000 (68%)]	Loss: -0.5605	Cost: 6.27s
Train Epoch: 289 [81920/90000 (91%)]	Loss: -0.0810	Cost: 19.29s
Train Epoch: 289 	Average Loss: 0.7430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1049

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 7.8763	Cost: 23.05s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 0.3005	Cost: 6.83s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 0.3284	Cost: 10.48s
Train Epoch: 290 [61440/90000 (68%)]	Loss: -0.2893	Cost: 6.40s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 0.3345	Cost: 11.53s
Train Epoch: 290 	Average Loss: 0.7399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1219

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 8.3383	Cost: 24.10s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 0.2195	Cost: 8.86s
Train Epoch: 291 [40960/90000 (45%)]	Loss: -0.3603	Cost: 8.90s
Train Epoch: 291 [61440/90000 (68%)]	Loss: -0.3105	Cost: 6.57s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 0.0471	Cost: 6.03s
Train Epoch: 291 	Average Loss: 0.6422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0290

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 7.9395	Cost: 23.92s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 0.0477	Cost: 6.08s
Train Epoch: 292 [40960/90000 (45%)]	Loss: -0.0928	Cost: 10.59s
Train Epoch: 292 [61440/90000 (68%)]	Loss: -0.3105	Cost: 8.30s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -0.0215	Cost: 8.29s
Train Epoch: 292 	Average Loss: 0.6149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0152

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 8.5637	Cost: 24.94s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 0.2214	Cost: 9.07s
Train Epoch: 293 [40960/90000 (45%)]	Loss: -0.3932	Cost: 9.03s
Train Epoch: 293 [61440/90000 (68%)]	Loss: -0.3976	Cost: 6.00s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 0.1012	Cost: 7.03s
Train Epoch: 293 	Average Loss: 0.5674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2008

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 8.0696	Cost: 33.06s
Train Epoch: 294 [20480/90000 (23%)]	Loss: -0.0386	Cost: 15.23s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -0.4099	Cost: 9.52s
Train Epoch: 294 [61440/90000 (68%)]	Loss: -0.3294	Cost: 9.44s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 0.1955	Cost: 6.28s
Train Epoch: 294 	Average Loss: 0.5690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9450

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 7.8143	Cost: 32.00s
Train Epoch: 295 [20480/90000 (23%)]	Loss: -0.3295	Cost: 13.09s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -0.1871	Cost: 15.34s
Train Epoch: 295 [61440/90000 (68%)]	Loss: -0.3169	Cost: 11.42s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 0.0842	Cost: 5.92s
Train Epoch: 295 	Average Loss: 0.6112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0720

Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 8.4837	Cost: 31.33s
Train Epoch: 296 [20480/90000 (23%)]	Loss: -0.0300	Cost: 9.40s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -0.4689	Cost: 15.68s
Train Epoch: 296 [61440/90000 (68%)]	Loss: -0.5444	Cost: 14.69s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 0.4623	Cost: 5.93s
Train Epoch: 296 	Average Loss: 0.5847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1356

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 8.2960	Cost: 29.62s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 0.0387	Cost: 6.09s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 0.0178	Cost: 15.06s
Train Epoch: 297 [61440/90000 (68%)]	Loss: -0.3258	Cost: 14.82s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -0.0161	Cost: 10.90s
Train Epoch: 297 	Average Loss: 0.5743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1264

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 8.0854	Cost: 29.68s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 0.2544	Cost: 6.25s
Train Epoch: 298 [40960/90000 (45%)]	Loss: -0.1475	Cost: 15.59s
Train Epoch: 298 [61440/90000 (68%)]	Loss: -0.6062	Cost: 14.68s
Train Epoch: 298 [81920/90000 (91%)]	Loss: -0.2590	Cost: 12.40s
Train Epoch: 298 	Average Loss: 0.4605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1571

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 8.3944	Cost: 27.74s
Train Epoch: 299 [20480/90000 (23%)]	Loss: -0.0078	Cost: 6.13s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -1.0019	Cost: 13.31s
Train Epoch: 299 [61440/90000 (68%)]	Loss: -0.2443	Cost: 15.98s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 0.3265	Cost: 12.97s
Train Epoch: 299 	Average Loss: 0.4739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3323

Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 8.1494	Cost: 26.24s
Train Epoch: 300 [20480/90000 (23%)]	Loss: -0.2304	Cost: 6.07s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -0.4379	Cost: 13.98s
Train Epoch: 300 [61440/90000 (68%)]	Loss: -0.7215	Cost: 15.27s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 0.0514	Cost: 12.90s
Train Epoch: 300 	Average Loss: 0.4680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1910

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 7.6418	Cost: 24.00s
Train Epoch: 301 [20480/90000 (23%)]	Loss: -0.1751	Cost: 6.35s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -0.6361	Cost: 8.92s
Train Epoch: 301 [61440/90000 (68%)]	Loss: -0.6212	Cost: 10.55s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -0.3176	Cost: 15.94s
Train Epoch: 301 	Average Loss: 0.4298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2331

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 8.4433	Cost: 27.66s
Train Epoch: 302 [20480/90000 (23%)]	Loss: -0.0009	Cost: 6.71s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -0.4956	Cost: 9.98s
Train Epoch: 302 [61440/90000 (68%)]	Loss: -0.6862	Cost: 12.23s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 0.0825	Cost: 15.84s
Train Epoch: 302 	Average Loss: 0.3532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1858

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 7.5722	Cost: 26.57s
Train Epoch: 303 [20480/90000 (23%)]	Loss: -0.5904	Cost: 6.48s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -0.3040	Cost: 9.84s
Train Epoch: 303 [61440/90000 (68%)]	Loss: -0.7150	Cost: 15.22s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -0.2864	Cost: 15.14s
Train Epoch: 303 	Average Loss: 0.3494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2602

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 8.1022	Cost: 27.53s
Train Epoch: 304 [20480/90000 (23%)]	Loss: -0.4545	Cost: 6.50s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -0.7749	Cost: 16.12s
Train Epoch: 304 [61440/90000 (68%)]	Loss: -0.6248	Cost: 15.60s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -0.0125	Cost: 13.57s
Train Epoch: 304 	Average Loss: 0.2743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9748

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 7.5659	Cost: 27.18s
Train Epoch: 305 [20480/90000 (23%)]	Loss: -0.5212	Cost: 6.38s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -0.6396	Cost: 15.42s
Train Epoch: 305 [61440/90000 (68%)]	Loss: -0.6801	Cost: 15.84s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -0.4531	Cost: 12.90s
Train Epoch: 305 	Average Loss: 0.2367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3184

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 8.1066	Cost: 24.94s
Train Epoch: 306 [20480/90000 (23%)]	Loss: -0.3361	Cost: 6.87s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -0.6459	Cost: 10.69s
Train Epoch: 306 [61440/90000 (68%)]	Loss: -0.6573	Cost: 13.61s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -0.1913	Cost: 15.62s
Train Epoch: 306 	Average Loss: 0.3039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1102

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 7.8152	Cost: 24.49s
Train Epoch: 307 [20480/90000 (23%)]	Loss: -0.2545	Cost: 6.35s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -0.4938	Cost: 10.95s
Train Epoch: 307 [61440/90000 (68%)]	Loss: -0.8690	Cost: 6.39s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -0.1377	Cost: 20.69s
Train Epoch: 307 	Average Loss: 0.3257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2427

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 8.1432	Cost: 24.07s
Train Epoch: 308 [20480/90000 (23%)]	Loss: -0.3819	Cost: 6.65s
Train Epoch: 308 [40960/90000 (45%)]	Loss: -0.4757	Cost: 9.01s
Train Epoch: 308 [61440/90000 (68%)]	Loss: -0.8093	Cost: 6.36s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -0.4467	Cost: 15.78s
Train Epoch: 308 	Average Loss: 0.2855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0538

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 8.2172	Cost: 23.76s
Train Epoch: 309 [20480/90000 (23%)]	Loss: -0.3475	Cost: 5.98s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -0.7651	Cost: 10.40s
Train Epoch: 309 [61440/90000 (68%)]	Loss: -0.9896	Cost: 6.57s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -0.2813	Cost: 11.34s
Train Epoch: 309 	Average Loss: 0.2236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0335

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 8.1095	Cost: 23.81s
Train Epoch: 310 [20480/90000 (23%)]	Loss: -0.3615	Cost: 7.38s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -0.6556	Cost: 9.34s
Train Epoch: 310 [61440/90000 (68%)]	Loss: -0.9229	Cost: 8.35s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -0.4261	Cost: 8.25s
Train Epoch: 310 	Average Loss: 0.1963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2718

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 8.1233	Cost: 25.60s
Train Epoch: 311 [20480/90000 (23%)]	Loss: -0.2361	Cost: 9.99s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -0.7326	Cost: 6.09s
Train Epoch: 311 [61440/90000 (68%)]	Loss: -0.7096	Cost: 6.05s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -0.4882	Cost: 6.54s
Train Epoch: 311 	Average Loss: 0.1564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2269

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 8.1950	Cost: 36.76s
Train Epoch: 312 [20480/90000 (23%)]	Loss: -0.5078	Cost: 13.27s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -0.3594	Cost: 10.00s
Train Epoch: 312 [61440/90000 (68%)]	Loss: -1.0305	Cost: 7.91s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -0.4944	Cost: 5.93s
Train Epoch: 312 	Average Loss: 0.2031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2248

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 7.9681	Cost: 36.15s
Train Epoch: 313 [20480/90000 (23%)]	Loss: -0.5676	Cost: 11.97s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -1.0345	Cost: 15.14s
Train Epoch: 313 [61440/90000 (68%)]	Loss: -1.2033	Cost: 12.84s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -0.3807	Cost: 5.89s
Train Epoch: 313 	Average Loss: 0.1100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1133

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 8.0594	Cost: 30.08s
Train Epoch: 314 [20480/90000 (23%)]	Loss: -0.7331	Cost: 6.48s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -0.7434	Cost: 15.83s
Train Epoch: 314 [61440/90000 (68%)]	Loss: -1.3061	Cost: 14.87s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -0.5703	Cost: 8.75s
Train Epoch: 314 	Average Loss: 0.0406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1936

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 7.6215	Cost: 30.59s
Train Epoch: 315 [20480/90000 (23%)]	Loss: -0.4132	Cost: 6.06s
Train Epoch: 315 [40960/90000 (45%)]	Loss: -0.3282	Cost: 16.07s
Train Epoch: 315 [61440/90000 (68%)]	Loss: -1.1703	Cost: 15.23s
Train Epoch: 315 [81920/90000 (91%)]	Loss: -0.3533	Cost: 8.62s
Train Epoch: 315 	Average Loss: 0.0966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1498

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 8.3350	Cost: 30.65s
Train Epoch: 316 [20480/90000 (23%)]	Loss: -0.5200	Cost: 6.32s
Train Epoch: 316 [40960/90000 (45%)]	Loss: -0.9582	Cost: 16.09s
Train Epoch: 316 [61440/90000 (68%)]	Loss: -0.8322	Cost: 15.90s
Train Epoch: 316 [81920/90000 (91%)]	Loss: -0.4659	Cost: 8.22s
Train Epoch: 316 	Average Loss: 0.1218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1952

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 8.2807	Cost: 29.34s
Train Epoch: 317 [20480/90000 (23%)]	Loss: -0.3373	Cost: 6.25s
Train Epoch: 317 [40960/90000 (45%)]	Loss: -0.5146	Cost: 13.57s
Train Epoch: 317 [61440/90000 (68%)]	Loss: -0.6041	Cost: 15.42s
Train Epoch: 317 [81920/90000 (91%)]	Loss: -0.4659	Cost: 12.72s
Train Epoch: 317 	Average Loss: 0.0865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1286

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 7.8996	Cost: 27.99s
Train Epoch: 318 [20480/90000 (23%)]	Loss: -0.5580	Cost: 6.32s
Train Epoch: 318 [40960/90000 (45%)]	Loss: -0.7678	Cost: 15.24s
Train Epoch: 318 [61440/90000 (68%)]	Loss: -1.1471	Cost: 15.99s
Train Epoch: 318 [81920/90000 (91%)]	Loss: -0.5186	Cost: 12.95s
Train Epoch: 318 	Average Loss: -0.0175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9533

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 7.8195	Cost: 28.22s
Train Epoch: 319 [20480/90000 (23%)]	Loss: -0.7960	Cost: 6.15s
Train Epoch: 319 [40960/90000 (45%)]	Loss: -1.0919	Cost: 15.96s
Train Epoch: 319 [61440/90000 (68%)]	Loss: -1.0529	Cost: 13.01s
Train Epoch: 319 [81920/90000 (91%)]	Loss: -0.6943	Cost: 11.12s
Train Epoch: 319 	Average Loss: 0.0197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0465

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 8.2641	Cost: 26.56s
Train Epoch: 320 [20480/90000 (23%)]	Loss: -0.6463	Cost: 6.50s
Train Epoch: 320 [40960/90000 (45%)]	Loss: -1.0142	Cost: 11.78s
Train Epoch: 320 [61440/90000 (68%)]	Loss: -1.1385	Cost: 15.31s
Train Epoch: 320 [81920/90000 (91%)]	Loss: -0.5459	Cost: 15.18s
Train Epoch: 320 	Average Loss: -0.0432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1584

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 8.3995	Cost: 26.68s
Train Epoch: 321 [20480/90000 (23%)]	Loss: -0.6944	Cost: 6.45s
Train Epoch: 321 [40960/90000 (45%)]	Loss: -1.0632	Cost: 13.00s
Train Epoch: 321 [61440/90000 (68%)]	Loss: -0.7807	Cost: 14.90s
Train Epoch: 321 [81920/90000 (91%)]	Loss: -0.6669	Cost: 15.34s
Train Epoch: 321 	Average Loss: 0.0239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1485

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 7.9984	Cost: 40.66s
Train Epoch: 322 [20480/90000 (23%)]	Loss: -0.7051	Cost: 7.19s
Train Epoch: 322 [40960/90000 (45%)]	Loss: -1.0239	Cost: 15.34s
Train Epoch: 322 [61440/90000 (68%)]	Loss: -1.1448	Cost: 14.75s
Train Epoch: 322 [81920/90000 (91%)]	Loss: -0.3203	Cost: 8.81s
Train Epoch: 322 	Average Loss: -0.0827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1523

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 8.1147	Cost: 35.29s
Train Epoch: 323 [20480/90000 (23%)]	Loss: -0.5499	Cost: 6.23s
Train Epoch: 323 [40960/90000 (45%)]	Loss: -1.1073	Cost: 11.28s
Train Epoch: 323 [61440/90000 (68%)]	Loss: -1.1792	Cost: 9.54s
Train Epoch: 323 [81920/90000 (91%)]	Loss: -0.6521	Cost: 15.24s
Train Epoch: 323 	Average Loss: -0.1460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0108

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 8.5995	Cost: 31.20s
Train Epoch: 324 [20480/90000 (23%)]	Loss: -0.3509	Cost: 6.44s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -0.8734	Cost: 12.33s
Train Epoch: 324 [61440/90000 (68%)]	Loss: -1.3473	Cost: 7.86s
Train Epoch: 324 [81920/90000 (91%)]	Loss: -0.7671	Cost: 18.27s
Train Epoch: 324 	Average Loss: -0.0414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2935

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 8.3654	Cost: 41.99s
Train Epoch: 325 [20480/90000 (23%)]	Loss: -0.5896	Cost: 6.27s
Train Epoch: 325 [40960/90000 (45%)]	Loss: -0.9696	Cost: 17.01s
Train Epoch: 325 [61440/90000 (68%)]	Loss: -1.3994	Cost: 15.96s
Train Epoch: 325 [81920/90000 (91%)]	Loss: -0.6159	Cost: 10.44s
Train Epoch: 325 	Average Loss: -0.0874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2608

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 8.6100	Cost: 34.45s
Train Epoch: 326 [20480/90000 (23%)]	Loss: -0.8468	Cost: 6.40s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -0.8862	Cost: 15.95s
Train Epoch: 326 [61440/90000 (68%)]	Loss: -1.2104	Cost: 15.34s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -0.6440	Cost: 11.16s
Train Epoch: 326 	Average Loss: -0.1635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2938

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 8.4707	Cost: 30.42s
Train Epoch: 327 [20480/90000 (23%)]	Loss: -0.4951	Cost: 6.09s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -1.4038	Cost: 15.95s
Train Epoch: 327 [61440/90000 (68%)]	Loss: -1.3617	Cost: 14.99s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -0.5588	Cost: 8.73s
Train Epoch: 327 	Average Loss: -0.1234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0522

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 7.6583	Cost: 30.34s
Train Epoch: 328 [20480/90000 (23%)]	Loss: -0.7741	Cost: 6.09s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -1.4159	Cost: 13.99s
Train Epoch: 328 [61440/90000 (68%)]	Loss: -1.2329	Cost: 15.10s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -0.6714	Cost: 12.59s
Train Epoch: 328 	Average Loss: -0.1928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1893

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 8.3447	Cost: 28.48s
Train Epoch: 329 [20480/90000 (23%)]	Loss: -0.6691	Cost: 6.50s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -0.6889	Cost: 14.83s
Train Epoch: 329 [61440/90000 (68%)]	Loss: -1.0616	Cost: 14.94s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -0.7473	Cost: 12.67s
Train Epoch: 329 	Average Loss: -0.1783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1658

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 8.5072	Cost: 26.15s
Train Epoch: 330 [20480/90000 (23%)]	Loss: -0.8852	Cost: 6.58s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -1.2965	Cost: 11.10s
Train Epoch: 330 [61440/90000 (68%)]	Loss: -1.2640	Cost: 14.30s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -0.9589	Cost: 15.09s
Train Epoch: 330 	Average Loss: -0.1741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1471

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 7.6835	Cost: 24.38s
Train Epoch: 331 [20480/90000 (23%)]	Loss: -0.5696	Cost: 6.57s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -1.0793	Cost: 10.13s
Train Epoch: 331 [61440/90000 (68%)]	Loss: -1.4609	Cost: 6.34s
Train Epoch: 331 [81920/90000 (91%)]	Loss: -0.7103	Cost: 19.86s
Train Epoch: 331 	Average Loss: -0.1930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0980

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 8.2086	Cost: 22.97s
Train Epoch: 332 [20480/90000 (23%)]	Loss: -0.6401	Cost: 6.86s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -1.1622	Cost: 9.96s
Train Epoch: 332 [61440/90000 (68%)]	Loss: -1.5578	Cost: 6.41s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -0.4344	Cost: 12.64s
Train Epoch: 332 	Average Loss: -0.2861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0341

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 7.8985	Cost: 26.60s
Train Epoch: 333 [20480/90000 (23%)]	Loss: -0.5341	Cost: 8.81s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -1.1611	Cost: 8.80s
Train Epoch: 333 [61440/90000 (68%)]	Loss: -1.5259	Cost: 8.36s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -0.9266	Cost: 6.76s
Train Epoch: 333 	Average Loss: -0.2673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0114

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 7.9046	Cost: 26.16s
Train Epoch: 334 [20480/90000 (23%)]	Loss: -0.7201	Cost: 6.28s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -1.1100	Cost: 9.14s
Train Epoch: 334 [61440/90000 (68%)]	Loss: -1.1834	Cost: 6.13s
Train Epoch: 334 [81920/90000 (91%)]	Loss: -0.5833	Cost: 11.66s
Train Epoch: 334 	Average Loss: -0.2653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2259

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 8.3415	Cost: 30.87s
Train Epoch: 335 [20480/90000 (23%)]	Loss: -0.9674	Cost: 10.78s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -1.2236	Cost: 6.37s
Train Epoch: 335 [61440/90000 (68%)]	Loss: -1.2662	Cost: 6.15s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -1.0056	Cost: 11.28s
Train Epoch: 335 	Average Loss: -0.2564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0712

Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 8.7147	Cost: 29.29s
Train Epoch: 336 [20480/90000 (23%)]	Loss: -1.0794	Cost: 10.84s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -1.4937	Cost: 11.68s
Train Epoch: 336 [61440/90000 (68%)]	Loss: -1.1055	Cost: 7.00s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -0.8433	Cost: 6.02s
Train Epoch: 336 	Average Loss: -0.3248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1807

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 8.1285	Cost: 30.48s
Train Epoch: 337 [20480/90000 (23%)]	Loss: -1.0555	Cost: 10.31s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -1.2579	Cost: 16.13s
Train Epoch: 337 [61440/90000 (68%)]	Loss: -1.7953	Cost: 14.06s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -1.1587	Cost: 6.00s
Train Epoch: 337 	Average Loss: -0.3516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0712

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 8.3129	Cost: 24.00s
Train Epoch: 338 [20480/90000 (23%)]	Loss: -1.0066	Cost: 6.86s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -1.2857	Cost: 17.53s
Train Epoch: 338 [61440/90000 (68%)]	Loss: -1.3159	Cost: 13.92s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -0.5093	Cost: 11.87s
Train Epoch: 338 	Average Loss: -0.2963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2170

Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 8.5878	Cost: 32.45s
Train Epoch: 339 [20480/90000 (23%)]	Loss: -0.9313	Cost: 6.49s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -1.1022	Cost: 18.47s
Train Epoch: 339 [61440/90000 (68%)]	Loss: -1.4055	Cost: 10.78s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -0.7752	Cost: 10.78s
Train Epoch: 339 	Average Loss: -0.3122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2699

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 7.5743	Cost: 36.16s
Train Epoch: 340 [20480/90000 (23%)]	Loss: -1.1804	Cost: 6.42s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -1.3742	Cost: 9.95s
Train Epoch: 340 [61440/90000 (68%)]	Loss: -1.2751	Cost: 15.20s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -1.0228	Cost: 14.93s
Train Epoch: 340 	Average Loss: -0.3794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2773

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 7.4976	Cost: 32.59s
Train Epoch: 341 [20480/90000 (23%)]	Loss: -0.8945	Cost: 7.34s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -1.3650	Cost: 11.10s
Train Epoch: 341 [61440/90000 (68%)]	Loss: -1.6745	Cost: 14.39s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -0.9367	Cost: 14.94s
Train Epoch: 341 	Average Loss: -0.3977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2448

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 7.8802	Cost: 32.24s
Train Epoch: 342 [20480/90000 (23%)]	Loss: -1.0418	Cost: 7.15s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -1.2001	Cost: 16.31s
Train Epoch: 342 [61440/90000 (68%)]	Loss: -1.5108	Cost: 15.10s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -1.1165	Cost: 9.64s
Train Epoch: 342 	Average Loss: -0.4039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1869

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 7.1366	Cost: 33.97s
Train Epoch: 343 [20480/90000 (23%)]	Loss: -0.6042	Cost: 6.66s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -1.0919	Cost: 11.08s
Train Epoch: 343 [61440/90000 (68%)]	Loss: -1.3359	Cost: 9.70s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -0.9898	Cost: 16.49s
Train Epoch: 343 	Average Loss: -0.4330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2062

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 8.1790	Cost: 31.66s
Train Epoch: 344 [20480/90000 (23%)]	Loss: -1.4475	Cost: 6.97s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -1.4388	Cost: 12.05s
Train Epoch: 344 [61440/90000 (68%)]	Loss: -1.7179	Cost: 6.63s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -1.3014	Cost: 19.81s
Train Epoch: 344 	Average Loss: -0.4306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2456

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 7.7217	Cost: 32.64s
Train Epoch: 345 [20480/90000 (23%)]	Loss: -1.3008	Cost: 8.00s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -1.4213	Cost: 12.01s
Train Epoch: 345 [61440/90000 (68%)]	Loss: -1.7419	Cost: 7.17s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -1.1113	Cost: 20.52s
Train Epoch: 345 	Average Loss: -0.4624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1851

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 8.1331	Cost: 37.78s
Train Epoch: 346 [20480/90000 (23%)]	Loss: -1.1719	Cost: 6.23s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -1.4928	Cost: 11.70s
Train Epoch: 346 [61440/90000 (68%)]	Loss: -1.4729	Cost: 8.53s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -0.8300	Cost: 16.65s
Train Epoch: 346 	Average Loss: -0.4311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1013

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 8.7214	Cost: 31.71s
Train Epoch: 347 [20480/90000 (23%)]	Loss: -1.1562	Cost: 6.51s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -1.6632	Cost: 12.54s
Train Epoch: 347 [61440/90000 (68%)]	Loss: -1.8060	Cost: 8.80s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -1.2147	Cost: 18.19s
Train Epoch: 347 	Average Loss: -0.4799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1812

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 8.2695	Cost: 31.52s
Train Epoch: 348 [20480/90000 (23%)]	Loss: -1.0214	Cost: 7.03s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -0.7429	Cost: 11.60s
Train Epoch: 348 [61440/90000 (68%)]	Loss: -1.5666	Cost: 12.35s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -1.0941	Cost: 14.84s
Train Epoch: 348 	Average Loss: -0.4754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2108

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 8.5460	Cost: 37.31s
Train Epoch: 349 [20480/90000 (23%)]	Loss: -1.5108	Cost: 6.56s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -1.3439	Cost: 15.51s
Train Epoch: 349 [61440/90000 (68%)]	Loss: -1.6011	Cost: 15.96s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -1.1577	Cost: 9.16s
Train Epoch: 349 	Average Loss: -0.4805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2003

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 7.9160	Cost: 35.13s
Train Epoch: 350 [20480/90000 (23%)]	Loss: -1.2752	Cost: 9.59s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -1.2253	Cost: 15.73s
Train Epoch: 350 [61440/90000 (68%)]	Loss: -1.5899	Cost: 14.72s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -0.9462	Cost: 6.09s
Train Epoch: 350 	Average Loss: -0.5753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0451

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 7.7170	Cost: 33.07s
Train Epoch: 351 [20480/90000 (23%)]	Loss: -1.4080	Cost: 6.12s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -1.8597	Cost: 15.31s
Train Epoch: 351 [61440/90000 (68%)]	Loss: -1.7012	Cost: 15.10s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -1.0794	Cost: 9.19s
Train Epoch: 351 	Average Loss: -0.5509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1168

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 8.8008	Cost: 29.57s
Train Epoch: 352 [20480/90000 (23%)]	Loss: -1.0313	Cost: 6.09s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -1.5916	Cost: 14.96s
Train Epoch: 352 [61440/90000 (68%)]	Loss: -1.4870	Cost: 14.87s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -1.0862	Cost: 9.85s
Train Epoch: 352 	Average Loss: -0.5242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0587

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 7.6324	Cost: 27.37s
Train Epoch: 353 [20480/90000 (23%)]	Loss: -1.2825	Cost: 6.47s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -1.4938	Cost: 12.04s
Train Epoch: 353 [61440/90000 (68%)]	Loss: -1.5737	Cost: 15.31s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -0.7872	Cost: 15.13s
Train Epoch: 353 	Average Loss: -0.5239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0202

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 8.3149	Cost: 25.03s
Train Epoch: 354 [20480/90000 (23%)]	Loss: -0.8588	Cost: 6.59s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -1.5178	Cost: 8.93s
Train Epoch: 354 [61440/90000 (68%)]	Loss: -1.7132	Cost: 9.50s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -1.4037	Cost: 15.31s
Train Epoch: 354 	Average Loss: -0.6102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0788

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 7.8358	Cost: 24.76s
Train Epoch: 355 [20480/90000 (23%)]	Loss: -1.2201	Cost: 6.65s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -1.4611	Cost: 10.80s
Train Epoch: 355 [61440/90000 (68%)]	Loss: -1.9415	Cost: 6.72s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -0.8708	Cost: 18.99s
Train Epoch: 355 	Average Loss: -0.6382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1325

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 7.1653	Cost: 22.99s
Train Epoch: 356 [20480/90000 (23%)]	Loss: -1.2198	Cost: 6.54s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -1.2584	Cost: 9.78s
Train Epoch: 356 [61440/90000 (68%)]	Loss: -2.0017	Cost: 6.32s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -1.1222	Cost: 10.98s
Train Epoch: 356 	Average Loss: -0.5878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1487

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 8.5951	Cost: 25.63s
Train Epoch: 357 [20480/90000 (23%)]	Loss: -1.0309	Cost: 8.72s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -1.3728	Cost: 8.73s
Train Epoch: 357 [61440/90000 (68%)]	Loss: -1.9381	Cost: 7.67s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -1.2335	Cost: 5.92s
Train Epoch: 357 	Average Loss: -0.6009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3145

Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 7.8883	Cost: 27.69s
Train Epoch: 358 [20480/90000 (23%)]	Loss: -1.3875	Cost: 6.30s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -1.8269	Cost: 11.01s
Train Epoch: 358 [61440/90000 (68%)]	Loss: -2.0914	Cost: 8.32s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -1.1927	Cost: 8.38s
Train Epoch: 358 	Average Loss: -0.6693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9894

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 7.7384	Cost: 31.58s
Train Epoch: 359 [20480/90000 (23%)]	Loss: -1.1410	Cost: 6.94s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -1.3487	Cost: 10.27s
Train Epoch: 359 [61440/90000 (68%)]	Loss: -1.6878	Cost: 6.14s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -1.2090	Cost: 11.95s
Train Epoch: 359 	Average Loss: -0.6673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1103

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 7.8147	Cost: 26.63s
Train Epoch: 360 [20480/90000 (23%)]	Loss: -0.8253	Cost: 6.39s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -1.6498	Cost: 13.18s
Train Epoch: 360 [61440/90000 (68%)]	Loss: -1.7460	Cost: 6.22s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -0.8738	Cost: 13.35s
Train Epoch: 360 	Average Loss: -0.6120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1483

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 7.8696	Cost: 29.78s
Train Epoch: 361 [20480/90000 (23%)]	Loss: -1.1297	Cost: 13.56s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -1.6172	Cost: 11.33s
Train Epoch: 361 [61440/90000 (68%)]	Loss: -1.7760	Cost: 6.93s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -1.1770	Cost: 6.13s
Train Epoch: 361 	Average Loss: -0.6536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2861

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 7.1053	Cost: 30.71s
Train Epoch: 362 [20480/90000 (23%)]	Loss: -1.2156	Cost: 10.19s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -1.6909	Cost: 15.40s
Train Epoch: 362 [61440/90000 (68%)]	Loss: -2.0050	Cost: 14.71s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -0.8605	Cost: 6.00s
Train Epoch: 362 	Average Loss: -0.6984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2643

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 7.6903	Cost: 31.16s
Train Epoch: 363 [20480/90000 (23%)]	Loss: -1.6335	Cost: 6.20s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -1.5385	Cost: 16.29s
Train Epoch: 363 [61440/90000 (68%)]	Loss: -1.9069	Cost: 12.60s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -1.0367	Cost: 11.86s
Train Epoch: 363 	Average Loss: -0.7034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0233

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 8.1162	Cost: 27.34s
Train Epoch: 364 [20480/90000 (23%)]	Loss: -1.1434	Cost: 6.19s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -1.5614	Cost: 17.57s
Train Epoch: 364 [61440/90000 (68%)]	Loss: -1.5836	Cost: 12.78s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -0.9997	Cost: 11.87s
Train Epoch: 364 	Average Loss: -0.6780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0436

Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 8.5454	Cost: 26.46s
Train Epoch: 365 [20480/90000 (23%)]	Loss: -1.3410	Cost: 7.41s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -1.7082	Cost: 16.89s
Train Epoch: 365 [61440/90000 (68%)]	Loss: -1.8077	Cost: 15.80s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -1.1459	Cost: 12.85s
Train Epoch: 365 	Average Loss: -0.6940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0167

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 8.0754	Cost: 31.39s
Train Epoch: 366 [20480/90000 (23%)]	Loss: -1.2377	Cost: 7.94s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -1.5197	Cost: 14.62s
Train Epoch: 366 [61440/90000 (68%)]	Loss: -1.9301	Cost: 15.27s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -0.9937	Cost: 11.19s
Train Epoch: 366 	Average Loss: -0.6926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8865

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 8.1576	Cost: 45.82s
Train Epoch: 367 [20480/90000 (23%)]	Loss: -1.4728	Cost: 6.07s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -1.6755	Cost: 15.43s
Train Epoch: 367 [61440/90000 (68%)]	Loss: -1.9515	Cost: 15.25s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -1.3593	Cost: 9.05s
Train Epoch: 367 	Average Loss: -0.7574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1437

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 8.0317	Cost: 48.39s
Train Epoch: 368 [20480/90000 (23%)]	Loss: -1.4565	Cost: 15.32s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -1.6352	Cost: 7.95s
Train Epoch: 368 [61440/90000 (68%)]	Loss: -1.9277	Cost: 11.83s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -1.2891	Cost: 6.33s
Train Epoch: 368 	Average Loss: -0.7506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2292

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 7.9816	Cost: 31.28s
Train Epoch: 369 [20480/90000 (23%)]	Loss: -1.4806	Cost: 6.04s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -1.8605	Cost: 15.12s
Train Epoch: 369 [61440/90000 (68%)]	Loss: -1.9068	Cost: 15.07s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -1.2345	Cost: 9.59s
Train Epoch: 369 	Average Loss: -0.7439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1743

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 8.1958	Cost: 29.27s
Train Epoch: 370 [20480/90000 (23%)]	Loss: -1.1921	Cost: 6.16s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -1.5170	Cost: 13.67s
Train Epoch: 370 [61440/90000 (68%)]	Loss: -2.1017	Cost: 15.86s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -0.9390	Cost: 14.70s
Train Epoch: 370 	Average Loss: -0.6794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1422

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 7.4683	Cost: 24.31s
Train Epoch: 371 [20480/90000 (23%)]	Loss: -1.4766	Cost: 6.37s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -1.5583	Cost: 9.65s
Train Epoch: 371 [61440/90000 (68%)]	Loss: -1.8842	Cost: 12.16s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -0.9553	Cost: 14.76s
Train Epoch: 371 	Average Loss: -0.7430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2277

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 8.6157	Cost: 26.74s
Train Epoch: 372 [20480/90000 (23%)]	Loss: -1.4761	Cost: 6.56s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -1.9278	Cost: 10.81s
Train Epoch: 372 [61440/90000 (68%)]	Loss: -1.8917	Cost: 8.61s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -1.1891	Cost: 16.93s
Train Epoch: 372 	Average Loss: -0.7464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9519

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 7.9032	Cost: 26.27s
Train Epoch: 373 [20480/90000 (23%)]	Loss: -1.3782	Cost: 6.50s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -1.5849	Cost: 11.44s
Train Epoch: 373 [61440/90000 (68%)]	Loss: -1.9366	Cost: 6.20s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -1.3916	Cost: 19.70s
Train Epoch: 373 	Average Loss: -0.7587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1093

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 8.5949	Cost: 23.69s
Train Epoch: 374 [20480/90000 (23%)]	Loss: -1.2651	Cost: 6.52s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -2.2336	Cost: 10.25s
Train Epoch: 374 [61440/90000 (68%)]	Loss: -1.8541	Cost: 6.20s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -1.1877	Cost: 19.47s
Train Epoch: 374 	Average Loss: -0.7768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1280

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 8.2359	Cost: 23.32s
Train Epoch: 375 [20480/90000 (23%)]	Loss: -1.2907	Cost: 6.62s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -1.8573	Cost: 10.38s
Train Epoch: 375 [61440/90000 (68%)]	Loss: -1.9746	Cost: 6.32s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -1.4780	Cost: 12.91s
Train Epoch: 375 	Average Loss: -0.7752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2162

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 8.3790	Cost: 26.12s
Train Epoch: 376 [20480/90000 (23%)]	Loss: -1.2389	Cost: 8.80s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -1.7802	Cost: 8.72s
Train Epoch: 376 [61440/90000 (68%)]	Loss: -1.8853	Cost: 8.43s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -1.4984	Cost: 8.01s
Train Epoch: 376 	Average Loss: -0.7689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0073

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 8.1007	Cost: 25.31s
Train Epoch: 377 [20480/90000 (23%)]	Loss: -1.5301	Cost: 6.39s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -1.7725	Cost: 9.03s
Train Epoch: 377 [61440/90000 (68%)]	Loss: -2.0730	Cost: 5.98s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -1.1486	Cost: 11.02s
Train Epoch: 377 	Average Loss: -0.7808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2710

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 7.9384	Cost: 31.35s
Train Epoch: 378 [20480/90000 (23%)]	Loss: -0.9070	Cost: 10.30s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -1.8700	Cost: 8.17s
Train Epoch: 378 [61440/90000 (68%)]	Loss: -1.8406	Cost: 6.18s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -1.2639	Cost: 10.35s
Train Epoch: 378 	Average Loss: -0.7954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0480

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 8.3242	Cost: 31.25s
Train Epoch: 379 [20480/90000 (23%)]	Loss: -1.4540	Cost: 8.68s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -1.9253	Cost: 14.25s
Train Epoch: 379 [61440/90000 (68%)]	Loss: -1.9993	Cost: 6.01s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -1.4223	Cost: 8.39s
Train Epoch: 379 	Average Loss: -0.8058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1637

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 8.1999	Cost: 28.07s
Train Epoch: 380 [20480/90000 (23%)]	Loss: -1.3245	Cost: 14.47s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -1.7269	Cost: 13.95s
Train Epoch: 380 [61440/90000 (68%)]	Loss: -1.8184	Cost: 11.96s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -1.1663	Cost: 6.09s
Train Epoch: 380 	Average Loss: -0.7838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1452

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 8.3917	Cost: 27.87s
Train Epoch: 381 [20480/90000 (23%)]	Loss: -1.1804	Cost: 6.55s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -1.7687	Cost: 16.61s
Train Epoch: 381 [61440/90000 (68%)]	Loss: -2.0069	Cost: 11.82s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -1.5274	Cost: 10.89s
Train Epoch: 381 	Average Loss: -0.7715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0303

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 8.0679	Cost: 25.62s
Train Epoch: 382 [20480/90000 (23%)]	Loss: -1.2836	Cost: 8.18s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -1.9645	Cost: 11.93s
Train Epoch: 382 [61440/90000 (68%)]	Loss: -2.0855	Cost: 15.78s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -1.3169	Cost: 14.89s
Train Epoch: 382 	Average Loss: -0.8215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1374

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 7.7400	Cost: 28.59s
Train Epoch: 383 [20480/90000 (23%)]	Loss: -1.3838	Cost: 7.67s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -1.7748	Cost: 14.43s
Train Epoch: 383 [61440/90000 (68%)]	Loss: -2.1757	Cost: 15.14s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -1.5573	Cost: 14.87s
Train Epoch: 383 	Average Loss: -0.8895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0941

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 7.7420	Cost: 34.26s
Train Epoch: 384 [20480/90000 (23%)]	Loss: -1.2788	Cost: 7.01s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -1.6444	Cost: 11.32s
Train Epoch: 384 [61440/90000 (68%)]	Loss: -1.9962	Cost: 8.91s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -1.3796	Cost: 18.10s
Train Epoch: 384 	Average Loss: -0.8048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0292

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 7.6355	Cost: 36.21s
Train Epoch: 385 [20480/90000 (23%)]	Loss: -1.3764	Cost: 7.01s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -1.6972	Cost: 12.45s
Train Epoch: 385 [61440/90000 (68%)]	Loss: -1.8383	Cost: 10.81s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -1.4471	Cost: 16.08s
Train Epoch: 385 	Average Loss: -0.8461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9772

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 8.1186	Cost: 31.90s
Train Epoch: 386 [20480/90000 (23%)]	Loss: -1.4686	Cost: 7.67s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -1.6568	Cost: 12.06s
Train Epoch: 386 [61440/90000 (68%)]	Loss: -2.0222	Cost: 6.21s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -1.3778	Cost: 20.61s
Train Epoch: 386 	Average Loss: -0.8829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2850

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 8.1432	Cost: 25.53s
Train Epoch: 387 [20480/90000 (23%)]	Loss: -1.3171	Cost: 9.12s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -1.7843	Cost: 11.50s
Train Epoch: 387 [61440/90000 (68%)]	Loss: -1.8927	Cost: 6.18s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -1.2211	Cost: 12.93s
Train Epoch: 387 	Average Loss: -0.8211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0261

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 8.9378	Cost: 26.35s
Train Epoch: 388 [20480/90000 (23%)]	Loss: -1.8018	Cost: 9.06s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -1.9265	Cost: 8.36s
Train Epoch: 388 [61440/90000 (68%)]	Loss: -2.3718	Cost: 6.41s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -1.4816	Cost: 12.48s
Train Epoch: 388 	Average Loss: -0.8613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3234

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 7.6053	Cost: 26.16s
Train Epoch: 389 [20480/90000 (23%)]	Loss: -1.4881	Cost: 7.69s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -1.6778	Cost: 12.14s
Train Epoch: 389 [61440/90000 (68%)]	Loss: -1.7811	Cost: 8.71s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -1.4983	Cost: 8.36s
Train Epoch: 389 	Average Loss: -0.8224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0247

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 7.9517	Cost: 22.71s
Train Epoch: 390 [20480/90000 (23%)]	Loss: -1.6282	Cost: 10.52s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -1.4957	Cost: 8.17s
Train Epoch: 390 [61440/90000 (68%)]	Loss: -2.1012	Cost: 6.29s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -1.5654	Cost: 8.63s
Train Epoch: 390 	Average Loss: -0.8533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0230

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 8.5577	Cost: 31.07s
Train Epoch: 391 [20480/90000 (23%)]	Loss: -1.6179	Cost: 15.02s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -1.6797	Cost: 15.52s
Train Epoch: 391 [61440/90000 (68%)]	Loss: -1.7686	Cost: 9.36s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -1.5719	Cost: 6.08s
Train Epoch: 391 	Average Loss: -0.7949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1812

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 8.4552	Cost: 28.15s
Train Epoch: 392 [20480/90000 (23%)]	Loss: -1.6396	Cost: 6.16s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -1.8173	Cost: 15.26s
Train Epoch: 392 [61440/90000 (68%)]	Loss: -1.9382	Cost: 13.05s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -1.2374	Cost: 12.01s
Train Epoch: 392 	Average Loss: -0.7774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0569

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 8.1518	Cost: 27.14s
Train Epoch: 393 [20480/90000 (23%)]	Loss: -1.3004	Cost: 6.12s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -1.6767	Cost: 15.56s
Train Epoch: 393 [61440/90000 (68%)]	Loss: -2.2899	Cost: 13.84s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -1.6360	Cost: 10.16s
Train Epoch: 393 	Average Loss: -0.8409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1679

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 7.8949	Cost: 29.47s
Train Epoch: 394 [20480/90000 (23%)]	Loss: -1.4367	Cost: 6.37s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -1.8614	Cost: 16.40s
Train Epoch: 394 [61440/90000 (68%)]	Loss: -1.8181	Cost: 15.60s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -1.6147	Cost: 14.15s
Train Epoch: 394 	Average Loss: -0.8155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0695

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 8.0663	Cost: 34.65s
Train Epoch: 395 [20480/90000 (23%)]	Loss: -1.2451	Cost: 6.31s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -1.6490	Cost: 17.14s
Train Epoch: 395 [61440/90000 (68%)]	Loss: -1.8319	Cost: 12.13s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -1.4388	Cost: 10.64s
Train Epoch: 395 	Average Loss: -0.8361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0231

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 8.6639	Cost: 38.33s
Train Epoch: 396 [20480/90000 (23%)]	Loss: -1.6113	Cost: 7.42s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -1.7388	Cost: 15.92s
Train Epoch: 396 [61440/90000 (68%)]	Loss: -1.8133	Cost: 14.29s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -1.1718	Cost: 8.53s
Train Epoch: 396 	Average Loss: -0.8107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1355

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 8.5259	Cost: 34.46s
Train Epoch: 397 [20480/90000 (23%)]	Loss: -1.4863	Cost: 6.44s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -1.8542	Cost: 11.31s
Train Epoch: 397 [61440/90000 (68%)]	Loss: -2.0219	Cost: 7.16s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -1.6492	Cost: 17.34s
Train Epoch: 397 	Average Loss: -0.8575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1206

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 7.3471	Cost: 30.39s
Train Epoch: 398 [20480/90000 (23%)]	Loss: -1.4413	Cost: 9.56s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -1.8540	Cost: 13.43s
Train Epoch: 398 [61440/90000 (68%)]	Loss: -1.6369	Cost: 15.24s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -1.4789	Cost: 14.69s
Train Epoch: 398 	Average Loss: -0.8432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2387

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 8.6505	Cost: 34.47s
Train Epoch: 399 [20480/90000 (23%)]	Loss: -1.2749	Cost: 6.57s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -1.7772	Cost: 16.24s
Train Epoch: 399 [61440/90000 (68%)]	Loss: -1.9252	Cost: 15.47s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -1.5068	Cost: 10.93s
Train Epoch: 399 	Average Loss: -0.8653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1565

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 8.3414	Cost: 35.06s
Train Epoch: 400 [20480/90000 (23%)]	Loss: -1.6110	Cost: 6.25s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -1.8468	Cost: 12.20s
Train Epoch: 400 [61440/90000 (68%)]	Loss: -2.3062	Cost: 15.19s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -1.4081	Cost: 15.47s
Train Epoch: 400 	Average Loss: -0.8646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1589

Stopping timer.
Training time (including validation): 186931.10161376 seconds
Saving model
Transfer learning by starting with alpha=0.2!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 33.9028	Cost: 29.09s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.2234	Cost: 6.98s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 18.8079	Cost: 10.40s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 17.9229	Cost: 8.93s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 17.0599	Cost: 8.63s
Train Epoch: 1 	Average Loss: 20.0390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8001

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 16.9491	Cost: 30.90s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 16.2563	Cost: 6.54s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 16.2167	Cost: 11.85s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 15.9434	Cost: 6.16s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 15.3822	Cost: 13.64s
Train Epoch: 2 	Average Loss: 16.0766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5255

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 15.5111	Cost: 27.48s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 15.1604	Cost: 6.39s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 14.9777	Cost: 12.94s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 15.0788	Cost: 6.09s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 15.0057	Cost: 11.85s
Train Epoch: 3 	Average Loss: 15.1724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9857

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 15.3445	Cost: 30.64s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 14.8468	Cost: 15.42s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 14.6875	Cost: 10.21s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 14.8341	Cost: 9.56s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 14.6326	Cost: 5.99s
Train Epoch: 4 	Average Loss: 14.7504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6971

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 15.1323	Cost: 27.99s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 14.3100	Cost: 14.70s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 14.5962	Cost: 15.77s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 14.4996	Cost: 10.00s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 14.5238	Cost: 6.22s
Train Epoch: 5 	Average Loss: 14.4591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5165

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 14.6824	Cost: 28.75s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 14.0740	Cost: 14.20s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 13.9725	Cost: 14.24s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 14.2066	Cost: 11.97s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 14.1239	Cost: 6.06s
Train Epoch: 6 	Average Loss: 14.2329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5832

Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 14.4472	Cost: 28.99s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 13.8012	Cost: 6.18s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 13.8733	Cost: 17.09s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 13.9181	Cost: 11.81s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 13.8216	Cost: 5.96s
Train Epoch: 7 	Average Loss: 14.0586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5035

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 14.3659	Cost: 25.45s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 14.1205	Cost: 6.68s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 13.8022	Cost: 9.88s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 14.0059	Cost: 9.57s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 13.7780	Cost: 17.74s
Train Epoch: 8 	Average Loss: 13.9431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4901

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 14.2522	Cost: 22.80s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 14.1549	Cost: 6.09s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 13.5663	Cost: 7.92s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 13.7664	Cost: 6.01s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 13.6643	Cost: 10.60s
Train Epoch: 9 	Average Loss: 13.8288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4174

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 14.3446	Cost: 23.63s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 13.8820	Cost: 6.01s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 13.5805	Cost: 8.32s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 14.0578	Cost: 5.91s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 13.4193	Cost: 7.44s
Train Epoch: 10 	Average Loss: 13.7725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3995

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 14.2282	Cost: 22.17s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 13.7722	Cost: 6.08s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 13.6026	Cost: 8.17s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 13.8361	Cost: 6.02s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 13.3357	Cost: 9.48s
Train Epoch: 11 	Average Loss: 13.6790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5612

Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 13.9695	Cost: 24.48s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 13.4218	Cost: 6.19s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 13.7273	Cost: 7.76s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 13.3555	Cost: 6.08s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 13.4381	Cost: 8.18s
Train Epoch: 12 	Average Loss: 13.5764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4871

Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 14.3080	Cost: 30.03s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 13.5095	Cost: 6.13s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 13.5044	Cost: 10.37s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 13.5260	Cost: 6.14s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 13.2168	Cost: 11.00s
Train Epoch: 13 	Average Loss: 13.5407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3777

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 14.0105	Cost: 24.25s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 13.5848	Cost: 6.27s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 13.5626	Cost: 10.54s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 13.4250	Cost: 6.09s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 13.0753	Cost: 10.09s
Train Epoch: 14 	Average Loss: 13.4905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4286

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 13.9903	Cost: 21.90s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 13.0245	Cost: 6.10s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 13.1996	Cost: 7.81s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 13.4608	Cost: 6.48s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 13.0920	Cost: 11.00s
Train Epoch: 15 	Average Loss: 13.3938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3776

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 13.9465	Cost: 23.86s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 13.1919	Cost: 8.71s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 13.2870	Cost: 8.69s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 13.2724	Cost: 8.36s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 12.9790	Cost: 6.13s
Train Epoch: 16 	Average Loss: 13.3679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4176

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 14.1470	Cost: 23.93s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 13.3835	Cost: 7.02s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 13.4489	Cost: 8.62s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 13.3519	Cost: 8.52s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 13.0906	Cost: 8.83s
Train Epoch: 17 	Average Loss: 13.3389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4210

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 14.5575	Cost: 26.45s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 12.9587	Cost: 10.11s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 13.2375	Cost: 6.19s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 13.2475	Cost: 6.05s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 13.1012	Cost: 7.46s
Train Epoch: 18 	Average Loss: 13.2890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4222

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 14.2341	Cost: 30.06s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 13.1166	Cost: 6.27s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 13.1134	Cost: 12.12s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 13.4435	Cost: 6.16s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 12.8544	Cost: 6.34s
Train Epoch: 19 	Average Loss: 13.2368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5464

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 14.3370	Cost: 32.82s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 13.2142	Cost: 15.25s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 13.0716	Cost: 15.15s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 13.2740	Cost: 7.93s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 12.5719	Cost: 5.85s
Train Epoch: 20 	Average Loss: 13.1949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4999

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 14.4213	Cost: 31.74s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 13.1345	Cost: 15.20s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 12.9454	Cost: 15.20s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 13.2848	Cost: 9.70s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 12.9449	Cost: 5.86s
Train Epoch: 21 	Average Loss: 13.1660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4609

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 14.0358	Cost: 28.22s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 13.0290	Cost: 11.16s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 12.8771	Cost: 16.02s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 12.9763	Cost: 12.95s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 12.9392	Cost: 5.99s
Train Epoch: 22 	Average Loss: 13.0849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5452

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 14.0907	Cost: 29.57s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 12.8764	Cost: 6.38s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 13.0838	Cost: 13.37s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 13.0521	Cost: 15.20s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 12.6103	Cost: 11.55s
Train Epoch: 23 	Average Loss: 13.0499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5287

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 14.0190	Cost: 28.23s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 12.8495	Cost: 6.57s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 12.7285	Cost: 15.30s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 12.9266	Cost: 15.26s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 12.8024	Cost: 13.75s
Train Epoch: 24 	Average Loss: 13.0195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5667

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 14.0434	Cost: 27.50s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 13.0485	Cost: 6.33s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 12.9098	Cost: 9.89s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 12.8886	Cost: 15.69s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 12.5517	Cost: 15.36s
Train Epoch: 25 	Average Loss: 12.9625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6406

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 13.6561	Cost: 27.85s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 13.0633	Cost: 6.31s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 12.7235	Cost: 13.74s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 12.9454	Cost: 15.72s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 12.7616	Cost: 12.15s
Train Epoch: 26 	Average Loss: 12.9145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7465

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 14.2494	Cost: 26.86s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 12.9845	Cost: 6.29s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 12.3928	Cost: 16.45s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 12.9264	Cost: 15.55s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 12.4591	Cost: 13.83s
Train Epoch: 27 	Average Loss: 12.9187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5392

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 14.2570	Cost: 30.22s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 12.6099	Cost: 8.17s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 12.5687	Cost: 10.39s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 13.0129	Cost: 6.23s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 12.1540	Cost: 19.70s
Train Epoch: 28 	Average Loss: 12.8187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7338

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 14.0470	Cost: 27.08s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 12.7961	Cost: 8.81s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 12.6019	Cost: 10.62s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 12.6609	Cost: 8.49s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 12.3651	Cost: 17.66s
Train Epoch: 29 	Average Loss: 12.8173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6898

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 14.4781	Cost: 25.52s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 12.5796	Cost: 6.47s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 12.4522	Cost: 13.48s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 12.9081	Cost: 6.36s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 12.5675	Cost: 20.03s
Train Epoch: 30 	Average Loss: 12.7779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5514

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 14.2243	Cost: 25.45s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 12.5715	Cost: 6.60s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 12.5618	Cost: 9.69s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 12.7560	Cost: 6.26s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 12.6707	Cost: 20.38s
Train Epoch: 31 	Average Loss: 12.6965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7185

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 14.4684	Cost: 26.80s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 12.4983	Cost: 6.47s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 12.6982	Cost: 9.91s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 12.4847	Cost: 8.62s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 12.6103	Cost: 16.84s
Train Epoch: 32 	Average Loss: 12.7106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5258

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 14.1285	Cost: 28.53s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 12.5198	Cost: 6.50s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 12.5920	Cost: 10.24s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 12.4438	Cost: 10.49s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 12.1954	Cost: 15.73s
Train Epoch: 33 	Average Loss: 12.6724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6313

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 14.1596	Cost: 24.89s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 12.3811	Cost: 6.70s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 12.6411	Cost: 9.93s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 12.5235	Cost: 7.88s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 12.2063	Cost: 18.58s
Train Epoch: 34 	Average Loss: 12.5883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7638

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 14.8187	Cost: 24.59s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 12.7864	Cost: 6.45s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 12.5979	Cost: 10.81s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 12.3658	Cost: 6.16s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 12.4798	Cost: 19.95s
Train Epoch: 35 	Average Loss: 12.6417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7459

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 14.4686	Cost: 24.00s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 12.6327	Cost: 6.54s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 12.3552	Cost: 10.43s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 12.5494	Cost: 6.46s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 12.2270	Cost: 19.77s
Train Epoch: 36 	Average Loss: 12.5884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7494

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 14.1594	Cost: 24.40s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 12.3253	Cost: 6.55s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 12.4324	Cost: 10.28s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 12.5934	Cost: 6.35s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 12.1677	Cost: 16.03s
Train Epoch: 37 	Average Loss: 12.5172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7821

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 14.2532	Cost: 25.09s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 12.2700	Cost: 8.74s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 12.2905	Cost: 6.72s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 12.3725	Cost: 6.48s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 12.2675	Cost: 9.56s
Train Epoch: 38 	Average Loss: 12.4886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7141

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 14.4814	Cost: 27.66s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 12.2642	Cost: 7.87s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 12.0465	Cost: 9.39s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 12.2265	Cost: 8.37s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 11.9263	Cost: 8.30s
Train Epoch: 39 	Average Loss: 12.4484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6797

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 14.2209	Cost: 30.50s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 12.4456	Cost: 6.48s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 12.2966	Cost: 12.25s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 12.5343	Cost: 6.31s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 11.9119	Cost: 13.74s
Train Epoch: 40 	Average Loss: 12.4581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7316

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 14.7457	Cost: 28.33s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 12.1424	Cost: 9.79s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 12.3972	Cost: 9.33s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 12.4893	Cost: 6.06s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 11.9205	Cost: 12.66s
Train Epoch: 41 	Average Loss: 12.5017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8708

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 14.5407	Cost: 29.24s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 12.1908	Cost: 12.73s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 12.2163	Cost: 12.23s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 12.3208	Cost: 6.26s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 12.0426	Cost: 6.37s
Train Epoch: 42 	Average Loss: 12.4032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8245

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 14.1413	Cost: 29.90s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 12.2638	Cost: 9.55s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 12.0654	Cost: 15.76s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 12.3291	Cost: 15.03s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 11.6601	Cost: 6.08s
Train Epoch: 43 	Average Loss: 12.3459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7969

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 14.4248	Cost: 29.44s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 11.8131	Cost: 13.21s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 12.3364	Cost: 16.08s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 11.9355	Cost: 11.14s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 11.7829	Cost: 6.09s
Train Epoch: 44 	Average Loss: 12.3491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7186

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 14.3702	Cost: 30.00s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 11.9599	Cost: 6.19s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 12.1608	Cost: 17.61s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 12.2031	Cost: 11.04s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 12.0039	Cost: 8.19s
Train Epoch: 45 	Average Loss: 12.2850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7137

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 14.1811	Cost: 23.59s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 12.0460	Cost: 6.67s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 12.0667	Cost: 7.99s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 12.2348	Cost: 6.30s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 11.8436	Cost: 20.17s
Train Epoch: 46 	Average Loss: 12.2794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8273

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 14.6401	Cost: 25.84s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 11.6721	Cost: 6.50s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 11.9925	Cost: 9.32s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 12.0842	Cost: 6.18s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 11.9169	Cost: 18.70s
Train Epoch: 47 	Average Loss: 12.2088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9212

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 14.3370	Cost: 23.67s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 11.9086	Cost: 6.48s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 12.2067	Cost: 9.93s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 11.8912	Cost: 6.30s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 11.9773	Cost: 20.26s
Train Epoch: 48 	Average Loss: 12.2221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0078

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 14.4892	Cost: 24.08s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 12.1951	Cost: 6.77s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 11.8899	Cost: 10.14s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 11.9256	Cost: 6.20s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 11.9321	Cost: 20.12s
Train Epoch: 49 	Average Loss: 12.1797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8701

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 14.7695	Cost: 24.76s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 12.0192	Cost: 6.80s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 11.8405	Cost: 10.39s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 12.1091	Cost: 6.17s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 11.8990	Cost: 19.93s
Train Epoch: 50 	Average Loss: 12.2093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9204

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 14.4750	Cost: 24.80s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 11.9422	Cost: 6.59s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 12.1026	Cost: 10.52s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 11.8735	Cost: 6.18s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 11.6068	Cost: 18.98s
Train Epoch: 51 	Average Loss: 12.1907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8180

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 14.7296	Cost: 23.02s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 11.7885	Cost: 6.47s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 11.9633	Cost: 10.04s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 11.8651	Cost: 6.44s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 11.6115	Cost: 11.98s
Train Epoch: 52 	Average Loss: 12.0988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8897

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 14.1927	Cost: 26.09s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 11.7445	Cost: 8.74s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 11.7025	Cost: 8.89s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 11.9196	Cost: 7.86s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 12.1085	Cost: 5.76s
Train Epoch: 53 	Average Loss: 12.0657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9567

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 14.8113	Cost: 27.14s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 11.9413	Cost: 6.29s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 11.7893	Cost: 9.83s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 12.0680	Cost: 8.33s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 11.5126	Cost: 8.31s
Train Epoch: 54 	Average Loss: 12.2131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8489

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 14.6262	Cost: 31.57s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 11.8865	Cost: 6.99s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 11.8675	Cost: 9.60s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 11.9160	Cost: 6.54s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 11.6373	Cost: 11.17s
Train Epoch: 55 	Average Loss: 12.1297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7476

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 14.7766	Cost: 27.56s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 11.7344	Cost: 6.50s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 11.9786	Cost: 12.62s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 11.5478	Cost: 6.11s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 11.4720	Cost: 13.08s
Train Epoch: 56 	Average Loss: 12.0236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9109

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 14.4740	Cost: 30.40s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 11.8723	Cost: 15.62s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 11.8387	Cost: 9.59s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 11.5051	Cost: 8.74s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 11.3997	Cost: 6.24s
Train Epoch: 57 	Average Loss: 11.9712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0125

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 14.3443	Cost: 29.36s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 11.5526	Cost: 11.13s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 11.6365	Cost: 15.41s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 11.5639	Cost: 13.77s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 11.6089	Cost: 6.02s
Train Epoch: 58 	Average Loss: 11.9141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9831

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 14.6454	Cost: 30.50s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 11.5783	Cost: 11.27s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 11.4894	Cost: 15.72s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 11.6666	Cost: 11.85s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 11.6572	Cost: 7.69s
Train Epoch: 59 	Average Loss: 11.9332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9759

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 14.7051	Cost: 27.89s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 11.5912	Cost: 6.37s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 11.7346	Cost: 15.56s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 11.7786	Cost: 15.50s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 11.6554	Cost: 9.55s
Train Epoch: 60 	Average Loss: 11.9121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0534

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 14.3767	Cost: 27.94s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 11.2594	Cost: 6.68s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 11.6634	Cost: 16.35s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 11.9625	Cost: 15.67s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 11.3877	Cost: 14.67s
Train Epoch: 61 	Average Loss: 11.9289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9360

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 14.3751	Cost: 36.32s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 11.3036	Cost: 6.88s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 11.2131	Cost: 14.73s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 11.6630	Cost: 16.03s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 11.1859	Cost: 9.56s
Train Epoch: 62 	Average Loss: 11.7525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9307

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 14.3672	Cost: 38.10s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 11.3496	Cost: 6.15s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 11.4639	Cost: 10.63s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 11.5874	Cost: 14.23s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 11.2440	Cost: 14.83s
Train Epoch: 63 	Average Loss: 11.8297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8857

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 14.4936	Cost: 32.87s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 11.4986	Cost: 6.76s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 11.7432	Cost: 12.41s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 11.8218	Cost: 15.29s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 11.4920	Cost: 14.72s
Train Epoch: 64 	Average Loss: 11.8178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9870

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 14.3383	Cost: 35.93s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 11.5010	Cost: 6.23s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 11.5492	Cost: 15.42s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 11.7278	Cost: 15.59s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 11.3172	Cost: 9.03s
Train Epoch: 65 	Average Loss: 11.7589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9609

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 14.9679	Cost: 32.17s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 11.4851	Cost: 6.10s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 11.4690	Cost: 15.17s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 11.5828	Cost: 14.69s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 11.2245	Cost: 9.83s
Train Epoch: 66 	Average Loss: 11.7709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0659

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 14.7296	Cost: 32.15s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 11.4127	Cost: 6.10s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 11.1954	Cost: 15.43s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 11.8064	Cost: 14.69s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 11.1459	Cost: 9.54s
Train Epoch: 67 	Average Loss: 11.7331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1729

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 14.7436	Cost: 32.04s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 11.3752	Cost: 6.18s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 11.5877	Cost: 15.31s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 11.6315	Cost: 15.06s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 11.1369	Cost: 9.35s
Train Epoch: 68 	Average Loss: 11.7244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9056

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 14.5814	Cost: 30.32s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 10.7812	Cost: 6.07s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 11.4222	Cost: 15.97s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 11.5243	Cost: 14.61s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 11.1693	Cost: 9.61s
Train Epoch: 69 	Average Loss: 11.6948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0732

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 14.7167	Cost: 28.92s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 11.5044	Cost: 6.23s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 11.5296	Cost: 15.29s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 11.5552	Cost: 15.04s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 11.3187	Cost: 9.60s
Train Epoch: 70 	Average Loss: 11.7743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0128

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 14.8175	Cost: 31.00s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 11.4514	Cost: 7.62s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 11.1660	Cost: 15.50s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 11.7156	Cost: 15.12s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 11.1475	Cost: 8.03s
Train Epoch: 71 	Average Loss: 11.6319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0601

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 14.3821	Cost: 29.97s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 11.2544	Cost: 6.26s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 11.5180	Cost: 14.07s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 11.5576	Cost: 15.23s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 11.2811	Cost: 10.75s
Train Epoch: 72 	Average Loss: 11.5916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1729

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 14.5806	Cost: 28.35s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 11.5103	Cost: 6.40s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 11.3593	Cost: 14.14s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 11.2923	Cost: 13.90s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 11.3544	Cost: 12.01s
Train Epoch: 73 	Average Loss: 11.5776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1209

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 14.7123	Cost: 27.97s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 11.0090	Cost: 6.02s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 11.3606	Cost: 15.41s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 11.3440	Cost: 14.08s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 11.3655	Cost: 12.03s
Train Epoch: 74 	Average Loss: 11.5169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1231

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 14.7135	Cost: 30.40s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 11.0107	Cost: 6.45s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 11.1656	Cost: 15.60s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 11.3616	Cost: 13.07s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 11.2629	Cost: 11.73s
Train Epoch: 75 	Average Loss: 11.4788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0392

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 14.4768	Cost: 29.12s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 11.2174	Cost: 6.23s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 11.1468	Cost: 17.83s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 11.4811	Cost: 11.80s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 11.1476	Cost: 11.91s
Train Epoch: 76 	Average Loss: 11.5409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0681

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 14.7169	Cost: 33.03s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 11.2338	Cost: 6.91s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 10.9784	Cost: 14.87s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 11.4552	Cost: 15.46s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 10.9429	Cost: 12.95s
Train Epoch: 77 	Average Loss: 11.4809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1610

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 14.5538	Cost: 41.09s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 11.0085	Cost: 11.21s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 11.0068	Cost: 15.22s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 11.1792	Cost: 13.69s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 11.0648	Cost: 5.91s
Train Epoch: 78 	Average Loss: 11.4464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2325

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 14.6642	Cost: 36.24s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 10.7874	Cost: 6.20s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 11.2612	Cost: 15.19s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 11.7508	Cost: 15.00s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 11.5643	Cost: 9.66s
Train Epoch: 79 	Average Loss: 11.5165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3127

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 14.9329	Cost: 35.22s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 11.3256	Cost: 6.28s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 11.4428	Cost: 15.22s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 11.4657	Cost: 15.07s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 11.1326	Cost: 9.55s
Train Epoch: 80 	Average Loss: 11.5719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0860

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 14.5955	Cost: 32.49s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 10.8779	Cost: 6.96s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 11.4314	Cost: 15.20s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 11.1685	Cost: 15.01s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 10.8585	Cost: 8.67s
Train Epoch: 81 	Average Loss: 11.3944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2195

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 14.8138	Cost: 29.08s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 11.0967	Cost: 6.09s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 11.0722	Cost: 16.07s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 11.3350	Cost: 15.31s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 10.8024	Cost: 8.34s
Train Epoch: 82 	Average Loss: 11.3965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1399

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 14.7867	Cost: 29.76s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 10.5333	Cost: 6.17s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 10.8013	Cost: 15.35s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 10.9205	Cost: 14.78s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 10.9472	Cost: 9.85s
Train Epoch: 83 	Average Loss: 11.2686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2329

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 14.5420	Cost: 28.89s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 11.0051	Cost: 6.19s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 10.7906	Cost: 15.11s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 10.8746	Cost: 15.17s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 10.8071	Cost: 9.79s
Train Epoch: 84 	Average Loss: 11.2566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3344

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 14.8842	Cost: 30.55s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 10.8434	Cost: 6.43s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 11.0254	Cost: 15.26s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 11.3564	Cost: 15.75s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 10.8063	Cost: 9.06s
Train Epoch: 85 	Average Loss: 11.3058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2301

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 14.9232	Cost: 29.36s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 10.8483	Cost: 6.38s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 10.7719	Cost: 14.42s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 10.9914	Cost: 15.81s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 10.8564	Cost: 9.90s
Train Epoch: 86 	Average Loss: 11.2313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2257

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 14.6968	Cost: 29.42s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 10.9752	Cost: 6.15s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 10.8502	Cost: 14.44s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 11.0723	Cost: 14.01s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 10.6380	Cost: 12.02s
Train Epoch: 87 	Average Loss: 11.1937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2780

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 14.3736	Cost: 26.96s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 11.0586	Cost: 6.47s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 10.9511	Cost: 15.81s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 10.9425	Cost: 15.09s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 10.8937	Cost: 13.77s
Train Epoch: 88 	Average Loss: 11.1274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2601

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 14.8147	Cost: 32.12s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 10.6054	Cost: 6.34s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 10.4686	Cost: 14.33s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 10.6168	Cost: 15.21s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 10.7264	Cost: 14.74s
Train Epoch: 89 	Average Loss: 11.0855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4770

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 14.6360	Cost: 31.31s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 10.5812	Cost: 8.40s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 10.7438	Cost: 15.01s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 10.9640	Cost: 15.53s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 10.6574	Cost: 12.96s
Train Epoch: 90 	Average Loss: 11.0544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2987

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 14.7735	Cost: 34.87s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 10.8274	Cost: 6.22s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 10.7616	Cost: 10.89s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 10.8115	Cost: 13.43s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 10.4979	Cost: 14.64s
Train Epoch: 91 	Average Loss: 11.0703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3590

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 15.0380	Cost: 33.14s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 10.4211	Cost: 6.73s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 10.5132	Cost: 14.49s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 10.6159	Cost: 15.84s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 10.5094	Cost: 14.67s
Train Epoch: 92 	Average Loss: 11.0694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3501

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 14.4803	Cost: 29.32s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 10.4338	Cost: 6.33s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 10.5139	Cost: 15.35s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 11.0456	Cost: 14.91s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 10.6193	Cost: 13.70s
Train Epoch: 93 	Average Loss: 11.0693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4600

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 14.8014	Cost: 26.73s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 10.4048	Cost: 6.42s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 10.6704	Cost: 9.80s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 10.8508	Cost: 14.54s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 10.5991	Cost: 14.64s
Train Epoch: 94 	Average Loss: 11.0170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2665

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 14.7726	Cost: 24.49s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 10.7291	Cost: 6.27s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 10.7993	Cost: 8.47s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 10.6904	Cost: 9.32s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 10.4110	Cost: 15.04s
Train Epoch: 95 	Average Loss: 10.9972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3103

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 14.4432	Cost: 25.74s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 10.3898	Cost: 6.61s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 10.7167	Cost: 10.20s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 10.7135	Cost: 6.17s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 10.8350	Cost: 19.91s
Train Epoch: 96 	Average Loss: 11.0266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4550

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 14.7841	Cost: 25.10s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 10.7592	Cost: 6.47s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 10.7245	Cost: 10.02s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 10.7468	Cost: 6.13s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 10.4650	Cost: 19.16s
Train Epoch: 97 	Average Loss: 10.9810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4092

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 14.8654	Cost: 23.50s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 10.2677	Cost: 6.92s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 10.1621	Cost: 9.34s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 10.4490	Cost: 6.26s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 10.1513	Cost: 11.87s
Train Epoch: 98 	Average Loss: 10.9040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4223

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 14.8536	Cost: 27.72s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 10.7436	Cost: 8.92s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 10.5304	Cost: 8.78s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 10.7286	Cost: 8.45s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 10.2490	Cost: 6.41s
Train Epoch: 99 	Average Loss: 10.8730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4521

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 15.0213	Cost: 27.70s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 10.6946	Cost: 8.32s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 10.4495	Cost: 8.81s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 10.5679	Cost: 8.33s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 10.5424	Cost: 8.37s
Train Epoch: 100 	Average Loss: 10.8798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4249

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 14.9343	Cost: 27.83s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 10.4288	Cost: 6.45s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 10.8781	Cost: 10.08s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 10.9449	Cost: 6.30s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 10.3195	Cost: 12.49s
Train Epoch: 101 	Average Loss: 10.9362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4410

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 15.0280	Cost: 29.83s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 10.6547	Cost: 8.93s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 10.4856	Cost: 9.72s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 10.7302	Cost: 6.33s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 10.1222	Cost: 11.63s
Train Epoch: 102 	Average Loss: 10.8695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6820

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 15.1165	Cost: 27.67s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 10.4299	Cost: 6.14s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 10.2354	Cost: 12.20s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 10.4253	Cost: 6.19s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 10.1946	Cost: 6.10s
Train Epoch: 103 	Average Loss: 10.8645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4387

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 14.5449	Cost: 28.31s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 10.5140	Cost: 9.90s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 10.4733	Cost: 15.23s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 10.7989	Cost: 14.93s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 10.4075	Cost: 6.54s
Train Epoch: 104 	Average Loss: 10.8526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4351

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 14.8303	Cost: 27.12s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 10.5156	Cost: 6.81s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 10.4287	Cost: 13.20s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 10.7816	Cost: 15.14s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 10.4510	Cost: 11.99s
Train Epoch: 105 	Average Loss: 10.8488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4996

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 14.8696	Cost: 28.33s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 10.3181	Cost: 6.35s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 10.1529	Cost: 15.42s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 10.5022	Cost: 15.29s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 10.2582	Cost: 9.81s
Train Epoch: 106 	Average Loss: 10.7247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5649

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 14.6485	Cost: 26.31s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 10.4322	Cost: 6.86s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 10.1891	Cost: 17.62s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 10.4077	Cost: 10.90s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 10.2849	Cost: 11.95s
Train Epoch: 107 	Average Loss: 10.6817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5432

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 14.6351	Cost: 27.23s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 10.4909	Cost: 6.26s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 10.2444	Cost: 17.39s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 10.4577	Cost: 15.91s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 9.9433	Cost: 11.95s
Train Epoch: 108 	Average Loss: 10.5954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6210

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 15.2307	Cost: 32.95s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 10.2145	Cost: 7.04s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 10.1077	Cost: 15.39s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 10.4072	Cost: 15.13s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 10.2231	Cost: 9.48s
Train Epoch: 109 	Average Loss: 10.5711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3937

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 15.0453	Cost: 32.41s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 10.2325	Cost: 7.20s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 10.0118	Cost: 15.46s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 10.4794	Cost: 15.35s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 9.8526	Cost: 9.22s
Train Epoch: 110 	Average Loss: 10.5452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5536

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 15.1852	Cost: 43.58s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 10.3087	Cost: 15.40s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 10.1942	Cost: 14.97s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 10.3126	Cost: 6.92s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 9.9698	Cost: 5.88s
Train Epoch: 111 	Average Loss: 10.5416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6155

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 14.8892	Cost: 33.49s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 10.0536	Cost: 6.24s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 9.9644	Cost: 15.23s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 10.2706	Cost: 15.03s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 10.2239	Cost: 12.54s
Train Epoch: 112 	Average Loss: 10.5108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5030

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 14.8576	Cost: 34.40s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 10.4856	Cost: 6.29s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 9.8219	Cost: 10.44s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 10.2814	Cost: 14.40s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 9.5719	Cost: 14.95s
Train Epoch: 113 	Average Loss: 10.5239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7019

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 15.1741	Cost: 29.55s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 10.0506	Cost: 7.11s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 10.1214	Cost: 9.42s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 10.2984	Cost: 9.79s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 10.1350	Cost: 15.36s
Train Epoch: 114 	Average Loss: 10.4794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4843

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 15.2501	Cost: 28.98s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 10.0481	Cost: 7.28s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 9.6759	Cost: 10.72s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 10.2619	Cost: 7.27s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 9.9893	Cost: 17.79s
Train Epoch: 115 	Average Loss: 10.4393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6697

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 14.9395	Cost: 34.16s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 9.8939	Cost: 6.47s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 10.0479	Cost: 11.50s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 10.3572	Cost: 7.88s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 10.2337	Cost: 17.54s
Train Epoch: 116 	Average Loss: 10.4146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7395

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 15.3136	Cost: 30.74s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 10.2318	Cost: 8.53s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 9.9048	Cost: 10.21s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 10.1443	Cost: 6.42s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 9.9713	Cost: 18.66s
Train Epoch: 117 	Average Loss: 10.4405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6009

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 15.0955	Cost: 30.31s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 9.8594	Cost: 9.34s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 9.9504	Cost: 9.57s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 10.0651	Cost: 9.21s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 10.0695	Cost: 16.21s
Train Epoch: 118 	Average Loss: 10.4354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7741

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 15.4795	Cost: 40.19s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 10.2651	Cost: 6.24s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 9.6865	Cost: 12.32s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 10.2026	Cost: 13.41s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 9.5250	Cost: 15.42s
Train Epoch: 119 	Average Loss: 10.3572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6417

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 15.2754	Cost: 33.71s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 10.2684	Cost: 6.82s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 9.8380	Cost: 10.50s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 10.3477	Cost: 6.17s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 9.5789	Cost: 19.28s
Train Epoch: 120 	Average Loss: 10.4360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6796

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 15.2881	Cost: 30.15s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 10.0352	Cost: 6.42s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 9.8274	Cost: 12.45s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 9.9268	Cost: 11.45s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 9.7656	Cost: 14.80s
Train Epoch: 121 	Average Loss: 10.4180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6481

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 15.4501	Cost: 32.24s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 9.8149	Cost: 7.44s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 9.8988	Cost: 11.22s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 9.8643	Cost: 8.72s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 9.8830	Cost: 15.79s
Train Epoch: 122 	Average Loss: 10.2903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5536

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 15.0676	Cost: 31.72s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 9.8869	Cost: 8.47s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 9.6318	Cost: 9.57s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 9.8650	Cost: 10.52s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 9.7520	Cost: 14.95s
Train Epoch: 123 	Average Loss: 10.2380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7383

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 14.9427	Cost: 31.95s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 10.1644	Cost: 9.65s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 10.0416	Cost: 14.37s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 10.3243	Cost: 15.63s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 10.0752	Cost: 11.84s
Train Epoch: 124 	Average Loss: 10.5011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7525

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 15.1954	Cost: 48.37s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 10.1998	Cost: 15.08s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 10.1425	Cost: 11.91s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 10.3213	Cost: 6.07s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 9.6529	Cost: 6.04s
Train Epoch: 125 	Average Loss: 10.4885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6211

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 15.3073	Cost: 36.10s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 9.8459	Cost: 15.70s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 9.7702	Cost: 13.84s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 9.9573	Cost: 5.95s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 9.8254	Cost: 6.15s
Train Epoch: 126 	Average Loss: 10.2731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6400

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 15.1109	Cost: 37.91s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 9.7444	Cost: 15.52s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 9.7844	Cost: 14.94s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 9.7767	Cost: 7.06s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 9.5243	Cost: 6.22s
Train Epoch: 127 	Average Loss: 10.1848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6643

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 15.0587	Cost: 38.97s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 9.8217	Cost: 15.51s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 9.9222	Cost: 15.01s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 9.7904	Cost: 6.28s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 9.6003	Cost: 6.32s
Train Epoch: 128 	Average Loss: 10.1441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8139

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 14.9881	Cost: 33.88s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 9.5844	Cost: 9.54s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 9.5355	Cost: 15.57s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 9.6692	Cost: 14.76s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 9.4208	Cost: 6.12s
Train Epoch: 129 	Average Loss: 10.0929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8465

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 14.8796	Cost: 32.94s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 9.6176	Cost: 8.18s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 9.4633	Cost: 15.17s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 9.6690	Cost: 14.88s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 9.5963	Cost: 7.93s
Train Epoch: 130 	Average Loss: 10.0623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8507

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 14.9126	Cost: 33.22s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 9.5842	Cost: 7.02s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 9.7081	Cost: 15.12s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 9.4319	Cost: 14.78s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 9.6731	Cost: 8.89s
Train Epoch: 131 	Average Loss: 10.0194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9564

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 14.8518	Cost: 29.63s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 9.4360	Cost: 6.05s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 9.3990	Cost: 14.24s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 9.7386	Cost: 14.99s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 9.6006	Cost: 10.60s
Train Epoch: 132 	Average Loss: 10.0301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6658

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 15.2674	Cost: 29.33s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 9.4211	Cost: 6.21s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 9.4390	Cost: 15.34s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 9.6867	Cost: 15.52s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 9.4572	Cost: 9.16s
Train Epoch: 133 	Average Loss: 9.9698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9953

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 15.1128	Cost: 30.53s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 9.6056	Cost: 8.21s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 9.7028	Cost: 15.64s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 9.3971	Cost: 15.52s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 9.5661	Cost: 6.99s
Train Epoch: 134 	Average Loss: 10.0532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8073

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 15.0080	Cost: 30.44s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 9.4614	Cost: 6.10s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 9.6016	Cost: 13.41s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 9.4390	Cost: 15.73s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 9.1061	Cost: 11.04s
Train Epoch: 135 	Average Loss: 9.9265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9787

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 15.4458	Cost: 28.00s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 9.6653	Cost: 6.43s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 9.3912	Cost: 14.42s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 9.2593	Cost: 15.87s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 9.1308	Cost: 9.94s
Train Epoch: 136 	Average Loss: 9.9697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9445

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 15.5292	Cost: 27.52s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 9.1709	Cost: 6.03s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 9.4555	Cost: 17.90s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 9.2808	Cost: 11.90s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 9.3112	Cost: 10.17s
Train Epoch: 137 	Average Loss: 9.8696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8885

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 15.2054	Cost: 31.79s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 9.2431	Cost: 11.60s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 9.3729	Cost: 15.50s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 9.6295	Cost: 12.84s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 9.3248	Cost: 6.81s
Train Epoch: 138 	Average Loss: 9.8757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8279

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 15.6196	Cost: 43.14s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 9.5412	Cost: 15.57s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 9.5573	Cost: 12.96s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 9.2842	Cost: 7.85s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 8.9503	Cost: 5.93s
Train Epoch: 139 	Average Loss: 9.8193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9890

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 15.0682	Cost: 43.95s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 9.1715	Cost: 15.54s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 9.5464	Cost: 14.18s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 9.4357	Cost: 5.91s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 9.4115	Cost: 6.62s
Train Epoch: 140 	Average Loss: 9.8333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1286

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 15.3811	Cost: 26.03s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 9.4307	Cost: 11.25s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 9.4850	Cost: 15.94s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 9.5860	Cost: 12.67s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 9.8397	Cost: 5.82s
Train Epoch: 141 	Average Loss: 10.0705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9694

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 15.6428	Cost: 26.64s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 9.3485	Cost: 7.15s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 9.5173	Cost: 15.92s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 9.6102	Cost: 14.92s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 9.4271	Cost: 7.99s
Train Epoch: 142 	Average Loss: 9.9059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0655

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 15.1760	Cost: 30.74s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 9.4078	Cost: 9.84s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 9.1629	Cost: 15.48s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 9.3246	Cost: 14.84s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 9.0926	Cost: 5.99s
Train Epoch: 143 	Average Loss: 9.7600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0716

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 15.1934	Cost: 26.82s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 9.1333	Cost: 7.72s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 9.3780	Cost: 15.58s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 9.4279	Cost: 15.71s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 8.8488	Cost: 6.81s
Train Epoch: 144 	Average Loss: 9.6889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1370

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 15.3465	Cost: 26.44s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 8.7471	Cost: 7.13s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 9.3375	Cost: 16.40s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 9.1760	Cost: 14.24s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 8.8193	Cost: 9.94s
Train Epoch: 145 	Average Loss: 9.6467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9013

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 15.2322	Cost: 32.85s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 9.3071	Cost: 6.48s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 9.2491	Cost: 16.50s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 9.2903	Cost: 15.56s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 8.7442	Cost: 8.08s
Train Epoch: 146 	Average Loss: 9.6185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1011

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 15.3391	Cost: 33.51s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 8.8693	Cost: 7.10s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 9.1373	Cost: 15.34s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 9.1454	Cost: 14.98s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 8.7745	Cost: 9.53s
Train Epoch: 147 	Average Loss: 9.5513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0515

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 15.4753	Cost: 33.07s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 9.0098	Cost: 7.28s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 8.9438	Cost: 14.93s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 9.1068	Cost: 14.72s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 8.9351	Cost: 10.39s
Train Epoch: 148 	Average Loss: 9.5148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0823

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 15.7543	Cost: 35.09s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 8.9858	Cost: 6.30s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 8.9181	Cost: 15.28s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 8.8953	Cost: 15.58s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 8.5370	Cost: 8.95s
Train Epoch: 149 	Average Loss: 9.4690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0638

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 15.7576	Cost: 35.81s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 9.0951	Cost: 6.37s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 9.1677	Cost: 15.27s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 9.1979	Cost: 15.68s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 9.0783	Cost: 8.88s
Train Epoch: 150 	Average Loss: 9.6028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3093

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 15.8201	Cost: 33.80s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 9.0724	Cost: 6.18s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 8.9055	Cost: 14.49s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 9.0851	Cost: 15.34s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 8.7147	Cost: 10.12s
Train Epoch: 151 	Average Loss: 9.5510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0908

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 15.0820	Cost: 34.44s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 9.0711	Cost: 6.14s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 8.9651	Cost: 12.38s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 8.9731	Cost: 15.50s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 8.9059	Cost: 14.40s
Train Epoch: 152 	Average Loss: 9.4421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1048

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 15.6009	Cost: 26.83s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 9.1249	Cost: 6.46s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 8.8634	Cost: 9.95s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 8.8383	Cost: 12.58s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 8.7101	Cost: 15.58s
Train Epoch: 153 	Average Loss: 9.3766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1441

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 15.2896	Cost: 25.00s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 8.7201	Cost: 6.45s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 9.0563	Cost: 10.25s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 8.7961	Cost: 8.79s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 8.4089	Cost: 18.29s
Train Epoch: 154 	Average Loss: 9.3502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1360

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 15.1975	Cost: 25.21s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 9.1155	Cost: 6.48s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 9.0372	Cost: 9.76s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 8.7358	Cost: 6.55s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 8.5370	Cost: 19.47s
Train Epoch: 155 	Average Loss: 9.4136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2107

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 15.4439	Cost: 24.93s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 8.8383	Cost: 6.51s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 9.0462	Cost: 10.01s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 9.0197	Cost: 6.19s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 8.6921	Cost: 20.89s
Train Epoch: 156 	Average Loss: 9.3162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2092

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 15.3381	Cost: 24.30s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 8.7804	Cost: 6.54s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 8.5654	Cost: 9.97s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 8.9337	Cost: 6.19s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 8.9991	Cost: 12.29s
Train Epoch: 157 	Average Loss: 9.3381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1853

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 15.4968	Cost: 28.25s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 8.7397	Cost: 8.79s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 8.8193	Cost: 8.75s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 9.1798	Cost: 8.36s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 8.3626	Cost: 5.74s
Train Epoch: 158 	Average Loss: 9.3093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1867

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 15.5094	Cost: 26.86s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 9.0316	Cost: 7.85s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 8.8839	Cost: 8.74s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 8.8152	Cost: 8.29s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 8.7795	Cost: 8.33s
Train Epoch: 159 	Average Loss: 9.3977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1798

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 15.3874	Cost: 31.60s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 8.7230	Cost: 6.52s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 8.8414	Cost: 10.66s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 8.7118	Cost: 6.10s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 8.6802	Cost: 13.19s
Train Epoch: 160 	Average Loss: 9.3319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3091

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 15.5394	Cost: 27.25s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 9.2235	Cost: 6.54s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 9.2447	Cost: 13.01s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 9.4410	Cost: 6.06s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 9.1246	Cost: 11.96s
Train Epoch: 161 	Average Loss: 9.7565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0663

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 15.4792	Cost: 29.96s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 9.1083	Cost: 15.18s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 9.0908	Cost: 12.75s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 8.9683	Cost: 7.92s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 8.5940	Cost: 6.12s
Train Epoch: 162 	Average Loss: 9.5315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2256

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 15.4144	Cost: 29.89s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 8.6309	Cost: 6.30s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 8.7056	Cost: 16.45s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 8.8366	Cost: 11.98s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 8.6314	Cost: 11.93s
Train Epoch: 163 	Average Loss: 9.3288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1632

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 15.3966	Cost: 28.07s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 8.7034	Cost: 6.44s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 8.6317	Cost: 16.78s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 8.6689	Cost: 15.68s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 8.4081	Cost: 11.88s
Train Epoch: 164 	Average Loss: 9.1576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2780

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 15.5460	Cost: 36.44s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 8.6431	Cost: 6.30s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 8.8831	Cost: 16.13s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 8.8112	Cost: 15.06s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 8.3015	Cost: 11.47s
Train Epoch: 165 	Average Loss: 9.1540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4198

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 15.6603	Cost: 44.33s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 8.5028	Cost: 12.12s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 8.6692	Cost: 15.08s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 8.6957	Cost: 12.66s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 8.0495	Cost: 6.33s
Train Epoch: 166 	Average Loss: 9.0618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2580

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 15.8556	Cost: 31.50s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 8.4381	Cost: 12.46s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 8.4708	Cost: 15.67s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 8.4590	Cost: 11.81s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 8.2034	Cost: 5.91s
Train Epoch: 167 	Average Loss: 8.9700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4251

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 15.7612	Cost: 32.59s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 8.2278	Cost: 15.23s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 8.4440	Cost: 15.55s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 8.6771	Cost: 9.08s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 8.2382	Cost: 5.88s
Train Epoch: 168 	Average Loss: 8.9942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3976

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 15.5107	Cost: 29.53s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 8.7171	Cost: 10.99s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 8.3224	Cost: 15.26s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 8.6136	Cost: 13.69s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 8.2790	Cost: 6.03s
Train Epoch: 169 	Average Loss: 9.0127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2955

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 15.3547	Cost: 31.93s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 8.6040	Cost: 10.38s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 8.2265	Cost: 15.00s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 8.6717	Cost: 14.93s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 8.3514	Cost: 6.08s
Train Epoch: 170 	Average Loss: 8.9542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3115

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 15.7163	Cost: 29.87s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 8.4904	Cost: 8.12s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 8.4291	Cost: 15.35s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 8.4195	Cost: 15.21s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 8.1019	Cost: 7.63s
Train Epoch: 171 	Average Loss: 8.9044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3174

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 15.7578	Cost: 28.46s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 8.1301	Cost: 6.23s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 8.4573	Cost: 16.56s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 8.6660	Cost: 11.60s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 8.3031	Cost: 7.95s
Train Epoch: 172 	Average Loss: 8.9090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3202

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 15.3763	Cost: 24.48s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 8.4161	Cost: 6.32s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 8.3226	Cost: 12.30s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 8.4728	Cost: 7.21s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 8.2761	Cost: 20.84s
Train Epoch: 173 	Average Loss: 8.8579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2868

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 15.2800	Cost: 25.50s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 8.4420	Cost: 6.64s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 8.4872	Cost: 9.25s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 8.3769	Cost: 7.84s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 7.9153	Cost: 16.83s
Train Epoch: 174 	Average Loss: 8.8870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5684

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 15.8411	Cost: 27.99s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 8.1635	Cost: 6.37s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 8.5492	Cost: 10.39s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 8.3772	Cost: 7.78s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 8.0675	Cost: 16.47s
Train Epoch: 175 	Average Loss: 8.8764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5264

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 15.8973	Cost: 25.99s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 8.0867	Cost: 6.26s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 8.1293	Cost: 9.28s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 8.3305	Cost: 12.41s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 7.9681	Cost: 15.01s
Train Epoch: 176 	Average Loss: 8.8306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4563

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 15.5588	Cost: 25.89s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 8.4055	Cost: 6.54s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 8.4801	Cost: 10.06s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 8.7221	Cost: 10.24s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 8.1557	Cost: 15.24s
Train Epoch: 177 	Average Loss: 8.9339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3672

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 15.7856	Cost: 24.81s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 8.3925	Cost: 6.65s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 8.3766	Cost: 9.93s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 8.2902	Cost: 6.49s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 8.5119	Cost: 19.32s
Train Epoch: 178 	Average Loss: 8.8856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5614

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 15.8762	Cost: 28.65s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 8.3851	Cost: 6.37s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 8.1426	Cost: 14.32s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 8.3194	Cost: 14.26s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 8.0715	Cost: 14.96s
Train Epoch: 179 	Average Loss: 8.8673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4543

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 15.9582	Cost: 25.99s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 8.2275	Cost: 6.45s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 8.1118	Cost: 10.76s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 8.4801	Cost: 14.15s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 8.1034	Cost: 14.76s
Train Epoch: 180 	Average Loss: 8.7523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4131

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 15.7315	Cost: 24.46s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 7.9344	Cost: 6.53s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 8.0886	Cost: 8.77s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 7.9659	Cost: 10.00s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 8.0289	Cost: 14.36s
Train Epoch: 181 	Average Loss: 8.6491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6192

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 15.6594	Cost: 23.73s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 7.9973	Cost: 6.58s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 7.7736	Cost: 9.81s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 8.3115	Cost: 6.20s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 7.8922	Cost: 19.58s
Train Epoch: 182 	Average Loss: 8.6599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5985

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 15.6093	Cost: 25.33s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 8.1019	Cost: 6.49s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 8.1288	Cost: 10.12s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 8.2136	Cost: 6.29s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 7.8025	Cost: 19.31s
Train Epoch: 183 	Average Loss: 8.6199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5801

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 15.5941	Cost: 23.81s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 7.8497	Cost: 6.51s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 8.3262	Cost: 10.42s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 8.1739	Cost: 6.31s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 7.8540	Cost: 12.50s
Train Epoch: 184 	Average Loss: 8.6358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4829

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 15.7912	Cost: 26.79s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 8.1124	Cost: 8.76s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 8.2064	Cost: 8.76s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 7.8394	Cost: 7.63s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 7.9453	Cost: 5.94s
Train Epoch: 185 	Average Loss: 8.5610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6468

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 16.0142	Cost: 27.41s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 7.8582	Cost: 6.91s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 7.9438	Cost: 9.84s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 7.9200	Cost: 8.35s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 7.9048	Cost: 8.34s
Train Epoch: 186 	Average Loss: 8.4953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7171

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 15.7287	Cost: 27.78s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 7.9529	Cost: 6.24s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 7.9147	Cost: 9.70s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 7.8397	Cost: 6.00s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 7.8825	Cost: 12.33s
Train Epoch: 187 	Average Loss: 8.4880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6434

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 15.8985	Cost: 26.63s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 7.8352	Cost: 12.24s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 8.1455	Cost: 6.63s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 8.1372	Cost: 6.13s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 7.6176	Cost: 12.14s
Train Epoch: 188 	Average Loss: 8.4784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5578

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 15.5987	Cost: 29.05s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 8.0102	Cost: 13.14s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 7.8163	Cost: 12.20s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 7.9744	Cost: 6.23s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 7.6556	Cost: 6.23s
Train Epoch: 189 	Average Loss: 8.4830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7642

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 15.3570	Cost: 30.56s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 7.7529	Cost: 10.73s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 8.1150	Cost: 15.49s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 7.8674	Cost: 14.04s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 7.4588	Cost: 6.03s
Train Epoch: 190 	Average Loss: 8.4260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5973

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 15.8546	Cost: 29.55s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 8.0195	Cost: 10.26s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 7.7140	Cost: 16.18s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 7.8778	Cost: 14.03s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 7.5785	Cost: 6.09s
Train Epoch: 191 	Average Loss: 8.3394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6977

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 16.0254	Cost: 30.65s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 7.4445	Cost: 7.95s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 7.7335	Cost: 15.69s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 7.7276	Cost: 14.03s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 8.0592	Cost: 8.75s
Train Epoch: 192 	Average Loss: 8.3450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6677

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 15.9494	Cost: 36.17s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 7.6140	Cost: 8.33s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 7.9457	Cost: 15.35s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 7.9181	Cost: 14.92s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 7.5060	Cost: 7.70s
Train Epoch: 193 	Average Loss: 8.4767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8255

Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 16.1881	Cost: 47.95s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 7.8594	Cost: 10.08s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 8.0602	Cost: 15.01s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 7.8415	Cost: 14.70s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 7.7912	Cost: 5.98s
Train Epoch: 194 	Average Loss: 8.5090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6140

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 16.0907	Cost: 39.86s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 7.6948	Cost: 15.10s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 7.8561	Cost: 15.02s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 8.0311	Cost: 9.76s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 7.2988	Cost: 6.14s
Train Epoch: 195 	Average Loss: 8.3779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7512

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 15.8124	Cost: 31.72s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 7.3885	Cost: 14.09s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 7.5694	Cost: 15.04s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 8.0481	Cost: 10.88s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 7.4446	Cost: 5.86s
Train Epoch: 196 	Average Loss: 8.2530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5866

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 15.6596	Cost: 28.51s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 7.6827	Cost: 12.17s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 7.6587	Cost: 15.19s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 7.8104	Cost: 12.70s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 7.3168	Cost: 5.96s
Train Epoch: 197 	Average Loss: 8.3464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6179

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 15.7860	Cost: 29.97s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 7.5980	Cost: 10.29s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 7.5537	Cost: 15.45s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 7.8784	Cost: 14.36s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 7.2938	Cost: 6.17s
Train Epoch: 198 	Average Loss: 8.2432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7361

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 15.9343	Cost: 30.61s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 7.4822	Cost: 10.48s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 7.5852	Cost: 15.65s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 7.6369	Cost: 14.09s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 7.3170	Cost: 6.08s
Train Epoch: 199 	Average Loss: 8.1468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7468

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 15.9607	Cost: 28.42s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 7.5868	Cost: 6.38s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 7.6423	Cost: 13.14s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 7.6112	Cost: 15.16s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 7.0868	Cost: 11.94s
Train Epoch: 200 	Average Loss: 8.1309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7479

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 15.8590	Cost: 30.75s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 7.5271	Cost: 6.27s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 7.5082	Cost: 16.61s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 7.9574	Cost: 12.74s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 7.3511	Cost: 11.00s
Train Epoch: 201 	Average Loss: 8.1282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7985

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 16.1284	Cost: 31.54s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 7.6538	Cost: 6.18s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 7.4933	Cost: 16.93s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 7.8677	Cost: 12.94s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 7.2866	Cost: 11.83s
Train Epoch: 202 	Average Loss: 8.0959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8494

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 15.9759	Cost: 34.19s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 7.7527	Cost: 6.54s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 7.2474	Cost: 15.42s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 7.4904	Cost: 15.63s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 7.1685	Cost: 8.96s
Train Epoch: 203 	Average Loss: 8.1230
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0060

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 16.0802	Cost: 35.18s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 7.5262	Cost: 6.29s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 7.1870	Cost: 10.73s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 7.4101	Cost: 8.21s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 7.4570	Cost: 17.78s
Train Epoch: 204 	Average Loss: 8.0222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8481

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 15.9233	Cost: 35.98s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 7.7709	Cost: 6.42s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 7.4103	Cost: 16.25s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 7.6756	Cost: 15.68s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 7.3933	Cost: 12.74s
Train Epoch: 205 	Average Loss: 8.1301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8656

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 16.0692	Cost: 33.22s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 7.6495	Cost: 6.28s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 7.5831	Cost: 15.61s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 7.5529	Cost: 15.09s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 7.2348	Cost: 9.75s
Train Epoch: 206 	Average Loss: 8.0111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1229

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 16.0995	Cost: 33.15s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 7.4970	Cost: 6.10s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 7.0756	Cost: 16.08s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 7.5572	Cost: 14.78s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 7.0292	Cost: 9.16s
Train Epoch: 207 	Average Loss: 7.9529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8654

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 16.0790	Cost: 32.15s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 7.2150	Cost: 6.10s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 7.2104	Cost: 15.26s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 7.6854	Cost: 15.05s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 7.0201	Cost: 10.62s
Train Epoch: 208 	Average Loss: 7.8984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8051

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 16.0021	Cost: 30.48s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 7.0403	Cost: 6.53s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 7.2169	Cost: 13.60s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 7.0271	Cost: 15.44s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 6.9936	Cost: 10.87s
Train Epoch: 209 	Average Loss: 7.7775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9599

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 15.9585	Cost: 28.72s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 6.8891	Cost: 6.21s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 7.2901	Cost: 15.44s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 7.2329	Cost: 15.30s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 6.7139	Cost: 9.50s
Train Epoch: 210 	Average Loss: 7.7962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9737

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 16.2000	Cost: 29.20s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 6.7486	Cost: 6.12s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 6.9186	Cost: 16.04s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 7.3583	Cost: 14.91s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 6.9633	Cost: 9.25s
Train Epoch: 211 	Average Loss: 7.7411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0052

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 15.8824	Cost: 30.67s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 7.2730	Cost: 6.07s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 7.4379	Cost: 15.39s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 7.1988	Cost: 15.26s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 6.8675	Cost: 9.50s
Train Epoch: 212 	Average Loss: 7.8404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9939

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 15.8538	Cost: 33.94s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 6.7992	Cost: 6.19s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 6.5086	Cost: 13.18s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 7.0480	Cost: 15.13s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 7.3933	Cost: 11.96s
Train Epoch: 213 	Average Loss: 7.6977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0208

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 16.0449	Cost: 26.18s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 7.0353	Cost: 6.41s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 7.1090	Cost: 14.82s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 6.9807	Cost: 14.75s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 6.7269	Cost: 11.95s
Train Epoch: 214 	Average Loss: 7.6649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0296

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 15.8246	Cost: 25.31s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 6.9838	Cost: 6.52s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 7.1117	Cost: 14.05s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 7.0123	Cost: 15.88s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 6.6074	Cost: 14.89s
Train Epoch: 215 	Average Loss: 7.6237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0526

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 16.1974	Cost: 29.09s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 6.9454	Cost: 6.67s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 7.2633	Cost: 16.40s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 6.7223	Cost: 15.32s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 6.5725	Cost: 13.66s
Train Epoch: 216 	Average Loss: 7.6345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0199

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 16.0578	Cost: 47.36s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 7.0181	Cost: 11.25s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 6.7777	Cost: 15.16s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 7.0195	Cost: 13.48s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 6.6294	Cost: 6.16s
Train Epoch: 217 	Average Loss: 7.5483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9758

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 16.2452	Cost: 34.28s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 6.7531	Cost: 6.19s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 6.9100	Cost: 16.04s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 7.1049	Cost: 14.99s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 6.7274	Cost: 8.89s
Train Epoch: 218 	Average Loss: 7.5597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2127

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 16.2550	Cost: 34.50s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 6.6835	Cost: 6.15s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 6.7409	Cost: 12.53s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 6.9955	Cost: 14.92s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 6.5475	Cost: 14.66s
Train Epoch: 219 	Average Loss: 7.5677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0687

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 16.3498	Cost: 29.19s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 6.6657	Cost: 6.53s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 7.2818	Cost: 10.94s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 6.9868	Cost: 15.69s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 6.6990	Cost: 15.61s
Train Epoch: 220 	Average Loss: 7.5402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9400

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 16.0036	Cost: 29.96s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 6.7518	Cost: 6.17s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 6.6176	Cost: 15.81s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 6.7546	Cost: 15.26s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 6.7393	Cost: 9.32s
Train Epoch: 221 	Average Loss: 7.4534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0736

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 16.0222	Cost: 28.25s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 6.8586	Cost: 6.16s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 6.8952	Cost: 15.43s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 7.0502	Cost: 15.12s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 6.3215	Cost: 11.03s
Train Epoch: 222 	Average Loss: 7.4094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1051

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 16.3655	Cost: 30.56s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 6.8999	Cost: 6.47s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 6.4001	Cost: 14.30s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 7.0092	Cost: 15.24s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 6.6640	Cost: 10.79s
Train Epoch: 223 	Average Loss: 7.4249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0857

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 16.2965	Cost: 28.06s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 6.4608	Cost: 6.37s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 6.8201	Cost: 12.72s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 6.8812	Cost: 15.14s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 6.7151	Cost: 13.03s
Train Epoch: 224 	Average Loss: 7.4118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0931

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 16.1253	Cost: 27.11s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 6.9952	Cost: 6.04s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 6.8332	Cost: 13.56s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 7.1111	Cost: 15.20s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 6.4920	Cost: 11.96s
Train Epoch: 225 	Average Loss: 7.4897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0416

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 15.7349	Cost: 26.36s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 6.4180	Cost: 6.48s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 6.8216	Cost: 10.28s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 7.0579	Cost: 15.78s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 6.3223	Cost: 15.29s
Train Epoch: 226 	Average Loss: 7.3218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1294

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 16.1458	Cost: 26.46s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 6.2659	Cost: 6.82s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 6.6757	Cost: 15.00s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 6.6590	Cost: 15.68s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 6.3177	Cost: 14.88s
Train Epoch: 227 	Average Loss: 7.2659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1843

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 16.3202	Cost: 35.88s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 6.7133	Cost: 6.34s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 6.5318	Cost: 16.54s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 6.6010	Cost: 15.56s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 6.3123	Cost: 9.88s
Train Epoch: 228 	Average Loss: 7.2365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2068

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 16.1496	Cost: 35.12s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 6.3763	Cost: 6.44s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 6.6312	Cost: 16.01s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 6.7242	Cost: 15.63s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 6.2958	Cost: 12.90s
Train Epoch: 229 	Average Loss: 7.2153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3027

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 16.1527	Cost: 47.21s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 6.4858	Cost: 15.40s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 6.5248	Cost: 15.67s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 6.7919	Cost: 7.10s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 6.2024	Cost: 6.56s
Train Epoch: 230 	Average Loss: 7.2077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1680

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 15.9695	Cost: 32.86s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 6.7308	Cost: 14.86s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 6.4162	Cost: 15.07s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 6.4189	Cost: 9.89s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 6.1662	Cost: 6.16s
Train Epoch: 231 	Average Loss: 7.1811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2665

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 16.4128	Cost: 32.61s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 6.2950	Cost: 13.34s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 6.4673	Cost: 15.77s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 6.5765	Cost: 10.87s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 6.1329	Cost: 6.00s
Train Epoch: 232 	Average Loss: 7.1273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2518

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 16.2916	Cost: 28.70s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 6.1290	Cost: 12.16s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 6.4962	Cost: 15.24s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 6.5797	Cost: 12.53s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 6.0684	Cost: 6.06s
Train Epoch: 233 	Average Loss: 7.1553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1623

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 16.9943	Cost: 28.38s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 6.2406	Cost: 15.09s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 6.6732	Cost: 15.38s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 6.4394	Cost: 9.33s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 6.2654	Cost: 6.21s
Train Epoch: 234 	Average Loss: 7.2024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2312

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 16.6347	Cost: 26.89s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 6.4853	Cost: 6.14s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 6.3661	Cost: 14.98s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 6.2428	Cost: 14.97s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 6.4165	Cost: 9.93s
Train Epoch: 235 	Average Loss: 7.1008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1540

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 16.4685	Cost: 28.03s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 6.4518	Cost: 6.34s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 6.4656	Cost: 15.90s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 6.6126	Cost: 14.38s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 6.0149	Cost: 13.62s
Train Epoch: 236 	Average Loss: 7.1610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3191

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 16.5434	Cost: 28.16s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 6.3958	Cost: 6.18s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 6.4392	Cost: 14.95s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 6.7168	Cost: 14.87s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 6.4153	Cost: 13.05s
Train Epoch: 237 	Average Loss: 7.0946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0935

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 16.2186	Cost: 28.47s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 5.8302	Cost: 6.35s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 6.0003	Cost: 13.27s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 6.3901	Cost: 15.19s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 5.6966	Cost: 11.87s
Train Epoch: 238 	Average Loss: 6.8984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2888

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 16.3834	Cost: 28.92s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 6.1811	Cost: 6.28s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 6.5330	Cost: 14.47s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 6.3425	Cost: 14.12s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 6.0137	Cost: 11.98s
Train Epoch: 239 	Average Loss: 6.9374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3887

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 16.1497	Cost: 29.99s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 6.1365	Cost: 6.20s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 6.2657	Cost: 17.95s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 6.1489	Cost: 12.04s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 5.9907	Cost: 11.92s
Train Epoch: 240 	Average Loss: 6.8648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3378

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 16.4773	Cost: 35.57s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 6.0860	Cost: 6.25s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 6.2590	Cost: 16.33s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 6.3955	Cost: 14.81s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 6.1048	Cost: 8.71s
Train Epoch: 241 	Average Loss: 6.9016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3867

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 16.6281	Cost: 34.20s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 6.5620	Cost: 7.66s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 6.1805	Cost: 15.47s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 6.2356	Cost: 15.03s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 6.2261	Cost: 8.36s
Train Epoch: 242 	Average Loss: 7.0308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4042

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 16.3598	Cost: 32.69s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 6.1395	Cost: 6.21s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 5.9725	Cost: 11.85s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 6.2114	Cost: 12.46s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 5.7371	Cost: 15.45s
Train Epoch: 243 	Average Loss: 6.8360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5204

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 16.6258	Cost: 40.10s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 6.2705	Cost: 6.18s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 5.9797	Cost: 11.69s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 6.1700	Cost: 14.12s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 5.7355	Cost: 14.19s
Train Epoch: 244 	Average Loss: 6.7807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2137

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 16.2564	Cost: 30.55s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 5.8810	Cost: 6.72s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 5.9442	Cost: 11.68s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 6.2469	Cost: 15.02s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 5.6487	Cost: 14.99s
Train Epoch: 245 	Average Loss: 6.7813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5135

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 16.5248	Cost: 29.76s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 6.4919	Cost: 6.58s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 6.3741	Cost: 9.26s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 6.1453	Cost: 14.28s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 5.8966	Cost: 15.83s
Train Epoch: 246 	Average Loss: 6.8179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4567

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 16.6551	Cost: 29.39s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 6.2499	Cost: 6.64s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 5.8440	Cost: 9.25s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 5.9734	Cost: 12.40s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 5.7875	Cost: 15.64s
Train Epoch: 247 	Average Loss: 6.7323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4111

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 16.3572	Cost: 25.46s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 6.0827	Cost: 6.47s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 6.2033	Cost: 10.17s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 6.0851	Cost: 12.36s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 5.7002	Cost: 15.19s
Train Epoch: 248 	Average Loss: 6.7455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4257

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 16.2293	Cost: 24.84s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 5.9380	Cost: 6.58s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 5.9904	Cost: 10.01s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 6.0538	Cost: 6.20s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 5.5727	Cost: 19.68s
Train Epoch: 249 	Average Loss: 6.6776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3950

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 16.6054	Cost: 23.74s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 5.9513	Cost: 6.64s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 5.8214	Cost: 9.81s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 5.8235	Cost: 6.27s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 5.7737	Cost: 12.09s
Train Epoch: 250 	Average Loss: 6.6448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5854

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 16.1437	Cost: 28.02s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 5.6682	Cost: 8.78s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 6.0148	Cost: 8.72s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 5.8120	Cost: 6.22s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 5.9040	Cost: 6.16s
Train Epoch: 251 	Average Loss: 6.6119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5807

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 16.4307	Cost: 26.47s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 5.7051	Cost: 7.61s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 5.9172	Cost: 8.78s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 5.6620	Cost: 8.34s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 5.4929	Cost: 8.28s
Train Epoch: 252 	Average Loss: 6.5455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3892

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 16.8146	Cost: 26.88s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 5.6608	Cost: 6.14s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 5.8686	Cost: 9.27s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 5.8768	Cost: 6.07s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 5.6625	Cost: 11.46s
Train Epoch: 253 	Average Loss: 6.5607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5315

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 16.5938	Cost: 30.08s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 5.5728	Cost: 6.36s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 5.6796	Cost: 12.11s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 5.9620	Cost: 6.13s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 5.2653	Cost: 11.00s
Train Epoch: 254 	Average Loss: 6.5145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6483

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 16.6139	Cost: 29.45s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 5.9580	Cost: 16.16s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 6.1665	Cost: 8.45s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 5.8888	Cost: 11.98s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 5.8763	Cost: 6.08s
Train Epoch: 255 	Average Loss: 6.7573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5251

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 16.1830	Cost: 26.07s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 5.7932	Cost: 6.74s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 6.0454	Cost: 17.18s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 5.7846	Cost: 12.82s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 5.4096	Cost: 11.95s
Train Epoch: 256 	Average Loss: 6.5955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6850

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 16.5347	Cost: 36.35s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 5.6004	Cost: 8.33s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 5.8469	Cost: 15.41s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 5.8138	Cost: 14.99s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 5.3722	Cost: 7.57s
Train Epoch: 257 	Average Loss: 6.4527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6408

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 16.6423	Cost: 31.96s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 5.6831	Cost: 6.38s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 5.6745	Cost: 16.24s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 5.8688	Cost: 14.82s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 5.5718	Cost: 8.95s
Train Epoch: 258 	Average Loss: 6.4020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6665

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 16.7787	Cost: 42.49s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 5.4876	Cost: 6.23s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 5.6143	Cost: 16.00s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 5.7820	Cost: 14.76s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 5.3825	Cost: 8.93s
Train Epoch: 259 	Average Loss: 6.3689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5695

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 16.6977	Cost: 41.03s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 5.3922	Cost: 12.11s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 5.4733	Cost: 15.03s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 5.6124	Cost: 12.81s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 5.3726	Cost: 5.91s
Train Epoch: 260 	Average Loss: 6.3992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6997

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 16.3153	Cost: 39.22s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 5.4120	Cost: 15.12s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 5.7028	Cost: 15.15s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 5.7512	Cost: 8.83s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 5.4415	Cost: 6.68s
Train Epoch: 261 	Average Loss: 6.3121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5633

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 16.2187	Cost: 31.29s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 5.3809	Cost: 15.32s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 5.4527	Cost: 15.42s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 5.5267	Cost: 8.24s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 4.8479	Cost: 5.93s
Train Epoch: 262 	Average Loss: 6.2679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5440

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 16.4467	Cost: 30.69s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 5.3253	Cost: 15.87s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 5.3744	Cost: 14.83s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 5.6455	Cost: 5.89s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 5.2257	Cost: 5.90s
Train Epoch: 263 	Average Loss: 6.2692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6040

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 16.5755	Cost: 30.21s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 5.4051	Cost: 14.22s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 5.4318	Cost: 15.55s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 5.4710	Cost: 10.02s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 5.2899	Cost: 5.97s
Train Epoch: 264 	Average Loss: 6.2433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6597

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 16.5195	Cost: 31.28s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 5.2385	Cost: 12.10s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 5.4994	Cost: 15.08s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 5.7196	Cost: 12.74s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 5.2919	Cost: 6.09s
Train Epoch: 265 	Average Loss: 6.1528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8646

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 16.7545	Cost: 30.54s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 5.2670	Cost: 6.16s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 5.1107	Cost: 15.16s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 5.6547	Cost: 15.42s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 5.1994	Cost: 9.55s
Train Epoch: 266 	Average Loss: 6.1810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7645

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 16.8215	Cost: 32.05s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 5.3904	Cost: 10.24s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 5.3699	Cost: 15.55s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 5.3274	Cost: 12.83s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 5.1037	Cost: 7.94s
Train Epoch: 267 	Average Loss: 6.2413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7618

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 17.0240	Cost: 31.74s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 5.3074	Cost: 6.48s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 5.2634	Cost: 15.49s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 5.4811	Cost: 13.84s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 5.2652	Cost: 10.71s
Train Epoch: 268 	Average Loss: 6.1681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7973

Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 16.6238	Cost: 34.37s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 5.0799	Cost: 7.08s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 5.1859	Cost: 9.83s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 5.5471	Cost: 9.29s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 4.9028	Cost: 16.80s
Train Epoch: 269 	Average Loss: 6.0958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8134

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 16.8538	Cost: 37.47s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 5.0551	Cost: 6.19s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 5.2794	Cost: 16.60s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 5.2088	Cost: 16.18s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 4.9930	Cost: 9.10s
Train Epoch: 270 	Average Loss: 6.0894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7061

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 16.7666	Cost: 42.09s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 4.9305	Cost: 15.79s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 5.3199	Cost: 14.98s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 5.4869	Cost: 6.83s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 5.2061	Cost: 6.20s
Train Epoch: 271 	Average Loss: 6.0458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8001

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 16.5974	Cost: 32.52s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 5.0732	Cost: 7.50s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 4.8433	Cost: 16.03s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 5.3192	Cost: 14.90s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 4.9800	Cost: 7.80s
Train Epoch: 272 	Average Loss: 5.9997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8031

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 16.8348	Cost: 34.52s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 5.1203	Cost: 9.38s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 5.2330	Cost: 16.05s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 5.3783	Cost: 14.80s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 4.9534	Cost: 6.20s
Train Epoch: 273 	Average Loss: 6.0327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7701

Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 16.3356	Cost: 34.49s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 4.9721	Cost: 9.37s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 5.1825	Cost: 15.35s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 5.1810	Cost: 14.54s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 4.7197	Cost: 6.88s
Train Epoch: 274 	Average Loss: 6.0021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8310

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 16.3846	Cost: 32.80s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 4.9489	Cost: 9.27s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 4.8531	Cost: 15.13s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 5.1606	Cost: 14.77s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 4.8468	Cost: 6.84s
Train Epoch: 275 	Average Loss: 5.9164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8602

Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 16.3929	Cost: 30.49s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 4.9813	Cost: 7.51s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 5.1095	Cost: 15.62s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 5.0948	Cost: 14.49s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 4.9908	Cost: 8.48s
Train Epoch: 276 	Average Loss: 5.8738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9050

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 16.7130	Cost: 30.00s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 4.9919	Cost: 6.09s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 5.1456	Cost: 15.27s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 5.2687	Cost: 15.30s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 4.9282	Cost: 9.38s
Train Epoch: 277 	Average Loss: 5.9540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0072

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 16.8071	Cost: 29.30s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 4.9279	Cost: 6.38s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 4.9108	Cost: 14.13s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 4.9923	Cost: 15.28s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 4.7239	Cost: 10.79s
Train Epoch: 278 	Average Loss: 5.8165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9507

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 16.4081	Cost: 30.71s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 5.0072	Cost: 6.17s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 4.9860	Cost: 13.34s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 5.0957	Cost: 15.62s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 4.7114	Cost: 11.18s
Train Epoch: 279 	Average Loss: 5.8319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8725

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 16.5321	Cost: 28.50s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 5.0768	Cost: 6.32s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 5.0073	Cost: 14.43s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 5.2028	Cost: 15.41s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 5.1302	Cost: 10.72s
Train Epoch: 280 	Average Loss: 5.8654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9585

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 16.7878	Cost: 25.04s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 4.8175	Cost: 6.13s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 4.6306	Cost: 15.98s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 5.0564	Cost: 14.76s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 4.7640	Cost: 11.95s
Train Epoch: 281 	Average Loss: 5.7799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0780

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 16.5555	Cost: 26.84s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 4.7460	Cost: 6.31s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 4.9124	Cost: 15.87s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 4.9423	Cost: 15.75s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 4.5944	Cost: 11.92s
Train Epoch: 282 	Average Loss: 5.7781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8092

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 17.4895	Cost: 26.37s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 4.8806	Cost: 7.17s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 4.9677	Cost: 17.04s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 5.3549	Cost: 15.89s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 4.4471	Cost: 10.79s
Train Epoch: 283 	Average Loss: 5.8092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0608

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 16.3204	Cost: 44.88s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 5.0109	Cost: 15.08s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 4.8332	Cost: 14.97s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 5.1224	Cost: 9.87s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 4.4139	Cost: 5.95s
Train Epoch: 284 	Average Loss: 5.7493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8214

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 16.8525	Cost: 36.91s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 4.7307	Cost: 6.22s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 4.9073	Cost: 15.57s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 4.9029	Cost: 15.08s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 4.7621	Cost: 9.30s
Train Epoch: 285 	Average Loss: 5.8027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9832

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 16.8958	Cost: 35.22s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 4.8681	Cost: 8.18s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 4.7366	Cost: 15.40s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 5.1018	Cost: 14.77s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 4.6618	Cost: 7.67s
Train Epoch: 286 	Average Loss: 5.7235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1223

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 16.3864	Cost: 31.58s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 4.8954	Cost: 7.01s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 4.6580	Cost: 15.23s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 4.9006	Cost: 14.82s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 4.7443	Cost: 8.67s
Train Epoch: 287 	Average Loss: 5.7217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9939

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 16.8014	Cost: 26.01s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 5.1159	Cost: 6.21s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 4.6651	Cost: 14.79s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 4.7776	Cost: 15.78s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 4.8298	Cost: 11.67s
Train Epoch: 288 	Average Loss: 5.6818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1493

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 16.4230	Cost: 26.71s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 4.7467	Cost: 6.25s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 4.7086	Cost: 14.12s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 5.1017	Cost: 14.72s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 4.5069	Cost: 11.28s
Train Epoch: 289 	Average Loss: 5.6719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9650

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 16.5083	Cost: 26.31s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 4.8743	Cost: 6.25s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 4.5363	Cost: 12.73s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 4.8825	Cost: 14.57s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 4.6498	Cost: 14.11s
Train Epoch: 290 	Average Loss: 5.6410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0845

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 17.5023	Cost: 25.88s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 5.1737	Cost: 6.27s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 4.8012	Cost: 8.00s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 4.7710	Cost: 15.09s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 4.3621	Cost: 14.82s
Train Epoch: 291 	Average Loss: 5.6891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0986

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 16.4057	Cost: 28.02s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 4.7822	Cost: 6.52s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 4.5772	Cost: 11.88s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 4.8293	Cost: 15.10s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 4.4522	Cost: 15.17s
Train Epoch: 292 	Average Loss: 5.6123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1361

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 17.0389	Cost: 24.72s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 4.8004	Cost: 6.60s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 4.5148	Cost: 8.93s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 4.8732	Cost: 13.31s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 4.5631	Cost: 14.79s
Train Epoch: 293 	Average Loss: 5.5264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0715

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 16.9638	Cost: 25.71s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 4.5772	Cost: 6.55s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 4.7266	Cost: 10.40s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 4.9901	Cost: 12.31s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 4.6170	Cost: 14.74s
Train Epoch: 294 	Average Loss: 5.6282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9392

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 16.6289	Cost: 23.04s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 4.5172	Cost: 6.56s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 4.5936	Cost: 9.00s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 4.5610	Cost: 6.32s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 4.4706	Cost: 17.60s
Train Epoch: 295 	Average Loss: 5.5565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1826

Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 16.4771	Cost: 23.83s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 4.8383	Cost: 6.49s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 4.3885	Cost: 10.27s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 5.0747	Cost: 6.22s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 4.2351	Cost: 14.56s
Train Epoch: 296 	Average Loss: 5.5426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1874

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 16.5341	Cost: 26.81s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 4.7666	Cost: 8.73s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 4.7238	Cost: 8.74s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 4.8442	Cost: 6.62s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 4.3038	Cost: 6.45s
Train Epoch: 297 	Average Loss: 5.4672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0158

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 16.8207	Cost: 27.39s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 4.7133	Cost: 8.55s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 4.3946	Cost: 8.70s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 4.6699	Cost: 8.34s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 4.4453	Cost: 8.28s
Train Epoch: 298 	Average Loss: 5.5307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1394

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 16.7216	Cost: 26.98s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 4.5827	Cost: 6.18s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 4.5668	Cost: 10.16s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 4.6344	Cost: 5.92s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 4.4258	Cost: 13.03s
Train Epoch: 299 	Average Loss: 5.4361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9778

Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 17.0113	Cost: 32.98s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 4.3924	Cost: 6.29s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 4.3224	Cost: 9.15s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 4.7820	Cost: 6.10s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 4.0982	Cost: 11.56s
Train Epoch: 300 	Average Loss: 5.3525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1917

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 16.9966	Cost: 27.83s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 4.2040	Cost: 6.60s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 4.3362	Cost: 12.66s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 4.5330	Cost: 6.08s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 4.0408	Cost: 13.52s
Train Epoch: 301 	Average Loss: 5.3519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1570

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 16.4560	Cost: 31.01s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 4.6636	Cost: 15.26s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 4.1826	Cost: 13.78s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 4.5302	Cost: 6.16s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 4.2878	Cost: 6.03s
Train Epoch: 302 	Average Loss: 5.3357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0942

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 17.1763	Cost: 30.97s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 4.5806	Cost: 15.75s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 4.1070	Cost: 14.34s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 4.5245	Cost: 8.94s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 4.2278	Cost: 6.00s
Train Epoch: 303 	Average Loss: 5.2661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1025

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 16.8058	Cost: 31.28s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 4.3806	Cost: 14.09s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 4.2705	Cost: 14.09s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 4.5840	Cost: 12.05s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 4.0883	Cost: 6.05s
Train Epoch: 304 	Average Loss: 5.2567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0799

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 16.8983	Cost: 32.17s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 4.4590	Cost: 7.34s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 4.3971	Cost: 15.75s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 4.7799	Cost: 14.06s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 3.9396	Cost: 9.48s
Train Epoch: 305 	Average Loss: 5.2665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1286

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 16.9866	Cost: 43.76s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 4.4509	Cost: 6.50s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 4.3106	Cost: 15.65s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 4.6779	Cost: 14.79s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 4.0930	Cost: 8.95s
Train Epoch: 306 	Average Loss: 5.2946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1478

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 16.9385	Cost: 34.71s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 3.9800	Cost: 6.23s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 4.5439	Cost: 16.45s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 4.3940	Cost: 15.75s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 3.9591	Cost: 12.90s
Train Epoch: 307 	Average Loss: 5.1674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1028

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 16.9442	Cost: 43.10s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 4.3749	Cost: 15.39s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 3.9293	Cost: 15.33s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 4.2467	Cost: 6.27s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 3.6859	Cost: 6.65s
Train Epoch: 308 	Average Loss: 5.1212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1611

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 16.9650	Cost: 40.88s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 4.3718	Cost: 14.69s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 3.9281	Cost: 12.07s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 4.3665	Cost: 6.13s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 4.0553	Cost: 6.46s
Train Epoch: 309 	Average Loss: 5.1229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1159

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 16.9778	Cost: 31.81s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 4.1094	Cost: 15.76s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 4.1158	Cost: 12.32s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 4.0573	Cost: 6.81s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 4.0508	Cost: 5.93s
Train Epoch: 310 	Average Loss: 5.0827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1305

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 16.9190	Cost: 31.91s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 4.4198	Cost: 15.86s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 4.0173	Cost: 14.68s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 4.4663	Cost: 6.03s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 4.0432	Cost: 6.04s
Train Epoch: 311 	Average Loss: 5.0670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1910

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 16.9931	Cost: 31.84s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 3.9528	Cost: 15.81s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 4.1631	Cost: 12.00s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 3.9947	Cost: 6.19s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 4.0004	Cost: 6.10s
Train Epoch: 312 	Average Loss: 5.0077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1840

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 17.1144	Cost: 31.74s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 4.0070	Cost: 15.25s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 3.8751	Cost: 12.96s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 4.3711	Cost: 6.02s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 3.9785	Cost: 5.79s
Train Epoch: 313 	Average Loss: 4.9414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3569

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 17.0917	Cost: 37.38s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 4.0713	Cost: 12.95s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 4.0713	Cost: 12.11s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 4.2151	Cost: 6.05s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 4.0133	Cost: 6.00s
Train Epoch: 314 	Average Loss: 4.9787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2670

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 17.0357	Cost: 32.40s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 3.8685	Cost: 14.94s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 3.9749	Cost: 15.36s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 4.3806	Cost: 7.14s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 3.6431	Cost: 5.95s
Train Epoch: 315 	Average Loss: 4.8876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2575

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 17.1671	Cost: 28.93s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 3.9370	Cost: 14.07s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 3.8931	Cost: 15.06s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 4.0627	Cost: 10.77s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 3.6172	Cost: 5.89s
Train Epoch: 316 	Average Loss: 4.9286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2355

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 16.5849	Cost: 30.63s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 4.0254	Cost: 15.23s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 3.9316	Cost: 15.29s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 4.2931	Cost: 9.35s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 3.6579	Cost: 6.21s
Train Epoch: 317 	Average Loss: 4.8950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2623

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 17.2313	Cost: 32.83s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 3.8416	Cost: 10.42s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 3.7113	Cost: 15.78s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 4.0159	Cost: 14.18s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 3.8260	Cost: 6.06s
Train Epoch: 318 	Average Loss: 4.8537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2812

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 17.0829	Cost: 29.00s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 3.9484	Cost: 6.42s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 3.6908	Cost: 15.37s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 4.2137	Cost: 15.50s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 3.5231	Cost: 8.95s
Train Epoch: 319 	Average Loss: 4.8649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2848

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 17.2640	Cost: 30.99s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 4.2591	Cost: 10.41s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 3.8676	Cost: 16.09s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 4.4272	Cost: 14.01s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 3.5495	Cost: 6.06s
Train Epoch: 320 	Average Loss: 4.8843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3002

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 17.1884	Cost: 30.37s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 3.9071	Cost: 6.31s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 4.0090	Cost: 17.41s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 4.0758	Cost: 10.84s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 3.3775	Cost: 11.85s
Train Epoch: 321 	Average Loss: 4.8048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4065

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 16.6693	Cost: 32.64s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 3.8321	Cost: 7.10s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 3.7007	Cost: 14.89s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 4.1740	Cost: 15.75s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 3.6046	Cost: 9.97s
Train Epoch: 322 	Average Loss: 4.7712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3690

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 17.2440	Cost: 34.79s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 3.6205	Cost: 6.29s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 3.6144	Cost: 15.55s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 3.6365	Cost: 14.98s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 3.6513	Cost: 9.94s
Train Epoch: 323 	Average Loss: 4.6781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4549

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 16.7490	Cost: 37.09s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 3.5182	Cost: 6.20s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 3.6882	Cost: 8.97s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 3.7101	Cost: 13.94s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 3.5151	Cost: 14.94s
Train Epoch: 324 	Average Loss: 4.6754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3658

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 17.0483	Cost: 30.64s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 3.8005	Cost: 6.84s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 3.9789	Cost: 10.12s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 3.8758	Cost: 13.03s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 3.5084	Cost: 15.04s
Train Epoch: 325 	Average Loss: 4.6632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4377

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 17.3011	Cost: 29.82s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 3.8463	Cost: 6.62s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 3.7309	Cost: 10.35s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 3.9880	Cost: 6.26s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 3.6944	Cost: 18.44s
Train Epoch: 326 	Average Loss: 4.6527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3091

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 16.8780	Cost: 26.57s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 3.8022	Cost: 7.28s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 3.4966	Cost: 10.54s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 3.8619	Cost: 6.27s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 3.4372	Cost: 19.23s
Train Epoch: 327 	Average Loss: 4.6387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4890

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 17.1992	Cost: 26.13s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 3.6550	Cost: 6.57s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 3.4325	Cost: 11.59s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 3.7734	Cost: 6.39s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 3.6298	Cost: 17.12s
Train Epoch: 328 	Average Loss: 4.5573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4923

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 17.0053	Cost: 26.74s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 3.3964	Cost: 8.20s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 3.7948	Cost: 11.15s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 3.9321	Cost: 6.30s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 2.8276	Cost: 14.50s
Train Epoch: 329 	Average Loss: 4.5744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4663

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 16.8663	Cost: 25.68s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 3.8246	Cost: 7.47s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 3.6187	Cost: 15.09s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 3.7463	Cost: 6.29s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 3.2360	Cost: 11.09s
Train Epoch: 330 	Average Loss: 4.5549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4004

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 16.8746	Cost: 24.77s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 3.5011	Cost: 9.29s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 3.3817	Cost: 9.64s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 3.9193	Cost: 6.23s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 3.3532	Cost: 12.31s
Train Epoch: 331 	Average Loss: 4.5242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3590

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 16.8066	Cost: 27.50s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 3.3051	Cost: 9.25s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 3.5441	Cost: 9.73s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 3.6943	Cost: 7.98s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 3.0947	Cost: 7.63s
Train Epoch: 332 	Average Loss: 4.4911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3376

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 17.2943	Cost: 29.88s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 3.4013	Cost: 6.45s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 3.4872	Cost: 12.23s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 3.7283	Cost: 8.87s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 3.2850	Cost: 8.71s
Train Epoch: 333 	Average Loss: 4.4698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5616

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 16.8616	Cost: 28.28s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 3.4956	Cost: 6.81s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 3.4678	Cost: 9.19s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 3.4662	Cost: 8.35s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 3.3096	Cost: 8.51s
Train Epoch: 334 	Average Loss: 4.4600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3975

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 17.1319	Cost: 28.30s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 3.6123	Cost: 6.41s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 3.7523	Cost: 12.19s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 3.4922	Cost: 6.19s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 3.2572	Cost: 11.24s
Train Epoch: 335 	Average Loss: 4.4119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5431

Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 17.0158	Cost: 26.39s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 3.4921	Cost: 6.38s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 3.5984	Cost: 12.33s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 3.4827	Cost: 6.23s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 2.9357	Cost: 9.58s
Train Epoch: 336 	Average Loss: 4.4156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5497

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 17.2163	Cost: 29.95s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 3.2694	Cost: 15.75s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 3.4963	Cost: 15.03s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 3.5630	Cost: 6.13s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 3.2124	Cost: 6.14s
Train Epoch: 337 	Average Loss: 4.4237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3747

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 17.5219	Cost: 29.36s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 3.4253	Cost: 9.53s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 3.4172	Cost: 15.70s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 3.5752	Cost: 15.14s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 3.0973	Cost: 6.04s
Train Epoch: 338 	Average Loss: 4.3762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4980

Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 17.2499	Cost: 30.35s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 3.6684	Cost: 9.69s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 3.3123	Cost: 15.89s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 3.5281	Cost: 14.11s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 2.9620	Cost: 6.89s
Train Epoch: 339 	Average Loss: 4.3214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4367

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 16.9719	Cost: 29.94s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 3.4311	Cost: 6.34s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 3.5059	Cost: 17.46s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 3.6630	Cost: 10.93s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 3.0885	Cost: 11.93s
Train Epoch: 340 	Average Loss: 4.3706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5529

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 17.2994	Cost: 33.23s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 3.5912	Cost: 6.31s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 2.9865	Cost: 15.47s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 3.2817	Cost: 15.06s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 3.0366	Cost: 9.49s
Train Epoch: 341 	Average Loss: 4.3006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5154

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 16.8216	Cost: 40.32s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 3.2567	Cost: 7.62s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 2.9830	Cost: 15.54s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 3.5962	Cost: 14.70s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 3.0741	Cost: 8.05s
Train Epoch: 342 	Average Loss: 4.2962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5859

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 16.9744	Cost: 35.86s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 3.4294	Cost: 8.47s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 3.2675	Cost: 15.36s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 3.2931	Cost: 14.46s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 3.2666	Cost: 7.54s
Train Epoch: 343 	Average Loss: 4.2987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4777

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 17.3973	Cost: 29.22s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 3.2123	Cost: 6.12s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 3.0179	Cost: 15.68s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 3.6705	Cost: 14.91s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 2.8638	Cost: 10.53s
Train Epoch: 344 	Average Loss: 4.2712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4638

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 17.0943	Cost: 29.17s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 3.5543	Cost: 6.11s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 3.3662	Cost: 14.00s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 3.5664	Cost: 15.17s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 3.2048	Cost: 13.47s
Train Epoch: 345 	Average Loss: 4.3042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5678

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 17.1592	Cost: 25.39s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 3.1173	Cost: 6.70s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 3.2691	Cost: 8.46s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 3.3616	Cost: 13.56s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 2.9121	Cost: 15.18s
Train Epoch: 346 	Average Loss: 4.2408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6099

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 17.2816	Cost: 24.42s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 3.1645	Cost: 7.30s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 3.2833	Cost: 9.03s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 3.3346	Cost: 6.15s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 3.0300	Cost: 19.93s
Train Epoch: 347 	Average Loss: 4.2119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3993

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 17.2384	Cost: 24.38s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 2.9281	Cost: 6.55s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 3.1403	Cost: 9.96s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 3.4168	Cost: 6.25s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 3.2639	Cost: 18.60s
Train Epoch: 348 	Average Loss: 4.1798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4265

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 17.0950	Cost: 24.81s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 3.3599	Cost: 6.56s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 3.2110	Cost: 10.55s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 3.4800	Cost: 6.24s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 2.8181	Cost: 15.76s
Train Epoch: 349 	Average Loss: 4.1701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5498

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 17.1612	Cost: 24.97s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 2.8907	Cost: 8.72s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 3.1834	Cost: 7.34s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 3.3272	Cost: 6.19s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 2.9402	Cost: 6.34s
Train Epoch: 350 	Average Loss: 4.1465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4663

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 17.4207	Cost: 25.94s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 2.9590	Cost: 7.02s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 2.9593	Cost: 9.14s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 3.2028	Cost: 8.30s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 2.7557	Cost: 8.38s
Train Epoch: 351 	Average Loss: 4.1615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5707

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 17.1496	Cost: 30.78s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 3.1110	Cost: 6.49s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 3.3664	Cost: 11.14s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 3.3331	Cost: 6.11s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 2.8161	Cost: 11.92s
Train Epoch: 352 	Average Loss: 4.1491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3821

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 17.3243	Cost: 29.21s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 2.7529	Cost: 12.34s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 2.8639	Cost: 6.30s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 3.5445	Cost: 6.12s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 2.7951	Cost: 12.33s
Train Epoch: 353 	Average Loss: 4.0915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7756

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 17.2815	Cost: 30.12s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 3.0635	Cost: 11.19s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 3.0033	Cost: 12.34s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 3.3699	Cost: 6.15s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 2.7518	Cost: 6.07s
Train Epoch: 354 	Average Loss: 4.1023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5377

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 16.9180	Cost: 29.73s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 3.1407	Cost: 12.97s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 2.9747	Cost: 15.45s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 3.0998	Cost: 11.83s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 2.8316	Cost: 5.98s
Train Epoch: 355 	Average Loss: 4.0693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6480

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 17.2743	Cost: 28.94s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 3.2208	Cost: 10.20s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 2.7940	Cost: 15.41s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 2.8781	Cost: 14.73s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 2.8784	Cost: 6.03s
Train Epoch: 356 	Average Loss: 4.0437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5070

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 17.1521	Cost: 30.95s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 2.8953	Cost: 11.33s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 3.2429	Cost: 16.17s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 3.0269	Cost: 12.96s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 2.4336	Cost: 6.07s
Train Epoch: 357 	Average Loss: 4.0245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6127

Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 16.9008	Cost: 32.56s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 3.0799	Cost: 7.43s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 3.1764	Cost: 16.06s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 3.2975	Cost: 13.97s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 2.6400	Cost: 9.30s
Train Epoch: 358 	Average Loss: 4.0828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6138

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 16.8602	Cost: 35.98s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 3.2784	Cost: 6.32s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 3.0060	Cost: 11.27s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 3.2437	Cost: 14.10s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 2.9890	Cost: 14.90s
Train Epoch: 359 	Average Loss: 4.0341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6981

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 17.1411	Cost: 46.27s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 2.8712	Cost: 15.36s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 3.1237	Cost: 14.58s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 2.7856	Cost: 9.55s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 2.6755	Cost: 6.04s
Train Epoch: 360 	Average Loss: 4.0631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5598

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 17.4914	Cost: 34.48s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 2.9955	Cost: 15.11s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 2.8893	Cost: 15.18s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 3.2418	Cost: 9.62s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 2.8880	Cost: 6.30s
Train Epoch: 361 	Average Loss: 4.0344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6859

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 17.2270	Cost: 33.66s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 2.8166	Cost: 7.23s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 2.8568	Cost: 15.26s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 3.1974	Cost: 14.80s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 2.8145	Cost: 8.75s
Train Epoch: 362 	Average Loss: 3.9962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6662

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 17.3310	Cost: 28.52s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 2.8059	Cost: 6.06s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 2.9694	Cost: 14.98s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 2.9915	Cost: 14.90s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 2.8396	Cost: 9.79s
Train Epoch: 363 	Average Loss: 3.9885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4299

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 17.3309	Cost: 30.05s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 3.0575	Cost: 6.06s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 2.8533	Cost: 16.09s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 2.9574	Cost: 15.10s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 2.4872	Cost: 8.67s
Train Epoch: 364 	Average Loss: 3.9747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5761

Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 17.3256	Cost: 29.50s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 2.6282	Cost: 6.17s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 2.9858	Cost: 15.09s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 2.9197	Cost: 14.21s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 2.7679	Cost: 10.77s
Train Epoch: 365 	Average Loss: 3.9901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5507

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 17.5681	Cost: 28.45s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 3.1370	Cost: 6.20s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 2.9166	Cost: 15.26s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 2.8918	Cost: 15.16s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 2.5651	Cost: 9.97s
Train Epoch: 366 	Average Loss: 3.9724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5617

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 17.5280	Cost: 28.70s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 2.8539	Cost: 6.12s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 3.0613	Cost: 15.37s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 3.0567	Cost: 14.11s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 2.6338	Cost: 10.80s
Train Epoch: 367 	Average Loss: 3.9491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5334

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 17.5369	Cost: 28.97s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 2.9451	Cost: 6.01s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 2.9885	Cost: 13.39s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 3.1727	Cost: 14.89s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 2.5893	Cost: 12.03s
Train Epoch: 368 	Average Loss: 3.9527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6965

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 17.3911	Cost: 28.84s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 2.9537	Cost: 6.17s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 2.6929	Cost: 16.55s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 3.1822	Cost: 12.45s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 2.8828	Cost: 11.00s
Train Epoch: 369 	Average Loss: 4.0138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6602

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 16.5811	Cost: 27.72s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 3.0781	Cost: 6.44s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 2.5890	Cost: 14.37s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 2.7927	Cost: 15.05s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 2.3846	Cost: 14.83s
Train Epoch: 370 	Average Loss: 3.9061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6068

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 17.4944	Cost: 31.37s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 2.8227	Cost: 7.97s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 2.9378	Cost: 15.31s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 2.9876	Cost: 15.07s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 2.7325	Cost: 9.48s
Train Epoch: 371 	Average Loss: 3.9249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6612

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 17.6568	Cost: 45.11s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 2.6534	Cost: 12.77s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 2.8212	Cost: 11.93s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 2.9960	Cost: 5.95s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 2.4491	Cost: 5.86s
Train Epoch: 372 	Average Loss: 3.9328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4990

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 17.3694	Cost: 41.93s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 2.8557	Cost: 12.78s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 2.8349	Cost: 11.33s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 2.7612	Cost: 6.60s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 2.6855	Cost: 5.91s
Train Epoch: 373 	Average Loss: 3.9077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7593

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 17.4224	Cost: 44.74s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 2.7329	Cost: 12.27s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 2.8213	Cost: 15.21s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 3.1104	Cost: 12.51s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 2.4397	Cost: 6.22s
Train Epoch: 374 	Average Loss: 3.8928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6954

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 17.3024	Cost: 34.98s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 2.9859	Cost: 12.04s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 2.9956	Cost: 14.93s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 2.8920	Cost: 12.92s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 2.5223	Cost: 6.10s
Train Epoch: 375 	Average Loss: 3.8519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6391

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 17.0311	Cost: 31.93s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 2.8517	Cost: 7.30s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 2.7513	Cost: 15.72s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 2.8809	Cost: 14.65s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 2.7675	Cost: 8.15s
Train Epoch: 376 	Average Loss: 3.8915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6326

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 17.3720	Cost: 30.71s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 2.8206	Cost: 6.24s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 2.7758	Cost: 15.62s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 2.9898	Cost: 14.86s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 2.8052	Cost: 9.38s
Train Epoch: 377 	Average Loss: 3.9300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6299

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 16.9929	Cost: 29.78s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 2.7588	Cost: 6.44s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 2.5658	Cost: 15.35s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 3.1140	Cost: 15.88s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 2.5041	Cost: 8.81s
Train Epoch: 378 	Average Loss: 3.8299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7819

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 17.1949	Cost: 30.68s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 2.6558	Cost: 8.45s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 2.7903	Cost: 15.15s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 3.0460	Cost: 15.30s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 2.5607	Cost: 7.84s
Train Epoch: 379 	Average Loss: 3.8800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7007

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 17.5089	Cost: 29.41s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 2.6930	Cost: 6.42s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 2.7939	Cost: 15.29s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 2.7885	Cost: 14.15s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 2.5999	Cost: 10.82s
Train Epoch: 380 	Average Loss: 3.8338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7529

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 17.7200	Cost: 27.37s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 2.9351	Cost: 6.24s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 2.8386	Cost: 16.43s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 3.0155	Cost: 12.03s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 2.4071	Cost: 11.92s
Train Epoch: 381 	Average Loss: 3.9331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6046

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 16.9544	Cost: 28.01s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 2.7236	Cost: 6.37s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 2.8305	Cost: 16.61s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 2.8261	Cost: 14.94s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 2.6162	Cost: 11.85s
Train Epoch: 382 	Average Loss: 3.8499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4683

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 16.9947	Cost: 31.04s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 2.9914	Cost: 6.73s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 2.9093	Cost: 15.70s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 2.8408	Cost: 14.66s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 2.5037	Cost: 11.04s
Train Epoch: 383 	Average Loss: 3.8452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6730

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 17.5549	Cost: 33.99s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 2.7171	Cost: 6.49s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 2.6505	Cost: 16.04s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 2.8068	Cost: 15.58s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 2.6289	Cost: 9.34s
Train Epoch: 384 	Average Loss: 3.8792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5978

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 17.2275	Cost: 43.05s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 2.9534	Cost: 15.32s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 2.7981	Cost: 14.31s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 2.9198	Cost: 5.92s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 2.7715	Cost: 6.45s
Train Epoch: 385 	Average Loss: 3.8219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6982

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 17.7225	Cost: 35.75s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 2.8113	Cost: 15.36s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 2.9583	Cost: 15.09s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 3.0388	Cost: 8.66s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 2.4561	Cost: 6.11s
Train Epoch: 386 	Average Loss: 3.8854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5216

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 17.1301	Cost: 34.80s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 2.8186	Cost: 15.38s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 2.8004	Cost: 14.06s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 2.9759	Cost: 5.97s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 2.3329	Cost: 5.89s
Train Epoch: 387 	Average Loss: 3.8388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6323

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 17.2870	Cost: 30.88s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 2.6823	Cost: 15.45s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 2.8082	Cost: 8.85s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 2.9970	Cost: 9.39s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 2.7341	Cost: 5.98s
Train Epoch: 388 	Average Loss: 3.8910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7810

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 16.8751	Cost: 32.57s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 2.7280	Cost: 15.63s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 2.7883	Cost: 13.44s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 2.9834	Cost: 9.57s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 2.5813	Cost: 5.90s
Train Epoch: 389 	Average Loss: 3.8338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6846

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 17.5128	Cost: 28.06s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 2.5213	Cost: 10.32s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 2.7301	Cost: 15.43s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 3.0388	Cost: 14.12s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 2.7018	Cost: 5.97s
Train Epoch: 390 	Average Loss: 3.8628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6939

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 16.8853	Cost: 30.76s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 2.7647	Cost: 8.25s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 2.8685	Cost: 15.22s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 2.9696	Cost: 15.73s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 2.6423	Cost: 7.17s
Train Epoch: 391 	Average Loss: 3.8516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7352

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 17.1418	Cost: 30.91s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 2.8412	Cost: 7.30s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 2.7539	Cost: 15.31s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 3.1900	Cost: 15.83s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 2.6643	Cost: 7.97s
Train Epoch: 392 	Average Loss: 3.8593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5749

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 17.2312	Cost: 24.25s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 2.9259	Cost: 6.13s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 2.6267	Cost: 13.77s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 2.8607	Cost: 14.78s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 2.4570	Cost: 11.96s
Train Epoch: 393 	Average Loss: 3.8156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6022

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 17.2408	Cost: 27.75s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 2.6544	Cost: 6.28s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 2.5020	Cost: 15.45s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 2.8394	Cost: 13.88s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 2.3814	Cost: 11.93s
Train Epoch: 394 	Average Loss: 3.7920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7040

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 17.0692	Cost: 26.57s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 3.0004	Cost: 6.38s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 3.0002	Cost: 15.36s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 3.0086	Cost: 15.57s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 2.4148	Cost: 14.43s
Train Epoch: 395 	Average Loss: 3.8324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8352

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 17.0810	Cost: 34.01s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 2.8759	Cost: 6.26s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 2.8224	Cost: 16.24s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 3.2379	Cost: 15.47s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 2.4037	Cost: 11.18s
Train Epoch: 396 	Average Loss: 3.8311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5899

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 17.4299	Cost: 52.14s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 2.6613	Cost: 8.91s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 2.6873	Cost: 11.99s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 2.9264	Cost: 6.02s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 2.6237	Cost: 5.97s
Train Epoch: 397 	Average Loss: 3.8583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6935

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 16.9460	Cost: 36.99s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 3.0403	Cost: 15.84s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 2.9130	Cost: 10.39s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 2.7324	Cost: 8.62s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 2.4738	Cost: 5.93s
Train Epoch: 398 	Average Loss: 3.8395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7208

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 17.1899	Cost: 38.55s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 2.8267	Cost: 15.86s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 2.8838	Cost: 12.28s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 3.0092	Cost: 7.77s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 2.7201	Cost: 5.97s
Train Epoch: 399 	Average Loss: 3.8592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6728

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 17.3047	Cost: 42.02s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 2.5131	Cost: 13.92s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 2.6736	Cost: 14.39s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 2.6669	Cost: 11.76s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 2.4823	Cost: 6.61s
Train Epoch: 400 	Average Loss: 3.8052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6622

Stopping timer.
Training time (including validation): 236838.21762609482 seconds
Saving model
Transfer learning by starting with alpha=0.1!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.8726	Cost: 35.71s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.8254	Cost: 15.26s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 19.9970	Cost: 12.69s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 19.4489	Cost: 7.84s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 18.6977	Cost: 6.00s
Train Epoch: 1 	Average Loss: 20.8048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4351

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 18.6691	Cost: 29.17s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 18.4837	Cost: 6.36s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 18.0820	Cost: 13.13s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 17.8782	Cost: 15.10s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 17.4434	Cost: 11.81s
Train Epoch: 2 	Average Loss: 18.0307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1048

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 17.7020	Cost: 29.18s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 17.2043	Cost: 6.46s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 17.1674	Cost: 15.37s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 17.2061	Cost: 15.15s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 17.0903	Cost: 12.59s
Train Epoch: 3 	Average Loss: 17.1932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6680

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 17.1689	Cost: 26.70s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 16.9781	Cost: 6.56s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 16.9354	Cost: 11.67s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 16.8925	Cost: 10.34s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 16.6753	Cost: 15.19s
Train Epoch: 4 	Average Loss: 16.8120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4183

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 17.0454	Cost: 25.25s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 16.5395	Cost: 6.52s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 16.6035	Cost: 11.87s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 16.5146	Cost: 6.14s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 16.6741	Cost: 20.34s
Train Epoch: 5 	Average Loss: 16.5843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2428

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 17.0467	Cost: 22.98s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 16.3217	Cost: 6.45s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 16.2703	Cost: 11.27s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 16.2262	Cost: 6.24s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 16.4350	Cost: 15.31s
Train Epoch: 6 	Average Loss: 16.3968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1613

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 16.8132	Cost: 24.07s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 16.7221	Cost: 6.16s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 16.4977	Cost: 9.33s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 16.2891	Cost: 6.38s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 16.2663	Cost: 12.45s
Train Epoch: 7 	Average Loss: 16.3836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1512

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 16.7558	Cost: 27.15s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 16.1579	Cost: 7.56s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 16.2675	Cost: 8.80s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 16.3119	Cost: 8.66s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 16.3073	Cost: 8.57s
Train Epoch: 8 	Average Loss: 16.4147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1107

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 16.7083	Cost: 28.39s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 16.1252	Cost: 8.62s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 16.3195	Cost: 6.18s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 16.1568	Cost: 6.06s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 15.9952	Cost: 7.18s
Train Epoch: 9 	Average Loss: 16.1557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9606

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 16.7084	Cost: 33.53s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 15.9787	Cost: 11.06s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 16.0619	Cost: 6.41s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 16.1743	Cost: 11.86s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 16.0039	Cost: 6.00s
Train Epoch: 10 	Average Loss: 16.0346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9880

Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 16.4607	Cost: 38.97s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 16.0055	Cost: 6.42s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 15.8541	Cost: 15.45s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 16.0235	Cost: 14.98s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 16.0126	Cost: 10.94s
Train Epoch: 11 	Average Loss: 16.0208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0232

Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 16.7089	Cost: 32.21s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 15.6766	Cost: 6.50s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 15.8528	Cost: 11.76s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 15.8977	Cost: 13.13s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 15.9207	Cost: 15.38s
Train Epoch: 12 	Average Loss: 15.9175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9209

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 16.7389	Cost: 26.97s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 15.9428	Cost: 6.48s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 16.0484	Cost: 11.81s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 15.8782	Cost: 6.08s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 15.8722	Cost: 19.61s
Train Epoch: 13 	Average Loss: 15.9576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0248

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 16.6136	Cost: 25.47s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 15.7006	Cost: 6.36s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 16.0564	Cost: 9.11s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 15.8868	Cost: 6.30s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 15.8068	Cost: 11.02s
Train Epoch: 14 	Average Loss: 15.8704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0208

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 16.6685	Cost: 27.60s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 15.8299	Cost: 8.03s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 15.6817	Cost: 8.91s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 15.8684	Cost: 8.50s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 15.7592	Cost: 8.25s
Train Epoch: 15 	Average Loss: 15.8179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1895

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 16.7258	Cost: 30.37s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 16.4810	Cost: 6.62s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 16.2949	Cost: 8.11s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 16.3110	Cost: 6.37s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 16.0689	Cost: 9.11s
Train Epoch: 16 	Average Loss: 16.2147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9883

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 16.8394	Cost: 33.48s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 15.8311	Cost: 7.79s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 15.8293	Cost: 10.39s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 15.8668	Cost: 5.97s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 15.9268	Cost: 5.81s
Train Epoch: 17 	Average Loss: 15.8758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0415

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 16.5707	Cost: 37.13s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 15.6690	Cost: 6.38s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 15.7932	Cost: 14.71s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 15.5276	Cost: 15.51s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 15.8542	Cost: 13.90s
Train Epoch: 18 	Average Loss: 15.7341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0760

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 16.5952	Cost: 36.67s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 15.5591	Cost: 6.65s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 15.5625	Cost: 14.64s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 15.8513	Cost: 15.81s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 15.6799	Cost: 14.71s
Train Epoch: 19 	Average Loss: 15.6788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0938

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 16.4324	Cost: 28.42s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 15.5527	Cost: 6.57s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 15.6399	Cost: 11.47s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 15.3178	Cost: 12.22s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 15.5011	Cost: 14.94s
Train Epoch: 20 	Average Loss: 15.6138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9907

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 16.9109	Cost: 22.96s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 15.5457	Cost: 6.28s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 15.6009	Cost: 7.67s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 15.2747	Cost: 5.97s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 15.6918	Cost: 7.53s
Train Epoch: 21 	Average Loss: 15.5970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0850

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 16.6742	Cost: 27.88s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 15.4289	Cost: 6.16s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 15.6481	Cost: 8.59s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 15.2795	Cost: 6.23s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 15.3531	Cost: 6.00s
Train Epoch: 22 	Average Loss: 15.4633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2177

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 16.6959	Cost: 23.82s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 15.4482	Cost: 6.19s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 15.4550	Cost: 9.41s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 15.3329	Cost: 5.96s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 15.3099	Cost: 10.70s
Train Epoch: 23 	Average Loss: 15.4227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1393

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 16.5190	Cost: 23.33s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 15.1427	Cost: 6.01s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 15.2634	Cost: 8.55s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 15.2830	Cost: 6.22s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 15.3150	Cost: 12.33s
Train Epoch: 24 	Average Loss: 15.3600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2608

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 16.6243	Cost: 24.50s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 15.2304	Cost: 6.19s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 15.5405	Cost: 8.55s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 15.1865	Cost: 6.00s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 15.2439	Cost: 6.93s
Train Epoch: 25 	Average Loss: 15.3380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1831

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 16.4841	Cost: 24.03s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 14.9888	Cost: 6.17s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 15.4026	Cost: 8.71s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 15.0699	Cost: 5.95s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 15.0901	Cost: 6.28s
Train Epoch: 26 	Average Loss: 15.2733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2245

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 16.6767	Cost: 26.60s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 15.3184	Cost: 6.17s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 15.2216	Cost: 9.10s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 15.1247	Cost: 6.04s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 15.0398	Cost: 8.04s
Train Epoch: 27 	Average Loss: 15.2332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1879

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 17.0285	Cost: 43.64s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 15.1932	Cost: 12.40s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 15.0772	Cost: 14.87s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 15.0267	Cost: 12.73s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 15.2203	Cost: 5.88s
Train Epoch: 28 	Average Loss: 15.2577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2835

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 16.8551	Cost: 26.65s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 15.1912	Cost: 6.48s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 14.9417	Cost: 8.02s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 15.0970	Cost: 12.03s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 14.8308	Cost: 14.10s
Train Epoch: 29 	Average Loss: 15.1928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2421

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 16.7423	Cost: 26.83s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 15.0489	Cost: 6.38s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 15.0295	Cost: 10.46s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 14.9400	Cost: 6.15s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 14.8358	Cost: 14.59s
Train Epoch: 30 	Average Loss: 15.0920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3484

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 16.9540	Cost: 22.77s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 14.9289	Cost: 8.63s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 14.9456	Cost: 9.13s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 14.9572	Cost: 8.31s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 15.0066	Cost: 6.03s
Train Epoch: 31 	Average Loss: 15.0515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4152

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 16.8884	Cost: 23.71s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 14.9077	Cost: 6.08s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 15.0132	Cost: 7.03s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 14.9160	Cost: 6.86s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 14.9347	Cost: 8.79s
Train Epoch: 32 	Average Loss: 15.0411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4320

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 16.9921	Cost: 24.35s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 14.5409	Cost: 6.37s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 14.7616	Cost: 8.71s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 14.8830	Cost: 9.62s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 14.7338	Cost: 5.79s
Train Epoch: 33 	Average Loss: 14.9732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4844

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 16.8783	Cost: 27.65s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 14.8933	Cost: 6.08s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 14.8046	Cost: 13.78s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 14.7906	Cost: 14.86s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 14.9620	Cost: 14.45s
Train Epoch: 34 	Average Loss: 14.9317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4781

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 17.0578	Cost: 23.49s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 14.5518	Cost: 6.19s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 14.5575	Cost: 8.37s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 14.6500	Cost: 6.04s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 14.6494	Cost: 10.27s
Train Epoch: 35 	Average Loss: 14.8654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4684

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 17.2735	Cost: 26.30s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 14.6770	Cost: 8.58s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 14.5139	Cost: 8.79s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 14.4575	Cost: 8.54s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 14.6987	Cost: 6.14s
Train Epoch: 36 	Average Loss: 14.8248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5345

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 17.2682	Cost: 26.47s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 14.8308	Cost: 6.26s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 14.4467	Cost: 9.20s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 14.4518	Cost: 6.70s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 14.6374	Cost: 9.18s
Train Epoch: 37 	Average Loss: 14.7772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5813

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 17.1328	Cost: 29.18s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 14.5706	Cost: 6.11s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 14.3791	Cost: 11.99s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 14.3398	Cost: 6.02s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 14.5602	Cost: 5.74s
Train Epoch: 38 	Average Loss: 14.7403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6288

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 17.1811	Cost: 27.50s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 14.5695	Cost: 7.37s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 14.4612	Cost: 7.65s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 14.5440	Cost: 10.17s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 14.8189	Cost: 14.69s
Train Epoch: 39 	Average Loss: 14.7317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5759

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 17.0889	Cost: 21.72s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 14.6951	Cost: 6.45s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 14.8190	Cost: 17.10s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 14.4476	Cost: 6.40s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 14.7014	Cost: 16.54s
Train Epoch: 40 	Average Loss: 14.7269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5536

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 17.0173	Cost: 24.16s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 14.6187	Cost: 8.63s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 14.6088	Cost: 8.81s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 14.2540	Cost: 8.99s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 14.2783	Cost: 6.87s
Train Epoch: 41 	Average Loss: 14.6397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6931

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 17.0348	Cost: 23.42s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 14.5100	Cost: 5.98s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 14.4025	Cost: 7.62s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 14.3863	Cost: 7.77s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 14.1750	Cost: 9.98s
Train Epoch: 42 	Average Loss: 14.5930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6101

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 17.0514	Cost: 24.13s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 14.4821	Cost: 6.08s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 14.3350	Cost: 11.47s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 14.2095	Cost: 6.69s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 14.1659	Cost: 5.76s
Train Epoch: 43 	Average Loss: 14.5665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7293

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 17.2648	Cost: 25.37s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 14.5357	Cost: 6.04s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 14.4944	Cost: 12.63s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 14.4301	Cost: 14.93s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 14.2998	Cost: 13.76s
Train Epoch: 44 	Average Loss: 14.6329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7327

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 17.3579	Cost: 22.43s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 14.3726	Cost: 6.19s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 14.5223	Cost: 8.64s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 14.2597	Cost: 6.03s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 14.3648	Cost: 10.11s
Train Epoch: 45 	Average Loss: 14.5523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8222

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 17.1383	Cost: 27.91s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 14.4620	Cost: 8.61s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 14.5282	Cost: 8.77s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 13.9794	Cost: 8.52s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 14.1635	Cost: 7.26s
Train Epoch: 46 	Average Loss: 14.5170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6889

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 17.1392	Cost: 24.32s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 14.0665	Cost: 6.13s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 14.4078	Cost: 6.96s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 14.1326	Cost: 6.03s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 14.3631	Cost: 7.14s
Train Epoch: 47 	Average Loss: 14.4306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7417

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 17.1963	Cost: 33.83s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 14.2899	Cost: 6.23s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 14.3156	Cost: 12.16s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 14.1205	Cost: 6.01s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 14.3332	Cost: 5.97s
Train Epoch: 48 	Average Loss: 14.4630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8553

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 17.0504	Cost: 28.38s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 14.5390	Cost: 8.13s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 14.2395	Cost: 15.32s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 14.0279	Cost: 14.05s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 14.2545	Cost: 8.87s
Train Epoch: 49 	Average Loss: 14.4232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8590

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 16.9123	Cost: 24.87s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 14.2861	Cost: 8.52s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 14.1944	Cost: 10.02s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 14.1165	Cost: 6.13s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 14.1948	Cost: 10.62s
Train Epoch: 50 	Average Loss: 14.3527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9512

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 17.4775	Cost: 23.40s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 14.3813	Cost: 8.54s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 14.3796	Cost: 8.72s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 13.9297	Cost: 9.09s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 14.0815	Cost: 7.00s
Train Epoch: 51 	Average Loss: 14.4371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9202

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 17.2944	Cost: 23.51s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 14.1105	Cost: 6.03s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 14.1630	Cost: 8.32s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 13.9983	Cost: 6.87s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 14.2140	Cost: 12.68s
Train Epoch: 52 	Average Loss: 14.2918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8851

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 17.3099	Cost: 25.27s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 14.3008	Cost: 11.11s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 14.2084	Cost: 7.21s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 13.9281	Cost: 5.95s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 13.9663	Cost: 5.80s
Train Epoch: 53 	Average Loss: 14.2660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9126

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 17.2815	Cost: 27.20s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 13.9692	Cost: 15.07s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 14.1572	Cost: 13.15s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 13.7474	Cost: 9.69s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 13.9493	Cost: 5.74s
Train Epoch: 54 	Average Loss: 14.2787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9175

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 17.1645	Cost: 26.36s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 13.8250	Cost: 6.15s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 14.0009	Cost: 9.79s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 13.7026	Cost: 14.82s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 13.7884	Cost: 14.46s
Train Epoch: 55 	Average Loss: 14.1530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9260

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 17.6258	Cost: 22.76s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 13.9769	Cost: 6.29s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 14.2524	Cost: 9.32s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 13.7675	Cost: 6.00s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 13.7676	Cost: 13.23s
Train Epoch: 56 	Average Loss: 14.1567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0462

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 17.2353	Cost: 24.61s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 13.7761	Cost: 8.71s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 13.8426	Cost: 8.84s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 13.7856	Cost: 7.70s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 13.7783	Cost: 5.84s
Train Epoch: 57 	Average Loss: 14.1368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0132

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 17.4060	Cost: 24.78s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 14.0872	Cost: 6.03s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 13.9099	Cost: 9.31s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 13.7978	Cost: 8.45s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 13.7482	Cost: 8.24s
Train Epoch: 58 	Average Loss: 14.1007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0602

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 17.5265	Cost: 29.16s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 13.8674	Cost: 8.14s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 14.0054	Cost: 10.25s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 13.7066	Cost: 6.21s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 13.7305	Cost: 6.05s
Train Epoch: 59 	Average Loss: 14.0865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0468

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 17.5781	Cost: 28.85s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 13.8912	Cost: 6.17s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 13.7235	Cost: 7.11s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 13.5366	Cost: 11.30s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 13.7642	Cost: 14.60s
Train Epoch: 60 	Average Loss: 14.0429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1186

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 17.6350	Cost: 27.28s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 13.8693	Cost: 6.25s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 13.9260	Cost: 10.19s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 13.7832	Cost: 6.26s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 13.9999	Cost: 14.76s
Train Epoch: 61 	Average Loss: 14.1026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1050

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 17.4150	Cost: 24.13s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 13.8247	Cost: 9.05s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 13.8462	Cost: 7.74s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 13.6900	Cost: 6.37s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 13.6501	Cost: 6.16s
Train Epoch: 62 	Average Loss: 14.0505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9612

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 17.3775	Cost: 23.56s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 13.5712	Cost: 6.14s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 13.6638	Cost: 11.21s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 13.4979	Cost: 8.74s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 13.7076	Cost: 8.97s
Train Epoch: 63 	Average Loss: 13.9941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1713

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 17.6127	Cost: 25.47s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 13.9317	Cost: 9.11s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 13.8930	Cost: 6.20s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 13.6976	Cost: 6.15s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 13.6713	Cost: 8.46s
Train Epoch: 64 	Average Loss: 14.0072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1455

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 17.5194	Cost: 26.19s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 13.5726	Cost: 9.38s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 13.6985	Cost: 15.04s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 13.5856	Cost: 14.04s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 13.7885	Cost: 7.79s
Train Epoch: 65 	Average Loss: 13.9851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0832

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 17.5345	Cost: 25.40s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 13.5340	Cost: 6.19s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 13.7129	Cost: 8.64s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 13.4883	Cost: 6.01s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 13.6831	Cost: 16.15s
Train Epoch: 66 	Average Loss: 13.8781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1867

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 17.6416	Cost: 22.30s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 13.2070	Cost: 6.19s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 13.5674	Cost: 9.26s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 13.4291	Cost: 6.12s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 13.4528	Cost: 12.11s
Train Epoch: 67 	Average Loss: 13.8143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1172

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 17.9400	Cost: 24.35s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 13.4256	Cost: 6.02s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 13.4904	Cost: 8.66s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 13.2481	Cost: 8.53s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 13.4505	Cost: 8.40s
Train Epoch: 68 	Average Loss: 13.7530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2218

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 17.9416	Cost: 27.98s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 13.3769	Cost: 11.76s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 13.5982	Cost: 6.37s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 13.4399	Cost: 6.05s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 13.3005	Cost: 5.96s
Train Epoch: 69 	Average Loss: 13.7643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2129

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 17.7699	Cost: 28.77s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 13.3304	Cost: 15.94s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 13.6332	Cost: 11.12s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 13.2304	Cost: 11.92s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 13.4375	Cost: 5.90s
Train Epoch: 70 	Average Loss: 13.6997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4066

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 17.6148	Cost: 26.99s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 13.4744	Cost: 8.15s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 13.5453	Cost: 10.51s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 13.3930	Cost: 8.25s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 13.4006	Cost: 16.20s
Train Epoch: 71 	Average Loss: 13.6937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3195

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 17.9028	Cost: 23.73s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 13.2813	Cost: 6.26s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 13.2658	Cost: 9.02s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 13.1115	Cost: 7.31s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 13.4215	Cost: 8.29s
Train Epoch: 72 	Average Loss: 13.6061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2614

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 17.7405	Cost: 23.32s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 13.5348	Cost: 6.17s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 13.3630	Cost: 8.75s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 12.9714	Cost: 8.46s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 13.3973	Cost: 8.79s
Train Epoch: 73 	Average Loss: 13.6123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3220

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 17.6906	Cost: 23.45s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 13.4821	Cost: 6.94s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 13.2711	Cost: 11.27s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 12.8594	Cost: 5.82s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 13.0761	Cost: 5.82s
Train Epoch: 74 	Average Loss: 13.5737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4277

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 17.5131	Cost: 29.99s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 13.2111	Cost: 12.16s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 13.3325	Cost: 14.92s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 13.1517	Cost: 12.79s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 13.4130	Cost: 5.81s
Train Epoch: 75 	Average Loss: 13.5287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4598

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 17.9660	Cost: 26.55s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 13.3291	Cost: 6.09s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 13.3173	Cost: 7.91s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 13.0434	Cost: 14.51s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 13.0995	Cost: 14.62s
Train Epoch: 76 	Average Loss: 13.5178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4927

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 17.8833	Cost: 23.11s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 13.2390	Cost: 6.19s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 13.2277	Cost: 8.41s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 13.0593	Cost: 6.06s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 13.3519	Cost: 9.33s
Train Epoch: 77 	Average Loss: 13.5579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4640

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 18.0683	Cost: 25.02s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 13.1606	Cost: 7.78s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 13.2814	Cost: 8.56s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 12.9588	Cost: 8.39s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 13.3654	Cost: 8.33s
Train Epoch: 78 	Average Loss: 13.5128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3899

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 18.0640	Cost: 26.63s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 13.0638	Cost: 12.13s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 13.2024	Cost: 6.24s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 13.2123	Cost: 6.20s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 13.5255	Cost: 5.78s
Train Epoch: 79 	Average Loss: 13.5747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4866

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 18.0365	Cost: 24.99s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 13.1684	Cost: 14.70s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 13.4408	Cost: 14.94s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 13.1293	Cost: 8.88s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 13.4436	Cost: 5.99s
Train Epoch: 80 	Average Loss: 13.5152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4832

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 17.8161	Cost: 25.73s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 12.9822	Cost: 6.14s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 13.1625	Cost: 11.95s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 13.2148	Cost: 15.78s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 13.2002	Cost: 10.02s
Train Epoch: 81 	Average Loss: 13.4343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4495

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 17.9062	Cost: 23.33s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 13.0661	Cost: 6.62s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 13.2114	Cost: 7.89s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 13.1081	Cost: 6.24s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 13.1148	Cost: 11.31s
Train Epoch: 82 	Average Loss: 13.3826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5090

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 17.9377	Cost: 24.46s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 13.2056	Cost: 8.53s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 12.9795	Cost: 8.55s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 12.6523	Cost: 8.27s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 13.0207	Cost: 7.94s
Train Epoch: 83 	Average Loss: 13.3204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4984

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 18.1271	Cost: 25.13s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 12.8446	Cost: 6.00s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 13.1778	Cost: 8.88s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 12.5426	Cost: 7.26s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 13.0493	Cost: 8.29s
Train Epoch: 84 	Average Loss: 13.2070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4415

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 17.8226	Cost: 24.21s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 12.8603	Cost: 6.06s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 13.0554	Cost: 11.46s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 12.5554	Cost: 7.75s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 12.8286	Cost: 5.79s
Train Epoch: 85 	Average Loss: 13.1863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6350

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 18.1188	Cost: 26.62s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 12.8812	Cost: 6.12s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 12.8099	Cost: 12.18s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 12.5537	Cost: 14.83s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 12.8009	Cost: 11.10s
Train Epoch: 86 	Average Loss: 13.1129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6174

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 18.1523	Cost: 25.15s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 12.7512	Cost: 6.18s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 12.8663	Cost: 8.58s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 12.6066	Cost: 6.01s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 12.8091	Cost: 17.32s
Train Epoch: 87 	Average Loss: 13.2024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5918

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 18.0476	Cost: 28.99s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 12.7509	Cost: 6.30s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 12.9603	Cost: 8.98s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 12.9484	Cost: 6.15s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 12.8087	Cost: 9.82s
Train Epoch: 88 	Average Loss: 13.2708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6313

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 17.9989	Cost: 26.40s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 12.6963	Cost: 6.19s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 12.8129	Cost: 8.73s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 12.7078	Cost: 8.49s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 12.6658	Cost: 8.31s
Train Epoch: 89 	Average Loss: 13.1443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5095

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 18.2117	Cost: 23.90s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 12.7722	Cost: 11.43s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 12.6043	Cost: 7.11s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 12.4496	Cost: 6.12s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 12.4397	Cost: 6.00s
Train Epoch: 90 	Average Loss: 13.0050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5306

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 17.9745	Cost: 27.07s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 12.4304	Cost: 6.06s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 12.5980	Cost: 12.70s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 12.4272	Cost: 15.81s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 12.7514	Cost: 11.26s
Train Epoch: 91 	Average Loss: 12.9791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7456

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 18.0237	Cost: 26.23s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 12.4272	Cost: 6.22s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 12.5709	Cost: 13.19s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 12.3469	Cost: 15.14s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 12.4099	Cost: 10.38s
Train Epoch: 92 	Average Loss: 12.9745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7082

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 17.9669	Cost: 23.04s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 12.8096	Cost: 6.33s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 12.7608	Cost: 7.95s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 12.5055	Cost: 6.21s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 12.7742	Cost: 8.72s
Train Epoch: 93 	Average Loss: 13.0425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6557

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 17.9922	Cost: 24.42s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 12.4933	Cost: 7.99s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 12.7179	Cost: 8.59s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 12.4290	Cost: 8.33s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 12.4646	Cost: 8.24s
Train Epoch: 94 	Average Loss: 12.9517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7550

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 18.0364	Cost: 24.41s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 12.4807	Cost: 7.13s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 12.5762	Cost: 11.00s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 12.3515	Cost: 5.90s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 12.4386	Cost: 5.77s
Train Epoch: 95 	Average Loss: 12.8757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7585

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 18.1220	Cost: 28.76s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 12.6801	Cost: 8.31s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 12.6380	Cost: 14.92s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 12.3121	Cost: 14.64s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 12.6691	Cost: 7.96s
Train Epoch: 96 	Average Loss: 12.9984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7345

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 18.3114	Cost: 25.66s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 12.5937	Cost: 6.19s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 12.6815	Cost: 8.41s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 12.3619	Cost: 7.28s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 12.5650	Cost: 15.96s
Train Epoch: 97 	Average Loss: 13.0198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7407

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 18.0765	Cost: 23.95s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 12.6615	Cost: 7.85s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 12.6704	Cost: 6.07s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 12.9044	Cost: 6.22s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 12.8986	Cost: 7.85s
Train Epoch: 98 	Average Loss: 13.1585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7029

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 18.0995	Cost: 23.57s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 12.6287	Cost: 6.11s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 12.7477	Cost: 8.21s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 12.5704	Cost: 8.43s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 12.6743	Cost: 8.26s
Train Epoch: 99 	Average Loss: 13.0742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5498

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 18.2237	Cost: 24.61s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 12.5578	Cost: 9.22s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 12.4292	Cost: 9.08s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 12.3460	Cost: 6.01s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 12.5318	Cost: 5.96s
Train Epoch: 100 	Average Loss: 12.8865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7668

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 18.1350	Cost: 25.25s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 12.5083	Cost: 6.11s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 12.5034	Cost: 11.16s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 12.0592	Cost: 15.33s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 12.3870	Cost: 9.65s
Train Epoch: 101 	Average Loss: 12.8059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7671

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 18.3423	Cost: 23.82s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 12.6231	Cost: 6.16s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 12.6969	Cost: 8.23s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 12.2281	Cost: 6.14s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 12.3931	Cost: 8.38s
Train Epoch: 102 	Average Loss: 12.7429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8630

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 18.4528	Cost: 23.86s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 12.4726	Cost: 8.52s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 12.3673	Cost: 8.79s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 12.1304	Cost: 8.43s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 12.2296	Cost: 8.13s
Train Epoch: 103 	Average Loss: 12.6948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8616

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 18.2619	Cost: 24.40s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 12.3616	Cost: 6.03s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 12.0600	Cost: 7.24s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 12.1233	Cost: 6.04s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 12.1356	Cost: 8.55s
Train Epoch: 104 	Average Loss: 12.6601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7330

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 18.1637	Cost: 26.78s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 12.1732	Cost: 14.85s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 12.1276	Cost: 6.57s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 12.0333	Cost: 11.59s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 12.0418	Cost: 6.13s
Train Epoch: 105 	Average Loss: 12.5451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9418

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 18.1630	Cost: 31.85s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 12.1417	Cost: 6.35s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 12.2442	Cost: 8.02s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 11.8264	Cost: 14.78s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 12.1556	Cost: 14.84s
Train Epoch: 106 	Average Loss: 12.5692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0055

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 18.1344	Cost: 25.34s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 12.1838	Cost: 6.62s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 11.8665	Cost: 8.24s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 11.8748	Cost: 6.03s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 12.1718	Cost: 10.54s
Train Epoch: 107 	Average Loss: 12.5530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9499

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 18.6087	Cost: 25.50s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 12.2458	Cost: 8.63s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 12.4163	Cost: 9.01s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 12.1365	Cost: 8.17s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 12.2048	Cost: 5.64s
Train Epoch: 108 	Average Loss: 12.7176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9261

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 18.2987	Cost: 25.76s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 12.2657	Cost: 6.15s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 12.1065	Cost: 7.87s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 11.9565	Cost: 6.73s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 12.0678	Cost: 9.35s
Train Epoch: 109 	Average Loss: 12.5483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9983

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 18.1603	Cost: 25.70s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 11.8818	Cost: 6.13s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 12.1038	Cost: 13.30s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 11.8077	Cost: 6.98s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 11.9442	Cost: 6.11s
Train Epoch: 110 	Average Loss: 12.3869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9999

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 18.3388	Cost: 25.35s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 12.0279	Cost: 6.21s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 12.0142	Cost: 7.86s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 11.8670	Cost: 12.51s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 12.2168	Cost: 15.11s
Train Epoch: 111 	Average Loss: 12.4424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0549

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 18.3182	Cost: 24.78s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 12.1140	Cost: 6.46s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 12.2233	Cost: 9.74s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 11.9393	Cost: 6.11s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 11.9629	Cost: 12.81s
Train Epoch: 112 	Average Loss: 12.4636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0877

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 18.4282	Cost: 23.43s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 11.8486	Cost: 8.78s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 11.8797	Cost: 8.86s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 11.5966	Cost: 7.13s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 12.0227	Cost: 6.16s
Train Epoch: 113 	Average Loss: 12.3086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1426

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 18.5483	Cost: 23.54s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 11.8681	Cost: 6.22s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 12.0282	Cost: 7.44s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 11.6368	Cost: 7.64s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 11.8881	Cost: 8.34s
Train Epoch: 114 	Average Loss: 12.2872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1845

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 18.3535	Cost: 25.94s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 11.8113	Cost: 6.21s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 11.8849	Cost: 12.23s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 11.6652	Cost: 7.21s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 11.6505	Cost: 6.30s
Train Epoch: 115 	Average Loss: 12.2896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1736

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 18.3973	Cost: 30.15s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 11.7201	Cost: 6.24s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 12.1256	Cost: 8.49s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 11.6985	Cost: 14.76s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 11.7593	Cost: 14.74s
Train Epoch: 116 	Average Loss: 12.3146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0984

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 18.2939	Cost: 25.93s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 11.8536	Cost: 6.37s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 11.9736	Cost: 9.08s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 11.4025	Cost: 6.06s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 11.6512	Cost: 12.94s
Train Epoch: 117 	Average Loss: 12.2399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2053

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 18.1819	Cost: 24.29s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 11.7542	Cost: 6.82s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 11.5731	Cost: 9.92s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 11.6199	Cost: 6.18s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 11.7132	Cost: 12.76s
Train Epoch: 118 	Average Loss: 12.1638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2239

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 18.4788	Cost: 25.28s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 11.6412	Cost: 6.21s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 11.4682	Cost: 9.04s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 11.3491	Cost: 8.90s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 11.6288	Cost: 8.91s
Train Epoch: 119 	Average Loss: 12.1009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2692

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 18.8538	Cost: 24.38s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 11.7499	Cost: 10.23s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 11.6431	Cost: 7.93s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 11.6364	Cost: 5.82s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 11.6739	Cost: 5.68s
Train Epoch: 120 	Average Loss: 12.1194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3224

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 18.6138	Cost: 26.85s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 11.6291	Cost: 14.36s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 11.8841	Cost: 14.25s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 11.6133	Cost: 11.43s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 11.9090	Cost: 5.71s
Train Epoch: 121 	Average Loss: 12.1910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3357

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 18.6960	Cost: 25.31s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 11.5675	Cost: 6.11s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 11.6800	Cost: 11.98s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 11.5676	Cost: 14.08s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 11.6687	Cost: 14.51s
Train Epoch: 122 	Average Loss: 12.1811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2802

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 18.5312	Cost: 23.95s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 11.7691	Cost: 6.12s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 11.8499	Cost: 9.97s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 11.4494	Cost: 6.14s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 11.6924	Cost: 14.12s
Train Epoch: 123 	Average Loss: 12.1585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2746

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 18.6575	Cost: 24.77s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 11.7213	Cost: 8.76s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 11.6660	Cost: 8.50s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 11.4848	Cost: 5.85s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 11.5323	Cost: 6.15s
Train Epoch: 124 	Average Loss: 12.0803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4213

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 18.5563	Cost: 25.74s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 11.8254	Cost: 6.16s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 11.7481	Cost: 10.46s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 11.5256	Cost: 8.44s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 11.6860	Cost: 8.25s
Train Epoch: 125 	Average Loss: 12.1251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2510

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 18.8179	Cost: 25.38s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 11.8166	Cost: 6.21s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 11.8066	Cost: 11.19s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 11.6614	Cost: 6.77s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 11.7370	Cost: 5.94s
Train Epoch: 126 	Average Loss: 12.2626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3754

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 18.8056	Cost: 30.87s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 11.7969	Cost: 6.27s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 11.6092	Cost: 13.56s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 11.3644	Cost: 14.98s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 11.6207	Cost: 14.53s
Train Epoch: 127 	Average Loss: 12.1000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3061

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 18.6143	Cost: 24.57s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 11.4370	Cost: 6.28s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 11.5302	Cost: 8.27s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 11.0723	Cost: 6.13s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 11.2443	Cost: 9.93s
Train Epoch: 128 	Average Loss: 11.9748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3604

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 18.4305	Cost: 25.29s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 11.3290	Cost: 8.87s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 11.3576	Cost: 8.75s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 11.4074	Cost: 8.34s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 11.4990	Cost: 8.27s
Train Epoch: 129 	Average Loss: 11.8564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3785

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 18.7356	Cost: 26.75s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 11.2367	Cost: 10.14s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 11.4389	Cost: 6.08s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 11.3799	Cost: 6.03s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 11.4532	Cost: 6.72s
Train Epoch: 130 	Average Loss: 11.8663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4127

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 18.7245	Cost: 25.55s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 11.6480	Cost: 8.19s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 11.4726	Cost: 14.49s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 11.2396	Cost: 13.05s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 11.1087	Cost: 10.63s
Train Epoch: 131 	Average Loss: 11.8211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3360

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 18.9621	Cost: 25.48s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 11.2770	Cost: 6.07s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 11.3046	Cost: 11.06s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 11.1624	Cost: 13.27s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 11.2204	Cost: 15.07s
Train Epoch: 132 	Average Loss: 11.7772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4324

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 18.7934	Cost: 23.50s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 11.2716	Cost: 6.38s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 11.5764	Cost: 9.55s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 11.0658	Cost: 6.12s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 11.2822	Cost: 11.84s
Train Epoch: 133 	Average Loss: 11.8178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2731

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 18.7517	Cost: 24.16s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 11.5127	Cost: 7.79s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 11.4473	Cost: 8.91s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 11.1026	Cost: 8.42s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 11.1925	Cost: 8.27s
Train Epoch: 134 	Average Loss: 11.8613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4196

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 18.5720	Cost: 25.46s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 11.2360	Cost: 12.07s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 11.3433	Cost: 6.24s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 10.9585	Cost: 6.11s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 11.0835	Cost: 5.83s
Train Epoch: 135 	Average Loss: 11.6679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4144

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 18.7299	Cost: 28.63s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 11.3180	Cost: 12.45s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 11.3731	Cost: 15.41s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 11.0036	Cost: 12.17s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 11.0305	Cost: 5.82s
Train Epoch: 136 	Average Loss: 11.6588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5106

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 19.0007	Cost: 28.27s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 11.2348	Cost: 6.22s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 11.3141	Cost: 10.31s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 10.9059	Cost: 14.96s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 11.0527	Cost: 14.81s
Train Epoch: 137 	Average Loss: 11.6861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4117

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 18.9879	Cost: 25.58s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 10.9340	Cost: 6.33s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 11.0321	Cost: 8.27s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 10.8560	Cost: 6.01s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 11.0341	Cost: 10.32s
Train Epoch: 138 	Average Loss: 11.5669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6535

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 18.8465	Cost: 25.41s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 10.8948	Cost: 8.69s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 11.1421	Cost: 8.79s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 10.8375	Cost: 8.37s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 10.7467	Cost: 8.22s
Train Epoch: 139 	Average Loss: 11.5619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5333

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 19.0993	Cost: 27.15s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 10.9756	Cost: 6.83s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 11.0942	Cost: 6.23s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 11.0449	Cost: 5.99s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 11.1025	Cost: 6.40s
Train Epoch: 140 	Average Loss: 11.5495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5530

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 18.6996	Cost: 26.05s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 11.2034	Cost: 12.51s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 11.0964	Cost: 15.28s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 10.8757	Cost: 10.89s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 11.0755	Cost: 7.73s
Train Epoch: 141 	Average Loss: 11.5331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7411

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 18.9630	Cost: 25.72s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 11.3066	Cost: 6.07s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 11.2757	Cost: 8.43s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 10.8626	Cost: 6.51s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 11.0500	Cost: 17.63s
Train Epoch: 142 	Average Loss: 11.6777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6457

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 18.8406	Cost: 23.31s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 11.1151	Cost: 6.09s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 10.8901	Cost: 7.96s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 10.7266	Cost: 6.37s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 10.9800	Cost: 9.01s
Train Epoch: 143 	Average Loss: 11.5300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5605

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 18.7701	Cost: 23.45s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 10.8706	Cost: 6.03s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 10.9384	Cost: 7.53s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 10.6915	Cost: 8.15s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 10.9410	Cost: 8.24s
Train Epoch: 144 	Average Loss: 11.5345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7499

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 18.9359	Cost: 27.48s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 11.0007	Cost: 8.28s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 11.0777	Cost: 9.83s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 10.6598	Cost: 5.99s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 11.0885	Cost: 5.92s
Train Epoch: 145 	Average Loss: 11.5175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5991

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 19.2624	Cost: 35.73s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 11.0767	Cost: 9.25s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 10.8247	Cost: 14.77s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 10.7288	Cost: 14.09s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 10.7310	Cost: 7.74s
Train Epoch: 146 	Average Loss: 11.4283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7099

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 18.9129	Cost: 27.23s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 10.7940	Cost: 6.45s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 11.0273	Cost: 8.36s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 10.4830	Cost: 8.32s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 10.6157	Cost: 14.86s
Train Epoch: 147 	Average Loss: 11.3034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6964

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 19.1114	Cost: 26.48s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 10.5891	Cost: 8.09s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 10.7538	Cost: 10.50s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 10.6655	Cost: 6.19s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 10.6224	Cost: 12.74s
Train Epoch: 148 	Average Loss: 11.2808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7661

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 19.1101	Cost: 22.34s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 10.4175	Cost: 8.70s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 10.8162	Cost: 9.00s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 10.2346	Cost: 8.88s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 10.6520	Cost: 6.09s
Train Epoch: 149 	Average Loss: 11.1904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7234

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 19.2547	Cost: 22.62s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 10.5459	Cost: 6.14s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 10.6202	Cost: 6.99s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 10.4614	Cost: 7.13s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 10.6031	Cost: 11.58s
Train Epoch: 150 	Average Loss: 11.1743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7555

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 18.7838	Cost: 23.79s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 10.5944	Cost: 7.70s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 10.8042	Cost: 10.59s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 10.5492	Cost: 5.84s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 10.8738	Cost: 5.86s
Train Epoch: 151 	Average Loss: 11.2171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8154

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 19.2471	Cost: 26.27s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 10.6162	Cost: 12.16s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 10.9217	Cost: 14.07s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 10.5882	Cost: 13.87s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 10.7789	Cost: 5.68s
Train Epoch: 152 	Average Loss: 11.2513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7849

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 18.9576	Cost: 24.64s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 10.6054	Cost: 6.09s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 10.7093	Cost: 8.44s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 10.3785	Cost: 12.11s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 10.8013	Cost: 14.73s
Train Epoch: 153 	Average Loss: 11.2622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8170

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 19.1697	Cost: 23.42s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 10.7764	Cost: 6.13s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 10.7425	Cost: 7.89s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 10.3624	Cost: 6.13s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 10.6107	Cost: 9.61s
Train Epoch: 154 	Average Loss: 11.2046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7767

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 19.3322	Cost: 25.48s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 10.6935	Cost: 6.09s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 10.8099	Cost: 8.94s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 10.2579	Cost: 8.45s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 10.5692	Cost: 8.39s
Train Epoch: 155 	Average Loss: 11.1449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8020

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 19.3302	Cost: 25.97s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 10.6352	Cost: 12.12s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 10.6292	Cost: 6.28s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 10.3090	Cost: 6.11s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 10.6179	Cost: 5.90s
Train Epoch: 156 	Average Loss: 11.0686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8837

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 19.3195	Cost: 28.83s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 10.6261	Cost: 15.22s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 10.7151	Cost: 12.16s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 10.2605	Cost: 10.97s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 10.4322	Cost: 6.96s
Train Epoch: 157 	Average Loss: 11.0069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8183

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 19.2316	Cost: 25.89s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 10.2914	Cost: 6.08s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 10.7147	Cost: 8.56s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 10.0535	Cost: 12.73s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 10.6372	Cost: 14.84s
Train Epoch: 158 	Average Loss: 10.9685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8193

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 19.2449	Cost: 22.48s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 10.3223	Cost: 6.29s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 10.6178	Cost: 8.33s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 10.3017	Cost: 6.25s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 10.5167	Cost: 9.40s
Train Epoch: 159 	Average Loss: 10.9422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8323

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 19.0170	Cost: 25.13s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 10.2777	Cost: 8.58s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 10.2150	Cost: 8.89s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 9.9843	Cost: 8.36s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 10.4626	Cost: 6.15s
Train Epoch: 160 	Average Loss: 10.8548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8625

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 19.1713	Cost: 24.99s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 10.2824	Cost: 8.86s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 10.2068	Cost: 6.16s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 9.8500	Cost: 6.03s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 10.3524	Cost: 5.81s
Train Epoch: 161 	Average Loss: 10.8849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8706

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 19.2739	Cost: 27.59s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 10.5500	Cost: 14.76s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 10.2749	Cost: 14.70s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 10.1114	Cost: 9.80s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 10.2630	Cost: 5.83s
Train Epoch: 162 	Average Loss: 10.9219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9187

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 19.1888	Cost: 30.20s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 10.2052	Cost: 6.21s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 10.4651	Cost: 8.34s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 9.8331	Cost: 12.14s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 9.8971	Cost: 14.33s
Train Epoch: 163 	Average Loss: 10.7413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9985

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 19.4522	Cost: 27.17s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 10.2096	Cost: 6.28s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 10.1914	Cost: 9.79s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 9.9259	Cost: 6.29s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 10.1560	Cost: 14.53s
Train Epoch: 164 	Average Loss: 10.8071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9705

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 19.3780	Cost: 22.54s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 10.2628	Cost: 7.78s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 10.2785	Cost: 8.01s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 9.7602	Cost: 6.34s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 10.1068	Cost: 12.62s
Train Epoch: 165 	Average Loss: 10.7651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8764

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 19.2910	Cost: 24.41s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 9.9733	Cost: 6.02s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 10.1829	Cost: 9.55s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 9.7130	Cost: 8.57s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 10.0470	Cost: 8.79s
Train Epoch: 166 	Average Loss: 10.6381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0668

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 19.1671	Cost: 25.40s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 10.0485	Cost: 12.02s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 10.1753	Cost: 6.10s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 9.7775	Cost: 5.97s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 10.0582	Cost: 5.69s
Train Epoch: 167 	Average Loss: 10.5919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9617

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 19.0424	Cost: 28.66s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 9.9313	Cost: 14.50s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 10.1627	Cost: 12.86s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 9.5244	Cost: 9.62s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 10.0722	Cost: 5.71s
Train Epoch: 168 	Average Loss: 10.5389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1247

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 19.2307	Cost: 27.01s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 9.9237	Cost: 6.05s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 10.0152	Cost: 11.95s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 9.5860	Cost: 14.89s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 9.7445	Cost: 14.46s
Train Epoch: 169 	Average Loss: 10.5041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1589

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 19.3409	Cost: 24.85s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 9.6263	Cost: 6.19s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 9.9339	Cost: 10.39s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 9.5838	Cost: 9.16s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 9.8407	Cost: 14.87s
Train Epoch: 170 	Average Loss: 10.4925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1729

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 19.2042	Cost: 22.70s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 9.7181	Cost: 6.08s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 9.9177	Cost: 8.38s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 9.7308	Cost: 6.16s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 10.0857	Cost: 10.03s
Train Epoch: 171 	Average Loss: 10.5151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1111

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 19.3982	Cost: 25.81s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 9.7615	Cost: 6.10s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 10.0828	Cost: 9.01s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 9.5140	Cost: 8.58s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 9.8145	Cost: 8.36s
Train Epoch: 172 	Average Loss: 10.4370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1907

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 19.3292	Cost: 28.72s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 9.7099	Cost: 8.92s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 9.9746	Cost: 6.41s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 9.4119	Cost: 6.07s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 9.4940	Cost: 5.86s
Train Epoch: 173 	Average Loss: 10.3579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1339

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 19.6901	Cost: 29.73s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 9.4109	Cost: 15.08s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 9.7732	Cost: 9.39s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 9.5043	Cost: 10.66s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 9.7347	Cost: 5.98s
Train Epoch: 174 	Average Loss: 10.3549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2438

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 19.5124	Cost: 28.03s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 9.5683	Cost: 6.03s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 9.7536	Cost: 15.71s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 9.6793	Cost: 14.02s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 9.8586	Cost: 6.02s
Train Epoch: 175 	Average Loss: 10.3368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2296

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 19.6014	Cost: 23.08s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 9.6901	Cost: 6.29s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 9.7611	Cost: 8.06s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 9.4079	Cost: 6.16s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 9.8231	Cost: 8.35s
Train Epoch: 176 	Average Loss: 10.2982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2618

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 19.4078	Cost: 24.15s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 9.9496	Cost: 6.67s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 9.9907	Cost: 9.37s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 9.5642	Cost: 8.40s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 10.0072	Cost: 8.24s
Train Epoch: 177 	Average Loss: 10.4266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1081

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 19.3682	Cost: 24.66s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 9.7251	Cost: 11.69s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 9.7899	Cost: 6.04s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 9.4042	Cost: 5.90s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 9.6916	Cost: 5.76s
Train Epoch: 178 	Average Loss: 10.2756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1255

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 19.5365	Cost: 39.63s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 9.2585	Cost: 14.44s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 9.5239	Cost: 9.97s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 9.2442	Cost: 9.87s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 9.5149	Cost: 5.86s
Train Epoch: 179 	Average Loss: 10.2349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2110

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 19.6018	Cost: 29.35s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 9.2778	Cost: 6.39s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 9.5547	Cost: 8.52s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 9.5400	Cost: 6.01s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 9.7021	Cost: 16.45s
Train Epoch: 180 	Average Loss: 10.1567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1680

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 19.5577	Cost: 26.17s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 9.3498	Cost: 6.71s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 9.6694	Cost: 10.29s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 9.0980	Cost: 6.16s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 9.3870	Cost: 11.21s
Train Epoch: 181 	Average Loss: 10.1783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2990

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 19.5887	Cost: 23.55s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 9.4625	Cost: 8.66s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 9.4347	Cost: 9.10s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 9.0411	Cost: 8.23s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 9.4207	Cost: 6.15s
Train Epoch: 182 	Average Loss: 10.0665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4250

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 19.6254	Cost: 23.47s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 9.3352	Cost: 6.15s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 9.6438	Cost: 8.90s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 9.1469	Cost: 9.03s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 9.2795	Cost: 8.80s
Train Epoch: 183 	Average Loss: 10.0410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2839

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 19.8242	Cost: 26.86s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 9.2980	Cost: 11.07s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 9.6288	Cost: 6.18s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 9.2645	Cost: 5.94s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 9.3280	Cost: 5.78s
Train Epoch: 184 	Average Loss: 10.0553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3957

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 19.6025	Cost: 28.05s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 9.1409	Cost: 12.23s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 9.5397	Cost: 6.16s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 9.0112	Cost: 11.82s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 9.2745	Cost: 5.68s
Train Epoch: 185 	Average Loss: 9.9410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4202

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 19.7381	Cost: 27.16s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 9.1510	Cost: 6.23s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 9.3476	Cost: 12.16s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 8.8597	Cost: 15.20s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 9.1597	Cost: 15.30s
Train Epoch: 186 	Average Loss: 9.9713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4265

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 19.8024	Cost: 23.43s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 9.3362	Cost: 6.20s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 9.6386	Cost: 8.39s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 9.0907	Cost: 6.02s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 9.3199	Cost: 10.70s
Train Epoch: 187 	Average Loss: 10.0076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5132

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 19.4165	Cost: 25.14s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 9.1399	Cost: 8.54s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 9.5283	Cost: 8.78s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 9.1241	Cost: 6.19s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 9.3339	Cost: 6.08s
Train Epoch: 188 	Average Loss: 9.9642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3877

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 19.4749	Cost: 26.32s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 9.1798	Cost: 6.24s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 9.4467	Cost: 7.94s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 8.9602	Cost: 8.55s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 9.2676	Cost: 8.29s
Train Epoch: 189 	Average Loss: 9.9539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3495

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 19.6372	Cost: 31.12s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 9.4245	Cost: 7.18s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 9.5390	Cost: 10.87s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 9.1894	Cost: 6.04s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 9.3092	Cost: 5.95s
Train Epoch: 190 	Average Loss: 10.0558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4478

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 19.6387	Cost: 33.42s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 9.1512	Cost: 6.23s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 9.4131	Cost: 8.09s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 9.1062	Cost: 12.99s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 9.0619	Cost: 14.05s
Train Epoch: 191 	Average Loss: 9.9698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4933

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 19.8153	Cost: 30.32s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 9.1842	Cost: 6.21s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 9.4141	Cost: 9.34s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 8.7782	Cost: 6.06s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 9.2080	Cost: 13.14s
Train Epoch: 192 	Average Loss: 9.8309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5463

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 19.7308	Cost: 23.73s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 9.0261	Cost: 7.74s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 9.1019	Cost: 7.32s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 8.8850	Cost: 8.01s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 9.1676	Cost: 8.69s
Train Epoch: 193 	Average Loss: 9.7491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6076

Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 19.7976	Cost: 24.07s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 8.9748	Cost: 6.16s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 9.0432	Cost: 9.20s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 8.6658	Cost: 8.94s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 8.8874	Cost: 8.88s
Train Epoch: 194 	Average Loss: 9.6391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5135

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 19.8744	Cost: 25.19s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 8.7060	Cost: 9.99s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 9.1121	Cost: 8.22s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 8.7777	Cost: 5.99s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 8.9912	Cost: 5.73s
Train Epoch: 195 	Average Loss: 9.6159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5978

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 19.7193	Cost: 29.79s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 8.9387	Cost: 15.04s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 9.0659	Cost: 10.99s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 8.8261	Cost: 9.64s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 8.9273	Cost: 5.75s
Train Epoch: 196 	Average Loss: 9.6892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4612

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 19.6570	Cost: 25.37s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 8.8959	Cost: 6.12s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 8.9352	Cost: 14.13s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 8.5978	Cost: 14.69s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 8.6044	Cost: 10.97s
Train Epoch: 197 	Average Loss: 9.5893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6813

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 19.9616	Cost: 24.04s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 8.6666	Cost: 6.33s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 8.8018	Cost: 10.99s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 8.6615	Cost: 5.97s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 8.6237	Cost: 19.33s
Train Epoch: 198 	Average Loss: 9.5203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6923

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 19.7796	Cost: 23.06s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 8.7707	Cost: 6.14s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 9.0559	Cost: 7.98s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 8.5862	Cost: 6.12s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 8.7455	Cost: 9.30s
Train Epoch: 199 	Average Loss: 9.5124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7245

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 20.0840	Cost: 25.01s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 8.9157	Cost: 7.70s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 8.9513	Cost: 8.82s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 8.4158	Cost: 8.44s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 8.7120	Cost: 8.38s
Train Epoch: 200 	Average Loss: 9.4401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7166

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 19.9295	Cost: 28.01s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 8.7260	Cost: 9.28s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 8.7080	Cost: 6.38s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 8.4770	Cost: 6.20s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 8.6413	Cost: 5.88s
Train Epoch: 201 	Average Loss: 9.4837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6844

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 19.7824	Cost: 25.35s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 8.7446	Cost: 14.91s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 8.7108	Cost: 15.05s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 8.2338	Cost: 9.92s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 8.4107	Cost: 6.00s
Train Epoch: 202 	Average Loss: 9.3650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6817

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 20.0941	Cost: 25.91s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 8.6207	Cost: 6.18s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 8.5263	Cost: 7.91s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 8.1438	Cost: 13.52s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 8.6308	Cost: 14.77s
Train Epoch: 203 	Average Loss: 9.3456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7962

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 19.8216	Cost: 23.80s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 8.4722	Cost: 6.40s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 8.9000	Cost: 8.11s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 8.3740	Cost: 6.18s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 8.7716	Cost: 8.90s
Train Epoch: 204 	Average Loss: 9.4515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7513

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 19.8335	Cost: 23.39s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 8.8148	Cost: 6.15s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 8.6681	Cost: 9.09s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 8.2817	Cost: 8.40s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 8.4859	Cost: 8.32s
Train Epoch: 205 	Average Loss: 9.3521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8332

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 20.1085	Cost: 24.57s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 8.4435	Cost: 11.33s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 8.5630	Cost: 6.67s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 8.1560	Cost: 5.95s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 8.4088	Cost: 5.90s
Train Epoch: 206 	Average Loss: 9.3354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8580

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 20.0985	Cost: 28.72s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 8.5752	Cost: 8.66s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 8.8659	Cost: 14.95s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 8.6672	Cost: 14.67s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 8.6516	Cost: 7.51s
Train Epoch: 207 	Average Loss: 9.3958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7660

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 20.0640	Cost: 27.76s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 8.8044	Cost: 6.38s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 8.7609	Cost: 8.74s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 8.3916	Cost: 12.36s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 8.5069	Cost: 14.66s
Train Epoch: 208 	Average Loss: 9.3672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8071

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 20.0729	Cost: 27.16s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 8.6187	Cost: 6.30s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 8.3943	Cost: 10.26s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 8.5228	Cost: 6.27s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 8.4646	Cost: 14.74s
Train Epoch: 209 	Average Loss: 9.2591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9237

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 19.7521	Cost: 23.55s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 8.3521	Cost: 9.00s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 8.7108	Cost: 7.47s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 8.0100	Cost: 6.14s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 8.4435	Cost: 10.16s
Train Epoch: 210 	Average Loss: 9.2167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7830

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 20.3361	Cost: 23.90s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 8.4943	Cost: 6.16s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 8.4960	Cost: 9.97s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 8.1536	Cost: 8.75s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 8.3235	Cost: 8.54s
Train Epoch: 211 	Average Loss: 9.1682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8240

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 20.1733	Cost: 26.53s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 8.3555	Cost: 11.67s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 8.7564	Cost: 6.43s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 8.5195	Cost: 6.27s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 8.5904	Cost: 6.10s
Train Epoch: 212 	Average Loss: 9.3381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7584

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 19.9495	Cost: 26.02s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 8.5185	Cost: 6.06s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 8.6470	Cost: 14.01s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 8.2402	Cost: 14.35s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 8.2299	Cost: 11.48s
Train Epoch: 213 	Average Loss: 9.3060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9319

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 20.0873	Cost: 22.94s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 8.3006	Cost: 6.15s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 8.4567	Cost: 8.64s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 8.1054	Cost: 5.99s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 8.1666	Cost: 10.69s
Train Epoch: 214 	Average Loss: 9.0974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9282

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 20.1942	Cost: 24.99s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 8.3097	Cost: 8.58s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 8.4253	Cost: 8.65s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 8.0781	Cost: 7.96s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 8.0726	Cost: 5.73s
Train Epoch: 215 	Average Loss: 9.0267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9788

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 20.1601	Cost: 26.00s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 8.2939	Cost: 6.00s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 8.2914	Cost: 7.79s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 8.0208	Cost: 6.48s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 8.0503	Cost: 8.63s
Train Epoch: 216 	Average Loss: 9.0058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0325

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 20.4034	Cost: 27.57s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 8.2086	Cost: 10.87s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 8.4830	Cost: 6.09s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 8.0298	Cost: 11.86s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 8.1807	Cost: 5.88s
Train Epoch: 217 	Average Loss: 9.0385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9837

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 19.9644	Cost: 28.56s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 8.1513	Cost: 6.41s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 8.2651	Cost: 8.41s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 7.8839	Cost: 13.11s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 7.9873	Cost: 14.77s
Train Epoch: 218 	Average Loss: 8.9912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9757

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 20.1649	Cost: 33.87s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 8.0698	Cost: 6.51s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 7.9583	Cost: 12.40s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 8.1298	Cost: 6.50s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 8.1679	Cost: 18.88s
Train Epoch: 219 	Average Loss: 8.9340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9245

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 20.2177	Cost: 22.89s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 7.9876	Cost: 7.45s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 8.2375	Cost: 14.00s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 7.8671	Cost: 7.49s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 7.9001	Cost: 12.69s
Train Epoch: 220 	Average Loss: 8.8718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9922

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 20.0646	Cost: 22.56s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 7.9065	Cost: 6.06s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 8.1883	Cost: 8.31s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 7.8466	Cost: 8.75s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 8.0294	Cost: 8.85s
Train Epoch: 221 	Average Loss: 8.8459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9872

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 19.7787	Cost: 28.38s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 7.7642	Cost: 10.50s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 8.2722	Cost: 6.07s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 7.8212	Cost: 5.94s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 7.9662	Cost: 5.63s
Train Epoch: 222 	Average Loss: 8.8567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0571

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 20.2210	Cost: 29.12s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 8.0316	Cost: 13.75s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 8.2157	Cost: 7.20s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 7.9508	Cost: 10.67s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 7.8089	Cost: 5.64s
Train Epoch: 223 	Average Loss: 8.8243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0406

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 20.3112	Cost: 25.47s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 8.2619	Cost: 6.02s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 8.2792	Cost: 12.17s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 8.1170	Cost: 14.39s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 8.0722	Cost: 13.27s
Train Epoch: 224 	Average Loss: 9.0265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0940

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 20.1754	Cost: 23.78s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 8.2428	Cost: 6.10s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 8.2909	Cost: 8.37s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 7.7916	Cost: 5.97s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 8.0028	Cost: 16.79s
Train Epoch: 225 	Average Loss: 8.9506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1129

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 20.5434	Cost: 24.54s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 8.1519	Cost: 6.10s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 8.1112	Cost: 7.79s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 8.3129	Cost: 6.16s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 8.2704	Cost: 9.69s
Train Epoch: 226 	Average Loss: 9.0366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9902

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 20.1768	Cost: 25.77s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 8.1641	Cost: 6.07s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 8.2169	Cost: 8.87s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 7.7178	Cost: 8.47s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 7.7745	Cost: 8.35s
Train Epoch: 227 	Average Loss: 8.7998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0396

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 20.1748	Cost: 28.34s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 7.7470	Cost: 10.73s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 7.9095	Cost: 6.11s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 7.5429	Cost: 6.07s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 7.7932	Cost: 5.83s
Train Epoch: 228 	Average Loss: 8.6355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0561

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 20.3208	Cost: 25.60s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 7.7005	Cost: 8.08s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 7.8420	Cost: 15.04s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 7.5433	Cost: 11.77s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 7.8607	Cost: 11.94s
Train Epoch: 229 	Average Loss: 8.6641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1547

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 20.0651	Cost: 24.01s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 7.8670	Cost: 6.57s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 8.0440	Cost: 8.09s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 7.6772	Cost: 6.61s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 7.9110	Cost: 9.71s
Train Epoch: 230 	Average Loss: 8.6714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0405

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 20.6411	Cost: 23.33s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 7.7195	Cost: 7.19s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 8.0348	Cost: 8.90s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 7.6575	Cost: 8.39s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 7.6887	Cost: 8.38s
Train Epoch: 231 	Average Loss: 8.6578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2563

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 20.3776	Cost: 25.06s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 7.6781	Cost: 7.24s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 7.6665	Cost: 11.00s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 7.4166	Cost: 5.93s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 7.7471	Cost: 5.82s
Train Epoch: 232 	Average Loss: 8.5271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2447

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 19.8909	Cost: 27.59s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 7.7827	Cost: 12.11s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 7.9075	Cost: 15.12s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 7.6457	Cost: 12.72s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 7.4755	Cost: 5.78s
Train Epoch: 233 	Average Loss: 8.5327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1978

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 20.3289	Cost: 27.91s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 7.7344	Cost: 6.43s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 7.8194	Cost: 7.75s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 7.3942	Cost: 15.58s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 7.4902	Cost: 14.45s
Train Epoch: 234 	Average Loss: 8.4621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2836

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 20.3481	Cost: 24.03s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 7.5862	Cost: 6.33s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 7.5752	Cost: 8.74s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 7.2201	Cost: 6.00s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 7.2424	Cost: 13.47s
Train Epoch: 235 	Average Loss: 8.4035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2930

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 20.4073	Cost: 28.59s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 7.6249	Cost: 8.63s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 7.5677	Cost: 7.05s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 7.2499	Cost: 6.07s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 7.4898	Cost: 8.55s
Train Epoch: 236 	Average Loss: 8.3835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2824

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 20.3244	Cost: 25.81s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 7.3553	Cost: 6.08s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 7.4183	Cost: 8.42s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 7.1612	Cost: 8.49s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 7.6969	Cost: 8.23s
Train Epoch: 237 	Average Loss: 8.3597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4269

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 20.4683	Cost: 25.32s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 7.4865	Cost: 12.14s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 7.5684	Cost: 6.09s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 7.1891	Cost: 6.21s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 7.6737	Cost: 5.93s
Train Epoch: 238 	Average Loss: 8.3408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3589

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 20.3642	Cost: 26.55s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 7.3175	Cost: 6.10s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 7.6679	Cost: 13.42s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 7.2028	Cost: 15.05s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 7.3049	Cost: 11.96s
Train Epoch: 239 	Average Loss: 8.2640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4151

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 20.4448	Cost: 23.57s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 7.4760	Cost: 6.44s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 7.3452	Cost: 8.34s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 7.1162	Cost: 6.18s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 7.5619	Cost: 20.51s
Train Epoch: 240 	Average Loss: 8.2747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3474

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 20.3599	Cost: 23.78s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 7.2448	Cost: 8.62s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 7.1439	Cost: 6.30s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 7.2895	Cost: 6.35s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 7.1088	Cost: 7.32s
Train Epoch: 241 	Average Loss: 8.1529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3999

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 20.7578	Cost: 25.27s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 7.3096	Cost: 6.08s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 7.3502	Cost: 10.02s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 7.1854	Cost: 8.62s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 7.4669	Cost: 8.43s
Train Epoch: 242 	Average Loss: 8.1619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4837

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 20.6468	Cost: 25.83s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 7.3342	Cost: 6.10s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 7.4670	Cost: 12.07s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 6.9772	Cost: 5.99s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 7.1363	Cost: 5.80s
Train Epoch: 243 	Average Loss: 8.1105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5053

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 20.5471	Cost: 29.24s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 7.2132	Cost: 6.10s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 7.3607	Cost: 13.64s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 6.8846	Cost: 14.41s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 7.0206	Cost: 11.86s
Train Epoch: 244 	Average Loss: 8.0736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5251

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 20.6451	Cost: 24.26s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 7.1045	Cost: 6.30s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 7.3029	Cost: 8.84s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 6.9294	Cost: 6.06s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 7.2224	Cost: 17.47s
Train Epoch: 245 	Average Loss: 8.0576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3904

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 20.0164	Cost: 25.37s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 6.9906	Cost: 8.72s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 7.3030	Cost: 8.82s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 6.9925	Cost: 5.95s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 7.3357	Cost: 6.21s
Train Epoch: 246 	Average Loss: 7.9890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5196

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 20.5894	Cost: 25.35s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 7.3372	Cost: 6.04s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 7.5757	Cost: 8.92s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 7.0859	Cost: 8.48s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 7.2219	Cost: 8.41s
Train Epoch: 247 	Average Loss: 8.1839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5265

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 20.5324	Cost: 29.66s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 7.1061	Cost: 8.85s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 7.3266	Cost: 6.39s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 6.7083	Cost: 6.11s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 7.1549	Cost: 5.64s
Train Epoch: 248 	Average Loss: 8.0349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4471

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 20.2841	Cost: 28.44s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 6.9188	Cost: 15.39s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 7.1419	Cost: 13.09s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 6.9048	Cost: 11.95s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 6.9232	Cost: 6.01s
Train Epoch: 249 	Average Loss: 7.9419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6090

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 20.4904	Cost: 27.61s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 6.8014	Cost: 6.30s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 7.0907	Cost: 9.66s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 6.6108	Cost: 10.32s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 7.0228	Cost: 15.06s
Train Epoch: 250 	Average Loss: 7.8661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5529

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 20.7635	Cost: 21.46s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 6.9258	Cost: 6.23s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 7.0147	Cost: 9.97s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 6.6488	Cost: 7.00s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 6.8574	Cost: 8.94s
Train Epoch: 251 	Average Loss: 7.8765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4997

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 20.6191	Cost: 25.67s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 6.8932	Cost: 6.05s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 6.9206	Cost: 10.23s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 6.8533	Cost: 8.30s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 7.0897	Cost: 8.41s
Train Epoch: 252 	Average Loss: 7.7867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5648

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 20.3714	Cost: 24.34s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 6.8652	Cost: 8.80s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 6.8958	Cost: 9.25s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 6.6395	Cost: 5.93s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 7.1159	Cost: 6.65s
Train Epoch: 253 	Average Loss: 7.7144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6646

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 20.5364	Cost: 27.52s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 6.8838	Cost: 15.00s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 6.8025	Cost: 13.10s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 6.5608	Cost: 9.38s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 6.8217	Cost: 5.75s
Train Epoch: 254 	Average Loss: 7.6925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6278

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 21.0843	Cost: 25.16s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 6.6876	Cost: 6.09s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 6.8068	Cost: 11.57s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 6.5176	Cost: 14.51s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 6.8965	Cost: 13.96s
Train Epoch: 255 	Average Loss: 7.7331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6463

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 20.5616	Cost: 25.46s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 6.7757	Cost: 6.27s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 6.7721	Cost: 11.61s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 6.5166	Cost: 14.80s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 6.6993	Cost: 13.68s
Train Epoch: 256 	Average Loss: 7.7503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7550

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 20.6935	Cost: 25.05s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 6.6802	Cost: 6.15s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 6.7782	Cost: 11.99s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 6.5199	Cost: 14.65s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 6.7077	Cost: 14.36s
Train Epoch: 257 	Average Loss: 7.6841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7585

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 20.9806	Cost: 25.29s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 6.7800	Cost: 6.09s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 6.8298	Cost: 11.98s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 6.2648	Cost: 14.36s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 6.5884	Cost: 14.64s
Train Epoch: 258 	Average Loss: 7.6163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6164

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 20.7377	Cost: 25.81s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 6.7025	Cost: 6.21s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 6.8870	Cost: 11.49s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 6.4924	Cost: 14.72s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 6.7038	Cost: 14.13s
Train Epoch: 259 	Average Loss: 7.6909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6091

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 20.6843	Cost: 27.50s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 6.7686	Cost: 6.53s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 6.7166	Cost: 13.79s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 6.3125	Cost: 14.36s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 6.4866	Cost: 14.71s
Train Epoch: 260 	Average Loss: 7.5254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6602

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 20.7328	Cost: 28.46s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 6.4076	Cost: 6.56s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 6.7129	Cost: 13.98s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 6.0909	Cost: 14.59s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 6.6276	Cost: 14.51s
Train Epoch: 261 	Average Loss: 7.4843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8566

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 20.6255	Cost: 27.79s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 6.5478	Cost: 6.25s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 6.5135	Cost: 15.20s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 6.2759	Cost: 14.92s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 6.7010	Cost: 14.10s
Train Epoch: 262 	Average Loss: 7.4903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6973

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 20.8782	Cost: 28.43s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 6.4532	Cost: 6.14s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 6.5945	Cost: 15.26s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 6.4088	Cost: 15.38s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 6.4278	Cost: 11.57s
Train Epoch: 263 	Average Loss: 7.4443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7560

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 20.9479	Cost: 30.75s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 6.4918	Cost: 6.65s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 6.4952	Cost: 15.63s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 6.1976	Cost: 15.32s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 6.6416	Cost: 9.59s
Train Epoch: 264 	Average Loss: 7.4560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7490

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 20.9239	Cost: 25.65s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 6.6096	Cost: 6.11s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 6.6083	Cost: 14.57s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 6.4471	Cost: 15.01s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 6.3762	Cost: 11.97s
Train Epoch: 265 	Average Loss: 7.4862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8652

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 20.3340	Cost: 28.32s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 6.3061	Cost: 6.51s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 6.4190	Cost: 16.96s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 6.0789	Cost: 15.65s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 6.4324	Cost: 13.05s
Train Epoch: 266 	Average Loss: 7.3813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7668

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 20.7849	Cost: 31.92s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 6.1516	Cost: 6.95s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 6.5145	Cost: 15.42s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 6.1158	Cost: 14.24s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 6.1486	Cost: 10.55s
Train Epoch: 267 	Average Loss: 7.3062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7568

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 20.2362	Cost: 39.25s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 6.4551	Cost: 6.25s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 6.3177	Cost: 13.45s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 6.4369	Cost: 15.04s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 6.1898	Cost: 14.56s
Train Epoch: 268 	Average Loss: 7.2710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9424

Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 21.0043	Cost: 41.34s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 6.2186	Cost: 12.14s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 6.2408	Cost: 15.07s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 5.9504	Cost: 12.72s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 6.0951	Cost: 6.06s
Train Epoch: 269 	Average Loss: 7.2243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8878

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 20.7792	Cost: 40.38s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 6.3668	Cost: 15.40s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 6.1262	Cost: 15.01s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 5.8186	Cost: 6.05s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 6.2133	Cost: 6.04s
Train Epoch: 270 	Average Loss: 7.1403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8641

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 20.9203	Cost: 30.10s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 6.2739	Cost: 15.30s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 6.3784	Cost: 15.45s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 5.9149	Cost: 9.50s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 6.1652	Cost: 6.11s
Train Epoch: 271 	Average Loss: 7.1145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9829

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 20.9440	Cost: 30.25s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 6.0238	Cost: 15.03s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 6.0903	Cost: 14.99s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 5.9448	Cost: 8.91s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 6.2434	Cost: 6.15s
Train Epoch: 272 	Average Loss: 7.0981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0024

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 21.1828	Cost: 24.91s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 6.1726	Cost: 7.39s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 6.2466	Cost: 15.40s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 5.9225	Cost: 14.79s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 6.0093	Cost: 8.85s
Train Epoch: 273 	Average Loss: 7.0491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0654

Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 21.0679	Cost: 26.07s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 5.9709	Cost: 6.56s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 6.2069	Cost: 12.40s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 5.7629	Cost: 14.26s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 5.9404	Cost: 13.63s
Train Epoch: 274 	Average Loss: 7.0042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0142

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 20.9228	Cost: 26.68s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 6.0665	Cost: 6.41s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 5.9613	Cost: 8.28s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 5.5609	Cost: 12.41s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 6.0044	Cost: 14.72s
Train Epoch: 275 	Average Loss: 6.9620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9344

Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 21.0078	Cost: 25.63s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 6.0852	Cost: 6.81s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 6.1008	Cost: 10.06s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 5.5942	Cost: 13.09s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 5.6832	Cost: 14.40s
Train Epoch: 276 	Average Loss: 6.9340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9935

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 20.9902	Cost: 24.88s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 5.8582	Cost: 6.73s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 6.0770	Cost: 9.99s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 5.8428	Cost: 8.61s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 5.8635	Cost: 16.38s
Train Epoch: 277 	Average Loss: 6.9470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9821

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 21.0924	Cost: 25.66s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 6.0224	Cost: 6.39s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 5.8609	Cost: 10.56s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 5.8568	Cost: 6.15s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 5.8995	Cost: 18.59s
Train Epoch: 278 	Average Loss: 6.8974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0351

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 21.0649	Cost: 24.81s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 5.6668	Cost: 6.40s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 5.7988	Cost: 9.77s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 5.5632	Cost: 6.29s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 5.8316	Cost: 19.34s
Train Epoch: 279 	Average Loss: 6.7956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1953

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 20.9545	Cost: 23.82s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 5.7589	Cost: 6.43s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 5.6758	Cost: 10.12s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 5.6695	Cost: 6.30s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 5.5999	Cost: 12.35s
Train Epoch: 280 	Average Loss: 6.7846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1701

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 20.9311	Cost: 25.92s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 5.7338	Cost: 8.75s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 5.9007	Cost: 8.70s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 5.5051	Cost: 7.33s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 5.7834	Cost: 5.75s
Train Epoch: 281 	Average Loss: 6.7426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0646

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 20.8198	Cost: 25.93s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 5.7670	Cost: 6.29s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 5.6748	Cost: 9.61s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 5.3157	Cost: 8.33s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 5.6344	Cost: 8.28s
Train Epoch: 282 	Average Loss: 6.6807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1417

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 20.9490	Cost: 29.52s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 5.4500	Cost: 6.63s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 5.6914	Cost: 12.28s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 5.4003	Cost: 6.53s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 5.5016	Cost: 12.97s
Train Epoch: 283 	Average Loss: 6.6148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2015

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 21.0954	Cost: 28.33s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 5.6621	Cost: 11.57s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 5.4494	Cost: 7.51s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 5.6953	Cost: 6.85s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 5.7035	Cost: 12.24s
Train Epoch: 284 	Average Loss: 6.6593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1850

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 21.2589	Cost: 30.40s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 5.8046	Cost: 12.59s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 5.7176	Cost: 11.46s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 5.2629	Cost: 7.17s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 5.6363	Cost: 6.15s
Train Epoch: 285 	Average Loss: 6.6480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1642

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 20.9740	Cost: 31.08s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 5.6549	Cost: 15.04s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 5.5017	Cost: 15.28s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 5.4475	Cost: 10.10s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 5.4014	Cost: 6.07s
Train Epoch: 286 	Average Loss: 6.5873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1781

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 21.4124	Cost: 29.69s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 5.6150	Cost: 12.17s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 5.5037	Cost: 15.89s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 5.2114	Cost: 12.36s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 5.4177	Cost: 6.06s
Train Epoch: 287 	Average Loss: 6.5922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2404

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 21.2509	Cost: 27.08s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 5.4013	Cost: 8.13s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 5.8672	Cost: 15.80s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 5.0850	Cost: 13.97s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 5.4844	Cost: 8.99s
Train Epoch: 288 	Average Loss: 6.4965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2599

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 21.1595	Cost: 29.93s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 5.4239	Cost: 6.30s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 5.4683	Cost: 17.56s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 5.0897	Cost: 12.60s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 5.3769	Cost: 10.46s
Train Epoch: 289 	Average Loss: 6.4396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1244

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 21.0634	Cost: 35.87s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 5.3714	Cost: 6.47s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 5.2501	Cost: 16.42s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 5.2052	Cost: 12.15s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 5.2590	Cost: 11.46s
Train Epoch: 290 	Average Loss: 6.3629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2812

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 21.2230	Cost: 35.72s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 5.4523	Cost: 6.41s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 5.4508	Cost: 15.24s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 5.0157	Cost: 15.06s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 5.0421	Cost: 9.89s
Train Epoch: 291 	Average Loss: 6.3849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3344

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 21.1941	Cost: 42.98s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 5.4012	Cost: 14.99s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 5.3427	Cost: 13.98s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 5.1448	Cost: 7.49s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 5.0850	Cost: 6.27s
Train Epoch: 292 	Average Loss: 6.3150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3958

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 21.4102	Cost: 33.38s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 5.3364	Cost: 12.27s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 5.3252	Cost: 14.93s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 5.0481	Cost: 12.83s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 5.0651	Cost: 6.17s
Train Epoch: 293 	Average Loss: 6.3350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3744

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 21.2568	Cost: 32.78s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 5.0762	Cost: 10.05s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 5.4799	Cost: 15.16s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 4.7956	Cost: 14.84s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 5.2268	Cost: 5.95s
Train Epoch: 294 	Average Loss: 6.2708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4300

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 21.4073	Cost: 28.96s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 5.3487	Cost: 6.20s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 5.0858	Cost: 13.59s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 4.8482	Cost: 14.88s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 4.9975	Cost: 11.63s
Train Epoch: 295 	Average Loss: 6.2357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4122

Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 20.8908	Cost: 29.49s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 5.3736	Cost: 6.15s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 5.1478	Cost: 15.62s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 4.9900	Cost: 15.57s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 5.0881	Cost: 9.99s
Train Epoch: 296 	Average Loss: 6.2058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3883

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 21.5767	Cost: 29.99s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 5.0366	Cost: 6.26s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 5.3317	Cost: 13.30s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 5.0576	Cost: 14.95s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 5.0446	Cost: 11.97s
Train Epoch: 297 	Average Loss: 6.2317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4154

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 21.5843	Cost: 29.49s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 5.2861	Cost: 6.15s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 5.1256	Cost: 14.84s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 4.7924	Cost: 15.01s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 5.0983	Cost: 11.94s
Train Epoch: 298 	Average Loss: 6.1288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4335

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 21.3466	Cost: 28.91s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 5.2827	Cost: 6.15s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 5.2649	Cost: 15.02s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 4.8294	Cost: 15.22s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 5.1063	Cost: 10.03s
Train Epoch: 299 	Average Loss: 6.2010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5028

Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 21.5732	Cost: 25.99s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 5.2199	Cost: 6.24s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 5.1237	Cost: 13.12s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 4.8829	Cost: 15.21s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 5.0647	Cost: 12.93s
Train Epoch: 300 	Average Loss: 6.1570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4085

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 21.2331	Cost: 27.29s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 5.1495	Cost: 6.25s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 5.0657	Cost: 12.60s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 4.9002	Cost: 15.23s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 5.0369	Cost: 14.98s
Train Epoch: 301 	Average Loss: 6.0930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4589

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 21.3365	Cost: 27.83s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 5.1541	Cost: 6.48s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 5.1368	Cost: 16.22s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 4.7712	Cost: 14.73s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 4.7614	Cost: 12.05s
Train Epoch: 302 	Average Loss: 6.0686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5568

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 21.5736	Cost: 27.64s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 4.9352	Cost: 6.33s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 5.0646	Cost: 16.24s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 4.6285	Cost: 15.10s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 4.7121	Cost: 12.83s
Train Epoch: 303 	Average Loss: 6.0266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4308

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 20.9539	Cost: 39.65s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 5.0717	Cost: 15.24s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 5.0146	Cost: 15.87s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 4.8310	Cost: 9.09s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 4.9186	Cost: 5.99s
Train Epoch: 304 	Average Loss: 6.0622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4065

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 21.6069	Cost: 37.98s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 5.0198	Cost: 10.39s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 4.8877	Cost: 15.15s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 4.8256	Cost: 14.58s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 4.7889	Cost: 6.13s
Train Epoch: 305 	Average Loss: 6.0149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5608

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 21.4662	Cost: 36.08s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 4.9799	Cost: 13.14s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 4.8469	Cost: 15.07s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 4.6316	Cost: 11.70s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 4.6575	Cost: 6.10s
Train Epoch: 306 	Average Loss: 5.9255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5217

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 21.6689	Cost: 31.06s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 4.9623	Cost: 11.29s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 4.9234	Cost: 15.10s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 4.5378	Cost: 13.75s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 4.7023	Cost: 5.95s
Train Epoch: 307 	Average Loss: 5.8731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4902

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 21.8806	Cost: 31.66s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 4.7150	Cost: 9.26s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 5.0052	Cost: 15.32s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 4.7654	Cost: 15.14s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 4.5844	Cost: 6.40s
Train Epoch: 308 	Average Loss: 5.9049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6233

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 21.4361	Cost: 30.42s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 4.8410	Cost: 6.85s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 4.6498	Cost: 15.44s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 4.4262	Cost: 14.98s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 4.6285	Cost: 8.99s
Train Epoch: 309 	Average Loss: 5.8400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6384

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 21.2522	Cost: 29.52s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 4.8016	Cost: 7.97s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 4.5979	Cost: 15.61s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 4.5461	Cost: 15.14s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 4.6188	Cost: 8.04s
Train Epoch: 310 	Average Loss: 5.8144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5577

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 21.0821	Cost: 28.64s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 4.7824	Cost: 6.34s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 4.7519	Cost: 13.52s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 4.6307	Cost: 15.01s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 4.7078	Cost: 11.99s
Train Epoch: 311 	Average Loss: 5.8155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7058

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 21.5534	Cost: 28.74s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 4.7427	Cost: 6.78s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 4.6346	Cost: 14.70s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 4.5037	Cost: 13.81s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 4.5265	Cost: 12.07s
Train Epoch: 312 	Average Loss: 5.8171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6025

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 21.7191	Cost: 25.14s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 4.8509	Cost: 6.30s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 4.5879	Cost: 13.30s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 4.4318	Cost: 15.67s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 4.5818	Cost: 15.30s
Train Epoch: 313 	Average Loss: 5.7496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7176

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 21.8153	Cost: 27.34s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 4.6704	Cost: 6.25s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 4.4944	Cost: 15.34s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 4.4319	Cost: 14.58s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 4.5622	Cost: 14.81s
Train Epoch: 314 	Average Loss: 5.7301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6959

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 21.3754	Cost: 32.46s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 4.5423	Cost: 6.38s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 4.5196	Cost: 15.23s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 4.3790	Cost: 15.54s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 4.4263	Cost: 12.97s
Train Epoch: 315 	Average Loss: 5.6867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6532

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 21.7419	Cost: 34.10s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 4.7715	Cost: 6.98s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 4.6413	Cost: 10.61s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 4.2860	Cost: 13.10s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 4.5744	Cost: 14.95s
Train Epoch: 316 	Average Loss: 5.7230
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6685

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 21.6033	Cost: 42.86s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 4.6442	Cost: 6.26s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 4.6644	Cost: 15.51s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 4.0858	Cost: 14.63s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 4.3701	Cost: 10.41s
Train Epoch: 317 	Average Loss: 5.6163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6173

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 21.8925	Cost: 33.54s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 4.5369	Cost: 6.34s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 4.5083	Cost: 16.16s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 4.2759	Cost: 14.92s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 4.3765	Cost: 8.83s
Train Epoch: 318 	Average Loss: 5.5829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7460

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 21.6928	Cost: 32.02s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 4.5015	Cost: 6.40s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 4.4090	Cost: 15.38s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 4.1342	Cost: 14.89s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 4.3271	Cost: 9.80s
Train Epoch: 319 	Average Loss: 5.5570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7780

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 21.4438	Cost: 31.60s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 4.5557	Cost: 6.39s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 4.6117	Cost: 14.51s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 4.0387	Cost: 14.63s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 4.4149	Cost: 10.98s
Train Epoch: 320 	Average Loss: 5.5560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6221

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 21.6923	Cost: 30.77s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 4.4187	Cost: 6.08s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 4.4656	Cost: 15.21s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 3.9974	Cost: 15.72s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 4.6020	Cost: 9.90s
Train Epoch: 321 	Average Loss: 5.5259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7508

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 21.5033	Cost: 28.72s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 4.3437	Cost: 6.19s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 4.3752	Cost: 13.52s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 4.1714	Cost: 14.96s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 4.3058	Cost: 11.61s
Train Epoch: 322 	Average Loss: 5.4498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8447

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 21.8136	Cost: 29.78s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 4.3764	Cost: 6.27s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 4.5104	Cost: 15.42s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 4.1066	Cost: 15.41s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 4.2632	Cost: 9.90s
Train Epoch: 323 	Average Loss: 5.4702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8203

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 22.0247	Cost: 30.13s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 4.1006	Cost: 6.12s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 4.5318	Cost: 15.24s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 4.2357	Cost: 15.14s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 4.1609	Cost: 10.72s
Train Epoch: 324 	Average Loss: 5.4659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9713

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 21.5845	Cost: 29.12s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 4.4407	Cost: 6.36s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 4.5822	Cost: 14.87s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 4.1240	Cost: 15.04s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 4.3327	Cost: 11.79s
Train Epoch: 325 	Average Loss: 5.4499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9674

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 21.6352	Cost: 29.68s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 4.0898	Cost: 6.05s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 4.3284	Cost: 15.32s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 3.8565	Cost: 15.67s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 4.2271	Cost: 9.31s
Train Epoch: 326 	Average Loss: 5.3740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9751

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 21.8541	Cost: 29.69s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 4.2184	Cost: 6.36s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 4.4801	Cost: 13.43s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 3.8145	Cost: 15.10s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 4.0364	Cost: 11.90s
Train Epoch: 327 	Average Loss: 5.3300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9075

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 21.5356	Cost: 30.17s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 4.0321	Cost: 8.28s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 4.3561	Cost: 15.44s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 3.9205	Cost: 15.30s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 4.0007	Cost: 7.79s
Train Epoch: 328 	Average Loss: 5.3420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8108

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 21.9772	Cost: 30.99s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 4.1316	Cost: 12.39s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 4.4000	Cost: 15.37s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 3.8447	Cost: 12.94s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 4.1447	Cost: 5.98s
Train Epoch: 329 	Average Loss: 5.3140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9270

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 21.5295	Cost: 32.81s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 4.2530	Cost: 6.30s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 4.2116	Cost: 15.03s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 3.8732	Cost: 15.09s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 4.0009	Cost: 10.45s
Train Epoch: 330 	Average Loss: 5.2429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0153

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 21.5252	Cost: 40.26s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 3.9644	Cost: 12.24s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 4.1690	Cost: 15.07s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 3.6957	Cost: 12.88s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 4.0721	Cost: 5.94s
Train Epoch: 331 	Average Loss: 5.2851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9465

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 21.7287	Cost: 35.54s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 4.0509	Cost: 7.22s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 4.1128	Cost: 15.19s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 3.7078	Cost: 14.93s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 3.9003	Cost: 8.89s
Train Epoch: 332 	Average Loss: 5.2283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0380

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 21.7481	Cost: 35.81s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 4.0829	Cost: 8.27s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 4.2163	Cost: 15.22s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 3.8634	Cost: 14.92s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 4.0987	Cost: 7.74s
Train Epoch: 333 	Average Loss: 5.2068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0101

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 21.9634	Cost: 33.02s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 3.8490	Cost: 7.97s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 4.0936	Cost: 15.45s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 3.8321	Cost: 15.81s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 3.9035	Cost: 6.89s
Train Epoch: 334 	Average Loss: 5.1781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0062

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 21.8978	Cost: 34.30s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 4.0225	Cost: 8.30s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 4.0998	Cost: 15.10s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 3.7586	Cost: 14.65s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 4.0859	Cost: 8.01s
Train Epoch: 335 	Average Loss: 5.2061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0756

Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 21.7957	Cost: 30.25s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 3.8074	Cost: 6.34s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 4.1386	Cost: 14.96s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 3.7107	Cost: 14.20s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 3.9463	Cost: 10.68s
Train Epoch: 336 	Average Loss: 5.1128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9756

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 22.0146	Cost: 27.65s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 3.8577	Cost: 6.32s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 4.1546	Cost: 13.49s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 3.7460	Cost: 14.76s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 3.7659	Cost: 13.66s
Train Epoch: 337 	Average Loss: 5.1480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0284

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 21.8371	Cost: 24.83s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 4.0139	Cost: 6.59s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 4.0341	Cost: 9.97s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 3.6358	Cost: 8.77s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 3.6890	Cost: 16.58s
Train Epoch: 338 	Average Loss: 5.0780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0776

Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 21.4780	Cost: 26.42s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 3.7512	Cost: 6.74s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 4.0921	Cost: 10.56s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 3.7233	Cost: 7.56s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 3.7261	Cost: 17.49s
Train Epoch: 339 	Average Loss: 5.0330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0028

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 21.9237	Cost: 23.67s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 3.7871	Cost: 6.69s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 4.0066	Cost: 8.97s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 3.6086	Cost: 6.19s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 3.6858	Cost: 18.43s
Train Epoch: 340 	Average Loss: 5.0273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1763

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 21.8097	Cost: 26.43s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 3.8490	Cost: 6.51s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 4.0264	Cost: 9.72s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 3.6156	Cost: 6.33s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 3.8634	Cost: 11.46s
Train Epoch: 341 	Average Loss: 4.9902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1373

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 22.0643	Cost: 27.21s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 3.7160	Cost: 8.93s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 3.9765	Cost: 8.94s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 3.6753	Cost: 7.30s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 3.5788	Cost: 6.41s
Train Epoch: 342 	Average Loss: 4.9779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1370

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 21.7775	Cost: 26.37s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 3.7184	Cost: 7.19s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 3.8517	Cost: 8.77s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 3.6166	Cost: 8.52s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 3.5391	Cost: 8.37s
Train Epoch: 343 	Average Loss: 4.9730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0551

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 22.1448	Cost: 29.01s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 3.7767	Cost: 6.62s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 3.9717	Cost: 11.62s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 3.3690	Cost: 6.22s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 3.8808	Cost: 13.45s
Train Epoch: 344 	Average Loss: 4.9658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0537

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 22.0577	Cost: 27.29s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 3.6488	Cost: 11.66s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 3.9589	Cost: 7.37s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 3.2794	Cost: 6.19s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 3.5465	Cost: 10.79s
Train Epoch: 345 	Average Loss: 4.9178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1217

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 21.9811	Cost: 29.56s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 3.7350	Cost: 14.59s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 3.7149	Cost: 12.89s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 3.4964	Cost: 6.35s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 3.4754	Cost: 6.19s
Train Epoch: 346 	Average Loss: 4.9037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0973

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 21.8881	Cost: 26.58s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 3.7535	Cost: 10.56s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 3.6612	Cost: 15.60s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 3.4939	Cost: 14.08s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 3.6173	Cost: 6.22s
Train Epoch: 347 	Average Loss: 4.8831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1204

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 21.8770	Cost: 30.13s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 3.8134	Cost: 6.30s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 3.7499	Cost: 14.74s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 3.3898	Cost: 15.46s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 3.5556	Cost: 10.22s
Train Epoch: 348 	Average Loss: 4.8747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1394

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 21.8772	Cost: 29.37s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 3.6015	Cost: 6.54s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 3.6244	Cost: 14.76s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 3.4122	Cost: 14.10s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 3.6084	Cost: 11.64s
Train Epoch: 349 	Average Loss: 4.8449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2334

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 22.1029	Cost: 26.47s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 3.6275	Cost: 6.30s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 3.7812	Cost: 15.35s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 3.4270	Cost: 15.39s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 3.6510	Cost: 12.06s
Train Epoch: 350 	Average Loss: 4.8286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1098

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 22.1525	Cost: 31.38s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 3.6233	Cost: 6.88s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 4.1333	Cost: 16.08s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 3.3876	Cost: 15.55s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 3.6272	Cost: 11.92s
Train Epoch: 351 	Average Loss: 4.8376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1714

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 21.8643	Cost: 33.80s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 3.4340	Cost: 6.57s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 3.6358	Cost: 15.42s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 3.4384	Cost: 15.16s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 3.3638	Cost: 10.45s
Train Epoch: 352 	Average Loss: 4.8011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3341

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 22.1245	Cost: 33.98s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 3.6819	Cost: 6.27s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 3.6155	Cost: 10.72s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 3.3920	Cost: 11.31s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 3.3713	Cost: 14.75s
Train Epoch: 353 	Average Loss: 4.8109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2301

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 21.8682	Cost: 32.96s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 3.5410	Cost: 7.64s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 3.4223	Cost: 15.04s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 3.4174	Cost: 15.81s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 3.4884	Cost: 14.98s
Train Epoch: 354 	Average Loss: 4.7507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1899

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 21.6740	Cost: 44.04s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 3.4971	Cost: 15.65s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 3.7187	Cost: 15.12s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 3.3208	Cost: 8.68s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 3.5229	Cost: 6.10s
Train Epoch: 355 	Average Loss: 4.7506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2254

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 22.2516	Cost: 35.65s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 3.4383	Cost: 12.34s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 3.6720	Cost: 15.80s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 3.2978	Cost: 11.90s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 3.3576	Cost: 6.09s
Train Epoch: 356 	Average Loss: 4.7562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2681

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 21.9492	Cost: 32.43s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 3.5142	Cost: 7.52s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 3.4912	Cost: 15.59s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 3.2485	Cost: 14.81s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 3.5340	Cost: 8.10s
Train Epoch: 357 	Average Loss: 4.7174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3021

Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 22.1876	Cost: 30.73s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 3.3168	Cost: 6.16s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 3.5575	Cost: 15.23s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 3.1662	Cost: 14.62s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 3.4198	Cost: 10.11s
Train Epoch: 358 	Average Loss: 4.7197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3605

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 21.8138	Cost: 28.54s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 3.4261	Cost: 6.17s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 3.8171	Cost: 15.19s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 3.2253	Cost: 14.89s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 3.4012	Cost: 9.65s
Train Epoch: 359 	Average Loss: 4.7093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2421

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 22.1484	Cost: 26.63s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 3.7227	Cost: 6.23s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 3.4340	Cost: 15.54s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 3.1625	Cost: 14.44s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 3.4197	Cost: 14.28s
Train Epoch: 360 	Average Loss: 4.6769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2401

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 21.9570	Cost: 29.68s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 3.4405	Cost: 6.17s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 3.4345	Cost: 15.46s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 3.2599	Cost: 14.68s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 3.4177	Cost: 10.34s
Train Epoch: 361 	Average Loss: 4.6682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2226

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 22.2409	Cost: 29.92s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 3.4245	Cost: 6.18s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 3.5116	Cost: 15.13s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 3.1470	Cost: 15.13s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 3.1734	Cost: 10.07s
Train Epoch: 362 	Average Loss: 4.6659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2891

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 22.1924	Cost: 29.37s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 3.4911	Cost: 6.30s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 3.4147	Cost: 14.64s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 3.1616	Cost: 15.17s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 3.3134	Cost: 10.69s
Train Epoch: 363 	Average Loss: 4.6707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2787

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 22.0832	Cost: 30.16s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 3.5326	Cost: 7.32s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 3.5750	Cost: 15.34s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 3.0143	Cost: 15.36s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 3.1181	Cost: 8.34s
Train Epoch: 364 	Average Loss: 4.6498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2946

Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 22.0007	Cost: 29.81s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 3.2910	Cost: 9.58s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 3.4840	Cost: 15.12s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 3.1208	Cost: 15.12s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 3.1790	Cost: 6.85s
Train Epoch: 365 	Average Loss: 4.6221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2659

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 22.0380	Cost: 31.55s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 3.4071	Cost: 8.31s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 3.3459	Cost: 16.07s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 3.4169	Cost: 14.90s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 3.3074	Cost: 7.76s
Train Epoch: 366 	Average Loss: 4.6304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3201

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 21.5237	Cost: 43.24s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 3.2709	Cost: 15.27s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 3.3025	Cost: 15.13s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 3.3695	Cost: 8.41s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 3.3419	Cost: 6.69s
Train Epoch: 367 	Average Loss: 4.5785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3207

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 21.7872	Cost: 34.45s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 3.2694	Cost: 6.26s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 3.3872	Cost: 14.86s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 3.1491	Cost: 14.98s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 3.4115	Cost: 10.12s
Train Epoch: 368 	Average Loss: 4.6216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2518

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 21.9584	Cost: 40.05s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 3.3783	Cost: 6.19s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 3.2496	Cost: 15.40s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 3.1007	Cost: 14.86s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 3.4715	Cost: 9.53s
Train Epoch: 369 	Average Loss: 4.5814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2562

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 22.0185	Cost: 32.17s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 3.5324	Cost: 6.26s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 3.4886	Cost: 15.22s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 3.1619	Cost: 14.22s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 3.0836	Cost: 10.67s
Train Epoch: 370 	Average Loss: 4.5827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2299

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 21.9644	Cost: 31.61s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 3.2980	Cost: 6.13s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 3.3181	Cost: 14.82s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 3.1419	Cost: 14.75s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 3.0237	Cost: 10.46s
Train Epoch: 371 	Average Loss: 4.5703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1886

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 22.0192	Cost: 27.22s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 3.4311	Cost: 6.24s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 3.2862	Cost: 13.93s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 2.9937	Cost: 15.28s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 3.2679	Cost: 13.22s
Train Epoch: 372 	Average Loss: 4.5647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3522

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 22.2066	Cost: 28.75s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 3.4609	Cost: 6.17s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 3.6477	Cost: 15.99s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 3.0654	Cost: 14.99s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 3.2536	Cost: 9.85s
Train Epoch: 373 	Average Loss: 4.5868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4114

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 22.0601	Cost: 28.09s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 3.3122	Cost: 6.41s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 3.2725	Cost: 14.29s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 3.0648	Cost: 15.66s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 3.0998	Cost: 15.05s
Train Epoch: 374 	Average Loss: 4.5698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3058

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 22.1406	Cost: 26.99s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 3.2090	Cost: 6.55s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 3.3342	Cost: 9.77s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 3.0015	Cost: 15.06s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 3.0680	Cost: 15.95s
Train Epoch: 375 	Average Loss: 4.5450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3698

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 22.3407	Cost: 27.66s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 3.2933	Cost: 6.36s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 3.4504	Cost: 15.64s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 3.0437	Cost: 14.70s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 3.1821	Cost: 14.06s
Train Epoch: 376 	Average Loss: 4.5444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3589

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 21.6835	Cost: 25.49s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 3.4873	Cost: 6.17s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 3.2008	Cost: 15.09s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 2.9479	Cost: 14.46s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 3.1077	Cost: 14.56s
Train Epoch: 377 	Average Loss: 4.5392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3214

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 22.3664	Cost: 28.37s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 3.1768	Cost: 6.41s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 3.4762	Cost: 15.25s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 3.0913	Cost: 13.19s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 3.2341	Cost: 12.12s
Train Epoch: 378 	Average Loss: 4.5364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3072

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 22.0921	Cost: 28.23s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 3.0719	Cost: 6.24s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 3.2822	Cost: 14.79s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 3.0203	Cost: 15.10s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 3.2765	Cost: 11.99s
Train Epoch: 379 	Average Loss: 4.5259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3205

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 22.0684	Cost: 27.18s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 3.4140	Cost: 6.28s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 3.5179	Cost: 13.91s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 3.0146	Cost: 14.78s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 3.3534	Cost: 11.96s
Train Epoch: 380 	Average Loss: 4.5257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4542

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 21.9017	Cost: 29.83s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 3.1483	Cost: 6.35s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 3.2624	Cost: 16.05s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 3.1105	Cost: 12.84s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 3.0417	Cost: 11.98s
Train Epoch: 381 	Average Loss: 4.5318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4093

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 21.9063	Cost: 27.25s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 3.1733	Cost: 6.53s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 3.4401	Cost: 15.85s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 3.1022	Cost: 15.75s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 3.3974	Cost: 12.12s
Train Epoch: 382 	Average Loss: 4.4955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3650

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 22.0477	Cost: 31.55s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 3.3730	Cost: 6.32s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 3.3387	Cost: 16.38s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 2.8525	Cost: 11.83s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 3.1081	Cost: 12.13s
Train Epoch: 383 	Average Loss: 4.5298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2945

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 22.0638	Cost: 39.40s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 3.3678	Cost: 12.25s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 3.4400	Cost: 15.20s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 2.9532	Cost: 12.68s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 3.2371	Cost: 5.96s
Train Epoch: 384 	Average Loss: 4.5193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3685

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 22.1776	Cost: 38.24s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 3.2439	Cost: 7.39s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 3.5747	Cost: 15.84s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 2.9656	Cost: 14.54s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 3.1950	Cost: 8.32s
Train Epoch: 385 	Average Loss: 4.5279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2858

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 21.9831	Cost: 31.43s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 3.3920	Cost: 8.24s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 3.3009	Cost: 15.36s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 2.9287	Cost: 15.53s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 3.1449	Cost: 7.11s
Train Epoch: 386 	Average Loss: 4.5120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3269

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 22.2933	Cost: 31.04s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 3.3298	Cost: 6.29s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 3.3993	Cost: 13.14s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 3.2120	Cost: 14.93s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 3.4767	Cost: 11.79s
Train Epoch: 387 	Average Loss: 4.5223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2490

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 22.5438	Cost: 27.40s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 3.3398	Cost: 6.35s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 3.1929	Cost: 15.78s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 2.9654	Cost: 14.89s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 3.1041	Cost: 13.97s
Train Epoch: 388 	Average Loss: 4.5258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2806

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 22.2369	Cost: 24.81s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 3.2980	Cost: 6.34s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 3.5132	Cost: 9.63s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 2.8184	Cost: 14.91s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 3.3027	Cost: 14.26s
Train Epoch: 389 	Average Loss: 4.5170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3983

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 22.3127	Cost: 28.03s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 3.2178	Cost: 6.53s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 3.1633	Cost: 11.57s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 2.9983	Cost: 14.35s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 2.9604	Cost: 14.69s
Train Epoch: 390 	Average Loss: 4.5101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3133

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 22.4178	Cost: 27.04s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 3.0899	Cost: 6.38s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 3.2646	Cost: 13.69s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 3.2256	Cost: 14.96s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 3.2566	Cost: 15.23s
Train Epoch: 391 	Average Loss: 4.4957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2547

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 22.3333	Cost: 26.58s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 3.2223	Cost: 6.53s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 3.2890	Cost: 11.45s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 2.9758	Cost: 14.83s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 3.2010	Cost: 15.16s
Train Epoch: 392 	Average Loss: 4.4969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3904

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 22.0059	Cost: 29.57s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 3.3210	Cost: 6.36s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 3.2900	Cost: 14.32s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 2.9087	Cost: 15.65s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 3.2855	Cost: 14.92s
Train Epoch: 393 	Average Loss: 4.4888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3601

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 22.0415	Cost: 28.56s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 3.2723	Cost: 6.29s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 3.2652	Cost: 13.51s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 2.9008	Cost: 15.03s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 3.1790	Cost: 13.91s
Train Epoch: 394 	Average Loss: 4.4705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3633

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 21.9704	Cost: 28.64s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 3.4925	Cost: 6.35s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 3.2581	Cost: 13.37s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 3.1501	Cost: 15.20s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 3.1719	Cost: 11.77s
Train Epoch: 395 	Average Loss: 4.4822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3018

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 21.9146	Cost: 30.39s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 3.1844	Cost: 6.16s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 3.2045	Cost: 14.43s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 2.9844	Cost: 14.03s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 3.0358	Cost: 12.00s
Train Epoch: 396 	Average Loss: 4.4911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3740

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 22.1236	Cost: 30.81s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 3.2046	Cost: 6.30s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 3.0579	Cost: 16.34s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 3.1311	Cost: 11.98s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 3.3326	Cost: 11.89s
Train Epoch: 397 	Average Loss: 4.5118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4334

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 21.9871	Cost: 29.03s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 3.2435	Cost: 6.31s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 3.5054	Cost: 17.20s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 3.0625	Cost: 13.66s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 3.2088	Cost: 11.22s
Train Epoch: 398 	Average Loss: 4.5004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3477

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 21.9164	Cost: 31.79s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 3.0678	Cost: 7.45s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 3.3096	Cost: 13.35s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 2.8804	Cost: 14.98s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 3.1025	Cost: 11.83s
Train Epoch: 399 	Average Loss: 4.4952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2946

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 22.3779	Cost: 34.56s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 3.2556	Cost: 6.38s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 3.3380	Cost: 14.62s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 2.9973	Cost: 15.04s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 3.1332	Cost: 10.38s
Train Epoch: 400 	Average Loss: 4.4887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4114

Stopping timer.
Training time (including validation): 283329.49710178375 seconds
Saving model
Transfer learning by starting with alpha=0.05!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 26.4537	Cost: 44.54s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 22.6990	Cost: 13.80s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.4472	Cost: 9.76s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 20.4511	Cost: 8.25s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.1527	Cost: 6.07s
Train Epoch: 1 	Average Loss: 21.7118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1171

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 19.8551	Cost: 35.10s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 19.0244	Cost: 15.46s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 18.7144	Cost: 15.65s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 18.8622	Cost: 8.96s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 18.4176	Cost: 6.08s
Train Epoch: 2 	Average Loss: 18.9613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9405

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 18.7201	Cost: 29.47s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 18.1496	Cost: 8.64s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.1180	Cost: 14.78s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 17.9179	Cost: 14.89s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 17.8167	Cost: 7.99s
Train Epoch: 3 	Average Loss: 18.1401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4692

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 18.2977	Cost: 32.21s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 17.7717	Cost: 6.55s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 17.7040	Cost: 13.61s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 17.6644	Cost: 15.10s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 17.6185	Cost: 13.74s
Train Epoch: 4 	Average Loss: 17.7411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1388

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 17.9724	Cost: 26.57s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 17.4143	Cost: 6.59s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.4217	Cost: 9.08s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 17.5372	Cost: 11.25s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 17.4455	Cost: 14.37s
Train Epoch: 5 	Average Loss: 17.4757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9289

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 17.9635	Cost: 25.19s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 17.0546	Cost: 6.43s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 17.2692	Cost: 11.75s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 17.2370	Cost: 6.05s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 17.1715	Cost: 18.50s
Train Epoch: 6 	Average Loss: 17.2454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8140

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 17.6919	Cost: 24.30s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 17.0358	Cost: 6.53s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 17.2639	Cost: 12.95s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 17.1257	Cost: 6.17s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 17.1111	Cost: 19.15s
Train Epoch: 7 	Average Loss: 17.1068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8285

Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 17.6330	Cost: 21.70s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 16.7240	Cost: 6.54s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 16.8843	Cost: 9.74s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 16.9808	Cost: 6.42s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 17.0420	Cost: 11.90s
Train Epoch: 8 	Average Loss: 16.9998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7515

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 17.6662	Cost: 26.01s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 16.8716	Cost: 8.80s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 16.9780	Cost: 8.77s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 16.8019	Cost: 8.58s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 16.8551	Cost: 8.04s
Train Epoch: 9 	Average Loss: 16.9055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7504

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 17.7445	Cost: 27.22s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 16.7218	Cost: 6.26s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 16.7749	Cost: 9.31s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 16.7720	Cost: 6.15s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 16.5326	Cost: 10.03s
Train Epoch: 10 	Average Loss: 16.7706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7346

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 17.7678	Cost: 30.19s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 16.6264	Cost: 7.23s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 16.7431	Cost: 11.02s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 16.8591	Cost: 6.03s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 16.6975	Cost: 5.99s
Train Epoch: 11 	Average Loss: 16.6837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8127

Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 17.8890	Cost: 36.51s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 16.5022	Cost: 11.51s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 16.4087	Cost: 15.74s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 16.4643	Cost: 13.08s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 16.4385	Cost: 5.91s
Train Epoch: 12 	Average Loss: 16.5835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7689

Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 17.8353	Cost: 36.19s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 16.3338	Cost: 6.42s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 16.5306	Cost: 14.29s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 16.5170	Cost: 15.19s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 16.5109	Cost: 13.62s
Train Epoch: 13 	Average Loss: 16.5438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8593

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 17.8105	Cost: 29.51s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 16.3065	Cost: 6.44s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 16.3857	Cost: 11.41s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 16.4029	Cost: 10.87s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 16.3419	Cost: 14.99s
Train Epoch: 14 	Average Loss: 16.4591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8213

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 17.7245	Cost: 28.15s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 16.3598	Cost: 6.37s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 16.4073	Cost: 12.53s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 16.2643	Cost: 6.30s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 16.4808	Cost: 20.37s
Train Epoch: 15 	Average Loss: 16.3740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8612

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 17.9078	Cost: 25.85s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 16.3050	Cost: 6.31s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 16.1603	Cost: 11.18s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 16.1509	Cost: 6.40s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 16.1063	Cost: 20.19s
Train Epoch: 16 	Average Loss: 16.2831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9256

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 17.6496	Cost: 25.43s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 16.0807	Cost: 6.28s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 15.9844	Cost: 8.43s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 16.1361	Cost: 6.20s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 16.0999	Cost: 9.99s
Train Epoch: 17 	Average Loss: 16.2260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9472

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 17.8426	Cost: 28.99s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 16.0271	Cost: 6.86s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 16.1408	Cost: 9.49s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 16.2721	Cost: 8.57s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 16.0945	Cost: 8.39s
Train Epoch: 18 	Average Loss: 16.1824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8874

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 18.0936	Cost: 30.59s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 16.0477	Cost: 7.61s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 16.0146	Cost: 6.62s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 15.9679	Cost: 6.26s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 16.0051	Cost: 9.39s
Train Epoch: 19 	Average Loss: 16.1186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0436

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 18.0092	Cost: 30.56s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 15.8076	Cost: 15.38s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 16.0536	Cost: 10.03s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 15.8953	Cost: 10.15s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 15.9241	Cost: 5.85s
Train Epoch: 20 	Average Loss: 16.0569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0107

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 17.9958	Cost: 41.12s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 15.9622	Cost: 6.85s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 16.0297	Cost: 14.36s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 16.0536	Cost: 14.80s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 15.8143	Cost: 10.94s
Train Epoch: 21 	Average Loss: 16.0179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1670

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 18.0313	Cost: 28.65s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 15.6486	Cost: 6.71s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 15.8292	Cost: 9.33s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 15.8628	Cost: 13.46s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 15.9208	Cost: 15.51s
Train Epoch: 22 	Average Loss: 15.9346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2011

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 18.1723	Cost: 27.82s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 15.7403	Cost: 6.39s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 15.7586	Cost: 10.73s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 15.8224	Cost: 6.28s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 15.7213	Cost: 18.32s
Train Epoch: 23 	Average Loss: 15.8659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3084

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 18.0482	Cost: 26.34s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 15.6927	Cost: 6.25s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 15.7806	Cost: 9.88s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 15.7732	Cost: 6.48s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 15.7038	Cost: 12.30s
Train Epoch: 24 	Average Loss: 15.8347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3831

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 18.2123	Cost: 28.31s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 15.6212	Cost: 8.76s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 15.6973	Cost: 8.93s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 15.5880	Cost: 8.53s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 15.7999	Cost: 8.43s
Train Epoch: 25 	Average Loss: 15.7722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3841

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 18.1812	Cost: 27.22s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 15.4621	Cost: 6.32s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 15.4784	Cost: 8.78s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 15.4352	Cost: 6.13s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 15.6728	Cost: 10.26s
Train Epoch: 26 	Average Loss: 15.6785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5099

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 18.3689	Cost: 33.14s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 15.5088	Cost: 8.09s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 15.4904	Cost: 9.97s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 15.3700	Cost: 5.93s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 15.3370	Cost: 8.59s
Train Epoch: 27 	Average Loss: 15.6306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5252

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 18.4334	Cost: 34.77s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 15.4139	Cost: 8.38s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 15.7117	Cost: 15.26s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 15.5404	Cost: 15.14s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 15.3835	Cost: 7.62s
Train Epoch: 28 	Average Loss: 15.6278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5641

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 18.4217	Cost: 37.53s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 15.4236	Cost: 6.43s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 15.3207	Cost: 14.16s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 15.4106	Cost: 14.79s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 15.2561	Cost: 12.80s
Train Epoch: 29 	Average Loss: 15.5497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6527

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 18.3081	Cost: 33.11s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 15.2142	Cost: 6.54s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 15.2525	Cost: 14.35s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 15.2829	Cost: 15.35s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 15.3859	Cost: 15.30s
Train Epoch: 30 	Average Loss: 15.4723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6152

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 18.3865	Cost: 27.98s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 15.2681	Cost: 6.43s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 15.2849	Cost: 12.23s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 15.2279	Cost: 9.31s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 15.2126	Cost: 15.98s
Train Epoch: 31 	Average Loss: 15.4423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6715

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 18.6778	Cost: 25.01s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 15.1408	Cost: 6.39s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 15.1380	Cost: 11.12s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 15.1673	Cost: 6.18s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 15.1349	Cost: 15.09s
Train Epoch: 32 	Average Loss: 15.4027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7694

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 18.7172	Cost: 25.61s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 15.0927	Cost: 8.98s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 15.2349	Cost: 7.63s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 15.1966	Cost: 6.25s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 15.1366	Cost: 6.47s
Train Epoch: 33 	Average Loss: 15.3573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7630

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 18.5176	Cost: 25.10s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 15.0684	Cost: 6.14s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 15.2941	Cost: 9.22s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 15.0803	Cost: 8.55s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 15.0361	Cost: 8.30s
Train Epoch: 34 	Average Loss: 15.3518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7889

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 18.7050	Cost: 29.78s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 15.0871	Cost: 9.84s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 15.2642	Cost: 6.26s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 15.0046	Cost: 6.07s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 15.1454	Cost: 7.13s
Train Epoch: 35 	Average Loss: 15.2695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8122

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 18.8870	Cost: 41.72s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 14.9455	Cost: 9.98s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 15.1601	Cost: 6.23s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 14.8862	Cost: 12.06s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 14.9612	Cost: 5.95s
Train Epoch: 36 	Average Loss: 15.2580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8994

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 18.7997	Cost: 46.58s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 14.7763	Cost: 6.37s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 15.0237	Cost: 13.32s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 14.8615	Cost: 14.73s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 14.7412	Cost: 11.92s
Train Epoch: 37 	Average Loss: 15.1597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9210

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 18.7657	Cost: 32.36s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 14.6492	Cost: 6.53s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 14.8824	Cost: 13.67s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 14.8684	Cost: 15.12s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 14.8570	Cost: 14.75s
Train Epoch: 38 	Average Loss: 15.0852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9736

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 18.6891	Cost: 29.11s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 14.7771	Cost: 6.58s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 14.7636	Cost: 10.62s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 14.7870	Cost: 11.34s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 14.9787	Cost: 15.26s
Train Epoch: 39 	Average Loss: 15.0528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9587

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 19.0915	Cost: 23.39s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 14.7095	Cost: 6.43s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 14.7708	Cost: 10.54s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 14.8339	Cost: 6.20s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 14.8449	Cost: 12.17s
Train Epoch: 40 	Average Loss: 15.0206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0269

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 18.9194	Cost: 25.87s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 14.6540	Cost: 8.94s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 14.8097	Cost: 8.70s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 14.8676	Cost: 7.66s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 14.9860	Cost: 6.09s
Train Epoch: 41 	Average Loss: 15.0347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0638

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 18.6961	Cost: 25.42s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 14.6089	Cost: 7.01s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 14.7500	Cost: 8.79s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 14.7090	Cost: 8.60s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 14.7233	Cost: 8.52s
Train Epoch: 42 	Average Loss: 15.0006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0888

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 18.9199	Cost: 28.24s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 14.6659	Cost: 12.07s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 14.6578	Cost: 6.05s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 14.7437	Cost: 6.04s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 14.5072	Cost: 6.08s
Train Epoch: 43 	Average Loss: 14.8851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1272

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 18.9819	Cost: 39.23s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 14.4789	Cost: 8.64s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 14.6070	Cost: 15.67s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 14.5225	Cost: 14.89s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 14.7225	Cost: 7.00s
Train Epoch: 44 	Average Loss: 14.8485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2390

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 18.8723	Cost: 36.40s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 14.3618	Cost: 6.68s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 14.6918	Cost: 11.65s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 14.6703	Cost: 14.82s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 14.5569	Cost: 15.26s
Train Epoch: 45 	Average Loss: 14.8614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2117

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 19.1638	Cost: 24.70s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 14.4861	Cost: 6.40s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 14.5449	Cost: 9.28s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 14.6614	Cost: 6.25s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 14.1994	Cost: 14.49s
Train Epoch: 46 	Average Loss: 14.7919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1971

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 19.1755	Cost: 27.64s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 14.5283	Cost: 8.82s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 14.6848	Cost: 8.90s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 14.4367	Cost: 7.91s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 14.3765	Cost: 6.10s
Train Epoch: 47 	Average Loss: 14.7910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2807

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 18.9797	Cost: 25.50s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 14.6020	Cost: 6.19s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 14.4229	Cost: 9.21s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 14.5208	Cost: 8.47s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 14.4312	Cost: 8.70s
Train Epoch: 48 	Average Loss: 14.8081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1571

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 18.9265	Cost: 26.10s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 14.4674	Cost: 12.08s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 14.5752	Cost: 6.22s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 14.4047	Cost: 6.17s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 14.4524	Cost: 6.17s
Train Epoch: 49 	Average Loss: 14.7834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2532

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 19.0381	Cost: 38.51s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 14.3023	Cost: 7.47s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 14.2589	Cost: 15.82s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 14.4115	Cost: 14.44s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 14.2598	Cost: 8.84s
Train Epoch: 50 	Average Loss: 14.6329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2281

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 18.9145	Cost: 38.77s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 14.2028	Cost: 6.42s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 14.3958	Cost: 14.47s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 14.1897	Cost: 15.25s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 14.1795	Cost: 10.45s
Train Epoch: 51 	Average Loss: 14.5776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2190

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 19.0930	Cost: 29.70s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 14.1578	Cost: 6.75s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 14.3567	Cost: 10.13s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 14.2551	Cost: 14.83s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 14.0908	Cost: 15.20s
Train Epoch: 52 	Average Loss: 14.5367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3084

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 19.0953	Cost: 28.63s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 14.0676	Cost: 6.61s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 14.1547	Cost: 10.48s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 14.2288	Cost: 7.92s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 14.0147	Cost: 17.51s
Train Epoch: 53 	Average Loss: 14.4755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3859

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 19.1362	Cost: 23.76s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 14.0850	Cost: 6.54s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 14.4068	Cost: 11.27s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 13.9902	Cost: 6.29s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 14.2106	Cost: 11.62s
Train Epoch: 54 	Average Loss: 14.4660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4466

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 19.3488	Cost: 26.90s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 14.2566	Cost: 8.79s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 14.3264	Cost: 8.83s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 14.1377	Cost: 8.69s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 14.1742	Cost: 7.88s
Train Epoch: 55 	Average Loss: 14.5353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2745

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 19.3959	Cost: 25.87s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 14.1458	Cost: 6.18s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 14.2565	Cost: 8.52s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 13.9979	Cost: 6.63s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 14.1022	Cost: 8.73s
Train Epoch: 56 	Average Loss: 14.4610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4502

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 19.1655	Cost: 32.29s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 14.1253	Cost: 8.87s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 14.1785	Cost: 9.32s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 14.3215	Cost: 5.90s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 13.9080	Cost: 6.67s
Train Epoch: 57 	Average Loss: 14.4221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3912

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 19.2505	Cost: 36.00s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 13.9903	Cost: 6.26s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 14.0973	Cost: 14.24s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 14.0192	Cost: 14.06s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 13.8277	Cost: 11.84s
Train Epoch: 58 	Average Loss: 14.3012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4305

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 19.3140	Cost: 34.86s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 13.7804	Cost: 6.80s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 13.8978	Cost: 10.80s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 13.7899	Cost: 10.82s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 13.9555	Cost: 14.98s
Train Epoch: 59 	Average Loss: 14.2646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5303

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 19.4733	Cost: 32.19s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 13.9551	Cost: 6.66s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 14.2260	Cost: 11.27s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 14.1604	Cost: 6.09s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 14.1152	Cost: 20.37s
Train Epoch: 60 	Average Loss: 14.3750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5133

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 19.5026	Cost: 27.63s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 14.0766	Cost: 6.84s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 13.8841	Cost: 8.83s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 14.0512	Cost: 6.09s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 13.8135	Cost: 19.68s
Train Epoch: 61 	Average Loss: 14.2864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5297

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 19.2847	Cost: 26.94s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 13.8240	Cost: 6.48s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 13.8745	Cost: 9.44s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 13.8598	Cost: 6.33s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 13.8141	Cost: 15.58s
Train Epoch: 62 	Average Loss: 14.1927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6237

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 19.3463	Cost: 25.10s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 13.6686	Cost: 6.68s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 14.0267	Cost: 10.68s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 13.8306	Cost: 6.39s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 13.6499	Cost: 11.28s
Train Epoch: 63 	Average Loss: 14.1467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6126

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 19.3158	Cost: 22.04s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 13.7155	Cost: 6.26s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 13.7065	Cost: 10.33s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 13.6728	Cost: 8.81s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 13.8042	Cost: 8.78s
Train Epoch: 64 	Average Loss: 14.1163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6639

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 19.5889	Cost: 23.66s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 13.7893	Cost: 8.02s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 13.9176	Cost: 10.43s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 13.8993	Cost: 6.40s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 13.7147	Cost: 6.26s
Train Epoch: 65 	Average Loss: 14.2000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6403

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 19.4996	Cost: 28.61s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 13.7866	Cost: 6.12s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 13.9346	Cost: 14.08s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 13.8106	Cost: 13.97s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 13.6377	Cost: 12.27s
Train Epoch: 66 	Average Loss: 14.0941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6589

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 19.4286	Cost: 28.08s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 13.6117	Cost: 6.43s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 13.9102	Cost: 10.19s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 13.6045	Cost: 15.23s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 13.7671	Cost: 15.02s
Train Epoch: 67 	Average Loss: 14.0270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6720

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 19.3188	Cost: 27.31s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 13.6554	Cost: 6.50s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 13.6489	Cost: 10.85s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 13.6572	Cost: 7.04s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 13.5626	Cost: 18.34s
Train Epoch: 68 	Average Loss: 13.9475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7608

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 19.6577	Cost: 24.29s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 13.5186	Cost: 6.59s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 13.6460	Cost: 11.05s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 13.4677	Cost: 6.34s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 13.5608	Cost: 17.83s
Train Epoch: 69 	Average Loss: 13.9075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7230

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 19.5326	Cost: 22.93s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 13.4822	Cost: 6.60s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 13.6366	Cost: 9.17s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 13.5176	Cost: 6.38s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 13.4354	Cost: 10.94s
Train Epoch: 70 	Average Loss: 13.9251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8414

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 19.0988	Cost: 24.03s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 13.4534	Cost: 8.66s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 13.6117	Cost: 8.72s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 13.4974	Cost: 8.27s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 13.5407	Cost: 6.28s
Train Epoch: 71 	Average Loss: 13.9748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8456

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 19.5645	Cost: 23.51s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 13.5746	Cost: 7.03s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 13.6171	Cost: 8.68s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 13.5901	Cost: 8.41s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 13.6189	Cost: 8.78s
Train Epoch: 72 	Average Loss: 14.0370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7891

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 19.3657	Cost: 23.26s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 13.6657	Cost: 9.02s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 13.8774	Cost: 9.07s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 13.6354	Cost: 5.90s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 13.6836	Cost: 6.20s
Train Epoch: 73 	Average Loss: 14.0889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6680

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 19.6967	Cost: 27.09s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 13.4248	Cost: 14.84s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 13.6737	Cost: 13.89s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 13.4555	Cost: 7.73s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 13.4811	Cost: 5.80s
Train Epoch: 74 	Average Loss: 13.9108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7388

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 19.7586	Cost: 27.39s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 13.2116	Cost: 6.22s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 13.4701	Cost: 14.26s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 13.4834	Cost: 14.22s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 13.3022	Cost: 11.75s
Train Epoch: 75 	Average Loss: 13.7734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7453

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 19.5984	Cost: 23.60s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 13.1994	Cost: 6.14s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 13.5556	Cost: 7.53s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 13.4385	Cost: 6.65s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 13.6126	Cost: 6.50s
Train Epoch: 76 	Average Loss: 13.7504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9252

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 19.5301	Cost: 23.88s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 13.1227	Cost: 6.21s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 13.4586	Cost: 7.49s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 13.3526	Cost: 6.04s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 13.3151	Cost: 7.04s
Train Epoch: 77 	Average Loss: 13.6932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9647

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 19.7128	Cost: 27.29s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 12.9637	Cost: 6.16s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 13.3651	Cost: 8.65s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 13.1072	Cost: 6.05s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 13.2282	Cost: 6.99s
Train Epoch: 78 	Average Loss: 13.5623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9071

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 19.6723	Cost: 25.94s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 13.0038	Cost: 6.33s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 13.2012	Cost: 9.15s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 13.0754	Cost: 6.24s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 13.0826	Cost: 7.70s
Train Epoch: 79 	Average Loss: 13.4951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9970

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 19.8425	Cost: 23.45s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 13.0252	Cost: 6.25s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 13.2072	Cost: 8.50s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 12.8580	Cost: 6.03s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 13.0501	Cost: 8.80s
Train Epoch: 80 	Average Loss: 13.4612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0557

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 19.7817	Cost: 24.07s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 12.8733	Cost: 6.06s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 13.0287	Cost: 8.15s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 13.0272	Cost: 6.19s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 12.9759	Cost: 12.23s
Train Epoch: 81 	Average Loss: 13.4031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9952

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 19.7192	Cost: 23.06s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 12.8765	Cost: 6.08s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 12.9197	Cost: 7.68s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 12.8717	Cost: 5.99s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 12.7761	Cost: 6.37s
Train Epoch: 82 	Average Loss: 13.3574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0561

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 19.9354	Cost: 24.54s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 12.8571	Cost: 11.89s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 13.0693	Cost: 6.16s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 12.7846	Cost: 11.97s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 13.1074	Cost: 5.82s
Train Epoch: 83 	Average Loss: 13.3486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0766

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 19.7579	Cost: 29.09s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 12.9271	Cost: 6.36s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 12.9394	Cost: 13.42s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 12.8866	Cost: 15.04s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 12.7244	Cost: 15.12s
Train Epoch: 84 	Average Loss: 13.3686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0688

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 20.0006	Cost: 27.96s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 12.5958	Cost: 6.57s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 12.9355	Cost: 10.83s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 12.7595	Cost: 7.07s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 12.8520	Cost: 16.77s
Train Epoch: 85 	Average Loss: 13.2407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1679

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 19.8834	Cost: 23.68s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 12.4644	Cost: 6.45s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 12.8482	Cost: 9.49s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 12.5813	Cost: 6.22s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 12.7144	Cost: 15.62s
Train Epoch: 86 	Average Loss: 13.1342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2198

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 19.8698	Cost: 22.40s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 12.5766	Cost: 6.15s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 12.7799	Cost: 9.01s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 12.5062	Cost: 6.31s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 12.8791	Cost: 10.39s
Train Epoch: 87 	Average Loss: 13.1365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2132

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 19.9664	Cost: 24.22s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 12.5144	Cost: 8.28s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 12.8969	Cost: 8.81s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 12.7505	Cost: 8.56s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 12.8066	Cost: 8.89s
Train Epoch: 88 	Average Loss: 13.1690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2823

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 19.9870	Cost: 30.50s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 12.4689	Cost: 8.37s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 12.5856	Cost: 6.32s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 12.8044	Cost: 6.11s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 12.6815	Cost: 9.35s
Train Epoch: 89 	Average Loss: 13.1217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2108

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 19.9494	Cost: 34.45s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 12.7333	Cost: 12.78s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 12.6717	Cost: 8.49s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 12.6501	Cost: 9.56s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 12.6322	Cost: 5.96s
Train Epoch: 90 	Average Loss: 13.0934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2868

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 19.9151	Cost: 41.66s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 12.4613	Cost: 7.97s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 12.6442	Cost: 15.72s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 12.4511	Cost: 14.82s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 12.5353	Cost: 7.79s
Train Epoch: 91 	Average Loss: 13.0211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3363

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 20.0381	Cost: 32.42s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 12.3184	Cost: 6.41s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 12.5688	Cost: 15.10s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 12.5926	Cost: 14.97s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 12.7139	Cost: 13.09s
Train Epoch: 92 	Average Loss: 13.0294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3820

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 20.2374	Cost: 30.04s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 12.5335	Cost: 6.46s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 12.6448	Cost: 15.04s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 12.3759	Cost: 15.18s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 12.5424	Cost: 13.65s
Train Epoch: 93 	Average Loss: 13.0282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3706

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 19.9860	Cost: 27.27s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 12.5119	Cost: 6.51s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 12.6680	Cost: 10.74s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 12.6462	Cost: 14.11s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 12.5333	Cost: 15.19s
Train Epoch: 94 	Average Loss: 13.0072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3639

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 20.0311	Cost: 24.56s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 12.3626	Cost: 6.43s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 12.7172	Cost: 8.95s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 12.5119	Cost: 6.13s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 12.5549	Cost: 18.44s
Train Epoch: 95 	Average Loss: 12.9758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3849

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 20.1005	Cost: 24.13s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 12.3903	Cost: 6.48s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 12.3934	Cost: 11.44s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 12.4328	Cost: 6.17s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 12.2967	Cost: 15.05s
Train Epoch: 96 	Average Loss: 12.9047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4341

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 20.0063	Cost: 24.91s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 12.6194	Cost: 8.83s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 12.5499	Cost: 8.72s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 12.4673	Cost: 6.75s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 12.1850	Cost: 6.06s
Train Epoch: 97 	Average Loss: 12.9185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4470

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 20.1343	Cost: 23.90s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 12.2890	Cost: 6.22s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 12.5516	Cost: 8.97s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 12.3568	Cost: 8.53s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 12.2550	Cost: 8.32s
Train Epoch: 98 	Average Loss: 12.8391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5910

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 20.2502	Cost: 26.32s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 12.3545	Cost: 8.95s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 12.4282	Cost: 9.29s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 12.1885	Cost: 5.89s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 11.9741	Cost: 5.76s
Train Epoch: 99 	Average Loss: 12.7316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4794

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 20.3514	Cost: 34.36s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 12.1922	Cost: 12.99s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 12.3586	Cost: 15.51s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 12.1776	Cost: 12.13s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 12.0666	Cost: 6.52s
Train Epoch: 100 	Average Loss: 12.6627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6914

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 20.2412	Cost: 35.46s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 12.1700	Cost: 6.64s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 12.2749	Cost: 11.72s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 12.1478	Cost: 14.64s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 11.9219	Cost: 14.99s
Train Epoch: 101 	Average Loss: 12.6269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6389

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 20.2560	Cost: 30.14s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 12.1269	Cost: 6.48s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 12.3678	Cost: 10.87s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 12.1334	Cost: 8.63s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 12.0637	Cost: 15.94s
Train Epoch: 102 	Average Loss: 12.7018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6743

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 20.2897	Cost: 26.36s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 12.1623	Cost: 6.55s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 12.2720	Cost: 11.95s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 12.0402	Cost: 6.25s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 12.0075	Cost: 11.79s
Train Epoch: 103 	Average Loss: 12.7142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6261

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 20.3463	Cost: 26.09s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 12.2163	Cost: 8.84s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 12.2979	Cost: 9.05s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 12.0912	Cost: 8.43s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 12.0529	Cost: 6.15s
Train Epoch: 104 	Average Loss: 12.6930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5727

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 20.0369	Cost: 26.57s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 12.1253	Cost: 6.21s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 12.2373	Cost: 9.73s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 12.1023	Cost: 8.60s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 12.0679	Cost: 8.49s
Train Epoch: 105 	Average Loss: 12.6264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6380

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 20.3648	Cost: 29.59s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 11.8731	Cost: 10.57s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 12.1040	Cost: 7.59s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 11.8485	Cost: 6.62s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 12.0351	Cost: 6.14s
Train Epoch: 106 	Average Loss: 12.5640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7206

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 20.2673	Cost: 43.54s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 11.9409	Cost: 16.00s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 12.1347	Cost: 10.01s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 11.7738	Cost: 11.82s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 11.8956	Cost: 5.89s
Train Epoch: 107 	Average Loss: 12.4991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6935

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 20.2134	Cost: 38.12s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 11.9239	Cost: 6.39s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 12.1687	Cost: 12.87s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 11.8815	Cost: 14.89s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 11.9471	Cost: 14.91s
Train Epoch: 108 	Average Loss: 12.4845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7965

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 20.3710	Cost: 31.20s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 11.9003	Cost: 6.78s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 12.1556	Cost: 11.33s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 11.7339	Cost: 14.04s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 11.9065	Cost: 14.95s
Train Epoch: 109 	Average Loss: 12.4587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7495

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 20.4529	Cost: 31.01s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 11.8516	Cost: 6.84s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 12.0473	Cost: 11.57s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 12.0311	Cost: 11.00s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 11.8600	Cost: 15.09s
Train Epoch: 110 	Average Loss: 12.4779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6547

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 20.4564	Cost: 31.34s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 11.9934	Cost: 6.64s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 11.9780	Cost: 11.12s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 11.9608	Cost: 11.22s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 11.8719	Cost: 15.09s
Train Epoch: 111 	Average Loss: 12.4846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6931

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 20.6419	Cost: 30.22s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 12.0278	Cost: 6.90s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 12.0167	Cost: 12.04s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 11.7111	Cost: 6.20s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 11.8949	Cost: 18.77s
Train Epoch: 112 	Average Loss: 12.4271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7161

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 20.2804	Cost: 30.98s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 11.8224	Cost: 6.67s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 11.9577	Cost: 11.92s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 11.8489	Cost: 6.00s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 11.6081	Cost: 19.79s
Train Epoch: 113 	Average Loss: 12.3770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7543

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 20.4587	Cost: 30.48s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 11.6647	Cost: 6.89s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 11.8112	Cost: 11.67s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 11.6339	Cost: 6.06s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 11.4317	Cost: 19.60s
Train Epoch: 114 	Average Loss: 12.2847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7994

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 20.4693	Cost: 29.55s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 11.6004	Cost: 6.67s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 11.9512	Cost: 11.06s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 11.6184	Cost: 7.33s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 11.5726	Cost: 16.96s
Train Epoch: 115 	Average Loss: 12.2766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7888

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 20.5414	Cost: 27.79s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 11.7626	Cost: 6.46s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 11.9098	Cost: 12.10s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 11.5412	Cost: 6.09s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 11.6822	Cost: 20.41s
Train Epoch: 116 	Average Loss: 12.2618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8128

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 20.4777	Cost: 25.30s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 11.6596	Cost: 6.42s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 11.8179	Cost: 10.18s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 11.3897	Cost: 6.22s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 11.5591	Cost: 11.50s
Train Epoch: 117 	Average Loss: 12.2179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7862

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 20.5600	Cost: 29.24s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 11.7744	Cost: 8.73s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 11.9446	Cost: 9.08s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 11.2594	Cost: 7.11s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 11.3099	Cost: 6.01s
Train Epoch: 118 	Average Loss: 12.1213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8727

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 20.4947	Cost: 27.63s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 11.4183	Cost: 8.14s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 11.5168	Cost: 8.74s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 11.4555	Cost: 8.62s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 11.4243	Cost: 8.54s
Train Epoch: 119 	Average Loss: 12.0617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8042

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 20.7255	Cost: 26.78s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 11.1814	Cost: 6.42s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 11.7252	Cost: 9.28s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 11.1798	Cost: 5.96s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 11.5917	Cost: 11.04s
Train Epoch: 120 	Average Loss: 12.0118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8974

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 20.5186	Cost: 29.66s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 11.3944	Cost: 6.17s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 11.6555	Cost: 12.10s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 11.4268	Cost: 5.92s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 11.8660	Cost: 5.95s
Train Epoch: 121 	Average Loss: 12.0971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9050

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 20.7550	Cost: 36.53s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 11.5770	Cost: 6.25s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 11.8891	Cost: 10.57s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 11.5656	Cost: 14.33s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 11.4822	Cost: 14.82s
Train Epoch: 122 	Average Loss: 12.2621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8375

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 20.4812	Cost: 35.25s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 11.3791	Cost: 6.85s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 11.7400	Cost: 9.93s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 11.7662	Cost: 14.00s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 12.4836	Cost: 14.95s
Train Epoch: 123 	Average Loss: 12.3820
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8123

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 20.4721	Cost: 28.17s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 12.1792	Cost: 6.69s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 12.1085	Cost: 11.69s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 11.7155	Cost: 6.17s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 11.8342	Cost: 19.27s
Train Epoch: 124 	Average Loss: 12.5282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7900

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 20.5164	Cost: 27.78s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 11.3776	Cost: 6.35s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 11.7378	Cost: 11.94s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 11.2777	Cost: 6.12s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 11.2893	Cost: 19.89s
Train Epoch: 125 	Average Loss: 12.0092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9577

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 20.7357	Cost: 26.72s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 11.0726	Cost: 6.39s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 11.6537	Cost: 12.31s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 11.2481	Cost: 6.01s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 11.1832	Cost: 20.72s
Train Epoch: 126 	Average Loss: 11.8170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9477

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 20.7416	Cost: 24.70s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 11.1243	Cost: 6.48s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 11.3387	Cost: 10.89s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 11.0041	Cost: 6.23s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 11.1265	Cost: 13.95s
Train Epoch: 127 	Average Loss: 11.7579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0222

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 20.8040	Cost: 27.94s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 10.9367	Cost: 8.84s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 11.4056	Cost: 8.76s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 10.9289	Cost: 8.45s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 11.2052	Cost: 6.11s
Train Epoch: 128 	Average Loss: 11.7186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1180

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 20.6645	Cost: 25.52s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 10.8896	Cost: 6.19s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 11.2696	Cost: 8.47s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 10.9448	Cost: 8.68s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 10.9483	Cost: 8.31s
Train Epoch: 129 	Average Loss: 11.6432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1432

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 20.7065	Cost: 29.35s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 11.1094	Cost: 12.07s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 11.3943	Cost: 6.10s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 10.9203	Cost: 6.02s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 11.0763	Cost: 6.53s
Train Epoch: 130 	Average Loss: 11.7149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1558

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 20.8719	Cost: 43.97s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 10.8353	Cost: 13.69s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 11.3489	Cost: 8.97s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 10.9411	Cost: 9.11s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 10.8695	Cost: 5.98s
Train Epoch: 131 	Average Loss: 11.6269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1857

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 20.6865	Cost: 39.92s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 10.5983	Cost: 6.29s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 11.0181	Cost: 14.73s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 10.7383	Cost: 15.02s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 10.8053	Cost: 12.23s
Train Epoch: 132 	Average Loss: 11.5100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2094

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 20.8856	Cost: 30.99s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 10.6997	Cost: 6.44s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 11.0474	Cost: 10.93s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 10.7888	Cost: 14.92s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 10.9148	Cost: 14.62s
Train Epoch: 133 	Average Loss: 11.5225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2119

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 20.8542	Cost: 24.34s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 10.6424	Cost: 6.49s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 10.9641	Cost: 12.55s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 10.7636	Cost: 6.11s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 10.8409	Cost: 19.91s
Train Epoch: 134 	Average Loss: 11.5096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2191

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 20.7922	Cost: 22.13s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 10.7426	Cost: 6.76s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 10.9280	Cost: 10.53s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 10.7141	Cost: 6.20s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 10.7305	Cost: 12.00s
Train Epoch: 135 	Average Loss: 11.4387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2013

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 21.0853	Cost: 26.32s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 10.5231	Cost: 8.72s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 11.0400	Cost: 9.02s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 10.6579	Cost: 8.57s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 10.6423	Cost: 6.91s
Train Epoch: 136 	Average Loss: 11.3896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2735

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 21.0809	Cost: 25.00s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 10.7506	Cost: 6.25s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 10.9945	Cost: 8.10s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 10.7401	Cost: 8.27s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 10.6515	Cost: 8.51s
Train Epoch: 137 	Average Loss: 11.4949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2605

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 21.0456	Cost: 26.24s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 10.7318	Cost: 6.27s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 11.0245	Cost: 11.35s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 10.7698	Cost: 6.67s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 10.4994	Cost: 6.03s
Train Epoch: 138 	Average Loss: 11.4361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3399

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 20.8807	Cost: 34.50s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 10.6641	Cost: 6.86s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 11.2098	Cost: 12.73s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 10.9620	Cost: 15.01s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 11.0690	Cost: 14.83s
Train Epoch: 139 	Average Loss: 11.6104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3193

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 21.0931	Cost: 30.78s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 10.7481	Cost: 6.40s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 11.0244	Cost: 10.96s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 10.7636	Cost: 13.24s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 10.6296	Cost: 15.56s
Train Epoch: 140 	Average Loss: 11.5418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3438

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 21.0939	Cost: 23.90s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 10.5784	Cost: 6.40s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 10.6220	Cost: 9.13s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 10.4461	Cost: 6.28s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 10.5265	Cost: 11.84s
Train Epoch: 141 	Average Loss: 11.2772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4442

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 21.0477	Cost: 25.34s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 10.5997	Cost: 8.81s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 10.9508	Cost: 8.85s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 10.5887	Cost: 8.45s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 10.7426	Cost: 7.44s
Train Epoch: 142 	Average Loss: 11.3341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4433

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 21.1514	Cost: 27.59s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 10.5248	Cost: 6.24s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 10.8508	Cost: 9.25s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 10.6039	Cost: 6.94s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 10.5579	Cost: 8.54s
Train Epoch: 143 	Average Loss: 11.3587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4691

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 21.2204	Cost: 30.22s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 10.5131	Cost: 9.22s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 10.6568	Cost: 9.06s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 10.5677	Cost: 5.94s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 10.5108	Cost: 6.03s
Train Epoch: 144 	Average Loss: 11.2400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5026

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 20.9292	Cost: 34.07s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 10.3279	Cost: 14.27s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 10.6567	Cost: 14.05s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 10.4357	Cost: 11.98s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 10.3624	Cost: 5.75s
Train Epoch: 145 	Average Loss: 11.1273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4742

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 21.0228	Cost: 37.83s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 10.4019	Cost: 11.33s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 10.6946	Cost: 14.90s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 10.3139	Cost: 14.09s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 10.3885	Cost: 6.13s
Train Epoch: 146 	Average Loss: 11.0759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5767

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 21.1479	Cost: 32.62s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 10.2108	Cost: 6.45s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 10.4691	Cost: 13.60s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 10.0968	Cost: 14.71s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 10.3110	Cost: 13.54s
Train Epoch: 147 	Average Loss: 11.0298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5960

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 21.1252	Cost: 27.32s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 10.2064	Cost: 6.53s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 10.5012	Cost: 9.79s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 10.2493	Cost: 14.39s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 10.2548	Cost: 15.00s
Train Epoch: 148 	Average Loss: 11.0135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6404

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 21.2820	Cost: 24.27s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 10.1632	Cost: 6.70s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 10.3822	Cost: 11.35s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 10.1078	Cost: 6.18s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 10.1813	Cost: 19.44s
Train Epoch: 149 	Average Loss: 11.0145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5819

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 21.3181	Cost: 22.37s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 10.3232	Cost: 6.77s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 10.3972	Cost: 9.84s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 10.3238	Cost: 6.23s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 10.4528	Cost: 11.45s
Train Epoch: 150 	Average Loss: 11.0929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5084

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 21.2260	Cost: 27.41s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 10.6253	Cost: 8.61s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 10.7837	Cost: 8.95s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 10.4024	Cost: 8.46s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 10.2351	Cost: 8.49s
Train Epoch: 151 	Average Loss: 11.2629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4871

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 21.1731	Cost: 28.03s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 10.2071	Cost: 6.28s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 10.5000	Cost: 9.58s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 10.1495	Cost: 5.94s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 10.2409	Cost: 10.27s
Train Epoch: 152 	Average Loss: 10.9770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6600

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 21.2914	Cost: 31.80s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 10.1093	Cost: 10.45s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 10.5316	Cost: 7.64s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 10.0663	Cost: 5.98s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 9.9771	Cost: 5.73s
Train Epoch: 153 	Average Loss: 10.8967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5728

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 21.3977	Cost: 34.09s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 10.0216	Cost: 12.15s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 10.0505	Cost: 14.75s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 9.9854	Cost: 13.46s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 10.0812	Cost: 5.97s
Train Epoch: 154 	Average Loss: 10.7839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6338

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 21.5267	Cost: 38.16s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 9.9570	Cost: 6.36s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 10.1040	Cost: 14.30s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 9.9127	Cost: 14.57s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 10.0208	Cost: 11.18s
Train Epoch: 155 	Average Loss: 10.7773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6025

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 21.3459	Cost: 31.41s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 10.0788	Cost: 6.38s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 10.1576	Cost: 10.98s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 9.9686	Cost: 14.88s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 9.9848	Cost: 15.06s
Train Epoch: 156 	Average Loss: 10.7576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7174

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 21.2812	Cost: 26.36s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 9.9658	Cost: 6.49s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 10.0532	Cost: 11.19s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 10.0771	Cost: 6.39s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 9.9711	Cost: 19.13s
Train Epoch: 157 	Average Loss: 10.7694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7392

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 21.2260	Cost: 24.20s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 9.8947	Cost: 6.57s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 10.1635	Cost: 11.13s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 9.9178	Cost: 6.21s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 9.8008	Cost: 16.48s
Train Epoch: 158 	Average Loss: 10.6961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6481

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 21.2791	Cost: 24.96s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 9.8002	Cost: 8.81s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 10.0911	Cost: 6.87s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 9.9863	Cost: 6.38s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 9.8952	Cost: 7.17s
Train Epoch: 159 	Average Loss: 10.6949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6552

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 21.4180	Cost: 25.15s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 9.8899	Cost: 8.95s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 10.1776	Cost: 8.73s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 10.1293	Cost: 8.52s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 9.7557	Cost: 8.47s
Train Epoch: 160 	Average Loss: 10.8048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6824

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 21.4421	Cost: 26.65s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 9.9138	Cost: 6.25s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 10.0462	Cost: 7.25s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 10.0070	Cost: 6.01s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 9.8164	Cost: 8.45s
Train Epoch: 161 	Average Loss: 10.7121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6953

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 21.3555	Cost: 32.34s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 9.8448	Cost: 6.13s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 10.1283	Cost: 13.37s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 9.9671	Cost: 8.96s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 9.7057	Cost: 5.92s
Train Epoch: 162 	Average Loss: 10.6488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7615

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 21.1106	Cost: 38.64s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 9.7930	Cost: 6.50s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 10.2191	Cost: 15.17s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 10.0249	Cost: 13.71s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 9.9533	Cost: 11.91s
Train Epoch: 163 	Average Loss: 10.6872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6949

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 21.4403	Cost: 39.22s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 9.7908	Cost: 6.45s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 10.0074	Cost: 14.73s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 9.9010	Cost: 14.95s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 9.9404	Cost: 11.78s
Train Epoch: 164 	Average Loss: 10.6590
