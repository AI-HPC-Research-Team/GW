Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=2000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_posterior_prior/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=1000, num_transform_blocks=10, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary_sample_from_all_posterior.hdf5', save_model_name='model_sample_from_all_posterior.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 2000 epochs
Starting timer
Learning rate: 0.0002
Re-generating waveforms for posterior prior.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.0027	Cost: 22.95s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.6451	Cost: 6.07s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 20.9854	Cost: 6.35s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 20.5906	Cost: 5.74s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.2808	Cost: 5.59s
Train Epoch: 1 	Average Loss: 21.3612
Re-generating waveforms for posterior prior.
Test set: Average loss: 20.1801

Learning rate: 0.00019999987662997035
Re-generating waveforms for posterior prior.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.3326	Cost: 22.93s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 19.9545	Cost: 5.88s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.4612	Cost: 6.75s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 18.7152	Cost: 5.72s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 18.4814	Cost: 5.75s
Train Epoch: 2 	Average Loss: 19.2427
Re-generating waveforms for posterior prior.
Test set: Average loss: 18.4712

Learning rate: 0.00019999950652018584
Re-generating waveforms for posterior prior.
Train Epoch: 3 [0/90000 (0%)]	Loss: 18.8352	Cost: 23.23s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 18.1302	Cost: 5.90s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 17.9685	Cost: 7.44s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 17.5905	Cost: 5.97s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 17.5171	Cost: 5.58s
Train Epoch: 3 	Average Loss: 17.9104
Re-generating waveforms for posterior prior.
Test set: Average loss: 18.0321

Learning rate: 0.00019999888967155963
Re-generating waveforms for posterior prior.
Train Epoch: 4 [0/90000 (0%)]	Loss: 19.4262	Cost: 22.00s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 17.2095	Cost: 6.17s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 17.1745	Cost: 7.20s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 16.7794	Cost: 5.92s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 16.7867	Cost: 5.94s
Train Epoch: 4 	Average Loss: 17.1472
Re-generating waveforms for posterior prior.
Test set: Average loss: 17.5499

Learning rate: 0.0001999980260856137
Re-generating waveforms for posterior prior.
Train Epoch: 5 [0/90000 (0%)]	Loss: 18.8915	Cost: 22.54s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 16.4860	Cost: 6.09s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 16.4855	Cost: 7.15s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 16.2162	Cost: 5.89s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 16.3650	Cost: 6.02s
Train Epoch: 5 	Average Loss: 16.5293
Re-generating waveforms for posterior prior.
Test set: Average loss: 17.1037

Learning rate: 0.00019999691576447898
Re-generating waveforms for posterior prior.
Train Epoch: 6 [0/90000 (0%)]	Loss: 17.9971	Cost: 22.77s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 15.9605	Cost: 6.71s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 15.8728	Cost: 6.82s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 15.7093	Cost: 5.95s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 15.7572	Cost: 5.79s
Train Epoch: 6 	Average Loss: 16.0173
Re-generating waveforms for posterior prior.
Test set: Average loss: 16.7529

Learning rate: 0.000199995558710895
Re-generating waveforms for posterior prior.
Train Epoch: 7 [0/90000 (0%)]	Loss: 18.2110	Cost: 22.53s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 15.3987	Cost: 6.00s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 15.4758	Cost: 7.55s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 15.2505	Cost: 5.83s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 15.4565	Cost: 5.79s
Train Epoch: 7 	Average Loss: 15.5569
Re-generating waveforms for posterior prior.
Test set: Average loss: 16.3013

Learning rate: 0.00019999395492821016
Re-generating waveforms for posterior prior.
Train Epoch: 8 [0/90000 (0%)]	Loss: 17.8367	Cost: 22.54s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 15.0757	Cost: 5.99s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 15.1032	Cost: 7.64s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 14.9005	Cost: 5.83s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 15.1967	Cost: 5.87s
Train Epoch: 8 	Average Loss: 15.2347
Re-generating waveforms for posterior prior.
Test set: Average loss: 16.1365

Learning rate: 0.00019999210442038165
Re-generating waveforms for posterior prior.
Train Epoch: 9 [0/90000 (0%)]	Loss: 17.4276	Cost: 22.91s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 14.7183	Cost: 6.21s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 14.6667	Cost: 7.40s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 14.6246	Cost: 5.82s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 14.4815	Cost: 6.12s
Train Epoch: 9 	Average Loss: 14.8272
Re-generating waveforms for posterior prior.
Test set: Average loss: 15.8684

Learning rate: 0.00019999000719197538
Re-generating waveforms for posterior prior.
Train Epoch: 10 [0/90000 (0%)]	Loss: 17.2535	Cost: 22.52s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 14.3601	Cost: 6.02s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 14.3437	Cost: 6.97s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 14.0117	Cost: 5.85s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 14.1646	Cost: 5.83s
Train Epoch: 10 	Average Loss: 14.4912
Re-generating waveforms for posterior prior.
Test set: Average loss: 15.5243

Learning rate: 0.0001999876632481661
Re-generating waveforms for posterior prior.
Train Epoch: 11 [0/90000 (0%)]	Loss: 16.6745	Cost: 22.97s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 14.0168	Cost: 6.06s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 13.9175	Cost: 7.42s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 13.9367	Cost: 5.84s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 14.0120	Cost: 5.98s
Train Epoch: 11 	Average Loss: 14.1771
Re-generating waveforms for posterior prior.
Test set: Average loss: 15.1972

Learning rate: 0.00019998507259473723
Re-generating waveforms for posterior prior.
Train Epoch: 12 [0/90000 (0%)]	Loss: 16.5076	Cost: 22.72s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 13.7721	Cost: 6.03s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 14.0043	Cost: 7.06s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 13.6734	Cost: 5.98s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 13.6030	Cost: 6.29s
Train Epoch: 12 	Average Loss: 13.9498
Re-generating waveforms for posterior prior.
Test set: Average loss: 14.8952

Learning rate: 0.00019998223523808094
Re-generating waveforms for posterior prior.
Train Epoch: 13 [0/90000 (0%)]	Loss: 16.1498	Cost: 22.50s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 13.4858	Cost: 6.00s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 13.3823	Cost: 7.65s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 13.4170	Cost: 5.83s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 13.3878	Cost: 6.12s
Train Epoch: 13 	Average Loss: 13.6276
Re-generating waveforms for posterior prior.
Test set: Average loss: 14.7548

Learning rate: 0.00019997915118519815
Re-generating waveforms for posterior prior.
Train Epoch: 14 [0/90000 (0%)]	Loss: 16.0759	Cost: 22.65s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 13.1075	Cost: 6.03s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 13.4009	Cost: 7.54s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 13.1619	Cost: 5.86s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 13.1500	Cost: 6.50s
Train Epoch: 14 	Average Loss: 13.4031
Re-generating waveforms for posterior prior.
Test set: Average loss: 14.3026

Learning rate: 0.00019997582044369846
Re-generating waveforms for posterior prior.
Train Epoch: 15 [0/90000 (0%)]	Loss: 15.9943	Cost: 23.16s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 13.1324	Cost: 6.00s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 13.1628	Cost: 7.51s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 12.8975	Cost: 5.87s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 13.1152	Cost: 5.75s
Train Epoch: 15 	Average Loss: 13.2164
Re-generating waveforms for posterior prior.
Test set: Average loss: 14.2013

Learning rate: 0.00019997224302180011
Re-generating waveforms for posterior prior.
Train Epoch: 16 [0/90000 (0%)]	Loss: 15.6333	Cost: 23.85s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 12.7384	Cost: 6.01s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 13.0314	Cost: 7.25s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 12.7968	Cost: 5.85s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 12.6710	Cost: 6.30s
Train Epoch: 16 	Average Loss: 12.9894
Re-generating waveforms for posterior prior.
Test set: Average loss: 13.9567

Learning rate: 0.00019996841892833004
Re-generating waveforms for posterior prior.
Train Epoch: 17 [0/90000 (0%)]	Loss: 15.4893	Cost: 22.90s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 12.6771	Cost: 5.99s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 12.7230	Cost: 7.48s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 12.4294	Cost: 5.84s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 12.4246	Cost: 5.81s
Train Epoch: 17 	Average Loss: 12.7993
Re-generating waveforms for posterior prior.
Test set: Average loss: 13.8698

Learning rate: 0.00019996434817272382
Re-generating waveforms for posterior prior.
Train Epoch: 18 [0/90000 (0%)]	Loss: 15.6820	Cost: 22.97s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 12.5272	Cost: 6.01s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 12.5099	Cost: 7.35s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 12.2332	Cost: 5.92s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 12.3738	Cost: 6.72s
Train Epoch: 18 	Average Loss: 12.6263
Re-generating waveforms for posterior prior.
Test set: Average loss: 13.7359

Learning rate: 0.00019996003076502565
Re-generating waveforms for posterior prior.
Train Epoch: 19 [0/90000 (0%)]	Loss: 15.0122	Cost: 23.05s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 12.1651	Cost: 6.08s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 12.2597	Cost: 7.16s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 12.1238	Cost: 6.34s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 12.4759	Cost: 5.76s
Train Epoch: 19 	Average Loss: 12.4815
Re-generating waveforms for posterior prior.
Test set: Average loss: 13.4861

Learning rate: 0.00019995546671588833
Re-generating waveforms for posterior prior.
Train Epoch: 20 [0/90000 (0%)]	Loss: 14.8936	Cost: 22.48s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 12.2475	Cost: 6.06s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 12.2936	Cost: 8.23s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 11.9887	Cost: 5.83s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 12.0684	Cost: 6.33s
Train Epoch: 20 	Average Loss: 12.3548
Re-generating waveforms for posterior prior.
Test set: Average loss: 13.3509

Learning rate: 0.00019995065603657316
Re-generating waveforms for posterior prior.
Train Epoch: 21 [0/90000 (0%)]	Loss: 14.7188	Cost: 22.67s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 11.9484	Cost: 6.10s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 12.0683	Cost: 7.71s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 11.9685	Cost: 5.83s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 11.9860	Cost: 5.91s
Train Epoch: 21 	Average Loss: 12.2621
Re-generating waveforms for posterior prior.
Test set: Average loss: 13.1750

Learning rate: 0.00019994559873895
Re-generating waveforms for posterior prior.
Train Epoch: 22 [0/90000 (0%)]	Loss: 14.5453	Cost: 22.94s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 11.9106	Cost: 6.01s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 11.8503	Cost: 7.42s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 11.6803	Cost: 5.82s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 11.8163	Cost: 5.78s
Train Epoch: 22 	Average Loss: 12.0639
Re-generating waveforms for posterior prior.
Test set: Average loss: 13.0205

Learning rate: 0.00019994029483549728
Re-generating waveforms for posterior prior.
Train Epoch: 23 [0/90000 (0%)]	Loss: 14.3496	Cost: 22.51s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 11.6969	Cost: 6.01s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 11.7361	Cost: 7.74s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 11.8242	Cost: 5.84s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 11.8350	Cost: 5.98s
Train Epoch: 23 	Average Loss: 11.9486
Re-generating waveforms for posterior prior.
Test set: Average loss: 13.0867

Learning rate: 0.00019993474433930184
Re-generating waveforms for posterior prior.
Train Epoch: 24 [0/90000 (0%)]	Loss: 14.4204	Cost: 23.34s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 11.6406	Cost: 5.98s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 11.9214	Cost: 7.37s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 11.6494	Cost: 5.86s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 11.6275	Cost: 6.40s
Train Epoch: 24 	Average Loss: 11.8733
Re-generating waveforms for posterior prior.
Test set: Average loss: 13.1340

Learning rate: 0.00019992894726405893
Re-generating waveforms for posterior prior.
Train Epoch: 25 [0/90000 (0%)]	Loss: 14.4373	Cost: 22.86s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 11.7347	Cost: 6.15s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 11.6636	Cost: 7.85s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 11.3838	Cost: 5.91s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 11.5992	Cost: 6.48s
Train Epoch: 25 	Average Loss: 11.7726
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.9643

Learning rate: 0.0001999229036240723
Re-generating waveforms for posterior prior.
Train Epoch: 26 [0/90000 (0%)]	Loss: 14.6661	Cost: 22.50s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 11.5286	Cost: 6.05s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 11.5397	Cost: 6.97s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 11.3215	Cost: 5.90s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 11.6361	Cost: 5.78s
Train Epoch: 26 	Average Loss: 11.6757
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.9128

Learning rate: 0.000199916613434254
Re-generating waveforms for posterior prior.
Train Epoch: 27 [0/90000 (0%)]	Loss: 14.0992	Cost: 22.60s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 11.3839	Cost: 6.08s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 11.5428	Cost: 7.27s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 11.4397	Cost: 5.88s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 11.2935	Cost: 5.90s
Train Epoch: 27 	Average Loss: 11.5547
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.8212

Learning rate: 0.0001999100767101245
Re-generating waveforms for posterior prior.
Train Epoch: 28 [0/90000 (0%)]	Loss: 13.8453	Cost: 22.92s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 11.2209	Cost: 6.22s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 11.2437	Cost: 7.18s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 11.5557	Cost: 5.93s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 11.4457	Cost: 5.67s
Train Epoch: 28 	Average Loss: 11.5098
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.8618

Learning rate: 0.00019990329346781247
Re-generating waveforms for posterior prior.
Train Epoch: 29 [0/90000 (0%)]	Loss: 14.0978	Cost: 23.19s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 11.2859	Cost: 6.18s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 11.0673	Cost: 7.31s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 11.0250	Cost: 5.96s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 11.1094	Cost: 5.76s
Train Epoch: 29 	Average Loss: 11.3813
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.7493

Learning rate: 0.0001998962637240549
Re-generating waveforms for posterior prior.
Train Epoch: 30 [0/90000 (0%)]	Loss: 13.7844	Cost: 22.26s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 11.0691	Cost: 6.09s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 11.0635	Cost: 7.63s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 11.0170	Cost: 5.85s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 11.2313	Cost: 6.10s
Train Epoch: 30 	Average Loss: 11.2848
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.7432

Learning rate: 0.00019988898749619702
Re-generating waveforms for posterior prior.
Train Epoch: 31 [0/90000 (0%)]	Loss: 13.6387	Cost: 23.11s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 11.0422	Cost: 6.73s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 11.0730	Cost: 7.32s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 11.0102	Cost: 6.42s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 11.0592	Cost: 5.68s
Train Epoch: 31 	Average Loss: 11.2610
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.7313

Learning rate: 0.00019988146480219213
Re-generating waveforms for posterior prior.
Train Epoch: 32 [0/90000 (0%)]	Loss: 13.8486	Cost: 22.91s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 10.9267	Cost: 6.01s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 10.9784	Cost: 7.73s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 10.8812	Cost: 5.87s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 11.0284	Cost: 5.81s
Train Epoch: 32 	Average Loss: 11.1474
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.6728

Learning rate: 0.00019987369566060176
Re-generating waveforms for posterior prior.
Train Epoch: 33 [0/90000 (0%)]	Loss: 13.6548	Cost: 23.03s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 10.8350	Cost: 6.06s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 10.9963	Cost: 7.71s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 10.7399	Cost: 5.89s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 10.8061	Cost: 5.85s
Train Epoch: 33 	Average Loss: 11.1381
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.5543

Learning rate: 0.0001998656800905955
Re-generating waveforms for posterior prior.
Train Epoch: 34 [0/90000 (0%)]	Loss: 13.7889	Cost: 23.27s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 10.6966	Cost: 6.24s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 11.0307	Cost: 7.20s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 10.7878	Cost: 5.87s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 10.8601	Cost: 5.99s
Train Epoch: 34 	Average Loss: 11.0925
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.6024

Learning rate: 0.00019985741811195097
Re-generating waveforms for posterior prior.
Train Epoch: 35 [0/90000 (0%)]	Loss: 13.7818	Cost: 22.17s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 10.7730	Cost: 6.03s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 10.8068	Cost: 6.93s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 10.8116	Cost: 5.85s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 10.9095	Cost: 5.76s
Train Epoch: 35 	Average Loss: 10.9792
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.6334

Learning rate: 0.0001998489097450538
Re-generating waveforms for posterior prior.
Train Epoch: 36 [0/90000 (0%)]	Loss: 13.4257	Cost: 23.29s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 10.7363	Cost: 6.08s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 10.8173	Cost: 7.37s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 10.5313	Cost: 5.77s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 10.7799	Cost: 6.02s
Train Epoch: 36 	Average Loss: 10.8902
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.6304

Learning rate: 0.0001998401550108975
Re-generating waveforms for posterior prior.
Train Epoch: 37 [0/90000 (0%)]	Loss: 13.6490	Cost: 22.61s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 10.5709	Cost: 6.01s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 10.7575	Cost: 6.86s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 10.6119	Cost: 5.80s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 10.6942	Cost: 6.34s
Train Epoch: 37 	Average Loss: 10.9019
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.4934

Learning rate: 0.00019983115393108352
Re-generating waveforms for posterior prior.
Train Epoch: 38 [0/90000 (0%)]	Loss: 13.5052	Cost: 22.80s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 10.6447	Cost: 6.04s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 10.6740	Cost: 7.84s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 10.5479	Cost: 5.73s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 10.7070	Cost: 6.07s
Train Epoch: 38 	Average Loss: 10.8166
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.4516

Learning rate: 0.0001998219065278212
Re-generating waveforms for posterior prior.
Train Epoch: 39 [0/90000 (0%)]	Loss: 13.6939	Cost: 23.10s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 10.7355	Cost: 6.00s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 10.7691	Cost: 7.52s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 10.4761	Cost: 5.73s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 10.5277	Cost: 6.07s
Train Epoch: 39 	Average Loss: 10.8514
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.4597

Learning rate: 0.00019981241282392744
Re-generating waveforms for posterior prior.
Train Epoch: 40 [0/90000 (0%)]	Loss: 13.2711	Cost: 23.48s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 10.5250	Cost: 6.00s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 10.6380	Cost: 7.63s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 10.3717	Cost: 5.73s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 10.4918	Cost: 6.18s
Train Epoch: 40 	Average Loss: 10.7189
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.5468

Learning rate: 0.00019980267284282714
Re-generating waveforms for posterior prior.
Train Epoch: 41 [0/90000 (0%)]	Loss: 13.3071	Cost: 22.66s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 10.5238	Cost: 5.99s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 10.5392	Cost: 7.60s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 10.4509	Cost: 5.78s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 10.5206	Cost: 5.94s
Train Epoch: 41 	Average Loss: 10.7298
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.5431

Learning rate: 0.0001997926866085527
Re-generating waveforms for posterior prior.
Train Epoch: 42 [0/90000 (0%)]	Loss: 13.1738	Cost: 22.91s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 10.4400	Cost: 5.98s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 10.4901	Cost: 7.73s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 10.3251	Cost: 5.75s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 10.4240	Cost: 6.28s
Train Epoch: 42 	Average Loss: 10.6385
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.4363

Learning rate: 0.00019978245414574417
Re-generating waveforms for posterior prior.
Train Epoch: 43 [0/90000 (0%)]	Loss: 13.5522	Cost: 22.90s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 10.2220	Cost: 6.01s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 10.3964	Cost: 6.79s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 10.3668	Cost: 5.94s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 10.6295	Cost: 6.11s
Train Epoch: 43 	Average Loss: 10.6184
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.3477

Learning rate: 0.00019977197547964908
Re-generating waveforms for posterior prior.
Train Epoch: 44 [0/90000 (0%)]	Loss: 13.1384	Cost: 22.62s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 10.2876	Cost: 6.07s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 10.3033	Cost: 7.31s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 10.3395	Cost: 5.79s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 10.4502	Cost: 7.07s
Train Epoch: 44 	Average Loss: 10.5524
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.3103

Learning rate: 0.00019976125063612252
Re-generating waveforms for posterior prior.
Train Epoch: 45 [0/90000 (0%)]	Loss: 13.5405	Cost: 22.63s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 10.4068	Cost: 5.99s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 10.4101	Cost: 7.23s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 10.3628	Cost: 5.72s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 10.3512	Cost: 6.14s
Train Epoch: 45 	Average Loss: 10.5187
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.3609

Learning rate: 0.00019975027964162702
Re-generating waveforms for posterior prior.
Train Epoch: 46 [0/90000 (0%)]	Loss: 13.1003	Cost: 22.70s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 10.2626	Cost: 6.02s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 10.3010	Cost: 7.35s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 10.1915	Cost: 5.82s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 10.1955	Cost: 6.15s
Train Epoch: 46 	Average Loss: 10.4471
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.3541

Learning rate: 0.00019973906252323238
Re-generating waveforms for posterior prior.
Train Epoch: 47 [0/90000 (0%)]	Loss: 13.1484	Cost: 22.43s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 10.1500	Cost: 6.02s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 10.1945	Cost: 7.64s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 10.1665	Cost: 5.71s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 10.1955	Cost: 5.95s
Train Epoch: 47 	Average Loss: 10.4426
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.4356

Learning rate: 0.00019972759930861572
Re-generating waveforms for posterior prior.
Train Epoch: 48 [0/90000 (0%)]	Loss: 13.4309	Cost: 23.22s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 10.2129	Cost: 6.04s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 10.1904	Cost: 6.70s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 10.1428	Cost: 5.80s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 10.3747	Cost: 5.92s
Train Epoch: 48 	Average Loss: 10.4407
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.2531

Learning rate: 0.00019971589002606142
Re-generating waveforms for posterior prior.
Train Epoch: 49 [0/90000 (0%)]	Loss: 12.9447	Cost: 23.07s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 10.1985	Cost: 5.99s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 10.1455	Cost: 7.51s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 10.0321	Cost: 5.87s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 10.2125	Cost: 5.89s
Train Epoch: 49 	Average Loss: 10.3348
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.2464

Learning rate: 0.00019970393470446093
Re-generating waveforms for posterior prior.
Train Epoch: 50 [0/90000 (0%)]	Loss: 12.7496	Cost: 22.79s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 10.0278	Cost: 6.05s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 10.0736	Cost: 6.92s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 10.2352	Cost: 5.79s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 10.0856	Cost: 5.98s
Train Epoch: 50 	Average Loss: 10.3343
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.2847

Saving model as model_sample_from_all_posterior.pt_e50 & waveforms_supplementary_sample_from_all_posterior.hdf5_e50
Learning rate: 0.00019969173337331284
Re-generating waveforms for posterior prior.
Train Epoch: 51 [0/90000 (0%)]	Loss: 13.0285	Cost: 22.62s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 10.0499	Cost: 5.99s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 10.1722	Cost: 7.86s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 9.9383	Cost: 5.76s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 10.1114	Cost: 6.63s
Train Epoch: 51 	Average Loss: 10.2714
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.2722

Learning rate: 0.0001996792860627227
Re-generating waveforms for posterior prior.
Train Epoch: 52 [0/90000 (0%)]	Loss: 13.2234	Cost: 22.80s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 9.9539	Cost: 5.99s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 10.1601	Cost: 7.34s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 10.0840	Cost: 5.73s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 10.1417	Cost: 5.83s
Train Epoch: 52 	Average Loss: 10.3143
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.2847

Learning rate: 0.000199666592803403
Re-generating waveforms for posterior prior.
Train Epoch: 53 [0/90000 (0%)]	Loss: 12.6257	Cost: 23.20s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 9.9348	Cost: 5.97s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 10.0634	Cost: 7.80s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 9.8846	Cost: 5.72s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 10.1542	Cost: 6.04s
Train Epoch: 53 	Average Loss: 10.2111
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.2604

Learning rate: 0.00019965365362667315
Re-generating waveforms for posterior prior.
Train Epoch: 54 [0/90000 (0%)]	Loss: 13.0135	Cost: 22.81s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 10.0812	Cost: 5.99s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 10.0032	Cost: 7.92s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 9.9016	Cost: 5.73s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 9.9417	Cost: 5.93s
Train Epoch: 54 	Average Loss: 10.1994
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.1384

Learning rate: 0.00019964046856445924
Re-generating waveforms for posterior prior.
Train Epoch: 55 [0/90000 (0%)]	Loss: 12.7196	Cost: 22.80s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 9.8907	Cost: 6.00s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 10.0980	Cost: 7.57s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 9.9788	Cost: 5.75s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 10.0098	Cost: 6.05s
Train Epoch: 55 	Average Loss: 10.2000
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.1107

Learning rate: 0.00019962703764929413
Re-generating waveforms for posterior prior.
Train Epoch: 56 [0/90000 (0%)]	Loss: 12.9252	Cost: 22.28s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 10.0514	Cost: 5.98s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 10.0660	Cost: 7.68s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 9.9136	Cost: 5.75s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 9.9588	Cost: 5.75s
Train Epoch: 56 	Average Loss: 10.1505
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.0238

Learning rate: 0.00019961336091431727
Re-generating waveforms for posterior prior.
Train Epoch: 57 [0/90000 (0%)]	Loss: 13.0505	Cost: 22.42s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 9.8542	Cost: 6.03s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 9.9633	Cost: 7.40s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 9.9124	Cost: 5.99s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 9.9760	Cost: 5.65s
Train Epoch: 57 	Average Loss: 10.1063
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.0683

Learning rate: 0.0001995994383932746
Re-generating waveforms for posterior prior.
Train Epoch: 58 [0/90000 (0%)]	Loss: 13.0179	Cost: 22.52s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 9.8554	Cost: 6.01s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 9.8737	Cost: 6.94s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 9.6902	Cost: 5.78s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 9.8665	Cost: 5.70s
Train Epoch: 58 	Average Loss: 10.0550
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.1135

Learning rate: 0.0001995852701205186
Re-generating waveforms for posterior prior.
Train Epoch: 59 [0/90000 (0%)]	Loss: 12.4786	Cost: 23.26s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 9.9059	Cost: 5.97s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 9.8266	Cost: 7.37s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 9.8073	Cost: 5.75s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 9.8344	Cost: 5.71s
Train Epoch: 59 	Average Loss: 10.0119
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.0349

Learning rate: 0.00019957085613100806
Re-generating waveforms for posterior prior.
Train Epoch: 60 [0/90000 (0%)]	Loss: 12.6242	Cost: 23.34s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 9.8613	Cost: 5.99s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 9.7234	Cost: 7.48s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 9.9213	Cost: 5.71s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 9.8064	Cost: 5.98s
Train Epoch: 60 	Average Loss: 10.0101
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.0073

Learning rate: 0.00019955619646030802
Re-generating waveforms for posterior prior.
Train Epoch: 61 [0/90000 (0%)]	Loss: 12.8466	Cost: 22.89s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 9.6291	Cost: 6.98s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 9.7690	Cost: 6.58s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 9.7638	Cost: 5.87s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 9.8035	Cost: 5.87s
Train Epoch: 61 	Average Loss: 9.9548
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.0140

Learning rate: 0.00019954129114458985
Re-generating waveforms for posterior prior.
Train Epoch: 62 [0/90000 (0%)]	Loss: 12.7193	Cost: 22.53s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 9.5942	Cost: 6.06s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 9.6705	Cost: 6.87s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 9.6163	Cost: 5.79s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 9.7321	Cost: 6.10s
Train Epoch: 62 	Average Loss: 9.9041
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.0010

Learning rate: 0.00019952614022063087
Re-generating waveforms for posterior prior.
Train Epoch: 63 [0/90000 (0%)]	Loss: 12.5898	Cost: 22.48s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 9.5475	Cost: 5.99s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 9.6574	Cost: 7.61s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 9.6137	Cost: 5.72s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 9.7516	Cost: 6.17s
Train Epoch: 63 	Average Loss: 9.8817
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.9308

Learning rate: 0.0001995107437258145
Re-generating waveforms for posterior prior.
Train Epoch: 64 [0/90000 (0%)]	Loss: 12.9901	Cost: 22.66s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 9.6449	Cost: 5.99s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 9.6399	Cost: 7.62s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 9.6093	Cost: 5.73s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 9.7389	Cost: 6.23s
Train Epoch: 64 	Average Loss: 9.8688
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.9564

Learning rate: 0.00019949510169813003
Re-generating waveforms for posterior prior.
Train Epoch: 65 [0/90000 (0%)]	Loss: 12.6224	Cost: 22.77s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 9.6735	Cost: 6.00s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 9.6551	Cost: 6.88s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 9.4575	Cost: 6.01s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 9.7167	Cost: 5.75s
Train Epoch: 65 	Average Loss: 9.8578
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.9077

Learning rate: 0.00019947921417617264
Re-generating waveforms for posterior prior.
Train Epoch: 66 [0/90000 (0%)]	Loss: 12.5296	Cost: 22.74s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 9.5478	Cost: 6.03s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 9.6691	Cost: 7.20s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 9.5344	Cost: 5.86s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 9.5683	Cost: 6.24s
Train Epoch: 66 	Average Loss: 9.8207
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.9496

Learning rate: 0.0001994630811991432
Re-generating waveforms for posterior prior.
Train Epoch: 67 [0/90000 (0%)]	Loss: 12.5615	Cost: 22.67s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 9.7584	Cost: 6.04s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 9.5311	Cost: 7.47s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 9.5698	Cost: 5.83s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 9.7737	Cost: 5.97s
Train Epoch: 67 	Average Loss: 9.8075
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.8333

Learning rate: 0.00019944670280684827
Re-generating waveforms for posterior prior.
Train Epoch: 68 [0/90000 (0%)]	Loss: 12.4333	Cost: 22.66s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 9.5453	Cost: 6.00s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 9.8758	Cost: 7.67s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 9.4943	Cost: 5.73s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 9.6416	Cost: 5.84s
Train Epoch: 68 	Average Loss: 9.7815
Re-generating waveforms for posterior prior.
Test set: Average loss: 12.0026

Learning rate: 0.00019943007903969987
Re-generating waveforms for posterior prior.
Train Epoch: 69 [0/90000 (0%)]	Loss: 12.5738	Cost: 22.22s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 9.5745	Cost: 6.03s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 9.6034	Cost: 7.20s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 9.4843	Cost: 5.77s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 9.5494	Cost: 6.15s
Train Epoch: 69 	Average Loss: 9.7604
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.8456

Learning rate: 0.00019941320993871546
Re-generating waveforms for posterior prior.
Train Epoch: 70 [0/90000 (0%)]	Loss: 12.4585	Cost: 22.83s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 9.4180	Cost: 6.06s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 9.5415	Cost: 8.15s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 9.5084	Cost: 5.71s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 9.4829	Cost: 6.21s
Train Epoch: 70 	Average Loss: 9.7161
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.8679

Learning rate: 0.00019939609554551794
Re-generating waveforms for posterior prior.
Train Epoch: 71 [0/90000 (0%)]	Loss: 12.2984	Cost: 23.52s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 9.4024	Cost: 6.01s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 9.5081	Cost: 7.40s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 9.4069	Cost: 5.77s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 9.7044	Cost: 5.93s
Train Epoch: 71 	Average Loss: 9.7028
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.8142

Learning rate: 0.0001993787359023353
Re-generating waveforms for posterior prior.
Train Epoch: 72 [0/90000 (0%)]	Loss: 12.4387	Cost: 23.37s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 9.3873	Cost: 6.01s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 9.6336	Cost: 7.31s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 9.4953	Cost: 5.94s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 9.6241	Cost: 5.89s
Train Epoch: 72 	Average Loss: 9.6762
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.6957

Learning rate: 0.00019936113105200077
Re-generating waveforms for posterior prior.
Train Epoch: 73 [0/90000 (0%)]	Loss: 12.4131	Cost: 22.82s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 9.3471	Cost: 6.02s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 9.4537	Cost: 7.18s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 9.1604	Cost: 5.76s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 9.4537	Cost: 6.12s
Train Epoch: 73 	Average Loss: 9.6279
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.7693

Learning rate: 0.00019934328103795259
Re-generating waveforms for posterior prior.
Train Epoch: 74 [0/90000 (0%)]	Loss: 12.4333	Cost: 22.36s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 9.3781	Cost: 6.05s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 9.4851	Cost: 6.86s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 9.3193	Cost: 5.76s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 9.3855	Cost: 6.31s
Train Epoch: 74 	Average Loss: 9.6464
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.6816

Learning rate: 0.00019932518590423388
Re-generating waveforms for posterior prior.
Train Epoch: 75 [0/90000 (0%)]	Loss: 12.7425	Cost: 22.95s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 9.2638	Cost: 6.01s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 9.4626	Cost: 7.37s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 9.3217	Cost: 5.79s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 9.4307	Cost: 6.18s
Train Epoch: 75 	Average Loss: 9.5970
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.7209

Learning rate: 0.0001993068456954926
Re-generating waveforms for posterior prior.
Train Epoch: 76 [0/90000 (0%)]	Loss: 12.4004	Cost: 22.79s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 9.3024	Cost: 6.01s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 9.3120	Cost: 6.67s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 9.1910	Cost: 5.84s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 9.3985	Cost: 5.82s
Train Epoch: 76 	Average Loss: 9.5628
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.6287

Learning rate: 0.0001992882604569813
Re-generating waveforms for posterior prior.
Train Epoch: 77 [0/90000 (0%)]	Loss: 12.2956	Cost: 22.37s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 9.2058	Cost: 6.04s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 9.2552	Cost: 7.37s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 9.2214	Cost: 5.88s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 9.4155	Cost: 5.95s
Train Epoch: 77 	Average Loss: 9.4955
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.6860

Learning rate: 0.0001992694302345573
Re-generating waveforms for posterior prior.
Train Epoch: 78 [0/90000 (0%)]	Loss: 12.2405	Cost: 22.68s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 9.3688	Cost: 6.02s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 9.3080	Cost: 6.82s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 9.2763	Cost: 5.80s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 9.4209	Cost: 5.93s
Train Epoch: 78 	Average Loss: 9.5295
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.6226

Learning rate: 0.00019925035507468232
Re-generating waveforms for posterior prior.
Train Epoch: 79 [0/90000 (0%)]	Loss: 12.1526	Cost: 22.42s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 9.1083	Cost: 6.02s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 9.3902	Cost: 7.61s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 9.2743	Cost: 5.74s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 9.5618	Cost: 6.29s
Train Epoch: 79 	Average Loss: 9.5113
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.7532

Learning rate: 0.00019923103502442234
Re-generating waveforms for posterior prior.
Train Epoch: 80 [0/90000 (0%)]	Loss: 12.2192	Cost: 22.28s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 9.1705	Cost: 6.05s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 9.2463	Cost: 7.37s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 9.1962	Cost: 5.76s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 9.3421	Cost: 5.78s
Train Epoch: 80 	Average Loss: 9.4679
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.6529

Learning rate: 0.00019921147013144772
Re-generating waveforms for posterior prior.
Train Epoch: 81 [0/90000 (0%)]	Loss: 12.3079	Cost: 22.61s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 9.1956	Cost: 6.11s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 9.0746	Cost: 7.40s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 9.2825	Cost: 5.82s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 9.3482	Cost: 6.64s
Train Epoch: 81 	Average Loss: 9.4028
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.7304

Learning rate: 0.00019919166044403286
Re-generating waveforms for posterior prior.
Train Epoch: 82 [0/90000 (0%)]	Loss: 12.0488	Cost: 22.76s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 9.2092	Cost: 6.02s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 9.2144	Cost: 7.40s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 9.2461	Cost: 5.77s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 9.4209	Cost: 6.29s
Train Epoch: 82 	Average Loss: 9.4235
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.6347

Learning rate: 0.00019917160601105622
Re-generating waveforms for posterior prior.
Train Epoch: 83 [0/90000 (0%)]	Loss: 12.2648	Cost: 22.35s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 9.2399	Cost: 6.00s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 9.2287	Cost: 7.63s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 9.1170	Cost: 5.74s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 9.3373	Cost: 5.96s
Train Epoch: 83 	Average Loss: 9.3737
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.6609

Learning rate: 0.00019915130688200007
Re-generating waveforms for posterior prior.
Train Epoch: 84 [0/90000 (0%)]	Loss: 12.1746	Cost: 22.49s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 9.0843	Cost: 6.00s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 9.1382	Cost: 7.25s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 9.1237	Cost: 5.77s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 9.2324	Cost: 5.91s
Train Epoch: 84 	Average Loss: 9.3826
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.7198

Learning rate: 0.00019913076310695057
Re-generating waveforms for posterior prior.
Train Epoch: 85 [0/90000 (0%)]	Loss: 11.9640	Cost: 22.65s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 8.9811	Cost: 6.00s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 9.1893	Cost: 7.25s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 9.0625	Cost: 5.92s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 9.2612	Cost: 6.06s
Train Epoch: 85 	Average Loss: 9.3356
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.6670

Learning rate: 0.0001991099747365974
Re-generating waveforms for posterior prior.
Train Epoch: 86 [0/90000 (0%)]	Loss: 12.1559	Cost: 22.93s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 9.0855	Cost: 6.02s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 9.2072	Cost: 7.35s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 9.1801	Cost: 5.77s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 9.1889	Cost: 5.83s
Train Epoch: 86 	Average Loss: 9.3204
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.5985

Learning rate: 0.00019908894182223377
Re-generating waveforms for posterior prior.
Train Epoch: 87 [0/90000 (0%)]	Loss: 12.0715	Cost: 22.45s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 9.0570	Cost: 6.02s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 9.1448	Cost: 7.42s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 8.9160	Cost: 5.74s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 9.0243	Cost: 5.67s
Train Epoch: 87 	Average Loss: 9.2478
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.5542

Learning rate: 0.00019906766441575634
Re-generating waveforms for posterior prior.
Train Epoch: 88 [0/90000 (0%)]	Loss: 11.7479	Cost: 22.81s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 8.9710	Cost: 6.03s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 9.1905	Cost: 6.99s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 9.0136	Cost: 5.76s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 8.9752	Cost: 5.97s
Train Epoch: 88 	Average Loss: 9.2461
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.4978

Learning rate: 0.00019904614256966498
Re-generating waveforms for posterior prior.
Train Epoch: 89 [0/90000 (0%)]	Loss: 12.2111	Cost: 22.54s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 8.9766	Cost: 6.04s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 9.0249	Cost: 6.88s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 8.9206	Cost: 5.86s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 9.0502	Cost: 5.71s
Train Epoch: 89 	Average Loss: 9.2307
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.4945

Learning rate: 0.00019902437633706276
Re-generating waveforms for posterior prior.
Train Epoch: 90 [0/90000 (0%)]	Loss: 12.0087	Cost: 22.42s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 8.9932	Cost: 6.02s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 8.9842	Cost: 7.46s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 8.9797	Cost: 5.78s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 9.1171	Cost: 5.74s
Train Epoch: 90 	Average Loss: 9.2195
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.4715

Learning rate: 0.00019900236577165563
Re-generating waveforms for posterior prior.
Train Epoch: 91 [0/90000 (0%)]	Loss: 11.9838	Cost: 22.88s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 8.8807	Cost: 6.06s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 8.8888	Cost: 7.03s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 8.9276	Cost: 5.76s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 9.1329	Cost: 6.01s
Train Epoch: 91 	Average Loss: 9.1721
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.3767

Learning rate: 0.00019898011092775247
Re-generating waveforms for posterior prior.
Train Epoch: 92 [0/90000 (0%)]	Loss: 11.9572	Cost: 22.24s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 8.8287	Cost: 6.02s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 8.9834	Cost: 7.71s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 8.9099	Cost: 5.73s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 9.0537	Cost: 6.07s
Train Epoch: 92 	Average Loss: 9.1446
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.4303

Learning rate: 0.00019895761186026494
Re-generating waveforms for posterior prior.
Train Epoch: 93 [0/90000 (0%)]	Loss: 11.9073	Cost: 22.45s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 8.8539	Cost: 6.01s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 9.0297	Cost: 7.10s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 8.9505	Cost: 5.80s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 9.0665	Cost: 6.07s
Train Epoch: 93 	Average Loss: 9.1314
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.3987

Learning rate: 0.00019893486862470724
Re-generating waveforms for posterior prior.
Train Epoch: 94 [0/90000 (0%)]	Loss: 11.6473	Cost: 22.97s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 8.8629	Cost: 6.00s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 8.9893	Cost: 7.31s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 8.7924	Cost: 5.75s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 8.9635	Cost: 5.70s
Train Epoch: 94 	Average Loss: 9.0941
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.4131

Learning rate: 0.00019891188127719601
Re-generating waveforms for posterior prior.
Train Epoch: 95 [0/90000 (0%)]	Loss: 11.8532	Cost: 24.15s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 8.8714	Cost: 6.05s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 8.9020	Cost: 7.35s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 8.8439	Cost: 6.94s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 8.8580	Cost: 5.62s
Train Epoch: 95 	Average Loss: 9.0867
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.4907

Learning rate: 0.00019888864987445033
Re-generating waveforms for posterior prior.
Train Epoch: 96 [0/90000 (0%)]	Loss: 12.1158	Cost: 22.46s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 8.8227	Cost: 6.02s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 8.9030	Cost: 7.41s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 8.8689	Cost: 5.76s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 8.7928	Cost: 6.01s
Train Epoch: 96 	Average Loss: 9.0806
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.3930

Learning rate: 0.00019886517447379124
Re-generating waveforms for posterior prior.
Train Epoch: 97 [0/90000 (0%)]	Loss: 11.7151	Cost: 23.30s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 8.7940	Cost: 5.99s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 8.9577	Cost: 7.21s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 8.8719	Cost: 5.77s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 8.8049	Cost: 6.17s
Train Epoch: 97 	Average Loss: 9.0231
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.3783

Learning rate: 0.0001988414551331421
Re-generating waveforms for posterior prior.
Train Epoch: 98 [0/90000 (0%)]	Loss: 11.6465	Cost: 23.46s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 8.6527	Cost: 5.99s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 8.8471	Cost: 7.35s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 8.7228	Cost: 5.82s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 8.8894	Cost: 6.12s
Train Epoch: 98 	Average Loss: 9.0017
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.3108

Learning rate: 0.0001988174919110279
Re-generating waveforms for posterior prior.
Train Epoch: 99 [0/90000 (0%)]	Loss: 11.9908	Cost: 22.42s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 8.8148	Cost: 6.09s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 8.9015	Cost: 7.09s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 8.6505	Cost: 5.81s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 9.0651	Cost: 6.18s
Train Epoch: 99 	Average Loss: 9.0126
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.4120

Learning rate: 0.0001987932848665756
Re-generating waveforms for posterior prior.
Train Epoch: 100 [0/90000 (0%)]	Loss: 11.7755	Cost: 22.71s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 8.7440	Cost: 6.02s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 8.6625	Cost: 6.95s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 8.5876	Cost: 5.80s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 8.9818	Cost: 5.99s
Train Epoch: 100 	Average Loss: 8.9571
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.4174

Saving model as model_sample_from_all_posterior.pt_e100 & waveforms_supplementary_sample_from_all_posterior.hdf5_e100
Learning rate: 0.0001987688340595136
Re-generating waveforms for posterior prior.
Train Epoch: 101 [0/90000 (0%)]	Loss: 11.8688	Cost: 22.38s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 8.6112	Cost: 6.01s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 8.6578	Cost: 7.78s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 8.6870	Cost: 5.76s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 8.8034	Cost: 5.74s
Train Epoch: 101 	Average Loss: 8.9722
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.3258

Learning rate: 0.00019874413955017192
Re-generating waveforms for posterior prior.
Train Epoch: 102 [0/90000 (0%)]	Loss: 11.8381	Cost: 22.51s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 8.6595	Cost: 6.00s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 8.7246	Cost: 6.76s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 8.7206	Cost: 6.10s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 8.7409	Cost: 5.68s
Train Epoch: 102 	Average Loss: 8.9211
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.2975

Learning rate: 0.0001987192013994818
Re-generating waveforms for posterior prior.
Train Epoch: 103 [0/90000 (0%)]	Loss: 11.4850	Cost: 22.63s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 8.5897	Cost: 6.03s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 8.7755	Cost: 7.33s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 8.7075	Cost: 6.00s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 8.6832	Cost: 5.67s
Train Epoch: 103 	Average Loss: 8.8694
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.3945

Learning rate: 0.00019869401966897556
Re-generating waveforms for posterior prior.
Train Epoch: 104 [0/90000 (0%)]	Loss: 11.6489	Cost: 22.39s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 8.7488	Cost: 6.02s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 8.7985	Cost: 7.25s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 8.6598	Cost: 5.74s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 8.8496	Cost: 6.05s
Train Epoch: 104 	Average Loss: 8.9068
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.3102

Learning rate: 0.00019866859442078667
Re-generating waveforms for posterior prior.
Train Epoch: 105 [0/90000 (0%)]	Loss: 11.7856	Cost: 22.72s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 8.7298	Cost: 6.02s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 8.7593	Cost: 7.34s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 8.5671	Cost: 5.77s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 8.7488	Cost: 5.87s
Train Epoch: 105 	Average Loss: 8.8990
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.2669

Learning rate: 0.00019864292571764941
Re-generating waveforms for posterior prior.
Train Epoch: 106 [0/90000 (0%)]	Loss: 11.6700	Cost: 22.47s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 8.6718	Cost: 6.05s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 8.6694	Cost: 6.86s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 8.5837	Cost: 5.79s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 8.6764	Cost: 6.03s
Train Epoch: 106 	Average Loss: 8.8294
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.3984

Learning rate: 0.00019861701362289876
Re-generating waveforms for posterior prior.
Train Epoch: 107 [0/90000 (0%)]	Loss: 11.6670	Cost: 22.35s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 8.6364	Cost: 6.00s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 8.6718	Cost: 7.11s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 8.7037	Cost: 5.84s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 8.7011	Cost: 5.87s
Train Epoch: 107 	Average Loss: 8.8109
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.3715

Learning rate: 0.0001985908582004702
Re-generating waveforms for posterior prior.
Train Epoch: 108 [0/90000 (0%)]	Loss: 11.6775	Cost: 22.94s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 8.4356	Cost: 5.99s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 8.5487	Cost: 7.34s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 8.5005	Cost: 5.76s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 8.8426	Cost: 5.88s
Train Epoch: 108 	Average Loss: 8.8030
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.2403

Learning rate: 0.00019856445951489966
Re-generating waveforms for posterior prior.
Train Epoch: 109 [0/90000 (0%)]	Loss: 11.9068	Cost: 24.79s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 8.5588	Cost: 6.03s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 8.6270	Cost: 8.44s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 8.3867	Cost: 5.70s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 8.6246	Cost: 5.65s
Train Epoch: 109 	Average Loss: 8.7804
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.1124

Learning rate: 0.00019853781763132326
Re-generating waveforms for posterior prior.
Train Epoch: 110 [0/90000 (0%)]	Loss: 11.4026	Cost: 22.65s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 8.4641	Cost: 6.00s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 8.6281	Cost: 6.60s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 8.3508	Cost: 5.86s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 8.6698	Cost: 6.14s
Train Epoch: 110 	Average Loss: 8.7446
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.1345

Learning rate: 0.00019851093261547722
Re-generating waveforms for posterior prior.
Train Epoch: 111 [0/90000 (0%)]	Loss: 11.4682	Cost: 22.70s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 8.4502	Cost: 6.03s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 8.5316	Cost: 7.39s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 8.4054	Cost: 5.80s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 8.5158	Cost: 6.05s
Train Epoch: 111 	Average Loss: 8.7064
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.2219

Learning rate: 0.00019848380453369764
Re-generating waveforms for posterior prior.
Train Epoch: 112 [0/90000 (0%)]	Loss: 11.5582	Cost: 22.68s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 8.4355	Cost: 6.01s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 8.4403	Cost: 7.22s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 8.4216	Cost: 5.85s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 8.5463	Cost: 5.68s
Train Epoch: 112 	Average Loss: 8.6641
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.2066

Learning rate: 0.00019845643345292038
Re-generating waveforms for posterior prior.
Train Epoch: 113 [0/90000 (0%)]	Loss: 11.6755	Cost: 22.68s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 8.5201	Cost: 6.04s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 8.4493	Cost: 6.76s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 8.2596	Cost: 5.82s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 8.5891	Cost: 5.94s
Train Epoch: 113 	Average Loss: 8.6684
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.1710

Learning rate: 0.00019842881944068082
Re-generating waveforms for posterior prior.
Train Epoch: 114 [0/90000 (0%)]	Loss: 11.4050	Cost: 22.65s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 8.4226	Cost: 6.01s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 8.5461	Cost: 7.48s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 8.4599	Cost: 5.71s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 8.3325	Cost: 6.12s
Train Epoch: 114 	Average Loss: 8.6533
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.0533

Learning rate: 0.0001984009625651138
Re-generating waveforms for posterior prior.
Train Epoch: 115 [0/90000 (0%)]	Loss: 11.5550	Cost: 22.90s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 8.4125	Cost: 6.00s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 8.4209	Cost: 6.93s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 8.3299	Cost: 5.86s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 8.5047	Cost: 5.88s
Train Epoch: 115 	Average Loss: 8.6405
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.0528

Learning rate: 0.00019837286289495343
Re-generating waveforms for posterior prior.
Train Epoch: 116 [0/90000 (0%)]	Loss: 11.5093	Cost: 22.66s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 8.3504	Cost: 6.03s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 8.4141	Cost: 7.43s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 8.3437	Cost: 5.78s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 8.5833	Cost: 6.00s
Train Epoch: 116 	Average Loss: 8.5699
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.0340

Learning rate: 0.0001983445204995328
Re-generating waveforms for posterior prior.
Train Epoch: 117 [0/90000 (0%)]	Loss: 11.3050	Cost: 22.85s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 8.2789	Cost: 6.02s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 8.4013	Cost: 7.40s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 8.3101	Cost: 5.75s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 8.5975	Cost: 6.09s
Train Epoch: 117 	Average Loss: 8.5658
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.1645

Learning rate: 0.00019831593544878396
Re-generating waveforms for posterior prior.
Train Epoch: 118 [0/90000 (0%)]	Loss: 11.3900	Cost: 22.96s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 8.3522	Cost: 6.01s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 8.4566	Cost: 7.37s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 8.2876	Cost: 5.76s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 8.3621	Cost: 5.77s
Train Epoch: 118 	Average Loss: 8.5553
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.0917

Learning rate: 0.00019828710781323773
Re-generating waveforms for posterior prior.
Train Epoch: 119 [0/90000 (0%)]	Loss: 11.7735	Cost: 22.29s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 8.2599	Cost: 6.02s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 8.3337	Cost: 6.92s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 8.2730	Cost: 5.81s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 8.3242	Cost: 6.08s
Train Epoch: 119 	Average Loss: 8.5435
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.1233

Learning rate: 0.00019825803766402341
Re-generating waveforms for posterior prior.
Train Epoch: 120 [0/90000 (0%)]	Loss: 11.6819	Cost: 22.54s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 8.3026	Cost: 6.02s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 8.2308	Cost: 7.40s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 8.1638	Cost: 5.76s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 8.2322	Cost: 6.25s
Train Epoch: 120 	Average Loss: 8.4926
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.9260

Learning rate: 0.00019822872507286872
Re-generating waveforms for posterior prior.
Train Epoch: 121 [0/90000 (0%)]	Loss: 11.3073	Cost: 23.24s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 8.3085	Cost: 6.00s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 8.1780	Cost: 7.24s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 8.2593	Cost: 5.75s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 8.2758	Cost: 5.95s
Train Epoch: 121 	Average Loss: 8.4769
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.0456

Learning rate: 0.00019819917011209951
Re-generating waveforms for posterior prior.
Train Epoch: 122 [0/90000 (0%)]	Loss: 11.3232	Cost: 22.82s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 8.2462	Cost: 6.01s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 8.3466	Cost: 6.73s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 8.2247	Cost: 5.87s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 8.3403	Cost: 5.65s
Train Epoch: 122 	Average Loss: 8.4768
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.9121

Learning rate: 0.00019816937285463973
Re-generating waveforms for posterior prior.
Train Epoch: 123 [0/90000 (0%)]	Loss: 11.5391	Cost: 22.66s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 8.2347	Cost: 6.01s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 8.2162	Cost: 7.14s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 8.2135	Cost: 5.80s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 8.3719	Cost: 6.05s
Train Epoch: 123 	Average Loss: 8.4635
Re-generating waveforms for posterior prior.
Test set: Average loss: 11.0023

Learning rate: 0.00019813933337401118
Re-generating waveforms for posterior prior.
Train Epoch: 124 [0/90000 (0%)]	Loss: 11.2884	Cost: 22.67s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 8.2413	Cost: 6.03s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 8.2537	Cost: 6.84s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 8.2590	Cost: 5.82s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 8.2234	Cost: 6.23s
Train Epoch: 124 	Average Loss: 8.4228
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.9250

Learning rate: 0.00019810905174433326
Re-generating waveforms for posterior prior.
Train Epoch: 125 [0/90000 (0%)]	Loss: 11.0774	Cost: 22.89s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 8.1287	Cost: 6.04s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 8.2028	Cost: 7.43s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 8.0962	Cost: 5.75s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 8.1734	Cost: 5.94s
Train Epoch: 125 	Average Loss: 8.3718
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.9312

Learning rate: 0.00019807852804032292
Re-generating waveforms for posterior prior.
Train Epoch: 126 [0/90000 (0%)]	Loss: 11.1467	Cost: 23.72s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 8.2038	Cost: 6.01s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 8.1780	Cost: 7.30s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 8.0864	Cost: 5.74s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 8.2223	Cost: 5.86s
Train Epoch: 126 	Average Loss: 8.3568
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.9351

Learning rate: 0.0001980477623372943
Re-generating waveforms for posterior prior.
Train Epoch: 127 [0/90000 (0%)]	Loss: 11.1621	Cost: 22.54s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 8.1496	Cost: 6.01s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 8.0896	Cost: 6.80s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 7.9949	Cost: 6.00s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 8.1880	Cost: 7.34s
Train Epoch: 127 	Average Loss: 8.3261
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.8842

Learning rate: 0.00019801675471115877
Re-generating waveforms for posterior prior.
Train Epoch: 128 [0/90000 (0%)]	Loss: 11.3426	Cost: 22.64s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 7.9830	Cost: 6.03s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 8.1742	Cost: 6.94s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 8.1987	Cost: 5.85s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 8.1745	Cost: 5.83s
Train Epoch: 128 	Average Loss: 8.3254
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.8712

Learning rate: 0.00019798550523842453
Re-generating waveforms for posterior prior.
Train Epoch: 129 [0/90000 (0%)]	Loss: 11.2733	Cost: 22.90s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 7.9547	Cost: 6.03s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 8.1653	Cost: 7.28s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 7.9887	Cost: 5.83s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 8.0786	Cost: 5.96s
Train Epoch: 129 	Average Loss: 8.2803
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.9032

Learning rate: 0.00019795401399619659
Re-generating waveforms for posterior prior.
Train Epoch: 130 [0/90000 (0%)]	Loss: 11.1185	Cost: 22.74s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 8.0530	Cost: 6.03s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 8.1332	Cost: 6.95s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 7.9783	Cost: 5.79s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 8.1810	Cost: 5.81s
Train Epoch: 130 	Average Loss: 8.2815
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.8540

Learning rate: 0.00019792228106217641
Re-generating waveforms for posterior prior.
Train Epoch: 131 [0/90000 (0%)]	Loss: 11.0016	Cost: 23.39s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 7.8575	Cost: 6.10s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 8.0987	Cost: 7.42s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 8.0588	Cost: 5.78s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 8.0225	Cost: 5.86s
Train Epoch: 131 	Average Loss: 8.2375
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.8934

Learning rate: 0.0001978903065146619
Re-generating waveforms for posterior prior.
Train Epoch: 132 [0/90000 (0%)]	Loss: 11.2613	Cost: 23.00s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 8.0345	Cost: 6.00s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 8.1021	Cost: 6.90s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 7.9297	Cost: 5.77s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 8.1230	Cost: 6.11s
Train Epoch: 132 	Average Loss: 8.2313
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.8399

Learning rate: 0.00019785809043254703
Re-generating waveforms for posterior prior.
Train Epoch: 133 [0/90000 (0%)]	Loss: 11.0085	Cost: 22.60s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 7.9266	Cost: 6.02s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 8.1292	Cost: 7.37s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 7.9536	Cost: 5.75s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 8.0901	Cost: 5.96s
Train Epoch: 133 	Average Loss: 8.1724
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.8494

Learning rate: 0.00019782563289532184
Re-generating waveforms for posterior prior.
Train Epoch: 134 [0/90000 (0%)]	Loss: 11.0422	Cost: 22.46s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 7.8697	Cost: 6.02s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 8.0106	Cost: 7.46s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 7.9165	Cost: 5.74s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 8.1028	Cost: 6.45s
Train Epoch: 134 	Average Loss: 8.1924
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.8622

Learning rate: 0.00019779293398307203
Re-generating waveforms for posterior prior.
Train Epoch: 135 [0/90000 (0%)]	Loss: 11.0867	Cost: 22.40s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 7.9279	Cost: 6.02s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 8.0383	Cost: 7.45s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 7.9230	Cost: 5.75s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 7.8724	Cost: 6.08s
Train Epoch: 135 	Average Loss: 8.1706
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.7840

Learning rate: 0.00019775999377647893
Re-generating waveforms for posterior prior.
Train Epoch: 136 [0/90000 (0%)]	Loss: 11.0153	Cost: 23.09s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 7.8027	Cost: 6.00s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 7.9540	Cost: 7.09s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 7.8088	Cost: 5.83s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 8.0170	Cost: 5.88s
Train Epoch: 136 	Average Loss: 8.1309
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.7405

Learning rate: 0.0001977268123568192
Re-generating waveforms for posterior prior.
Train Epoch: 137 [0/90000 (0%)]	Loss: 11.1203	Cost: 23.59s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 7.8956	Cost: 6.10s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 7.9037	Cost: 7.35s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 7.8733	Cost: 5.72s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 8.0638	Cost: 6.11s
Train Epoch: 137 	Average Loss: 8.0935
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.8075

Learning rate: 0.00019769338980596472
Re-generating waveforms for posterior prior.
Train Epoch: 138 [0/90000 (0%)]	Loss: 11.0388	Cost: 22.58s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 7.8255	Cost: 6.07s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 7.9733	Cost: 7.08s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 7.7918	Cost: 5.83s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 7.9662	Cost: 6.03s
Train Epoch: 138 	Average Loss: 8.1121
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.6632

Learning rate: 0.00019765972620638231
Re-generating waveforms for posterior prior.
Train Epoch: 139 [0/90000 (0%)]	Loss: 10.8293	Cost: 22.49s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 7.8723	Cost: 6.02s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 7.8525	Cost: 7.12s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 7.7861	Cost: 5.94s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 7.7805	Cost: 5.94s
Train Epoch: 139 	Average Loss: 8.0426
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.6635

Learning rate: 0.00019762582164113354
Re-generating waveforms for posterior prior.
Train Epoch: 140 [0/90000 (0%)]	Loss: 11.1171	Cost: 23.22s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 7.8160	Cost: 6.06s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 7.9422	Cost: 7.25s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 7.7141	Cost: 5.75s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 7.9469	Cost: 6.07s
Train Epoch: 140 	Average Loss: 8.0629
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.7150

Learning rate: 0.00019759167619387457
Re-generating waveforms for posterior prior.
Train Epoch: 141 [0/90000 (0%)]	Loss: 11.0207	Cost: 22.82s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 7.8116	Cost: 6.04s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 7.8876	Cost: 7.39s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 7.8079	Cost: 5.77s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 7.7284	Cost: 5.86s
Train Epoch: 141 	Average Loss: 8.0412
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.7596

Learning rate: 0.0001975572899488559
Re-generating waveforms for posterior prior.
Train Epoch: 142 [0/90000 (0%)]	Loss: 10.9857	Cost: 22.96s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 7.6303	Cost: 6.02s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 7.8279	Cost: 7.23s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 7.8514	Cost: 5.87s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 7.8151	Cost: 5.79s
Train Epoch: 142 	Average Loss: 7.9840
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.7199

Learning rate: 0.00019752266299092217
Re-generating waveforms for posterior prior.
Train Epoch: 143 [0/90000 (0%)]	Loss: 10.7754	Cost: 22.55s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 7.7052	Cost: 6.07s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 7.8581	Cost: 7.40s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 7.6694	Cost: 5.76s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 7.8923	Cost: 5.89s
Train Epoch: 143 	Average Loss: 7.9750
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.7975

Learning rate: 0.00019748779540551198
Re-generating waveforms for posterior prior.
Train Epoch: 144 [0/90000 (0%)]	Loss: 11.0644	Cost: 22.67s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 7.6427	Cost: 6.06s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 7.6858	Cost: 7.39s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 7.6327	Cost: 5.89s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 7.8189	Cost: 6.03s
Train Epoch: 144 	Average Loss: 7.9423
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.6287

Learning rate: 0.00019745268727865758
Re-generating waveforms for posterior prior.
Train Epoch: 145 [0/90000 (0%)]	Loss: 10.8802	Cost: 23.04s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 7.5891	Cost: 6.05s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 7.8280	Cost: 7.42s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 7.5767	Cost: 5.84s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 7.5802	Cost: 6.12s
Train Epoch: 145 	Average Loss: 7.8810
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.5421

Learning rate: 0.0001974173386969848
Re-generating waveforms for posterior prior.
Train Epoch: 146 [0/90000 (0%)]	Loss: 10.6460	Cost: 22.59s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 7.6587	Cost: 6.03s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 7.7492	Cost: 7.48s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 7.7295	Cost: 5.73s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 7.8346	Cost: 5.91s
Train Epoch: 146 	Average Loss: 7.9065
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.6513

Learning rate: 0.0001973817497477127
Re-generating waveforms for posterior prior.
Train Epoch: 147 [0/90000 (0%)]	Loss: 11.0264	Cost: 22.63s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 7.6300	Cost: 6.05s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 7.5428	Cost: 10.57s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 7.5918	Cost: 5.63s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 7.5886	Cost: 5.64s
Train Epoch: 147 	Average Loss: 7.8758
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.5453

Learning rate: 0.0001973459205186536
Re-generating waveforms for posterior prior.
Train Epoch: 148 [0/90000 (0%)]	Loss: 10.8737	Cost: 24.18s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 7.6189	Cost: 5.95s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 7.6492	Cost: 7.09s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 7.5081	Cost: 6.01s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 7.5912	Cost: 5.65s
Train Epoch: 148 	Average Loss: 7.8425
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.4934

Learning rate: 0.0001973098510982125
Re-generating waveforms for posterior prior.
Train Epoch: 149 [0/90000 (0%)]	Loss: 10.7869	Cost: 23.23s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 7.6318	Cost: 6.05s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 7.8233	Cost: 7.17s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 7.5625	Cost: 5.78s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 7.7739	Cost: 5.77s
Train Epoch: 149 	Average Loss: 7.8407
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.4797

Learning rate: 0.00019727354157538706
Re-generating waveforms for posterior prior.
Train Epoch: 150 [0/90000 (0%)]	Loss: 10.8688	Cost: 22.68s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 7.5372	Cost: 6.04s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 7.6590	Cost: 7.45s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 7.6595	Cost: 5.80s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 7.6080	Cost: 5.92s
Train Epoch: 150 	Average Loss: 7.8410
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.5978

Saving model as model_sample_from_all_posterior.pt_e150 & waveforms_supplementary_sample_from_all_posterior.hdf5_e150
Learning rate: 0.0001972369920397675
Re-generating waveforms for posterior prior.
Train Epoch: 151 [0/90000 (0%)]	Loss: 10.9705	Cost: 22.67s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 7.4227	Cost: 6.09s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 7.5756	Cost: 6.85s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 7.5783	Cost: 5.84s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 7.5413	Cost: 5.85s
Train Epoch: 151 	Average Loss: 7.7770
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.6357

Learning rate: 0.0001972002025815361
Re-generating waveforms for posterior prior.
Train Epoch: 152 [0/90000 (0%)]	Loss: 10.7706	Cost: 22.24s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 7.6255	Cost: 6.06s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 7.6350	Cost: 7.49s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 7.5047	Cost: 5.75s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 7.4084	Cost: 5.93s
Train Epoch: 152 	Average Loss: 7.7412
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.4233

Learning rate: 0.00019716317329146726
Re-generating waveforms for posterior prior.
Train Epoch: 153 [0/90000 (0%)]	Loss: 10.8243	Cost: 22.71s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 7.4053	Cost: 6.05s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 7.5719	Cost: 6.98s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 7.4986	Cost: 5.88s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 7.6556	Cost: 5.78s
Train Epoch: 153 	Average Loss: 7.7103
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.4661

Learning rate: 0.000197125904260927
Re-generating waveforms for posterior prior.
Train Epoch: 154 [0/90000 (0%)]	Loss: 10.7836	Cost: 22.53s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 7.4552	Cost: 6.03s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 7.5004	Cost: 6.68s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 7.4501	Cost: 5.88s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 7.4548	Cost: 5.85s
Train Epoch: 154 	Average Loss: 7.6999
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.4386

Learning rate: 0.00019708839558187297
Re-generating waveforms for posterior prior.
Train Epoch: 155 [0/90000 (0%)]	Loss: 10.6659	Cost: 22.56s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 7.4997	Cost: 6.03s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 7.5563	Cost: 7.42s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 7.3788	Cost: 5.78s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 7.4183	Cost: 5.98s
Train Epoch: 155 	Average Loss: 7.6621
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.6240

Learning rate: 0.00019705064734685412
Re-generating waveforms for posterior prior.
Train Epoch: 156 [0/90000 (0%)]	Loss: 10.9295	Cost: 22.94s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 7.4548	Cost: 6.02s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 7.5908	Cost: 7.11s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 7.3370	Cost: 5.78s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 7.4828	Cost: 6.23s
Train Epoch: 156 	Average Loss: 7.6745
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.4222

Learning rate: 0.00019701265964901045
Re-generating waveforms for posterior prior.
Train Epoch: 157 [0/90000 (0%)]	Loss: 10.5687	Cost: 22.72s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 7.3878	Cost: 6.02s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 7.3798	Cost: 7.37s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 7.4520	Cost: 5.78s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 7.4490	Cost: 5.96s
Train Epoch: 157 	Average Loss: 7.6294
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.4293

Learning rate: 0.00019697443258207285
Re-generating waveforms for posterior prior.
Train Epoch: 158 [0/90000 (0%)]	Loss: 10.8662	Cost: 22.90s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 7.3456	Cost: 6.02s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 7.4414	Cost: 7.25s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 7.3199	Cost: 5.72s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 7.6118	Cost: 6.15s
Train Epoch: 158 	Average Loss: 7.6109
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.4888

Learning rate: 0.00019693596624036278
Re-generating waveforms for posterior prior.
Train Epoch: 159 [0/90000 (0%)]	Loss: 10.6966	Cost: 22.68s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 7.3303	Cost: 6.03s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 7.4826	Cost: 7.13s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 7.2269	Cost: 5.77s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 7.2540	Cost: 5.88s
Train Epoch: 159 	Average Loss: 7.5429
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.3823

Learning rate: 0.00019689726071879217
Re-generating waveforms for posterior prior.
Train Epoch: 160 [0/90000 (0%)]	Loss: 10.7483	Cost: 22.72s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 7.3017	Cost: 6.01s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 7.3871	Cost: 7.23s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 7.3607	Cost: 5.76s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 7.3314	Cost: 6.22s
Train Epoch: 160 	Average Loss: 7.5742
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.4354

Learning rate: 0.000196858316112863
Re-generating waveforms for posterior prior.
Train Epoch: 161 [0/90000 (0%)]	Loss: 10.4634	Cost: 23.29s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 7.2065	Cost: 6.02s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 7.2605	Cost: 6.91s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 7.2889	Cost: 5.85s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 7.4011	Cost: 6.43s
Train Epoch: 161 	Average Loss: 7.4784
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.3719

Learning rate: 0.0001968191325186672
Re-generating waveforms for posterior prior.
Train Epoch: 162 [0/90000 (0%)]	Loss: 10.5494	Cost: 23.01s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 7.2248	Cost: 6.03s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 7.3758	Cost: 6.99s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 7.2802	Cost: 5.80s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 7.3947	Cost: 5.99s
Train Epoch: 162 	Average Loss: 7.5078
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.4348

Learning rate: 0.00019677971003288642
Re-generating waveforms for posterior prior.
Train Epoch: 163 [0/90000 (0%)]	Loss: 10.7472	Cost: 22.72s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 7.1150	Cost: 6.09s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 7.1981	Cost: 6.74s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 7.2025	Cost: 6.07s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 7.2322	Cost: 5.83s
Train Epoch: 163 	Average Loss: 7.4557
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.4015

Learning rate: 0.00019674004875279172
Re-generating waveforms for posterior prior.
Train Epoch: 164 [0/90000 (0%)]	Loss: 10.4507	Cost: 23.43s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 7.0433	Cost: 6.06s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 7.2858	Cost: 7.14s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 7.1823	Cost: 5.76s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 7.2322	Cost: 6.02s
Train Epoch: 164 	Average Loss: 7.4067
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.3115

Learning rate: 0.00019670014877624337
Re-generating waveforms for posterior prior.
Train Epoch: 165 [0/90000 (0%)]	Loss: 10.6079	Cost: 22.83s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 7.0480	Cost: 6.03s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 7.2251	Cost: 7.51s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 7.0834	Cost: 5.77s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 7.2411	Cost: 5.80s
Train Epoch: 165 	Average Loss: 7.4149
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.2662

Learning rate: 0.0001966600102016906
Re-generating waveforms for posterior prior.
Train Epoch: 166 [0/90000 (0%)]	Loss: 10.3999	Cost: 23.04s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 7.1230	Cost: 6.08s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 7.0831	Cost: 7.05s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 7.2361	Cost: 5.79s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 7.1575	Cost: 6.05s
Train Epoch: 166 	Average Loss: 7.3582
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.3831

Learning rate: 0.00019661963312817132
Re-generating waveforms for posterior prior.
Train Epoch: 167 [0/90000 (0%)]	Loss: 10.3067	Cost: 22.55s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 7.1231	Cost: 6.06s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 7.1748	Cost: 7.52s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 7.1130	Cost: 5.78s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 7.1554	Cost: 6.34s
Train Epoch: 167 	Average Loss: 7.3050
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.2914

Learning rate: 0.00019657901765531203
Re-generating waveforms for posterior prior.
Train Epoch: 168 [0/90000 (0%)]	Loss: 10.2894	Cost: 24.58s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 6.9708	Cost: 9.44s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 7.0949	Cost: 6.00s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 7.1675	Cost: 5.94s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 7.1754	Cost: 5.64s
Train Epoch: 168 	Average Loss: 7.2964
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.2367

Learning rate: 0.00019653816388332727
Re-generating waveforms for posterior prior.
Train Epoch: 169 [0/90000 (0%)]	Loss: 10.3722	Cost: 23.20s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 6.9631	Cost: 6.04s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 7.0488	Cost: 7.60s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 6.9883	Cost: 5.75s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 6.9904	Cost: 6.01s
Train Epoch: 169 	Average Loss: 7.2466
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.1287

Learning rate: 0.00019649707191301971
Re-generating waveforms for posterior prior.
Train Epoch: 170 [0/90000 (0%)]	Loss: 10.7321	Cost: 23.33s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 6.9846	Cost: 6.01s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 7.0976	Cost: 7.17s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 7.0529	Cost: 5.77s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 7.1126	Cost: 6.03s
Train Epoch: 170 	Average Loss: 7.2657
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.2564

Learning rate: 0.0001964557418457797
Re-generating waveforms for posterior prior.
Train Epoch: 171 [0/90000 (0%)]	Loss: 10.5288	Cost: 22.53s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 6.9629	Cost: 6.07s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 7.0176	Cost: 6.90s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 6.9784	Cost: 5.82s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 7.1039	Cost: 6.08s
Train Epoch: 171 	Average Loss: 7.2510
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.2702

Learning rate: 0.00019641417378358508
Re-generating waveforms for posterior prior.
Train Epoch: 172 [0/90000 (0%)]	Loss: 10.4992	Cost: 23.10s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 6.8760	Cost: 6.02s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 7.0388	Cost: 7.33s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 6.8233	Cost: 5.75s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 6.9995	Cost: 5.73s
Train Epoch: 172 	Average Loss: 7.1712
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.2315

Learning rate: 0.00019637236782900087
Re-generating waveforms for posterior prior.
Train Epoch: 173 [0/90000 (0%)]	Loss: 10.2133	Cost: 22.47s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 6.7888	Cost: 6.08s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 6.8943	Cost: 7.48s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 6.8352	Cost: 5.77s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 6.9275	Cost: 6.08s
Train Epoch: 173 	Average Loss: 7.1489
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.2566

Learning rate: 0.00019633032408517914
Re-generating waveforms for posterior prior.
Train Epoch: 174 [0/90000 (0%)]	Loss: 10.4592	Cost: 23.31s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 6.8136	Cost: 6.05s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 6.9532	Cost: 7.13s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 6.9180	Cost: 5.77s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 6.9669	Cost: 6.14s
Train Epoch: 174 	Average Loss: 7.1472
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.1364

Learning rate: 0.00019628804265585866
Re-generating waveforms for posterior prior.
Train Epoch: 175 [0/90000 (0%)]	Loss: 10.2765	Cost: 22.86s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 6.8033	Cost: 6.04s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 6.9503	Cost: 7.43s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 6.8217	Cost: 5.75s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 6.9217	Cost: 5.87s
Train Epoch: 175 	Average Loss: 7.0850
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.1788

Learning rate: 0.00019624552364536462
Re-generating waveforms for posterior prior.
Train Epoch: 176 [0/90000 (0%)]	Loss: 10.2004	Cost: 22.68s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 6.7561	Cost: 5.99s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 6.9902	Cost: 6.80s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 6.8335	Cost: 5.94s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 6.9165	Cost: 6.16s
Train Epoch: 176 	Average Loss: 7.0566
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.0471

Learning rate: 0.00019620276715860848
Re-generating waveforms for posterior prior.
Train Epoch: 177 [0/90000 (0%)]	Loss: 10.1001	Cost: 22.49s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 6.7921	Cost: 6.06s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 6.8089	Cost: 7.29s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 6.7027	Cost: 5.85s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 6.7397	Cost: 5.91s
Train Epoch: 177 	Average Loss: 7.0607
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.0353

Learning rate: 0.0001961597733010876
Re-generating waveforms for posterior prior.
Train Epoch: 178 [0/90000 (0%)]	Loss: 10.3143	Cost: 22.95s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 6.7312	Cost: 6.01s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 6.8609	Cost: 7.23s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 6.7791	Cost: 6.13s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 6.7545	Cost: 5.79s
Train Epoch: 178 	Average Loss: 7.0191
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.9944

Learning rate: 0.0001961165421788851
Re-generating waveforms for posterior prior.
Train Epoch: 179 [0/90000 (0%)]	Loss: 10.2036	Cost: 22.83s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 6.5937	Cost: 6.10s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 6.8886	Cost: 6.96s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 6.6809	Cost: 5.87s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 6.6705	Cost: 5.66s
Train Epoch: 179 	Average Loss: 6.9883
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.9581

Learning rate: 0.00019607307389866941
Re-generating waveforms for posterior prior.
Train Epoch: 180 [0/90000 (0%)]	Loss: 10.1615	Cost: 22.94s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 6.6165	Cost: 6.03s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 6.8106	Cost: 7.18s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 6.6730	Cost: 5.86s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 6.5920	Cost: 5.95s
Train Epoch: 180 	Average Loss: 6.9496
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.9235

Learning rate: 0.00019602936856769423
Re-generating waveforms for posterior prior.
Train Epoch: 181 [0/90000 (0%)]	Loss: 10.2451	Cost: 22.97s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 6.6523	Cost: 6.03s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 6.7291	Cost: 7.36s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 6.6606	Cost: 5.77s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 6.7413	Cost: 5.68s
Train Epoch: 181 	Average Loss: 6.9304
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.9531

Learning rate: 0.0001959854262937981
Re-generating waveforms for posterior prior.
Train Epoch: 182 [0/90000 (0%)]	Loss: 10.0261	Cost: 22.91s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 6.5979	Cost: 6.08s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 6.8339	Cost: 7.15s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 6.6713	Cost: 5.86s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 6.7262	Cost: 5.79s
Train Epoch: 182 	Average Loss: 6.9099
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.9534

Learning rate: 0.0001959412471854042
Re-generating waveforms for posterior prior.
Train Epoch: 183 [0/90000 (0%)]	Loss: 10.1858	Cost: 23.01s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 6.6190	Cost: 6.04s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 6.7374	Cost: 7.24s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 6.5433	Cost: 5.82s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 6.6961	Cost: 6.01s
Train Epoch: 183 	Average Loss: 6.8669
Re-generating waveforms for posterior prior.
Test set: Average loss: 10.0064

Learning rate: 0.00019589683135152013
Re-generating waveforms for posterior prior.
Train Epoch: 184 [0/90000 (0%)]	Loss: 9.9669	Cost: 23.21s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 6.5602	Cost: 6.05s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 6.7843	Cost: 7.14s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 6.6490	Cost: 6.03s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 6.6702	Cost: 5.70s
Train Epoch: 184 	Average Loss: 6.8699
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.9866

Learning rate: 0.0001958521789017375
Re-generating waveforms for posterior prior.
Train Epoch: 185 [0/90000 (0%)]	Loss: 9.9904	Cost: 22.44s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 6.5140	Cost: 6.08s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 6.6453	Cost: 7.52s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 6.5999	Cost: 6.21s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 6.6589	Cost: 5.71s
Train Epoch: 185 	Average Loss: 6.8451
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.9139

Learning rate: 0.00019580728994623184
Re-generating waveforms for posterior prior.
Train Epoch: 186 [0/90000 (0%)]	Loss: 10.2600	Cost: 22.88s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 6.6223	Cost: 6.06s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 6.6233	Cost: 7.32s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 6.5890	Cost: 5.77s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 6.6250	Cost: 5.87s
Train Epoch: 186 	Average Loss: 6.8509
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.8917

Learning rate: 0.0001957621645957621
Re-generating waveforms for posterior prior.
Train Epoch: 187 [0/90000 (0%)]	Loss: 10.0193	Cost: 24.14s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 6.6285	Cost: 5.95s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 6.5409	Cost: 7.10s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 6.4422	Cost: 5.76s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 6.4450	Cost: 6.10s
Train Epoch: 187 	Average Loss: 6.7402
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.7730

Learning rate: 0.00019571680296167073
Re-generating waveforms for posterior prior.
Train Epoch: 188 [0/90000 (0%)]	Loss: 9.9820	Cost: 22.96s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 6.4725	Cost: 6.05s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 6.6588	Cost: 7.51s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 6.5483	Cost: 5.83s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 6.5202	Cost: 6.16s
Train Epoch: 188 	Average Loss: 6.7398
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.7803

Learning rate: 0.00019567120515588297
Re-generating waveforms for posterior prior.
Train Epoch: 189 [0/90000 (0%)]	Loss: 10.0566	Cost: 23.00s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 6.4191	Cost: 6.08s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 6.7149	Cost: 7.46s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 6.4065	Cost: 5.82s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 6.4908	Cost: 6.20s
Train Epoch: 189 	Average Loss: 6.7437
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.9284

Learning rate: 0.00019562537129090684
Re-generating waveforms for posterior prior.
Train Epoch: 190 [0/90000 (0%)]	Loss: 10.0795	Cost: 22.79s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 6.3974	Cost: 6.03s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 6.5668	Cost: 7.69s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 6.4608	Cost: 5.74s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 6.5105	Cost: 5.84s
Train Epoch: 190 	Average Loss: 6.7019
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.8430

Learning rate: 0.0001955793014798329
Re-generating waveforms for posterior prior.
Train Epoch: 191 [0/90000 (0%)]	Loss: 9.9196	Cost: 23.11s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 6.3847	Cost: 6.04s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 6.5841	Cost: 6.87s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 6.2630	Cost: 5.81s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 6.3767	Cost: 6.46s
Train Epoch: 191 	Average Loss: 6.6516
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.8835

Learning rate: 0.00019553299583633386
Re-generating waveforms for posterior prior.
Train Epoch: 192 [0/90000 (0%)]	Loss: 10.1121	Cost: 23.04s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 6.2410	Cost: 6.07s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 6.4593	Cost: 6.79s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 6.3087	Cost: 5.81s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 6.4776	Cost: 5.71s
Train Epoch: 192 	Average Loss: 6.6084
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.7348

Learning rate: 0.00019548645447466423
Re-generating waveforms for posterior prior.
Train Epoch: 193 [0/90000 (0%)]	Loss: 9.9446	Cost: 25.41s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 6.2167	Cost: 6.07s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 6.3418	Cost: 7.68s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 6.1849	Cost: 8.40s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 6.3409	Cost: 5.63s
Train Epoch: 193 	Average Loss: 6.5571
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.6596

Learning rate: 0.0001954396775096602
Re-generating waveforms for posterior prior.
Train Epoch: 194 [0/90000 (0%)]	Loss: 9.9233	Cost: 22.80s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 6.2291	Cost: 6.06s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 6.3943	Cost: 7.29s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 6.2832	Cost: 5.80s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 6.2307	Cost: 6.06s
Train Epoch: 194 	Average Loss: 6.5492
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.7333

Learning rate: 0.0001953926650567393
Re-generating waveforms for posterior prior.
Train Epoch: 195 [0/90000 (0%)]	Loss: 9.7463	Cost: 22.87s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 6.1258	Cost: 6.07s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 6.2507	Cost: 7.33s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 6.1985	Cost: 5.83s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 6.3953	Cost: 6.19s
Train Epoch: 195 	Average Loss: 6.5046
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.6330

Learning rate: 0.00019534541723190005
Re-generating waveforms for posterior prior.
Train Epoch: 196 [0/90000 (0%)]	Loss: 9.8378	Cost: 24.20s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 6.1555	Cost: 6.08s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 6.3005	Cost: 6.51s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 6.2100	Cost: 5.81s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 6.3055	Cost: 5.84s
Train Epoch: 196 	Average Loss: 6.4678
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.6974

Learning rate: 0.00019529793415172183
Re-generating waveforms for posterior prior.
Train Epoch: 197 [0/90000 (0%)]	Loss: 9.6823	Cost: 23.21s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 6.1545	Cost: 6.04s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 6.4077	Cost: 7.44s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 6.1281	Cost: 5.75s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 6.2495	Cost: 6.00s
Train Epoch: 197 	Average Loss: 6.4452
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.6617

Learning rate: 0.00019525021593336434
Re-generating waveforms for posterior prior.
Train Epoch: 198 [0/90000 (0%)]	Loss: 9.7625	Cost: 23.24s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 6.0899	Cost: 6.04s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 6.2352	Cost: 7.35s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 6.1696	Cost: 5.78s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 6.2588	Cost: 5.66s
Train Epoch: 198 	Average Loss: 6.4765
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.6079

Learning rate: 0.0001952022626945676
Re-generating waveforms for posterior prior.
Train Epoch: 199 [0/90000 (0%)]	Loss: 9.7639	Cost: 23.66s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 6.0555	Cost: 6.05s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 6.2967	Cost: 7.47s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 6.1517	Cost: 5.76s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 6.1953	Cost: 5.97s
Train Epoch: 199 	Average Loss: 6.4368
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.6616

Learning rate: 0.0001951540745536514
Re-generating waveforms for posterior prior.
Train Epoch: 200 [0/90000 (0%)]	Loss: 9.7966	Cost: 23.77s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 6.0486	Cost: 6.11s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 6.2328	Cost: 7.48s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 6.1388	Cost: 5.77s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 6.0337	Cost: 5.79s
Train Epoch: 200 	Average Loss: 6.3983
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.6166

Saving model as model_sample_from_all_posterior.pt_e200 & waveforms_supplementary_sample_from_all_posterior.hdf5_e200
Learning rate: 0.0001951056516295153
Re-generating waveforms for posterior prior.
Train Epoch: 201 [0/90000 (0%)]	Loss: 9.5532	Cost: 24.67s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 5.9185	Cost: 6.01s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 6.2122	Cost: 7.18s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 6.0441	Cost: 5.79s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 6.0786	Cost: 6.05s
Train Epoch: 201 	Average Loss: 6.3404
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.5168

Learning rate: 0.00019505699404163794
Re-generating waveforms for posterior prior.
Train Epoch: 202 [0/90000 (0%)]	Loss: 9.8301	Cost: 22.63s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 6.0136	Cost: 6.06s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 6.0978	Cost: 7.59s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 6.0527	Cost: 5.76s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 6.0660	Cost: 5.79s
Train Epoch: 202 	Average Loss: 6.2961
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.5572

Learning rate: 0.00019500810191007707
Re-generating waveforms for posterior prior.
Train Epoch: 203 [0/90000 (0%)]	Loss: 9.5749	Cost: 23.08s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 5.9553	Cost: 6.07s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 6.1257	Cost: 6.90s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 5.9754	Cost: 5.87s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 6.0904	Cost: 5.84s
Train Epoch: 203 	Average Loss: 6.2549
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.5317

Learning rate: 0.00019495897535546928
Re-generating waveforms for posterior prior.
Train Epoch: 204 [0/90000 (0%)]	Loss: 9.5572	Cost: 22.73s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 5.8332	Cost: 6.17s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 5.9596	Cost: 7.38s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 6.0691	Cost: 5.78s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 6.0795	Cost: 6.05s
Train Epoch: 204 	Average Loss: 6.2377
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.5194

Learning rate: 0.00019490961449902938
Re-generating waveforms for posterior prior.
Train Epoch: 205 [0/90000 (0%)]	Loss: 9.4981	Cost: 23.15s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 5.9349	Cost: 6.06s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 6.0341	Cost: 7.35s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 5.9221	Cost: 5.76s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 5.9285	Cost: 6.10s
Train Epoch: 205 	Average Loss: 6.1992
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.5076

Learning rate: 0.00019486001946255037
Re-generating waveforms for posterior prior.
Train Epoch: 206 [0/90000 (0%)]	Loss: 9.5293	Cost: 23.25s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 5.7466	Cost: 6.05s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 6.0097	Cost: 7.74s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 5.9788	Cost: 5.72s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 5.8141	Cost: 5.83s
Train Epoch: 206 	Average Loss: 6.1821
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.3734

Learning rate: 0.00019481019036840313
Re-generating waveforms for posterior prior.
Train Epoch: 207 [0/90000 (0%)]	Loss: 9.5820	Cost: 22.89s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 5.7104	Cost: 6.09s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 5.9524	Cost: 7.56s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 5.8294	Cost: 5.81s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 5.9008	Cost: 6.12s
Train Epoch: 207 	Average Loss: 6.1370
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.3520

Learning rate: 0.00019476012733953596
Re-generating waveforms for posterior prior.
Train Epoch: 208 [0/90000 (0%)]	Loss: 9.5154	Cost: 23.22s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 5.7159	Cost: 6.10s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 5.9892	Cost: 7.58s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 5.7999	Cost: 5.76s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 5.8026	Cost: 5.98s
Train Epoch: 208 	Average Loss: 6.1050
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.5247

Learning rate: 0.00019470983049947436
Re-generating waveforms for posterior prior.
Train Epoch: 209 [0/90000 (0%)]	Loss: 9.7956	Cost: 23.08s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 5.7231	Cost: 6.08s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 6.0101	Cost: 7.49s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 5.7551	Cost: 5.84s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 5.7178	Cost: 6.01s
Train Epoch: 209 	Average Loss: 6.0921
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.3938

Learning rate: 0.00019465929997232088
Re-generating waveforms for posterior prior.
Train Epoch: 210 [0/90000 (0%)]	Loss: 9.4890	Cost: 23.08s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 5.7395	Cost: 6.08s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 5.7745	Cost: 6.89s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 5.7723	Cost: 5.81s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 5.8103	Cost: 6.29s
Train Epoch: 210 	Average Loss: 6.0311
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.4860

Learning rate: 0.0001946085358827545
Re-generating waveforms for posterior prior.
Train Epoch: 211 [0/90000 (0%)]	Loss: 9.4939	Cost: 24.03s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 5.6509	Cost: 6.01s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 5.8157	Cost: 7.27s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 5.8057	Cost: 5.76s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 5.7630	Cost: 5.87s
Train Epoch: 211 	Average Loss: 6.0273
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.4988

Learning rate: 0.00019455753835603056
Re-generating waveforms for posterior prior.
Train Epoch: 212 [0/90000 (0%)]	Loss: 9.6134	Cost: 23.49s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 5.6808	Cost: 6.05s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 5.7962	Cost: 7.13s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 5.7205	Cost: 5.78s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 5.7061	Cost: 6.07s
Train Epoch: 212 	Average Loss: 5.9938
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.3395

Learning rate: 0.00019450630751798042
Re-generating waveforms for posterior prior.
Train Epoch: 213 [0/90000 (0%)]	Loss: 9.5358	Cost: 22.79s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 5.7775	Cost: 6.02s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 5.9371	Cost: 7.20s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 5.8219	Cost: 5.78s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 5.7222	Cost: 5.91s
Train Epoch: 213 	Average Loss: 5.9838
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.2920

Learning rate: 0.0001944548434950111
Re-generating waveforms for posterior prior.
Train Epoch: 214 [0/90000 (0%)]	Loss: 9.4481	Cost: 23.09s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 5.6464	Cost: 6.07s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 5.7512	Cost: 7.23s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 5.6215	Cost: 5.83s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 5.5801	Cost: 5.97s
Train Epoch: 214 	Average Loss: 5.9286
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.2372

Learning rate: 0.00019440314641410494
Re-generating waveforms for posterior prior.
Train Epoch: 215 [0/90000 (0%)]	Loss: 9.4132	Cost: 22.96s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 5.5692	Cost: 6.04s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 5.6593	Cost: 7.02s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 5.5138	Cost: 5.99s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 5.6592	Cost: 5.80s
Train Epoch: 215 	Average Loss: 5.8877
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.2170

Learning rate: 0.00019435121640281933
Re-generating waveforms for posterior prior.
Train Epoch: 216 [0/90000 (0%)]	Loss: 9.4663	Cost: 23.09s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 5.4693	Cost: 6.10s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 5.6717	Cost: 7.62s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 5.6130	Cost: 5.75s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 5.5373	Cost: 6.13s
Train Epoch: 216 	Average Loss: 5.8406
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.3203

Learning rate: 0.00019429905358928643
Re-generating waveforms for posterior prior.
Train Epoch: 217 [0/90000 (0%)]	Loss: 9.3727	Cost: 23.98s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 5.5332	Cost: 6.03s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 5.6373	Cost: 7.34s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 5.6299	Cost: 5.74s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 5.5609	Cost: 5.73s
Train Epoch: 217 	Average Loss: 5.8430
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.1703

Learning rate: 0.00019424665810221278
Re-generating waveforms for posterior prior.
Train Epoch: 218 [0/90000 (0%)]	Loss: 9.7402	Cost: 23.00s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 5.3546	Cost: 6.06s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 5.6544	Cost: 7.36s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 5.4328	Cost: 5.78s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 5.4741	Cost: 5.89s
Train Epoch: 218 	Average Loss: 5.7944
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.1654

Learning rate: 0.00019419403007087905
Re-generating waveforms for posterior prior.
Train Epoch: 219 [0/90000 (0%)]	Loss: 9.3763	Cost: 23.58s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 5.2450	Cost: 6.00s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 5.6261	Cost: 7.40s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 5.5104	Cost: 5.88s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 5.4990	Cost: 5.97s
Train Epoch: 219 	Average Loss: 5.7662
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.1865

Learning rate: 0.00019414116962513967
Re-generating waveforms for posterior prior.
Train Epoch: 220 [0/90000 (0%)]	Loss: 9.0482	Cost: 23.03s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 5.4212	Cost: 6.05s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 5.5978	Cost: 7.36s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 5.3624	Cost: 5.77s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 5.4593	Cost: 5.70s
Train Epoch: 220 	Average Loss: 5.7193
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.1417

Learning rate: 0.00019408807689542254
Re-generating waveforms for posterior prior.
Train Epoch: 221 [0/90000 (0%)]	Loss: 9.3132	Cost: 25.87s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 5.2980	Cost: 9.54s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 5.4803	Cost: 6.01s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 5.3900	Cost: 5.78s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 5.5090	Cost: 5.65s
Train Epoch: 221 	Average Loss: 5.6994
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.2410

Learning rate: 0.0001940347520127287
Re-generating waveforms for posterior prior.
Train Epoch: 222 [0/90000 (0%)]	Loss: 9.1462	Cost: 22.97s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 5.3675	Cost: 6.07s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 5.5582	Cost: 7.55s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 5.3850	Cost: 5.76s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 5.3940	Cost: 6.02s
Train Epoch: 222 	Average Loss: 5.6472
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.2007

Learning rate: 0.00019398119510863194
Re-generating waveforms for posterior prior.
Train Epoch: 223 [0/90000 (0%)]	Loss: 9.1681	Cost: 22.86s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 5.2773	Cost: 6.09s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 5.4069	Cost: 7.05s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 5.3490	Cost: 5.89s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 5.3019	Cost: 5.89s
Train Epoch: 223 	Average Loss: 5.6492
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.1152

Learning rate: 0.0001939274063152787
Re-generating waveforms for posterior prior.
Train Epoch: 224 [0/90000 (0%)]	Loss: 9.3648	Cost: 24.01s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 5.3380	Cost: 6.14s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 5.5232	Cost: 6.90s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 5.3699	Cost: 5.84s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 5.4918	Cost: 5.91s
Train Epoch: 224 	Average Loss: 5.6870
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.1012

Learning rate: 0.00019387338576538739
Re-generating waveforms for posterior prior.
Train Epoch: 225 [0/90000 (0%)]	Loss: 9.3082	Cost: 22.77s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 5.2541	Cost: 6.13s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 5.5301	Cost: 7.22s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 5.2619	Cost: 5.85s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 5.4283	Cost: 5.89s
Train Epoch: 225 	Average Loss: 5.6160
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.1243

Learning rate: 0.0001938191335922484
Re-generating waveforms for posterior prior.
Train Epoch: 226 [0/90000 (0%)]	Loss: 9.2198	Cost: 22.95s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 5.0166	Cost: 6.07s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 5.4312	Cost: 7.40s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 5.3308	Cost: 5.77s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 5.3297	Cost: 6.10s
Train Epoch: 226 	Average Loss: 5.5562
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.0530

Learning rate: 0.0001937646499297235
Re-generating waveforms for posterior prior.
Train Epoch: 227 [0/90000 (0%)]	Loss: 9.1413	Cost: 23.47s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 5.2181	Cost: 6.05s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 5.3163	Cost: 7.40s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 5.3236	Cost: 5.88s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 5.2335	Cost: 6.00s
Train Epoch: 227 	Average Loss: 5.5172
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.0243

Learning rate: 0.00019370993491224584
Re-generating waveforms for posterior prior.
Train Epoch: 228 [0/90000 (0%)]	Loss: 9.3182	Cost: 22.84s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 5.0976	Cost: 6.07s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 5.4571	Cost: 7.18s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 5.1493	Cost: 5.76s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 5.1435	Cost: 6.17s
Train Epoch: 228 	Average Loss: 5.4822
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.9034

Learning rate: 0.0001936549886748192
Re-generating waveforms for posterior prior.
Train Epoch: 229 [0/90000 (0%)]	Loss: 9.2655	Cost: 23.21s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 5.0494	Cost: 6.04s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 5.3215	Cost: 7.11s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 5.1553	Cost: 5.77s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 5.3196	Cost: 6.03s
Train Epoch: 229 	Average Loss: 5.4957
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.9634

Learning rate: 0.00019359981135301795
Re-generating waveforms for posterior prior.
Train Epoch: 230 [0/90000 (0%)]	Loss: 9.1318	Cost: 22.66s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 5.1344	Cost: 6.05s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 5.3191	Cost: 7.12s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 5.1790	Cost: 5.94s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 5.1525	Cost: 5.93s
Train Epoch: 230 	Average Loss: 5.4759
Re-generating waveforms for posterior prior.
Test set: Average loss: 9.0260

Learning rate: 0.0001935444030829867
Re-generating waveforms for posterior prior.
Train Epoch: 231 [0/90000 (0%)]	Loss: 8.9855	Cost: 23.23s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 5.0516	Cost: 6.11s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 5.2836	Cost: 7.55s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 5.1159	Cost: 5.75s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 5.1486	Cost: 6.04s
Train Epoch: 231 	Average Loss: 5.4071
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.8964

Learning rate: 0.00019348876400143976
Re-generating waveforms for posterior prior.
Train Epoch: 232 [0/90000 (0%)]	Loss: 8.9552	Cost: 22.81s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 4.9310	Cost: 6.07s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 5.1746	Cost: 7.32s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 5.0620	Cost: 5.89s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 4.9375	Cost: 6.02s
Train Epoch: 232 	Average Loss: 5.3675
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.9370

Learning rate: 0.00019343289424566116
Re-generating waveforms for posterior prior.
Train Epoch: 233 [0/90000 (0%)]	Loss: 9.1217	Cost: 23.42s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 5.0707	Cost: 6.05s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 5.1128	Cost: 7.24s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 5.0934	Cost: 5.76s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 4.9583	Cost: 5.88s
Train Epoch: 233 	Average Loss: 5.3546
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.7429

Learning rate: 0.00019337679395350387
Re-generating waveforms for posterior prior.
Train Epoch: 234 [0/90000 (0%)]	Loss: 9.1027	Cost: 24.08s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 5.0029	Cost: 6.03s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 5.0763	Cost: 7.12s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 4.9602	Cost: 5.82s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 5.0280	Cost: 5.89s
Train Epoch: 234 	Average Loss: 5.2817
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.9107

Learning rate: 0.0001933204632633898
Re-generating waveforms for posterior prior.
Train Epoch: 235 [0/90000 (0%)]	Loss: 8.9971	Cost: 23.07s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 4.8185	Cost: 6.09s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 5.1288	Cost: 6.89s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 4.8929	Cost: 5.83s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 5.0348	Cost: 5.90s
Train Epoch: 235 	Average Loss: 5.2792
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.7288

Learning rate: 0.00019326390231430937
Re-generating waveforms for posterior prior.
Train Epoch: 236 [0/90000 (0%)]	Loss: 8.9345	Cost: 23.70s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 4.8623	Cost: 6.07s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 5.0412	Cost: 7.00s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 4.9597	Cost: 5.80s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 4.9633	Cost: 6.12s
Train Epoch: 236 	Average Loss: 5.2414
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.8751

Learning rate: 0.00019320711124582105
Re-generating waveforms for posterior prior.
Train Epoch: 237 [0/90000 (0%)]	Loss: 9.0448	Cost: 23.11s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 4.9308	Cost: 6.05s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 5.0825	Cost: 7.03s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 4.8644	Cost: 5.83s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 4.9300	Cost: 5.83s
Train Epoch: 237 	Average Loss: 5.2298
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.7639

Learning rate: 0.00019315009019805118
Re-generating waveforms for posterior prior.
Train Epoch: 238 [0/90000 (0%)]	Loss: 8.9479	Cost: 23.20s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 4.8147	Cost: 6.08s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 5.0023	Cost: 7.39s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 4.8355	Cost: 5.77s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 4.9564	Cost: 6.10s
Train Epoch: 238 	Average Loss: 5.1625
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.7153

Learning rate: 0.0001930928393116935
Re-generating waveforms for posterior prior.
Train Epoch: 239 [0/90000 (0%)]	Loss: 9.0163	Cost: 23.06s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 4.7294	Cost: 6.07s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 4.9494	Cost: 6.87s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 4.9294	Cost: 6.08s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 4.8618	Cost: 6.37s
Train Epoch: 239 	Average Loss: 5.1673
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.7767

Learning rate: 0.00019303535872800895
Re-generating waveforms for posterior prior.
Train Epoch: 240 [0/90000 (0%)]	Loss: 8.7066	Cost: 23.10s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 4.8456	Cost: 6.08s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 5.0773	Cost: 7.16s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 4.9273	Cost: 6.20s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 4.8768	Cost: 5.70s
Train Epoch: 240 	Average Loss: 5.1653
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.7297

Learning rate: 0.00019297764858882508
Re-generating waveforms for posterior prior.
Train Epoch: 241 [0/90000 (0%)]	Loss: 9.0538	Cost: 23.01s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 4.7978	Cost: 6.13s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 5.0358	Cost: 7.18s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 4.8636	Cost: 6.04s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 4.7658	Cost: 5.65s
Train Epoch: 241 	Average Loss: 5.1479
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.6743

Learning rate: 0.000192919709036536
Re-generating waveforms for posterior prior.
Train Epoch: 242 [0/90000 (0%)]	Loss: 8.7555	Cost: 23.10s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 4.7465	Cost: 6.08s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 4.9054	Cost: 7.62s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 4.8120	Cost: 5.74s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 4.9073	Cost: 6.07s
Train Epoch: 242 	Average Loss: 5.0549
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.7202

Learning rate: 0.0001928615402141017
Re-generating waveforms for posterior prior.
Train Epoch: 243 [0/90000 (0%)]	Loss: 9.0072	Cost: 22.80s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 4.7668	Cost: 6.09s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 4.8982	Cost: 7.18s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 4.7398	Cost: 5.75s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 4.7630	Cost: 6.25s
Train Epoch: 243 	Average Loss: 5.0820
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.7398

Learning rate: 0.00019280314226504804
Re-generating waveforms for posterior prior.
Train Epoch: 244 [0/90000 (0%)]	Loss: 8.6846	Cost: 23.14s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 4.6480	Cost: 6.07s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 4.8246	Cost: 6.91s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 4.7309	Cost: 5.92s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 4.6875	Cost: 5.69s
Train Epoch: 244 	Average Loss: 5.0357
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.6469

Learning rate: 0.0001927445153334661
Re-generating waveforms for posterior prior.
Train Epoch: 245 [0/90000 (0%)]	Loss: 8.7262	Cost: 23.33s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 4.5890	Cost: 6.08s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 4.8569	Cost: 7.08s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 4.7087	Cost: 5.83s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 4.7088	Cost: 5.90s
Train Epoch: 245 	Average Loss: 4.9760
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.7986

Learning rate: 0.00019268565956401205
Re-generating waveforms for posterior prior.
Train Epoch: 246 [0/90000 (0%)]	Loss: 8.5789	Cost: 23.17s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 4.6911	Cost: 6.03s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 4.9124	Cost: 7.22s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 4.7644	Cost: 5.82s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 4.5844	Cost: 6.02s
Train Epoch: 246 	Average Loss: 5.0017
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.5401

Learning rate: 0.00019262657510190666
Re-generating waveforms for posterior prior.
Train Epoch: 247 [0/90000 (0%)]	Loss: 8.6736	Cost: 23.56s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 4.5797	Cost: 6.07s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 4.7960	Cost: 6.75s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 4.6082	Cost: 5.79s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 4.5376	Cost: 6.32s
Train Epoch: 247 	Average Loss: 4.9097
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.3709

Learning rate: 0.00019256726209293494
Re-generating waveforms for posterior prior.
Train Epoch: 248 [0/90000 (0%)]	Loss: 8.5443	Cost: 23.26s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 4.4280	Cost: 6.06s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 4.7520	Cost: 6.74s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 4.6699	Cost: 5.94s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 4.6838	Cost: 6.10s
Train Epoch: 248 	Average Loss: 4.8964
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.4434

Learning rate: 0.0001925077206834458
Re-generating waveforms for posterior prior.
Train Epoch: 249 [0/90000 (0%)]	Loss: 8.7699	Cost: 23.32s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 4.4425	Cost: 6.09s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 4.6737	Cost: 7.40s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 4.5441	Cost: 5.74s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 4.5407	Cost: 6.16s
Train Epoch: 249 	Average Loss: 4.8505
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.4955

Learning rate: 0.00019244795102035185
Re-generating waveforms for posterior prior.
Train Epoch: 250 [0/90000 (0%)]	Loss: 8.8553	Cost: 23.56s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 4.3820	Cost: 6.06s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 4.6451	Cost: 6.96s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 4.5384	Cost: 5.76s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 4.4845	Cost: 5.95s
Train Epoch: 250 	Average Loss: 4.8062
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.4845

Saving model as model_sample_from_all_posterior.pt_e250 & waveforms_supplementary_sample_from_all_posterior.hdf5_e250
Learning rate: 0.0001923879532511287
Re-generating waveforms for posterior prior.
Train Epoch: 251 [0/90000 (0%)]	Loss: 8.8113	Cost: 23.27s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 4.4363	Cost: 6.03s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 4.6985	Cost: 6.71s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 4.5970	Cost: 5.77s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 4.3905	Cost: 6.21s
Train Epoch: 251 	Average Loss: 4.7914
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.4833

Learning rate: 0.0001923277275238149
Re-generating waveforms for posterior prior.
Train Epoch: 252 [0/90000 (0%)]	Loss: 8.5156	Cost: 30.20s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 4.3064	Cost: 6.04s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 4.7393	Cost: 6.03s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 4.4332	Cost: 5.85s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 4.3360	Cost: 5.63s
Train Epoch: 252 	Average Loss: 4.7441
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.3686

Learning rate: 0.0001922672739870115
Re-generating waveforms for posterior prior.
Train Epoch: 253 [0/90000 (0%)]	Loss: 8.8701	Cost: 23.11s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 4.3111	Cost: 6.06s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 4.6485	Cost: 7.45s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 4.4220	Cost: 5.75s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 4.3047	Cost: 5.95s
Train Epoch: 253 	Average Loss: 4.7352
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.4491

Learning rate: 0.00019220659278988152
Re-generating waveforms for posterior prior.
Train Epoch: 254 [0/90000 (0%)]	Loss: 8.8012	Cost: 23.36s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 4.3634	Cost: 6.09s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 4.5726	Cost: 7.37s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 4.4321	Cost: 5.78s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 4.4003	Cost: 6.11s
Train Epoch: 254 	Average Loss: 4.7250
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.4897

Learning rate: 0.00019214568408214985
Re-generating waveforms for posterior prior.
Train Epoch: 255 [0/90000 (0%)]	Loss: 8.4393	Cost: 22.92s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 4.3639	Cost: 6.06s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 4.5221	Cost: 7.09s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 4.3691	Cost: 5.83s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 4.3209	Cost: 5.85s
Train Epoch: 255 	Average Loss: 4.6888
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.3635

Learning rate: 0.00019208454801410266
Re-generating waveforms for posterior prior.
Train Epoch: 256 [0/90000 (0%)]	Loss: 8.3595	Cost: 22.87s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 4.1549	Cost: 6.07s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 4.3630	Cost: 7.48s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 4.2990	Cost: 5.82s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 4.2341	Cost: 6.08s
Train Epoch: 256 	Average Loss: 4.6339
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.3973

Learning rate: 0.00019202318473658705
Re-generating waveforms for posterior prior.
Train Epoch: 257 [0/90000 (0%)]	Loss: 8.6056	Cost: 23.19s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 4.2151	Cost: 6.08s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 4.3729	Cost: 6.65s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 4.1941	Cost: 6.10s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 4.4226	Cost: 6.01s
Train Epoch: 257 	Average Loss: 4.6070
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.3857

Learning rate: 0.00019196159440101085
Re-generating waveforms for posterior prior.
Train Epoch: 258 [0/90000 (0%)]	Loss: 8.5476	Cost: 23.07s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 4.1986	Cost: 6.11s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 4.3646	Cost: 6.89s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 4.1933	Cost: 5.82s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 4.2751	Cost: 5.91s
Train Epoch: 258 	Average Loss: 4.5704
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.3482

Learning rate: 0.0001918997771593421
Re-generating waveforms for posterior prior.
Train Epoch: 259 [0/90000 (0%)]	Loss: 8.6179	Cost: 23.64s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 4.0362	Cost: 6.04s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 4.3235	Cost: 7.27s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 4.2395	Cost: 5.76s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 4.2620	Cost: 5.98s
Train Epoch: 259 	Average Loss: 4.5105
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.2363

Learning rate: 0.00019183773316410873
Re-generating waveforms for posterior prior.
Train Epoch: 260 [0/90000 (0%)]	Loss: 8.9218	Cost: 23.26s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 4.0354	Cost: 6.06s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 4.3101	Cost: 7.32s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 4.1726	Cost: 5.77s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 4.1199	Cost: 5.76s
Train Epoch: 260 	Average Loss: 4.4995
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.1905

Learning rate: 0.00019177546256839807
Re-generating waveforms for posterior prior.
Train Epoch: 261 [0/90000 (0%)]	Loss: 8.4967	Cost: 23.47s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 4.1061	Cost: 6.05s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 4.3058	Cost: 7.35s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 4.3030	Cost: 5.74s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 4.1320	Cost: 5.99s
Train Epoch: 261 	Average Loss: 4.5037
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.3778

Learning rate: 0.00019171296552585666
Re-generating waveforms for posterior prior.
Train Epoch: 262 [0/90000 (0%)]	Loss: 8.2722	Cost: 23.08s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 4.1601	Cost: 6.05s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 4.4095	Cost: 7.25s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 4.1762	Cost: 5.77s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 4.2216	Cost: 5.95s
Train Epoch: 262 	Average Loss: 4.4956
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.2370

Learning rate: 0.00019165024219068973
Re-generating waveforms for posterior prior.
Train Epoch: 263 [0/90000 (0%)]	Loss: 8.4142	Cost: 23.64s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 4.0804	Cost: 6.02s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 4.2827	Cost: 7.40s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 4.0989	Cost: 5.73s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 3.9654	Cost: 6.06s
Train Epoch: 263 	Average Loss: 4.4067
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.1693

Learning rate: 0.0001915872927176609
Re-generating waveforms for posterior prior.
Train Epoch: 264 [0/90000 (0%)]	Loss: 8.5355	Cost: 23.47s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 4.1146	Cost: 6.05s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 4.2028	Cost: 7.43s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 4.0681	Cost: 5.76s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 4.0916	Cost: 5.76s
Train Epoch: 264 	Average Loss: 4.3973
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.1406

Learning rate: 0.0001915241172620917
Re-generating waveforms for posterior prior.
Train Epoch: 265 [0/90000 (0%)]	Loss: 8.4038	Cost: 22.94s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 3.9502	Cost: 6.03s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 4.1295	Cost: 7.59s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 4.0444	Cost: 5.73s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 4.0703	Cost: 6.02s
Train Epoch: 265 	Average Loss: 4.3498
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.0630

Learning rate: 0.00019146071597986132
Re-generating waveforms for posterior prior.
Train Epoch: 266 [0/90000 (0%)]	Loss: 8.2778	Cost: 23.12s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 3.9372	Cost: 6.11s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 4.1189	Cost: 7.17s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 4.0673	Cost: 5.78s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 4.1243	Cost: 6.01s
Train Epoch: 266 	Average Loss: 4.3590
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.2383

Learning rate: 0.00019139708902740608
Re-generating waveforms for posterior prior.
Train Epoch: 267 [0/90000 (0%)]	Loss: 8.5604	Cost: 22.62s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 3.9454	Cost: 6.14s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 4.1461	Cost: 7.32s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 3.9110	Cost: 5.79s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 3.9226	Cost: 6.04s
Train Epoch: 267 	Average Loss: 4.3853
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.9784

Learning rate: 0.00019133323656171918
Re-generating waveforms for posterior prior.
Train Epoch: 268 [0/90000 (0%)]	Loss: 8.2949	Cost: 23.22s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 3.8610	Cost: 6.05s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 4.0499	Cost: 7.39s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 3.9665	Cost: 5.77s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 3.9672	Cost: 6.24s
Train Epoch: 268 	Average Loss: 4.2548
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.0887

Learning rate: 0.00019126915874035025
Re-generating waveforms for posterior prior.
Train Epoch: 269 [0/90000 (0%)]	Loss: 8.2678	Cost: 23.25s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 3.8077	Cost: 6.07s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 4.0679	Cost: 7.47s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 3.8369	Cost: 5.74s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 3.8480	Cost: 6.01s
Train Epoch: 269 	Average Loss: 4.2297
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.0256

Learning rate: 0.00019120485572140492
Re-generating waveforms for posterior prior.
Train Epoch: 270 [0/90000 (0%)]	Loss: 8.2866	Cost: 23.08s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 3.7616	Cost: 6.05s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 3.9885	Cost: 7.62s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 3.7841	Cost: 5.75s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 3.7727	Cost: 5.98s
Train Epoch: 270 	Average Loss: 4.2119
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.0220

Learning rate: 0.00019114032766354448
Re-generating waveforms for posterior prior.
Train Epoch: 271 [0/90000 (0%)]	Loss: 8.2529	Cost: 23.18s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 3.7509	Cost: 6.06s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 3.8689	Cost: 7.34s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 3.8295	Cost: 5.79s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 3.8040	Cost: 5.77s
Train Epoch: 271 	Average Loss: 4.1445
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.0383

Learning rate: 0.00019107557472598552
Re-generating waveforms for posterior prior.
Train Epoch: 272 [0/90000 (0%)]	Loss: 8.3220	Cost: 23.23s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 3.7880	Cost: 6.04s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 3.8991	Cost: 7.11s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 3.7440	Cost: 5.92s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 3.8308	Cost: 5.85s
Train Epoch: 272 	Average Loss: 4.0945
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.9039

Learning rate: 0.00019101059706849952
Re-generating waveforms for posterior prior.
Train Epoch: 273 [0/90000 (0%)]	Loss: 8.0830	Cost: 23.95s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 3.7713	Cost: 6.12s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 4.1438	Cost: 6.99s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 3.9729	Cost: 5.77s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 3.8100	Cost: 5.89s
Train Epoch: 273 	Average Loss: 4.2205
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.0415

Learning rate: 0.00019094539485141232
Re-generating waveforms for posterior prior.
Train Epoch: 274 [0/90000 (0%)]	Loss: 8.2603	Cost: 23.12s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 3.7375	Cost: 6.07s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 3.9792	Cost: 7.48s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 3.7343	Cost: 5.90s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 3.6441	Cost: 6.06s
Train Epoch: 274 	Average Loss: 4.1210
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.0685

Learning rate: 0.00019087996823560397
Re-generating waveforms for posterior prior.
Train Epoch: 275 [0/90000 (0%)]	Loss: 8.1950	Cost: 23.32s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 3.8885	Cost: 6.07s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 4.0808	Cost: 7.39s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 3.8575	Cost: 5.81s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 3.7820	Cost: 5.81s
Train Epoch: 275 	Average Loss: 4.1918
Re-generating waveforms for posterior prior.
Test set: Average loss: 8.0129

Learning rate: 0.00019081431738250809
Re-generating waveforms for posterior prior.
Train Epoch: 276 [0/90000 (0%)]	Loss: 8.1260	Cost: 23.02s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 3.7806	Cost: 6.06s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 3.8140	Cost: 7.45s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 3.7406	Cost: 5.74s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 3.6214	Cost: 6.13s
Train Epoch: 276 	Average Loss: 4.0351
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.9044

Learning rate: 0.00019074844245411162
Re-generating waveforms for posterior prior.
Train Epoch: 277 [0/90000 (0%)]	Loss: 8.0281	Cost: 23.21s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 3.5973	Cost: 6.03s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 3.9274	Cost: 7.43s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 3.6295	Cost: 5.72s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 3.6362	Cost: 6.25s
Train Epoch: 277 	Average Loss: 4.0149
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.8980

Learning rate: 0.00019068234361295448
Re-generating waveforms for posterior prior.
Train Epoch: 278 [0/90000 (0%)]	Loss: 8.1025	Cost: 23.14s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 3.6524	Cost: 6.06s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 3.8517	Cost: 7.34s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 3.7215	Cost: 5.75s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 3.6341	Cost: 5.83s
Train Epoch: 278 	Average Loss: 3.9962
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.9531

Learning rate: 0.00019061602102212892
Re-generating waveforms for posterior prior.
Train Epoch: 279 [0/90000 (0%)]	Loss: 8.2165	Cost: 23.25s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 3.5576	Cost: 6.06s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 3.8435	Cost: 7.29s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 3.5253	Cost: 5.83s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 3.4783	Cost: 5.94s
Train Epoch: 279 	Average Loss: 3.9287
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.7526

Learning rate: 0.00019054947484527937
Re-generating waveforms for posterior prior.
Train Epoch: 280 [0/90000 (0%)]	Loss: 8.1212	Cost: 23.03s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 3.6277	Cost: 6.09s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 3.7699	Cost: 7.64s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 3.8103	Cost: 5.75s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 3.6647	Cost: 6.10s
Train Epoch: 280 	Average Loss: 3.9918
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.8059

Learning rate: 0.00019048270524660188
Re-generating waveforms for posterior prior.
Train Epoch: 281 [0/90000 (0%)]	Loss: 8.1201	Cost: 22.94s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 3.5300	Cost: 6.10s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 3.6396	Cost: 7.48s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 3.5759	Cost: 5.75s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 3.5005	Cost: 6.16s
Train Epoch: 281 	Average Loss: 3.8526
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.8767

Learning rate: 0.00019041571239084384
Re-generating waveforms for posterior prior.
Train Epoch: 282 [0/90000 (0%)]	Loss: 8.0637	Cost: 23.22s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 3.3766	Cost: 6.07s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 3.7706	Cost: 7.05s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 3.4083	Cost: 5.92s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 3.5341	Cost: 5.91s
Train Epoch: 282 	Average Loss: 3.8565
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.7569

Learning rate: 0.00019034849644330342
Re-generating waveforms for posterior prior.
Train Epoch: 283 [0/90000 (0%)]	Loss: 7.9751	Cost: 23.37s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 3.3740	Cost: 6.10s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 3.7355	Cost: 7.21s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 3.4052	Cost: 5.90s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 3.3615	Cost: 5.74s
Train Epoch: 283 	Average Loss: 3.8507
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.8801

Learning rate: 0.0001902810575698293
Re-generating waveforms for posterior prior.
Train Epoch: 284 [0/90000 (0%)]	Loss: 8.0681	Cost: 23.12s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 3.5129	Cost: 6.09s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 3.7219	Cost: 6.98s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 3.4028	Cost: 5.90s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 3.4796	Cost: 6.02s
Train Epoch: 284 	Average Loss: 3.8464
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.8539

Learning rate: 0.00019021339593682023
Re-generating waveforms for posterior prior.
Train Epoch: 285 [0/90000 (0%)]	Loss: 8.0120	Cost: 23.06s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 3.3778	Cost: 6.10s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 3.6632	Cost: 7.30s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 3.3883	Cost: 5.79s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 3.5304	Cost: 6.08s
Train Epoch: 285 	Average Loss: 3.8210
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.7511

Learning rate: 0.00019014551171122452
Re-generating waveforms for posterior prior.
Train Epoch: 286 [0/90000 (0%)]	Loss: 7.9666	Cost: 23.16s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 3.4015	Cost: 6.05s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 3.6300	Cost: 7.36s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 3.3797	Cost: 5.80s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 3.2816	Cost: 5.82s
Train Epoch: 286 	Average Loss: 3.7518
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.7853

Learning rate: 0.00019007740506053977
Re-generating waveforms for posterior prior.
Train Epoch: 287 [0/90000 (0%)]	Loss: 8.0632	Cost: 24.48s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 3.3799	Cost: 6.04s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 3.5473	Cost: 7.21s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 3.4455	Cost: 5.79s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 3.3167	Cost: 6.00s
Train Epoch: 287 	Average Loss: 3.7492
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.7056

Learning rate: 0.00019000907615281234
Re-generating waveforms for posterior prior.
Train Epoch: 288 [0/90000 (0%)]	Loss: 7.8104	Cost: 22.68s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 3.2392	Cost: 6.04s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 3.5051	Cost: 7.49s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 3.3186	Cost: 5.74s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 3.3237	Cost: 5.85s
Train Epoch: 288 	Average Loss: 3.6654
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.6124

Learning rate: 0.00018994052515663705
Re-generating waveforms for posterior prior.
Train Epoch: 289 [0/90000 (0%)]	Loss: 7.6165	Cost: 23.15s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 3.2635	Cost: 6.08s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 3.4104	Cost: 7.12s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 3.4204	Cost: 5.85s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 3.3497	Cost: 5.81s
Train Epoch: 289 	Average Loss: 3.6481
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.7906

Learning rate: 0.00018987175224115667
Re-generating waveforms for posterior prior.
Train Epoch: 290 [0/90000 (0%)]	Loss: 7.7821	Cost: 23.66s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 3.3153	Cost: 6.07s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 3.5663	Cost: 6.92s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 3.4014	Cost: 6.06s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 3.2969	Cost: 5.71s
Train Epoch: 290 	Average Loss: 3.7244
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.6734

Learning rate: 0.0001898027575760615
Re-generating waveforms for posterior prior.
Train Epoch: 291 [0/90000 (0%)]	Loss: 7.8924	Cost: 22.60s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 3.1383	Cost: 6.09s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 3.4984	Cost: 7.72s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 3.3507	Cost: 5.96s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 3.2878	Cost: 5.79s
Train Epoch: 291 	Average Loss: 3.6380
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.6026

Learning rate: 0.00018973354133158905
Re-generating waveforms for posterior prior.
Train Epoch: 292 [0/90000 (0%)]	Loss: 7.6022	Cost: 23.59s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 3.2373	Cost: 6.09s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 3.4730	Cost: 6.90s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 3.1783	Cost: 5.84s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 3.1314	Cost: 6.00s
Train Epoch: 292 	Average Loss: 3.5929
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.5402

Learning rate: 0.0001896641036785235
Re-generating waveforms for posterior prior.
Train Epoch: 293 [0/90000 (0%)]	Loss: 7.8228	Cost: 23.09s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 3.1873	Cost: 6.08s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 3.5148	Cost: 6.59s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 3.2847	Cost: 5.86s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 3.1969	Cost: 5.75s
Train Epoch: 293 	Average Loss: 3.5626
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.6450

Learning rate: 0.00018959444478819538
Re-generating waveforms for posterior prior.
Train Epoch: 294 [0/90000 (0%)]	Loss: 7.6022	Cost: 24.69s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 3.1101	Cost: 5.99s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 3.2205	Cost: 7.06s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 3.2336	Cost: 5.79s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 3.2708	Cost: 6.17s
Train Epoch: 294 	Average Loss: 3.5153
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.5761

Learning rate: 0.00018952456483248108
Re-generating waveforms for posterior prior.
Train Epoch: 295 [0/90000 (0%)]	Loss: 7.9138	Cost: 23.02s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 3.1776	Cost: 6.06s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 3.2071	Cost: 7.44s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 3.0134	Cost: 5.73s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 3.1823	Cost: 5.96s
Train Epoch: 295 	Average Loss: 3.4818
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.5547

Learning rate: 0.0001894544639838024
Re-generating waveforms for posterior prior.
Train Epoch: 296 [0/90000 (0%)]	Loss: 7.7997	Cost: 23.16s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 3.0113	Cost: 6.09s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 3.2291	Cost: 7.53s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 3.0650	Cost: 5.76s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 2.9824	Cost: 6.10s
Train Epoch: 296 	Average Loss: 3.4521
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.4570

Learning rate: 0.00018938414241512626
Re-generating waveforms for posterior prior.
Train Epoch: 297 [0/90000 (0%)]	Loss: 7.7056	Cost: 23.19s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 3.1078	Cost: 6.06s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 3.3119	Cost: 7.53s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 3.1158	Cost: 5.75s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 2.9345	Cost: 6.07s
Train Epoch: 297 	Average Loss: 3.4555
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.5247

Learning rate: 0.00018931360029996412
Re-generating waveforms for posterior prior.
Train Epoch: 298 [0/90000 (0%)]	Loss: 7.7845	Cost: 23.35s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 3.0719	Cost: 6.06s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 3.3133	Cost: 7.13s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 3.1049	Cost: 5.84s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 2.9114	Cost: 5.98s
Train Epoch: 298 	Average Loss: 3.3998
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.5618

Learning rate: 0.00018924283781237167
Re-generating waveforms for posterior prior.
Train Epoch: 299 [0/90000 (0%)]	Loss: 7.7226	Cost: 23.43s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 2.7747	Cost: 6.09s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 3.0039	Cost: 7.03s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 2.8477	Cost: 5.79s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 3.0041	Cost: 6.02s
Train Epoch: 299 	Average Loss: 3.3265
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.5444

Learning rate: 0.00018917185512694828
Re-generating waveforms for posterior prior.
Train Epoch: 300 [0/90000 (0%)]	Loss: 7.8355	Cost: 23.24s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 2.8839	Cost: 6.08s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 3.1601	Cost: 7.45s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 2.9231	Cost: 5.78s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 3.1308	Cost: 5.90s
Train Epoch: 300 	Average Loss: 3.3785
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.6032

Saving model as model_sample_from_all_posterior.pt_e300 & waveforms_supplementary_sample_from_all_posterior.hdf5_e300
Learning rate: 0.00018910065241883666
Re-generating waveforms for posterior prior.
Train Epoch: 301 [0/90000 (0%)]	Loss: 7.7794	Cost: 23.40s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 3.0133	Cost: 6.09s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 3.2180	Cost: 7.34s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 2.8985	Cost: 5.76s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 2.8401	Cost: 6.16s
Train Epoch: 301 	Average Loss: 3.3608
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.2968

Learning rate: 0.00018902922986372247
Re-generating waveforms for posterior prior.
Train Epoch: 302 [0/90000 (0%)]	Loss: 7.4115	Cost: 23.34s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 2.8746	Cost: 6.04s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 3.2546	Cost: 7.35s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 3.0919	Cost: 5.76s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 3.0289	Cost: 6.16s
Train Epoch: 302 	Average Loss: 3.3913
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.4041

Learning rate: 0.0001889575876378337
Re-generating waveforms for posterior prior.
Train Epoch: 303 [0/90000 (0%)]	Loss: 7.6297	Cost: 23.48s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 2.8236	Cost: 6.06s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 3.1576	Cost: 6.70s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 2.8965	Cost: 5.79s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 2.8657	Cost: 6.04s
Train Epoch: 303 	Average Loss: 3.3122
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.4279

Learning rate: 0.00018888572591794041
Re-generating waveforms for posterior prior.
Train Epoch: 304 [0/90000 (0%)]	Loss: 7.7070	Cost: 23.45s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 2.9049	Cost: 6.05s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 3.1357	Cost: 7.08s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 2.8800	Cost: 5.75s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 2.7861	Cost: 6.05s
Train Epoch: 304 	Average Loss: 3.2738
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.3374

Learning rate: 0.00018881364488135434
Re-generating waveforms for posterior prior.
Train Epoch: 305 [0/90000 (0%)]	Loss: 7.5906	Cost: 23.13s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 2.7977	Cost: 6.06s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 2.9463	Cost: 6.85s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 2.7068	Cost: 5.78s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 2.7246	Cost: 6.11s
Train Epoch: 305 	Average Loss: 3.1469
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.2676

Learning rate: 0.00018874134470592822
Re-generating waveforms for posterior prior.
Train Epoch: 306 [0/90000 (0%)]	Loss: 7.6170	Cost: 23.16s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 2.6360	Cost: 6.02s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 2.9352	Cost: 7.32s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 2.6919	Cost: 5.72s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 2.8178	Cost: 6.09s
Train Epoch: 306 	Average Loss: 3.1173
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.4173

Learning rate: 0.00018866882557005553
Re-generating waveforms for posterior prior.
Train Epoch: 307 [0/90000 (0%)]	Loss: 7.3021	Cost: 23.21s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 2.7310	Cost: 6.08s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 2.8116	Cost: 7.43s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 2.8273	Cost: 5.74s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 2.8492	Cost: 6.48s
Train Epoch: 307 	Average Loss: 3.1066
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.2458

Learning rate: 0.00018859608765267006
Re-generating waveforms for posterior prior.
Train Epoch: 308 [0/90000 (0%)]	Loss: 7.5397	Cost: 23.93s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 2.6530	Cost: 6.05s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 2.9478	Cost: 7.37s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 2.7565	Cost: 5.76s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 2.7296	Cost: 5.92s
Train Epoch: 308 	Average Loss: 3.0996
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.1824

Learning rate: 0.00018852313113324541
Re-generating waveforms for posterior prior.
Train Epoch: 309 [0/90000 (0%)]	Loss: 7.7693	Cost: 23.60s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 2.9330	Cost: 6.05s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 3.1548	Cost: 7.28s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 2.9135	Cost: 6.11s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 2.8582	Cost: 5.66s
Train Epoch: 309 	Average Loss: 3.2895
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.3315

Learning rate: 0.00018844995619179448
Re-generating waveforms for posterior prior.
Train Epoch: 310 [0/90000 (0%)]	Loss: 7.4729	Cost: 23.58s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 2.7736	Cost: 6.11s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 2.9534	Cost: 6.81s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 2.6668	Cost: 5.81s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 2.6476	Cost: 6.25s
Train Epoch: 310 	Average Loss: 3.1030
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.0997

Learning rate: 0.00018837656300886923
Re-generating waveforms for posterior prior.
Train Epoch: 311 [0/90000 (0%)]	Loss: 7.5569	Cost: 22.87s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 2.5231	Cost: 6.08s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 2.8279	Cost: 7.01s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 2.6531	Cost: 5.76s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 2.6098	Cost: 6.03s
Train Epoch: 311 	Average Loss: 2.9986
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.2000

Learning rate: 0.00018830295176555997
Re-generating waveforms for posterior prior.
Train Epoch: 312 [0/90000 (0%)]	Loss: 7.4879	Cost: 23.27s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 2.5255	Cost: 6.09s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 2.8547	Cost: 7.50s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 2.7245	Cost: 5.77s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 3.1481	Cost: 6.30s
Train Epoch: 312 	Average Loss: 3.0943
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.5495

Learning rate: 0.0001882291226434952
Re-generating waveforms for posterior prior.
Train Epoch: 313 [0/90000 (0%)]	Loss: 7.5401	Cost: 23.64s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 2.8488	Cost: 6.07s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 2.9468	Cost: 7.38s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 2.6991	Cost: 5.76s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 2.6266	Cost: 6.35s
Train Epoch: 313 	Average Loss: 3.2395
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.2508

Learning rate: 0.00018815507582484086
Re-generating waveforms for posterior prior.
Train Epoch: 314 [0/90000 (0%)]	Loss: 7.6743	Cost: 23.46s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 2.7498	Cost: 6.07s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 2.8809	Cost: 7.24s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 2.6437	Cost: 5.83s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 2.7152	Cost: 6.29s
Train Epoch: 314 	Average Loss: 3.0760
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.2363

Learning rate: 0.00018808081149230022
Re-generating waveforms for posterior prior.
Train Epoch: 315 [0/90000 (0%)]	Loss: 7.2512	Cost: 23.66s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 2.6909	Cost: 6.06s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 2.8703	Cost: 7.51s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 2.7934	Cost: 5.81s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 2.6715	Cost: 5.92s
Train Epoch: 315 	Average Loss: 3.0766
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.2348

Learning rate: 0.00018800632982911308
Re-generating waveforms for posterior prior.
Train Epoch: 316 [0/90000 (0%)]	Loss: 7.6037	Cost: 23.68s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 2.8800	Cost: 6.08s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 2.9695	Cost: 7.42s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 2.8964	Cost: 5.75s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 2.8734	Cost: 6.19s
Train Epoch: 316 	Average Loss: 3.1587
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.1645

Learning rate: 0.0001879316310190555
Re-generating waveforms for posterior prior.
Train Epoch: 317 [0/90000 (0%)]	Loss: 7.4162	Cost: 23.17s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 2.6103	Cost: 6.06s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 2.8027	Cost: 7.64s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 2.6142	Cost: 5.76s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 2.5121	Cost: 5.79s
Train Epoch: 317 	Average Loss: 2.9734
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.2169

Learning rate: 0.0001878567152464394
Re-generating waveforms for posterior prior.
Train Epoch: 318 [0/90000 (0%)]	Loss: 7.3986	Cost: 23.58s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 2.3570	Cost: 6.09s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 2.7444	Cost: 6.77s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 2.4887	Cost: 5.81s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 2.2441	Cost: 5.81s
Train Epoch: 318 	Average Loss: 2.8930
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.8818

Learning rate: 0.00018778158269611205
Re-generating waveforms for posterior prior.
Train Epoch: 319 [0/90000 (0%)]	Loss: 7.2554	Cost: 23.09s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 2.4601	Cost: 6.10s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 2.6555	Cost: 7.48s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 2.4845	Cost: 5.79s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 2.3520	Cost: 5.81s
Train Epoch: 319 	Average Loss: 2.8200
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.0554

Learning rate: 0.0001877062335534555
Re-generating waveforms for posterior prior.
Train Epoch: 320 [0/90000 (0%)]	Loss: 7.1618	Cost: 22.66s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 2.3043	Cost: 6.13s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 2.6505	Cost: 6.82s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 2.4806	Cost: 5.85s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 2.5013	Cost: 5.99s
Train Epoch: 320 	Average Loss: 2.7799
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.9771

Learning rate: 0.00018763066800438623
Re-generating waveforms for posterior prior.
Train Epoch: 321 [0/90000 (0%)]	Loss: 7.2635	Cost: 23.54s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 2.2791	Cost: 6.05s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 2.6247	Cost: 6.92s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 2.2849	Cost: 5.78s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 2.3580	Cost: 5.96s
Train Epoch: 321 	Average Loss: 2.7397
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.8314

Learning rate: 0.00018755488623535478
Re-generating waveforms for posterior prior.
Train Epoch: 322 [0/90000 (0%)]	Loss: 7.0574	Cost: 22.98s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 2.3675	Cost: 6.15s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 2.6107	Cost: 7.21s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 2.5184	Cost: 5.81s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 2.3685	Cost: 6.03s
Train Epoch: 322 	Average Loss: 2.7230
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.9794

Learning rate: 0.00018747888843334516
Re-generating waveforms for posterior prior.
Train Epoch: 323 [0/90000 (0%)]	Loss: 7.0606	Cost: 23.38s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 2.2123	Cost: 6.13s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 2.5596	Cost: 7.35s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 2.2811	Cost: 5.75s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 2.3370	Cost: 6.17s
Train Epoch: 323 	Average Loss: 2.7052
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.9465

Learning rate: 0.00018740267478587432
Re-generating waveforms for posterior prior.
Train Epoch: 324 [0/90000 (0%)]	Loss: 7.3450	Cost: 23.55s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 2.3341	Cost: 6.08s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 2.4236	Cost: 7.27s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 2.2789	Cost: 5.97s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 2.2983	Cost: 5.83s
Train Epoch: 324 	Average Loss: 2.6712
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.9483

Learning rate: 0.0001873262454809919
Re-generating waveforms for posterior prior.
Train Epoch: 325 [0/90000 (0%)]	Loss: 7.3260	Cost: 23.31s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 2.1759	Cost: 6.05s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 2.3442	Cost: 7.06s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 2.1603	Cost: 5.78s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 2.1962	Cost: 6.28s
Train Epoch: 325 	Average Loss: 2.5979
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.9075

Learning rate: 0.0001872496007072796
Re-generating waveforms for posterior prior.
Train Epoch: 326 [0/90000 (0%)]	Loss: 7.2534	Cost: 23.24s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 2.1442	Cost: 6.09s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 2.3978	Cost: 7.28s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 2.0794	Cost: 5.77s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 1.9601	Cost: 5.84s
Train Epoch: 326 	Average Loss: 2.5475
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.7165

Learning rate: 0.0001871727406538508
Re-generating waveforms for posterior prior.
Train Epoch: 327 [0/90000 (0%)]	Loss: 6.8616	Cost: 23.12s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 2.0536	Cost: 6.07s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 2.2735	Cost: 7.38s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 2.1535	Cost: 5.76s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 2.1638	Cost: 5.81s
Train Epoch: 327 	Average Loss: 2.5427
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.8669

Learning rate: 0.00018709566551034998
Re-generating waveforms for posterior prior.
Train Epoch: 328 [0/90000 (0%)]	Loss: 7.1063	Cost: 23.27s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 2.0619	Cost: 6.05s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 2.4424	Cost: 7.45s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 2.3933	Cost: 5.71s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 2.2762	Cost: 6.21s
Train Epoch: 328 	Average Loss: 2.6340
Re-generating waveforms for posterior prior.
Test set: Average loss: 7.0055

Learning rate: 0.00018701837546695246
Re-generating waveforms for posterior prior.
Train Epoch: 329 [0/90000 (0%)]	Loss: 6.9607	Cost: 23.03s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 2.1715	Cost: 6.08s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 2.5451	Cost: 7.41s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 2.1595	Cost: 5.76s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 1.9529	Cost: 5.94s
Train Epoch: 329 	Average Loss: 2.5659
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.8085

Learning rate: 0.0001869408707143637
Re-generating waveforms for posterior prior.
Train Epoch: 330 [0/90000 (0%)]	Loss: 7.2047	Cost: 23.08s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 2.1806	Cost: 6.07s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 2.4274	Cost: 7.39s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 2.2097	Cost: 6.16s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 2.3178	Cost: 5.67s
Train Epoch: 330 	Average Loss: 2.6088
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.9095

Learning rate: 0.000186863151443819
Re-generating waveforms for posterior prior.
Train Epoch: 331 [0/90000 (0%)]	Loss: 6.8876	Cost: 23.07s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 2.1877	Cost: 6.06s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 2.3419	Cost: 7.38s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 2.2460	Cost: 5.76s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 2.0571	Cost: 6.45s
Train Epoch: 331 	Average Loss: 2.5579
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.8581

Learning rate: 0.00018678521784708292
Re-generating waveforms for posterior prior.
Train Epoch: 332 [0/90000 (0%)]	Loss: 7.2223	Cost: 23.71s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 2.0314	Cost: 6.31s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 2.1790	Cost: 7.40s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 2.1653	Cost: 5.99s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 2.2226	Cost: 6.03s
Train Epoch: 332 	Average Loss: 2.5060
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.7990

Learning rate: 0.00018670707011644887
Re-generating waveforms for posterior prior.
Train Epoch: 333 [0/90000 (0%)]	Loss: 7.4178	Cost: 23.92s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 2.0123	Cost: 6.35s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 2.2944	Cost: 7.54s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 2.0553	Cost: 5.97s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 2.0973	Cost: 6.68s
Train Epoch: 333 	Average Loss: 2.4639
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.7611

Learning rate: 0.00018662870844473863
Re-generating waveforms for posterior prior.
Train Epoch: 334 [0/90000 (0%)]	Loss: 7.0413	Cost: 24.36s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 1.9206	Cost: 6.37s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 2.1810	Cost: 7.37s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 2.0394	Cost: 6.01s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 2.0197	Cost: 6.11s
Train Epoch: 334 	Average Loss: 2.3781
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.8501

Learning rate: 0.00018655013302530177
Re-generating waveforms for posterior prior.
Train Epoch: 335 [0/90000 (0%)]	Loss: 6.8607	Cost: 24.68s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 1.8485	Cost: 6.31s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 2.1883	Cost: 7.59s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 1.9800	Cost: 5.92s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 2.1201	Cost: 6.89s
Train Epoch: 335 	Average Loss: 2.3872
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.6571

Learning rate: 0.00018647134405201538
Re-generating waveforms for posterior prior.
Train Epoch: 336 [0/90000 (0%)]	Loss: 6.9322	Cost: 24.33s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 1.8293	Cost: 6.37s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 2.0833	Cost: 7.36s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 2.0266	Cost: 5.91s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 1.9692	Cost: 6.30s
Train Epoch: 336 	Average Loss: 2.3516
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.6069

Learning rate: 0.0001863923417192834
Re-generating waveforms for posterior prior.
Train Epoch: 337 [0/90000 (0%)]	Loss: 6.9960	Cost: 23.79s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 1.8826	Cost: 6.37s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 2.1712	Cost: 7.76s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 1.8998	Cost: 6.05s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 1.8030	Cost: 10.85s
Train Epoch: 337 	Average Loss: 2.3346
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.7149

Learning rate: 0.00018631312622203626
Re-generating waveforms for posterior prior.
Train Epoch: 338 [0/90000 (0%)]	Loss: 6.7300	Cost: 24.07s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 1.6568	Cost: 6.24s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 2.0794	Cost: 7.16s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 1.8123	Cost: 5.78s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 1.9522	Cost: 6.32s
Train Epoch: 338 	Average Loss: 2.2211
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.6123

Learning rate: 0.0001862336977557303
Re-generating waveforms for posterior prior.
Train Epoch: 339 [0/90000 (0%)]	Loss: 6.9073	Cost: 23.98s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 1.7599	Cost: 6.18s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 2.2266	Cost: 7.26s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 2.0168	Cost: 5.88s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 1.8304	Cost: 5.85s
Train Epoch: 339 	Average Loss: 2.2786
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.6100

Learning rate: 0.00018615405651634733
Re-generating waveforms for posterior prior.
Train Epoch: 340 [0/90000 (0%)]	Loss: 6.9487	Cost: 23.87s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 1.7010	Cost: 6.22s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 1.9802	Cost: 7.12s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 1.8119	Cost: 5.91s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 1.7947	Cost: 5.72s
Train Epoch: 340 	Average Loss: 2.2111
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.4918

Learning rate: 0.00018607420270039425
Re-generating waveforms for posterior prior.
Train Epoch: 341 [0/90000 (0%)]	Loss: 6.6289	Cost: 23.27s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 1.7625	Cost: 6.11s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 2.0233	Cost: 7.26s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 2.0794	Cost: 5.91s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 2.1534	Cost: 6.08s
Train Epoch: 341 	Average Loss: 2.3204
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.7625

Learning rate: 0.0001859941365049024
Re-generating waveforms for posterior prior.
Train Epoch: 342 [0/90000 (0%)]	Loss: 7.0114	Cost: 23.43s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 1.6707	Cost: 6.19s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 2.0488	Cost: 7.13s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 1.8023	Cost: 5.81s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 2.3156	Cost: 6.30s
Train Epoch: 342 	Average Loss: 2.2958
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.9576

Learning rate: 0.00018591385812742712
Re-generating waveforms for posterior prior.
Train Epoch: 343 [0/90000 (0%)]	Loss: 6.8372	Cost: 24.04s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 2.0659	Cost: 6.30s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 2.2423	Cost: 6.97s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 1.8316	Cost: 5.93s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 1.9332	Cost: 5.88s
Train Epoch: 343 	Average Loss: 2.4226
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.6368

Learning rate: 0.00018583336776604735
Re-generating waveforms for posterior prior.
Train Epoch: 344 [0/90000 (0%)]	Loss: 6.5198	Cost: 24.10s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 1.8990	Cost: 6.35s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 1.9853	Cost: 6.85s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 1.8741	Cost: 5.79s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 1.7414	Cost: 6.08s
Train Epoch: 344 	Average Loss: 2.2189
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.5568

Learning rate: 0.0001857526656193651
Re-generating waveforms for posterior prior.
Train Epoch: 345 [0/90000 (0%)]	Loss: 6.7067	Cost: 22.76s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 1.6755	Cost: 6.14s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 1.9316	Cost: 7.41s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 1.8667	Cost: 5.90s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 1.7683	Cost: 5.87s
Train Epoch: 345 	Average Loss: 2.1603
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.5037

Learning rate: 0.00018567175188650484
Re-generating waveforms for posterior prior.
Train Epoch: 346 [0/90000 (0%)]	Loss: 6.4285	Cost: 24.05s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 1.6611	Cost: 6.31s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 1.8746	Cost: 6.67s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 1.7701	Cost: 6.00s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 1.5191	Cost: 6.40s
Train Epoch: 346 	Average Loss: 2.0682
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.3609

Learning rate: 0.0001855906267671132
Re-generating waveforms for posterior prior.
Train Epoch: 347 [0/90000 (0%)]	Loss: 6.7113	Cost: 23.96s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 1.4162	Cost: 6.41s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 1.7948	Cost: 6.93s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 1.5921	Cost: 5.93s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 1.5441	Cost: 6.61s
Train Epoch: 347 	Average Loss: 1.9956
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.5454

Learning rate: 0.00018550929046135827
Re-generating waveforms for posterior prior.
Train Epoch: 348 [0/90000 (0%)]	Loss: 6.5294	Cost: 23.23s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 1.5238	Cost: 6.22s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 1.8479	Cost: 6.89s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 1.6196	Cost: 5.96s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 1.6806	Cost: 5.89s
Train Epoch: 348 	Average Loss: 2.0258
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.6332

Learning rate: 0.0001854277431699294
Re-generating waveforms for posterior prior.
Train Epoch: 349 [0/90000 (0%)]	Loss: 6.8692	Cost: 24.28s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 1.4892	Cost: 6.22s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 2.0834	Cost: 7.44s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 1.8017	Cost: 6.11s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 1.7506	Cost: 5.62s
Train Epoch: 349 	Average Loss: 2.1098
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.5077

Learning rate: 0.00018534598509403635
Re-generating waveforms for posterior prior.
Train Epoch: 350 [0/90000 (0%)]	Loss: 6.8901	Cost: 24.12s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 1.4419	Cost: 6.26s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 1.9243	Cost: 7.10s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 1.5718	Cost: 6.44s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 1.4545	Cost: 6.03s
Train Epoch: 350 	Average Loss: 2.0121
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.3626

Saving model as model_sample_from_all_posterior.pt_e350 & waveforms_supplementary_sample_from_all_posterior.hdf5_e350
Learning rate: 0.00018526401643540908
Re-generating waveforms for posterior prior.
Train Epoch: 351 [0/90000 (0%)]	Loss: 6.5706	Cost: 23.08s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 1.4705	Cost: 6.32s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 1.7413	Cost: 7.22s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 1.5655	Cost: 6.12s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 1.4914	Cost: 5.93s
Train Epoch: 351 	Average Loss: 1.9353
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.4305

Learning rate: 0.0001851818373962971
Re-generating waveforms for posterior prior.
Train Epoch: 352 [0/90000 (0%)]	Loss: 6.8486	Cost: 23.38s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 1.5588	Cost: 6.31s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 1.8483	Cost: 7.23s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 1.5646	Cost: 5.81s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 1.4939	Cost: 5.88s
Train Epoch: 352 	Average Loss: 2.0379
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.4177

Learning rate: 0.00018509944817946905
Re-generating waveforms for posterior prior.
Train Epoch: 353 [0/90000 (0%)]	Loss: 6.5714	Cost: 23.28s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 1.4136	Cost: 6.79s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 1.8594	Cost: 6.47s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 1.4200	Cost: 5.93s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 1.4308	Cost: 6.55s
Train Epoch: 353 	Average Loss: 1.8721
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.3108

Learning rate: 0.0001850168489882121
Re-generating waveforms for posterior prior.
Train Epoch: 354 [0/90000 (0%)]	Loss: 6.5833	Cost: 23.40s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 1.3597	Cost: 6.78s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 1.5893	Cost: 6.40s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 1.4859	Cost: 5.89s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 1.3756	Cost: 5.98s
Train Epoch: 354 	Average Loss: 1.8236
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.4330

Learning rate: 0.00018493404002633152
Re-generating waveforms for posterior prior.
Train Epoch: 355 [0/90000 (0%)]	Loss: 6.5314	Cost: 22.64s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 1.4811	Cost: 6.33s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 1.8176	Cost: 6.82s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 1.6194	Cost: 5.83s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 1.4827	Cost: 6.11s
Train Epoch: 355 	Average Loss: 1.9472
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.4904

Learning rate: 0.00018485102149815025
Re-generating waveforms for posterior prior.
Train Epoch: 356 [0/90000 (0%)]	Loss: 6.6180	Cost: 23.83s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 1.4470	Cost: 6.09s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 1.8789	Cost: 7.05s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 1.7646	Cost: 5.99s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 1.9099	Cost: 6.21s
Train Epoch: 356 	Average Loss: 2.0932
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.6516

Learning rate: 0.0001847677936085082
Re-generating waveforms for posterior prior.
Train Epoch: 357 [0/90000 (0%)]	Loss: 6.6726	Cost: 23.08s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 1.8094	Cost: 6.24s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 2.1087	Cost: 7.44s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 1.7289	Cost: 5.90s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 1.5906	Cost: 6.16s
Train Epoch: 357 	Average Loss: 2.1649
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.3337

Learning rate: 0.00018468435656276194
Re-generating waveforms for posterior prior.
Train Epoch: 358 [0/90000 (0%)]	Loss: 6.6774	Cost: 23.76s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 1.4020	Cost: 6.31s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 1.8124	Cost: 7.05s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 1.7542	Cost: 6.51s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 1.6917	Cost: 5.72s
Train Epoch: 358 	Average Loss: 1.9685
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.5936

Learning rate: 0.00018460071056678408
Re-generating waveforms for posterior prior.
Train Epoch: 359 [0/90000 (0%)]	Loss: 6.6118	Cost: 23.57s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 1.4064	Cost: 6.08s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 1.6049	Cost: 7.57s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 1.5535	Cost: 5.92s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 1.4814	Cost: 5.79s
Train Epoch: 359 	Average Loss: 1.9275
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.4528

Learning rate: 0.0001845168558269628
Re-generating waveforms for posterior prior.
Train Epoch: 360 [0/90000 (0%)]	Loss: 6.4392	Cost: 23.10s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 1.3549	Cost: 6.19s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 1.4903	Cost: 7.46s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 1.3241	Cost: 5.90s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 1.4895	Cost: 5.76s
Train Epoch: 360 	Average Loss: 1.7954
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.5228

Learning rate: 0.00018443279255020136
Re-generating waveforms for posterior prior.
Train Epoch: 361 [0/90000 (0%)]	Loss: 6.6229	Cost: 24.47s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 1.4979	Cost: 6.24s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 1.6413	Cost: 7.13s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 1.7131	Cost: 6.45s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 1.4670	Cost: 6.28s
Train Epoch: 361 	Average Loss: 1.9749
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.4504

Learning rate: 0.0001843485209439175
Re-generating waveforms for posterior prior.
Train Epoch: 362 [0/90000 (0%)]	Loss: 6.6451	Cost: 23.42s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 1.4438	Cost: 6.71s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 1.7033	Cost: 6.85s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 1.3800	Cost: 5.96s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 1.2108	Cost: 6.05s
Train Epoch: 362 	Average Loss: 1.7670
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.3273

Learning rate: 0.00018426404121604307
Re-generating waveforms for posterior prior.
Train Epoch: 363 [0/90000 (0%)]	Loss: 6.3393	Cost: 23.29s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 1.1408	Cost: 6.16s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 1.3739	Cost: 7.40s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 1.1150	Cost: 5.91s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 1.3929	Cost: 6.28s
Train Epoch: 363 	Average Loss: 1.6373
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.4193

Learning rate: 0.00018417935357502337
Re-generating waveforms for posterior prior.
Train Epoch: 364 [0/90000 (0%)]	Loss: 6.7753	Cost: 24.17s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 1.3047	Cost: 6.28s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 1.4679	Cost: 6.84s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 1.2406	Cost: 5.76s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 1.0695	Cost: 5.92s
Train Epoch: 364 	Average Loss: 1.6337
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.1931

Learning rate: 0.00018409445822981674
Re-generating waveforms for posterior prior.
Train Epoch: 365 [0/90000 (0%)]	Loss: 6.2694	Cost: 23.33s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 1.1266	Cost: 6.26s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 1.4854	Cost: 7.40s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 1.6303	Cost: 5.91s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 1.3908	Cost: 6.40s
Train Epoch: 365 	Average Loss: 1.7853
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.4175

Learning rate: 0.000184009355389894
Re-generating waveforms for posterior prior.
Train Epoch: 366 [0/90000 (0%)]	Loss: 6.6373	Cost: 23.08s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 1.2872	Cost: 6.16s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 1.5641	Cost: 7.06s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 1.2393	Cost: 5.82s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 1.1970	Cost: 5.85s
Train Epoch: 366 	Average Loss: 1.7305
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.2361

Learning rate: 0.00018392404526523798
Re-generating waveforms for posterior prior.
Train Epoch: 367 [0/90000 (0%)]	Loss: 6.3444	Cost: 23.95s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 1.1255	Cost: 6.33s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 1.2956	Cost: 7.03s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 1.1831	Cost: 5.97s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 0.9342	Cost: 5.84s
Train Epoch: 367 	Average Loss: 1.5347
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.1524

Learning rate: 0.0001838385280663429
Re-generating waveforms for posterior prior.
Train Epoch: 368 [0/90000 (0%)]	Loss: 6.5769	Cost: 23.06s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 1.0252	Cost: 6.26s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 1.3310	Cost: 7.24s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 1.0945	Cost: 5.79s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 1.3509	Cost: 5.89s
Train Epoch: 368 	Average Loss: 1.5892
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.2423

Learning rate: 0.000183752804004214
Re-generating waveforms for posterior prior.
Train Epoch: 369 [0/90000 (0%)]	Loss: 6.4071	Cost: 23.69s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 1.1508	Cost: 6.34s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 1.6242	Cost: 7.08s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 1.3573	Cost: 5.79s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 1.1797	Cost: 5.96s
Train Epoch: 369 	Average Loss: 1.7020
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.2132

Learning rate: 0.0001836668732903668
Re-generating waveforms for posterior prior.
Train Epoch: 370 [0/90000 (0%)]	Loss: 6.4160	Cost: 23.29s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 1.1118	Cost: 6.28s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 1.5782	Cost: 7.11s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 1.2004	Cost: 6.02s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 0.9003	Cost: 6.39s
Train Epoch: 370 	Average Loss: 1.5644
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.9387

Learning rate: 0.00018358073613682687
Re-generating waveforms for posterior prior.
Train Epoch: 371 [0/90000 (0%)]	Loss: 6.1502	Cost: 24.26s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 0.7789	Cost: 6.14s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 1.0876	Cost: 7.21s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 0.9688	Cost: 5.97s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 0.8041	Cost: 6.07s
Train Epoch: 371 	Average Loss: 1.3374
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.0357

Learning rate: 0.00018349439275612903
Re-generating waveforms for posterior prior.
Train Epoch: 372 [0/90000 (0%)]	Loss: 6.1968	Cost: 23.21s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 0.9109	Cost: 6.23s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 1.1457	Cost: 7.52s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 0.8868	Cost: 5.98s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 0.7907	Cost: 5.79s
Train Epoch: 372 	Average Loss: 1.3194
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.9484

Learning rate: 0.00018340784336131697
Re-generating waveforms for posterior prior.
Train Epoch: 373 [0/90000 (0%)]	Loss: 5.9583	Cost: 23.86s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 0.6955	Cost: 6.41s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 1.0794	Cost: 7.23s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 0.8115	Cost: 5.88s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 0.7993	Cost: 6.03s
Train Epoch: 373 	Average Loss: 1.2199
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.9323

Learning rate: 0.00018332108816594274
Re-generating waveforms for posterior prior.
Train Epoch: 374 [0/90000 (0%)]	Loss: 5.9103	Cost: 23.29s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 0.8198	Cost: 6.32s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 1.2371	Cost: 7.31s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 1.1273	Cost: 5.99s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 0.9146	Cost: 6.03s
Train Epoch: 374 	Average Loss: 1.3507
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.0195

Learning rate: 0.0001832341273840662
Re-generating waveforms for posterior prior.
Train Epoch: 375 [0/90000 (0%)]	Loss: 6.2315	Cost: 22.77s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 0.9160	Cost: 6.39s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 1.1840	Cost: 7.27s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 0.8451	Cost: 6.14s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 0.8202	Cost: 5.85s
Train Epoch: 375 	Average Loss: 1.3329
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.1228

Learning rate: 0.00018314696123025438
Re-generating waveforms for posterior prior.
Train Epoch: 376 [0/90000 (0%)]	Loss: 6.2524	Cost: 24.13s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 1.0371	Cost: 6.44s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 1.1626	Cost: 6.77s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 0.8856	Cost: 5.93s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 0.7647	Cost: 6.42s
Train Epoch: 376 	Average Loss: 1.3716
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.9635

Learning rate: 0.0001830595899195811
Re-generating waveforms for posterior prior.
Train Epoch: 377 [0/90000 (0%)]	Loss: 6.2143	Cost: 23.55s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 0.8029	Cost: 6.34s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 1.1701	Cost: 7.02s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 0.9477	Cost: 6.00s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 0.8453	Cost: 5.79s
Train Epoch: 377 	Average Loss: 1.3089
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.0160

Learning rate: 0.00018297201366762643
Re-generating waveforms for posterior prior.
Train Epoch: 378 [0/90000 (0%)]	Loss: 6.0950	Cost: 22.91s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 0.7367	Cost: 6.11s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 1.2602	Cost: 7.53s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 0.9518	Cost: 5.78s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 0.9803	Cost: 5.98s
Train Epoch: 378 	Average Loss: 1.4024
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.9712

Learning rate: 0.000182884232690476
Re-generating waveforms for posterior prior.
Train Epoch: 379 [0/90000 (0%)]	Loss: 6.1485	Cost: 23.36s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 0.6779	Cost: 6.09s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 1.1691	Cost: 7.28s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 0.8901	Cost: 5.80s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 0.7755	Cost: 5.95s
Train Epoch: 379 	Average Loss: 1.2755
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.9233

Learning rate: 0.00018279624720472074
Re-generating waveforms for posterior prior.
Train Epoch: 380 [0/90000 (0%)]	Loss: 6.0308	Cost: 23.73s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 0.6623	Cost: 6.12s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 1.1087	Cost: 7.45s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 0.7877	Cost: 5.76s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 0.6311	Cost: 5.91s
Train Epoch: 380 	Average Loss: 1.1869
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.9330

Learning rate: 0.000182708057427456
Re-generating waveforms for posterior prior.
Train Epoch: 381 [0/90000 (0%)]	Loss: 5.8747	Cost: 23.65s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 0.9264	Cost: 6.11s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 1.1691	Cost: 7.25s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 0.9201	Cost: 5.77s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 0.8825	Cost: 5.79s
Train Epoch: 381 	Average Loss: 1.3657
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.9753

Learning rate: 0.00018261966357628135
Re-generating waveforms for posterior prior.
Train Epoch: 382 [0/90000 (0%)]	Loss: 6.2705	Cost: 23.62s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 0.6822	Cost: 6.17s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 1.1778	Cost: 7.48s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 0.7171	Cost: 5.77s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 0.6085	Cost: 5.82s
Train Epoch: 382 	Average Loss: 1.1604
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.7847

Learning rate: 0.0001825310658692998
Re-generating waveforms for posterior prior.
Train Epoch: 383 [0/90000 (0%)]	Loss: 5.7862	Cost: 22.91s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 0.7535	Cost: 6.15s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 1.0513	Cost: 6.85s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 0.6316	Cost: 6.06s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 0.6482	Cost: 5.74s
Train Epoch: 383 	Average Loss: 1.1128
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.8622

Learning rate: 0.00018244226452511736
Re-generating waveforms for posterior prior.
Train Epoch: 384 [0/90000 (0%)]	Loss: 6.2477	Cost: 23.38s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 0.6771	Cost: 6.14s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 0.9395	Cost: 7.61s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 0.6691	Cost: 5.75s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 0.7386	Cost: 5.88s
Train Epoch: 384 	Average Loss: 1.1242
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.9649

Learning rate: 0.00018235325976284256
Re-generating waveforms for posterior prior.
Train Epoch: 385 [0/90000 (0%)]	Loss: 5.9453	Cost: 24.70s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 0.5766	Cost: 6.13s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 1.1067	Cost: 13.46s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 0.6758	Cost: 10.65s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 0.6373	Cost: 5.63s
Train Epoch: 385 	Average Loss: 1.1400
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.8027

Learning rate: 0.0001822640518020858
Re-generating waveforms for posterior prior.
Train Epoch: 386 [0/90000 (0%)]	Loss: 5.9662	Cost: 23.00s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 0.6504	Cost: 6.17s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 0.8488	Cost: 7.44s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 0.7005	Cost: 5.81s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 0.7968	Cost: 6.22s
Train Epoch: 386 	Average Loss: 1.1141
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.8362

Learning rate: 0.00018217464086295885
Re-generating waveforms for posterior prior.
Train Epoch: 387 [0/90000 (0%)]	Loss: 5.9956	Cost: 23.51s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 0.4872	Cost: 6.09s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 0.8940	Cost: 7.52s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 0.8658	Cost: 5.76s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 1.1206	Cost: 6.31s
Train Epoch: 387 	Average Loss: 1.2166
Re-generating waveforms for posterior prior.
Test set: Average loss: 6.2436

Learning rate: 0.00018208502716607428
Re-generating waveforms for posterior prior.
Train Epoch: 388 [0/90000 (0%)]	Loss: 6.2032	Cost: 23.78s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 1.0402	Cost: 6.07s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 1.0871	Cost: 7.06s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 0.9347	Cost: 5.84s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 0.9430	Cost: 5.82s
Train Epoch: 388 	Average Loss: 1.3663
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.8567

Learning rate: 0.00018199521093254507
Re-generating waveforms for posterior prior.
Train Epoch: 389 [0/90000 (0%)]	Loss: 5.9076	Cost: 23.89s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 0.5078	Cost: 6.09s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 0.7479	Cost: 7.44s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 0.7183	Cost: 5.83s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 0.6538	Cost: 6.06s
Train Epoch: 389 	Average Loss: 1.1033
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.8010

Learning rate: 0.00018190519238398374
Re-generating waveforms for posterior prior.
Train Epoch: 390 [0/90000 (0%)]	Loss: 6.0142	Cost: 23.91s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 0.4303	Cost: 6.12s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 0.7596	Cost: 7.40s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 0.5913	Cost: 5.82s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 0.6042	Cost: 5.99s
Train Epoch: 390 	Average Loss: 1.0177
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.7883

Learning rate: 0.00018181497174250217
Re-generating waveforms for posterior prior.
Train Epoch: 391 [0/90000 (0%)]	Loss: 5.9118	Cost: 23.25s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 0.3859	Cost: 6.15s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 0.8322	Cost: 7.26s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 0.9227	Cost: 5.77s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 0.5516	Cost: 5.93s
Train Epoch: 391 	Average Loss: 1.0516
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.8596

Learning rate: 0.00018172454923071082
Re-generating waveforms for posterior prior.
Train Epoch: 392 [0/90000 (0%)]	Loss: 5.7684	Cost: 23.43s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 0.4412	Cost: 6.10s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 0.7638	Cost: 7.56s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 0.5722	Cost: 5.78s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 0.5112	Cost: 5.84s
Train Epoch: 392 	Average Loss: 1.0299
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.7421

Learning rate: 0.00018163392507171823
Re-generating waveforms for posterior prior.
Train Epoch: 393 [0/90000 (0%)]	Loss: 6.0867	Cost: 23.39s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 0.3757	Cost: 6.11s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 0.8350	Cost: 7.55s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 0.3808	Cost: 5.75s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 0.2278	Cost: 5.92s
Train Epoch: 393 	Average Loss: 0.8587
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.5116

Learning rate: 0.0001815430994891305
Re-generating waveforms for posterior prior.
Train Epoch: 394 [0/90000 (0%)]	Loss: 5.9049	Cost: 23.53s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 0.2725	Cost: 6.11s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 0.4884	Cost: 7.64s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 0.2879	Cost: 5.76s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 0.4150	Cost: 6.09s
Train Epoch: 394 	Average Loss: 0.7490
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.6435

Learning rate: 0.00018145207270705077
Re-generating waveforms for posterior prior.
Train Epoch: 395 [0/90000 (0%)]	Loss: 5.8234	Cost: 23.25s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 0.2518	Cost: 6.11s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 0.8217	Cost: 7.46s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 0.6427	Cost: 5.76s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 0.4408	Cost: 5.89s
Train Epoch: 395 	Average Loss: 0.9006
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.7356

Learning rate: 0.00018136084495007856
Re-generating waveforms for posterior prior.
Train Epoch: 396 [0/90000 (0%)]	Loss: 5.8759	Cost: 23.93s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 0.5183	Cost: 6.08s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 0.7156	Cost: 7.42s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 0.2392	Cost: 5.80s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 0.4664	Cost: 5.99s
Train Epoch: 396 	Average Loss: 0.8850
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.7653

Learning rate: 0.00018126941644330921
Re-generating waveforms for posterior prior.
Train Epoch: 397 [0/90000 (0%)]	Loss: 6.1004	Cost: 23.55s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 0.3100	Cost: 6.13s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 0.7054	Cost: 7.36s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 0.2319	Cost: 5.78s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 0.1806	Cost: 6.06s
Train Epoch: 397 	Average Loss: 0.8555
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.5111

Learning rate: 0.0001811777874123336
Re-generating waveforms for posterior prior.
Train Epoch: 398 [0/90000 (0%)]	Loss: 5.6061	Cost: 22.93s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 0.2294	Cost: 6.14s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 0.5964	Cost: 7.60s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 0.2071	Cost: 5.78s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 0.3172	Cost: 6.20s
Train Epoch: 398 	Average Loss: 0.7228
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.6153

Learning rate: 0.0001810859580832372
Re-generating waveforms for posterior prior.
Train Epoch: 399 [0/90000 (0%)]	Loss: 5.7086	Cost: 23.13s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 0.2400	Cost: 6.13s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 0.5781	Cost: 7.37s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 0.3666	Cost: 5.77s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 0.4657	Cost: 6.14s
Train Epoch: 399 	Average Loss: 0.7743
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.6988

Learning rate: 0.00018099392868259971
Re-generating waveforms for posterior prior.
Train Epoch: 400 [0/90000 (0%)]	Loss: 6.1168	Cost: 23.85s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 0.4317	Cost: 6.12s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 0.4916	Cost: 7.06s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 0.3086	Cost: 5.78s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 0.2856	Cost: 5.98s
Train Epoch: 400 	Average Loss: 0.7968
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.4658

Saving model as model_sample_from_all_posterior.pt_e400 & waveforms_supplementary_sample_from_all_posterior.hdf5_e400
Learning rate: 0.0001809016994374946
Re-generating waveforms for posterior prior.
Train Epoch: 401 [0/90000 (0%)]	Loss: 5.9084	Cost: 23.63s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 0.0430	Cost: 6.09s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 0.5496	Cost: 7.45s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 0.1531	Cost: 5.75s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 0.1305	Cost: 5.79s
Train Epoch: 401 	Average Loss: 0.6357
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.4942

Learning rate: 0.00018080927057548832
Re-generating waveforms for posterior prior.
Train Epoch: 402 [0/90000 (0%)]	Loss: 5.5672	Cost: 23.20s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 0.0611	Cost: 6.09s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 0.5181	Cost: 7.27s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 0.1425	Cost: 5.76s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 0.0867	Cost: 5.85s
Train Epoch: 402 	Average Loss: 0.5465
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.4382

Learning rate: 0.00018071664232463988
Re-generating waveforms for posterior prior.
Train Epoch: 403 [0/90000 (0%)]	Loss: 6.0304	Cost: 23.19s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 0.0003	Cost: 6.10s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 0.4945	Cost: 7.32s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 0.1225	Cost: 5.78s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 0.1914	Cost: 5.91s
Train Epoch: 403 	Average Loss: 0.6133
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.5018

Learning rate: 0.00018062381491350035
Re-generating waveforms for posterior prior.
Train Epoch: 404 [0/90000 (0%)]	Loss: 5.8124	Cost: 23.66s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 0.1943	Cost: 6.09s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 0.4272	Cost: 7.17s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 0.1441	Cost: 5.76s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 0.4817	Cost: 6.01s
Train Epoch: 404 	Average Loss: 0.6552
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.7014

Learning rate: 0.00018053078857111204
Re-generating waveforms for posterior prior.
Train Epoch: 405 [0/90000 (0%)]	Loss: 6.0479	Cost: 23.15s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 0.2392	Cost: 6.15s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 0.8522	Cost: 7.42s
Train Epoch: 405 [61440/90000 (68%)]	Loss: 0.5873	Cost: 5.94s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 0.6202	Cost: 6.06s
Train Epoch: 405 	Average Loss: 0.9710
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.6058

Learning rate: 0.0001804375635270083
Re-generating waveforms for posterior prior.
Train Epoch: 406 [0/90000 (0%)]	Loss: 5.7770	Cost: 23.59s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 0.2678	Cost: 6.09s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 0.5250	Cost: 7.43s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 0.2956	Cost: 5.78s
Train Epoch: 406 [81920/90000 (91%)]	Loss: -0.1058	Cost: 5.89s
Train Epoch: 406 	Average Loss: 0.6959
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.4858

Learning rate: 0.00018034414001121265
Re-generating waveforms for posterior prior.
Train Epoch: 407 [0/90000 (0%)]	Loss: 5.3172	Cost: 23.46s
Train Epoch: 407 [20480/90000 (23%)]	Loss: -0.2158	Cost: 6.21s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 0.1515	Cost: 7.25s
Train Epoch: 407 [61440/90000 (68%)]	Loss: -0.1167	Cost: 5.79s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 0.0105	Cost: 5.87s
Train Epoch: 407 	Average Loss: 0.3728
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.3907

Learning rate: 0.00018025051825423826
Re-generating waveforms for posterior prior.
Train Epoch: 408 [0/90000 (0%)]	Loss: 5.8337	Cost: 23.14s
Train Epoch: 408 [20480/90000 (23%)]	Loss: -0.2135	Cost: 6.20s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 0.3413	Cost: 7.26s
Train Epoch: 408 [61440/90000 (68%)]	Loss: 0.1343	Cost: 5.84s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 0.2275	Cost: 6.01s
Train Epoch: 408 	Average Loss: 0.5232
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.5778

Learning rate: 0.00018015669848708756
Re-generating waveforms for posterior prior.
Train Epoch: 409 [0/90000 (0%)]	Loss: 5.7511	Cost: 24.76s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 0.2132	Cost: 6.04s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 0.5307	Cost: 7.22s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 0.3218	Cost: 5.78s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 0.0259	Cost: 5.85s
Train Epoch: 409 	Average Loss: 0.6333
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.4689

Learning rate: 0.00018006268094125148
Re-generating waveforms for posterior prior.
Train Epoch: 410 [0/90000 (0%)]	Loss: 5.5836	Cost: 23.86s
Train Epoch: 410 [20480/90000 (23%)]	Loss: -0.0937	Cost: 6.19s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 0.2201	Cost: 7.34s
Train Epoch: 410 [61440/90000 (68%)]	Loss: -0.0993	Cost: 5.81s
Train Epoch: 410 [81920/90000 (91%)]	Loss: -0.1579	Cost: 5.85s
Train Epoch: 410 	Average Loss: 0.3745
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.3257

Learning rate: 0.00017996846584870897
Re-generating waveforms for posterior prior.
Train Epoch: 411 [0/90000 (0%)]	Loss: 5.5153	Cost: 24.01s
Train Epoch: 411 [20480/90000 (23%)]	Loss: -0.0648	Cost: 6.14s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 0.4155	Cost: 7.03s
Train Epoch: 411 [61440/90000 (68%)]	Loss: -0.0109	Cost: 5.82s
Train Epoch: 411 [81920/90000 (91%)]	Loss: -0.2425	Cost: 5.74s
Train Epoch: 411 	Average Loss: 0.4089
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.2242

Learning rate: 0.00017987405344192637
Re-generating waveforms for posterior prior.
Train Epoch: 412 [0/90000 (0%)]	Loss: 5.4393	Cost: 23.67s
Train Epoch: 412 [20480/90000 (23%)]	Loss: -0.2607	Cost: 6.07s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 0.1081	Cost: 7.56s
Train Epoch: 412 [61440/90000 (68%)]	Loss: -0.1216	Cost: 5.82s
Train Epoch: 412 [81920/90000 (91%)]	Loss: -0.1712	Cost: 5.95s
Train Epoch: 412 	Average Loss: 0.3261
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.3063

Learning rate: 0.000179779443953857
Re-generating waveforms for posterior prior.
Train Epoch: 413 [0/90000 (0%)]	Loss: 5.6290	Cost: 23.29s
Train Epoch: 413 [20480/90000 (23%)]	Loss: -0.0807	Cost: 6.13s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 0.1041	Cost: 7.45s
Train Epoch: 413 [61440/90000 (68%)]	Loss: 0.0293	Cost: 5.73s
Train Epoch: 413 [81920/90000 (91%)]	Loss: -0.0786	Cost: 6.19s
Train Epoch: 413 	Average Loss: 0.3985
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.2563

Learning rate: 0.0001796846376179403
Re-generating waveforms for posterior prior.
Train Epoch: 414 [0/90000 (0%)]	Loss: 5.7391	Cost: 23.31s
Train Epoch: 414 [20480/90000 (23%)]	Loss: -0.0912	Cost: 6.09s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 0.3214	Cost: 7.46s
Train Epoch: 414 [61440/90000 (68%)]	Loss: 0.0362	Cost: 5.73s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 0.1347	Cost: 5.92s
Train Epoch: 414 	Average Loss: 0.4738
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.2758

Learning rate: 0.00017958963466810148
Re-generating waveforms for posterior prior.
Train Epoch: 415 [0/90000 (0%)]	Loss: 5.5428	Cost: 22.89s
Train Epoch: 415 [20480/90000 (23%)]	Loss: -0.1460	Cost: 6.13s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 0.1016	Cost: 7.37s
Train Epoch: 415 [61440/90000 (68%)]	Loss: -0.0430	Cost: 5.77s
Train Epoch: 415 [81920/90000 (91%)]	Loss: -0.1496	Cost: 6.10s
Train Epoch: 415 	Average Loss: 0.3753
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.5570

Learning rate: 0.0001794944353387509
Re-generating waveforms for posterior prior.
Train Epoch: 416 [0/90000 (0%)]	Loss: 5.7608	Cost: 23.49s
Train Epoch: 416 [20480/90000 (23%)]	Loss: -0.1078	Cost: 6.20s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 0.1681	Cost: 7.17s
Train Epoch: 416 [61440/90000 (68%)]	Loss: -0.1584	Cost: 5.82s
Train Epoch: 416 [81920/90000 (91%)]	Loss: -0.1950	Cost: 6.03s
Train Epoch: 416 	Average Loss: 0.3329
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.1350

Learning rate: 0.0001793990398647834
Re-generating waveforms for posterior prior.
Train Epoch: 417 [0/90000 (0%)]	Loss: 5.6033	Cost: 24.21s
Train Epoch: 417 [20480/90000 (23%)]	Loss: -0.3821	Cost: 6.23s
Train Epoch: 417 [40960/90000 (45%)]	Loss: -0.0184	Cost: 6.77s
Train Epoch: 417 [61440/90000 (68%)]	Loss: -0.2894	Cost: 5.89s
Train Epoch: 417 [81920/90000 (91%)]	Loss: -0.4173	Cost: 5.99s
Train Epoch: 417 	Average Loss: 0.1326
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.0679

Learning rate: 0.00017930344848157793
Re-generating waveforms for posterior prior.
Train Epoch: 418 [0/90000 (0%)]	Loss: 5.5489	Cost: 23.59s
Train Epoch: 418 [20480/90000 (23%)]	Loss: -0.4081	Cost: 6.13s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 0.1803	Cost: 7.37s
Train Epoch: 418 [61440/90000 (68%)]	Loss: 0.2362	Cost: 5.76s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 0.1181	Cost: 5.89s
Train Epoch: 418 	Average Loss: 0.4061
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.4901

Learning rate: 0.0001792076614249966
Re-generating waveforms for posterior prior.
Train Epoch: 419 [0/90000 (0%)]	Loss: 5.5892	Cost: 23.45s
Train Epoch: 419 [20480/90000 (23%)]	Loss: 0.2757	Cost: 6.16s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 0.4238	Cost: 7.27s
Train Epoch: 419 [61440/90000 (68%)]	Loss: 0.0994	Cost: 5.75s
Train Epoch: 419 [81920/90000 (91%)]	Loss: -0.1241	Cost: 6.06s
Train Epoch: 419 	Average Loss: 0.6020
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.4378

Learning rate: 0.00017911167893138453
Re-generating waveforms for posterior prior.
Train Epoch: 420 [0/90000 (0%)]	Loss: 5.3834	Cost: 23.58s
Train Epoch: 420 [20480/90000 (23%)]	Loss: -0.1723	Cost: 6.09s
Train Epoch: 420 [40960/90000 (45%)]	Loss: -0.1237	Cost: 7.53s
Train Epoch: 420 [61440/90000 (68%)]	Loss: -0.0818	Cost: 5.74s
Train Epoch: 420 [81920/90000 (91%)]	Loss: -0.3184	Cost: 5.73s
Train Epoch: 420 	Average Loss: 0.2416
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.9823

Learning rate: 0.00017901550123756893
Re-generating waveforms for posterior prior.
Train Epoch: 421 [0/90000 (0%)]	Loss: 5.4460	Cost: 23.92s
Train Epoch: 421 [20480/90000 (23%)]	Loss: -0.3374	Cost: 6.15s
Train Epoch: 421 [40960/90000 (45%)]	Loss: -0.1926	Cost: 7.51s
Train Epoch: 421 [61440/90000 (68%)]	Loss: -0.3597	Cost: 5.78s
Train Epoch: 421 [81920/90000 (91%)]	Loss: -0.2931	Cost: 5.99s
Train Epoch: 421 	Average Loss: 0.1409
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.0489

Learning rate: 0.00017891912858085876
Re-generating waveforms for posterior prior.
Train Epoch: 422 [0/90000 (0%)]	Loss: 5.1378	Cost: 24.03s
Train Epoch: 422 [20480/90000 (23%)]	Loss: -0.4201	Cost: 6.06s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 0.2187	Cost: 7.48s
Train Epoch: 422 [61440/90000 (68%)]	Loss: 0.0844	Cost: 5.75s
Train Epoch: 422 [81920/90000 (91%)]	Loss: -0.1687	Cost: 6.02s
Train Epoch: 422 	Average Loss: 0.3146
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.3006

Learning rate: 0.0001788225611990439
Re-generating waveforms for posterior prior.
Train Epoch: 423 [0/90000 (0%)]	Loss: 5.3461	Cost: 23.69s
Train Epoch: 423 [20480/90000 (23%)]	Loss: -0.0677	Cost: 6.10s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 0.2548	Cost: 7.55s
Train Epoch: 423 [61440/90000 (68%)]	Loss: -0.0281	Cost: 5.76s
Train Epoch: 423 [81920/90000 (91%)]	Loss: -0.1039	Cost: 6.07s
Train Epoch: 423 	Average Loss: 0.4094
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.3817

Learning rate: 0.0001787257993303948
Re-generating waveforms for posterior prior.
Train Epoch: 424 [0/90000 (0%)]	Loss: 5.5692	Cost: 23.45s
Train Epoch: 424 [20480/90000 (23%)]	Loss: -0.4026	Cost: 6.09s
Train Epoch: 424 [40960/90000 (45%)]	Loss: -0.0872	Cost: 7.46s
Train Epoch: 424 [61440/90000 (68%)]	Loss: -0.2376	Cost: 5.77s
Train Epoch: 424 [81920/90000 (91%)]	Loss: -0.1356	Cost: 5.73s
Train Epoch: 424 	Average Loss: 0.2015
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.3117

Learning rate: 0.00017862884321366177
Re-generating waveforms for posterior prior.
Train Epoch: 425 [0/90000 (0%)]	Loss: 5.4574	Cost: 23.42s
Train Epoch: 425 [20480/90000 (23%)]	Loss: -0.3540	Cost: 6.05s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 0.0892	Cost: 7.65s
Train Epoch: 425 [61440/90000 (68%)]	Loss: -0.1884	Cost: 5.84s
Train Epoch: 425 [81920/90000 (91%)]	Loss: -0.2987	Cost: 5.73s
Train Epoch: 425 	Average Loss: 0.2256
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.3340

Learning rate: 0.00017853169308807438
Re-generating waveforms for posterior prior.
Train Epoch: 426 [0/90000 (0%)]	Loss: 5.1511	Cost: 23.82s
Train Epoch: 426 [20480/90000 (23%)]	Loss: -0.4467	Cost: 6.14s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 0.0571	Cost: 7.08s
Train Epoch: 426 [61440/90000 (68%)]	Loss: -0.0475	Cost: 5.83s
Train Epoch: 426 [81920/90000 (91%)]	Loss: -0.1960	Cost: 5.77s
Train Epoch: 426 	Average Loss: 0.2059
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.2706

Learning rate: 0.0001784343491933409
Re-generating waveforms for posterior prior.
Train Epoch: 427 [0/90000 (0%)]	Loss: 5.5438	Cost: 23.40s
Train Epoch: 427 [20480/90000 (23%)]	Loss: -0.3357	Cost: 6.13s
Train Epoch: 427 [40960/90000 (45%)]	Loss: -0.1490	Cost: 7.34s
Train Epoch: 427 [61440/90000 (68%)]	Loss: -0.5119	Cost: 5.78s
Train Epoch: 427 [81920/90000 (91%)]	Loss: -0.3620	Cost: 6.05s
Train Epoch: 427 	Average Loss: 0.1105
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.1493

Learning rate: 0.00017833681176964773
Re-generating waveforms for posterior prior.
Train Epoch: 428 [0/90000 (0%)]	Loss: 5.3049	Cost: 23.59s
Train Epoch: 428 [20480/90000 (23%)]	Loss: -0.3740	Cost: 6.17s
Train Epoch: 428 [40960/90000 (45%)]	Loss: -0.1026	Cost: 7.55s
Train Epoch: 428 [61440/90000 (68%)]	Loss: -0.3997	Cost: 5.77s
Train Epoch: 428 [81920/90000 (91%)]	Loss: -0.5406	Cost: 5.99s
Train Epoch: 428 	Average Loss: 0.0580
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.9001

Learning rate: 0.00017823908105765873
Re-generating waveforms for posterior prior.
Train Epoch: 429 [0/90000 (0%)]	Loss: 4.9045	Cost: 23.31s
Train Epoch: 429 [20480/90000 (23%)]	Loss: -0.5199	Cost: 6.10s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 0.1016	Cost: 6.76s
Train Epoch: 429 [61440/90000 (68%)]	Loss: 0.2654	Cost: 5.99s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 0.1905	Cost: 5.68s
Train Epoch: 429 	Average Loss: 0.2633
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.4074

Learning rate: 0.00017814115729851472
Re-generating waveforms for posterior prior.
Train Epoch: 430 [0/90000 (0%)]	Loss: 5.6702	Cost: 23.20s
Train Epoch: 430 [20480/90000 (23%)]	Loss: -0.1537	Cost: 6.12s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 0.1692	Cost: 7.35s
Train Epoch: 430 [61440/90000 (68%)]	Loss: -0.1271	Cost: 6.00s
Train Epoch: 430 [81920/90000 (91%)]	Loss: -0.4015	Cost: 5.91s
Train Epoch: 430 	Average Loss: 0.3041
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.0385

Learning rate: 0.00017804304073383288
Re-generating waveforms for posterior prior.
Train Epoch: 431 [0/90000 (0%)]	Loss: 5.1960	Cost: 23.47s
Train Epoch: 431 [20480/90000 (23%)]	Loss: 0.0618	Cost: 6.11s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 0.3416	Cost: 7.31s
Train Epoch: 431 [61440/90000 (68%)]	Loss: 0.1000	Cost: 5.76s
Train Epoch: 431 [81920/90000 (91%)]	Loss: -0.0123	Cost: 6.15s
Train Epoch: 431 	Average Loss: 0.4462
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.3834

Learning rate: 0.00017794473160570606
Re-generating waveforms for posterior prior.
Train Epoch: 432 [0/90000 (0%)]	Loss: 5.9141	Cost: 23.87s
Train Epoch: 432 [20480/90000 (23%)]	Loss: -0.2941	Cost: 6.13s
Train Epoch: 432 [40960/90000 (45%)]	Loss: -0.0430	Cost: 6.69s
Train Epoch: 432 [61440/90000 (68%)]	Loss: -0.4696	Cost: 5.90s
Train Epoch: 432 [81920/90000 (91%)]	Loss: -0.5241	Cost: 5.89s
Train Epoch: 432 	Average Loss: 0.1157
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.1093

Learning rate: 0.00017784623015670227
Re-generating waveforms for posterior prior.
Train Epoch: 433 [0/90000 (0%)]	Loss: 5.4548	Cost: 22.98s
Train Epoch: 433 [20480/90000 (23%)]	Loss: -0.4235	Cost: 6.18s
Train Epoch: 433 [40960/90000 (45%)]	Loss: -0.2783	Cost: 7.68s
Train Epoch: 433 [61440/90000 (68%)]	Loss: -0.6193	Cost: 5.73s
Train Epoch: 433 [81920/90000 (91%)]	Loss: -0.6947	Cost: 6.03s
Train Epoch: 433 	Average Loss: -0.0525
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.9163

Learning rate: 0.000177747536629864
Re-generating waveforms for posterior prior.
Train Epoch: 434 [0/90000 (0%)]	Loss: 4.9474	Cost: 23.86s
Train Epoch: 434 [20480/90000 (23%)]	Loss: -0.7242	Cost: 6.10s
Train Epoch: 434 [40960/90000 (45%)]	Loss: -0.4072	Cost: 6.98s
Train Epoch: 434 [61440/90000 (68%)]	Loss: -0.6612	Cost: 5.85s
Train Epoch: 434 [81920/90000 (91%)]	Loss: -0.7660	Cost: 5.98s
Train Epoch: 434 	Average Loss: -0.2160
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.9934

Learning rate: 0.00017764865126870775
Re-generating waveforms for posterior prior.
Train Epoch: 435 [0/90000 (0%)]	Loss: 5.2444	Cost: 23.02s
Train Epoch: 435 [20480/90000 (23%)]	Loss: -0.5240	Cost: 6.11s
Train Epoch: 435 [40960/90000 (45%)]	Loss: -0.3180	Cost: 7.53s
Train Epoch: 435 [61440/90000 (68%)]	Loss: -0.6525	Cost: 5.76s
Train Epoch: 435 [81920/90000 (91%)]	Loss: -0.7501	Cost: 5.77s
Train Epoch: 435 	Average Loss: -0.1172
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.8799

Learning rate: 0.00017754957431722335
Re-generating waveforms for posterior prior.
Train Epoch: 436 [0/90000 (0%)]	Loss: 5.0067	Cost: 23.22s
Train Epoch: 436 [20480/90000 (23%)]	Loss: -0.9624	Cost: 6.13s
Train Epoch: 436 [40960/90000 (45%)]	Loss: -0.4824	Cost: 7.51s
Train Epoch: 436 [61440/90000 (68%)]	Loss: -0.8883	Cost: 5.79s
Train Epoch: 436 [81920/90000 (91%)]	Loss: -0.8941	Cost: 5.89s
Train Epoch: 436 	Average Loss: -0.4048
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.7892

Learning rate: 0.0001774503060198733
Re-generating waveforms for posterior prior.
Train Epoch: 437 [0/90000 (0%)]	Loss: 5.0765	Cost: 23.50s
Train Epoch: 437 [20480/90000 (23%)]	Loss: -0.8190	Cost: 6.12s
Train Epoch: 437 [40960/90000 (45%)]	Loss: -0.4842	Cost: 7.37s
Train Epoch: 437 [61440/90000 (68%)]	Loss: -0.6074	Cost: 5.76s
Train Epoch: 437 [81920/90000 (91%)]	Loss: -0.6803	Cost: 6.03s
Train Epoch: 437 	Average Loss: -0.2373
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.0102

Learning rate: 0.00017735084662159222
Re-generating waveforms for posterior prior.
Train Epoch: 438 [0/90000 (0%)]	Loss: 5.3160	Cost: 22.92s
Train Epoch: 438 [20480/90000 (23%)]	Loss: -0.4771	Cost: 6.12s
Train Epoch: 438 [40960/90000 (45%)]	Loss: -0.3358	Cost: 7.16s
Train Epoch: 438 [61440/90000 (68%)]	Loss: -0.5418	Cost: 5.86s
Train Epoch: 438 [81920/90000 (91%)]	Loss: -0.6488	Cost: 5.87s
Train Epoch: 438 	Average Loss: -0.1346
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.6674

Learning rate: 0.00017725119636778633
Re-generating waveforms for posterior prior.
Train Epoch: 439 [0/90000 (0%)]	Loss: 4.8237	Cost: 23.98s
Train Epoch: 439 [20480/90000 (23%)]	Loss: -0.8119	Cost: 6.12s
Train Epoch: 439 [40960/90000 (45%)]	Loss: -0.5430	Cost: 7.44s
Train Epoch: 439 [61440/90000 (68%)]	Loss: -0.8297	Cost: 5.88s
Train Epoch: 439 [81920/90000 (91%)]	Loss: -0.9777	Cost: 5.94s
Train Epoch: 439 	Average Loss: -0.3956
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.7382

Learning rate: 0.00017715135550433272
Re-generating waveforms for posterior prior.
Train Epoch: 440 [0/90000 (0%)]	Loss: 5.0878	Cost: 24.63s
Train Epoch: 440 [20480/90000 (23%)]	Loss: -0.8958	Cost: 6.04s
Train Epoch: 440 [40960/90000 (45%)]	Loss: -0.3821	Cost: 14.09s
Train Epoch: 440 [61440/90000 (68%)]	Loss: -0.5792	Cost: 5.69s
Train Epoch: 440 [81920/90000 (91%)]	Loss: -0.7430	Cost: 6.07s
Train Epoch: 440 	Average Loss: -0.2159
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.8528

Learning rate: 0.00017705132427757878
Re-generating waveforms for posterior prior.
Train Epoch: 441 [0/90000 (0%)]	Loss: 5.0753	Cost: 23.45s
Train Epoch: 441 [20480/90000 (23%)]	Loss: -0.7891	Cost: 6.14s
Train Epoch: 441 [40960/90000 (45%)]	Loss: -0.4788	Cost: 7.66s
Train Epoch: 441 [61440/90000 (68%)]	Loss: -0.7489	Cost: 5.89s
Train Epoch: 441 [81920/90000 (91%)]	Loss: -0.9769	Cost: 6.56s
Train Epoch: 441 	Average Loss: -0.3155
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.5820

Learning rate: 0.00017695110293434167
Re-generating waveforms for posterior prior.
Train Epoch: 442 [0/90000 (0%)]	Loss: 4.9088	Cost: 23.89s
Train Epoch: 442 [20480/90000 (23%)]	Loss: -0.9802	Cost: 6.34s
Train Epoch: 442 [40960/90000 (45%)]	Loss: -0.6018	Cost: 7.73s
Train Epoch: 442 [61440/90000 (68%)]	Loss: -0.7455	Cost: 5.92s
Train Epoch: 442 [81920/90000 (91%)]	Loss: -0.8363	Cost: 6.10s
Train Epoch: 442 	Average Loss: -0.3946
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.6443

Learning rate: 0.00017685069172190753
Re-generating waveforms for posterior prior.
Train Epoch: 443 [0/90000 (0%)]	Loss: 4.7177	Cost: 24.75s
Train Epoch: 443 [20480/90000 (23%)]	Loss: -0.8170	Cost: 6.20s
Train Epoch: 443 [40960/90000 (45%)]	Loss: -0.5177	Cost: 8.10s
Train Epoch: 443 [61440/90000 (68%)]	Loss: -0.9476	Cost: 5.93s
Train Epoch: 443 [81920/90000 (91%)]	Loss: -1.0661	Cost: 7.04s
Train Epoch: 443 	Average Loss: -0.4420
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.5614

Learning rate: 0.00017675009088803106
Re-generating waveforms for posterior prior.
Train Epoch: 444 [0/90000 (0%)]	Loss: 4.5850	Cost: 24.32s
Train Epoch: 444 [20480/90000 (23%)]	Loss: -0.9483	Cost: 6.32s
Train Epoch: 444 [40960/90000 (45%)]	Loss: -0.4706	Cost: 7.37s
Train Epoch: 444 [61440/90000 (68%)]	Loss: -0.8621	Cost: 5.98s
Train Epoch: 444 [81920/90000 (91%)]	Loss: -0.7629	Cost: 6.58s
Train Epoch: 444 	Average Loss: -0.3834
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.7331

Learning rate: 0.00017664930068093484
Re-generating waveforms for posterior prior.
Train Epoch: 445 [0/90000 (0%)]	Loss: 5.0411	Cost: 24.61s
Train Epoch: 445 [20480/90000 (23%)]	Loss: -0.8583	Cost: 6.37s
Train Epoch: 445 [40960/90000 (45%)]	Loss: -0.6469	Cost: 7.24s
Train Epoch: 445 [61440/90000 (68%)]	Loss: -1.0026	Cost: 5.98s
Train Epoch: 445 [81920/90000 (91%)]	Loss: -1.1421	Cost: 6.02s
Train Epoch: 445 	Average Loss: -0.4350
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.5659

Learning rate: 0.00017654832134930869
Re-generating waveforms for posterior prior.
Train Epoch: 446 [0/90000 (0%)]	Loss: 4.8969	Cost: 24.92s
Train Epoch: 446 [20480/90000 (23%)]	Loss: -1.1659	Cost: 6.29s
Train Epoch: 446 [40960/90000 (45%)]	Loss: -0.8790	Cost: 7.74s
Train Epoch: 446 [61440/90000 (68%)]	Loss: -1.0722	Cost: 6.11s
Train Epoch: 446 [81920/90000 (91%)]	Loss: -1.0604	Cost: 5.81s
Train Epoch: 446 	Average Loss: -0.5766
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.5457

Learning rate: 0.00017644715314230901
Re-generating waveforms for posterior prior.
Train Epoch: 447 [0/90000 (0%)]	Loss: 4.6474	Cost: 24.86s
Train Epoch: 447 [20480/90000 (23%)]	Loss: -1.2936	Cost: 6.32s
Train Epoch: 447 [40960/90000 (45%)]	Loss: -0.8032	Cost: 7.37s
Train Epoch: 447 [61440/90000 (68%)]	Loss: -0.9673	Cost: 6.01s
Train Epoch: 447 [81920/90000 (91%)]	Loss: -1.0219	Cost: 6.36s
Train Epoch: 447 	Average Loss: -0.5822
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.6925

Learning rate: 0.0001763457963095584
Re-generating waveforms for posterior prior.
Train Epoch: 448 [0/90000 (0%)]	Loss: 4.7096	Cost: 23.92s
Train Epoch: 448 [20480/90000 (23%)]	Loss: -0.9525	Cost: 6.23s
Train Epoch: 448 [40960/90000 (45%)]	Loss: -0.2200	Cost: 7.05s
Train Epoch: 448 [61440/90000 (68%)]	Loss: -0.8437	Cost: 5.83s
Train Epoch: 448 [81920/90000 (91%)]	Loss: -0.9420	Cost: 5.72s
Train Epoch: 448 	Average Loss: -0.3319
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.6014

Learning rate: 0.00017624425110114464
Re-generating waveforms for posterior prior.
Train Epoch: 449 [0/90000 (0%)]	Loss: 5.1161	Cost: 23.17s
Train Epoch: 449 [20480/90000 (23%)]	Loss: -0.8535	Cost: 6.09s
Train Epoch: 449 [40960/90000 (45%)]	Loss: -0.2339	Cost: 7.36s
Train Epoch: 449 [61440/90000 (68%)]	Loss: -0.5939	Cost: 5.86s
Train Epoch: 449 [81920/90000 (91%)]	Loss: -0.9406	Cost: 5.76s
Train Epoch: 449 	Average Loss: -0.2333
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.6491

Learning rate: 0.0001761425177676205
Re-generating waveforms for posterior prior.
Train Epoch: 450 [0/90000 (0%)]	Loss: 5.2155	Cost: 23.53s
Train Epoch: 450 [20480/90000 (23%)]	Loss: -1.0971	Cost: 6.11s
Train Epoch: 450 [40960/90000 (45%)]	Loss: -0.8660	Cost: 7.14s
Train Epoch: 450 [61440/90000 (68%)]	Loss: -0.9913	Cost: 5.80s
Train Epoch: 450 [81920/90000 (91%)]	Loss: -0.9540	Cost: 5.66s
Train Epoch: 450 	Average Loss: -0.5093
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.7102

Saving model as model_sample_from_all_posterior.pt_e450 & waveforms_supplementary_sample_from_all_posterior.hdf5_e450
Learning rate: 0.00017604059656000295
Re-generating waveforms for posterior prior.
Train Epoch: 451 [0/90000 (0%)]	Loss: 4.7123	Cost: 23.52s
Train Epoch: 451 [20480/90000 (23%)]	Loss: -0.0047	Cost: 6.13s
Train Epoch: 451 [40960/90000 (45%)]	Loss: -0.0254	Cost: 7.42s
Train Epoch: 451 [61440/90000 (68%)]	Loss: -0.4017	Cost: 5.76s
Train Epoch: 451 [81920/90000 (91%)]	Loss: -0.6529	Cost: 5.88s
Train Epoch: 451 	Average Loss: 0.0895
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.8696

Learning rate: 0.00017593848772977228
Re-generating waveforms for posterior prior.
Train Epoch: 452 [0/90000 (0%)]	Loss: 5.0012	Cost: 23.59s
Train Epoch: 452 [20480/90000 (23%)]	Loss: -1.0360	Cost: 6.12s
Train Epoch: 452 [40960/90000 (45%)]	Loss: -0.4884	Cost: 7.59s
Train Epoch: 452 [61440/90000 (68%)]	Loss: -0.7806	Cost: 5.82s
Train Epoch: 452 [81920/90000 (91%)]	Loss: -0.9815	Cost: 5.99s
Train Epoch: 452 	Average Loss: -0.3287
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.7683

Learning rate: 0.00017583619152887204
Re-generating waveforms for posterior prior.
Train Epoch: 453 [0/90000 (0%)]	Loss: 4.6491	Cost: 23.29s
Train Epoch: 453 [20480/90000 (23%)]	Loss: -0.8744	Cost: 6.11s
Train Epoch: 453 [40960/90000 (45%)]	Loss: -0.6356	Cost: 7.62s
Train Epoch: 453 [61440/90000 (68%)]	Loss: -1.1017	Cost: 5.74s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 0.6728	Cost: 6.09s
Train Epoch: 453 	Average Loss: -0.2477
Re-generating waveforms for posterior prior.
Test set: Average loss: 5.7526

Learning rate: 0.0001757337082097078
Re-generating waveforms for posterior prior.
Train Epoch: 454 [0/90000 (0%)]	Loss: 6.0092	Cost: 23.18s
Train Epoch: 454 [20480/90000 (23%)]	Loss: -0.0872	Cost: 6.13s
Train Epoch: 454 [40960/90000 (45%)]	Loss: -0.2127	Cost: 7.49s
Train Epoch: 454 [61440/90000 (68%)]	Loss: -0.4945	Cost: 5.76s
Train Epoch: 454 [81920/90000 (91%)]	Loss: -0.5780	Cost: 5.93s
Train Epoch: 454 	Average Loss: 0.0839
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.7335

Learning rate: 0.00017563103802514706
Re-generating waveforms for posterior prior.
Train Epoch: 455 [0/90000 (0%)]	Loss: 4.9425	Cost: 24.40s
Train Epoch: 455 [20480/90000 (23%)]	Loss: -0.8769	Cost: 6.09s
Train Epoch: 455 [40960/90000 (45%)]	Loss: -0.6330	Cost: 7.35s
Train Epoch: 455 [61440/90000 (68%)]	Loss: -0.6132	Cost: 5.78s
Train Epoch: 455 [81920/90000 (91%)]	Loss: -0.9722	Cost: 6.10s
Train Epoch: 455 	Average Loss: -0.3309
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.8683

Learning rate: 0.0001755281812285182
Re-generating waveforms for posterior prior.
Train Epoch: 456 [0/90000 (0%)]	Loss: 5.0908	Cost: 24.07s
Train Epoch: 456 [20480/90000 (23%)]	Loss: -0.9627	Cost: 6.04s
Train Epoch: 456 [40960/90000 (45%)]	Loss: -0.6409	Cost: 7.27s
Train Epoch: 456 [61440/90000 (68%)]	Loss: -1.0654	Cost: 5.80s
Train Epoch: 456 [81920/90000 (91%)]	Loss: -1.0738	Cost: 5.83s
Train Epoch: 456 	Average Loss: -0.4813
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.5696

Learning rate: 0.00017542513807361024
Re-generating waveforms for posterior prior.
Train Epoch: 457 [0/90000 (0%)]	Loss: 4.9216	Cost: 23.29s
Train Epoch: 457 [20480/90000 (23%)]	Loss: -1.2237	Cost: 6.23s
Train Epoch: 457 [40960/90000 (45%)]	Loss: -0.8654	Cost: 7.12s
Train Epoch: 457 [61440/90000 (68%)]	Loss: -0.7675	Cost: 5.81s
Train Epoch: 457 [81920/90000 (91%)]	Loss: -0.9436	Cost: 6.15s
Train Epoch: 457 	Average Loss: -0.4907
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.6830

Learning rate: 0.00017532190881467186
Re-generating waveforms for posterior prior.
Train Epoch: 458 [0/90000 (0%)]	Loss: 4.7707	Cost: 23.65s
Train Epoch: 458 [20480/90000 (23%)]	Loss: -1.0887	Cost: 6.07s
Train Epoch: 458 [40960/90000 (45%)]	Loss: -0.7946	Cost: 7.57s
Train Epoch: 458 [61440/90000 (68%)]	Loss: -1.1580	Cost: 5.76s
Train Epoch: 458 [81920/90000 (91%)]	Loss: -1.2479	Cost: 5.81s
Train Epoch: 458 	Average Loss: -0.5645
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.5994

Learning rate: 0.000175218493706411
Re-generating waveforms for posterior prior.
Train Epoch: 459 [0/90000 (0%)]	Loss: 4.7363	Cost: 23.91s
Train Epoch: 459 [20480/90000 (23%)]	Loss: -1.2727	Cost: 6.09s
Train Epoch: 459 [40960/90000 (45%)]	Loss: -1.0354	Cost: 7.38s
Train Epoch: 459 [61440/90000 (68%)]	Loss: -1.3012	Cost: 5.76s
Train Epoch: 459 [81920/90000 (91%)]	Loss: -1.4729	Cost: 6.10s
Train Epoch: 459 	Average Loss: -0.8292
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.4028

Learning rate: 0.0001751148930039942
Re-generating waveforms for posterior prior.
Train Epoch: 460 [0/90000 (0%)]	Loss: 4.2739	Cost: 23.67s
Train Epoch: 460 [20480/90000 (23%)]	Loss: -1.4773	Cost: 6.07s
Train Epoch: 460 [40960/90000 (45%)]	Loss: -1.1160	Cost: 7.45s
Train Epoch: 460 [61440/90000 (68%)]	Loss: -1.4017	Cost: 5.75s
Train Epoch: 460 [81920/90000 (91%)]	Loss: -1.4662	Cost: 6.14s
Train Epoch: 460 	Average Loss: -0.9178
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.3173

Learning rate: 0.00017501110696304582
Re-generating waveforms for posterior prior.
Train Epoch: 461 [0/90000 (0%)]	Loss: 4.2130	Cost: 23.38s
Train Epoch: 461 [20480/90000 (23%)]	Loss: -1.0330	Cost: 6.08s
Train Epoch: 461 [40960/90000 (45%)]	Loss: -0.9786	Cost: 7.61s
Train Epoch: 461 [61440/90000 (68%)]	Loss: -1.0678	Cost: 5.80s
Train Epoch: 461 [81920/90000 (91%)]	Loss: -1.2176	Cost: 6.05s
Train Epoch: 461 	Average Loss: -0.7151
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.3894

Learning rate: 0.00017490713583964766
Re-generating waveforms for posterior prior.
Train Epoch: 462 [0/90000 (0%)]	Loss: 4.5074	Cost: 23.59s
Train Epoch: 462 [20480/90000 (23%)]	Loss: -1.2193	Cost: 6.14s
Train Epoch: 462 [40960/90000 (45%)]	Loss: -1.0615	Cost: 7.40s
Train Epoch: 462 [61440/90000 (68%)]	Loss: -1.4438	Cost: 5.79s
Train Epoch: 462 [81920/90000 (91%)]	Loss: -1.6403	Cost: 5.85s
Train Epoch: 462 	Average Loss: -0.8864
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.4384

Learning rate: 0.00017480297989033809
Re-generating waveforms for posterior prior.
Train Epoch: 463 [0/90000 (0%)]	Loss: 4.1803	Cost: 24.07s
Train Epoch: 463 [20480/90000 (23%)]	Loss: -1.5316	Cost: 6.10s
Train Epoch: 463 [40960/90000 (45%)]	Loss: -0.7806	Cost: 7.32s
Train Epoch: 463 [61440/90000 (68%)]	Loss: -1.0370	Cost: 5.77s
Train Epoch: 463 [81920/90000 (91%)]	Loss: -1.1452	Cost: 6.02s
Train Epoch: 463 	Average Loss: -0.7349
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.4931

Learning rate: 0.0001746986393721116
Re-generating waveforms for posterior prior.
Train Epoch: 464 [0/90000 (0%)]	Loss: 4.8924	Cost: 23.83s
Train Epoch: 464 [20480/90000 (23%)]	Loss: -1.3074	Cost: 6.08s
Train Epoch: 464 [40960/90000 (45%)]	Loss: -0.8897	Cost: 7.38s
Train Epoch: 464 [61440/90000 (68%)]	Loss: -1.1603	Cost: 5.78s
Train Epoch: 464 [81920/90000 (91%)]	Loss: -1.4828	Cost: 6.08s
Train Epoch: 464 	Average Loss: -0.7820
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.3968

Learning rate: 0.0001745941145424181
Re-generating waveforms for posterior prior.
Train Epoch: 465 [0/90000 (0%)]	Loss: 4.3987	Cost: 24.03s
Train Epoch: 465 [20480/90000 (23%)]	Loss: -1.6093	Cost: 6.08s
Train Epoch: 465 [40960/90000 (45%)]	Loss: -0.9783	Cost: 7.27s
Train Epoch: 465 [61440/90000 (68%)]	Loss: -1.3989	Cost: 6.08s
Train Epoch: 465 [81920/90000 (91%)]	Loss: -1.3690	Cost: 5.71s
Train Epoch: 465 	Average Loss: -0.8957
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.3807

Learning rate: 0.00017448940565916205
Re-generating waveforms for posterior prior.
Train Epoch: 466 [0/90000 (0%)]	Loss: 4.4264	Cost: 23.85s
Train Epoch: 466 [20480/90000 (23%)]	Loss: -1.2881	Cost: 6.11s
Train Epoch: 466 [40960/90000 (45%)]	Loss: -1.0541	Cost: 7.20s
Train Epoch: 466 [61440/90000 (68%)]	Loss: -1.4051	Cost: 5.80s
Train Epoch: 466 [81920/90000 (91%)]	Loss: -1.2814	Cost: 5.78s
Train Epoch: 466 	Average Loss: -0.8476
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.5327

Learning rate: 0.00017438451298070235
Re-generating waveforms for posterior prior.
Train Epoch: 467 [0/90000 (0%)]	Loss: 4.9125	Cost: 23.29s
Train Epoch: 467 [20480/90000 (23%)]	Loss: -1.1929	Cost: 6.10s
Train Epoch: 467 [40960/90000 (45%)]	Loss: -1.0317	Cost: 7.58s
Train Epoch: 467 [61440/90000 (68%)]	Loss: -1.3730	Cost: 5.76s
Train Epoch: 467 [81920/90000 (91%)]	Loss: -1.4713	Cost: 5.80s
Train Epoch: 467 	Average Loss: -0.8253
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.2759

Learning rate: 0.00017427943676585122
Re-generating waveforms for posterior prior.
Train Epoch: 468 [0/90000 (0%)]	Loss: 4.4324	Cost: 23.61s
Train Epoch: 468 [20480/90000 (23%)]	Loss: -1.4709	Cost: 6.09s
Train Epoch: 468 [40960/90000 (45%)]	Loss: -1.2059	Cost: 7.17s
Train Epoch: 468 [61440/90000 (68%)]	Loss: -1.4191	Cost: 5.77s
Train Epoch: 468 [81920/90000 (91%)]	Loss: -1.5169	Cost: 5.92s
Train Epoch: 468 	Average Loss: -0.9684
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.3671

Learning rate: 0.00017417417727387375
Re-generating waveforms for posterior prior.
Train Epoch: 469 [0/90000 (0%)]	Loss: 4.3919	Cost: 23.24s
Train Epoch: 469 [20480/90000 (23%)]	Loss: -1.5160	Cost: 6.10s
Train Epoch: 469 [40960/90000 (45%)]	Loss: -1.1247	Cost: 7.52s
Train Epoch: 469 [61440/90000 (68%)]	Loss: -1.5272	Cost: 5.80s
Train Epoch: 469 [81920/90000 (91%)]	Loss: -1.7212	Cost: 5.88s
Train Epoch: 469 	Average Loss: -1.0138
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.3017

Learning rate: 0.00017406873476448733
Re-generating waveforms for posterior prior.
Train Epoch: 470 [0/90000 (0%)]	Loss: 4.2274	Cost: 24.16s
Train Epoch: 470 [20480/90000 (23%)]	Loss: -1.7694	Cost: 6.11s
Train Epoch: 470 [40960/90000 (45%)]	Loss: -1.2524	Cost: 7.37s
Train Epoch: 470 [61440/90000 (68%)]	Loss: -1.4021	Cost: 5.79s
Train Epoch: 470 [81920/90000 (91%)]	Loss: -1.5429	Cost: 6.05s
Train Epoch: 470 	Average Loss: -1.0395
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.3385

Learning rate: 0.0001739631094978608
Re-generating waveforms for posterior prior.
Train Epoch: 471 [0/90000 (0%)]	Loss: 4.5903	Cost: 23.90s
Train Epoch: 471 [20480/90000 (23%)]	Loss: -1.2675	Cost: 6.11s
Train Epoch: 471 [40960/90000 (45%)]	Loss: -0.9437	Cost: 7.06s
Train Epoch: 471 [61440/90000 (68%)]	Loss: -1.3223	Cost: 5.97s
Train Epoch: 471 [81920/90000 (91%)]	Loss: -1.2358	Cost: 5.98s
Train Epoch: 471 	Average Loss: -0.8083
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.5375

Learning rate: 0.00017385730173461407
Re-generating waveforms for posterior prior.
Train Epoch: 472 [0/90000 (0%)]	Loss: 4.6093	Cost: 25.50s
Train Epoch: 472 [20480/90000 (23%)]	Loss: -1.1701	Cost: 6.02s
Train Epoch: 472 [40960/90000 (45%)]	Loss: -1.0846	Cost: 6.77s
Train Epoch: 472 [61440/90000 (68%)]	Loss: -1.3794	Cost: 5.82s
Train Epoch: 472 [81920/90000 (91%)]	Loss: -1.4948	Cost: 6.19s
Train Epoch: 472 	Average Loss: -0.8476
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.3084

Learning rate: 0.00017375131173581724
Re-generating waveforms for posterior prior.
Train Epoch: 473 [0/90000 (0%)]	Loss: 4.0524	Cost: 23.13s
Train Epoch: 473 [20480/90000 (23%)]	Loss: -1.6088	Cost: 6.09s
Train Epoch: 473 [40960/90000 (45%)]	Loss: -1.3029	Cost: 7.63s
Train Epoch: 473 [61440/90000 (68%)]	Loss: -1.7558	Cost: 5.75s
Train Epoch: 473 [81920/90000 (91%)]	Loss: -1.7658	Cost: 6.16s
Train Epoch: 473 	Average Loss: -1.1656
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.3287

Learning rate: 0.0001736451397629901
Re-generating waveforms for posterior prior.
Train Epoch: 474 [0/90000 (0%)]	Loss: 4.1262	Cost: 23.44s
Train Epoch: 474 [20480/90000 (23%)]	Loss: -1.6611	Cost: 6.10s
Train Epoch: 474 [40960/90000 (45%)]	Loss: -1.2575	Cost: 7.73s
Train Epoch: 474 [61440/90000 (68%)]	Loss: -1.3913	Cost: 5.75s
Train Epoch: 474 [81920/90000 (91%)]	Loss: -1.6274	Cost: 5.97s
Train Epoch: 474 	Average Loss: -1.0222
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.2929

Learning rate: 0.00017353878607810145
Re-generating waveforms for posterior prior.
Train Epoch: 475 [0/90000 (0%)]	Loss: 4.2851	Cost: 23.57s
Train Epoch: 475 [20480/90000 (23%)]	Loss: -1.5104	Cost: 6.12s
Train Epoch: 475 [40960/90000 (45%)]	Loss: -0.9681	Cost: 7.25s
Train Epoch: 475 [61440/90000 (68%)]	Loss: -1.4488	Cost: 5.80s
Train Epoch: 475 [81920/90000 (91%)]	Loss: -1.6982	Cost: 6.03s
Train Epoch: 475 	Average Loss: -0.9769
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.1534

Learning rate: 0.0001734322509435684
Re-generating waveforms for posterior prior.
Train Epoch: 476 [0/90000 (0%)]	Loss: 4.2970	Cost: 23.31s
Train Epoch: 476 [20480/90000 (23%)]	Loss: -1.6621	Cost: 6.19s
Train Epoch: 476 [40960/90000 (45%)]	Loss: -1.2306	Cost: 7.05s
Train Epoch: 476 [61440/90000 (68%)]	Loss: -1.6746	Cost: 5.80s
Train Epoch: 476 [81920/90000 (91%)]	Loss: -1.9076	Cost: 6.09s
Train Epoch: 476 	Average Loss: -1.2011
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.0242

Learning rate: 0.00017332553462225583
Re-generating waveforms for posterior prior.
Train Epoch: 477 [0/90000 (0%)]	Loss: 4.2953	Cost: 23.36s
Train Epoch: 477 [20480/90000 (23%)]	Loss: -1.8797	Cost: 6.09s
Train Epoch: 477 [40960/90000 (45%)]	Loss: -1.4969	Cost: 7.50s
Train Epoch: 477 [61440/90000 (68%)]	Loss: -1.6529	Cost: 5.75s
Train Epoch: 477 [81920/90000 (91%)]	Loss: -1.8222	Cost: 6.19s
Train Epoch: 477 	Average Loss: -1.3237
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.0804

Learning rate: 0.00017321863737747566
Re-generating waveforms for posterior prior.
Train Epoch: 478 [0/90000 (0%)]	Loss: 4.3047	Cost: 23.91s
Train Epoch: 478 [20480/90000 (23%)]	Loss: -1.7417	Cost: 6.13s
Train Epoch: 478 [40960/90000 (45%)]	Loss: -1.3342	Cost: 7.53s
Train Epoch: 478 [61440/90000 (68%)]	Loss: -1.7248	Cost: 5.79s
Train Epoch: 478 [81920/90000 (91%)]	Loss: -1.8084	Cost: 6.05s
Train Epoch: 478 	Average Loss: -1.2616
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.1240

Learning rate: 0.00017311155947298624
Re-generating waveforms for posterior prior.
Train Epoch: 479 [0/90000 (0%)]	Loss: 4.0846	Cost: 23.05s
Train Epoch: 479 [20480/90000 (23%)]	Loss: -1.9256	Cost: 6.07s
Train Epoch: 479 [40960/90000 (45%)]	Loss: -1.4413	Cost: 7.22s
Train Epoch: 479 [61440/90000 (68%)]	Loss: -1.7330	Cost: 5.75s
Train Epoch: 479 [81920/90000 (91%)]	Loss: -1.9287	Cost: 5.96s
Train Epoch: 479 	Average Loss: -1.3287
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.0929

Learning rate: 0.0001730043011729916
Re-generating waveforms for posterior prior.
Train Epoch: 480 [0/90000 (0%)]	Loss: 4.4084	Cost: 23.85s
Train Epoch: 480 [20480/90000 (23%)]	Loss: -1.4569	Cost: 6.09s
Train Epoch: 480 [40960/90000 (45%)]	Loss: -1.2228	Cost: 7.48s
Train Epoch: 480 [61440/90000 (68%)]	Loss: -1.4883	Cost: 5.84s
Train Epoch: 480 [81920/90000 (91%)]	Loss: -1.3451	Cost: 5.73s
Train Epoch: 480 	Average Loss: -0.9858
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.3098

Learning rate: 0.00017289686274214099
Re-generating waveforms for posterior prior.
Train Epoch: 481 [0/90000 (0%)]	Loss: 4.4102	Cost: 23.59s
Train Epoch: 481 [20480/90000 (23%)]	Loss: -1.6353	Cost: 6.16s
Train Epoch: 481 [40960/90000 (45%)]	Loss: -1.2428	Cost: 7.17s
Train Epoch: 481 [61440/90000 (68%)]	Loss: -1.6820	Cost: 5.79s
Train Epoch: 481 [81920/90000 (91%)]	Loss: -1.9234	Cost: 5.80s
Train Epoch: 481 	Average Loss: -1.1550
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.0213

Learning rate: 0.000172789244445528
Re-generating waveforms for posterior prior.
Train Epoch: 482 [0/90000 (0%)]	Loss: 4.4506	Cost: 23.95s
Train Epoch: 482 [20480/90000 (23%)]	Loss: -1.9110	Cost: 6.17s
Train Epoch: 482 [40960/90000 (45%)]	Loss: -1.4272	Cost: 7.32s
Train Epoch: 482 [61440/90000 (68%)]	Loss: -1.7874	Cost: 5.86s
Train Epoch: 482 [81920/90000 (91%)]	Loss: -1.9033	Cost: 6.06s
Train Epoch: 482 	Average Loss: -1.3293
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.0969

Learning rate: 0.0001726814465486901
Re-generating waveforms for posterior prior.
Train Epoch: 483 [0/90000 (0%)]	Loss: 4.2392	Cost: 23.86s
Train Epoch: 483 [20480/90000 (23%)]	Loss: -1.9016	Cost: 6.12s
Train Epoch: 483 [40960/90000 (45%)]	Loss: -1.5178	Cost: 7.20s
Train Epoch: 483 [61440/90000 (68%)]	Loss: -1.7582	Cost: 5.78s
Train Epoch: 483 [81920/90000 (91%)]	Loss: -1.9328	Cost: 6.13s
Train Epoch: 483 	Average Loss: -1.3655
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.1450

Learning rate: 0.00017257346931760792
Re-generating waveforms for posterior prior.
Train Epoch: 484 [0/90000 (0%)]	Loss: 4.2593	Cost: 23.70s
Train Epoch: 484 [20480/90000 (23%)]	Loss: -2.0455	Cost: 6.09s
Train Epoch: 484 [40960/90000 (45%)]	Loss: -1.5116	Cost: 7.57s
Train Epoch: 484 [61440/90000 (68%)]	Loss: -2.0011	Cost: 5.76s
Train Epoch: 484 [81920/90000 (91%)]	Loss: -1.8719	Cost: 5.82s
Train Epoch: 484 	Average Loss: -1.4313
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.2569

Learning rate: 0.0001724653130187045
Re-generating waveforms for posterior prior.
Train Epoch: 485 [0/90000 (0%)]	Loss: 4.1615	Cost: 24.07s
Train Epoch: 485 [20480/90000 (23%)]	Loss: -1.8155	Cost: 6.08s
Train Epoch: 485 [40960/90000 (45%)]	Loss: -1.4261	Cost: 7.49s
Train Epoch: 485 [61440/90000 (68%)]	Loss: -1.7505	Cost: 5.82s
Train Epoch: 485 [81920/90000 (91%)]	Loss: -1.7111	Cost: 6.12s
Train Epoch: 485 	Average Loss: -1.2721
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.1642

Learning rate: 0.00017235697791884475
Re-generating waveforms for posterior prior.
Train Epoch: 486 [0/90000 (0%)]	Loss: 4.1967	Cost: 24.23s
Train Epoch: 486 [20480/90000 (23%)]	Loss: -1.9152	Cost: 6.11s
Train Epoch: 486 [40960/90000 (45%)]	Loss: -1.3885	Cost: 6.84s
Train Epoch: 486 [61440/90000 (68%)]	Loss: -1.8899	Cost: 6.19s
Train Epoch: 486 [81920/90000 (91%)]	Loss: -2.0020	Cost: 5.90s
Train Epoch: 486 	Average Loss: -1.3408
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.0026

Learning rate: 0.0001722484642853348
Re-generating waveforms for posterior prior.
Train Epoch: 487 [0/90000 (0%)]	Loss: 4.2498	Cost: 23.66s
Train Epoch: 487 [20480/90000 (23%)]	Loss: -1.9360	Cost: 6.11s
Train Epoch: 487 [40960/90000 (45%)]	Loss: -1.3907	Cost: 7.19s
Train Epoch: 487 [61440/90000 (68%)]	Loss: -1.8110	Cost: 5.78s
Train Epoch: 487 [81920/90000 (91%)]	Loss: -1.9321	Cost: 5.97s
Train Epoch: 487 	Average Loss: -1.3644
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.0726

Learning rate: 0.00017213977238592123
Re-generating waveforms for posterior prior.
Train Epoch: 488 [0/90000 (0%)]	Loss: 4.0957	Cost: 23.48s
Train Epoch: 488 [20480/90000 (23%)]	Loss: -2.0343	Cost: 6.11s
Train Epoch: 488 [40960/90000 (45%)]	Loss: -1.7499	Cost: 7.35s
Train Epoch: 488 [61440/90000 (68%)]	Loss: -2.0205	Cost: 5.76s
Train Epoch: 488 [81920/90000 (91%)]	Loss: -2.2965	Cost: 6.10s
Train Epoch: 488 	Average Loss: -1.5075
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.7926

Learning rate: 0.00017203090248879048
Re-generating waveforms for posterior prior.
Train Epoch: 489 [0/90000 (0%)]	Loss: 3.6284	Cost: 24.68s
Train Epoch: 489 [20480/90000 (23%)]	Loss: -2.2994	Cost: 6.08s
Train Epoch: 489 [40960/90000 (45%)]	Loss: -1.7973	Cost: 7.19s
Train Epoch: 489 [61440/90000 (68%)]	Loss: -1.8582	Cost: 5.82s
Train Epoch: 489 [81920/90000 (91%)]	Loss: -1.8654	Cost: 5.96s
Train Epoch: 489 	Average Loss: -1.5729
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.1174

Learning rate: 0.00017192185486256825
Re-generating waveforms for posterior prior.
Train Epoch: 490 [0/90000 (0%)]	Loss: 4.0926	Cost: 23.37s
Train Epoch: 490 [20480/90000 (23%)]	Loss: -2.0379	Cost: 6.09s
Train Epoch: 490 [40960/90000 (45%)]	Loss: -1.6827	Cost: 7.46s
Train Epoch: 490 [61440/90000 (68%)]	Loss: -1.9918	Cost: 5.76s
Train Epoch: 490 [81920/90000 (91%)]	Loss: -2.1732	Cost: 6.18s
Train Epoch: 490 	Average Loss: -1.5372
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.9827

Learning rate: 0.00017181262977631866
Re-generating waveforms for posterior prior.
Train Epoch: 491 [0/90000 (0%)]	Loss: 3.9384	Cost: 23.51s
Train Epoch: 491 [20480/90000 (23%)]	Loss: -2.0245	Cost: 6.11s
Train Epoch: 491 [40960/90000 (45%)]	Loss: -1.7081	Cost: 7.44s
Train Epoch: 491 [61440/90000 (68%)]	Loss: -2.0653	Cost: 5.78s
Train Epoch: 491 [81920/90000 (91%)]	Loss: -2.1636	Cost: 6.21s
Train Epoch: 491 	Average Loss: -1.5096
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.9561

Learning rate: 0.0001717032274995438
Re-generating waveforms for posterior prior.
Train Epoch: 492 [0/90000 (0%)]	Loss: 4.0714	Cost: 23.35s
Train Epoch: 492 [20480/90000 (23%)]	Loss: -2.1897	Cost: 6.09s
Train Epoch: 492 [40960/90000 (45%)]	Loss: -1.7692	Cost: 6.82s
Train Epoch: 492 [61440/90000 (68%)]	Loss: -2.2789	Cost: 5.84s
Train Epoch: 492 [81920/90000 (91%)]	Loss: -2.2370	Cost: 6.25s
Train Epoch: 492 	Average Loss: -1.6976
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.8823

Learning rate: 0.00017159364830218287
Re-generating waveforms for posterior prior.
Train Epoch: 493 [0/90000 (0%)]	Loss: 3.7886	Cost: 23.83s
Train Epoch: 493 [20480/90000 (23%)]	Loss: -2.4106	Cost: 6.09s
Train Epoch: 493 [40960/90000 (45%)]	Loss: -1.8769	Cost: 7.33s
Train Epoch: 493 [61440/90000 (68%)]	Loss: -2.2942	Cost: 5.83s
Train Epoch: 493 [81920/90000 (91%)]	Loss: -2.0955	Cost: 5.67s
Train Epoch: 493 	Average Loss: -1.7169
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.6904

Learning rate: 0.0001714838924546117
Re-generating waveforms for posterior prior.
Train Epoch: 494 [0/90000 (0%)]	Loss: 3.8700	Cost: 23.66s
Train Epoch: 494 [20480/90000 (23%)]	Loss: -2.3112	Cost: 6.14s
Train Epoch: 494 [40960/90000 (45%)]	Loss: -1.6264	Cost: 7.33s
Train Epoch: 494 [61440/90000 (68%)]	Loss: -2.1188	Cost: 5.82s
Train Epoch: 494 [81920/90000 (91%)]	Loss: -2.2478	Cost: 6.12s
Train Epoch: 494 	Average Loss: -1.6705
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.7060

Learning rate: 0.0001713739602276419
Re-generating waveforms for posterior prior.
Train Epoch: 495 [0/90000 (0%)]	Loss: 3.8817	Cost: 24.10s
Train Epoch: 495 [20480/90000 (23%)]	Loss: -2.4466	Cost: 6.12s
Train Epoch: 495 [40960/90000 (45%)]	Loss: -2.0218	Cost: 7.43s
Train Epoch: 495 [61440/90000 (68%)]	Loss: -2.1214	Cost: 5.80s
Train Epoch: 495 [81920/90000 (91%)]	Loss: -2.3947	Cost: 5.79s
Train Epoch: 495 	Average Loss: -1.8127
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.6662

Learning rate: 0.00017126385189252032
Re-generating waveforms for posterior prior.
Train Epoch: 496 [0/90000 (0%)]	Loss: 4.0667	Cost: 23.51s
Train Epoch: 496 [20480/90000 (23%)]	Loss: -2.2366	Cost: 6.20s
Train Epoch: 496 [40960/90000 (45%)]	Loss: -1.7473	Cost: 7.13s
Train Epoch: 496 [61440/90000 (68%)]	Loss: -1.9296	Cost: 5.83s
Train Epoch: 496 [81920/90000 (91%)]	Loss: -2.1037	Cost: 5.85s
Train Epoch: 496 	Average Loss: -1.6163
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.8745

Learning rate: 0.00017115356772092835
Re-generating waveforms for posterior prior.
Train Epoch: 497 [0/90000 (0%)]	Loss: 3.7909	Cost: 23.51s
Train Epoch: 497 [20480/90000 (23%)]	Loss: -2.4656	Cost: 6.10s
Train Epoch: 497 [40960/90000 (45%)]	Loss: -1.5147	Cost: 7.46s
Train Epoch: 497 [61440/90000 (68%)]	Loss: -1.6204	Cost: 5.78s
Train Epoch: 497 [81920/90000 (91%)]	Loss: -2.0024	Cost: 5.77s
Train Epoch: 497 	Average Loss: -1.4721
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.7904

Learning rate: 0.00017104310798498113
Re-generating waveforms for posterior prior.
Train Epoch: 498 [0/90000 (0%)]	Loss: 3.9057	Cost: 23.51s
Train Epoch: 498 [20480/90000 (23%)]	Loss: -1.9693	Cost: 6.11s
Train Epoch: 498 [40960/90000 (45%)]	Loss: -1.6945	Cost: 7.45s
Train Epoch: 498 [61440/90000 (68%)]	Loss: -2.1058	Cost: 5.88s
Train Epoch: 498 [81920/90000 (91%)]	Loss: -2.4061	Cost: 5.71s
Train Epoch: 498 	Average Loss: -1.6454
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.8599

Learning rate: 0.00017093247295722717
Re-generating waveforms for posterior prior.
Train Epoch: 499 [0/90000 (0%)]	Loss: 4.3532	Cost: 23.02s
Train Epoch: 499 [20480/90000 (23%)]	Loss: -2.2757	Cost: 6.18s
Train Epoch: 499 [40960/90000 (45%)]	Loss: -1.9184	Cost: 7.14s
Train Epoch: 499 [61440/90000 (68%)]	Loss: -2.2232	Cost: 5.80s
Train Epoch: 499 [81920/90000 (91%)]	Loss: -1.7259	Cost: 6.06s
Train Epoch: 499 	Average Loss: -1.5886
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.1652

Learning rate: 0.0001708216629106474
Re-generating waveforms for posterior prior.
Train Epoch: 500 [0/90000 (0%)]	Loss: 4.1578	Cost: 23.65s
Train Epoch: 500 [20480/90000 (23%)]	Loss: -1.5555	Cost: 6.10s
Train Epoch: 500 [40960/90000 (45%)]	Loss: -0.8525	Cost: 7.42s
Train Epoch: 500 [61440/90000 (68%)]	Loss: -1.0448	Cost: 5.78s
Train Epoch: 500 [81920/90000 (91%)]	Loss: -1.5566	Cost: 6.03s
Train Epoch: 500 	Average Loss: -0.8930
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.2279

Saving model as model_sample_from_all_posterior.pt_e500 & waveforms_supplementary_sample_from_all_posterior.hdf5_e500
Learning rate: 0.00017071067811865454
Re-generating waveforms for posterior prior.
Train Epoch: 501 [0/90000 (0%)]	Loss: 4.6189	Cost: 23.70s
Train Epoch: 501 [20480/90000 (23%)]	Loss: -1.8399	Cost: 6.09s
Train Epoch: 501 [40960/90000 (45%)]	Loss: -1.8035	Cost: 7.27s
Train Epoch: 501 [61440/90000 (68%)]	Loss: -2.0015	Cost: 5.80s
Train Epoch: 501 [81920/90000 (91%)]	Loss: -2.2555	Cost: 5.92s
Train Epoch: 501 	Average Loss: -1.4810
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.7636

Learning rate: 0.00017059951885509258
Re-generating waveforms for posterior prior.
Train Epoch: 502 [0/90000 (0%)]	Loss: 3.8084	Cost: 23.59s
Train Epoch: 502 [20480/90000 (23%)]	Loss: -2.3394	Cost: 6.10s
Train Epoch: 502 [40960/90000 (45%)]	Loss: -1.7943	Cost: 7.49s
Train Epoch: 502 [61440/90000 (68%)]	Loss: -1.4169	Cost: 5.78s
Train Epoch: 502 [81920/90000 (91%)]	Loss: -1.8015	Cost: 5.82s
Train Epoch: 502 	Average Loss: -1.5303
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.1675

Learning rate: 0.00017048818539423593
Re-generating waveforms for posterior prior.
Train Epoch: 503 [0/90000 (0%)]	Loss: 4.2943	Cost: 32.08s
Train Epoch: 503 [20480/90000 (23%)]	Loss: -1.8378	Cost: 6.14s
Train Epoch: 503 [40960/90000 (45%)]	Loss: -1.6352	Cost: 14.11s
Train Epoch: 503 [61440/90000 (68%)]	Loss: -1.9443	Cost: 5.65s
Train Epoch: 503 [81920/90000 (91%)]	Loss: -1.8085	Cost: 5.63s
Train Epoch: 503 	Average Loss: -1.3462
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.1290

Learning rate: 0.00017037667801078887
Re-generating waveforms for posterior prior.
Train Epoch: 504 [0/90000 (0%)]	Loss: 4.5341	Cost: 23.36s
Train Epoch: 504 [20480/90000 (23%)]	Loss: -2.0159	Cost: 6.11s
Train Epoch: 504 [40960/90000 (45%)]	Loss: -1.8169	Cost: 6.98s
Train Epoch: 504 [61440/90000 (68%)]	Loss: -2.0157	Cost: 5.81s
Train Epoch: 504 [81920/90000 (91%)]	Loss: -2.1387	Cost: 6.07s
Train Epoch: 504 	Average Loss: -1.4588
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.9908

Learning rate: 0.00017026499697988474
Re-generating waveforms for posterior prior.
Train Epoch: 505 [0/90000 (0%)]	Loss: 4.2488	Cost: 23.56s
Train Epoch: 505 [20480/90000 (23%)]	Loss: -2.3073	Cost: 6.12s
Train Epoch: 505 [40960/90000 (45%)]	Loss: -2.1764	Cost: 7.25s
Train Epoch: 505 [61440/90000 (68%)]	Loss: -2.1197	Cost: 5.82s
Train Epoch: 505 [81920/90000 (91%)]	Loss: -2.4909	Cost: 5.71s
Train Epoch: 505 	Average Loss: -1.7586
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.6899

Learning rate: 0.0001701531425770854
Re-generating waveforms for posterior prior.
Train Epoch: 506 [0/90000 (0%)]	Loss: 3.6637	Cost: 23.74s
Train Epoch: 506 [20480/90000 (23%)]	Loss: -2.5710	Cost: 6.11s
Train Epoch: 506 [40960/90000 (45%)]	Loss: -2.1799	Cost: 7.42s
Train Epoch: 506 [61440/90000 (68%)]	Loss: -2.5363	Cost: 6.16s
Train Epoch: 506 [81920/90000 (91%)]	Loss: -2.6174	Cost: 5.77s
Train Epoch: 506 	Average Loss: -2.0061
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.6299

Learning rate: 0.00017004111507838045
Re-generating waveforms for posterior prior.
Train Epoch: 507 [0/90000 (0%)]	Loss: 3.3109	Cost: 24.00s
Train Epoch: 507 [20480/90000 (23%)]	Loss: -2.8691	Cost: 6.13s
Train Epoch: 507 [40960/90000 (45%)]	Loss: -2.2757	Cost: 7.44s
Train Epoch: 507 [61440/90000 (68%)]	Loss: -2.6808	Cost: 5.79s
Train Epoch: 507 [81920/90000 (91%)]	Loss: -2.6656	Cost: 5.87s
Train Epoch: 507 	Average Loss: -2.1784
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.3997

Learning rate: 0.00016992891476018667
Re-generating waveforms for posterior prior.
Train Epoch: 508 [0/90000 (0%)]	Loss: 3.4197	Cost: 23.80s
Train Epoch: 508 [20480/90000 (23%)]	Loss: -2.7462	Cost: 6.11s
Train Epoch: 508 [40960/90000 (45%)]	Loss: -2.1223	Cost: 7.16s
Train Epoch: 508 [61440/90000 (68%)]	Loss: -2.1674	Cost: 5.79s
Train Epoch: 508 [81920/90000 (91%)]	Loss: -2.2896	Cost: 5.97s
Train Epoch: 508 	Average Loss: -1.8649
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.8058

Learning rate: 0.0001698165418993471
Re-generating waveforms for posterior prior.
Train Epoch: 509 [0/90000 (0%)]	Loss: 3.7519	Cost: 23.53s
Train Epoch: 509 [20480/90000 (23%)]	Loss: -2.4780	Cost: 6.13s
Train Epoch: 509 [40960/90000 (45%)]	Loss: -2.1919	Cost: 7.22s
Train Epoch: 509 [61440/90000 (68%)]	Loss: -2.2474	Cost: 5.79s
Train Epoch: 509 [81920/90000 (91%)]	Loss: -2.5955	Cost: 5.98s
Train Epoch: 509 	Average Loss: -1.9365
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.6686

Learning rate: 0.00016970399677313067
Re-generating waveforms for posterior prior.
Train Epoch: 510 [0/90000 (0%)]	Loss: 3.7859	Cost: 23.51s
Train Epoch: 510 [20480/90000 (23%)]	Loss: -2.6467	Cost: 6.15s
Train Epoch: 510 [40960/90000 (45%)]	Loss: -2.1495	Cost: 7.40s
Train Epoch: 510 [61440/90000 (68%)]	Loss: -2.5149	Cost: 5.79s
Train Epoch: 510 [81920/90000 (91%)]	Loss: -2.6968	Cost: 6.20s
Train Epoch: 510 	Average Loss: -2.0784
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.5761

Learning rate: 0.00016959127965923126
Re-generating waveforms for posterior prior.
Train Epoch: 511 [0/90000 (0%)]	Loss: 3.6858	Cost: 23.54s
Train Epoch: 511 [20480/90000 (23%)]	Loss: -2.8433	Cost: 6.09s
Train Epoch: 511 [40960/90000 (45%)]	Loss: -2.3345	Cost: 7.61s
Train Epoch: 511 [61440/90000 (68%)]	Loss: -2.3939	Cost: 5.77s
Train Epoch: 511 [81920/90000 (91%)]	Loss: -2.6658	Cost: 6.09s
Train Epoch: 511 	Average Loss: -2.0669
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.4133

Learning rate: 0.00016947839083576718
Re-generating waveforms for posterior prior.
Train Epoch: 512 [0/90000 (0%)]	Loss: 3.9898	Cost: 23.58s
Train Epoch: 512 [20480/90000 (23%)]	Loss: -2.6316	Cost: 6.10s
Train Epoch: 512 [40960/90000 (45%)]	Loss: -2.2590	Cost: 7.41s
Train Epoch: 512 [61440/90000 (68%)]	Loss: -2.4632	Cost: 5.83s
Train Epoch: 512 [81920/90000 (91%)]	Loss: -2.8095	Cost: 5.76s
Train Epoch: 512 	Average Loss: -2.0548
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.4399

Learning rate: 0.00016936533058128033
Re-generating waveforms for posterior prior.
Train Epoch: 513 [0/90000 (0%)]	Loss: 3.4688	Cost: 24.22s
Train Epoch: 513 [20480/90000 (23%)]	Loss: -2.4122	Cost: 6.12s
Train Epoch: 513 [40960/90000 (45%)]	Loss: -1.8778	Cost: 7.33s
Train Epoch: 513 [61440/90000 (68%)]	Loss: -2.1318	Cost: 5.79s
Train Epoch: 513 [81920/90000 (91%)]	Loss: -2.4750	Cost: 5.79s
Train Epoch: 513 	Average Loss: -1.8113
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.7669

Learning rate: 0.0001692520991747357
Re-generating waveforms for posterior prior.
Train Epoch: 514 [0/90000 (0%)]	Loss: 3.8745	Cost: 23.88s
Train Epoch: 514 [20480/90000 (23%)]	Loss: -2.6607	Cost: 6.11s
Train Epoch: 514 [40960/90000 (45%)]	Loss: -2.4645	Cost: 7.47s
Train Epoch: 514 [61440/90000 (68%)]	Loss: -2.7166	Cost: 5.77s
Train Epoch: 514 [81920/90000 (91%)]	Loss: -2.8913	Cost: 6.19s
Train Epoch: 514 	Average Loss: -2.1076
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.4538

Learning rate: 0.0001691386968955205
Re-generating waveforms for posterior prior.
Train Epoch: 515 [0/90000 (0%)]	Loss: 3.5440	Cost: 23.37s
Train Epoch: 515 [20480/90000 (23%)]	Loss: -2.6814	Cost: 6.09s
Train Epoch: 515 [40960/90000 (45%)]	Loss: -2.3660	Cost: 7.66s
Train Epoch: 515 [61440/90000 (68%)]	Loss: -2.6032	Cost: 5.77s
Train Epoch: 515 [81920/90000 (91%)]	Loss: -2.7623	Cost: 5.99s
Train Epoch: 515 	Average Loss: -2.2218
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.4709

Learning rate: 0.0001690251240234436
Re-generating waveforms for posterior prior.
Train Epoch: 516 [0/90000 (0%)]	Loss: 3.6486	Cost: 24.12s
Train Epoch: 516 [20480/90000 (23%)]	Loss: -2.9638	Cost: 6.06s
Train Epoch: 516 [40960/90000 (45%)]	Loss: -2.3663	Cost: 7.19s
Train Epoch: 516 [61440/90000 (68%)]	Loss: -2.5540	Cost: 6.20s
Train Epoch: 516 [81920/90000 (91%)]	Loss: -2.7837	Cost: 5.68s
Train Epoch: 516 	Average Loss: -2.2460
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.5599

Learning rate: 0.00016891138083873473
Re-generating waveforms for posterior prior.
Train Epoch: 517 [0/90000 (0%)]	Loss: 3.6674	Cost: 25.02s
Train Epoch: 517 [20480/90000 (23%)]	Loss: -2.7420	Cost: 6.09s
Train Epoch: 517 [40960/90000 (45%)]	Loss: -2.2445	Cost: 7.18s
Train Epoch: 517 [61440/90000 (68%)]	Loss: -2.3891	Cost: 5.77s
Train Epoch: 517 [81920/90000 (91%)]	Loss: -2.2482	Cost: 5.96s
Train Epoch: 517 	Average Loss: -1.9971
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.8987

Learning rate: 0.00016879746762204391
Re-generating waveforms for posterior prior.
Train Epoch: 518 [0/90000 (0%)]	Loss: 4.1080	Cost: 23.40s
Train Epoch: 518 [20480/90000 (23%)]	Loss: -2.4035	Cost: 6.10s
Train Epoch: 518 [40960/90000 (45%)]	Loss: -2.0747	Cost: 7.40s
Train Epoch: 518 [61440/90000 (68%)]	Loss: -2.6605	Cost: 5.79s
Train Epoch: 518 [81920/90000 (91%)]	Loss: -2.6665	Cost: 5.75s
Train Epoch: 518 	Average Loss: -1.9491
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.6424

Learning rate: 0.00016868338465444072
Re-generating waveforms for posterior prior.
Train Epoch: 519 [0/90000 (0%)]	Loss: 3.6783	Cost: 24.16s
Train Epoch: 519 [20480/90000 (23%)]	Loss: -2.7464	Cost: 6.20s
Train Epoch: 519 [40960/90000 (45%)]	Loss: -2.4758	Cost: 7.12s
Train Epoch: 519 [61440/90000 (68%)]	Loss: -2.8378	Cost: 5.79s
Train Epoch: 519 [81920/90000 (91%)]	Loss: -2.8679	Cost: 5.92s
Train Epoch: 519 	Average Loss: -2.2596
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.4497

Learning rate: 0.00016856913221741346
Re-generating waveforms for posterior prior.
Train Epoch: 520 [0/90000 (0%)]	Loss: 3.9440	Cost: 23.90s
Train Epoch: 520 [20480/90000 (23%)]	Loss: -2.9203	Cost: 6.11s
Train Epoch: 520 [40960/90000 (45%)]	Loss: -2.3649	Cost: 7.18s
Train Epoch: 520 [61440/90000 (68%)]	Loss: -2.8056	Cost: 5.79s
Train Epoch: 520 [81920/90000 (91%)]	Loss: -2.9881	Cost: 6.11s
Train Epoch: 520 	Average Loss: -2.2618
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.2175

Learning rate: 0.00016845471059286874
Re-generating waveforms for posterior prior.
Train Epoch: 521 [0/90000 (0%)]	Loss: 3.1536	Cost: 23.53s
Train Epoch: 521 [20480/90000 (23%)]	Loss: -3.0771	Cost: 6.11s
Train Epoch: 521 [40960/90000 (45%)]	Loss: -2.6702	Cost: 7.26s
Train Epoch: 521 [61440/90000 (68%)]	Loss: -2.8377	Cost: 5.78s
Train Epoch: 521 [81920/90000 (91%)]	Loss: -3.0292	Cost: 5.72s
Train Epoch: 521 	Average Loss: -2.4319
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.2510

Learning rate: 0.0001683401200631305
Re-generating waveforms for posterior prior.
Train Epoch: 522 [0/90000 (0%)]	Loss: 3.3173	Cost: 24.59s
Train Epoch: 522 [20480/90000 (23%)]	Loss: -2.9513	Cost: 6.03s
Train Epoch: 522 [40960/90000 (45%)]	Loss: -2.6550	Cost: 7.15s
Train Epoch: 522 [61440/90000 (68%)]	Loss: -2.7661	Cost: 5.77s
Train Epoch: 522 [81920/90000 (91%)]	Loss: -2.9907	Cost: 5.83s
Train Epoch: 522 	Average Loss: -2.3924
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.2454

Learning rate: 0.00016822536091093952
Re-generating waveforms for posterior prior.
Train Epoch: 523 [0/90000 (0%)]	Loss: 3.4366	Cost: 23.75s
Train Epoch: 523 [20480/90000 (23%)]	Loss: -2.3829	Cost: 6.13s
Train Epoch: 523 [40960/90000 (45%)]	Loss: -2.1161	Cost: 7.61s
Train Epoch: 523 [61440/90000 (68%)]	Loss: -2.5878	Cost: 5.79s
Train Epoch: 523 [81920/90000 (91%)]	Loss: -2.8220	Cost: 5.91s
Train Epoch: 523 	Average Loss: -2.0680
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.3571

Learning rate: 0.00016811043341945255
Re-generating waveforms for posterior prior.
Train Epoch: 524 [0/90000 (0%)]	Loss: 3.5708	Cost: 24.01s
Train Epoch: 524 [20480/90000 (23%)]	Loss: -2.9605	Cost: 6.10s
Train Epoch: 524 [40960/90000 (45%)]	Loss: -2.4117	Cost: 7.46s
Train Epoch: 524 [61440/90000 (68%)]	Loss: -2.8514	Cost: 5.77s
Train Epoch: 524 [81920/90000 (91%)]	Loss: -2.9799	Cost: 6.05s
Train Epoch: 524 	Average Loss: -2.3538
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.3981

Learning rate: 0.00016799533787224176
Re-generating waveforms for posterior prior.
Train Epoch: 525 [0/90000 (0%)]	Loss: 3.3907	Cost: 23.59s
Train Epoch: 525 [20480/90000 (23%)]	Loss: -2.8809	Cost: 6.12s
Train Epoch: 525 [40960/90000 (45%)]	Loss: -2.4611	Cost: 7.63s
Train Epoch: 525 [61440/90000 (68%)]	Loss: -2.7583	Cost: 5.78s
Train Epoch: 525 [81920/90000 (91%)]	Loss: -3.0232	Cost: 6.04s
Train Epoch: 525 	Average Loss: -2.3587
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.1457

Learning rate: 0.00016788007455329404
Re-generating waveforms for posterior prior.
Train Epoch: 526 [0/90000 (0%)]	Loss: 2.9566	Cost: 24.03s
Train Epoch: 526 [20480/90000 (23%)]	Loss: -3.1280	Cost: 6.10s
Train Epoch: 526 [40960/90000 (45%)]	Loss: -2.6126	Cost: 7.31s
Train Epoch: 526 [61440/90000 (68%)]	Loss: -3.1068	Cost: 5.79s
Train Epoch: 526 [81920/90000 (91%)]	Loss: -2.8546	Cost: 6.21s
Train Epoch: 526 	Average Loss: -2.4796
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.3346

Learning rate: 0.0001677646437470101
Re-generating waveforms for posterior prior.
Train Epoch: 527 [0/90000 (0%)]	Loss: 3.4763	Cost: 23.97s
Train Epoch: 527 [20480/90000 (23%)]	Loss: -2.9275	Cost: 6.13s
Train Epoch: 527 [40960/90000 (45%)]	Loss: -2.4012	Cost: 7.35s
Train Epoch: 527 [61440/90000 (68%)]	Loss: -2.7797	Cost: 5.98s
Train Epoch: 527 [81920/90000 (91%)]	Loss: -2.9295	Cost: 5.95s
Train Epoch: 527 	Average Loss: -2.2943
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.4036

Learning rate: 0.000167649045738204
Re-generating waveforms for posterior prior.
Train Epoch: 528 [0/90000 (0%)]	Loss: 3.1971	Cost: 24.00s
Train Epoch: 528 [20480/90000 (23%)]	Loss: -2.8284	Cost: 6.12s
Train Epoch: 528 [40960/90000 (45%)]	Loss: -2.6059	Cost: 6.93s
Train Epoch: 528 [61440/90000 (68%)]	Loss: -2.9964	Cost: 5.82s
Train Epoch: 528 [81920/90000 (91%)]	Loss: -3.0268	Cost: 6.06s
Train Epoch: 528 	Average Loss: -2.4129
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.4358

Learning rate: 0.00016753328081210231
Re-generating waveforms for posterior prior.
Train Epoch: 529 [0/90000 (0%)]	Loss: 3.3181	Cost: 23.49s
Train Epoch: 529 [20480/90000 (23%)]	Loss: -3.0383	Cost: 6.10s
Train Epoch: 529 [40960/90000 (45%)]	Loss: -2.4208	Cost: 7.50s
Train Epoch: 529 [61440/90000 (68%)]	Loss: -2.8814	Cost: 5.79s
Train Epoch: 529 [81920/90000 (91%)]	Loss: -3.2261	Cost: 6.21s
Train Epoch: 529 	Average Loss: -2.4611
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.2535

Learning rate: 0.00016741734925434354
Re-generating waveforms for posterior prior.
Train Epoch: 530 [0/90000 (0%)]	Loss: 3.4194	Cost: 24.18s
Train Epoch: 530 [20480/90000 (23%)]	Loss: -3.1364	Cost: 6.09s
Train Epoch: 530 [40960/90000 (45%)]	Loss: -2.8207	Cost: 7.35s
Train Epoch: 530 [61440/90000 (68%)]	Loss: -3.2869	Cost: 5.75s
Train Epoch: 530 [81920/90000 (91%)]	Loss: -3.0370	Cost: 6.06s
Train Epoch: 530 	Average Loss: -2.5786
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.1953

Learning rate: 0.0001673012513509772
Re-generating waveforms for posterior prior.
Train Epoch: 531 [0/90000 (0%)]	Loss: 3.3923	Cost: 23.72s
Train Epoch: 531 [20480/90000 (23%)]	Loss: -3.0936	Cost: 6.11s
Train Epoch: 531 [40960/90000 (45%)]	Loss: -2.8509	Cost: 7.41s
Train Epoch: 531 [61440/90000 (68%)]	Loss: -2.8100	Cost: 5.86s
Train Epoch: 531 [81920/90000 (91%)]	Loss: -3.0006	Cost: 6.10s
Train Epoch: 531 	Average Loss: -2.5424
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.3617

Learning rate: 0.0001671849873884634
Re-generating waveforms for posterior prior.
Train Epoch: 532 [0/90000 (0%)]	Loss: 3.0654	Cost: 23.70s
Train Epoch: 532 [20480/90000 (23%)]	Loss: -3.1231	Cost: 6.14s
Train Epoch: 532 [40960/90000 (45%)]	Loss: -2.7730	Cost: 7.30s
Train Epoch: 532 [61440/90000 (68%)]	Loss: -3.0389	Cost: 5.84s
Train Epoch: 532 [81920/90000 (91%)]	Loss: -3.1937	Cost: 6.22s
Train Epoch: 532 	Average Loss: -2.5853
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.1739

Learning rate: 0.0001670685576536719
Re-generating waveforms for posterior prior.
Train Epoch: 533 [0/90000 (0%)]	Loss: 3.3489	Cost: 24.33s
Train Epoch: 533 [20480/90000 (23%)]	Loss: -3.2667	Cost: 6.14s
Train Epoch: 533 [40960/90000 (45%)]	Loss: -2.8734	Cost: 7.30s
Train Epoch: 533 [61440/90000 (68%)]	Loss: -3.0620	Cost: 5.77s
Train Epoch: 533 [81920/90000 (91%)]	Loss: -3.2271	Cost: 6.13s
Train Epoch: 533 	Average Loss: -2.6474
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.0691

Learning rate: 0.00016695196243388143
Re-generating waveforms for posterior prior.
Train Epoch: 534 [0/90000 (0%)]	Loss: 3.2584	Cost: 24.00s
Train Epoch: 534 [20480/90000 (23%)]	Loss: -3.1229	Cost: 6.12s
Train Epoch: 534 [40960/90000 (45%)]	Loss: -2.6000	Cost: 6.82s
Train Epoch: 534 [61440/90000 (68%)]	Loss: -2.8854	Cost: 6.11s
Train Epoch: 534 [81920/90000 (91%)]	Loss: -2.9056	Cost: 5.83s
Train Epoch: 534 	Average Loss: -2.4462
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.2548

Learning rate: 0.0001668352020167792
Re-generating waveforms for posterior prior.
Train Epoch: 535 [0/90000 (0%)]	Loss: 3.4056	Cost: 23.84s
Train Epoch: 535 [20480/90000 (23%)]	Loss: -3.0215	Cost: 6.15s
Train Epoch: 535 [40960/90000 (45%)]	Loss: -2.8045	Cost: 7.28s
Train Epoch: 535 [61440/90000 (68%)]	Loss: -3.3118	Cost: 5.81s
Train Epoch: 535 [81920/90000 (91%)]	Loss: -3.3656	Cost: 6.00s
Train Epoch: 535 	Average Loss: -2.6245
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.0969

Learning rate: 0.00016671827669045988
Re-generating waveforms for posterior prior.
Train Epoch: 536 [0/90000 (0%)]	Loss: 3.0999	Cost: 24.11s
Train Epoch: 536 [20480/90000 (23%)]	Loss: -3.1686	Cost: 6.11s
Train Epoch: 536 [40960/90000 (45%)]	Loss: -2.8770	Cost: 7.21s
Train Epoch: 536 [61440/90000 (68%)]	Loss: -3.2270	Cost: 5.79s
Train Epoch: 536 [81920/90000 (91%)]	Loss: -3.3412	Cost: 6.10s
Train Epoch: 536 	Average Loss: -2.6770
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.2102

Learning rate: 0.00016660118674342506
Re-generating waveforms for posterior prior.
Train Epoch: 537 [0/90000 (0%)]	Loss: 3.3590	Cost: 24.22s
Train Epoch: 537 [20480/90000 (23%)]	Loss: -3.0851	Cost: 6.16s
Train Epoch: 537 [40960/90000 (45%)]	Loss: -2.8264	Cost: 7.17s
Train Epoch: 537 [61440/90000 (68%)]	Loss: -2.8791	Cost: 5.78s
Train Epoch: 537 [81920/90000 (91%)]	Loss: -3.0252	Cost: 6.11s
Train Epoch: 537 	Average Loss: -2.5521
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.4072

Learning rate: 0.00016648393246458258
Re-generating waveforms for posterior prior.
Train Epoch: 538 [0/90000 (0%)]	Loss: 3.7184	Cost: 23.41s
Train Epoch: 538 [20480/90000 (23%)]	Loss: -2.6382	Cost: 6.11s
Train Epoch: 538 [40960/90000 (45%)]	Loss: -2.5028	Cost: 7.36s
Train Epoch: 538 [61440/90000 (68%)]	Loss: -2.8735	Cost: 5.77s
Train Epoch: 538 [81920/90000 (91%)]	Loss: -0.7910	Cost: 6.01s
Train Epoch: 538 	Average Loss: -1.7611
Re-generating waveforms for posterior prior.
Test set: Average loss: 4.8187

Learning rate: 0.00016636651414324576
Re-generating waveforms for posterior prior.
Train Epoch: 539 [0/90000 (0%)]	Loss: 4.7571	Cost: 23.39s
Train Epoch: 539 [20480/90000 (23%)]	Loss: -1.5542	Cost: 6.11s
Train Epoch: 539 [40960/90000 (45%)]	Loss: -1.5659	Cost: 7.66s
Train Epoch: 539 [61440/90000 (68%)]	Loss: -2.3949	Cost: 5.82s
Train Epoch: 539 [81920/90000 (91%)]	Loss: -2.8158	Cost: 6.14s
Train Epoch: 539 	Average Loss: -1.4558
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.3572

Learning rate: 0.00016624893206913257
Re-generating waveforms for posterior prior.
Train Epoch: 540 [0/90000 (0%)]	Loss: 3.2800	Cost: 23.87s
Train Epoch: 540 [20480/90000 (23%)]	Loss: -3.1365	Cost: 6.16s
Train Epoch: 540 [40960/90000 (45%)]	Loss: -2.6824	Cost: 7.66s
Train Epoch: 540 [61440/90000 (68%)]	Loss: -3.3007	Cost: 5.78s
Train Epoch: 540 [81920/90000 (91%)]	Loss: -3.3320	Cost: 5.80s
Train Epoch: 540 	Average Loss: -2.5825
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.0312

Learning rate: 0.0001661311865323651
Re-generating waveforms for posterior prior.
Train Epoch: 541 [0/90000 (0%)]	Loss: 3.3041	Cost: 23.47s
Train Epoch: 541 [20480/90000 (23%)]	Loss: -3.1595	Cost: 6.12s
Train Epoch: 541 [40960/90000 (45%)]	Loss: -2.8697	Cost: 7.15s
Train Epoch: 541 [61440/90000 (68%)]	Loss: -2.9436	Cost: 5.79s
Train Epoch: 541 [81920/90000 (91%)]	Loss: -3.2495	Cost: 6.23s
Train Epoch: 541 	Average Loss: -2.5865
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.0553

Learning rate: 0.00016601327782346878
Re-generating waveforms for posterior prior.
Train Epoch: 542 [0/90000 (0%)]	Loss: 2.9943	Cost: 24.99s
Train Epoch: 542 [20480/90000 (23%)]	Loss: -3.2291	Cost: 6.05s
Train Epoch: 542 [40960/90000 (45%)]	Loss: -3.0487	Cost: 7.35s
Train Epoch: 542 [61440/90000 (68%)]	Loss: -3.0967	Cost: 5.82s
Train Epoch: 542 [81920/90000 (91%)]	Loss: -2.9134	Cost: 6.04s
Train Epoch: 542 	Average Loss: -2.6239
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.2876

Learning rate: 0.00016589520623337163
Re-generating waveforms for posterior prior.
Train Epoch: 543 [0/90000 (0%)]	Loss: 3.2654	Cost: 23.52s
Train Epoch: 543 [20480/90000 (23%)]	Loss: -3.0732	Cost: 6.15s
Train Epoch: 543 [40960/90000 (45%)]	Loss: -2.6369	Cost: 6.87s
Train Epoch: 543 [61440/90000 (68%)]	Loss: -2.8012	Cost: 5.86s
Train Epoch: 543 [81920/90000 (91%)]	Loss: -2.9990	Cost: 5.89s
Train Epoch: 543 	Average Loss: -2.3739
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.2937

Learning rate: 0.00016577697205340353
Re-generating waveforms for posterior prior.
Train Epoch: 544 [0/90000 (0%)]	Loss: 3.6170	Cost: 24.17s
Train Epoch: 544 [20480/90000 (23%)]	Loss: -3.1643	Cost: 6.10s
Train Epoch: 544 [40960/90000 (45%)]	Loss: -2.7192	Cost: 7.18s
Train Epoch: 544 [61440/90000 (68%)]	Loss: -3.2276	Cost: 5.82s
Train Epoch: 544 [81920/90000 (91%)]	Loss: -3.3477	Cost: 6.08s
Train Epoch: 544 	Average Loss: -2.6651
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.9855

Learning rate: 0.00016565857557529557
Re-generating waveforms for posterior prior.
Train Epoch: 545 [0/90000 (0%)]	Loss: 2.8199	Cost: 23.56s
Train Epoch: 545 [20480/90000 (23%)]	Loss: -3.5279	Cost: 6.12s
Train Epoch: 545 [40960/90000 (45%)]	Loss: -2.8853	Cost: 7.19s
Train Epoch: 545 [61440/90000 (68%)]	Loss: -3.4381	Cost: 5.80s
Train Epoch: 545 [81920/90000 (91%)]	Loss: -3.3011	Cost: 6.06s
Train Epoch: 545 	Average Loss: -2.8671
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.0892

Learning rate: 0.00016554001709117932
Re-generating waveforms for posterior prior.
Train Epoch: 546 [0/90000 (0%)]	Loss: 3.5830	Cost: 23.28s
Train Epoch: 546 [20480/90000 (23%)]	Loss: -3.0697	Cost: 6.14s
Train Epoch: 546 [40960/90000 (45%)]	Loss: -2.6878	Cost: 7.60s
Train Epoch: 546 [61440/90000 (68%)]	Loss: -3.3483	Cost: 5.76s
Train Epoch: 546 [81920/90000 (91%)]	Loss: -3.2514	Cost: 5.93s
Train Epoch: 546 	Average Loss: -2.6700
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.9954

Learning rate: 0.00016542129689358606
Re-generating waveforms for posterior prior.
Train Epoch: 547 [0/90000 (0%)]	Loss: 3.1995	Cost: 23.73s
Train Epoch: 547 [20480/90000 (23%)]	Loss: -3.1900	Cost: 6.10s
Train Epoch: 547 [40960/90000 (45%)]	Loss: -2.8211	Cost: 7.39s
Train Epoch: 547 [61440/90000 (68%)]	Loss: -2.6563	Cost: 5.75s
Train Epoch: 547 [81920/90000 (91%)]	Loss: -2.8746	Cost: 5.80s
Train Epoch: 547 	Average Loss: -2.5041
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.4504

Learning rate: 0.00016530241527544604
Re-generating waveforms for posterior prior.
Train Epoch: 548 [0/90000 (0%)]	Loss: 3.2555	Cost: 23.60s
Train Epoch: 548 [20480/90000 (23%)]	Loss: -2.8349	Cost: 6.17s
Train Epoch: 548 [40960/90000 (45%)]	Loss: -2.0902	Cost: 7.34s
Train Epoch: 548 [61440/90000 (68%)]	Loss: -2.6959	Cost: 6.40s
Train Epoch: 548 [81920/90000 (91%)]	Loss: -3.0753	Cost: 5.70s
Train Epoch: 548 	Average Loss: -2.2492
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.1780

Learning rate: 0.0001651833725300878
Re-generating waveforms for posterior prior.
Train Epoch: 549 [0/90000 (0%)]	Loss: 3.0931	Cost: 24.03s
Train Epoch: 549 [20480/90000 (23%)]	Loss: -2.7790	Cost: 6.11s
Train Epoch: 549 [40960/90000 (45%)]	Loss: -2.3845	Cost: 7.30s
Train Epoch: 549 [61440/90000 (68%)]	Loss: -2.9608	Cost: 5.79s
Train Epoch: 549 [81920/90000 (91%)]	Loss: -3.0522	Cost: 5.81s
Train Epoch: 549 	Average Loss: -2.4204
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.1557

Learning rate: 0.00016506416895123758
Re-generating waveforms for posterior prior.
Train Epoch: 550 [0/90000 (0%)]	Loss: 2.9549	Cost: 23.68s
Train Epoch: 550 [20480/90000 (23%)]	Loss: -3.5165	Cost: 6.10s
Train Epoch: 550 [40960/90000 (45%)]	Loss: -3.1964	Cost: 6.89s
Train Epoch: 550 [61440/90000 (68%)]	Loss: -3.4902	Cost: 5.80s
Train Epoch: 550 [81920/90000 (91%)]	Loss: -3.5910	Cost: 6.17s
Train Epoch: 550 	Average Loss: -2.9066
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.8498

Saving model as model_sample_from_all_posterior.pt_e550 & waveforms_supplementary_sample_from_all_posterior.hdf5_e550
Learning rate: 0.0001649448048330183
Re-generating waveforms for posterior prior.
Train Epoch: 551 [0/90000 (0%)]	Loss: 3.0154	Cost: 23.30s
Train Epoch: 551 [20480/90000 (23%)]	Loss: -3.6644	Cost: 6.10s
Train Epoch: 551 [40960/90000 (45%)]	Loss: -3.3125	Cost: 6.52s
Train Epoch: 551 [61440/90000 (68%)]	Loss: -3.5103	Cost: 5.88s
Train Epoch: 551 [81920/90000 (91%)]	Loss: -3.5459	Cost: 5.74s
Train Epoch: 551 	Average Loss: -3.0602
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.8342

Learning rate: 0.00016482528046994906
Re-generating waveforms for posterior prior.
Train Epoch: 552 [0/90000 (0%)]	Loss: 2.9162	Cost: 24.50s
Train Epoch: 552 [20480/90000 (23%)]	Loss: -3.7189	Cost: 6.05s
Train Epoch: 552 [40960/90000 (45%)]	Loss: -3.3403	Cost: 7.40s
Train Epoch: 552 [61440/90000 (68%)]	Loss: -3.5614	Cost: 5.78s
Train Epoch: 552 [81920/90000 (91%)]	Loss: -3.6582	Cost: 5.92s
Train Epoch: 552 	Average Loss: -3.1079
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.8914

Learning rate: 0.00016470559615694438
Re-generating waveforms for posterior prior.
Train Epoch: 553 [0/90000 (0%)]	Loss: 3.0570	Cost: 23.74s
Train Epoch: 553 [20480/90000 (23%)]	Loss: -3.3185	Cost: 6.08s
Train Epoch: 553 [40960/90000 (45%)]	Loss: -2.2643	Cost: 7.57s
Train Epoch: 553 [61440/90000 (68%)]	Loss: -2.6726	Cost: 5.78s
Train Epoch: 553 [81920/90000 (91%)]	Loss: -2.9348	Cost: 6.02s
Train Epoch: 553 	Average Loss: -2.4360
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.0505

Learning rate: 0.00016458575218931336
Re-generating waveforms for posterior prior.
Train Epoch: 554 [0/90000 (0%)]	Loss: 3.0920	Cost: 25.01s
Train Epoch: 554 [20480/90000 (23%)]	Loss: -3.3214	Cost: 6.11s
Train Epoch: 554 [40960/90000 (45%)]	Loss: -3.0920	Cost: 7.19s
Train Epoch: 554 [61440/90000 (68%)]	Loss: -3.5652	Cost: 5.81s
Train Epoch: 554 [81920/90000 (91%)]	Loss: -3.5723	Cost: 6.12s
Train Epoch: 554 	Average Loss: -2.8529
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.9704

Learning rate: 0.00016446574886275908
Re-generating waveforms for posterior prior.
Train Epoch: 555 [0/90000 (0%)]	Loss: 3.0311	Cost: 24.51s
Train Epoch: 555 [20480/90000 (23%)]	Loss: -3.3274	Cost: 6.09s
Train Epoch: 555 [40960/90000 (45%)]	Loss: -3.0616	Cost: 7.11s
Train Epoch: 555 [61440/90000 (68%)]	Loss: -3.4309	Cost: 5.81s
Train Epoch: 555 [81920/90000 (91%)]	Loss: -3.7536	Cost: 6.01s
Train Epoch: 555 	Average Loss: -2.9119
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.7919

Learning rate: 0.00016434558647337785
Re-generating waveforms for posterior prior.
Train Epoch: 556 [0/90000 (0%)]	Loss: 2.9162	Cost: 24.26s
Train Epoch: 556 [20480/90000 (23%)]	Loss: -3.5801	Cost: 6.14s
Train Epoch: 556 [40960/90000 (45%)]	Loss: -3.1999	Cost: 7.27s
Train Epoch: 556 [61440/90000 (68%)]	Loss: -3.5864	Cost: 5.79s
Train Epoch: 556 [81920/90000 (91%)]	Loss: -3.7690	Cost: 6.22s
Train Epoch: 556 	Average Loss: -3.1004
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.7729

Learning rate: 0.0001642252653176584
Re-generating waveforms for posterior prior.
Train Epoch: 557 [0/90000 (0%)]	Loss: 2.8605	Cost: 23.89s
Train Epoch: 557 [20480/90000 (23%)]	Loss: -3.8509	Cost: 6.26s
Train Epoch: 557 [40960/90000 (45%)]	Loss: -3.3255	Cost: 7.09s
Train Epoch: 557 [61440/90000 (68%)]	Loss: -3.4927	Cost: 5.82s
Train Epoch: 557 [81920/90000 (91%)]	Loss: -3.4808	Cost: 6.07s
Train Epoch: 557 	Average Loss: -3.1133
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.9207

Learning rate: 0.0001641047856924812
Re-generating waveforms for posterior prior.
Train Epoch: 558 [0/90000 (0%)]	Loss: 3.1187	Cost: 23.91s
Train Epoch: 558 [20480/90000 (23%)]	Loss: -3.5176	Cost: 6.14s
Train Epoch: 558 [40960/90000 (45%)]	Loss: -3.3391	Cost: 7.37s
Train Epoch: 558 [61440/90000 (68%)]	Loss: -3.5948	Cost: 5.81s
Train Epoch: 558 [81920/90000 (91%)]	Loss: -3.7984	Cost: 5.80s
Train Epoch: 558 	Average Loss: -3.0355
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.7238

Learning rate: 0.0001639841478951178
Re-generating waveforms for posterior prior.
Train Epoch: 559 [0/90000 (0%)]	Loss: 2.5524	Cost: 23.89s
Train Epoch: 559 [20480/90000 (23%)]	Loss: -3.9186	Cost: 6.13s
Train Epoch: 559 [40960/90000 (45%)]	Loss: -3.2094	Cost: 7.28s
Train Epoch: 559 [61440/90000 (68%)]	Loss: -3.5770	Cost: 5.81s
Train Epoch: 559 [81920/90000 (91%)]	Loss: -3.4519	Cost: 5.73s
Train Epoch: 559 	Average Loss: -3.1122
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.9474

Learning rate: 0.00016386335222322995
Re-generating waveforms for posterior prior.
Train Epoch: 560 [0/90000 (0%)]	Loss: 3.1283	Cost: 23.87s
Train Epoch: 560 [20480/90000 (23%)]	Loss: -3.6016	Cost: 6.12s
Train Epoch: 560 [40960/90000 (45%)]	Loss: -3.2947	Cost: 7.44s
Train Epoch: 560 [61440/90000 (68%)]	Loss: -3.5316	Cost: 5.83s
Train Epoch: 560 [81920/90000 (91%)]	Loss: -3.6789	Cost: 5.81s
Train Epoch: 560 	Average Loss: -3.0020
Re-generating waveforms for posterior prior.
Test set: Average loss: 3.0373

Learning rate: 0.00016374239897486894
Re-generating waveforms for posterior prior.
Train Epoch: 561 [0/90000 (0%)]	Loss: 3.0887	Cost: 23.51s
Train Epoch: 561 [20480/90000 (23%)]	Loss: -3.3588	Cost: 6.13s
Train Epoch: 561 [40960/90000 (45%)]	Loss: -3.2356	Cost: 6.98s
Train Epoch: 561 [61440/90000 (68%)]	Loss: -3.5061	Cost: 5.84s
Train Epoch: 561 [81920/90000 (91%)]	Loss: -3.8194	Cost: 5.98s
Train Epoch: 561 	Average Loss: -2.9947
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.8917

Learning rate: 0.0001636212884484749
Re-generating waveforms for posterior prior.
Train Epoch: 562 [0/90000 (0%)]	Loss: 3.1939	Cost: 25.11s
Train Epoch: 562 [20480/90000 (23%)]	Loss: -3.8349	Cost: 6.07s
Train Epoch: 562 [40960/90000 (45%)]	Loss: -3.4542	Cost: 7.00s
Train Epoch: 562 [61440/90000 (68%)]	Loss: -3.9708	Cost: 5.82s
Train Epoch: 562 [81920/90000 (91%)]	Loss: -3.8041	Cost: 5.80s
Train Epoch: 562 	Average Loss: -3.2607
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.6924

Learning rate: 0.00016350002094287603
Re-generating waveforms for posterior prior.
Train Epoch: 563 [0/90000 (0%)]	Loss: 2.7937	Cost: 23.83s
Train Epoch: 563 [20480/90000 (23%)]	Loss: -3.8720	Cost: 6.08s
Train Epoch: 563 [40960/90000 (45%)]	Loss: -3.2663	Cost: 7.51s
Train Epoch: 563 [61440/90000 (68%)]	Loss: -3.7730	Cost: 5.79s
Train Epoch: 563 [81920/90000 (91%)]	Loss: -4.0806	Cost: 5.77s
Train Epoch: 563 	Average Loss: -3.2795
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.5676

Learning rate: 0.0001633785967572878
Re-generating waveforms for posterior prior.
Train Epoch: 564 [0/90000 (0%)]	Loss: 2.6212	Cost: 24.65s
Train Epoch: 564 [20480/90000 (23%)]	Loss: -3.8466	Cost: 6.09s
Train Epoch: 564 [40960/90000 (45%)]	Loss: -3.4801	Cost: 6.97s
Train Epoch: 564 [61440/90000 (68%)]	Loss: -3.6294	Cost: 5.88s
Train Epoch: 564 [81920/90000 (91%)]	Loss: -3.5361	Cost: 6.01s
Train Epoch: 564 	Average Loss: -3.2041
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.8364

Learning rate: 0.00016325701619131238
Re-generating waveforms for posterior prior.
Train Epoch: 565 [0/90000 (0%)]	Loss: 3.0465	Cost: 24.12s
Train Epoch: 565 [20480/90000 (23%)]	Loss: -3.5798	Cost: 6.11s
Train Epoch: 565 [40960/90000 (45%)]	Loss: -3.3591	Cost: 7.21s
Train Epoch: 565 [61440/90000 (68%)]	Loss: -3.7514	Cost: 5.87s
Train Epoch: 565 [81920/90000 (91%)]	Loss: -4.0353	Cost: 6.06s
Train Epoch: 565 	Average Loss: -3.1891
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.4992

Learning rate: 0.0001631352795449377
Re-generating waveforms for posterior prior.
Train Epoch: 566 [0/90000 (0%)]	Loss: 2.9716	Cost: 23.82s
Train Epoch: 566 [20480/90000 (23%)]	Loss: -3.8685	Cost: 6.15s
Train Epoch: 566 [40960/90000 (45%)]	Loss: -3.3627	Cost: 7.38s
Train Epoch: 566 [61440/90000 (68%)]	Loss: -3.7896	Cost: 5.82s
Train Epoch: 566 [81920/90000 (91%)]	Loss: -4.0039	Cost: 5.82s
Train Epoch: 566 	Average Loss: -3.3312
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.6969

Learning rate: 0.00016301338711853684
Re-generating waveforms for posterior prior.
Train Epoch: 567 [0/90000 (0%)]	Loss: 2.6848	Cost: 23.70s
Train Epoch: 567 [20480/90000 (23%)]	Loss: -3.9218	Cost: 6.13s
Train Epoch: 567 [40960/90000 (45%)]	Loss: -3.3350	Cost: 7.48s
Train Epoch: 567 [61440/90000 (68%)]	Loss: -3.7881	Cost: 5.80s
Train Epoch: 567 [81920/90000 (91%)]	Loss: -3.8853	Cost: 5.86s
Train Epoch: 567 	Average Loss: -3.2125
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.7284

Learning rate: 0.00016289133921286726
Re-generating waveforms for posterior prior.
Train Epoch: 568 [0/90000 (0%)]	Loss: 3.0905	Cost: 24.15s
Train Epoch: 568 [20480/90000 (23%)]	Loss: -3.8253	Cost: 6.08s
Train Epoch: 568 [40960/90000 (45%)]	Loss: -3.3034	Cost: 7.33s
Train Epoch: 568 [61440/90000 (68%)]	Loss: -3.7819	Cost: 5.80s
Train Epoch: 568 [81920/90000 (91%)]	Loss: -4.0963	Cost: 5.72s
Train Epoch: 568 	Average Loss: -3.3283
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.5561

Learning rate: 0.00016276913612907
Re-generating waveforms for posterior prior.
Train Epoch: 569 [0/90000 (0%)]	Loss: 2.6146	Cost: 23.94s
Train Epoch: 569 [20480/90000 (23%)]	Loss: -4.0973	Cost: 6.11s
Train Epoch: 569 [40960/90000 (45%)]	Loss: -3.6222	Cost: 7.06s
Train Epoch: 569 [61440/90000 (68%)]	Loss: -3.8998	Cost: 5.78s
Train Epoch: 569 [81920/90000 (91%)]	Loss: -4.2042	Cost: 5.99s
Train Epoch: 569 	Average Loss: -3.4996
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.3999

Learning rate: 0.00016264677816866906
Re-generating waveforms for posterior prior.
Train Epoch: 570 [0/90000 (0%)]	Loss: 2.4631	Cost: 23.70s
Train Epoch: 570 [20480/90000 (23%)]	Loss: -4.1681	Cost: 6.21s
Train Epoch: 570 [40960/90000 (45%)]	Loss: -3.9177	Cost: 7.44s
Train Epoch: 570 [61440/90000 (68%)]	Loss: -3.9967	Cost: 5.82s
Train Epoch: 570 [81920/90000 (91%)]	Loss: -4.1491	Cost: 5.77s
Train Epoch: 570 	Average Loss: -3.5153
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.5610

Learning rate: 0.0001625242656335705
Re-generating waveforms for posterior prior.
Train Epoch: 571 [0/90000 (0%)]	Loss: 2.3087	Cost: 24.73s
Train Epoch: 571 [20480/90000 (23%)]	Loss: -4.0067	Cost: 6.08s
Train Epoch: 571 [40960/90000 (45%)]	Loss: -3.6947	Cost: 7.18s
Train Epoch: 571 [61440/90000 (68%)]	Loss: -3.8316	Cost: 5.84s
Train Epoch: 571 [81920/90000 (91%)]	Loss: -3.9866	Cost: 5.83s
Train Epoch: 571 	Average Loss: -3.4360
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.7712

Learning rate: 0.00016240159882606185
Re-generating waveforms for posterior prior.
Train Epoch: 572 [0/90000 (0%)]	Loss: 2.5993	Cost: 23.35s
Train Epoch: 572 [20480/90000 (23%)]	Loss: -3.8847	Cost: 6.12s
Train Epoch: 572 [40960/90000 (45%)]	Loss: -3.6169	Cost: 7.69s
Train Epoch: 572 [61440/90000 (68%)]	Loss: -4.0710	Cost: 5.78s
Train Epoch: 572 [81920/90000 (91%)]	Loss: -3.8231	Cost: 5.95s
Train Epoch: 572 	Average Loss: -3.3644
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.6784

Learning rate: 0.00016227877804881124
Re-generating waveforms for posterior prior.
Train Epoch: 573 [0/90000 (0%)]	Loss: 2.7509	Cost: 23.58s
Train Epoch: 573 [20480/90000 (23%)]	Loss: -3.9196	Cost: 6.14s
Train Epoch: 573 [40960/90000 (45%)]	Loss: -3.7379	Cost: 6.88s
Train Epoch: 573 [61440/90000 (68%)]	Loss: -3.9633	Cost: 5.83s
Train Epoch: 573 [81920/90000 (91%)]	Loss: -4.0609	Cost: 6.28s
Train Epoch: 573 	Average Loss: -3.4629
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.4200

Learning rate: 0.00016215580360486674
Re-generating waveforms for posterior prior.
Train Epoch: 574 [0/90000 (0%)]	Loss: 2.4893	Cost: 23.95s
Train Epoch: 574 [20480/90000 (23%)]	Loss: -4.3472	Cost: 6.11s
Train Epoch: 574 [40960/90000 (45%)]	Loss: -3.8570	Cost: 7.37s
Train Epoch: 574 [61440/90000 (68%)]	Loss: -4.3052	Cost: 5.80s
Train Epoch: 574 [81920/90000 (91%)]	Loss: -4.4207	Cost: 5.86s
Train Epoch: 574 	Average Loss: -3.6622
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.2786

Learning rate: 0.0001620326757976556
Re-generating waveforms for posterior prior.
Train Epoch: 575 [0/90000 (0%)]	Loss: 2.3182	Cost: 24.10s
Train Epoch: 575 [20480/90000 (23%)]	Loss: -4.3200	Cost: 6.38s
Train Epoch: 575 [40960/90000 (45%)]	Loss: -3.8625	Cost: 15.35s
Train Epoch: 575 [61440/90000 (68%)]	Loss: -3.5238	Cost: 6.03s
Train Epoch: 575 [81920/90000 (91%)]	Loss: -3.6969	Cost: 14.12s
Train Epoch: 575 	Average Loss: -3.4427
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.6250

Learning rate: 0.00016190939493098338
Re-generating waveforms for posterior prior.
Train Epoch: 576 [0/90000 (0%)]	Loss: 2.6600	Cost: 23.75s
Train Epoch: 576 [20480/90000 (23%)]	Loss: -4.0534	Cost: 6.07s
Train Epoch: 576 [40960/90000 (45%)]	Loss: -3.3932	Cost: 6.99s
Train Epoch: 576 [61440/90000 (68%)]	Loss: -3.7746	Cost: 5.87s
Train Epoch: 576 [81920/90000 (91%)]	Loss: -4.0832	Cost: 5.72s
Train Epoch: 576 	Average Loss: -3.3706
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.4630

Learning rate: 0.0001617859613090334
Re-generating waveforms for posterior prior.
Train Epoch: 577 [0/90000 (0%)]	Loss: 2.2752	Cost: 23.65s
Train Epoch: 577 [20480/90000 (23%)]	Loss: -4.1637	Cost: 6.11s
Train Epoch: 577 [40960/90000 (45%)]	Loss: -3.6287	Cost: 6.76s
Train Epoch: 577 [61440/90000 (68%)]	Loss: -3.7655	Cost: 5.83s
Train Epoch: 577 [81920/90000 (91%)]	Loss: -4.0118	Cost: 5.95s
Train Epoch: 577 	Average Loss: -3.4213
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.5013

Learning rate: 0.00016166237523636588
Re-generating waveforms for posterior prior.
Train Epoch: 578 [0/90000 (0%)]	Loss: 2.4533	Cost: 23.89s
Train Epoch: 578 [20480/90000 (23%)]	Loss: -4.2657	Cost: 6.09s
Train Epoch: 578 [40960/90000 (45%)]	Loss: -3.8073	Cost: 7.31s
Train Epoch: 578 [61440/90000 (68%)]	Loss: -4.1660	Cost: 5.79s
Train Epoch: 578 [81920/90000 (91%)]	Loss: -4.1808	Cost: 6.14s
Train Epoch: 578 	Average Loss: -3.6380
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.3169

Learning rate: 0.00016153863701791712
Re-generating waveforms for posterior prior.
Train Epoch: 579 [0/90000 (0%)]	Loss: 2.5476	Cost: 24.14s
Train Epoch: 579 [20480/90000 (23%)]	Loss: -4.1592	Cost: 6.06s
Train Epoch: 579 [40960/90000 (45%)]	Loss: -3.6526	Cost: 7.37s
Train Epoch: 579 [61440/90000 (68%)]	Loss: -4.0894	Cost: 5.74s
Train Epoch: 579 [81920/90000 (91%)]	Loss: -4.2651	Cost: 6.09s
Train Epoch: 579 	Average Loss: -3.6102
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.5072

Learning rate: 0.00016141474695899888
Re-generating waveforms for posterior prior.
Train Epoch: 580 [0/90000 (0%)]	Loss: 2.5815	Cost: 23.60s
Train Epoch: 580 [20480/90000 (23%)]	Loss: -4.3219	Cost: 6.10s
Train Epoch: 580 [40960/90000 (45%)]	Loss: -3.8545	Cost: 7.35s
Train Epoch: 580 [61440/90000 (68%)]	Loss: -4.0862	Cost: 5.79s
Train Epoch: 580 [81920/90000 (91%)]	Loss: -4.1663	Cost: 5.92s
Train Epoch: 580 	Average Loss: -3.6199
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.7367

Learning rate: 0.0001612907053652976
Re-generating waveforms for posterior prior.
Train Epoch: 581 [0/90000 (0%)]	Loss: 2.5892	Cost: 23.89s
Train Epoch: 581 [20480/90000 (23%)]	Loss: -4.2738	Cost: 6.10s
Train Epoch: 581 [40960/90000 (45%)]	Loss: -3.7862	Cost: 7.19s
Train Epoch: 581 [61440/90000 (68%)]	Loss: -4.0932	Cost: 5.82s
Train Epoch: 581 [81920/90000 (91%)]	Loss: -4.2409	Cost: 5.70s
Train Epoch: 581 	Average Loss: -3.5684
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.4740

Learning rate: 0.00016116651254287356
Re-generating waveforms for posterior prior.
Train Epoch: 582 [0/90000 (0%)]	Loss: 2.5478	Cost: 24.03s
Train Epoch: 582 [20480/90000 (23%)]	Loss: -4.2700	Cost: 6.09s
Train Epoch: 582 [40960/90000 (45%)]	Loss: -3.9158	Cost: 7.39s
Train Epoch: 582 [61440/90000 (68%)]	Loss: -4.1232	Cost: 5.79s
Train Epoch: 582 [81920/90000 (91%)]	Loss: -4.3577	Cost: 6.03s
Train Epoch: 582 	Average Loss: -3.6460
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.3331

Learning rate: 0.00016104216879816018
Re-generating waveforms for posterior prior.
Train Epoch: 583 [0/90000 (0%)]	Loss: 2.4142	Cost: 24.02s
Train Epoch: 583 [20480/90000 (23%)]	Loss: -4.2198	Cost: 6.10s
Train Epoch: 583 [40960/90000 (45%)]	Loss: -3.8558	Cost: 7.16s
Train Epoch: 583 [61440/90000 (68%)]	Loss: -4.0373	Cost: 5.79s
Train Epoch: 583 [81920/90000 (91%)]	Loss: -4.3540	Cost: 6.33s
Train Epoch: 583 	Average Loss: -3.6589
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.2371

Learning rate: 0.00016091767443796333
Re-generating waveforms for posterior prior.
Train Epoch: 584 [0/90000 (0%)]	Loss: 2.4620	Cost: 24.09s
Train Epoch: 584 [20480/90000 (23%)]	Loss: -4.1547	Cost: 6.22s
Train Epoch: 584 [40960/90000 (45%)]	Loss: -3.7742	Cost: 7.49s
Train Epoch: 584 [61440/90000 (68%)]	Loss: -4.1800	Cost: 5.84s
Train Epoch: 584 [81920/90000 (91%)]	Loss: -4.3060	Cost: 6.03s
Train Epoch: 584 	Average Loss: -3.6212
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.3472

Learning rate: 0.00016079302976946047
Re-generating waveforms for posterior prior.
Train Epoch: 585 [0/90000 (0%)]	Loss: 2.1340	Cost: 23.69s
Train Epoch: 585 [20480/90000 (23%)]	Loss: -4.5219	Cost: 6.09s
Train Epoch: 585 [40960/90000 (45%)]	Loss: -4.0004	Cost: 7.27s
Train Epoch: 585 [61440/90000 (68%)]	Loss: -4.5115	Cost: 6.40s
Train Epoch: 585 [81920/90000 (91%)]	Loss: -4.4654	Cost: 5.70s
Train Epoch: 585 	Average Loss: -3.8621
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.1551

Learning rate: 0.00016066823510019987
Re-generating waveforms for posterior prior.
Train Epoch: 586 [0/90000 (0%)]	Loss: 2.3018	Cost: 24.02s
Train Epoch: 586 [20480/90000 (23%)]	Loss: -4.4967	Cost: 6.11s
Train Epoch: 586 [40960/90000 (45%)]	Loss: -4.2071	Cost: 7.27s
Train Epoch: 586 [61440/90000 (68%)]	Loss: -4.4004	Cost: 5.84s
Train Epoch: 586 [81920/90000 (91%)]	Loss: -4.5237	Cost: 5.65s
Train Epoch: 586 	Average Loss: -3.9215
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.1959

Learning rate: 0.00016054329073810007
Re-generating waveforms for posterior prior.
Train Epoch: 587 [0/90000 (0%)]	Loss: 1.8649	Cost: 23.85s
Train Epoch: 587 [20480/90000 (23%)]	Loss: -4.5223	Cost: 6.12s
Train Epoch: 587 [40960/90000 (45%)]	Loss: -3.8189	Cost: 7.29s
Train Epoch: 587 [61440/90000 (68%)]	Loss: -3.8843	Cost: 5.79s
Train Epoch: 587 [81920/90000 (91%)]	Loss: -3.8389	Cost: 5.79s
Train Epoch: 587 	Average Loss: -3.5965
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.7187

Learning rate: 0.00016041819699144877
Re-generating waveforms for posterior prior.
Train Epoch: 588 [0/90000 (0%)]	Loss: 3.2195	Cost: 23.66s
Train Epoch: 588 [20480/90000 (23%)]	Loss: -4.2216	Cost: 6.12s
Train Epoch: 588 [40960/90000 (45%)]	Loss: -3.6741	Cost: 7.30s
Train Epoch: 588 [61440/90000 (68%)]	Loss: -3.9085	Cost: 5.78s
Train Epoch: 588 [81920/90000 (91%)]	Loss: -4.1518	Cost: 5.80s
Train Epoch: 588 	Average Loss: -3.4881
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.4185

Learning rate: 0.00016029295416890242
Re-generating waveforms for posterior prior.
Train Epoch: 589 [0/90000 (0%)]	Loss: 2.6254	Cost: 23.49s
Train Epoch: 589 [20480/90000 (23%)]	Loss: -4.5219	Cost: 6.11s
Train Epoch: 589 [40960/90000 (45%)]	Loss: -3.9461	Cost: 7.46s
Train Epoch: 589 [61440/90000 (68%)]	Loss: -4.4189	Cost: 5.77s
Train Epoch: 589 [81920/90000 (91%)]	Loss: -4.7036	Cost: 5.76s
Train Epoch: 589 	Average Loss: -3.8471
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.0478

Learning rate: 0.00016016756257948518
Re-generating waveforms for posterior prior.
Train Epoch: 590 [0/90000 (0%)]	Loss: 1.9250	Cost: 23.82s
Train Epoch: 590 [20480/90000 (23%)]	Loss: -4.4859	Cost: 6.10s
Train Epoch: 590 [40960/90000 (45%)]	Loss: -3.8039	Cost: 7.34s
Train Epoch: 590 [61440/90000 (68%)]	Loss: -3.8485	Cost: 5.77s
Train Epoch: 590 [81920/90000 (91%)]	Loss: -3.7454	Cost: 5.90s
Train Epoch: 590 	Average Loss: -3.5848
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.6467

Learning rate: 0.00016004202253258834
Re-generating waveforms for posterior prior.
Train Epoch: 591 [0/90000 (0%)]	Loss: 2.3739	Cost: 24.04s
Train Epoch: 591 [20480/90000 (23%)]	Loss: -3.9608	Cost: 6.09s
Train Epoch: 591 [40960/90000 (45%)]	Loss: -3.6533	Cost: 6.89s
Train Epoch: 591 [61440/90000 (68%)]	Loss: -4.1761	Cost: 5.88s
Train Epoch: 591 [81920/90000 (91%)]	Loss: -4.3488	Cost: 5.86s
Train Epoch: 591 	Average Loss: -3.5091
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.4609

Learning rate: 0.00015991633433796955
Re-generating waveforms for posterior prior.
Train Epoch: 592 [0/90000 (0%)]	Loss: 2.3361	Cost: 24.07s
Train Epoch: 592 [20480/90000 (23%)]	Loss: -4.5414	Cost: 6.14s
Train Epoch: 592 [40960/90000 (45%)]	Loss: -4.0767	Cost: 7.11s
Train Epoch: 592 [61440/90000 (68%)]	Loss: -4.4301	Cost: 5.89s
Train Epoch: 592 [81920/90000 (91%)]	Loss: -4.5961	Cost: 5.96s
Train Epoch: 592 	Average Loss: -3.8919
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.0613

Learning rate: 0.00015979049830575185
Re-generating waveforms for posterior prior.
Train Epoch: 593 [0/90000 (0%)]	Loss: 2.3518	Cost: 23.47s
Train Epoch: 593 [20480/90000 (23%)]	Loss: -4.6009	Cost: 6.15s
Train Epoch: 593 [40960/90000 (45%)]	Loss: -3.9600	Cost: 7.23s
Train Epoch: 593 [61440/90000 (68%)]	Loss: -4.1150	Cost: 5.82s
Train Epoch: 593 [81920/90000 (91%)]	Loss: -4.3240	Cost: 6.15s
Train Epoch: 593 	Average Loss: -3.8301
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.2678

Learning rate: 0.00015966451474642317
Re-generating waveforms for posterior prior.
Train Epoch: 594 [0/90000 (0%)]	Loss: 1.9094	Cost: 24.18s
Train Epoch: 594 [20480/90000 (23%)]	Loss: -4.5663	Cost: 6.12s
Train Epoch: 594 [40960/90000 (45%)]	Loss: -4.1666	Cost: 7.17s
Train Epoch: 594 [61440/90000 (68%)]	Loss: -4.3105	Cost: 5.85s
Train Epoch: 594 [81920/90000 (91%)]	Loss: -4.7676	Cost: 5.86s
Train Epoch: 594 	Average Loss: -3.9971
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.0568

Learning rate: 0.00015953838397083544
Re-generating waveforms for posterior prior.
Train Epoch: 595 [0/90000 (0%)]	Loss: 2.2986	Cost: 23.96s
Train Epoch: 595 [20480/90000 (23%)]	Loss: -4.8694	Cost: 6.16s
Train Epoch: 595 [40960/90000 (45%)]	Loss: -4.5159	Cost: 7.46s
Train Epoch: 595 [61440/90000 (68%)]	Loss: -4.5800	Cost: 5.80s
Train Epoch: 595 [81920/90000 (91%)]	Loss: -4.6661	Cost: 6.00s
Train Epoch: 595 	Average Loss: -4.1722
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.2091

Learning rate: 0.00015941210629020382
Re-generating waveforms for posterior prior.
Train Epoch: 596 [0/90000 (0%)]	Loss: 2.4154	Cost: 24.37s
Train Epoch: 596 [20480/90000 (23%)]	Loss: -4.3698	Cost: 6.15s
Train Epoch: 596 [40960/90000 (45%)]	Loss: -4.0937	Cost: 7.45s
Train Epoch: 596 [61440/90000 (68%)]	Loss: -4.5770	Cost: 5.79s
Train Epoch: 596 [81920/90000 (91%)]	Loss: -4.6389	Cost: 5.72s
Train Epoch: 596 	Average Loss: -3.9430
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.0447

Learning rate: 0.0001592856820161059
Re-generating waveforms for posterior prior.
Train Epoch: 597 [0/90000 (0%)]	Loss: 2.0483	Cost: 24.55s
Train Epoch: 597 [20480/90000 (23%)]	Loss: -4.6315	Cost: 6.07s
Train Epoch: 597 [40960/90000 (45%)]	Loss: -4.3256	Cost: 7.20s
Train Epoch: 597 [61440/90000 (68%)]	Loss: -4.4627	Cost: 5.83s
Train Epoch: 597 [81920/90000 (91%)]	Loss: -4.5711	Cost: 5.65s
Train Epoch: 597 	Average Loss: -4.0612
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.1010

Learning rate: 0.000159159111460481
Re-generating waveforms for posterior prior.
Train Epoch: 598 [0/90000 (0%)]	Loss: 2.1405	Cost: 23.32s
Train Epoch: 598 [20480/90000 (23%)]	Loss: -4.4156	Cost: 6.12s
Train Epoch: 598 [40960/90000 (45%)]	Loss: -4.2333	Cost: 7.65s
Train Epoch: 598 [61440/90000 (68%)]	Loss: -4.3379	Cost: 5.80s
Train Epoch: 598 [81920/90000 (91%)]	Loss: -4.6939	Cost: 5.80s
Train Epoch: 598 	Average Loss: -3.9544
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.2268

Learning rate: 0.00015903239493562945
Re-generating waveforms for posterior prior.
Train Epoch: 599 [0/90000 (0%)]	Loss: 2.3637	Cost: 23.46s
Train Epoch: 599 [20480/90000 (23%)]	Loss: -4.7305	Cost: 6.23s
Train Epoch: 599 [40960/90000 (45%)]	Loss: -4.0861	Cost: 7.11s
Train Epoch: 599 [61440/90000 (68%)]	Loss: -4.2519	Cost: 5.92s
Train Epoch: 599 [81920/90000 (91%)]	Loss: -4.6782	Cost: 5.98s
Train Epoch: 599 	Average Loss: -3.9431
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.2241

Learning rate: 0.00015890553275421158
Re-generating waveforms for posterior prior.
Train Epoch: 600 [0/90000 (0%)]	Loss: 2.0678	Cost: 23.38s
Train Epoch: 600 [20480/90000 (23%)]	Loss: -4.6376	Cost: 6.16s
Train Epoch: 600 [40960/90000 (45%)]	Loss: -4.1533	Cost: 7.37s
Train Epoch: 600 [61440/90000 (68%)]	Loss: -4.5978	Cost: 5.81s
Train Epoch: 600 [81920/90000 (91%)]	Loss: -4.7299	Cost: 6.14s
Train Epoch: 600 	Average Loss: -4.0231
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.0555

Saving model as model_sample_from_all_posterior.pt_e600 & waveforms_supplementary_sample_from_all_posterior.hdf5_e600
Learning rate: 0.0001587785252292473
Re-generating waveforms for posterior prior.
Train Epoch: 601 [0/90000 (0%)]	Loss: 1.8534	Cost: 23.63s
Train Epoch: 601 [20480/90000 (23%)]	Loss: -4.8553	Cost: 6.11s
Train Epoch: 601 [40960/90000 (45%)]	Loss: -4.1719	Cost: 6.48s
Train Epoch: 601 [61440/90000 (68%)]	Loss: -4.6020	Cost: 5.85s
Train Epoch: 601 [81920/90000 (91%)]	Loss: -4.5462	Cost: 5.91s
Train Epoch: 601 	Average Loss: -4.0076
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.2283

Learning rate: 0.000158651372674115
Re-generating waveforms for posterior prior.
Train Epoch: 602 [0/90000 (0%)]	Loss: 2.1816	Cost: 23.66s
Train Epoch: 602 [20480/90000 (23%)]	Loss: -4.5796	Cost: 6.17s
Train Epoch: 602 [40960/90000 (45%)]	Loss: -4.5197	Cost: 6.53s
Train Epoch: 602 [61440/90000 (68%)]	Loss: -4.7240	Cost: 5.87s
Train Epoch: 602 [81920/90000 (91%)]	Loss: -4.8693	Cost: 6.18s
Train Epoch: 602 	Average Loss: -4.1571
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.0900

Learning rate: 0.000158524075402551
Re-generating waveforms for posterior prior.
Train Epoch: 603 [0/90000 (0%)]	Loss: 1.7542	Cost: 24.28s
Train Epoch: 603 [20480/90000 (23%)]	Loss: -4.7324	Cost: 6.09s
Train Epoch: 603 [40960/90000 (45%)]	Loss: -4.4185	Cost: 7.46s
Train Epoch: 603 [61440/90000 (68%)]	Loss: -4.8992	Cost: 5.80s
Train Epoch: 603 [81920/90000 (91%)]	Loss: -4.8350	Cost: 5.70s
Train Epoch: 603 	Average Loss: -4.2747
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.8569

Learning rate: 0.00015839663372864865
Re-generating waveforms for posterior prior.
Train Epoch: 604 [0/90000 (0%)]	Loss: 1.9335	Cost: 23.94s
Train Epoch: 604 [20480/90000 (23%)]	Loss: -5.0300	Cost: 6.25s
Train Epoch: 604 [40960/90000 (45%)]	Loss: -4.6056	Cost: 7.17s
Train Epoch: 604 [61440/90000 (68%)]	Loss: -4.8472	Cost: 5.88s
Train Epoch: 604 [81920/90000 (91%)]	Loss: -4.8297	Cost: 5.71s
Train Epoch: 604 	Average Loss: -4.3136
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.9097

Learning rate: 0.00015826904796685762
Re-generating waveforms for posterior prior.
Train Epoch: 605 [0/90000 (0%)]	Loss: 2.1693	Cost: 24.84s
Train Epoch: 605 [20480/90000 (23%)]	Loss: -4.9788	Cost: 6.07s
Train Epoch: 605 [40960/90000 (45%)]	Loss: -4.4451	Cost: 7.09s
Train Epoch: 605 [61440/90000 (68%)]	Loss: -4.8768	Cost: 5.82s
Train Epoch: 605 [81920/90000 (91%)]	Loss: -4.9723	Cost: 5.67s
Train Epoch: 605 	Average Loss: -4.3299
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.8215

Learning rate: 0.00015814131843198305
Re-generating waveforms for posterior prior.
Train Epoch: 606 [0/90000 (0%)]	Loss: 1.8853	Cost: 23.95s
Train Epoch: 606 [20480/90000 (23%)]	Loss: -4.6107	Cost: 6.09s
Train Epoch: 606 [40960/90000 (45%)]	Loss: -4.1162	Cost: 7.49s
Train Epoch: 606 [61440/90000 (68%)]	Loss: -4.3850	Cost: 5.81s
Train Epoch: 606 [81920/90000 (91%)]	Loss: -4.6098	Cost: 6.04s
Train Epoch: 606 	Average Loss: -4.0001
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.2904

Learning rate: 0.00015801344543918495
Re-generating waveforms for posterior prior.
Train Epoch: 607 [0/90000 (0%)]	Loss: 2.1098	Cost: 24.41s
Train Epoch: 607 [20480/90000 (23%)]	Loss: -4.6949	Cost: 6.09s
Train Epoch: 607 [40960/90000 (45%)]	Loss: -4.4713	Cost: 6.73s
Train Epoch: 607 [61440/90000 (68%)]	Loss: -4.7427	Cost: 5.86s
Train Epoch: 607 [81920/90000 (91%)]	Loss: -5.0649	Cost: 6.09s
Train Epoch: 607 	Average Loss: -4.2625
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.9717

Learning rate: 0.00015788542930397713
Re-generating waveforms for posterior prior.
Train Epoch: 608 [0/90000 (0%)]	Loss: 1.8232	Cost: 24.05s
Train Epoch: 608 [20480/90000 (23%)]	Loss: -5.1670	Cost: 6.13s
Train Epoch: 608 [40960/90000 (45%)]	Loss: -4.7493	Cost: 6.87s
Train Epoch: 608 [61440/90000 (68%)]	Loss: -4.5814	Cost: 5.86s
Train Epoch: 608 [81920/90000 (91%)]	Loss: -4.8810	Cost: 5.76s
Train Epoch: 608 	Average Loss: -4.3731
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.9710

Learning rate: 0.00015775727034222675
Re-generating waveforms for posterior prior.
Train Epoch: 609 [0/90000 (0%)]	Loss: 1.9293	Cost: 24.02s
Train Epoch: 609 [20480/90000 (23%)]	Loss: -4.8294	Cost: 6.09s
Train Epoch: 609 [40960/90000 (45%)]	Loss: -4.5331	Cost: 7.20s
Train Epoch: 609 [61440/90000 (68%)]	Loss: -5.1044	Cost: 5.81s
Train Epoch: 609 [81920/90000 (91%)]	Loss: -5.2429	Cost: 5.84s
Train Epoch: 609 	Average Loss: -4.4141
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.7351

Learning rate: 0.00015762896887015328
Re-generating waveforms for posterior prior.
Train Epoch: 610 [0/90000 (0%)]	Loss: 1.9493	Cost: 24.78s
Train Epoch: 610 [20480/90000 (23%)]	Loss: -5.1987	Cost: 6.08s
Train Epoch: 610 [40960/90000 (45%)]	Loss: -4.7154	Cost: 7.17s
Train Epoch: 610 [61440/90000 (68%)]	Loss: -5.0098	Cost: 5.82s
Train Epoch: 610 [81920/90000 (91%)]	Loss: -5.0523	Cost: 5.67s
Train Epoch: 610 	Average Loss: -4.4857
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.7888

Learning rate: 0.00015750052520432787
Re-generating waveforms for posterior prior.
Train Epoch: 611 [0/90000 (0%)]	Loss: 1.8673	Cost: 23.66s
Train Epoch: 611 [20480/90000 (23%)]	Loss: -5.0339	Cost: 6.10s
Train Epoch: 611 [40960/90000 (45%)]	Loss: -4.7992	Cost: 7.70s
Train Epoch: 611 [61440/90000 (68%)]	Loss: -5.0793	Cost: 5.79s
Train Epoch: 611 [81920/90000 (91%)]	Loss: -5.2042	Cost: 6.06s
Train Epoch: 611 	Average Loss: -4.5107
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.8154

Learning rate: 0.00015737193966167246
Re-generating waveforms for posterior prior.
Train Epoch: 612 [0/90000 (0%)]	Loss: 1.6651	Cost: 24.00s
Train Epoch: 612 [20480/90000 (23%)]	Loss: -5.2003	Cost: 6.11s
Train Epoch: 612 [40960/90000 (45%)]	Loss: -4.6015	Cost: 7.57s
Train Epoch: 612 [61440/90000 (68%)]	Loss: -4.9917	Cost: 5.78s
Train Epoch: 612 [81920/90000 (91%)]	Loss: -5.1729	Cost: 5.83s
Train Epoch: 612 	Average Loss: -4.4251
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.8248

Learning rate: 0.0001572432125594591
Re-generating waveforms for posterior prior.
Train Epoch: 613 [0/90000 (0%)]	Loss: 2.0564	Cost: 23.76s
Train Epoch: 613 [20480/90000 (23%)]	Loss: -5.0473	Cost: 6.12s
Train Epoch: 613 [40960/90000 (45%)]	Loss: -4.0953	Cost: 7.14s
Train Epoch: 613 [61440/90000 (68%)]	Loss: -4.4506	Cost: 5.79s
Train Epoch: 613 [81920/90000 (91%)]	Loss: -4.4377	Cost: 6.19s
Train Epoch: 613 	Average Loss: -4.0244
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.3995

Learning rate: 0.00015711434421530914
Re-generating waveforms for posterior prior.
Train Epoch: 614 [0/90000 (0%)]	Loss: 2.2182	Cost: 24.41s
Train Epoch: 614 [20480/90000 (23%)]	Loss: -3.5780	Cost: 6.09s
Train Epoch: 614 [40960/90000 (45%)]	Loss: -2.5890	Cost: 6.66s
Train Epoch: 614 [61440/90000 (68%)]	Loss: -3.4179	Cost: 5.82s
Train Epoch: 614 [81920/90000 (91%)]	Loss: -3.8355	Cost: 5.99s
Train Epoch: 614 	Average Loss: -3.0001
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.6080

Learning rate: 0.0001569853349471924
Re-generating waveforms for posterior prior.
Train Epoch: 615 [0/90000 (0%)]	Loss: 2.2847	Cost: 23.98s
Train Epoch: 615 [20480/90000 (23%)]	Loss: -4.0695	Cost: 6.08s
Train Epoch: 615 [40960/90000 (45%)]	Loss: -4.1599	Cost: 7.72s
Train Epoch: 615 [61440/90000 (68%)]	Loss: -4.5150	Cost: 5.76s
Train Epoch: 615 [81920/90000 (91%)]	Loss: -4.6656	Cost: 6.18s
Train Epoch: 615 	Average Loss: -3.7957
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.0850

Learning rate: 0.00015685618507342642
Re-generating waveforms for posterior prior.
Train Epoch: 616 [0/90000 (0%)]	Loss: 2.3072	Cost: 23.50s
Train Epoch: 616 [20480/90000 (23%)]	Loss: -4.6133	Cost: 6.15s
Train Epoch: 616 [40960/90000 (45%)]	Loss: -4.4134	Cost: 7.60s
Train Epoch: 616 [61440/90000 (68%)]	Loss: -3.5951	Cost: 5.79s
Train Epoch: 616 [81920/90000 (91%)]	Loss: -4.2200	Cost: 6.09s
Train Epoch: 616 	Average Loss: -3.7895
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.2439

Learning rate: 0.0001567268949126757
Re-generating waveforms for posterior prior.
Train Epoch: 617 [0/90000 (0%)]	Loss: 2.4567	Cost: 23.79s
Train Epoch: 617 [20480/90000 (23%)]	Loss: -4.6962	Cost: 6.08s
Train Epoch: 617 [40960/90000 (45%)]	Loss: -4.5026	Cost: 7.44s
Train Epoch: 617 [61440/90000 (68%)]	Loss: -5.0507	Cost: 5.78s
Train Epoch: 617 [81920/90000 (91%)]	Loss: -5.1274	Cost: 5.74s
Train Epoch: 617 	Average Loss: -4.2245
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.7527

Learning rate: 0.0001565974647839508
Re-generating waveforms for posterior prior.
Train Epoch: 618 [0/90000 (0%)]	Loss: 1.6433	Cost: 23.46s
Train Epoch: 618 [20480/90000 (23%)]	Loss: -5.1355	Cost: 6.06s
Train Epoch: 618 [40960/90000 (45%)]	Loss: -4.5068	Cost: 7.12s
Train Epoch: 618 [61440/90000 (68%)]	Loss: -4.9605	Cost: 5.78s
Train Epoch: 618 [81920/90000 (91%)]	Loss: -5.0185	Cost: 6.35s
Train Epoch: 618 	Average Loss: -4.3966
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.9105

Learning rate: 0.00015646789500660776
Re-generating waveforms for posterior prior.
Train Epoch: 619 [0/90000 (0%)]	Loss: 1.8066	Cost: 23.75s
Train Epoch: 619 [20480/90000 (23%)]	Loss: -5.1410	Cost: 6.08s
Train Epoch: 619 [40960/90000 (45%)]	Loss: -3.9198	Cost: 6.92s
Train Epoch: 619 [61440/90000 (68%)]	Loss: -4.5773	Cost: 5.84s
Train Epoch: 619 [81920/90000 (91%)]	Loss: -4.6155	Cost: 5.76s
Train Epoch: 619 	Average Loss: -4.0421
Re-generating waveforms for posterior prior.
Test set: Average loss: 2.1227

Learning rate: 0.00015633818590034707
Re-generating waveforms for posterior prior.
Train Epoch: 620 [0/90000 (0%)]	Loss: 2.2879	Cost: 24.57s
Train Epoch: 620 [20480/90000 (23%)]	Loss: -4.6844	Cost: 6.11s
Train Epoch: 620 [40960/90000 (45%)]	Loss: -4.5804	Cost: 6.43s
Train Epoch: 620 [61440/90000 (68%)]	Loss: -5.2001	Cost: 5.87s
Train Epoch: 620 [81920/90000 (91%)]	Loss: -5.1514	Cost: 5.69s
Train Epoch: 620 	Average Loss: -4.3308
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.8698

Learning rate: 0.0001562083377852131
Re-generating waveforms for posterior prior.
Train Epoch: 621 [0/90000 (0%)]	Loss: 1.6810	Cost: 23.53s
Train Epoch: 621 [20480/90000 (23%)]	Loss: -5.1698	Cost: 6.11s
Train Epoch: 621 [40960/90000 (45%)]	Loss: -4.1890	Cost: 7.49s
Train Epoch: 621 [61440/90000 (68%)]	Loss: -4.8247	Cost: 5.79s
Train Epoch: 621 [81920/90000 (91%)]	Loss: -5.1827	Cost: 5.72s
Train Epoch: 621 	Average Loss: -4.3061
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.7399

Learning rate: 0.00015607835098159316
Re-generating waveforms for posterior prior.
Train Epoch: 622 [0/90000 (0%)]	Loss: 1.3863	Cost: 24.43s
Train Epoch: 622 [20480/90000 (23%)]	Loss: -5.2977	Cost: 6.21s
Train Epoch: 622 [40960/90000 (45%)]	Loss: -4.9632	Cost: 6.90s
Train Epoch: 622 [61440/90000 (68%)]	Loss: -5.1618	Cost: 5.85s
Train Epoch: 622 [81920/90000 (91%)]	Loss: -5.5954	Cost: 5.79s
Train Epoch: 622 	Average Loss: -4.7153
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.5255

Learning rate: 0.00015594822581021676
Re-generating waveforms for posterior prior.
Train Epoch: 623 [0/90000 (0%)]	Loss: 1.6212	Cost: 23.30s
Train Epoch: 623 [20480/90000 (23%)]	Loss: -5.4655	Cost: 6.14s
Train Epoch: 623 [40960/90000 (45%)]	Loss: -5.2061	Cost: 7.47s
Train Epoch: 623 [61440/90000 (68%)]	Loss: -5.2691	Cost: 5.81s
Train Epoch: 623 [81920/90000 (91%)]	Loss: -5.2721	Cost: 6.13s
Train Epoch: 623 	Average Loss: -4.7840
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.6697

Learning rate: 0.0001558179625921548
Re-generating waveforms for posterior prior.
Train Epoch: 624 [0/90000 (0%)]	Loss: 1.8745	Cost: 23.74s
Train Epoch: 624 [20480/90000 (23%)]	Loss: -5.3245	Cost: 6.11s
Train Epoch: 624 [40960/90000 (45%)]	Loss: -5.1100	Cost: 7.56s
Train Epoch: 624 [61440/90000 (68%)]	Loss: -5.4030	Cost: 5.79s
Train Epoch: 624 [81920/90000 (91%)]	Loss: -5.5497	Cost: 5.76s
Train Epoch: 624 	Average Loss: -4.7975
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.5335

Learning rate: 0.00015568756164881885
Re-generating waveforms for posterior prior.
Train Epoch: 625 [0/90000 (0%)]	Loss: 1.8463	Cost: 24.02s
Train Epoch: 625 [20480/90000 (23%)]	Loss: -5.1366	Cost: 6.13s
Train Epoch: 625 [40960/90000 (45%)]	Loss: -4.7151	Cost: 7.39s
Train Epoch: 625 [61440/90000 (68%)]	Loss: -5.2759	Cost: 5.81s
Train Epoch: 625 [81920/90000 (91%)]	Loss: -5.3683	Cost: 6.02s
Train Epoch: 625 	Average Loss: -4.7043
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.5074

Learning rate: 0.00015555702330196026
Re-generating waveforms for posterior prior.
Train Epoch: 626 [0/90000 (0%)]	Loss: 1.4892	Cost: 23.71s
Train Epoch: 626 [20480/90000 (23%)]	Loss: -5.5061	Cost: 6.12s
Train Epoch: 626 [40960/90000 (45%)]	Loss: -5.0435	Cost: 7.34s
Train Epoch: 626 [61440/90000 (68%)]	Loss: -5.3684	Cost: 5.78s
Train Epoch: 626 [81920/90000 (91%)]	Loss: -5.4352	Cost: 5.78s
Train Epoch: 626 	Average Loss: -4.8978
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.5558

Learning rate: 0.00015542634787366944
Re-generating waveforms for posterior prior.
Train Epoch: 627 [0/90000 (0%)]	Loss: 1.5903	Cost: 24.65s
Train Epoch: 627 [20480/90000 (23%)]	Loss: -5.1850	Cost: 6.09s
Train Epoch: 627 [40960/90000 (45%)]	Loss: -5.1027	Cost: 7.28s
Train Epoch: 627 [61440/90000 (68%)]	Loss: -5.4416	Cost: 5.81s
Train Epoch: 627 [81920/90000 (91%)]	Loss: -5.2462	Cost: 6.00s
Train Epoch: 627 	Average Loss: -4.7105
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.9064

Learning rate: 0.00015529553568637504
Re-generating waveforms for posterior prior.
Train Epoch: 628 [0/90000 (0%)]	Loss: 1.7903	Cost: 23.77s
Train Epoch: 628 [20480/90000 (23%)]	Loss: -5.0739	Cost: 6.12s
Train Epoch: 628 [40960/90000 (45%)]	Loss: -5.0512	Cost: 7.39s
Train Epoch: 628 [61440/90000 (68%)]	Loss: -5.2013	Cost: 5.85s
Train Epoch: 628 [81920/90000 (91%)]	Loss: -5.4708	Cost: 6.07s
Train Epoch: 628 	Average Loss: -4.6128
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.6061

Learning rate: 0.0001551645870628431
Re-generating waveforms for posterior prior.
Train Epoch: 629 [0/90000 (0%)]	Loss: 1.6551	Cost: 23.89s
Train Epoch: 629 [20480/90000 (23%)]	Loss: -5.4984	Cost: 6.17s
Train Epoch: 629 [40960/90000 (45%)]	Loss: -5.0122	Cost: 7.32s
Train Epoch: 629 [61440/90000 (68%)]	Loss: -4.9509	Cost: 5.82s
Train Epoch: 629 [81920/90000 (91%)]	Loss: -5.3582	Cost: 6.05s
Train Epoch: 629 	Average Loss: -4.7273
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.5461

Learning rate: 0.00015503350232617626
Re-generating waveforms for posterior prior.
Train Epoch: 630 [0/90000 (0%)]	Loss: 1.5519	Cost: 23.29s
Train Epoch: 630 [20480/90000 (23%)]	Loss: -5.3736	Cost: 6.13s
Train Epoch: 630 [40960/90000 (45%)]	Loss: -5.2123	Cost: 7.69s
Train Epoch: 630 [61440/90000 (68%)]	Loss: -5.3795	Cost: 5.78s
Train Epoch: 630 [81920/90000 (91%)]	Loss: -5.4841	Cost: 5.82s
Train Epoch: 630 	Average Loss: -4.8700
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.4607

Learning rate: 0.00015490228179981322
Re-generating waveforms for posterior prior.
Train Epoch: 631 [0/90000 (0%)]	Loss: 1.5496	Cost: 25.01s
Train Epoch: 631 [20480/90000 (23%)]	Loss: -5.6790	Cost: 6.06s
Train Epoch: 631 [40960/90000 (45%)]	Loss: -5.1839	Cost: 7.11s
Train Epoch: 631 [61440/90000 (68%)]	Loss: -5.5299	Cost: 5.86s
Train Epoch: 631 [81920/90000 (91%)]	Loss: -5.6516	Cost: 5.81s
Train Epoch: 631 	Average Loss: -4.9657
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.3330

Learning rate: 0.0001547709258075275
Re-generating waveforms for posterior prior.
Train Epoch: 632 [0/90000 (0%)]	Loss: 1.3869	Cost: 23.95s
Train Epoch: 632 [20480/90000 (23%)]	Loss: -5.7480	Cost: 6.13s
Train Epoch: 632 [40960/90000 (45%)]	Loss: -5.0937	Cost: 7.49s
Train Epoch: 632 [61440/90000 (68%)]	Loss: -4.9802	Cost: 5.78s
Train Epoch: 632 [81920/90000 (91%)]	Loss: -5.3468	Cost: 6.06s
Train Epoch: 632 	Average Loss: -4.8047
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.7066

Learning rate: 0.00015463943467342695
Re-generating waveforms for posterior prior.
Train Epoch: 633 [0/90000 (0%)]	Loss: 1.8591	Cost: 24.68s
Train Epoch: 633 [20480/90000 (23%)]	Loss: -5.6099	Cost: 6.45s
Train Epoch: 633 [40960/90000 (45%)]	Loss: -5.0681	Cost: 6.96s
Train Epoch: 633 [61440/90000 (68%)]	Loss: -5.3938	Cost: 5.87s
Train Epoch: 633 [81920/90000 (91%)]	Loss: -5.4478	Cost: 5.84s
Train Epoch: 633 	Average Loss: -4.8291
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.6221

Learning rate: 0.0001545078087219529
Re-generating waveforms for posterior prior.
Train Epoch: 634 [0/90000 (0%)]	Loss: 1.3492	Cost: 23.97s
Train Epoch: 634 [20480/90000 (23%)]	Loss: -5.3297	Cost: 6.13s
Train Epoch: 634 [40960/90000 (45%)]	Loss: -4.9750	Cost: 7.25s
Train Epoch: 634 [61440/90000 (68%)]	Loss: -5.2819	Cost: 5.79s
Train Epoch: 634 [81920/90000 (91%)]	Loss: -5.4600	Cost: 5.96s
Train Epoch: 634 	Average Loss: -4.7725
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.4576

Learning rate: 0.0001543760482778793
Re-generating waveforms for posterior prior.
Train Epoch: 635 [0/90000 (0%)]	Loss: 1.5610	Cost: 23.54s
Train Epoch: 635 [20480/90000 (23%)]	Loss: -5.2743	Cost: 6.16s
Train Epoch: 635 [40960/90000 (45%)]	Loss: -5.2018	Cost: 7.24s
Train Epoch: 635 [61440/90000 (68%)]	Loss: -5.5373	Cost: 5.80s
Train Epoch: 635 [81920/90000 (91%)]	Loss: -5.7800	Cost: 5.98s
Train Epoch: 635 	Average Loss: -4.9429
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.3792

Learning rate: 0.00015424415366631193
Re-generating waveforms for posterior prior.
Train Epoch: 636 [0/90000 (0%)]	Loss: 1.7783	Cost: 23.58s
Train Epoch: 636 [20480/90000 (23%)]	Loss: -5.3977	Cost: 6.11s
Train Epoch: 636 [40960/90000 (45%)]	Loss: -5.1159	Cost: 7.15s
Train Epoch: 636 [61440/90000 (68%)]	Loss: -5.5742	Cost: 5.81s
Train Epoch: 636 [81920/90000 (91%)]	Loss: -5.8935	Cost: 5.76s
Train Epoch: 636 	Average Loss: -4.9971
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.3294

Learning rate: 0.00015411212521268763
Re-generating waveforms for posterior prior.
Train Epoch: 637 [0/90000 (0%)]	Loss: 1.1543	Cost: 23.64s
Train Epoch: 637 [20480/90000 (23%)]	Loss: -5.8319	Cost: 6.15s
Train Epoch: 637 [40960/90000 (45%)]	Loss: -5.2524	Cost: 7.51s
Train Epoch: 637 [61440/90000 (68%)]	Loss: -5.4020	Cost: 5.81s
Train Epoch: 637 [81920/90000 (91%)]	Loss: -5.6493	Cost: 6.11s
Train Epoch: 637 	Average Loss: -5.0540
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.3758

Learning rate: 0.0001539799632427735
Re-generating waveforms for posterior prior.
Train Epoch: 638 [0/90000 (0%)]	Loss: 1.1949	Cost: 24.12s
Train Epoch: 638 [20480/90000 (23%)]	Loss: -5.6391	Cost: 6.17s
Train Epoch: 638 [40960/90000 (45%)]	Loss: -5.2415	Cost: 7.40s
Train Epoch: 638 [61440/90000 (68%)]	Loss: -5.6293	Cost: 5.83s
Train Epoch: 638 [81920/90000 (91%)]	Loss: -5.7140	Cost: 5.70s
Train Epoch: 638 	Average Loss: -5.0882
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.3319

Learning rate: 0.00015384766808266604
Re-generating waveforms for posterior prior.
Train Epoch: 639 [0/90000 (0%)]	Loss: 1.3114	Cost: 24.50s
Train Epoch: 639 [20480/90000 (23%)]	Loss: -5.6556	Cost: 6.13s
Train Epoch: 639 [40960/90000 (45%)]	Loss: -5.1809	Cost: 7.23s
Train Epoch: 639 [61440/90000 (68%)]	Loss: -5.5330	Cost: 5.83s
Train Epoch: 639 [81920/90000 (91%)]	Loss: -5.5256	Cost: 5.72s
Train Epoch: 639 	Average Loss: -4.9894
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.4167

Learning rate: 0.0001537152400587905
Re-generating waveforms for posterior prior.
Train Epoch: 640 [0/90000 (0%)]	Loss: 1.3264	Cost: 22.91s
Train Epoch: 640 [20480/90000 (23%)]	Loss: -5.7193	Cost: 6.14s
Train Epoch: 640 [40960/90000 (45%)]	Loss: -5.2769	Cost: 7.47s
Train Epoch: 640 [61440/90000 (68%)]	Loss: -5.3907	Cost: 5.79s
Train Epoch: 640 [81920/90000 (91%)]	Loss: -5.6501	Cost: 5.81s
Train Epoch: 640 	Average Loss: -4.9888
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.2879

Learning rate: 0.0001535826794978997
Re-generating waveforms for posterior prior.
Train Epoch: 641 [0/90000 (0%)]	Loss: 1.1382	Cost: 24.12s
Train Epoch: 641 [20480/90000 (23%)]	Loss: -5.6510	Cost: 6.12s
Train Epoch: 641 [40960/90000 (45%)]	Loss: -5.3317	Cost: 7.20s
Train Epoch: 641 [61440/90000 (68%)]	Loss: -5.5904	Cost: 5.84s
Train Epoch: 641 [81920/90000 (91%)]	Loss: -5.9006	Cost: 5.79s
Train Epoch: 641 	Average Loss: -5.0693
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.2303

Learning rate: 0.00015344998672707375
Re-generating waveforms for posterior prior.
Train Epoch: 642 [0/90000 (0%)]	Loss: 1.6931	Cost: 24.25s
Train Epoch: 642 [20480/90000 (23%)]	Loss: -5.7981	Cost: 6.05s
Train Epoch: 642 [40960/90000 (45%)]	Loss: -5.3896	Cost: 7.45s
Train Epoch: 642 [61440/90000 (68%)]	Loss: -5.7971	Cost: 5.82s
Train Epoch: 642 [81920/90000 (91%)]	Loss: -5.5171	Cost: 5.72s
Train Epoch: 642 	Average Loss: -5.1230
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.6661

Learning rate: 0.00015331716207371888
Re-generating waveforms for posterior prior.
Train Epoch: 643 [0/90000 (0%)]	Loss: 1.4509	Cost: 23.75s
Train Epoch: 643 [20480/90000 (23%)]	Loss: -5.4859	Cost: 6.15s
Train Epoch: 643 [40960/90000 (45%)]	Loss: -4.9581	Cost: 7.19s
Train Epoch: 643 [61440/90000 (68%)]	Loss: -5.3094	Cost: 5.80s
Train Epoch: 643 [81920/90000 (91%)]	Loss: -5.6104	Cost: 6.03s
Train Epoch: 643 	Average Loss: -4.8803
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.2422

Learning rate: 0.00015318420586556668
Re-generating waveforms for posterior prior.
Train Epoch: 644 [0/90000 (0%)]	Loss: 1.2997	Cost: 24.24s
Train Epoch: 644 [20480/90000 (23%)]	Loss: -5.7079	Cost: 6.11s
Train Epoch: 644 [40960/90000 (45%)]	Loss: -5.2113	Cost: 7.60s
Train Epoch: 644 [61440/90000 (68%)]	Loss: -5.5086	Cost: 5.77s
Train Epoch: 644 [81920/90000 (91%)]	Loss: -5.6292	Cost: 5.88s
Train Epoch: 644 	Average Loss: -4.9370
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.4093

Learning rate: 0.0001530511184306734
Re-generating waveforms for posterior prior.
Train Epoch: 645 [0/90000 (0%)]	Loss: 1.5860	Cost: 23.53s
Train Epoch: 645 [20480/90000 (23%)]	Loss: -4.7234	Cost: 6.10s
Train Epoch: 645 [40960/90000 (45%)]	Loss: -4.4317	Cost: 7.60s
Train Epoch: 645 [61440/90000 (68%)]	Loss: -4.8978	Cost: 5.81s
Train Epoch: 645 [81920/90000 (91%)]	Loss: -5.2512	Cost: 5.70s
Train Epoch: 645 	Average Loss: -4.4000
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.4134

Learning rate: 0.00015291790009741907
Re-generating waveforms for posterior prior.
Train Epoch: 646 [0/90000 (0%)]	Loss: 1.1405	Cost: 24.23s
Train Epoch: 646 [20480/90000 (23%)]	Loss: -5.6963	Cost: 6.09s
Train Epoch: 646 [40960/90000 (45%)]	Loss: -5.1777	Cost: 7.18s
Train Epoch: 646 [61440/90000 (68%)]	Loss: -5.7841	Cost: 5.88s
Train Epoch: 646 [81920/90000 (91%)]	Loss: -5.9150	Cost: 5.83s
Train Epoch: 646 	Average Loss: -5.1003
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.1453

Learning rate: 0.00015278455119450667
Re-generating waveforms for posterior prior.
Train Epoch: 647 [0/90000 (0%)]	Loss: 1.3398	Cost: 23.52s
Train Epoch: 647 [20480/90000 (23%)]	Loss: -6.0531	Cost: 6.10s
Train Epoch: 647 [40960/90000 (45%)]	Loss: -5.5825	Cost: 7.52s
Train Epoch: 647 [61440/90000 (68%)]	Loss: -5.4558	Cost: 5.80s
Train Epoch: 647 [81920/90000 (91%)]	Loss: -5.6981	Cost: 6.06s
Train Epoch: 647 	Average Loss: -5.2043
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.1724

Learning rate: 0.00015265107205096132
Re-generating waveforms for posterior prior.
Train Epoch: 648 [0/90000 (0%)]	Loss: 1.3648	Cost: 24.13s
Train Epoch: 648 [20480/90000 (23%)]	Loss: -5.7854	Cost: 6.12s
Train Epoch: 648 [40960/90000 (45%)]	Loss: -5.5748	Cost: 7.01s
Train Epoch: 648 [61440/90000 (68%)]	Loss: -5.8287	Cost: 5.84s
Train Epoch: 648 [81920/90000 (91%)]	Loss: -5.7900	Cost: 5.69s
Train Epoch: 648 	Average Loss: -5.1918
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.2106

Learning rate: 0.0001525174629961296
Re-generating waveforms for posterior prior.
Train Epoch: 649 [0/90000 (0%)]	Loss: 1.2402	Cost: 23.52s
Train Epoch: 649 [20480/90000 (23%)]	Loss: -6.1112	Cost: 6.18s
Train Epoch: 649 [40960/90000 (45%)]	Loss: -5.6055	Cost: 7.15s
Train Epoch: 649 [61440/90000 (68%)]	Loss: -5.9979	Cost: 5.82s
Train Epoch: 649 [81920/90000 (91%)]	Loss: -6.0468	Cost: 5.94s
Train Epoch: 649 	Average Loss: -5.3235
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.7047

Learning rate: 0.0001523837243596785
Re-generating waveforms for posterior prior.
Train Epoch: 650 [0/90000 (0%)]	Loss: 1.4521	Cost: 23.76s
Train Epoch: 650 [20480/90000 (23%)]	Loss: -5.4025	Cost: 6.12s
Train Epoch: 650 [40960/90000 (45%)]	Loss: -5.1724	Cost: 7.05s
Train Epoch: 650 [61440/90000 (68%)]	Loss: -5.5789	Cost: 5.91s
Train Epoch: 650 [81920/90000 (91%)]	Loss: -5.8229	Cost: 6.10s
Train Epoch: 650 	Average Loss: -4.9470
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.2776

Saving model as model_sample_from_all_posterior.pt_e650 & waveforms_supplementary_sample_from_all_posterior.hdf5_e650
Learning rate: 0.0001522498564715949
Re-generating waveforms for posterior prior.
Train Epoch: 651 [0/90000 (0%)]	Loss: 1.9259	Cost: 24.52s
Train Epoch: 651 [20480/90000 (23%)]	Loss: -5.9667	Cost: 6.13s
Train Epoch: 651 [40960/90000 (45%)]	Loss: -5.6670	Cost: 7.00s
Train Epoch: 651 [61440/90000 (68%)]	Loss: -6.0414	Cost: 5.92s
Train Epoch: 651 [81920/90000 (91%)]	Loss: -5.9346	Cost: 5.81s
Train Epoch: 651 	Average Loss: -5.3180
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.0202

Learning rate: 0.00015211585966218449
Re-generating waveforms for posterior prior.
Train Epoch: 652 [0/90000 (0%)]	Loss: 1.2727	Cost: 23.32s
Train Epoch: 652 [20480/90000 (23%)]	Loss: -6.1129	Cost: 6.16s
Train Epoch: 652 [40960/90000 (45%)]	Loss: -5.7793	Cost: 7.33s
Train Epoch: 652 [61440/90000 (68%)]	Loss: -5.7481	Cost: 5.85s
Train Epoch: 652 [81920/90000 (91%)]	Loss: -5.8944	Cost: 6.16s
Train Epoch: 652 	Average Loss: -5.3789
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.4371

Learning rate: 0.00015198173426207097
Re-generating waveforms for posterior prior.
Train Epoch: 653 [0/90000 (0%)]	Loss: 1.6088	Cost: 24.22s
Train Epoch: 653 [20480/90000 (23%)]	Loss: -5.6666	Cost: 6.13s
Train Epoch: 653 [40960/90000 (45%)]	Loss: -5.2451	Cost: 7.24s
Train Epoch: 653 [61440/90000 (68%)]	Loss: -5.6849	Cost: 5.89s
Train Epoch: 653 [81920/90000 (91%)]	Loss: -5.8401	Cost: 5.71s
Train Epoch: 653 	Average Loss: -5.0848
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.1718

Learning rate: 0.00015184748060219556
Re-generating waveforms for posterior prior.
Train Epoch: 654 [0/90000 (0%)]	Loss: 1.2179	Cost: 24.15s
Train Epoch: 654 [20480/90000 (23%)]	Loss: -6.0649	Cost: 6.13s
Train Epoch: 654 [40960/90000 (45%)]	Loss: -5.7744	Cost: 7.39s
Train Epoch: 654 [61440/90000 (68%)]	Loss: -6.0574	Cost: 6.27s
Train Epoch: 654 [81920/90000 (91%)]	Loss: -6.0481	Cost: 5.95s
Train Epoch: 654 	Average Loss: -5.4503
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.1708

Learning rate: 0.00015171309901381574
Re-generating waveforms for posterior prior.
Train Epoch: 655 [0/90000 (0%)]	Loss: 1.4431	Cost: 23.63s
Train Epoch: 655 [20480/90000 (23%)]	Loss: -6.1729	Cost: 6.14s
Train Epoch: 655 [40960/90000 (45%)]	Loss: -5.8724	Cost: 6.95s
Train Epoch: 655 [61440/90000 (68%)]	Loss: -5.9954	Cost: 5.84s
Train Epoch: 655 [81920/90000 (91%)]	Loss: -5.9986	Cost: 6.08s
Train Epoch: 655 	Average Loss: -5.5253
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.1692

Learning rate: 0.00015157858982850475
Re-generating waveforms for posterior prior.
Train Epoch: 656 [0/90000 (0%)]	Loss: 1.5433	Cost: 24.15s
Train Epoch: 656 [20480/90000 (23%)]	Loss: -5.6668	Cost: 6.10s
Train Epoch: 656 [40960/90000 (45%)]	Loss: -5.4116	Cost: 7.40s
Train Epoch: 656 [61440/90000 (68%)]	Loss: -5.9173	Cost: 5.76s
Train Epoch: 656 [81920/90000 (91%)]	Loss: -5.5274	Cost: 6.03s
Train Epoch: 656 	Average Loss: -5.1819
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.5911

Learning rate: 0.00015144395337815067
Re-generating waveforms for posterior prior.
Train Epoch: 657 [0/90000 (0%)]	Loss: 1.9426	Cost: 23.36s
Train Epoch: 657 [20480/90000 (23%)]	Loss: -5.6325	Cost: 6.09s
Train Epoch: 657 [40960/90000 (45%)]	Loss: -5.4302	Cost: 7.57s
Train Epoch: 657 [61440/90000 (68%)]	Loss: -5.8079	Cost: 5.80s
Train Epoch: 657 [81920/90000 (91%)]	Loss: -6.1670	Cost: 5.86s
Train Epoch: 657 	Average Loss: -5.1714
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.2584

Learning rate: 0.00015130918999495548
Re-generating waveforms for posterior prior.
Train Epoch: 658 [0/90000 (0%)]	Loss: 1.2594	Cost: 23.80s
Train Epoch: 658 [20480/90000 (23%)]	Loss: -5.9618	Cost: 6.16s
Train Epoch: 658 [40960/90000 (45%)]	Loss: -5.8135	Cost: 7.45s
Train Epoch: 658 [61440/90000 (68%)]	Loss: -5.9158	Cost: 5.82s
Train Epoch: 658 [81920/90000 (91%)]	Loss: -6.1148	Cost: 5.85s
Train Epoch: 658 	Average Loss: -5.3806
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.0747

Learning rate: 0.0001511743000114345
Re-generating waveforms for posterior prior.
Train Epoch: 659 [0/90000 (0%)]	Loss: 1.3391	Cost: 23.74s
Train Epoch: 659 [20480/90000 (23%)]	Loss: -6.1396	Cost: 6.16s
Train Epoch: 659 [40960/90000 (45%)]	Loss: -5.7911	Cost: 6.60s
Train Epoch: 659 [61440/90000 (68%)]	Loss: -5.8854	Cost: 5.98s
Train Epoch: 659 [81920/90000 (91%)]	Loss: -6.0024	Cost: 5.67s
Train Epoch: 659 	Average Loss: -5.4321
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.1073

Learning rate: 0.00015103928376041529
Re-generating waveforms for posterior prior.
Train Epoch: 660 [0/90000 (0%)]	Loss: 1.3401	Cost: 32.73s
Train Epoch: 660 [20480/90000 (23%)]	Loss: -6.2774	Cost: 6.21s
Train Epoch: 660 [40960/90000 (45%)]	Loss: -5.5949	Cost: 17.82s
Train Epoch: 660 [61440/90000 (68%)]	Loss: -6.0874	Cost: 5.77s
Train Epoch: 660 [81920/90000 (91%)]	Loss: -6.2150	Cost: 5.72s
Train Epoch: 660 	Average Loss: -5.5520
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.0634

Learning rate: 0.0001509041415750371
Re-generating waveforms for posterior prior.
Train Epoch: 661 [0/90000 (0%)]	Loss: 1.0851	Cost: 23.45s
Train Epoch: 661 [20480/90000 (23%)]	Loss: -6.3254	Cost: 6.20s
Train Epoch: 661 [40960/90000 (45%)]	Loss: -5.9069	Cost: 7.48s
Train Epoch: 661 [61440/90000 (68%)]	Loss: -6.0276	Cost: 5.80s
Train Epoch: 661 [81920/90000 (91%)]	Loss: -6.0792	Cost: 5.78s
Train Epoch: 661 	Average Loss: -5.5584
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.0872

Learning rate: 0.00015076887378874981
Re-generating waveforms for posterior prior.
Train Epoch: 662 [0/90000 (0%)]	Loss: 1.3013	Cost: 24.16s
Train Epoch: 662 [20480/90000 (23%)]	Loss: -6.4447	Cost: 6.09s
Train Epoch: 662 [40960/90000 (45%)]	Loss: -5.9283	Cost: 7.19s
Train Epoch: 662 [61440/90000 (68%)]	Loss: -6.2484	Cost: 6.06s
Train Epoch: 662 [81920/90000 (91%)]	Loss: -6.4396	Cost: 6.05s
Train Epoch: 662 	Average Loss: -5.6647
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.9418

Learning rate: 0.00015063348073531324
Re-generating waveforms for posterior prior.
Train Epoch: 663 [0/90000 (0%)]	Loss: 1.1215	Cost: 23.95s
Train Epoch: 663 [20480/90000 (23%)]	Loss: -6.2654	Cost: 6.11s
Train Epoch: 663 [40960/90000 (45%)]	Loss: -5.7209	Cost: 7.28s
Train Epoch: 663 [61440/90000 (68%)]	Loss: -5.6049	Cost: 5.82s
Train Epoch: 663 [81920/90000 (91%)]	Loss: -5.4598	Cost: 6.17s
Train Epoch: 663 	Average Loss: -5.3649
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.5473

Learning rate: 0.00015049796274879627
Re-generating waveforms for posterior prior.
Train Epoch: 664 [0/90000 (0%)]	Loss: 1.4234	Cost: 24.91s
Train Epoch: 664 [20480/90000 (23%)]	Loss: -5.7106	Cost: 6.11s
Train Epoch: 664 [40960/90000 (45%)]	Loss: -5.4828	Cost: 7.11s
Train Epoch: 664 [61440/90000 (68%)]	Loss: -5.8673	Cost: 5.82s
Train Epoch: 664 [81920/90000 (91%)]	Loss: -6.1719	Cost: 5.79s
Train Epoch: 664 	Average Loss: -5.2490
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.2386

Learning rate: 0.00015036232016357604
Re-generating waveforms for posterior prior.
Train Epoch: 665 [0/90000 (0%)]	Loss: 1.4322	Cost: 24.18s
Train Epoch: 665 [20480/90000 (23%)]	Loss: -6.2039	Cost: 6.11s
Train Epoch: 665 [40960/90000 (45%)]	Loss: -5.7328	Cost: 7.44s
Train Epoch: 665 [61440/90000 (68%)]	Loss: -6.1304	Cost: 5.80s
Train Epoch: 665 [81920/90000 (91%)]	Loss: -6.2565	Cost: 6.02s
Train Epoch: 665 	Average Loss: -5.4665
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.0911

Learning rate: 0.00015022655331433724
Re-generating waveforms for posterior prior.
Train Epoch: 666 [0/90000 (0%)]	Loss: 1.1917	Cost: 25.09s
Train Epoch: 666 [20480/90000 (23%)]	Loss: -5.9089	Cost: 6.16s
Train Epoch: 666 [40960/90000 (45%)]	Loss: -5.6889	Cost: 7.27s
Train Epoch: 666 [61440/90000 (68%)]	Loss: -6.1763	Cost: 5.86s
Train Epoch: 666 [81920/90000 (91%)]	Loss: -6.2305	Cost: 5.65s
Train Epoch: 666 	Average Loss: -5.4678
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.0006

Learning rate: 0.000150090662536071
Re-generating waveforms for posterior prior.
Train Epoch: 667 [0/90000 (0%)]	Loss: 0.7783	Cost: 24.85s
Train Epoch: 667 [20480/90000 (23%)]	Loss: -6.4431	Cost: 6.09s
Train Epoch: 667 [40960/90000 (45%)]	Loss: -5.9269	Cost: 7.24s
Train Epoch: 667 [61440/90000 (68%)]	Loss: -6.3629	Cost: 5.83s
Train Epoch: 667 [81920/90000 (91%)]	Loss: -6.2850	Cost: 5.94s
Train Epoch: 667 	Average Loss: -5.7210
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.8396

Learning rate: 0.0001499546481640743
Re-generating waveforms for posterior prior.
Train Epoch: 668 [0/90000 (0%)]	Loss: 0.7783	Cost: 23.62s
Train Epoch: 668 [20480/90000 (23%)]	Loss: -6.4251	Cost: 6.12s
Train Epoch: 668 [40960/90000 (45%)]	Loss: -5.8852	Cost: 7.35s
Train Epoch: 668 [61440/90000 (68%)]	Loss: -6.1356	Cost: 5.79s
Train Epoch: 668 [81920/90000 (91%)]	Loss: -6.1168	Cost: 6.10s
Train Epoch: 668 	Average Loss: -5.6506
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.8104

Learning rate: 0.0001498185105339491
Re-generating waveforms for posterior prior.
Train Epoch: 669 [0/90000 (0%)]	Loss: 1.5999	Cost: 24.08s
Train Epoch: 669 [20480/90000 (23%)]	Loss: -5.0887	Cost: 6.10s
Train Epoch: 669 [40960/90000 (45%)]	Loss: -4.9572	Cost: 7.51s
Train Epoch: 669 [61440/90000 (68%)]	Loss: -5.6818	Cost: 5.78s
Train Epoch: 669 [81920/90000 (91%)]	Loss: -5.7528	Cost: 5.99s
Train Epoch: 669 	Average Loss: -4.7804
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.3988

Learning rate: 0.00014968224998160147
Re-generating waveforms for posterior prior.
Train Epoch: 670 [0/90000 (0%)]	Loss: 1.2591	Cost: 23.66s
Train Epoch: 670 [20480/90000 (23%)]	Loss: -5.7515	Cost: 6.11s
Train Epoch: 670 [40960/90000 (45%)]	Loss: -5.6424	Cost: 7.49s
Train Epoch: 670 [61440/90000 (68%)]	Loss: -6.2670	Cost: 5.81s
Train Epoch: 670 [81920/90000 (91%)]	Loss: -6.4410	Cost: 6.12s
Train Epoch: 670 	Average Loss: -5.4601
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.9774

Learning rate: 0.00014954586684324078
Re-generating waveforms for posterior prior.
Train Epoch: 671 [0/90000 (0%)]	Loss: 0.9653	Cost: 23.78s
Train Epoch: 671 [20480/90000 (23%)]	Loss: -6.4413	Cost: 6.15s
Train Epoch: 671 [40960/90000 (45%)]	Loss: -5.7131	Cost: 7.41s
Train Epoch: 671 [61440/90000 (68%)]	Loss: -5.8948	Cost: 5.82s
Train Epoch: 671 [81920/90000 (91%)]	Loss: -6.1768	Cost: 6.05s
Train Epoch: 671 	Average Loss: -5.5938
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.9909

Learning rate: 0.00014940936145537887
Re-generating waveforms for posterior prior.
Train Epoch: 672 [0/90000 (0%)]	Loss: 1.4225	Cost: 24.15s
Train Epoch: 672 [20480/90000 (23%)]	Loss: -6.0305	Cost: 6.17s
Train Epoch: 672 [40960/90000 (45%)]	Loss: -5.7472	Cost: 7.43s
Train Epoch: 672 [61440/90000 (68%)]	Loss: -6.1016	Cost: 5.81s
Train Epoch: 672 [81920/90000 (91%)]	Loss: -6.3532	Cost: 5.81s
Train Epoch: 672 	Average Loss: -5.4818
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.9910

Learning rate: 0.00014927273415482918
Re-generating waveforms for posterior prior.
Train Epoch: 673 [0/90000 (0%)]	Loss: 0.5177	Cost: 23.52s
Train Epoch: 673 [20480/90000 (23%)]	Loss: -6.4558	Cost: 6.12s
Train Epoch: 673 [40960/90000 (45%)]	Loss: -5.8520	Cost: 7.41s
Train Epoch: 673 [61440/90000 (68%)]	Loss: -6.1788	Cost: 5.81s
Train Epoch: 673 [81920/90000 (91%)]	Loss: -6.4979	Cost: 5.81s
Train Epoch: 673 	Average Loss: -5.7675
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.7012

Learning rate: 0.00014913598527870604
Re-generating waveforms for posterior prior.
Train Epoch: 674 [0/90000 (0%)]	Loss: 0.5885	Cost: 23.86s
Train Epoch: 674 [20480/90000 (23%)]	Loss: -6.7158	Cost: 6.14s
Train Epoch: 674 [40960/90000 (45%)]	Loss: -6.1219	Cost: 7.26s
Train Epoch: 674 [61440/90000 (68%)]	Loss: -6.3370	Cost: 5.79s
Train Epoch: 674 [81920/90000 (91%)]	Loss: -6.6843	Cost: 6.02s
Train Epoch: 674 	Average Loss: -5.9496
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.6844

Learning rate: 0.0001489991151644237
Re-generating waveforms for posterior prior.
Train Epoch: 675 [0/90000 (0%)]	Loss: 0.3476	Cost: 24.18s
Train Epoch: 675 [20480/90000 (23%)]	Loss: -6.7696	Cost: 6.11s
Train Epoch: 675 [40960/90000 (45%)]	Loss: -6.1400	Cost: 7.44s
Train Epoch: 675 [61440/90000 (68%)]	Loss: -6.5389	Cost: 5.80s
Train Epoch: 675 [81920/90000 (91%)]	Loss: -6.0218	Cost: 5.91s
Train Epoch: 675 	Average Loss: -5.8304
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.3647

Learning rate: 0.00014886212414969553
Re-generating waveforms for posterior prior.
Train Epoch: 676 [0/90000 (0%)]	Loss: 2.1572	Cost: 23.83s
Train Epoch: 676 [20480/90000 (23%)]	Loss: -6.2117	Cost: 6.12s
Train Epoch: 676 [40960/90000 (45%)]	Loss: -6.1016	Cost: 7.47s
Train Epoch: 676 [61440/90000 (68%)]	Loss: -6.4571	Cost: 5.78s
Train Epoch: 676 [81920/90000 (91%)]	Loss: -6.5623	Cost: 5.99s
Train Epoch: 676 	Average Loss: -5.6541
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.8826

Learning rate: 0.00014872501257253326
Re-generating waveforms for posterior prior.
Train Epoch: 677 [0/90000 (0%)]	Loss: 1.0233	Cost: 25.68s
Train Epoch: 677 [20480/90000 (23%)]	Loss: -6.3423	Cost: 6.05s
Train Epoch: 677 [40960/90000 (45%)]	Loss: -6.0313	Cost: 7.12s
Train Epoch: 677 [61440/90000 (68%)]	Loss: -6.0898	Cost: 5.84s
Train Epoch: 677 [81920/90000 (91%)]	Loss: -6.3629	Cost: 5.88s
Train Epoch: 677 	Average Loss: -5.7115
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.8227

Learning rate: 0.0001485877807712461
Re-generating waveforms for posterior prior.
Train Epoch: 678 [0/90000 (0%)]	Loss: 0.6916	Cost: 24.36s
Train Epoch: 678 [20480/90000 (23%)]	Loss: -6.5481	Cost: 6.19s
Train Epoch: 678 [40960/90000 (45%)]	Loss: -6.1219	Cost: 7.35s
Train Epoch: 678 [61440/90000 (68%)]	Loss: -6.4364	Cost: 5.83s
Train Epoch: 678 [81920/90000 (91%)]	Loss: -6.7031	Cost: 5.65s
Train Epoch: 678 	Average Loss: -5.8791
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.8643

Learning rate: 0.00014845042908443986
Re-generating waveforms for posterior prior.
Train Epoch: 679 [0/90000 (0%)]	Loss: 0.5228	Cost: 24.00s
Train Epoch: 679 [20480/90000 (23%)]	Loss: -6.3823	Cost: 6.23s
Train Epoch: 679 [40960/90000 (45%)]	Loss: -6.2130	Cost: 7.40s
Train Epoch: 679 [61440/90000 (68%)]	Loss: -6.4698	Cost: 5.83s
Train Epoch: 679 [81920/90000 (91%)]	Loss: -6.7288	Cost: 5.91s
Train Epoch: 679 	Average Loss: -6.0006
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.7413

Learning rate: 0.0001483129578510161
Re-generating waveforms for posterior prior.
Train Epoch: 680 [0/90000 (0%)]	Loss: 0.7623	Cost: 24.08s
Train Epoch: 680 [20480/90000 (23%)]	Loss: -6.7916	Cost: 6.23s
Train Epoch: 680 [40960/90000 (45%)]	Loss: -6.3003	Cost: 7.41s
Train Epoch: 680 [61440/90000 (68%)]	Loss: -6.4331	Cost: 5.80s
Train Epoch: 680 [81920/90000 (91%)]	Loss: -6.4640	Cost: 6.06s
Train Epoch: 680 	Average Loss: -6.0552
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.7969

Learning rate: 0.00014817536741017155
Re-generating waveforms for posterior prior.
Train Epoch: 681 [0/90000 (0%)]	Loss: 1.0431	Cost: 24.42s
Train Epoch: 681 [20480/90000 (23%)]	Loss: -6.8177	Cost: 6.10s
Train Epoch: 681 [40960/90000 (45%)]	Loss: -6.2832	Cost: 7.43s
Train Epoch: 681 [61440/90000 (68%)]	Loss: -6.6442	Cost: 5.78s
Train Epoch: 681 [81920/90000 (91%)]	Loss: -6.7058	Cost: 6.10s
Train Epoch: 681 	Average Loss: -6.0644
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.5319

Learning rate: 0.0001480376581013969
Re-generating waveforms for posterior prior.
Train Epoch: 682 [0/90000 (0%)]	Loss: 0.8319	Cost: 24.18s
Train Epoch: 682 [20480/90000 (23%)]	Loss: -6.8886	Cost: 6.16s
Train Epoch: 682 [40960/90000 (45%)]	Loss: -6.4029	Cost: 7.36s
Train Epoch: 682 [61440/90000 (68%)]	Loss: -6.5295	Cost: 5.82s
Train Epoch: 682 [81920/90000 (91%)]	Loss: -6.8824	Cost: 5.74s
Train Epoch: 682 	Average Loss: -6.1756
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.5766

Learning rate: 0.00014789983026447615
Re-generating waveforms for posterior prior.
Train Epoch: 683 [0/90000 (0%)]	Loss: 0.9080	Cost: 25.21s
Train Epoch: 683 [20480/90000 (23%)]	Loss: -6.9097	Cost: 6.05s
Train Epoch: 683 [40960/90000 (45%)]	Loss: -6.5398	Cost: 7.12s
Train Epoch: 683 [61440/90000 (68%)]	Loss: -6.7858	Cost: 5.82s
Train Epoch: 683 [81920/90000 (91%)]	Loss: -6.8069	Cost: 6.10s
Train Epoch: 683 	Average Loss: -6.1840
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.6921

Learning rate: 0.0001477618842394858
Re-generating waveforms for posterior prior.
Train Epoch: 684 [0/90000 (0%)]	Loss: -0.1607	Cost: 24.43s
Train Epoch: 684 [20480/90000 (23%)]	Loss: -6.9401	Cost: 6.15s
Train Epoch: 684 [40960/90000 (45%)]	Loss: -6.3945	Cost: 6.89s
Train Epoch: 684 [61440/90000 (68%)]	Loss: -6.8531	Cost: 6.01s
Train Epoch: 684 [81920/90000 (91%)]	Loss: -6.9339	Cost: 5.87s
Train Epoch: 684 	Average Loss: -6.2606
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.4678

Learning rate: 0.00014762382036679397
Re-generating waveforms for posterior prior.
Train Epoch: 685 [0/90000 (0%)]	Loss: 0.2137	Cost: 23.69s
Train Epoch: 685 [20480/90000 (23%)]	Loss: -7.1070	Cost: 6.13s
Train Epoch: 685 [40960/90000 (45%)]	Loss: -6.4402	Cost: 7.51s
Train Epoch: 685 [61440/90000 (68%)]	Loss: -6.8149	Cost: 5.79s
Train Epoch: 685 [81920/90000 (91%)]	Loss: -7.0281	Cost: 5.78s
Train Epoch: 685 	Average Loss: -6.2861
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.5033

Learning rate: 0.00014748563898705951
Re-generating waveforms for posterior prior.
Train Epoch: 686 [0/90000 (0%)]	Loss: 0.4373	Cost: 23.75s
Train Epoch: 686 [20480/90000 (23%)]	Loss: -6.9756	Cost: 6.13s
Train Epoch: 686 [40960/90000 (45%)]	Loss: -6.6146	Cost: 7.52s
Train Epoch: 686 [61440/90000 (68%)]	Loss: -6.7099	Cost: 5.78s
Train Epoch: 686 [81920/90000 (91%)]	Loss: -7.0107	Cost: 5.80s
Train Epoch: 686 	Average Loss: -6.2666
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.6116

Learning rate: 0.00014734734044123126
Re-generating waveforms for posterior prior.
Train Epoch: 687 [0/90000 (0%)]	Loss: -0.0220	Cost: 23.36s
Train Epoch: 687 [20480/90000 (23%)]	Loss: -6.9432	Cost: 6.06s
Train Epoch: 687 [40960/90000 (45%)]	Loss: -6.5857	Cost: 6.71s
Train Epoch: 687 [61440/90000 (68%)]	Loss: -6.8850	Cost: 5.81s
Train Epoch: 687 [81920/90000 (91%)]	Loss: -7.1057	Cost: 6.25s
Train Epoch: 687 	Average Loss: -6.3140
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.4042

Learning rate: 0.00014720892507054715
Re-generating waveforms for posterior prior.
Train Epoch: 688 [0/90000 (0%)]	Loss: 0.4303	Cost: 24.48s
Train Epoch: 688 [20480/90000 (23%)]	Loss: -6.9344	Cost: 6.14s
Train Epoch: 688 [40960/90000 (45%)]	Loss: -6.6218	Cost: 7.39s
Train Epoch: 688 [61440/90000 (68%)]	Loss: -6.5971	Cost: 6.25s
Train Epoch: 688 [81920/90000 (91%)]	Loss: -6.9767	Cost: 5.73s
Train Epoch: 688 	Average Loss: -6.2977
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.6715

Learning rate: 0.0001470703932165333
Re-generating waveforms for posterior prior.
Train Epoch: 689 [0/90000 (0%)]	Loss: 0.6970	Cost: 24.67s
Train Epoch: 689 [20480/90000 (23%)]	Loss: -7.0712	Cost: 6.25s
Train Epoch: 689 [40960/90000 (45%)]	Loss: -6.5799	Cost: 6.94s
Train Epoch: 689 [61440/90000 (68%)]	Loss: -6.8251	Cost: 5.85s
Train Epoch: 689 [81920/90000 (91%)]	Loss: -7.0024	Cost: 5.66s
Train Epoch: 689 	Average Loss: -6.2725
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.5025

Learning rate: 0.00014693174522100333
Re-generating waveforms for posterior prior.
Train Epoch: 690 [0/90000 (0%)]	Loss: 0.7505	Cost: 24.09s
Train Epoch: 690 [20480/90000 (23%)]	Loss: -7.1340	Cost: 6.10s
Train Epoch: 690 [40960/90000 (45%)]	Loss: -6.5610	Cost: 6.48s
Train Epoch: 690 [61440/90000 (68%)]	Loss: -6.7456	Cost: 5.87s
Train Epoch: 690 [81920/90000 (91%)]	Loss: -6.9612	Cost: 5.73s
Train Epoch: 690 	Average Loss: -6.2876
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.4327

Learning rate: 0.0001467929814260574
Re-generating waveforms for posterior prior.
Train Epoch: 691 [0/90000 (0%)]	Loss: 0.3440	Cost: 25.45s
Train Epoch: 691 [20480/90000 (23%)]	Loss: -7.0290	Cost: 6.01s
Train Epoch: 691 [40960/90000 (45%)]	Loss: -6.5071	Cost: 7.33s
Train Epoch: 691 [61440/90000 (68%)]	Loss: -6.6309	Cost: 5.79s
Train Epoch: 691 [81920/90000 (91%)]	Loss: -7.0001	Cost: 5.72s
Train Epoch: 691 	Average Loss: -6.2212
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.4811

Learning rate: 0.00014665410217408134
Re-generating waveforms for posterior prior.
Train Epoch: 692 [0/90000 (0%)]	Loss: 0.3917	Cost: 23.61s
Train Epoch: 692 [20480/90000 (23%)]	Loss: -6.8151	Cost: 6.14s
Train Epoch: 692 [40960/90000 (45%)]	Loss: -6.3738	Cost: 7.25s
Train Epoch: 692 [61440/90000 (68%)]	Loss: -6.6825	Cost: 5.82s
Train Epoch: 692 [81920/90000 (91%)]	Loss: -6.8644	Cost: 5.93s
Train Epoch: 692 	Average Loss: -6.1750
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.5717

Learning rate: 0.0001465151078077459
Re-generating waveforms for posterior prior.
Train Epoch: 693 [0/90000 (0%)]	Loss: 0.9515	Cost: 23.83s
Train Epoch: 693 [20480/90000 (23%)]	Loss: -6.8788	Cost: 6.11s
Train Epoch: 693 [40960/90000 (45%)]	Loss: -6.6227	Cost: 7.03s
Train Epoch: 693 [61440/90000 (68%)]	Loss: -6.7925	Cost: 5.88s
Train Epoch: 693 [81920/90000 (91%)]	Loss: -6.6776	Cost: 5.83s
Train Epoch: 693 	Average Loss: -6.2140
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.5274

Learning rate: 0.00014637599867000587
Re-generating waveforms for posterior prior.
Train Epoch: 694 [0/90000 (0%)]	Loss: 0.5011	Cost: 24.37s
Train Epoch: 694 [20480/90000 (23%)]	Loss: -6.5165	Cost: 6.14s
Train Epoch: 694 [40960/90000 (45%)]	Loss: -6.3056	Cost: 7.30s
Train Epoch: 694 [61440/90000 (68%)]	Loss: -6.6574	Cost: 5.81s
Train Epoch: 694 [81920/90000 (91%)]	Loss: -6.9063	Cost: 6.00s
Train Epoch: 694 	Average Loss: -6.0755
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.4033

Learning rate: 0.00014623677510409918
Re-generating waveforms for posterior prior.
Train Epoch: 695 [0/90000 (0%)]	Loss: 0.5603	Cost: 24.80s
Train Epoch: 695 [20480/90000 (23%)]	Loss: -7.2096	Cost: 6.06s
Train Epoch: 695 [40960/90000 (45%)]	Loss: -6.6363	Cost: 6.96s
Train Epoch: 695 [61440/90000 (68%)]	Loss: -6.8492	Cost: 6.09s
Train Epoch: 695 [81920/90000 (91%)]	Loss: -7.2374	Cost: 5.90s
Train Epoch: 695 	Average Loss: -6.4236
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.4272

Learning rate: 0.00014609743745354627
Re-generating waveforms for posterior prior.
Train Epoch: 696 [0/90000 (0%)]	Loss: 0.6053	Cost: 23.83s
Train Epoch: 696 [20480/90000 (23%)]	Loss: -6.9107	Cost: 6.10s
Train Epoch: 696 [40960/90000 (45%)]	Loss: -6.3633	Cost: 7.47s
Train Epoch: 696 [61440/90000 (68%)]	Loss: -6.6823	Cost: 5.81s
Train Epoch: 696 [81920/90000 (91%)]	Loss: -7.1125	Cost: 6.09s
Train Epoch: 696 	Average Loss: -6.2615
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.4678

Learning rate: 0.00014595798606214884
Re-generating waveforms for posterior prior.
Train Epoch: 697 [0/90000 (0%)]	Loss: 0.5743	Cost: 24.38s
Train Epoch: 697 [20480/90000 (23%)]	Loss: -7.1131	Cost: 6.12s
Train Epoch: 697 [40960/90000 (45%)]	Loss: -6.6490	Cost: 7.37s
Train Epoch: 697 [61440/90000 (68%)]	Loss: -6.9913	Cost: 5.79s
Train Epoch: 697 [81920/90000 (91%)]	Loss: -6.8027	Cost: 6.02s
Train Epoch: 697 	Average Loss: -6.3403
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.6359

Learning rate: 0.0001458184212739893
Re-generating waveforms for posterior prior.
Train Epoch: 698 [0/90000 (0%)]	Loss: 0.6019	Cost: 25.16s
Train Epoch: 698 [20480/90000 (23%)]	Loss: -6.5977	Cost: 6.07s
Train Epoch: 698 [40960/90000 (45%)]	Loss: -6.5887	Cost: 7.53s
Train Epoch: 698 [61440/90000 (68%)]	Loss: -6.8398	Cost: 5.80s
Train Epoch: 698 [81920/90000 (91%)]	Loss: -6.9430	Cost: 5.98s
Train Epoch: 698 	Average Loss: -6.1350
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.4001

Learning rate: 0.00014567874343343
Re-generating waveforms for posterior prior.
Train Epoch: 699 [0/90000 (0%)]	Loss: 0.7071	Cost: 24.09s
Train Epoch: 699 [20480/90000 (23%)]	Loss: -7.0115	Cost: 6.13s
Train Epoch: 699 [40960/90000 (45%)]	Loss: -6.8129	Cost: 7.10s
Train Epoch: 699 [61440/90000 (68%)]	Loss: -7.0983	Cost: 5.81s
Train Epoch: 699 [81920/90000 (91%)]	Loss: -7.2026	Cost: 5.99s
Train Epoch: 699 	Average Loss: -6.4457
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.2767

Learning rate: 0.00014553895288511206
Re-generating waveforms for posterior prior.
Train Epoch: 700 [0/90000 (0%)]	Loss: 0.1518	Cost: 24.22s
Train Epoch: 700 [20480/90000 (23%)]	Loss: -7.3107	Cost: 6.25s
Train Epoch: 700 [40960/90000 (45%)]	Loss: -6.7656	Cost: 7.01s
Train Epoch: 700 [61440/90000 (68%)]	Loss: -7.0541	Cost: 5.87s
Train Epoch: 700 [81920/90000 (91%)]	Loss: -7.2963	Cost: 6.06s
Train Epoch: 700 	Average Loss: -6.5996
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.3680

Saving model as model_sample_from_all_posterior.pt_e700 & waveforms_supplementary_sample_from_all_posterior.hdf5_e700
Learning rate: 0.0001453990499739547
Re-generating waveforms for posterior prior.
Train Epoch: 701 [0/90000 (0%)]	Loss: 0.2279	Cost: 24.82s
Train Epoch: 701 [20480/90000 (23%)]	Loss: -6.7461	Cost: 6.19s
Train Epoch: 701 [40960/90000 (45%)]	Loss: -6.6210	Cost: 7.10s
Train Epoch: 701 [61440/90000 (68%)]	Loss: -6.7562	Cost: 5.87s
Train Epoch: 701 [81920/90000 (91%)]	Loss: -6.9995	Cost: 5.92s
Train Epoch: 701 	Average Loss: -6.2508
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.3615

Learning rate: 0.0001452590350451546
Re-generating waveforms for posterior prior.
Train Epoch: 702 [0/90000 (0%)]	Loss: 0.3820	Cost: 23.95s
Train Epoch: 702 [20480/90000 (23%)]	Loss: -6.2550	Cost: 6.13s
Train Epoch: 702 [40960/90000 (45%)]	Loss: -6.0851	Cost: 7.52s
Train Epoch: 702 [61440/90000 (68%)]	Loss: -6.5931	Cost: 5.83s
Train Epoch: 702 [81920/90000 (91%)]	Loss: -6.9894	Cost: 5.98s
Train Epoch: 702 	Average Loss: -5.9572
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.5616

Learning rate: 0.00014511890844418458
Re-generating waveforms for posterior prior.
Train Epoch: 703 [0/90000 (0%)]	Loss: -0.0760	Cost: 23.91s
Train Epoch: 703 [20480/90000 (23%)]	Loss: -7.0221	Cost: 6.16s
Train Epoch: 703 [40960/90000 (45%)]	Loss: -6.8092	Cost: 7.43s
Train Epoch: 703 [61440/90000 (68%)]	Loss: -7.0003	Cost: 5.82s
Train Epoch: 703 [81920/90000 (91%)]	Loss: -6.9521	Cost: 5.81s
Train Epoch: 703 	Average Loss: -6.4325
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.4727

Learning rate: 0.00014497867051679308
Re-generating waveforms for posterior prior.
Train Epoch: 704 [0/90000 (0%)]	Loss: -0.0834	Cost: 24.47s
Train Epoch: 704 [20480/90000 (23%)]	Loss: -7.2859	Cost: 6.13s
Train Epoch: 704 [40960/90000 (45%)]	Loss: -6.8171	Cost: 6.57s
Train Epoch: 704 [61440/90000 (68%)]	Loss: -7.1006	Cost: 5.90s
Train Epoch: 704 [81920/90000 (91%)]	Loss: -7.3044	Cost: 5.92s
Train Epoch: 704 	Average Loss: -6.6339
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.1315

Learning rate: 0.0001448383216090033
Re-generating waveforms for posterior prior.
Train Epoch: 705 [0/90000 (0%)]	Loss: 0.1852	Cost: 25.32s
Train Epoch: 705 [20480/90000 (23%)]	Loss: -7.3521	Cost: 6.19s
Train Epoch: 705 [40960/90000 (45%)]	Loss: -6.9597	Cost: 6.84s
Train Epoch: 705 [61440/90000 (68%)]	Loss: -7.0454	Cost: 5.86s
Train Epoch: 705 [81920/90000 (91%)]	Loss: -7.2723	Cost: 6.02s
Train Epoch: 705 	Average Loss: -6.6309
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.3909

Learning rate: 0.00014469786206711217
Re-generating waveforms for posterior prior.
Train Epoch: 706 [0/90000 (0%)]	Loss: 0.2831	Cost: 25.42s
Train Epoch: 706 [20480/90000 (23%)]	Loss: -7.4355	Cost: 6.07s
Train Epoch: 706 [40960/90000 (45%)]	Loss: -6.9046	Cost: 6.97s
Train Epoch: 706 [61440/90000 (68%)]	Loss: -7.1320	Cost: 5.80s
Train Epoch: 706 [81920/90000 (91%)]	Loss: -6.6862	Cost: 5.99s
Train Epoch: 706 	Average Loss: -6.5235
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.0086

Learning rate: 0.00014455729223768966
Re-generating waveforms for posterior prior.
Train Epoch: 707 [0/90000 (0%)]	Loss: 0.9654	Cost: 24.03s
Train Epoch: 707 [20480/90000 (23%)]	Loss: -6.6855	Cost: 6.12s
Train Epoch: 707 [40960/90000 (45%)]	Loss: -6.3372	Cost: 7.39s
Train Epoch: 707 [61440/90000 (68%)]	Loss: -6.9398	Cost: 5.81s
Train Epoch: 707 [81920/90000 (91%)]	Loss: -7.1931	Cost: 6.10s
Train Epoch: 707 	Average Loss: -6.2192
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.2065

Learning rate: 0.0001444166124675779
Re-generating waveforms for posterior prior.
Train Epoch: 708 [0/90000 (0%)]	Loss: 0.1277	Cost: 24.05s
Train Epoch: 708 [20480/90000 (23%)]	Loss: -7.2301	Cost: 6.11s
Train Epoch: 708 [40960/90000 (45%)]	Loss: -6.9495	Cost: 7.47s
Train Epoch: 708 [61440/90000 (68%)]	Loss: -7.1686	Cost: 5.83s
Train Epoch: 708 [81920/90000 (91%)]	Loss: -7.2518	Cost: 5.97s
Train Epoch: 708 	Average Loss: -6.6417
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.0565

Learning rate: 0.0001442758231038902
Re-generating waveforms for posterior prior.
Train Epoch: 709 [0/90000 (0%)]	Loss: 0.2877	Cost: 24.08s
Train Epoch: 709 [20480/90000 (23%)]	Loss: -7.2234	Cost: 6.18s
Train Epoch: 709 [40960/90000 (45%)]	Loss: -7.0850	Cost: 7.23s
Train Epoch: 709 [61440/90000 (68%)]	Loss: -7.2355	Cost: 5.82s
Train Epoch: 709 [81920/90000 (91%)]	Loss: -7.3355	Cost: 5.99s
Train Epoch: 709 	Average Loss: -6.5805
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.1076

Learning rate: 0.0001441349244940103
Re-generating waveforms for posterior prior.
Train Epoch: 710 [0/90000 (0%)]	Loss: 0.0666	Cost: 25.11s
Train Epoch: 710 [20480/90000 (23%)]	Loss: -7.2551	Cost: 6.10s
Train Epoch: 710 [40960/90000 (45%)]	Loss: -6.7727	Cost: 7.08s
Train Epoch: 710 [61440/90000 (68%)]	Loss: -7.0497	Cost: 5.86s
Train Epoch: 710 [81920/90000 (91%)]	Loss: -7.2465	Cost: 5.79s
Train Epoch: 710 	Average Loss: -6.5875
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.1352

Learning rate: 0.00014399391698559155
Re-generating waveforms for posterior prior.
Train Epoch: 711 [0/90000 (0%)]	Loss: -0.0455	Cost: 24.82s
Train Epoch: 711 [20480/90000 (23%)]	Loss: -7.2491	Cost: 6.14s
Train Epoch: 711 [40960/90000 (45%)]	Loss: -6.7423	Cost: 7.28s
Train Epoch: 711 [61440/90000 (68%)]	Loss: -7.1021	Cost: 5.83s
Train Epoch: 711 [81920/90000 (91%)]	Loss: -7.1787	Cost: 5.80s
Train Epoch: 711 	Average Loss: -6.5801
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.1387

Learning rate: 0.00014385280092655596
Re-generating waveforms for posterior prior.
Train Epoch: 712 [0/90000 (0%)]	Loss: 0.2324	Cost: 24.15s
Train Epoch: 712 [20480/90000 (23%)]	Loss: -7.2653	Cost: 6.12s
Train Epoch: 712 [40960/90000 (45%)]	Loss: -6.2150	Cost: 7.48s
Train Epoch: 712 [61440/90000 (68%)]	Loss: -6.5969	Cost: 5.81s
Train Epoch: 712 [81920/90000 (91%)]	Loss: -6.9133	Cost: 6.03s
Train Epoch: 712 	Average Loss: -6.2761
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.4495

Learning rate: 0.00014371157666509332
Re-generating waveforms for posterior prior.
Train Epoch: 713 [0/90000 (0%)]	Loss: 0.9584	Cost: 23.77s
Train Epoch: 713 [20480/90000 (23%)]	Loss: -7.1928	Cost: 6.15s
Train Epoch: 713 [40960/90000 (45%)]	Loss: -5.6614	Cost: 7.45s
Train Epoch: 713 [61440/90000 (68%)]	Loss: -6.1715	Cost: 5.86s
Train Epoch: 713 [81920/90000 (91%)]	Loss: -6.6226	Cost: 5.95s
Train Epoch: 713 	Average Loss: -5.8897
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.8451

Learning rate: 0.00014357024454966053
Re-generating waveforms for posterior prior.
Train Epoch: 714 [0/90000 (0%)]	Loss: 1.6503	Cost: 24.16s
Train Epoch: 714 [20480/90000 (23%)]	Loss: -6.7325	Cost: 6.12s
Train Epoch: 714 [40960/90000 (45%)]	Loss: -6.6115	Cost: 6.59s
Train Epoch: 714 [61440/90000 (68%)]	Loss: -6.9626	Cost: 5.87s
Train Epoch: 714 [81920/90000 (91%)]	Loss: -7.3125	Cost: 6.02s
Train Epoch: 714 	Average Loss: -6.2810
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.1460

Learning rate: 0.0001434288049289805
Re-generating waveforms for posterior prior.
Train Epoch: 715 [0/90000 (0%)]	Loss: 0.5800	Cost: 24.42s
Train Epoch: 715 [20480/90000 (23%)]	Loss: -7.4574	Cost: 6.10s
Train Epoch: 715 [40960/90000 (45%)]	Loss: -7.0677	Cost: 7.39s
Train Epoch: 715 [61440/90000 (68%)]	Loss: -7.3958	Cost: 5.87s
Train Epoch: 715 [81920/90000 (91%)]	Loss: -7.5577	Cost: 5.74s
Train Epoch: 715 	Average Loss: -6.7908
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.0575

Learning rate: 0.00014328725815204144
Re-generating waveforms for posterior prior.
Train Epoch: 716 [0/90000 (0%)]	Loss: 0.0055	Cost: 24.34s
Train Epoch: 716 [20480/90000 (23%)]	Loss: -7.5783	Cost: 6.12s
Train Epoch: 716 [40960/90000 (45%)]	Loss: -7.2851	Cost: 7.43s
Train Epoch: 716 [61440/90000 (68%)]	Loss: -7.2404	Cost: 5.80s
Train Epoch: 716 [81920/90000 (91%)]	Loss: -7.2497	Cost: 6.10s
Train Epoch: 716 	Average Loss: -6.8545
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.1608

Learning rate: 0.00014314560456809596
Re-generating waveforms for posterior prior.
Train Epoch: 717 [0/90000 (0%)]	Loss: 0.3698	Cost: 24.01s
Train Epoch: 717 [20480/90000 (23%)]	Loss: -7.3844	Cost: 6.10s
Train Epoch: 717 [40960/90000 (45%)]	Loss: -7.1237	Cost: 7.41s
Train Epoch: 717 [61440/90000 (68%)]	Loss: -7.2672	Cost: 5.79s
Train Epoch: 717 [81920/90000 (91%)]	Loss: -7.4209	Cost: 6.04s
Train Epoch: 717 	Average Loss: -6.6945
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.0726

Learning rate: 0.0001430038445266602
Re-generating waveforms for posterior prior.
Train Epoch: 718 [0/90000 (0%)]	Loss: -0.1097	Cost: 23.76s
Train Epoch: 718 [20480/90000 (23%)]	Loss: -7.4942	Cost: 6.17s
Train Epoch: 718 [40960/90000 (45%)]	Loss: -7.0980	Cost: 7.54s
Train Epoch: 718 [61440/90000 (68%)]	Loss: -7.4225	Cost: 5.84s
Train Epoch: 718 [81920/90000 (91%)]	Loss: -7.7012	Cost: 5.88s
Train Epoch: 718 	Average Loss: -6.8562
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.0736

Learning rate: 0.00014286197837751292
Re-generating waveforms for posterior prior.
Train Epoch: 719 [0/90000 (0%)]	Loss: 0.0888	Cost: 24.10s
Train Epoch: 719 [20480/90000 (23%)]	Loss: -7.6365	Cost: 6.12s
Train Epoch: 719 [40960/90000 (45%)]	Loss: -7.4194	Cost: 7.42s
Train Epoch: 719 [61440/90000 (68%)]	Loss: -7.3969	Cost: 5.82s
Train Epoch: 719 [81920/90000 (91%)]	Loss: -7.6808	Cost: 6.13s
Train Epoch: 719 	Average Loss: -6.9851
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.1649

Learning rate: 0.00014272000647069476
Re-generating waveforms for posterior prior.
Train Epoch: 720 [0/90000 (0%)]	Loss: 0.1681	Cost: 24.23s
Train Epoch: 720 [20480/90000 (23%)]	Loss: -7.4885	Cost: 6.13s
Train Epoch: 720 [40960/90000 (45%)]	Loss: -7.1854	Cost: 7.54s
Train Epoch: 720 [61440/90000 (68%)]	Loss: -7.4540	Cost: 5.82s
Train Epoch: 720 [81920/90000 (91%)]	Loss: -7.6423	Cost: 5.87s
Train Epoch: 720 	Average Loss: -6.9182
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.1997

Learning rate: 0.00014257792915650734
Re-generating waveforms for posterior prior.
Train Epoch: 721 [0/90000 (0%)]	Loss: 0.1712	Cost: 24.34s
Train Epoch: 721 [20480/90000 (23%)]	Loss: -7.8298	Cost: 6.12s
Train Epoch: 721 [40960/90000 (45%)]	Loss: -7.4624	Cost: 7.05s
Train Epoch: 721 [61440/90000 (68%)]	Loss: -7.5348	Cost: 5.83s
Train Epoch: 721 [81920/90000 (91%)]	Loss: -7.5808	Cost: 5.91s
Train Epoch: 721 	Average Loss: -6.9996
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.2837

Learning rate: 0.00014243574678551225
Re-generating waveforms for posterior prior.
Train Epoch: 722 [0/90000 (0%)]	Loss: 0.2303	Cost: 24.44s
Train Epoch: 722 [20480/90000 (23%)]	Loss: -7.6760	Cost: 6.11s
Train Epoch: 722 [40960/90000 (45%)]	Loss: -7.2216	Cost: 7.23s
Train Epoch: 722 [61440/90000 (68%)]	Loss: -7.5142	Cost: 5.82s
Train Epoch: 722 [81920/90000 (91%)]	Loss: -7.7177	Cost: 5.75s
Train Epoch: 722 	Average Loss: -6.9582
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.0118

Learning rate: 0.00014229345970853043
Re-generating waveforms for posterior prior.
Train Epoch: 723 [0/90000 (0%)]	Loss: 0.1661	Cost: 23.96s
Train Epoch: 723 [20480/90000 (23%)]	Loss: -7.8295	Cost: 6.13s
Train Epoch: 723 [40960/90000 (45%)]	Loss: -7.3988	Cost: 7.41s
Train Epoch: 723 [61440/90000 (68%)]	Loss: -7.6193	Cost: 5.80s
Train Epoch: 723 [81920/90000 (91%)]	Loss: -7.7403	Cost: 6.08s
Train Epoch: 723 	Average Loss: -7.0995
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.1440

Learning rate: 0.000142151068276641
Re-generating waveforms for posterior prior.
Train Epoch: 724 [0/90000 (0%)]	Loss: -0.1748	Cost: 24.20s
Train Epoch: 724 [20480/90000 (23%)]	Loss: -7.8847	Cost: 6.12s
Train Epoch: 724 [40960/90000 (45%)]	Loss: -7.3498	Cost: 7.19s
Train Epoch: 724 [61440/90000 (68%)]	Loss: -7.5798	Cost: 5.83s
Train Epoch: 724 [81920/90000 (91%)]	Loss: -7.9099	Cost: 6.01s
Train Epoch: 724 	Average Loss: -7.0566
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.1127

Learning rate: 0.00014200857284118069
Re-generating waveforms for posterior prior.
Train Epoch: 725 [0/90000 (0%)]	Loss: -0.0976	Cost: 25.26s
Train Epoch: 725 [20480/90000 (23%)]	Loss: -7.8866	Cost: 6.05s
Train Epoch: 725 [40960/90000 (45%)]	Loss: -7.4850	Cost: 7.05s
Train Epoch: 725 [61440/90000 (68%)]	Loss: -7.5032	Cost: 6.16s
Train Epoch: 725 [81920/90000 (91%)]	Loss: -7.5542	Cost: 5.78s
Train Epoch: 725 	Average Loss: -7.0783
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.0844

Learning rate: 0.0001418659737537429
Re-generating waveforms for posterior prior.
Train Epoch: 726 [0/90000 (0%)]	Loss: 0.4735	Cost: 24.08s
Train Epoch: 726 [20480/90000 (23%)]	Loss: -7.8110	Cost: 6.12s
Train Epoch: 726 [40960/90000 (45%)]	Loss: -7.1765	Cost: 6.92s
Train Epoch: 726 [61440/90000 (68%)]	Loss: -7.5517	Cost: 5.85s
Train Epoch: 726 [81920/90000 (91%)]	Loss: -7.7784	Cost: 6.05s
Train Epoch: 726 	Average Loss: -7.0441
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.1088

Learning rate: 0.0001417232713661766
Re-generating waveforms for posterior prior.
Train Epoch: 727 [0/90000 (0%)]	Loss: -0.0057	Cost: 23.79s
Train Epoch: 727 [20480/90000 (23%)]	Loss: -7.7722	Cost: 6.13s
Train Epoch: 727 [40960/90000 (45%)]	Loss: -7.3934	Cost: 7.33s
Train Epoch: 727 [61440/90000 (68%)]	Loss: -7.7654	Cost: 6.07s
Train Epoch: 727 [81920/90000 (91%)]	Loss: -7.9590	Cost: 5.75s
Train Epoch: 727 	Average Loss: -7.1224
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.0421

Learning rate: 0.00014158046603058582
Re-generating waveforms for posterior prior.
Train Epoch: 728 [0/90000 (0%)]	Loss: 0.1530	Cost: 24.02s
Train Epoch: 728 [20480/90000 (23%)]	Loss: -7.5638	Cost: 6.11s
Train Epoch: 728 [40960/90000 (45%)]	Loss: -7.2778	Cost: 7.46s
Train Epoch: 728 [61440/90000 (68%)]	Loss: -7.5872	Cost: 5.84s
Train Epoch: 728 [81920/90000 (91%)]	Loss: -7.7557	Cost: 5.94s
Train Epoch: 728 	Average Loss: -6.9408
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.0692

Learning rate: 0.0001414375580993285
Re-generating waveforms for posterior prior.
Train Epoch: 729 [0/90000 (0%)]	Loss: -0.1342	Cost: 24.57s
Train Epoch: 729 [20480/90000 (23%)]	Loss: -7.3188	Cost: 6.12s
Train Epoch: 729 [40960/90000 (45%)]	Loss: -6.9036	Cost: 7.39s
Train Epoch: 729 [61440/90000 (68%)]	Loss: -7.1666	Cost: 5.79s
Train Epoch: 729 [81920/90000 (91%)]	Loss: -7.2778	Cost: 5.97s
Train Epoch: 729 	Average Loss: -6.7978
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.0816

Learning rate: 0.00014129454792501575
Re-generating waveforms for posterior prior.
Train Epoch: 730 [0/90000 (0%)]	Loss: -0.0379	Cost: 24.08s
Train Epoch: 730 [20480/90000 (23%)]	Loss: -7.7666	Cost: 6.13s
Train Epoch: 730 [40960/90000 (45%)]	Loss: -7.4768	Cost: 7.12s
Train Epoch: 730 [61440/90000 (68%)]	Loss: -7.8369	Cost: 5.84s
Train Epoch: 730 [81920/90000 (91%)]	Loss: -7.8682	Cost: 5.99s
Train Epoch: 730 	Average Loss: -7.0651
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.2016

Learning rate: 0.00014115143586051094
Re-generating waveforms for posterior prior.
Train Epoch: 731 [0/90000 (0%)]	Loss: 0.1883	Cost: 24.45s
Train Epoch: 731 [20480/90000 (23%)]	Loss: -7.9430	Cost: 6.11s
Train Epoch: 731 [40960/90000 (45%)]	Loss: -7.5411	Cost: 7.32s
Train Epoch: 731 [61440/90000 (68%)]	Loss: -7.8764	Cost: 5.81s
Train Epoch: 731 [81920/90000 (91%)]	Loss: -7.9674	Cost: 6.13s
Train Epoch: 731 	Average Loss: -7.2392
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.1066

Learning rate: 0.0001410082222589289
Re-generating waveforms for posterior prior.
Train Epoch: 732 [0/90000 (0%)]	Loss: -0.5323	Cost: 24.19s
Train Epoch: 732 [20480/90000 (23%)]	Loss: -7.7875	Cost: 6.17s
Train Epoch: 732 [40960/90000 (45%)]	Loss: -7.2998	Cost: 7.33s
Train Epoch: 732 [61440/90000 (68%)]	Loss: -7.5660	Cost: 5.82s
Train Epoch: 732 [81920/90000 (91%)]	Loss: -7.8260	Cost: 5.98s
Train Epoch: 732 	Average Loss: -7.0864
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.4024

Learning rate: 0.00014086490747363499
Re-generating waveforms for posterior prior.
Train Epoch: 733 [0/90000 (0%)]	Loss: -0.3493	Cost: 24.93s
Train Epoch: 733 [20480/90000 (23%)]	Loss: -7.9692	Cost: 6.14s
Train Epoch: 733 [40960/90000 (45%)]	Loss: -7.2347	Cost: 7.29s
Train Epoch: 733 [61440/90000 (68%)]	Loss: -7.7289	Cost: 5.87s
Train Epoch: 733 [81920/90000 (91%)]	Loss: -7.9636	Cost: 5.66s
Train Epoch: 733 	Average Loss: -7.2838
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.1594

Learning rate: 0.00014072149185824414
Re-generating waveforms for posterior prior.
Train Epoch: 734 [0/90000 (0%)]	Loss: -0.0445	Cost: 23.90s
Train Epoch: 734 [20480/90000 (23%)]	Loss: -7.5973	Cost: 6.11s
Train Epoch: 734 [40960/90000 (45%)]	Loss: -7.1380	Cost: 7.29s
Train Epoch: 734 [61440/90000 (68%)]	Loss: -7.7060	Cost: 5.77s
Train Epoch: 734 [81920/90000 (91%)]	Loss: -8.1683	Cost: 5.95s
Train Epoch: 734 	Average Loss: -7.1034
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.1372

Learning rate: 0.00014057797576662008
Re-generating waveforms for posterior prior.
Train Epoch: 735 [0/90000 (0%)]	Loss: -0.1119	Cost: 24.03s
Train Epoch: 735 [20480/90000 (23%)]	Loss: -8.0163	Cost: 6.11s
Train Epoch: 735 [40960/90000 (45%)]	Loss: -7.5444	Cost: 7.10s
Train Epoch: 735 [61440/90000 (68%)]	Loss: -8.1186	Cost: 5.92s
Train Epoch: 735 [81920/90000 (91%)]	Loss: -8.1079	Cost: 5.87s
Train Epoch: 735 	Average Loss: -7.3689
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.3094

Learning rate: 0.0001404343595528746
Re-generating waveforms for posterior prior.
Train Epoch: 736 [0/90000 (0%)]	Loss: -0.0319	Cost: 24.05s
Train Epoch: 736 [20480/90000 (23%)]	Loss: -7.9870	Cost: 6.13s
Train Epoch: 736 [40960/90000 (45%)]	Loss: -7.4456	Cost: 7.46s
Train Epoch: 736 [61440/90000 (68%)]	Loss: -7.6230	Cost: 5.81s
Train Epoch: 736 [81920/90000 (91%)]	Loss: -7.8170	Cost: 6.05s
Train Epoch: 736 	Average Loss: -7.2085
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.0353

Learning rate: 0.00014029064357136637
Re-generating waveforms for posterior prior.
Train Epoch: 737 [0/90000 (0%)]	Loss: 0.3825	Cost: 24.75s
Train Epoch: 737 [20480/90000 (23%)]	Loss: -7.9177	Cost: 6.11s
Train Epoch: 737 [40960/90000 (45%)]	Loss: -7.5326	Cost: 6.83s
Train Epoch: 737 [61440/90000 (68%)]	Loss: -7.8108	Cost: 5.89s
Train Epoch: 737 [81920/90000 (91%)]	Loss: -8.0363	Cost: 5.99s
Train Epoch: 737 	Average Loss: -7.3036
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.3060

Learning rate: 0.00014014682817670027
Re-generating waveforms for posterior prior.
Train Epoch: 738 [0/90000 (0%)]	Loss: -0.2650	Cost: 23.87s
Train Epoch: 738 [20480/90000 (23%)]	Loss: -8.1554	Cost: 6.13s
Train Epoch: 738 [40960/90000 (45%)]	Loss: -7.6828	Cost: 7.54s
Train Epoch: 738 [61440/90000 (68%)]	Loss: -7.6815	Cost: 5.81s
Train Epoch: 738 [81920/90000 (91%)]	Loss: -8.0854	Cost: 5.72s
Train Epoch: 738 	Average Loss: -7.4129
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.1933

Learning rate: 0.00014000291372372653
Re-generating waveforms for posterior prior.
Train Epoch: 739 [0/90000 (0%)]	Loss: -0.3244	Cost: 24.39s
Train Epoch: 739 [20480/90000 (23%)]	Loss: -8.1450	Cost: 6.09s
Train Epoch: 739 [40960/90000 (45%)]	Loss: -4.1331	Cost: 7.30s
Train Epoch: 739 [61440/90000 (68%)]	Loss: -4.7049	Cost: 5.82s
Train Epoch: 739 [81920/90000 (91%)]	Loss: -5.4406	Cost: 6.19s
Train Epoch: 739 	Average Loss: -5.4934
Re-generating waveforms for posterior prior.
Test set: Average loss: 1.0602

Learning rate: 0.00013985890056753979
Re-generating waveforms for posterior prior.
Train Epoch: 740 [0/90000 (0%)]	Loss: 0.8811	Cost: 24.34s
Train Epoch: 740 [20480/90000 (23%)]	Loss: -6.5002	Cost: 6.09s
Train Epoch: 740 [40960/90000 (45%)]	Loss: -6.3097	Cost: 6.33s
Train Epoch: 740 [61440/90000 (68%)]	Loss: -6.9448	Cost: 5.93s
Train Epoch: 740 [81920/90000 (91%)]	Loss: -7.0613	Cost: 5.70s
Train Epoch: 740 	Average Loss: -6.1668
Re-generating waveforms for posterior prior.
Test set: Average loss: 0.2721

Learning rate: 0.00013971478906347812
Re-generating waveforms for posterior prior.
Train Epoch: 741 [0/90000 (0%)]	Loss: -0.1086	Cost: 24.06s
Train Epoch: 741 [20480/90000 (23%)]	Loss: -7.4493	Cost: 6.15s
Train Epoch: 741 [40960/90000 (45%)]	Loss: -7.3523	Cost: 7.31s
Train Epoch: 741 [61440/90000 (68%)]	Loss: -7.6142	Cost: 5.82s
Train Epoch: 741 [81920/90000 (91%)]	Loss: -7.8276	Cost: 5.95s
Train Epoch: 741 	Average Loss: -6.9673
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.1626

Learning rate: 0.00013957057956712237
Re-generating waveforms for posterior prior.
Train Epoch: 742 [0/90000 (0%)]	Loss: -0.2308	Cost: 23.90s
Train Epoch: 742 [20480/90000 (23%)]	Loss: -8.0798	Cost: 6.12s
Train Epoch: 742 [40960/90000 (45%)]	Loss: -7.7086	Cost: 7.34s
Train Epoch: 742 [61440/90000 (68%)]	Loss: -8.1618	Cost: 6.00s
Train Epoch: 742 [81920/90000 (91%)]	Loss: -7.9880	Cost: 5.86s
Train Epoch: 742 	Average Loss: -7.3492
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.2076

Learning rate: 0.00013942627243429512
Re-generating waveforms for posterior prior.
Train Epoch: 743 [0/90000 (0%)]	Loss: -0.3840	Cost: 23.89s
Train Epoch: 743 [20480/90000 (23%)]	Loss: -7.9089	Cost: 6.20s
Train Epoch: 743 [40960/90000 (45%)]	Loss: -7.7591	Cost: 7.43s
Train Epoch: 743 [61440/90000 (68%)]	Loss: -8.0300	Cost: 5.82s
Train Epoch: 743 [81920/90000 (91%)]	Loss: -8.2640	Cost: 6.10s
Train Epoch: 743 	Average Loss: -7.3823
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.4606

Learning rate: 0.00013928186802105995
Re-generating waveforms for posterior prior.
Train Epoch: 744 [0/90000 (0%)]	Loss: 0.1366	Cost: 24.18s
Train Epoch: 744 [20480/90000 (23%)]	Loss: -8.1926	Cost: 6.12s
Train Epoch: 744 [40960/90000 (45%)]	Loss: -7.6431	Cost: 7.43s
Train Epoch: 744 [61440/90000 (68%)]	Loss: -7.9474	Cost: 5.83s
Train Epoch: 744 [81920/90000 (91%)]	Loss: -8.2525	Cost: 5.82s
Train Epoch: 744 	Average Loss: -7.4617
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.4575

Learning rate: 0.00013913736668372029
Re-generating waveforms for posterior prior.
Train Epoch: 745 [0/90000 (0%)]	Loss: 0.0946	Cost: 24.18s
Train Epoch: 745 [20480/90000 (23%)]	Loss: -8.1365	Cost: 6.13s
Train Epoch: 745 [40960/90000 (45%)]	Loss: -7.6739	Cost: 7.20s
Train Epoch: 745 [61440/90000 (68%)]	Loss: -8.0608	Cost: 5.84s
Train Epoch: 745 [81920/90000 (91%)]	Loss: -8.0971	Cost: 5.76s
Train Epoch: 745 	Average Loss: -7.4478
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.0615

Learning rate: 0.00013899276877881887
Re-generating waveforms for posterior prior.
Train Epoch: 746 [0/90000 (0%)]	Loss: 0.0170	Cost: 24.75s
Train Epoch: 746 [20480/90000 (23%)]	Loss: -7.7629	Cost: 6.09s
Train Epoch: 746 [40960/90000 (45%)]	Loss: -7.5701	Cost: 7.58s
Train Epoch: 746 [61440/90000 (68%)]	Loss: -7.8164	Cost: 5.77s
Train Epoch: 746 [81920/90000 (91%)]	Loss: -7.7884	Cost: 5.88s
Train Epoch: 746 	Average Loss: -7.1678
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.0622

Learning rate: 0.00013884807466313666
Re-generating waveforms for posterior prior.
Train Epoch: 747 [0/90000 (0%)]	Loss: -0.3504	Cost: 24.27s
Train Epoch: 747 [20480/90000 (23%)]	Loss: -7.9475	Cost: 6.11s
Train Epoch: 747 [40960/90000 (45%)]	Loss: -7.3813	Cost: 7.26s
Train Epoch: 747 [61440/90000 (68%)]	Loss: -7.6307	Cost: 5.82s
Train Epoch: 747 [81920/90000 (91%)]	Loss: -7.9582	Cost: 6.04s
Train Epoch: 747 	Average Loss: -7.1913
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.2940

Learning rate: 0.000138703284693692
Re-generating waveforms for posterior prior.
Train Epoch: 748 [0/90000 (0%)]	Loss: -0.2020	Cost: 24.38s
Train Epoch: 748 [20480/90000 (23%)]	Loss: -8.2329	Cost: 6.10s
Train Epoch: 748 [40960/90000 (45%)]	Loss: -7.6883	Cost: 7.38s
Train Epoch: 748 [61440/90000 (68%)]	Loss: -7.9113	Cost: 5.81s
Train Epoch: 748 [81920/90000 (91%)]	Loss: -8.1363	Cost: 5.88s
Train Epoch: 748 	Average Loss: -7.4020
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.4551

Learning rate: 0.00013855839922773968
Re-generating waveforms for posterior prior.
Train Epoch: 749 [0/90000 (0%)]	Loss: -0.1746	Cost: 24.21s
Train Epoch: 749 [20480/90000 (23%)]	Loss: -8.2332	Cost: 6.11s
Train Epoch: 749 [40960/90000 (45%)]	Loss: -7.9315	Cost: 6.92s
Train Epoch: 749 [61440/90000 (68%)]	Loss: -8.1393	Cost: 5.83s
Train Epoch: 749 [81920/90000 (91%)]	Loss: -8.3093	Cost: 6.15s
Train Epoch: 749 	Average Loss: -7.5977
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.5074

Learning rate: 0.00013841341862277028
Re-generating waveforms for posterior prior.
Train Epoch: 750 [0/90000 (0%)]	Loss: -0.4279	Cost: 24.29s
Train Epoch: 750 [20480/90000 (23%)]	Loss: -8.5002	Cost: 6.11s
Train Epoch: 750 [40960/90000 (45%)]	Loss: -7.9693	Cost: 7.69s
Train Epoch: 750 [61440/90000 (68%)]	Loss: -8.3540	Cost: 6.64s
Train Epoch: 750 [81920/90000 (91%)]	Loss: -8.4546	Cost: 5.69s
Train Epoch: 750 	Average Loss: -7.6782
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.6046

Saving model as model_sample_from_all_posterior.pt_e750 & waveforms_supplementary_sample_from_all_posterior.hdf5_e750
Learning rate: 0.00013826834323650902
Re-generating waveforms for posterior prior.
Train Epoch: 751 [0/90000 (0%)]	Loss: -0.3259	Cost: 35.69s
Train Epoch: 751 [20480/90000 (23%)]	Loss: -8.4652	Cost: 6.20s
Train Epoch: 751 [40960/90000 (45%)]	Loss: -7.4989	Cost: 19.79s
Train Epoch: 751 [61440/90000 (68%)]	Loss: -8.0261	Cost: 5.70s
Train Epoch: 751 [81920/90000 (91%)]	Loss: -8.2752	Cost: 5.65s
Train Epoch: 751 	Average Loss: -7.5097
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.4774

Learning rate: 0.00013812317342691495
Re-generating waveforms for posterior prior.
Train Epoch: 752 [0/90000 (0%)]	Loss: -0.5078	Cost: 23.96s
Train Epoch: 752 [20480/90000 (23%)]	Loss: -7.8190	Cost: 6.13s
Train Epoch: 752 [40960/90000 (45%)]	Loss: -7.6892	Cost: 7.37s
Train Epoch: 752 [61440/90000 (68%)]	Loss: -8.0424	Cost: 5.84s
Train Epoch: 752 [81920/90000 (91%)]	Loss: -8.0490	Cost: 5.98s
Train Epoch: 752 	Average Loss: -7.3481
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.2390

Learning rate: 0.00013797790955218017
Re-generating waveforms for posterior prior.
Train Epoch: 753 [0/90000 (0%)]	Loss: -0.2719	Cost: 24.54s
Train Epoch: 753 [20480/90000 (23%)]	Loss: -7.9554	Cost: 6.25s
Train Epoch: 753 [40960/90000 (45%)]	Loss: -7.6605	Cost: 7.13s
Train Epoch: 753 [61440/90000 (68%)]	Loss: -7.9145	Cost: 5.85s
Train Epoch: 753 [81920/90000 (91%)]	Loss: -8.3102	Cost: 5.85s
Train Epoch: 753 	Average Loss: -7.3889
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.4053

Learning rate: 0.00013783255197072884
Re-generating waveforms for posterior prior.
Train Epoch: 754 [0/90000 (0%)]	Loss: -0.5934	Cost: 24.45s
Train Epoch: 754 [20480/90000 (23%)]	Loss: -8.0703	Cost: 6.22s
Train Epoch: 754 [40960/90000 (45%)]	Loss: -7.6827	Cost: 7.19s
Train Epoch: 754 [61440/90000 (68%)]	Loss: -8.0277	Cost: 5.86s
Train Epoch: 754 [81920/90000 (91%)]	Loss: -8.2734	Cost: 5.84s
Train Epoch: 754 	Average Loss: -7.5273
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.6738

Learning rate: 0.00013768710104121633
Re-generating waveforms for posterior prior.
Train Epoch: 755 [0/90000 (0%)]	Loss: -0.8394	Cost: 25.54s
Train Epoch: 755 [20480/90000 (23%)]	Loss: -8.5640	Cost: 6.07s
Train Epoch: 755 [40960/90000 (45%)]	Loss: -7.9261	Cost: 7.10s
Train Epoch: 755 [61440/90000 (68%)]	Loss: -8.4192	Cost: 5.80s
Train Epoch: 755 [81920/90000 (91%)]	Loss: -8.6787	Cost: 6.05s
Train Epoch: 755 	Average Loss: -7.8371
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.5832

Learning rate: 0.00013754155712252837
Re-generating waveforms for posterior prior.
Train Epoch: 756 [0/90000 (0%)]	Loss: -0.7287	Cost: 25.20s
Train Epoch: 756 [20480/90000 (23%)]	Loss: -8.4942	Cost: 6.08s
Train Epoch: 756 [40960/90000 (45%)]	Loss: -7.9992	Cost: 6.17s
Train Epoch: 756 [61440/90000 (68%)]	Loss: -8.1670	Cost: 5.88s
Train Epoch: 756 [81920/90000 (91%)]	Loss: -7.9618	Cost: 5.86s
Train Epoch: 756 	Average Loss: -7.6543
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.0520

Learning rate: 0.00013739592057378008
Re-generating waveforms for posterior prior.
Train Epoch: 757 [0/90000 (0%)]	Loss: 0.4646	Cost: 24.91s
Train Epoch: 757 [20480/90000 (23%)]	Loss: -7.3086	Cost: 6.14s
Train Epoch: 757 [40960/90000 (45%)]	Loss: -7.2397	Cost: 7.29s
Train Epoch: 757 [61440/90000 (68%)]	Loss: -7.4643	Cost: 5.84s
Train Epoch: 757 [81920/90000 (91%)]	Loss: -7.8353	Cost: 6.00s
Train Epoch: 757 	Average Loss: -6.8738
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.3179

Learning rate: 0.00013725019175431526
Re-generating waveforms for posterior prior.
Train Epoch: 758 [0/90000 (0%)]	Loss: -0.3794	Cost: 24.35s
Train Epoch: 758 [20480/90000 (23%)]	Loss: -8.1589	Cost: 6.16s
Train Epoch: 758 [40960/90000 (45%)]	Loss: -7.7867	Cost: 7.29s
Train Epoch: 758 [61440/90000 (68%)]	Loss: -8.0505	Cost: 5.89s
Train Epoch: 758 [81920/90000 (91%)]	Loss: -8.3958	Cost: 5.80s
Train Epoch: 758 	Average Loss: -7.4869
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.5355

Learning rate: 0.00013710437102370517
Re-generating waveforms for posterior prior.
Train Epoch: 759 [0/90000 (0%)]	Loss: -0.8846	Cost: 23.91s
Train Epoch: 759 [20480/90000 (23%)]	Loss: -8.5277	Cost: 6.16s
Train Epoch: 759 [40960/90000 (45%)]	Loss: -7.8285	Cost: 7.24s
Train Epoch: 759 [61440/90000 (68%)]	Loss: -8.2874	Cost: 5.84s
Train Epoch: 759 [81920/90000 (91%)]	Loss: -8.4091	Cost: 5.99s
Train Epoch: 759 	Average Loss: -7.6951
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.4288

Learning rate: 0.00013695845874174802
Re-generating waveforms for posterior prior.
Train Epoch: 760 [0/90000 (0%)]	Loss: -0.4494	Cost: 24.06s
Train Epoch: 760 [20480/90000 (23%)]	Loss: -8.1240	Cost: 6.13s
Train Epoch: 760 [40960/90000 (45%)]	Loss: -7.8268	Cost: 7.36s
Train Epoch: 760 [61440/90000 (68%)]	Loss: -8.2543	Cost: 5.89s
Train Epoch: 760 [81920/90000 (91%)]	Loss: -8.5647	Cost: 6.02s
Train Epoch: 760 	Average Loss: -7.6539
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.6350

Learning rate: 0.00013681245526846785
Re-generating waveforms for posterior prior.
Train Epoch: 761 [0/90000 (0%)]	Loss: -0.8836	Cost: 24.76s
Train Epoch: 761 [20480/90000 (23%)]	Loss: -8.3285	Cost: 6.14s
Train Epoch: 761 [40960/90000 (45%)]	Loss: -7.9441	Cost: 7.24s
Train Epoch: 761 [61440/90000 (68%)]	Loss: -8.3948	Cost: 5.87s
Train Epoch: 761 [81920/90000 (91%)]	Loss: -7.8208	Cost: 5.80s
Train Epoch: 761 	Average Loss: -7.5925
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.2661

Learning rate: 0.00013666636096411374
Re-generating waveforms for posterior prior.
Train Epoch: 762 [0/90000 (0%)]	Loss: -0.8043	Cost: 24.06s
Train Epoch: 762 [20480/90000 (23%)]	Loss: -8.2165	Cost: 6.10s
Train Epoch: 762 [40960/90000 (45%)]	Loss: -8.0017	Cost: 7.50s
Train Epoch: 762 [61440/90000 (68%)]	Loss: -8.0551	Cost: 5.83s
Train Epoch: 762 [81920/90000 (91%)]	Loss: -8.1415	Cost: 6.17s
Train Epoch: 762 	Average Loss: -7.6186
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.5589

Learning rate: 0.00013652017618915883
Re-generating waveforms for posterior prior.
Train Epoch: 763 [0/90000 (0%)]	Loss: -0.3665	Cost: 25.06s
Train Epoch: 763 [20480/90000 (23%)]	Loss: -8.6656	Cost: 6.11s
Train Epoch: 763 [40960/90000 (45%)]	Loss: -8.1879	Cost: 7.24s
Train Epoch: 763 [61440/90000 (68%)]	Loss: -8.4219	Cost: 5.84s
Train Epoch: 763 [81920/90000 (91%)]	Loss: -8.7158	Cost: 5.88s
Train Epoch: 763 	Average Loss: -7.8715
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.7093

Learning rate: 0.00013637390130429955
Re-generating waveforms for posterior prior.
Train Epoch: 764 [0/90000 (0%)]	Loss: -0.9280	Cost: 24.45s
Train Epoch: 764 [20480/90000 (23%)]	Loss: -8.5161	Cost: 6.12s
Train Epoch: 764 [40960/90000 (45%)]	Loss: -8.2567	Cost: 6.91s
Train Epoch: 764 [61440/90000 (68%)]	Loss: -8.6332	Cost: 5.94s
Train Epoch: 764 [81920/90000 (91%)]	Loss: -8.6579	Cost: 6.06s
Train Epoch: 764 	Average Loss: -7.9301
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.7168

Learning rate: 0.00013622753667045463
Re-generating waveforms for posterior prior.
Train Epoch: 765 [0/90000 (0%)]	Loss: -0.8748	Cost: 24.68s
Train Epoch: 765 [20480/90000 (23%)]	Loss: -8.6431	Cost: 6.16s
Train Epoch: 765 [40960/90000 (45%)]	Loss: -8.4201	Cost: 7.28s
Train Epoch: 765 [61440/90000 (68%)]	Loss: -8.6626	Cost: 5.80s
Train Epoch: 765 [81920/90000 (91%)]	Loss: -8.5085	Cost: 5.79s
Train Epoch: 765 	Average Loss: -7.9610
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.4850

Learning rate: 0.00013608108264876424
Re-generating waveforms for posterior prior.
Train Epoch: 766 [0/90000 (0%)]	Loss: -0.5816	Cost: 24.21s
Train Epoch: 766 [20480/90000 (23%)]	Loss: -8.4154	Cost: 6.13s
Train Epoch: 766 [40960/90000 (45%)]	Loss: -7.7166	Cost: 7.30s
Train Epoch: 766 [61440/90000 (68%)]	Loss: -8.2957	Cost: 5.82s
Train Epoch: 766 [81920/90000 (91%)]	Loss: -8.4337	Cost: 6.19s
Train Epoch: 766 	Average Loss: -7.7277
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.7323

Learning rate: 0.00013593453960058914
Re-generating waveforms for posterior prior.
Train Epoch: 767 [0/90000 (0%)]	Loss: -0.5133	Cost: 25.04s
Train Epoch: 767 [20480/90000 (23%)]	Loss: -8.3264	Cost: 6.15s
Train Epoch: 767 [40960/90000 (45%)]	Loss: -7.8731	Cost: 7.25s
Train Epoch: 767 [61440/90000 (68%)]	Loss: -8.1940	Cost: 5.83s
Train Epoch: 767 [81920/90000 (91%)]	Loss: -7.9879	Cost: 5.93s
Train Epoch: 767 	Average Loss: -7.5429
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.4149

Learning rate: 0.00013578790788750967
Re-generating waveforms for posterior prior.
Train Epoch: 768 [0/90000 (0%)]	Loss: -0.7258	Cost: 24.37s
Train Epoch: 768 [20480/90000 (23%)]	Loss: -8.3586	Cost: 6.12s
Train Epoch: 768 [40960/90000 (45%)]	Loss: -8.1223	Cost: 7.10s
Train Epoch: 768 [61440/90000 (68%)]	Loss: -8.5251	Cost: 5.84s
Train Epoch: 768 [81920/90000 (91%)]	Loss: -8.4375	Cost: 5.77s
Train Epoch: 768 	Average Loss: -7.7398
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.3451

Learning rate: 0.0001356411878713251
Re-generating waveforms for posterior prior.
Train Epoch: 769 [0/90000 (0%)]	Loss: -0.3590	Cost: 24.44s
Train Epoch: 769 [20480/90000 (23%)]	Loss: -8.5618	Cost: 6.12s
Train Epoch: 769 [40960/90000 (45%)]	Loss: -8.2430	Cost: 7.44s
Train Epoch: 769 [61440/90000 (68%)]	Loss: -8.3034	Cost: 5.84s
Train Epoch: 769 [81920/90000 (91%)]	Loss: -8.4051	Cost: 5.96s
Train Epoch: 769 	Average Loss: -7.8330
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.6192

Learning rate: 0.00013549437991405245
Re-generating waveforms for posterior prior.
Train Epoch: 770 [0/90000 (0%)]	Loss: -0.7223	Cost: 24.45s
Train Epoch: 770 [20480/90000 (23%)]	Loss: -8.2164	Cost: 6.16s
Train Epoch: 770 [40960/90000 (45%)]	Loss: -8.0186	Cost: 7.42s
Train Epoch: 770 [61440/90000 (68%)]	Loss: -8.5927	Cost: 5.85s
Train Epoch: 770 [81920/90000 (91%)]	Loss: -8.6262	Cost: 5.74s
Train Epoch: 770 	Average Loss: -7.7999
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.7449

Learning rate: 0.00013534748437792575
Re-generating waveforms for posterior prior.
Train Epoch: 771 [0/90000 (0%)]	Loss: -0.6377	Cost: 23.51s
Train Epoch: 771 [20480/90000 (23%)]	Loss: -8.5374	Cost: 6.19s
Train Epoch: 771 [40960/90000 (45%)]	Loss: -8.4235	Cost: 7.47s
Train Epoch: 771 [61440/90000 (68%)]	Loss: -8.7554	Cost: 5.80s
Train Epoch: 771 [81920/90000 (91%)]	Loss: -8.7151	Cost: 6.01s
Train Epoch: 771 	Average Loss: -8.1075
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.8954

Learning rate: 0.00013520050162539515
Re-generating waveforms for posterior prior.
Train Epoch: 772 [0/90000 (0%)]	Loss: -1.0680	Cost: 24.84s
Train Epoch: 772 [20480/90000 (23%)]	Loss: -8.7282	Cost: 6.09s
Train Epoch: 772 [40960/90000 (45%)]	Loss: -8.4522	Cost: 6.63s
Train Epoch: 772 [61440/90000 (68%)]	Loss: -8.7951	Cost: 5.89s
Train Epoch: 772 [81920/90000 (91%)]	Loss: -9.0037	Cost: 6.06s
Train Epoch: 772 	Average Loss: -8.1877
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.0160

Learning rate: 0.00013505343201912593
Re-generating waveforms for posterior prior.
Train Epoch: 773 [0/90000 (0%)]	Loss: -0.9638	Cost: 24.21s
Train Epoch: 773 [20480/90000 (23%)]	Loss: -8.6923	Cost: 6.10s
Train Epoch: 773 [40960/90000 (45%)]	Loss: -8.2929	Cost: 7.42s
Train Epoch: 773 [61440/90000 (68%)]	Loss: -8.7767	Cost: 5.84s
Train Epoch: 773 [81920/90000 (91%)]	Loss: -8.9241	Cost: 5.79s
Train Epoch: 773 	Average Loss: -8.0809
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.8611

Learning rate: 0.00013490627592199777
Re-generating waveforms for posterior prior.
Train Epoch: 774 [0/90000 (0%)]	Loss: -1.1877	Cost: 23.56s
Train Epoch: 774 [20480/90000 (23%)]	Loss: -8.8238	Cost: 6.14s
Train Epoch: 774 [40960/90000 (45%)]	Loss: -8.3787	Cost: 7.29s
Train Epoch: 774 [61440/90000 (68%)]	Loss: -8.6793	Cost: 5.85s
Train Epoch: 774 [81920/90000 (91%)]	Loss: -8.8607	Cost: 5.89s
Train Epoch: 774 	Average Loss: -8.1288
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.9381

Learning rate: 0.0001347590336971037
Re-generating waveforms for posterior prior.
Train Epoch: 775 [0/90000 (0%)]	Loss: -1.2266	Cost: 24.32s
Train Epoch: 775 [20480/90000 (23%)]	Loss: -9.0404	Cost: 6.17s
Train Epoch: 775 [40960/90000 (45%)]	Loss: -8.5550	Cost: 7.06s
Train Epoch: 775 [61440/90000 (68%)]	Loss: -8.7613	Cost: 5.82s
Train Epoch: 775 [81920/90000 (91%)]	Loss: -8.9578	Cost: 5.87s
Train Epoch: 775 	Average Loss: -8.2354
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.8703

Learning rate: 0.00013461170570774932
Re-generating waveforms for posterior prior.
Train Epoch: 776 [0/90000 (0%)]	Loss: -1.1056	Cost: 24.23s
Train Epoch: 776 [20480/90000 (23%)]	Loss: -9.0602	Cost: 6.16s
Train Epoch: 776 [40960/90000 (45%)]	Loss: -8.6529	Cost: 7.20s
Train Epoch: 776 [61440/90000 (68%)]	Loss: -8.8838	Cost: 5.86s
Train Epoch: 776 [81920/90000 (91%)]	Loss: -9.1445	Cost: 5.69s
Train Epoch: 776 	Average Loss: -8.3071
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.9711

Learning rate: 0.00013446429231745173
Re-generating waveforms for posterior prior.
Train Epoch: 777 [0/90000 (0%)]	Loss: -0.7715	Cost: 23.92s
Train Epoch: 777 [20480/90000 (23%)]	Loss: -9.1244	Cost: 6.12s
Train Epoch: 777 [40960/90000 (45%)]	Loss: -8.6482	Cost: 7.40s
Train Epoch: 777 [61440/90000 (68%)]	Loss: -8.9033	Cost: 5.90s
Train Epoch: 777 [81920/90000 (91%)]	Loss: -9.2499	Cost: 5.74s
Train Epoch: 777 	Average Loss: -8.3592
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.0869

Learning rate: 0.00013431679388993886
Re-generating waveforms for posterior prior.
Train Epoch: 778 [0/90000 (0%)]	Loss: -1.5210	Cost: 23.99s
Train Epoch: 778 [20480/90000 (23%)]	Loss: -9.1315	Cost: 6.14s
Train Epoch: 778 [40960/90000 (45%)]	Loss: -8.8250	Cost: 7.17s
Train Epoch: 778 [61440/90000 (68%)]	Loss: -8.8315	Cost: 5.84s
Train Epoch: 778 [81920/90000 (91%)]	Loss: -8.9564	Cost: 5.74s
Train Epoch: 778 	Average Loss: -8.3953
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.1923

Learning rate: 0.00013416921078914833
Re-generating waveforms for posterior prior.
Train Epoch: 779 [0/90000 (0%)]	Loss: -1.1404	Cost: 24.75s
Train Epoch: 779 [20480/90000 (23%)]	Loss: -9.1044	Cost: 6.12s
Train Epoch: 779 [40960/90000 (45%)]	Loss: -8.5799	Cost: 7.03s
Train Epoch: 779 [61440/90000 (68%)]	Loss: -8.7319	Cost: 5.86s
Train Epoch: 779 [81920/90000 (91%)]	Loss: -9.1089	Cost: 5.69s
Train Epoch: 779 	Average Loss: -8.3585
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.9406

Learning rate: 0.0001340215433792269
Re-generating waveforms for posterior prior.
Train Epoch: 780 [0/90000 (0%)]	Loss: -0.8361	Cost: 24.88s
Train Epoch: 780 [20480/90000 (23%)]	Loss: -8.9787	Cost: 6.08s
Train Epoch: 780 [40960/90000 (45%)]	Loss: -8.5674	Cost: 7.33s
Train Epoch: 780 [61440/90000 (68%)]	Loss: -8.7983	Cost: 5.80s
Train Epoch: 780 [81920/90000 (91%)]	Loss: -8.7108	Cost: 5.72s
Train Epoch: 780 	Average Loss: -8.2731
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.7828

Learning rate: 0.00013387379202452917
Re-generating waveforms for posterior prior.
Train Epoch: 781 [0/90000 (0%)]	Loss: -1.3078	Cost: 26.01s
Train Epoch: 781 [20480/90000 (23%)]	Loss: -7.8020	Cost: 6.05s
Train Epoch: 781 [40960/90000 (45%)]	Loss: -7.6356	Cost: 7.30s
Train Epoch: 781 [61440/90000 (68%)]	Loss: -8.2430	Cost: 5.81s
Train Epoch: 781 [81920/90000 (91%)]	Loss: -8.4946	Cost: 6.01s
Train Epoch: 781 	Average Loss: -7.5406
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.8718

Learning rate: 0.00013372595708961685
Re-generating waveforms for posterior prior.
Train Epoch: 782 [0/90000 (0%)]	Loss: -1.0681	Cost: 24.32s
Train Epoch: 782 [20480/90000 (23%)]	Loss: -8.7428	Cost: 6.11s
Train Epoch: 782 [40960/90000 (45%)]	Loss: -8.2412	Cost: 7.35s
Train Epoch: 782 [61440/90000 (68%)]	Loss: -8.5439	Cost: 5.88s
Train Epoch: 782 [81920/90000 (91%)]	Loss: -8.4386	Cost: 6.12s
Train Epoch: 782 	Average Loss: -7.9387
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.1689

Learning rate: 0.00013357803893925807
Re-generating waveforms for posterior prior.
Train Epoch: 783 [0/90000 (0%)]	Loss: 0.3844	Cost: 24.02s
Train Epoch: 783 [20480/90000 (23%)]	Loss: -8.4733	Cost: 6.15s
Train Epoch: 783 [40960/90000 (45%)]	Loss: -8.2568	Cost: 7.28s
Train Epoch: 783 [61440/90000 (68%)]	Loss: -8.5333	Cost: 5.82s
Train Epoch: 783 [81920/90000 (91%)]	Loss: -8.7147	Cost: 5.89s
Train Epoch: 783 	Average Loss: -7.9043
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.6939

Learning rate: 0.0001334300379384261
Re-generating waveforms for posterior prior.
Train Epoch: 784 [0/90000 (0%)]	Loss: -0.6568	Cost: 24.83s
Train Epoch: 784 [20480/90000 (23%)]	Loss: -8.2782	Cost: 6.10s
Train Epoch: 784 [40960/90000 (45%)]	Loss: -7.9260	Cost: 6.83s
Train Epoch: 784 [61440/90000 (68%)]	Loss: -8.4569	Cost: 5.87s
Train Epoch: 784 [81920/90000 (91%)]	Loss: -8.7748	Cost: 5.81s
Train Epoch: 784 	Average Loss: -7.9289
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.7541

Learning rate: 0.00013328195445229868
Re-generating waveforms for posterior prior.
Train Epoch: 785 [0/90000 (0%)]	Loss: -0.5633	Cost: 24.46s
Train Epoch: 785 [20480/90000 (23%)]	Loss: -9.0648	Cost: 6.08s
Train Epoch: 785 [40960/90000 (45%)]	Loss: -8.5046	Cost: 7.37s
Train Epoch: 785 [61440/90000 (68%)]	Loss: -8.8897	Cost: 5.78s
Train Epoch: 785 [81920/90000 (91%)]	Loss: -9.0294	Cost: 5.78s
Train Epoch: 785 	Average Loss: -8.3126
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.0751

Learning rate: 0.00013313378884625707
Re-generating waveforms for posterior prior.
Train Epoch: 786 [0/90000 (0%)]	Loss: -1.0958	Cost: 23.55s
Train Epoch: 786 [20480/90000 (23%)]	Loss: -8.9868	Cost: 6.12s
Train Epoch: 786 [40960/90000 (45%)]	Loss: -8.4012	Cost: 7.35s
Train Epoch: 786 [61440/90000 (68%)]	Loss: -8.6881	Cost: 5.82s
Train Epoch: 786 [81920/90000 (91%)]	Loss: -8.9114	Cost: 5.70s
Train Epoch: 786 	Average Loss: -8.2109
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.8236

Learning rate: 0.00013298554148588528
Re-generating waveforms for posterior prior.
Train Epoch: 787 [0/90000 (0%)]	Loss: -1.0682	Cost: 24.46s
Train Epoch: 787 [20480/90000 (23%)]	Loss: -9.0080	Cost: 6.10s
Train Epoch: 787 [40960/90000 (45%)]	Loss: -8.6907	Cost: 6.43s
Train Epoch: 787 [61440/90000 (68%)]	Loss: -9.0046	Cost: 5.93s
Train Epoch: 787 [81920/90000 (91%)]	Loss: -9.2683	Cost: 5.68s
Train Epoch: 787 	Average Loss: -8.3513
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.1301

Learning rate: 0.00013283721273696887
Re-generating waveforms for posterior prior.
Train Epoch: 788 [0/90000 (0%)]	Loss: -0.9868	Cost: 24.35s
Train Epoch: 788 [20480/90000 (23%)]	Loss: -8.9849	Cost: 6.15s
Train Epoch: 788 [40960/90000 (45%)]	Loss: -8.4114	Cost: 7.39s
Train Epoch: 788 [61440/90000 (68%)]	Loss: -8.9733	Cost: 5.86s
Train Epoch: 788 [81920/90000 (91%)]	Loss: -9.1993	Cost: 5.71s
Train Epoch: 788 	Average Loss: -8.3681
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.9021

Learning rate: 0.00013268880296549428
Re-generating waveforms for posterior prior.
Train Epoch: 789 [0/90000 (0%)]	Loss: -0.8604	Cost: 24.43s
Train Epoch: 789 [20480/90000 (23%)]	Loss: -8.9050	Cost: 6.13s
Train Epoch: 789 [40960/90000 (45%)]	Loss: -8.5690	Cost: 7.26s
Train Epoch: 789 [61440/90000 (68%)]	Loss: -8.8870	Cost: 5.85s
Train Epoch: 789 [81920/90000 (91%)]	Loss: -9.0002	Cost: 5.90s
Train Epoch: 789 	Average Loss: -8.2410
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.1612

Learning rate: 0.0001325403125376478
Re-generating waveforms for posterior prior.
Train Epoch: 790 [0/90000 (0%)]	Loss: -0.9892	Cost: 24.35s
Train Epoch: 790 [20480/90000 (23%)]	Loss: -9.1624	Cost: 6.10s
Train Epoch: 790 [40960/90000 (45%)]	Loss: -8.6485	Cost: 6.98s
Train Epoch: 790 [61440/90000 (68%)]	Loss: -9.0572	Cost: 5.85s
Train Epoch: 790 [81920/90000 (91%)]	Loss: -9.3552	Cost: 5.65s
Train Epoch: 790 	Average Loss: -8.5116
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.2505

Learning rate: 0.00013239174181981493
Re-generating waveforms for posterior prior.
Train Epoch: 791 [0/90000 (0%)]	Loss: -1.6701	Cost: 24.27s
Train Epoch: 791 [20480/90000 (23%)]	Loss: -9.4130	Cost: 6.10s
Train Epoch: 791 [40960/90000 (45%)]	Loss: -8.7285	Cost: 6.83s
Train Epoch: 791 [61440/90000 (68%)]	Loss: -9.2422	Cost: 5.86s
Train Epoch: 791 [81920/90000 (91%)]	Loss: -9.4936	Cost: 6.09s
Train Epoch: 791 	Average Loss: -8.7123
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.3592

Learning rate: 0.00013224309117857908
Re-generating waveforms for posterior prior.
Train Epoch: 792 [0/90000 (0%)]	Loss: -1.1338	Cost: 24.74s
Train Epoch: 792 [20480/90000 (23%)]	Loss: -9.4991	Cost: 6.11s
Train Epoch: 792 [40960/90000 (45%)]	Loss: -8.1489	Cost: 6.61s
Train Epoch: 792 [61440/90000 (68%)]	Loss: -8.4041	Cost: 5.93s
Train Epoch: 792 [81920/90000 (91%)]	Loss: -8.7522	Cost: 6.34s
Train Epoch: 792 	Average Loss: -8.2663
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.9392

Learning rate: 0.0001320943609807209
Re-generating waveforms for posterior prior.
Train Epoch: 793 [0/90000 (0%)]	Loss: -1.3283	Cost: 24.47s
Train Epoch: 793 [20480/90000 (23%)]	Loss: -9.1464	Cost: 6.11s
Train Epoch: 793 [40960/90000 (45%)]	Loss: -8.5440	Cost: 7.41s
Train Epoch: 793 [61440/90000 (68%)]	Loss: -9.0215	Cost: 5.83s
Train Epoch: 793 [81920/90000 (91%)]	Loss: -9.1289	Cost: 6.07s
Train Epoch: 793 	Average Loss: -8.3784
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.0005

Learning rate: 0.00013194555159321746
Re-generating waveforms for posterior prior.
Train Epoch: 794 [0/90000 (0%)]	Loss: -1.3141	Cost: 24.53s
Train Epoch: 794 [20480/90000 (23%)]	Loss: -9.1297	Cost: 6.12s
Train Epoch: 794 [40960/90000 (45%)]	Loss: -8.7781	Cost: 7.32s
Train Epoch: 794 [61440/90000 (68%)]	Loss: -9.2159	Cost: 5.83s
Train Epoch: 794 [81920/90000 (91%)]	Loss: -9.2928	Cost: 5.93s
Train Epoch: 794 	Average Loss: -8.5278
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.1520

Learning rate: 0.00013179666338324108
Re-generating waveforms for posterior prior.
Train Epoch: 795 [0/90000 (0%)]	Loss: -0.9825	Cost: 24.59s
Train Epoch: 795 [20480/90000 (23%)]	Loss: -9.2636	Cost: 6.12s
Train Epoch: 795 [40960/90000 (45%)]	Loss: -8.4165	Cost: 7.26s
Train Epoch: 795 [61440/90000 (68%)]	Loss: -9.0355	Cost: 5.81s
Train Epoch: 795 [81920/90000 (91%)]	Loss: -9.2417	Cost: 6.04s
Train Epoch: 795 	Average Loss: -8.4175
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.1065

Learning rate: 0.0001316476967181586
Re-generating waveforms for posterior prior.
Train Epoch: 796 [0/90000 (0%)]	Loss: -1.4972	Cost: 24.54s
Train Epoch: 796 [20480/90000 (23%)]	Loss: -9.0309	Cost: 6.11s
Train Epoch: 796 [40960/90000 (45%)]	Loss: -8.6820	Cost: 7.24s
Train Epoch: 796 [61440/90000 (68%)]	Loss: -9.2051	Cost: 5.81s
Train Epoch: 796 [81920/90000 (91%)]	Loss: -9.3892	Cost: 5.88s
Train Epoch: 796 	Average Loss: -8.5252
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.3540

Learning rate: 0.00013149865196553044
Re-generating waveforms for posterior prior.
Train Epoch: 797 [0/90000 (0%)]	Loss: -1.6603	Cost: 24.29s
Train Epoch: 797 [20480/90000 (23%)]	Loss: -9.5486	Cost: 6.11s
Train Epoch: 797 [40960/90000 (45%)]	Loss: -8.9492	Cost: 7.41s
Train Epoch: 797 [61440/90000 (68%)]	Loss: -9.1835	Cost: 5.83s
Train Epoch: 797 [81920/90000 (91%)]	Loss: -9.5266	Cost: 6.00s
Train Epoch: 797 	Average Loss: -8.6880
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.2292

Learning rate: 0.00013134952949310976
Re-generating waveforms for posterior prior.
Train Epoch: 798 [0/90000 (0%)]	Loss: -1.5031	Cost: 23.75s
Train Epoch: 798 [20480/90000 (23%)]	Loss: -9.1636	Cost: 6.12s
Train Epoch: 798 [40960/90000 (45%)]	Loss: -8.7560	Cost: 7.61s
Train Epoch: 798 [61440/90000 (68%)]	Loss: -9.3129	Cost: 5.80s
Train Epoch: 798 [81920/90000 (91%)]	Loss: -9.4452	Cost: 6.01s
Train Epoch: 798 	Average Loss: -8.6144
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.2862

Learning rate: 0.00013120032966884145
Re-generating waveforms for posterior prior.
Train Epoch: 799 [0/90000 (0%)]	Loss: -0.9566	Cost: 24.01s
Train Epoch: 799 [20480/90000 (23%)]	Loss: -9.5153	Cost: 6.10s
Train Epoch: 799 [40960/90000 (45%)]	Loss: -9.0434	Cost: 7.46s
Train Epoch: 799 [61440/90000 (68%)]	Loss: -9.2631	Cost: 5.81s
Train Epoch: 799 [81920/90000 (91%)]	Loss: -9.5100	Cost: 5.81s
Train Epoch: 799 	Average Loss: -8.7419
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.3169

Learning rate: 0.0001310510528608612
Re-generating waveforms for posterior prior.
Train Epoch: 800 [0/90000 (0%)]	Loss: -1.2237	Cost: 24.96s
Train Epoch: 800 [20480/90000 (23%)]	Loss: -9.4774	Cost: 6.15s
Train Epoch: 800 [40960/90000 (45%)]	Loss: -9.0478	Cost: 7.19s
Train Epoch: 800 [61440/90000 (68%)]	Loss: -9.3518	Cost: 5.83s
Train Epoch: 800 [81920/90000 (91%)]	Loss: -9.5233	Cost: 5.84s
Train Epoch: 800 	Average Loss: -8.8011
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.3558

Saving model as model_sample_from_all_posterior.pt_e800 & waveforms_supplementary_sample_from_all_posterior.hdf5_e800
Learning rate: 0.00013090169943749468
Re-generating waveforms for posterior prior.
Train Epoch: 801 [0/90000 (0%)]	Loss: -0.8685	Cost: 24.40s
Train Epoch: 801 [20480/90000 (23%)]	Loss: -9.4962	Cost: 6.08s
Train Epoch: 801 [40960/90000 (45%)]	Loss: -8.6191	Cost: 7.49s
Train Epoch: 801 [61440/90000 (68%)]	Loss: -9.1810	Cost: 5.87s
Train Epoch: 801 [81920/90000 (91%)]	Loss: -9.3779	Cost: 6.14s
Train Epoch: 801 	Average Loss: -8.6481
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.3730

Learning rate: 0.0001307522697672567
Re-generating waveforms for posterior prior.
Train Epoch: 802 [0/90000 (0%)]	Loss: -1.1305	Cost: 24.21s
Train Epoch: 802 [20480/90000 (23%)]	Loss: -9.5736	Cost: 6.14s
Train Epoch: 802 [40960/90000 (45%)]	Loss: -8.9919	Cost: 7.19s
Train Epoch: 802 [61440/90000 (68%)]	Loss: -9.4475	Cost: 5.83s
Train Epoch: 802 [81920/90000 (91%)]	Loss: -9.6319	Cost: 5.76s
Train Epoch: 802 	Average Loss: -8.8316
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.4862

Learning rate: 0.00013060276421885002
Re-generating waveforms for posterior prior.
Train Epoch: 803 [0/90000 (0%)]	Loss: -1.3280	Cost: 24.54s
Train Epoch: 803 [20480/90000 (23%)]	Loss: -9.5058	Cost: 6.11s
Train Epoch: 803 [40960/90000 (45%)]	Loss: -9.1025	Cost: 7.15s
Train Epoch: 803 [61440/90000 (68%)]	Loss: -9.4533	Cost: 5.85s
Train Epoch: 803 [81920/90000 (91%)]	Loss: -9.5984	Cost: 5.81s
Train Epoch: 803 	Average Loss: -8.8511
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.3560

Learning rate: 0.00013045318316116478
Re-generating waveforms for posterior prior.
Train Epoch: 804 [0/90000 (0%)]	Loss: -1.3265	Cost: 23.86s
Train Epoch: 804 [20480/90000 (23%)]	Loss: -9.5660	Cost: 6.16s
Train Epoch: 804 [40960/90000 (45%)]	Loss: -8.4753	Cost: 7.45s
Train Epoch: 804 [61440/90000 (68%)]	Loss: -8.9725	Cost: 5.83s
Train Epoch: 804 [81920/90000 (91%)]	Loss: -9.2347	Cost: 5.79s
Train Epoch: 804 	Average Loss: -8.5488
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.1664

Learning rate: 0.00013030352696327734
Re-generating waveforms for posterior prior.
Train Epoch: 805 [0/90000 (0%)]	Loss: -0.9601	Cost: 24.12s
Train Epoch: 805 [20480/90000 (23%)]	Loss: -9.3251	Cost: 6.11s
Train Epoch: 805 [40960/90000 (45%)]	Loss: -9.0942	Cost: 6.93s
Train Epoch: 805 [61440/90000 (68%)]	Loss: -9.4382	Cost: 5.93s
Train Epoch: 805 [81920/90000 (91%)]	Loss: -9.7367	Cost: 5.89s
Train Epoch: 805 	Average Loss: -8.7629
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.4093

Learning rate: 0.0001301537959944495
Re-generating waveforms for posterior prior.
Train Epoch: 806 [0/90000 (0%)]	Loss: -1.4479	Cost: 24.39s
Train Epoch: 806 [20480/90000 (23%)]	Loss: -9.5150	Cost: 6.16s
Train Epoch: 806 [40960/90000 (45%)]	Loss: -9.0392	Cost: 7.36s
Train Epoch: 806 [61440/90000 (68%)]	Loss: -9.5127	Cost: 5.82s
Train Epoch: 806 [81920/90000 (91%)]	Loss: -9.4614	Cost: 5.83s
Train Epoch: 806 	Average Loss: -8.8699
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.4129

Learning rate: 0.00013000399062412758
Re-generating waveforms for posterior prior.
Train Epoch: 807 [0/90000 (0%)]	Loss: -1.7512	Cost: 24.71s
Train Epoch: 807 [20480/90000 (23%)]	Loss: -9.6654	Cost: 6.13s
Train Epoch: 807 [40960/90000 (45%)]	Loss: -9.1071	Cost: 7.35s
Train Epoch: 807 [61440/90000 (68%)]	Loss: -9.5735	Cost: 5.80s
Train Epoch: 807 [81920/90000 (91%)]	Loss: -9.6691	Cost: 5.80s
Train Epoch: 807 	Average Loss: -8.9197
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.3389

Learning rate: 0.00012985411122194137
Re-generating waveforms for posterior prior.
Train Epoch: 808 [0/90000 (0%)]	Loss: -1.2948	Cost: 24.14s
Train Epoch: 808 [20480/90000 (23%)]	Loss: -9.5258	Cost: 6.12s
Train Epoch: 808 [40960/90000 (45%)]	Loss: -8.9924	Cost: 7.20s
Train Epoch: 808 [61440/90000 (68%)]	Loss: -9.5923	Cost: 5.89s
Train Epoch: 808 [81920/90000 (91%)]	Loss: -9.7822	Cost: 6.00s
Train Epoch: 808 	Average Loss: -8.8976
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.5570

Learning rate: 0.00012970415815770342
Re-generating waveforms for posterior prior.
Train Epoch: 809 [0/90000 (0%)]	Loss: -1.6447	Cost: 23.95s
Train Epoch: 809 [20480/90000 (23%)]	Loss: -9.7847	Cost: 6.13s
Train Epoch: 809 [40960/90000 (45%)]	Loss: -9.3773	Cost: 6.61s
Train Epoch: 809 [61440/90000 (68%)]	Loss: -9.5242	Cost: 5.91s
Train Epoch: 809 [81920/90000 (91%)]	Loss: -9.7355	Cost: 6.12s
Train Epoch: 809 	Average Loss: -9.0101
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.4110

Learning rate: 0.00012955413180140804
Re-generating waveforms for posterior prior.
Train Epoch: 810 [0/90000 (0%)]	Loss: -1.2526	Cost: 24.51s
Train Epoch: 810 [20480/90000 (23%)]	Loss: -9.6230	Cost: 6.22s
Train Epoch: 810 [40960/90000 (45%)]	Loss: -9.2568	Cost: 7.30s
Train Epoch: 810 [61440/90000 (68%)]	Loss: -9.6290	Cost: 5.83s
Train Epoch: 810 [81920/90000 (91%)]	Loss: -9.8950	Cost: 6.07s
Train Epoch: 810 	Average Loss: -9.0428
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.5226

Learning rate: 0.00012940403252323032
Re-generating waveforms for posterior prior.
Train Epoch: 811 [0/90000 (0%)]	Loss: -1.3924	Cost: 24.15s
Train Epoch: 811 [20480/90000 (23%)]	Loss: -9.7773	Cost: 6.14s
Train Epoch: 811 [40960/90000 (45%)]	Loss: -9.2918	Cost: 7.42s
Train Epoch: 811 [61440/90000 (68%)]	Loss: -9.5911	Cost: 5.83s
Train Epoch: 811 [81920/90000 (91%)]	Loss: -9.7733	Cost: 5.78s
Train Epoch: 811 	Average Loss: -9.0077
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.5442

Learning rate: 0.0001292538606935253
Re-generating waveforms for posterior prior.
Train Epoch: 812 [0/90000 (0%)]	Loss: -1.5108	Cost: 24.13s
Train Epoch: 812 [20480/90000 (23%)]	Loss: -9.7234	Cost: 6.21s
Train Epoch: 812 [40960/90000 (45%)]	Loss: -9.2269	Cost: 7.36s
Train Epoch: 812 [61440/90000 (68%)]	Loss: -9.5338	Cost: 5.82s
Train Epoch: 812 [81920/90000 (91%)]	Loss: -9.7280	Cost: 5.86s
Train Epoch: 812 	Average Loss: -8.9646
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.6026

Learning rate: 0.0001291036166828271
Re-generating waveforms for posterior prior.
Train Epoch: 813 [0/90000 (0%)]	Loss: -1.6425	Cost: 23.94s
Train Epoch: 813 [20480/90000 (23%)]	Loss: -9.5690	Cost: 6.12s
Train Epoch: 813 [40960/90000 (45%)]	Loss: -9.0511	Cost: 7.49s
Train Epoch: 813 [61440/90000 (68%)]	Loss: -9.4541	Cost: 5.81s
Train Epoch: 813 [81920/90000 (91%)]	Loss: -9.7155	Cost: 6.03s
Train Epoch: 813 	Average Loss: -8.9179
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.6855

Learning rate: 0.00012895330086184784
Re-generating waveforms for posterior prior.
Train Epoch: 814 [0/90000 (0%)]	Loss: -1.4046	Cost: 24.08s
Train Epoch: 814 [20480/90000 (23%)]	Loss: -9.6909	Cost: 6.14s
Train Epoch: 814 [40960/90000 (45%)]	Loss: -9.2410	Cost: 6.51s
Train Epoch: 814 [61440/90000 (68%)]	Loss: -8.8090	Cost: 5.87s
Train Epoch: 814 [81920/90000 (91%)]	Loss: -9.2903	Cost: 5.97s
Train Epoch: 814 	Average Loss: -8.7325
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.1992

Learning rate: 0.00012880291360147682
Re-generating waveforms for posterior prior.
Train Epoch: 815 [0/90000 (0%)]	Loss: -1.1573	Cost: 23.87s
Train Epoch: 815 [20480/90000 (23%)]	Loss: -9.2927	Cost: 6.08s
Train Epoch: 815 [40960/90000 (45%)]	Loss: -8.9990	Cost: 6.65s
Train Epoch: 815 [61440/90000 (68%)]	Loss: -9.4822	Cost: 5.87s
Train Epoch: 815 [81920/90000 (91%)]	Loss: -9.7316	Cost: 5.74s
Train Epoch: 815 	Average Loss: -8.8110
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.5364

Learning rate: 0.00012865245527277972
Re-generating waveforms for posterior prior.
Train Epoch: 816 [0/90000 (0%)]	Loss: -2.0621	Cost: 24.77s
Train Epoch: 816 [20480/90000 (23%)]	Loss: -9.8793	Cost: 6.11s
Train Epoch: 816 [40960/90000 (45%)]	Loss: -9.3850	Cost: 6.92s
Train Epoch: 816 [61440/90000 (68%)]	Loss: -9.7297	Cost: 5.83s
Train Epoch: 816 [81920/90000 (91%)]	Loss: -9.9344	Cost: 5.96s
Train Epoch: 816 	Average Loss: -9.0919
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.3525

Learning rate: 0.0001285019262469975
Re-generating waveforms for posterior prior.
Train Epoch: 817 [0/90000 (0%)]	Loss: -0.8742	Cost: 24.83s
Train Epoch: 817 [20480/90000 (23%)]	Loss: -9.7540	Cost: 6.14s
Train Epoch: 817 [40960/90000 (45%)]	Loss: -9.3262	Cost: 7.31s
Train Epoch: 817 [61440/90000 (68%)]	Loss: -9.8411	Cost: 5.84s
Train Epoch: 817 [81920/90000 (91%)]	Loss: -9.6782	Cost: 5.86s
Train Epoch: 817 	Average Loss: -8.9806
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.4608

Learning rate: 0.0001283513268955456
Re-generating waveforms for posterior prior.
Train Epoch: 818 [0/90000 (0%)]	Loss: -1.7065	Cost: 25.99s
Train Epoch: 818 [20480/90000 (23%)]	Loss: -9.7641	Cost: 6.02s
Train Epoch: 818 [40960/90000 (45%)]	Loss: -9.4875	Cost: 7.14s
Train Epoch: 818 [61440/90000 (68%)]	Loss: -9.6066	Cost: 5.82s
Train Epoch: 818 [81920/90000 (91%)]	Loss: -9.9477	Cost: 5.94s
Train Epoch: 818 	Average Loss: -9.1372
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.6414

Learning rate: 0.00012820065759001282
Re-generating waveforms for posterior prior.
Train Epoch: 819 [0/90000 (0%)]	Loss: -1.7925	Cost: 23.67s
Train Epoch: 819 [20480/90000 (23%)]	Loss: -10.0472	Cost: 6.11s
Train Epoch: 819 [40960/90000 (45%)]	Loss: -9.6227	Cost: 7.37s
Train Epoch: 819 [61440/90000 (68%)]	Loss: -9.8410	Cost: 5.81s
Train Epoch: 819 [81920/90000 (91%)]	Loss: -9.9950	Cost: 6.02s
Train Epoch: 819 	Average Loss: -9.2589
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.5973

Learning rate: 0.00012804991870216085
Re-generating waveforms for posterior prior.
Train Epoch: 820 [0/90000 (0%)]	Loss: -1.3976	Cost: 23.98s
Train Epoch: 820 [20480/90000 (23%)]	Loss: -9.9231	Cost: 6.18s
Train Epoch: 820 [40960/90000 (45%)]	Loss: -9.4698	Cost: 6.52s
Train Epoch: 820 [61440/90000 (68%)]	Loss: -9.8681	Cost: 5.90s
Train Epoch: 820 [81920/90000 (91%)]	Loss: -10.0531	Cost: 6.00s
Train Epoch: 820 	Average Loss: -9.2604
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.6306

Learning rate: 0.00012789911060392283
Re-generating waveforms for posterior prior.
Train Epoch: 821 [0/90000 (0%)]	Loss: -1.7837	Cost: 24.45s
Train Epoch: 821 [20480/90000 (23%)]	Loss: -10.0243	Cost: 6.11s
Train Epoch: 821 [40960/90000 (45%)]	Loss: -9.2600	Cost: 6.53s
Train Epoch: 821 [61440/90000 (68%)]	Loss: -9.8020	Cost: 6.13s
Train Epoch: 821 [81920/90000 (91%)]	Loss: -9.8660	Cost: 5.81s
Train Epoch: 821 	Average Loss: -9.1966
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.5648

Learning rate: 0.00012774823366740277
Re-generating waveforms for posterior prior.
Train Epoch: 822 [0/90000 (0%)]	Loss: -1.8707	Cost: 24.38s
Train Epoch: 822 [20480/90000 (23%)]	Loss: -9.8084	Cost: 6.14s
Train Epoch: 822 [40960/90000 (45%)]	Loss: -9.3037	Cost: 7.54s
Train Epoch: 822 [61440/90000 (68%)]	Loss: -9.8381	Cost: 5.90s
Train Epoch: 822 [81920/90000 (91%)]	Loss: -10.1350	Cost: 5.90s
Train Epoch: 822 	Average Loss: -9.1942
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.6321

Learning rate: 0.00012759728826487447
Re-generating waveforms for posterior prior.
Train Epoch: 823 [0/90000 (0%)]	Loss: -1.9739	Cost: 24.21s
Train Epoch: 823 [20480/90000 (23%)]	Loss: -9.9397	Cost: 6.13s
Train Epoch: 823 [40960/90000 (45%)]	Loss: -9.6022	Cost: 6.60s
Train Epoch: 823 [61440/90000 (68%)]	Loss: -9.6352	Cost: 5.85s
Train Epoch: 823 [81920/90000 (91%)]	Loss: -9.7887	Cost: 5.67s
Train Epoch: 823 	Average Loss: -9.1991
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.5387

Learning rate: 0.00012744627476878078
Re-generating waveforms for posterior prior.
Train Epoch: 824 [0/90000 (0%)]	Loss: -1.4718	Cost: 24.21s
Train Epoch: 824 [20480/90000 (23%)]	Loss: -9.9340	Cost: 6.13s
Train Epoch: 824 [40960/90000 (45%)]	Loss: -9.5628	Cost: 7.14s
Train Epoch: 824 [61440/90000 (68%)]	Loss: -9.9815	Cost: 5.85s
Train Epoch: 824 [81920/90000 (91%)]	Loss: -10.0791	Cost: 5.79s
Train Epoch: 824 	Average Loss: -9.2182
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.6373

Learning rate: 0.00012729519355173243
Re-generating waveforms for posterior prior.
Train Epoch: 825 [0/90000 (0%)]	Loss: -1.5312	Cost: 25.07s
Train Epoch: 825 [20480/90000 (23%)]	Loss: -9.8927	Cost: 6.10s
Train Epoch: 825 [40960/90000 (45%)]	Loss: -9.5548	Cost: 7.19s
Train Epoch: 825 [61440/90000 (68%)]	Loss: -9.7756	Cost: 5.84s
Train Epoch: 825 [81920/90000 (91%)]	Loss: -9.8660	Cost: 5.75s
Train Epoch: 825 	Average Loss: -9.1648
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.6082

Learning rate: 0.00012714404498650732
Re-generating waveforms for posterior prior.
Train Epoch: 826 [0/90000 (0%)]	Loss: -1.8053	Cost: 24.09s
Train Epoch: 826 [20480/90000 (23%)]	Loss: -9.8372	Cost: 6.12s
Train Epoch: 826 [40960/90000 (45%)]	Loss: -9.4526	Cost: 6.48s
Train Epoch: 826 [61440/90000 (68%)]	Loss: -10.0299	Cost: 5.91s
Train Epoch: 826 [81920/90000 (91%)]	Loss: -10.1550	Cost: 5.80s
Train Epoch: 826 	Average Loss: -9.2853
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.7664

Learning rate: 0.00012699282944604953
Re-generating waveforms for posterior prior.
Train Epoch: 827 [0/90000 (0%)]	Loss: -2.2871	Cost: 24.35s
Train Epoch: 827 [20480/90000 (23%)]	Loss: -10.0059	Cost: 6.11s
Train Epoch: 827 [40960/90000 (45%)]	Loss: -9.7620	Cost: 7.19s
Train Epoch: 827 [61440/90000 (68%)]	Loss: -9.9418	Cost: 5.85s
Train Epoch: 827 [81920/90000 (91%)]	Loss: -10.0310	Cost: 5.76s
Train Epoch: 827 	Average Loss: -9.3286
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.9051

Learning rate: 0.00012684154730346837
Re-generating waveforms for posterior prior.
Train Epoch: 828 [0/90000 (0%)]	Loss: -1.9368	Cost: 24.89s
Train Epoch: 828 [20480/90000 (23%)]	Loss: -10.0243	Cost: 6.12s
Train Epoch: 828 [40960/90000 (45%)]	Loss: -9.4974	Cost: 7.41s
Train Epoch: 828 [61440/90000 (68%)]	Loss: -9.9381	Cost: 5.80s
Train Epoch: 828 [81920/90000 (91%)]	Loss: -9.7200	Cost: 5.69s
Train Epoch: 828 	Average Loss: -9.2439
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.3370

Learning rate: 0.00012669019893203748
Re-generating waveforms for posterior prior.
Train Epoch: 829 [0/90000 (0%)]	Loss: -1.7442	Cost: 24.39s
Train Epoch: 829 [20480/90000 (23%)]	Loss: -9.5506	Cost: 6.13s
Train Epoch: 829 [40960/90000 (45%)]	Loss: -9.4354	Cost: 7.25s
Train Epoch: 829 [61440/90000 (68%)]	Loss: -9.8518	Cost: 5.86s
Train Epoch: 829 [81920/90000 (91%)]	Loss: -10.0287	Cost: 5.68s
Train Epoch: 829 	Average Loss: -9.1344
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.7356

Learning rate: 0.00012653878470519388
Re-generating waveforms for posterior prior.
Train Epoch: 830 [0/90000 (0%)]	Loss: -1.5407	Cost: 24.19s
Train Epoch: 830 [20480/90000 (23%)]	Loss: -10.1844	Cost: 6.14s
Train Epoch: 830 [40960/90000 (45%)]	Loss: -9.8487	Cost: 7.03s
Train Epoch: 830 [61440/90000 (68%)]	Loss: -9.9059	Cost: 5.87s
Train Epoch: 830 [81920/90000 (91%)]	Loss: -9.9587	Cost: 6.22s
Train Epoch: 830 	Average Loss: -9.3640
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.7576

Learning rate: 0.0001263873049965372
Re-generating waveforms for posterior prior.
Train Epoch: 831 [0/90000 (0%)]	Loss: -1.7232	Cost: 25.91s
Train Epoch: 831 [20480/90000 (23%)]	Loss: -9.9777	Cost: 6.10s
Train Epoch: 831 [40960/90000 (45%)]	Loss: -9.4394	Cost: 6.42s
Train Epoch: 831 [61440/90000 (68%)]	Loss: -9.7848	Cost: 6.10s
Train Epoch: 831 [81920/90000 (91%)]	Loss: -9.9434	Cost: 5.81s
Train Epoch: 831 	Average Loss: -9.2218
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.6317

Learning rate: 0.00012623576017982852
Re-generating waveforms for posterior prior.
Train Epoch: 832 [0/90000 (0%)]	Loss: -1.7131	Cost: 24.95s
Train Epoch: 832 [20480/90000 (23%)]	Loss: -10.1323	Cost: 6.35s
Train Epoch: 832 [40960/90000 (45%)]	Loss: -9.6578	Cost: 7.13s
Train Epoch: 832 [61440/90000 (68%)]	Loss: -10.1172	Cost: 5.94s
Train Epoch: 832 [81920/90000 (91%)]	Loss: -10.2164	Cost: 5.78s
Train Epoch: 832 	Average Loss: -9.4026
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.9003

Learning rate: 0.00012608415062898958
Re-generating waveforms for posterior prior.
Train Epoch: 833 [0/90000 (0%)]	Loss: -2.0265	Cost: 24.44s
Train Epoch: 833 [20480/90000 (23%)]	Loss: -10.2131	Cost: 6.14s
Train Epoch: 833 [40960/90000 (45%)]	Loss: -9.0817	Cost: 7.10s
Train Epoch: 833 [61440/90000 (68%)]	Loss: -9.4806	Cost: 5.83s
Train Epoch: 833 [81920/90000 (91%)]	Loss: -9.6155	Cost: 5.84s
Train Epoch: 833 	Average Loss: -9.1460
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.6271

Learning rate: 0.00012593247671810194
Re-generating waveforms for posterior prior.
Train Epoch: 834 [0/90000 (0%)]	Loss: -2.1819	Cost: 24.80s
Train Epoch: 834 [20480/90000 (23%)]	Loss: -9.7594	Cost: 6.09s
Train Epoch: 834 [40960/90000 (45%)]	Loss: -9.3697	Cost: 6.68s
Train Epoch: 834 [61440/90000 (68%)]	Loss: -9.7362	Cost: 5.84s
Train Epoch: 834 [81920/90000 (91%)]	Loss: -10.0433	Cost: 6.14s
Train Epoch: 834 	Average Loss: -9.1353
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.7539

Learning rate: 0.0001257807388214059
Re-generating waveforms for posterior prior.
Train Epoch: 835 [0/90000 (0%)]	Loss: -2.1160	Cost: 23.82s
Train Epoch: 835 [20480/90000 (23%)]	Loss: -10.1370	Cost: 6.10s
Train Epoch: 835 [40960/90000 (45%)]	Loss: -9.7572	Cost: 7.18s
Train Epoch: 835 [61440/90000 (68%)]	Loss: -9.8501	Cost: 5.81s
Train Epoch: 835 [81920/90000 (91%)]	Loss: -9.9872	Cost: 6.00s
Train Epoch: 835 	Average Loss: -9.3258
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.7755

Learning rate: 0.00012562893731329956
Re-generating waveforms for posterior prior.
Train Epoch: 836 [0/90000 (0%)]	Loss: -1.6977	Cost: 24.71s
Train Epoch: 836 [20480/90000 (23%)]	Loss: -9.8993	Cost: 6.09s
Train Epoch: 836 [40960/90000 (45%)]	Loss: -9.6639	Cost: 6.54s
Train Epoch: 836 [61440/90000 (68%)]	Loss: -10.0137	Cost: 5.95s
Train Epoch: 836 [81920/90000 (91%)]	Loss: -10.1328	Cost: 5.82s
Train Epoch: 836 	Average Loss: -9.4351
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.9623

Learning rate: 0.00012547707256833812
Re-generating waveforms for posterior prior.
Train Epoch: 837 [0/90000 (0%)]	Loss: -1.7291	Cost: 24.30s
Train Epoch: 837 [20480/90000 (23%)]	Loss: -10.1296	Cost: 6.20s
Train Epoch: 837 [40960/90000 (45%)]	Loss: -9.7090	Cost: 7.32s
Train Epoch: 837 [61440/90000 (68%)]	Loss: -10.1239	Cost: 5.83s
Train Epoch: 837 [81920/90000 (91%)]	Loss: -10.4134	Cost: 6.06s
Train Epoch: 837 	Average Loss: -9.4763
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.8871

Learning rate: 0.0001253251449612327
Re-generating waveforms for posterior prior.
Train Epoch: 838 [0/90000 (0%)]	Loss: -1.7113	Cost: 24.25s
Train Epoch: 838 [20480/90000 (23%)]	Loss: -10.3222	Cost: 6.16s
Train Epoch: 838 [40960/90000 (45%)]	Loss: -10.0278	Cost: 6.49s
Train Epoch: 838 [61440/90000 (68%)]	Loss: -10.1225	Cost: 5.89s
Train Epoch: 838 [81920/90000 (91%)]	Loss: -10.3924	Cost: 5.84s
Train Epoch: 838 	Average Loss: -9.6139
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.0372

Learning rate: 0.0001251731548668496
Re-generating waveforms for posterior prior.
Train Epoch: 839 [0/90000 (0%)]	Loss: -1.8420	Cost: 24.48s
Train Epoch: 839 [20480/90000 (23%)]	Loss: -10.4285	Cost: 6.11s
Train Epoch: 839 [40960/90000 (45%)]	Loss: -9.9368	Cost: 7.48s
Train Epoch: 839 [61440/90000 (68%)]	Loss: -10.3366	Cost: 5.76s
Train Epoch: 839 [81920/90000 (91%)]	Loss: -10.4262	Cost: 6.14s
Train Epoch: 839 	Average Loss: -9.6402
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.0292

Learning rate: 0.00012502110266020928
Re-generating waveforms for posterior prior.
Train Epoch: 840 [0/90000 (0%)]	Loss: -2.0638	Cost: 24.73s
Train Epoch: 840 [20480/90000 (23%)]	Loss: -10.2555	Cost: 6.10s
Train Epoch: 840 [40960/90000 (45%)]	Loss: -9.8424	Cost: 7.44s
Train Epoch: 840 [61440/90000 (68%)]	Loss: -10.2278	Cost: 5.81s
Train Epoch: 840 [81920/90000 (91%)]	Loss: -10.3666	Cost: 5.92s
Train Epoch: 840 	Average Loss: -9.6371
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.9738

Learning rate: 0.00012486898871648538
Re-generating waveforms for posterior prior.
Train Epoch: 841 [0/90000 (0%)]	Loss: -1.8291	Cost: 25.57s
Train Epoch: 841 [20480/90000 (23%)]	Loss: -10.5271	Cost: 6.10s
Train Epoch: 841 [40960/90000 (45%)]	Loss: -10.2092	Cost: 6.66s
Train Epoch: 841 [61440/90000 (68%)]	Loss: -10.2513	Cost: 5.97s
Train Epoch: 841 [81920/90000 (91%)]	Loss: -9.9507	Cost: 5.68s
Train Epoch: 841 	Average Loss: -9.5968
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.5695

Learning rate: 0.000124716813411004
Re-generating waveforms for posterior prior.
Train Epoch: 842 [0/90000 (0%)]	Loss: -1.4529	Cost: 25.00s
Train Epoch: 842 [20480/90000 (23%)]	Loss: -9.7698	Cost: 6.16s
Train Epoch: 842 [40960/90000 (45%)]	Loss: -9.6630	Cost: 7.34s
Train Epoch: 842 [61440/90000 (68%)]	Loss: -8.3165	Cost: 5.82s
Train Epoch: 842 [81920/90000 (91%)]	Loss: -8.6665	Cost: 6.05s
Train Epoch: 842 	Average Loss: -8.6664
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.8371

Learning rate: 0.00012456457711924255
Re-generating waveforms for posterior prior.
Train Epoch: 843 [0/90000 (0%)]	Loss: -0.6318	Cost: 24.52s
Train Epoch: 843 [20480/90000 (23%)]	Loss: -9.3648	Cost: 6.13s
Train Epoch: 843 [40960/90000 (45%)]	Loss: -9.3067	Cost: 7.13s
Train Epoch: 843 [61440/90000 (68%)]	Loss: -9.5751	Cost: 5.97s
Train Epoch: 843 [81920/90000 (91%)]	Loss: -10.1152	Cost: 5.91s
Train Epoch: 843 	Average Loss: -8.8424
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.8620

Learning rate: 0.00012441228021682895
Re-generating waveforms for posterior prior.
Train Epoch: 844 [0/90000 (0%)]	Loss: -2.0612	Cost: 24.04s
Train Epoch: 844 [20480/90000 (23%)]	Loss: -10.1273	Cost: 6.17s
Train Epoch: 844 [40960/90000 (45%)]	Loss: -9.3998	Cost: 7.08s
Train Epoch: 844 [61440/90000 (68%)]	Loss: -9.8241	Cost: 5.88s
Train Epoch: 844 [81920/90000 (91%)]	Loss: -10.0534	Cost: 6.14s
Train Epoch: 844 	Average Loss: -9.2646
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.6398

Learning rate: 0.00012425992307954067
Re-generating waveforms for posterior prior.
Train Epoch: 845 [0/90000 (0%)]	Loss: -1.0889	Cost: 23.90s
Train Epoch: 845 [20480/90000 (23%)]	Loss: -10.2620	Cost: 6.14s
Train Epoch: 845 [40960/90000 (45%)]	Loss: -9.6807	Cost: 7.41s
Train Epoch: 845 [61440/90000 (68%)]	Loss: -10.2159	Cost: 5.83s
Train Epoch: 845 [81920/90000 (91%)]	Loss: -10.4179	Cost: 6.06s
Train Epoch: 845 	Average Loss: -9.5179
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.9063

Learning rate: 0.0001241075060833038
Re-generating waveforms for posterior prior.
Train Epoch: 846 [0/90000 (0%)]	Loss: -1.9381	Cost: 23.98s
Train Epoch: 846 [20480/90000 (23%)]	Loss: -10.3475	Cost: 6.14s
Train Epoch: 846 [40960/90000 (45%)]	Loss: -9.9438	Cost: 7.48s
Train Epoch: 846 [61440/90000 (68%)]	Loss: -10.2422	Cost: 5.85s
Train Epoch: 846 [81920/90000 (91%)]	Loss: -10.3769	Cost: 5.88s
Train Epoch: 846 	Average Loss: -9.6477
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1139

Learning rate: 0.00012395502960419212
Re-generating waveforms for posterior prior.
Train Epoch: 847 [0/90000 (0%)]	Loss: -1.8371	Cost: 24.23s
Train Epoch: 847 [20480/90000 (23%)]	Loss: -10.5704	Cost: 6.12s
Train Epoch: 847 [40960/90000 (45%)]	Loss: -10.0546	Cost: 6.54s
Train Epoch: 847 [61440/90000 (68%)]	Loss: -10.3075	Cost: 5.91s
Train Epoch: 847 [81920/90000 (91%)]	Loss: -10.5034	Cost: 5.79s
Train Epoch: 847 	Average Loss: -9.7764
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1530

Learning rate: 0.00012380249401842616
Re-generating waveforms for posterior prior.
Train Epoch: 848 [0/90000 (0%)]	Loss: -2.4391	Cost: 24.53s
Train Epoch: 848 [20480/90000 (23%)]	Loss: -10.6634	Cost: 6.14s
Train Epoch: 848 [40960/90000 (45%)]	Loss: -10.1483	Cost: 6.72s
Train Epoch: 848 [61440/90000 (68%)]	Loss: -10.3486	Cost: 6.29s
Train Epoch: 848 [81920/90000 (91%)]	Loss: -10.6178	Cost: 6.21s
Train Epoch: 848 	Average Loss: -9.8438
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1066

Learning rate: 0.0001236498997023724
Re-generating waveforms for posterior prior.
Train Epoch: 849 [0/90000 (0%)]	Loss: -2.1791	Cost: 24.30s
Train Epoch: 849 [20480/90000 (23%)]	Loss: -10.5189	Cost: 6.13s
Train Epoch: 849 [40960/90000 (45%)]	Loss: -9.8954	Cost: 7.49s
Train Epoch: 849 [61440/90000 (68%)]	Loss: -10.0774	Cost: 5.84s
Train Epoch: 849 [81920/90000 (91%)]	Loss: -10.2967	Cost: 6.01s
Train Epoch: 849 	Average Loss: -9.7150
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.9609

Learning rate: 0.00012349724703254207
Re-generating waveforms for posterior prior.
Train Epoch: 850 [0/90000 (0%)]	Loss: -2.2364	Cost: 24.45s
Train Epoch: 850 [20480/90000 (23%)]	Loss: -10.3488	Cost: 6.14s
Train Epoch: 850 [40960/90000 (45%)]	Loss: -10.1393	Cost: 7.31s
Train Epoch: 850 [61440/90000 (68%)]	Loss: -10.4781	Cost: 5.82s
Train Epoch: 850 [81920/90000 (91%)]	Loss: -10.6385	Cost: 5.89s
Train Epoch: 850 	Average Loss: -9.8114
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1863

Saving model as model_sample_from_all_posterior.pt_e850 & waveforms_supplementary_sample_from_all_posterior.hdf5_e850
Learning rate: 0.0001233445363855905
Re-generating waveforms for posterior prior.
Train Epoch: 851 [0/90000 (0%)]	Loss: -2.2461	Cost: 24.20s
Train Epoch: 851 [20480/90000 (23%)]	Loss: -10.4430	Cost: 6.11s
Train Epoch: 851 [40960/90000 (45%)]	Loss: -10.0102	Cost: 7.27s
Train Epoch: 851 [61440/90000 (68%)]	Loss: -10.3751	Cost: 5.84s
Train Epoch: 851 [81920/90000 (91%)]	Loss: -10.5438	Cost: 5.98s
Train Epoch: 851 	Average Loss: -9.8027
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.9586

Learning rate: 0.00012319176813831595
Re-generating waveforms for posterior prior.
Train Epoch: 852 [0/90000 (0%)]	Loss: -2.6200	Cost: 24.06s
Train Epoch: 852 [20480/90000 (23%)]	Loss: -10.5666	Cost: 6.11s
Train Epoch: 852 [40960/90000 (45%)]	Loss: -10.3144	Cost: 7.15s
Train Epoch: 852 [61440/90000 (68%)]	Loss: -10.5974	Cost: 6.00s
Train Epoch: 852 [81920/90000 (91%)]	Loss: -10.3986	Cost: 5.77s
Train Epoch: 852 	Average Loss: -9.8654
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.0263

Learning rate: 0.000123038942667659
Re-generating waveforms for posterior prior.
Train Epoch: 853 [0/90000 (0%)]	Loss: -2.3677	Cost: 24.10s
Train Epoch: 853 [20480/90000 (23%)]	Loss: -10.7047	Cost: 6.10s
Train Epoch: 853 [40960/90000 (45%)]	Loss: -9.9721	Cost: 7.47s
Train Epoch: 853 [61440/90000 (68%)]	Loss: -10.2638	Cost: 5.90s
Train Epoch: 853 [81920/90000 (91%)]	Loss: -10.4519	Cost: 6.01s
Train Epoch: 853 	Average Loss: -9.7110
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.9542

Learning rate: 0.00012288606035070125
Re-generating waveforms for posterior prior.
Train Epoch: 854 [0/90000 (0%)]	Loss: -1.9808	Cost: 24.67s
Train Epoch: 854 [20480/90000 (23%)]	Loss: -10.5336	Cost: 6.12s
Train Epoch: 854 [40960/90000 (45%)]	Loss: -10.1187	Cost: 7.45s
Train Epoch: 854 [61440/90000 (68%)]	Loss: -10.4648	Cost: 5.81s
Train Epoch: 854 [81920/90000 (91%)]	Loss: -10.6502	Cost: 5.81s
Train Epoch: 854 	Average Loss: -9.8866
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1103

Learning rate: 0.0001227331215646646
Re-generating waveforms for posterior prior.
Train Epoch: 855 [0/90000 (0%)]	Loss: -1.8826	Cost: 24.90s
Train Epoch: 855 [20480/90000 (23%)]	Loss: -10.5602	Cost: 6.12s
Train Epoch: 855 [40960/90000 (45%)]	Loss: -10.0315	Cost: 7.01s
Train Epoch: 855 [61440/90000 (68%)]	Loss: -10.6598	Cost: 5.86s
Train Epoch: 855 [81920/90000 (91%)]	Loss: -10.5489	Cost: 6.17s
Train Epoch: 855 	Average Loss: -9.8355
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1022

Learning rate: 0.00012258012668691032
Re-generating waveforms for posterior prior.
Train Epoch: 856 [0/90000 (0%)]	Loss: -1.6607	Cost: 24.04s
Train Epoch: 856 [20480/90000 (23%)]	Loss: -10.1063	Cost: 6.16s
Train Epoch: 856 [40960/90000 (45%)]	Loss: -9.6649	Cost: 7.44s
Train Epoch: 856 [61440/90000 (68%)]	Loss: -10.1121	Cost: 5.87s
Train Epoch: 856 [81920/90000 (91%)]	Loss: -10.4586	Cost: 6.03s
Train Epoch: 856 	Average Loss: -9.5684
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.9276

Learning rate: 0.00012242707609493806
Re-generating waveforms for posterior prior.
Train Epoch: 857 [0/90000 (0%)]	Loss: -1.8037	Cost: 23.91s
Train Epoch: 857 [20480/90000 (23%)]	Loss: -10.4218	Cost: 6.15s
Train Epoch: 857 [40960/90000 (45%)]	Loss: -10.0026	Cost: 7.23s
Train Epoch: 857 [61440/90000 (68%)]	Loss: -10.3738	Cost: 5.94s
Train Epoch: 857 [81920/90000 (91%)]	Loss: -10.6169	Cost: 6.06s
Train Epoch: 857 	Average Loss: -9.7510
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1681

Learning rate: 0.00012227397016638494
Re-generating waveforms for posterior prior.
Train Epoch: 858 [0/90000 (0%)]	Loss: -2.2493	Cost: 24.04s
Train Epoch: 858 [20480/90000 (23%)]	Loss: -10.6460	Cost: 6.12s
Train Epoch: 858 [40960/90000 (45%)]	Loss: -10.3749	Cost: 7.38s
Train Epoch: 858 [61440/90000 (68%)]	Loss: -10.4849	Cost: 5.81s
Train Epoch: 858 [81920/90000 (91%)]	Loss: -10.7863	Cost: 6.24s
Train Epoch: 858 	Average Loss: -9.9620
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1165

Learning rate: 0.00012212080927902466
Re-generating waveforms for posterior prior.
Train Epoch: 859 [0/90000 (0%)]	Loss: -2.2296	Cost: 24.71s
Train Epoch: 859 [20480/90000 (23%)]	Loss: -10.8365	Cost: 6.08s
Train Epoch: 859 [40960/90000 (45%)]	Loss: -10.1865	Cost: 7.47s
Train Epoch: 859 [61440/90000 (68%)]	Loss: -10.6158	Cost: 5.77s
Train Epoch: 859 [81920/90000 (91%)]	Loss: -10.7992	Cost: 6.03s
Train Epoch: 859 	Average Loss: -10.0449
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1015

Learning rate: 0.00012196759381076645
Re-generating waveforms for posterior prior.
Train Epoch: 860 [0/90000 (0%)]	Loss: -1.9340	Cost: 24.68s
Train Epoch: 860 [20480/90000 (23%)]	Loss: -10.5071	Cost: 6.11s
Train Epoch: 860 [40960/90000 (45%)]	Loss: -10.2352	Cost: 6.56s
Train Epoch: 860 [61440/90000 (68%)]	Loss: -10.5253	Cost: 5.86s
Train Epoch: 860 [81920/90000 (91%)]	Loss: -10.8001	Cost: 6.06s
Train Epoch: 860 	Average Loss: -9.9205
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.2438

Learning rate: 0.00012181432413965421
Re-generating waveforms for posterior prior.
Train Epoch: 861 [0/90000 (0%)]	Loss: -1.9316	Cost: 25.85s
Train Epoch: 861 [20480/90000 (23%)]	Loss: -10.7320	Cost: 6.07s
Train Epoch: 861 [40960/90000 (45%)]	Loss: -9.7268	Cost: 6.78s
Train Epoch: 861 [61440/90000 (68%)]	Loss: -9.8742	Cost: 5.86s
Train Epoch: 861 [81920/90000 (91%)]	Loss: -10.3268	Cost: 5.92s
Train Epoch: 861 	Average Loss: -9.6164
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.9432

Learning rate: 0.00012166100064386567
Re-generating waveforms for posterior prior.
Train Epoch: 862 [0/90000 (0%)]	Loss: -2.1205	Cost: 24.26s
Train Epoch: 862 [20480/90000 (23%)]	Loss: -10.5451	Cost: 6.11s
Train Epoch: 862 [40960/90000 (45%)]	Loss: -9.9622	Cost: 6.42s
Train Epoch: 862 [61440/90000 (68%)]	Loss: -10.3948	Cost: 5.90s
Train Epoch: 862 [81920/90000 (91%)]	Loss: -10.6301	Cost: 5.67s
Train Epoch: 862 	Average Loss: -9.8319
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.0482

Learning rate: 0.00012150762370171128
Re-generating waveforms for posterior prior.
Train Epoch: 863 [0/90000 (0%)]	Loss: -2.0555	Cost: 24.98s
Train Epoch: 863 [20480/90000 (23%)]	Loss: -10.7090	Cost: 6.13s
Train Epoch: 863 [40960/90000 (45%)]	Loss: -10.4138	Cost: 7.41s
Train Epoch: 863 [61440/90000 (68%)]	Loss: -10.3178	Cost: 5.82s
Train Epoch: 863 [81920/90000 (91%)]	Loss: -10.6852	Cost: 5.76s
Train Epoch: 863 	Average Loss: -9.9179
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.0665

Learning rate: 0.00012135419369163344
Re-generating waveforms for posterior prior.
Train Epoch: 864 [0/90000 (0%)]	Loss: -2.0584	Cost: 24.82s
Train Epoch: 864 [20480/90000 (23%)]	Loss: -10.5736	Cost: 6.09s
Train Epoch: 864 [40960/90000 (45%)]	Loss: -9.9732	Cost: 7.41s
Train Epoch: 864 [61440/90000 (68%)]	Loss: -10.2939	Cost: 5.83s
Train Epoch: 864 [81920/90000 (91%)]	Loss: -10.7470	Cost: 5.88s
Train Epoch: 864 	Average Loss: -9.7635
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1945

Learning rate: 0.00012120071099220544
Re-generating waveforms for posterior prior.
Train Epoch: 865 [0/90000 (0%)]	Loss: -2.1146	Cost: 24.68s
Train Epoch: 865 [20480/90000 (23%)]	Loss: -10.8580	Cost: 6.08s
Train Epoch: 865 [40960/90000 (45%)]	Loss: -10.2371	Cost: 7.26s
Train Epoch: 865 [61440/90000 (68%)]	Loss: -10.8234	Cost: 5.84s
Train Epoch: 865 [81920/90000 (91%)]	Loss: -10.9483	Cost: 5.92s
Train Epoch: 865 	Average Loss: -10.0225
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.2816

Learning rate: 0.0001210471759821305
Re-generating waveforms for posterior prior.
Train Epoch: 866 [0/90000 (0%)]	Loss: -2.2832	Cost: 24.63s
Train Epoch: 866 [20480/90000 (23%)]	Loss: -10.8491	Cost: 6.10s
Train Epoch: 866 [40960/90000 (45%)]	Loss: -10.3993	Cost: 7.60s
Train Epoch: 866 [61440/90000 (68%)]	Loss: -10.6000	Cost: 5.81s
Train Epoch: 866 [81920/90000 (91%)]	Loss: -10.7557	Cost: 5.80s
Train Epoch: 866 	Average Loss: -10.0185
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.0737

Learning rate: 0.00012089358904024111
Re-generating waveforms for posterior prior.
Train Epoch: 867 [0/90000 (0%)]	Loss: -2.3901	Cost: 24.02s
Train Epoch: 867 [20480/90000 (23%)]	Loss: -10.7293	Cost: 6.13s
Train Epoch: 867 [40960/90000 (45%)]	Loss: -10.2534	Cost: 6.92s
Train Epoch: 867 [61440/90000 (68%)]	Loss: -10.5707	Cost: 5.90s
Train Epoch: 867 [81920/90000 (91%)]	Loss: -10.7306	Cost: 6.08s
Train Epoch: 867 	Average Loss: -10.0093
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1801

Learning rate: 0.00012073995054549775
Re-generating waveforms for posterior prior.
Train Epoch: 868 [0/90000 (0%)]	Loss: -2.2750	Cost: 24.43s
Train Epoch: 868 [20480/90000 (23%)]	Loss: -10.8436	Cost: 6.17s
Train Epoch: 868 [40960/90000 (45%)]	Loss: -10.4578	Cost: 6.83s
Train Epoch: 868 [61440/90000 (68%)]	Loss: -10.8463	Cost: 5.87s
Train Epoch: 868 [81920/90000 (91%)]	Loss: -11.0018	Cost: 5.86s
Train Epoch: 868 	Average Loss: -10.1689
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.3217

Learning rate: 0.00012058626087698809
Re-generating waveforms for posterior prior.
Train Epoch: 869 [0/90000 (0%)]	Loss: -2.3604	Cost: 24.56s
Train Epoch: 869 [20480/90000 (23%)]	Loss: -11.0823	Cost: 6.12s
Train Epoch: 869 [40960/90000 (45%)]	Loss: -10.4389	Cost: 7.26s
Train Epoch: 869 [61440/90000 (68%)]	Loss: -10.7122	Cost: 5.83s
Train Epoch: 869 [81920/90000 (91%)]	Loss: -10.9467	Cost: 6.06s
Train Epoch: 869 	Average Loss: -10.1645
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.3304

Learning rate: 0.00012043252041392612
Re-generating waveforms for posterior prior.
Train Epoch: 870 [0/90000 (0%)]	Loss: -2.5645	Cost: 24.79s
Train Epoch: 870 [20480/90000 (23%)]	Loss: -11.0873	Cost: 6.09s
Train Epoch: 870 [40960/90000 (45%)]	Loss: -10.2858	Cost: 7.48s
Train Epoch: 870 [61440/90000 (68%)]	Loss: -10.5558	Cost: 5.81s
Train Epoch: 870 [81920/90000 (91%)]	Loss: -10.6277	Cost: 5.80s
Train Epoch: 870 	Average Loss: -10.1286
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.3444

Learning rate: 0.00012027872953565117
Re-generating waveforms for posterior prior.
Train Epoch: 871 [0/90000 (0%)]	Loss: -2.4227	Cost: 24.76s
Train Epoch: 871 [20480/90000 (23%)]	Loss: -10.9974	Cost: 6.14s
Train Epoch: 871 [40960/90000 (45%)]	Loss: -10.5223	Cost: 6.45s
Train Epoch: 871 [61440/90000 (68%)]	Loss: -10.8373	Cost: 5.90s
Train Epoch: 871 [81920/90000 (91%)]	Loss: -10.9599	Cost: 5.76s
Train Epoch: 871 	Average Loss: -10.1487
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.2867

Learning rate: 0.00012012488862162697
Re-generating waveforms for posterior prior.
Train Epoch: 872 [0/90000 (0%)]	Loss: -2.4491	Cost: 25.53s
Train Epoch: 872 [20480/90000 (23%)]	Loss: -11.1080	Cost: 6.10s
Train Epoch: 872 [40960/90000 (45%)]	Loss: -10.6314	Cost: 6.82s
Train Epoch: 872 [61440/90000 (68%)]	Loss: -11.0741	Cost: 5.95s
Train Epoch: 872 [81920/90000 (91%)]	Loss: -11.0548	Cost: 5.94s
Train Epoch: 872 	Average Loss: -10.3242
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.3656

Learning rate: 0.00011997099805144064
Re-generating waveforms for posterior prior.
Train Epoch: 873 [0/90000 (0%)]	Loss: -2.3150	Cost: 26.12s
Train Epoch: 873 [20480/90000 (23%)]	Loss: -11.1482	Cost: 6.24s
Train Epoch: 873 [40960/90000 (45%)]	Loss: -10.6764	Cost: 6.66s
Train Epoch: 873 [61440/90000 (68%)]	Loss: -11.0065	Cost: 5.88s
Train Epoch: 873 [81920/90000 (91%)]	Loss: -11.0519	Cost: 6.06s
Train Epoch: 873 	Average Loss: -10.2935
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.4432

Learning rate: 0.00011981705820480187
Re-generating waveforms for posterior prior.
Train Epoch: 874 [0/90000 (0%)]	Loss: -2.2328	Cost: 24.78s
Train Epoch: 874 [20480/90000 (23%)]	Loss: -11.1800	Cost: 6.11s
Train Epoch: 874 [40960/90000 (45%)]	Loss: -10.6808	Cost: 7.18s
Train Epoch: 874 [61440/90000 (68%)]	Loss: -10.4775	Cost: 5.84s
Train Epoch: 874 [81920/90000 (91%)]	Loss: -10.4745	Cost: 6.03s
Train Epoch: 874 	Average Loss: -10.2175
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.1342

Learning rate: 0.00011966306946154192
Re-generating waveforms for posterior prior.
Train Epoch: 875 [0/90000 (0%)]	Loss: -2.0322	Cost: 24.64s
Train Epoch: 875 [20480/90000 (23%)]	Loss: -10.9697	Cost: 6.12s
Train Epoch: 875 [40960/90000 (45%)]	Loss: -10.4741	Cost: 7.41s
Train Epoch: 875 [61440/90000 (68%)]	Loss: -10.7019	Cost: 5.83s
Train Epoch: 875 [81920/90000 (91%)]	Loss: -10.4780	Cost: 6.00s
Train Epoch: 875 	Average Loss: -10.0214
Re-generating waveforms for posterior prior.
Test set: Average loss: -1.9821

Learning rate: 0.00011950903220161275
Re-generating waveforms for posterior prior.
Train Epoch: 876 [0/90000 (0%)]	Loss: -2.5738	Cost: 24.44s
Train Epoch: 876 [20480/90000 (23%)]	Loss: -10.9288	Cost: 6.15s
Train Epoch: 876 [40960/90000 (45%)]	Loss: -10.4411	Cost: 6.72s
Train Epoch: 876 [61440/90000 (68%)]	Loss: -10.9336	Cost: 5.86s
Train Epoch: 876 [81920/90000 (91%)]	Loss: -11.0704	Cost: 6.13s
Train Epoch: 876 	Average Loss: -10.1949
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.4145

Learning rate: 0.00011935494680508593
Re-generating waveforms for posterior prior.
Train Epoch: 877 [0/90000 (0%)]	Loss: -3.0198	Cost: 24.55s
Train Epoch: 877 [20480/90000 (23%)]	Loss: -10.9616	Cost: 6.08s
Train Epoch: 877 [40960/90000 (45%)]	Loss: -10.4575	Cost: 6.98s
Train Epoch: 877 [61440/90000 (68%)]	Loss: -10.8684	Cost: 5.90s
Train Epoch: 877 [81920/90000 (91%)]	Loss: -10.8949	Cost: 5.91s
Train Epoch: 877 	Average Loss: -10.2768
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.3787

Learning rate: 0.0001192008136521519
Re-generating waveforms for posterior prior.
Train Epoch: 878 [0/90000 (0%)]	Loss: -1.6495	Cost: 25.72s
Train Epoch: 878 [20480/90000 (23%)]	Loss: -10.8612	Cost: 6.18s
Train Epoch: 878 [40960/90000 (45%)]	Loss: -10.5947	Cost: 7.11s
Train Epoch: 878 [61440/90000 (68%)]	Loss: -10.8722	Cost: 5.84s
Train Epoch: 878 [81920/90000 (91%)]	Loss: -11.1234	Cost: 5.86s
Train Epoch: 878 	Average Loss: -10.2848
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.5517

Learning rate: 0.00011904663312311891
Re-generating waveforms for posterior prior.
Train Epoch: 879 [0/90000 (0%)]	Loss: -3.0054	Cost: 24.17s
Train Epoch: 879 [20480/90000 (23%)]	Loss: -11.0616	Cost: 6.17s
Train Epoch: 879 [40960/90000 (45%)]	Loss: -10.7200	Cost: 7.20s
Train Epoch: 879 [61440/90000 (68%)]	Loss: -10.9999	Cost: 5.84s
Train Epoch: 879 [81920/90000 (91%)]	Loss: -11.1044	Cost: 5.79s
Train Epoch: 879 	Average Loss: -10.3552
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.3001

Learning rate: 0.00011889240559841206
Re-generating waveforms for posterior prior.
Train Epoch: 880 [0/90000 (0%)]	Loss: -2.1534	Cost: 24.37s
Train Epoch: 880 [20480/90000 (23%)]	Loss: -10.9750	Cost: 6.11s
Train Epoch: 880 [40960/90000 (45%)]	Loss: -10.5078	Cost: 7.48s
Train Epoch: 880 [61440/90000 (68%)]	Loss: -10.9420	Cost: 5.85s
Train Epoch: 880 [81920/90000 (91%)]	Loss: -10.9502	Cost: 6.11s
Train Epoch: 880 	Average Loss: -10.1964
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.2534

Learning rate: 0.00011873813145857238
Re-generating waveforms for posterior prior.
Train Epoch: 881 [0/90000 (0%)]	Loss: -2.2406	Cost: 24.87s
Train Epoch: 881 [20480/90000 (23%)]	Loss: -10.9360	Cost: 6.12s
Train Epoch: 881 [40960/90000 (45%)]	Loss: -10.3012	Cost: 7.53s
Train Epoch: 881 [61440/90000 (68%)]	Loss: -10.6743	Cost: 5.82s
Train Epoch: 881 [81920/90000 (91%)]	Loss: -10.7728	Cost: 5.85s
Train Epoch: 881 	Average Loss: -10.0853
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.4123

Learning rate: 0.00011858381108425605
Re-generating waveforms for posterior prior.
Train Epoch: 882 [0/90000 (0%)]	Loss: -2.2484	Cost: 25.33s
Train Epoch: 882 [20480/90000 (23%)]	Loss: -10.8253	Cost: 6.10s
Train Epoch: 882 [40960/90000 (45%)]	Loss: -10.5727	Cost: 7.25s
Train Epoch: 882 [61440/90000 (68%)]	Loss: -11.0259	Cost: 5.90s
Train Epoch: 882 [81920/90000 (91%)]	Loss: -10.7915	Cost: 5.86s
Train Epoch: 882 	Average Loss: -10.1978
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.2532

Learning rate: 0.00011842944485623326
Re-generating waveforms for posterior prior.
Train Epoch: 883 [0/90000 (0%)]	Loss: -2.0321	Cost: 24.38s
Train Epoch: 883 [20480/90000 (23%)]	Loss: -10.7373	Cost: 6.15s
Train Epoch: 883 [40960/90000 (45%)]	Loss: -10.3604	Cost: 7.26s
Train Epoch: 883 [61440/90000 (68%)]	Loss: -10.9561	Cost: 5.86s
Train Epoch: 883 [81920/90000 (91%)]	Loss: -11.0919	Cost: 5.96s
Train Epoch: 883 	Average Loss: -10.1664
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.5294

Learning rate: 0.00011827503315538728
Re-generating waveforms for posterior prior.
Train Epoch: 884 [0/90000 (0%)]	Loss: -2.2854	Cost: 24.85s
Train Epoch: 884 [20480/90000 (23%)]	Loss: -11.1758	Cost: 6.13s
Train Epoch: 884 [40960/90000 (45%)]	Loss: -10.6289	Cost: 6.82s
Train Epoch: 884 [61440/90000 (68%)]	Loss: -11.0662	Cost: 5.88s
Train Epoch: 884 [81920/90000 (91%)]	Loss: -11.3042	Cost: 6.09s
Train Epoch: 884 	Average Loss: -10.4351
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.7048

Learning rate: 0.00011812057636271365
Re-generating waveforms for posterior prior.
Train Epoch: 885 [0/90000 (0%)]	Loss: -2.5944	Cost: 24.42s
Train Epoch: 885 [20480/90000 (23%)]	Loss: -11.3881	Cost: 6.15s
Train Epoch: 885 [40960/90000 (45%)]	Loss: -10.8417	Cost: 6.63s
Train Epoch: 885 [61440/90000 (68%)]	Loss: -11.1849	Cost: 5.92s
Train Epoch: 885 [81920/90000 (91%)]	Loss: -11.3807	Cost: 6.10s
Train Epoch: 885 	Average Loss: -10.5265
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.7793

Learning rate: 0.00011796607485931917
Re-generating waveforms for posterior prior.
Train Epoch: 886 [0/90000 (0%)]	Loss: -3.0431	Cost: 24.36s
Train Epoch: 886 [20480/90000 (23%)]	Loss: -11.2916	Cost: 6.15s
Train Epoch: 886 [40960/90000 (45%)]	Loss: -10.9278	Cost: 7.16s
Train Epoch: 886 [61440/90000 (68%)]	Loss: -11.3763	Cost: 5.90s
Train Epoch: 886 [81920/90000 (91%)]	Loss: -11.5004	Cost: 5.99s
Train Epoch: 886 	Average Loss: -10.6452
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.6826

Learning rate: 0.0001178115290264209
Re-generating waveforms for posterior prior.
Train Epoch: 887 [0/90000 (0%)]	Loss: -2.9396	Cost: 24.07s
Train Epoch: 887 [20480/90000 (23%)]	Loss: -11.6486	Cost: 6.13s
Train Epoch: 887 [40960/90000 (45%)]	Loss: -10.8643	Cost: 7.18s
Train Epoch: 887 [61440/90000 (68%)]	Loss: -11.1578	Cost: 5.84s
Train Epoch: 887 [81920/90000 (91%)]	Loss: -11.3160	Cost: 6.10s
Train Epoch: 887 	Average Loss: -10.5676
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.6202

Learning rate: 0.00011765693924534537
Re-generating waveforms for posterior prior.
Train Epoch: 888 [0/90000 (0%)]	Loss: -2.7654	Cost: 24.11s
Train Epoch: 888 [20480/90000 (23%)]	Loss: -11.5635	Cost: 6.16s
Train Epoch: 888 [40960/90000 (45%)]	Loss: -10.9586	Cost: 6.78s
Train Epoch: 888 [61440/90000 (68%)]	Loss: -11.3534	Cost: 5.87s
Train Epoch: 888 [81920/90000 (91%)]	Loss: -11.3458	Cost: 6.18s
Train Epoch: 888 	Average Loss: -10.6470
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.4698

Learning rate: 0.0001175023058975275
Re-generating waveforms for posterior prior.
Train Epoch: 889 [0/90000 (0%)]	Loss: -2.8600	Cost: 24.19s
Train Epoch: 889 [20480/90000 (23%)]	Loss: -11.3599	Cost: 6.11s
Train Epoch: 889 [40960/90000 (45%)]	Loss: -11.0559	Cost: 7.47s
Train Epoch: 889 [61440/90000 (68%)]	Loss: -11.2665	Cost: 5.85s
Train Epoch: 889 [81920/90000 (91%)]	Loss: -11.0590	Cost: 6.19s
Train Epoch: 889 	Average Loss: -10.6003
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.5244

Learning rate: 0.00011734762936450966
Re-generating waveforms for posterior prior.
Train Epoch: 890 [0/90000 (0%)]	Loss: -2.6083	Cost: 24.69s
Train Epoch: 890 [20480/90000 (23%)]	Loss: -11.2363	Cost: 6.10s
Train Epoch: 890 [40960/90000 (45%)]	Loss: -10.7597	Cost: 7.41s
Train Epoch: 890 [61440/90000 (68%)]	Loss: -11.1409	Cost: 5.83s
Train Epoch: 890 [81920/90000 (91%)]	Loss: -11.2210	Cost: 5.82s
Train Epoch: 890 	Average Loss: -10.4585
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.6105

Learning rate: 0.00011719291002794086
Re-generating waveforms for posterior prior.
Train Epoch: 891 [0/90000 (0%)]	Loss: -2.4612	Cost: 24.64s
Train Epoch: 891 [20480/90000 (23%)]	Loss: -10.5738	Cost: 6.13s
Train Epoch: 891 [40960/90000 (45%)]	Loss: -10.1668	Cost: 7.40s
Train Epoch: 891 [61440/90000 (68%)]	Loss: -10.7149	Cost: 5.84s
Train Epoch: 891 [81920/90000 (91%)]	Loss: -10.9149	Cost: 6.07s
Train Epoch: 891 	Average Loss: -10.0711
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.4682

Learning rate: 0.00011703814826957564
Re-generating waveforms for posterior prior.
Train Epoch: 892 [0/90000 (0%)]	Loss: -2.3307	Cost: 24.63s
Train Epoch: 892 [20480/90000 (23%)]	Loss: -11.3023	Cost: 6.11s
Train Epoch: 892 [40960/90000 (45%)]	Loss: -10.8861	Cost: 7.25s
Train Epoch: 892 [61440/90000 (68%)]	Loss: -11.2782	Cost: 5.91s
Train Epoch: 892 [81920/90000 (91%)]	Loss: -11.3453	Cost: 5.98s
Train Epoch: 892 	Average Loss: -10.5431
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.7079

Learning rate: 0.00011688334447127327
Re-generating waveforms for posterior prior.
Train Epoch: 893 [0/90000 (0%)]	Loss: -2.7110	Cost: 25.02s
Train Epoch: 893 [20480/90000 (23%)]	Loss: -11.4748	Cost: 6.16s
Train Epoch: 893 [40960/90000 (45%)]	Loss: -10.8574	Cost: 7.47s
Train Epoch: 893 [61440/90000 (68%)]	Loss: -11.3227	Cost: 5.83s
Train Epoch: 893 [81920/90000 (91%)]	Loss: -11.3709	Cost: 5.87s
Train Epoch: 893 	Average Loss: -10.6566
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.7967

Learning rate: 0.00011672849901499676
Re-generating waveforms for posterior prior.
Train Epoch: 894 [0/90000 (0%)]	Loss: -2.6387	Cost: 24.81s
Train Epoch: 894 [20480/90000 (23%)]	Loss: -11.4742	Cost: 6.15s
Train Epoch: 894 [40960/90000 (45%)]	Loss: -10.9119	Cost: 7.31s
Train Epoch: 894 [61440/90000 (68%)]	Loss: -11.3720	Cost: 5.85s
Train Epoch: 894 [81920/90000 (91%)]	Loss: -11.4398	Cost: 6.02s
Train Epoch: 894 	Average Loss: -10.7328
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.7854

Learning rate: 0.00011657361228281188
Re-generating waveforms for posterior prior.
Train Epoch: 895 [0/90000 (0%)]	Loss: -2.7952	Cost: 24.40s
Train Epoch: 895 [20480/90000 (23%)]	Loss: -11.5985	Cost: 6.13s
Train Epoch: 895 [40960/90000 (45%)]	Loss: -11.0167	Cost: 7.31s
Train Epoch: 895 [61440/90000 (68%)]	Loss: -11.2332	Cost: 5.95s
Train Epoch: 895 [81920/90000 (91%)]	Loss: -11.4288	Cost: 5.71s
Train Epoch: 895 	Average Loss: -10.7668
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.7715

Learning rate: 0.0001164186846568862
Re-generating waveforms for posterior prior.
Train Epoch: 896 [0/90000 (0%)]	Loss: -3.4636	Cost: 24.29s
Train Epoch: 896 [20480/90000 (23%)]	Loss: -11.4279	Cost: 6.14s
Train Epoch: 896 [40960/90000 (45%)]	Loss: -11.1152	Cost: 7.42s
Train Epoch: 896 [61440/90000 (68%)]	Loss: -11.3192	Cost: 5.86s
Train Epoch: 896 [81920/90000 (91%)]	Loss: -11.6575	Cost: 6.27s
Train Epoch: 896 	Average Loss: -10.7356
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.7277

Learning rate: 0.00011626371651948827
Re-generating waveforms for posterior prior.
Train Epoch: 897 [0/90000 (0%)]	Loss: -3.2715	Cost: 26.26s
Train Epoch: 897 [20480/90000 (23%)]	Loss: -11.6754	Cost: 6.07s
Train Epoch: 897 [40960/90000 (45%)]	Loss: -11.1875	Cost: 7.16s
Train Epoch: 897 [61440/90000 (68%)]	Loss: -11.4784	Cost: 5.86s
Train Epoch: 897 [81920/90000 (91%)]	Loss: -11.5967	Cost: 6.01s
Train Epoch: 897 	Average Loss: -10.8042
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.9562

Learning rate: 0.00011610870825298657
Re-generating waveforms for posterior prior.
Train Epoch: 898 [0/90000 (0%)]	Loss: -2.7501	Cost: 24.82s
Train Epoch: 898 [20480/90000 (23%)]	Loss: -11.4588	Cost: 6.12s
Train Epoch: 898 [40960/90000 (45%)]	Loss: -10.7438	Cost: 7.59s
Train Epoch: 898 [61440/90000 (68%)]	Loss: -11.2435	Cost: 5.81s
Train Epoch: 898 [81920/90000 (91%)]	Loss: -11.3129	Cost: 5.93s
Train Epoch: 898 	Average Loss: -10.6179
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.4658

Learning rate: 0.0001159536602398485
Re-generating waveforms for posterior prior.
Train Epoch: 899 [0/90000 (0%)]	Loss: -3.3247	Cost: 24.68s
Train Epoch: 899 [20480/90000 (23%)]	Loss: -11.1037	Cost: 6.12s
Train Epoch: 899 [40960/90000 (45%)]	Loss: -10.3613	Cost: 7.32s
Train Epoch: 899 [61440/90000 (68%)]	Loss: -11.0540	Cost: 5.81s
Train Epoch: 899 [81920/90000 (91%)]	Loss: -11.3365	Cost: 6.06s
Train Epoch: 899 	Average Loss: -10.3801
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.8026

Learning rate: 0.00011579857286263978
Re-generating waveforms for posterior prior.
Train Epoch: 900 [0/90000 (0%)]	Loss: -2.8742	Cost: 24.35s
Train Epoch: 900 [20480/90000 (23%)]	Loss: -11.3508	Cost: 6.12s
Train Epoch: 900 [40960/90000 (45%)]	Loss: -11.0821	Cost: 7.05s
Train Epoch: 900 [61440/90000 (68%)]	Loss: -11.3938	Cost: 5.82s
Train Epoch: 900 [81920/90000 (91%)]	Loss: -11.7363	Cost: 6.07s
Train Epoch: 900 	Average Loss: -10.7640
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.8213

Saving model as model_sample_from_all_posterior.pt_e900 & waveforms_supplementary_sample_from_all_posterior.hdf5_e900
Learning rate: 0.000115643446504023
Re-generating waveforms for posterior prior.
Train Epoch: 901 [0/90000 (0%)]	Loss: -3.0349	Cost: 24.53s
Train Epoch: 901 [20480/90000 (23%)]	Loss: -11.5830	Cost: 6.11s
Train Epoch: 901 [40960/90000 (45%)]	Loss: -11.0535	Cost: 7.45s
Train Epoch: 901 [61440/90000 (68%)]	Loss: -11.4630	Cost: 5.83s
Train Epoch: 901 [81920/90000 (91%)]	Loss: -11.7209	Cost: 5.87s
Train Epoch: 901 	Average Loss: -10.8724
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.8867

Learning rate: 0.00011548828154675702
Re-generating waveforms for posterior prior.
Train Epoch: 902 [0/90000 (0%)]	Loss: -3.5405	Cost: 24.77s
Train Epoch: 902 [20480/90000 (23%)]	Loss: -11.5725	Cost: 6.13s
Train Epoch: 902 [40960/90000 (45%)]	Loss: -11.0644	Cost: 7.22s
Train Epoch: 902 [61440/90000 (68%)]	Loss: -11.5312	Cost: 5.85s
Train Epoch: 902 [81920/90000 (91%)]	Loss: -11.7467	Cost: 5.91s
Train Epoch: 902 	Average Loss: -10.8707
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.7605

Learning rate: 0.00011533307837369596
Re-generating waveforms for posterior prior.
Train Epoch: 903 [0/90000 (0%)]	Loss: -2.4213	Cost: 24.74s
Train Epoch: 903 [20480/90000 (23%)]	Loss: -11.2978	Cost: 6.12s
Train Epoch: 903 [40960/90000 (45%)]	Loss: -10.9680	Cost: 7.41s
Train Epoch: 903 [61440/90000 (68%)]	Loss: -10.2687	Cost: 5.85s
Train Epoch: 903 [81920/90000 (91%)]	Loss: -8.3625	Cost: 6.02s
Train Epoch: 903 	Average Loss: -9.9156
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.4633

Learning rate: 0.00011517783736778825
Re-generating waveforms for posterior prior.
Train Epoch: 904 [0/90000 (0%)]	Loss: -0.6229	Cost: 24.85s
Train Epoch: 904 [20480/90000 (23%)]	Loss: -4.5825	Cost: 6.15s
Train Epoch: 904 [40960/90000 (45%)]	Loss: -5.3667	Cost: 7.49s
Train Epoch: 904 [61440/90000 (68%)]	Loss: -7.1351	Cost: 5.86s
Train Epoch: 904 [81920/90000 (91%)]	Loss: -8.4989	Cost: 6.09s
Train Epoch: 904 	Average Loss: -5.8779
Re-generating waveforms for posterior prior.
Test set: Average loss: -0.7857

Learning rate: 0.00011502255891207562
Re-generating waveforms for posterior prior.
Train Epoch: 905 [0/90000 (0%)]	Loss: -1.1632	Cost: 24.94s
Train Epoch: 905 [20480/90000 (23%)]	Loss: -9.1910	Cost: 6.15s
Train Epoch: 905 [40960/90000 (45%)]	Loss: -9.4852	Cost: 7.30s
Train Epoch: 905 [61440/90000 (68%)]	Loss: -10.0920	Cost: 5.81s
Train Epoch: 905 [81920/90000 (91%)]	Loss: -10.5801	Cost: 6.28s
Train Epoch: 905 	Average Loss: -9.1399
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.0976

Learning rate: 0.00011486724338969223
Re-generating waveforms for posterior prior.
Train Epoch: 906 [0/90000 (0%)]	Loss: -2.2927	Cost: 24.55s
Train Epoch: 906 [20480/90000 (23%)]	Loss: -10.8895	Cost: 6.11s
Train Epoch: 906 [40960/90000 (45%)]	Loss: -10.3555	Cost: 7.43s
Train Epoch: 906 [61440/90000 (68%)]	Loss: -10.7980	Cost: 5.80s
Train Epoch: 906 [81920/90000 (91%)]	Loss: -11.2371	Cost: 6.04s
Train Epoch: 906 	Average Loss: -10.1999
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.5421

Learning rate: 0.00011471189118386365
Re-generating waveforms for posterior prior.
Train Epoch: 907 [0/90000 (0%)]	Loss: -2.7092	Cost: 24.60s
Train Epoch: 907 [20480/90000 (23%)]	Loss: -11.1716	Cost: 6.07s
Train Epoch: 907 [40960/90000 (45%)]	Loss: -10.8461	Cost: 7.43s
Train Epoch: 907 [61440/90000 (68%)]	Loss: -11.1076	Cost: 5.88s
Train Epoch: 907 [81920/90000 (91%)]	Loss: -11.0969	Cost: 5.74s
Train Epoch: 907 	Average Loss: -10.5147
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.3902

Learning rate: 0.00011455650267790607
Re-generating waveforms for posterior prior.
Train Epoch: 908 [0/90000 (0%)]	Loss: -2.9461	Cost: 24.55s
Train Epoch: 908 [20480/90000 (23%)]	Loss: -11.0486	Cost: 6.13s
Train Epoch: 908 [40960/90000 (45%)]	Loss: -10.5740	Cost: 7.56s
Train Epoch: 908 [61440/90000 (68%)]	Loss: -11.0971	Cost: 5.82s
Train Epoch: 908 [81920/90000 (91%)]	Loss: -11.2534	Cost: 5.86s
Train Epoch: 908 	Average Loss: -10.4132
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.6385

Learning rate: 0.00011440107825522514
Re-generating waveforms for posterior prior.
Train Epoch: 909 [0/90000 (0%)]	Loss: -2.8947	Cost: 24.15s
Train Epoch: 909 [20480/90000 (23%)]	Loss: -11.4270	Cost: 6.10s
Train Epoch: 909 [40960/90000 (45%)]	Loss: -11.2415	Cost: 7.36s
Train Epoch: 909 [61440/90000 (68%)]	Loss: -11.4401	Cost: 5.85s
Train Epoch: 909 [81920/90000 (91%)]	Loss: -11.6175	Cost: 5.89s
Train Epoch: 909 	Average Loss: -10.7893
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.6913

Learning rate: 0.00011424561829931519
Re-generating waveforms for posterior prior.
Train Epoch: 910 [0/90000 (0%)]	Loss: -3.0294	Cost: 24.39s
Train Epoch: 910 [20480/90000 (23%)]	Loss: -11.5417	Cost: 6.13s
Train Epoch: 910 [40960/90000 (45%)]	Loss: -11.3155	Cost: 7.47s
Train Epoch: 910 [61440/90000 (68%)]	Loss: -11.6194	Cost: 5.84s
Train Epoch: 910 [81920/90000 (91%)]	Loss: -11.6721	Cost: 5.81s
Train Epoch: 910 	Average Loss: -10.9333
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.7912

Learning rate: 0.00011409012319375819
Re-generating waveforms for posterior prior.
Train Epoch: 911 [0/90000 (0%)]	Loss: -2.8789	Cost: 24.97s
Train Epoch: 911 [20480/90000 (23%)]	Loss: -11.4493	Cost: 6.12s
Train Epoch: 911 [40960/90000 (45%)]	Loss: -11.1095	Cost: 7.30s
Train Epoch: 911 [61440/90000 (68%)]	Loss: -11.5701	Cost: 5.87s
Train Epoch: 911 [81920/90000 (91%)]	Loss: -11.7479	Cost: 6.06s
Train Epoch: 911 	Average Loss: -10.8925
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.9867

Learning rate: 0.00011393459332222288
Re-generating waveforms for posterior prior.
Train Epoch: 912 [0/90000 (0%)]	Loss: -3.3839	Cost: 26.24s
Train Epoch: 912 [20480/90000 (23%)]	Loss: -11.5856	Cost: 6.10s
Train Epoch: 912 [40960/90000 (45%)]	Loss: -11.2057	Cost: 6.77s
Train Epoch: 912 [61440/90000 (68%)]	Loss: -11.5568	Cost: 5.86s
Train Epoch: 912 [81920/90000 (91%)]	Loss: -11.8163	Cost: 5.81s
Train Epoch: 912 	Average Loss: -10.9717
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.8275

Learning rate: 0.00011377902906846375
Re-generating waveforms for posterior prior.
Train Epoch: 913 [0/90000 (0%)]	Loss: -2.7801	Cost: 24.41s
Train Epoch: 913 [20480/90000 (23%)]	Loss: -11.9515	Cost: 6.14s
Train Epoch: 913 [40960/90000 (45%)]	Loss: -11.1404	Cost: 7.49s
Train Epoch: 913 [61440/90000 (68%)]	Loss: -11.1607	Cost: 5.84s
Train Epoch: 913 [81920/90000 (91%)]	Loss: -11.5754	Cost: 5.98s
Train Epoch: 913 	Average Loss: -10.9031
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.8299

Learning rate: 0.00011362343081632008
Re-generating waveforms for posterior prior.
Train Epoch: 914 [0/90000 (0%)]	Loss: -3.0527	Cost: 24.40s
Train Epoch: 914 [20480/90000 (23%)]	Loss: -11.2284	Cost: 6.11s
Train Epoch: 914 [40960/90000 (45%)]	Loss: -11.0012	Cost: 6.90s
Train Epoch: 914 [61440/90000 (68%)]	Loss: -11.2222	Cost: 6.13s
Train Epoch: 914 [81920/90000 (91%)]	Loss: -11.4731	Cost: 5.84s
Train Epoch: 914 	Average Loss: -10.7506
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.8593

Learning rate: 0.00011346779894971517
Re-generating waveforms for posterior prior.
Train Epoch: 915 [0/90000 (0%)]	Loss: -2.7856	Cost: 26.18s
Train Epoch: 915 [20480/90000 (23%)]	Loss: -11.5851	Cost: 6.09s
Train Epoch: 915 [40960/90000 (45%)]	Loss: -11.3341	Cost: 7.06s
Train Epoch: 915 [61440/90000 (68%)]	Loss: -11.6269	Cost: 5.85s
Train Epoch: 915 [81920/90000 (91%)]	Loss: -11.9846	Cost: 5.82s
Train Epoch: 915 	Average Loss: -11.0425
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.0074

Learning rate: 0.00011331213385265517
Re-generating waveforms for posterior prior.
Train Epoch: 916 [0/90000 (0%)]	Loss: -3.3505	Cost: 24.52s
Train Epoch: 916 [20480/90000 (23%)]	Loss: -11.8912	Cost: 6.14s
Train Epoch: 916 [40960/90000 (45%)]	Loss: -11.3352	Cost: 7.50s
Train Epoch: 916 [61440/90000 (68%)]	Loss: -11.7936	Cost: 5.81s
Train Epoch: 916 [81920/90000 (91%)]	Loss: -11.8520	Cost: 5.87s
Train Epoch: 916 	Average Loss: -11.0604
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.6747

Learning rate: 0.00011315643590922817
Re-generating waveforms for posterior prior.
Train Epoch: 917 [0/90000 (0%)]	Loss: -3.4213	Cost: 24.77s
Train Epoch: 917 [20480/90000 (23%)]	Loss: -11.4653	Cost: 6.11s
Train Epoch: 917 [40960/90000 (45%)]	Loss: -11.0287	Cost: 6.86s
Train Epoch: 917 [61440/90000 (68%)]	Loss: -11.6339	Cost: 5.85s
Train Epoch: 917 [81920/90000 (91%)]	Loss: -11.9766	Cost: 6.02s
Train Epoch: 917 	Average Loss: -10.9114
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.9813

Learning rate: 0.00011300070550360342
Re-generating waveforms for posterior prior.
Train Epoch: 918 [0/90000 (0%)]	Loss: -2.9995	Cost: 25.01s
Train Epoch: 918 [20480/90000 (23%)]	Loss: -11.6797	Cost: 6.11s
Train Epoch: 918 [40960/90000 (45%)]	Loss: -11.2437	Cost: 7.35s
Train Epoch: 918 [61440/90000 (68%)]	Loss: -11.7488	Cost: 5.80s
Train Epoch: 918 [81920/90000 (91%)]	Loss: -12.0250	Cost: 6.06s
Train Epoch: 918 	Average Loss: -11.0264
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.2273

Learning rate: 0.00011284494302003022
Re-generating waveforms for posterior prior.
Train Epoch: 919 [0/90000 (0%)]	Loss: -3.3848	Cost: 24.54s
Train Epoch: 919 [20480/90000 (23%)]	Loss: -11.9617	Cost: 6.12s
Train Epoch: 919 [40960/90000 (45%)]	Loss: -11.4514	Cost: 7.53s
Train Epoch: 919 [61440/90000 (68%)]	Loss: -11.8378	Cost: 5.84s
Train Epoch: 919 [81920/90000 (91%)]	Loss: -11.7217	Cost: 5.84s
Train Epoch: 919 	Average Loss: -11.1562
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.1159

Learning rate: 0.00011268914884283697
Re-generating waveforms for posterior prior.
Train Epoch: 920 [0/90000 (0%)]	Loss: -3.7570	Cost: 25.29s
Train Epoch: 920 [20480/90000 (23%)]	Loss: -11.9758	Cost: 6.09s
Train Epoch: 920 [40960/90000 (45%)]	Loss: -11.5407	Cost: 7.38s
Train Epoch: 920 [61440/90000 (68%)]	Loss: -11.8713	Cost: 5.84s
Train Epoch: 920 [81920/90000 (91%)]	Loss: -11.9453	Cost: 6.20s
Train Epoch: 920 	Average Loss: -11.1488
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.2915

Learning rate: 0.00011253332335643035
Re-generating waveforms for posterior prior.
Train Epoch: 921 [0/90000 (0%)]	Loss: -3.4693	Cost: 24.26s
Train Epoch: 921 [20480/90000 (23%)]	Loss: -12.0574	Cost: 6.12s
Train Epoch: 921 [40960/90000 (45%)]	Loss: -11.3635	Cost: 7.37s
Train Epoch: 921 [61440/90000 (68%)]	Loss: -11.7124	Cost: 5.83s
Train Epoch: 921 [81920/90000 (91%)]	Loss: -12.0707	Cost: 5.87s
Train Epoch: 921 	Average Loss: -11.1649
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.1410

Learning rate: 0.00011237746694529426
Re-generating waveforms for posterior prior.
Train Epoch: 922 [0/90000 (0%)]	Loss: -3.4069	Cost: 25.01s
Train Epoch: 922 [20480/90000 (23%)]	Loss: -11.9250	Cost: 6.14s
Train Epoch: 922 [40960/90000 (45%)]	Loss: -11.5122	Cost: 7.42s
Train Epoch: 922 [61440/90000 (68%)]	Loss: -11.8306	Cost: 5.88s
Train Epoch: 922 [81920/90000 (91%)]	Loss: -11.9693	Cost: 6.12s
Train Epoch: 922 	Average Loss: -11.2287
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.9871

Learning rate: 0.00011222157999398887
Re-generating waveforms for posterior prior.
Train Epoch: 923 [0/90000 (0%)]	Loss: -2.8675	Cost: 24.40s
Train Epoch: 923 [20480/90000 (23%)]	Loss: -12.0351	Cost: 6.17s
Train Epoch: 923 [40960/90000 (45%)]	Loss: -11.4332	Cost: 7.34s
Train Epoch: 923 [61440/90000 (68%)]	Loss: -11.7598	Cost: 5.83s
Train Epoch: 923 [81920/90000 (91%)]	Loss: -12.0369	Cost: 6.11s
Train Epoch: 923 	Average Loss: -11.1510
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.0472

Learning rate: 0.00011206566288714977
Re-generating waveforms for posterior prior.
Train Epoch: 924 [0/90000 (0%)]	Loss: -2.7551	Cost: 24.33s
Train Epoch: 924 [20480/90000 (23%)]	Loss: -11.8393	Cost: 6.11s
Train Epoch: 924 [40960/90000 (45%)]	Loss: -11.3876	Cost: 7.36s
Train Epoch: 924 [61440/90000 (68%)]	Loss: -11.6969	Cost: 5.80s
Train Epoch: 924 [81920/90000 (91%)]	Loss: -12.0892	Cost: 6.03s
Train Epoch: 924 	Average Loss: -11.1095
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.0899

Learning rate: 0.0001119097160094869
Re-generating waveforms for posterior prior.
Train Epoch: 925 [0/90000 (0%)]	Loss: -3.0448	Cost: 24.39s
Train Epoch: 925 [20480/90000 (23%)]	Loss: -11.7950	Cost: 6.16s
Train Epoch: 925 [40960/90000 (45%)]	Loss: -11.5149	Cost: 7.01s
Train Epoch: 925 [61440/90000 (68%)]	Loss: -12.0439	Cost: 5.86s
Train Epoch: 925 [81920/90000 (91%)]	Loss: -11.8930	Cost: 6.05s
Train Epoch: 925 	Average Loss: -11.2394
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.2738

Learning rate: 0.0001117537397457837
Re-generating waveforms for posterior prior.
Train Epoch: 926 [0/90000 (0%)]	Loss: -3.5513	Cost: 24.43s
Train Epoch: 926 [20480/90000 (23%)]	Loss: -12.1213	Cost: 6.14s
Train Epoch: 926 [40960/90000 (45%)]	Loss: -11.6583	Cost: 7.18s
Train Epoch: 926 [61440/90000 (68%)]	Loss: -11.9077	Cost: 5.85s
Train Epoch: 926 [81920/90000 (91%)]	Loss: -12.0463	Cost: 5.90s
Train Epoch: 926 	Average Loss: -11.3100
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.1259

Learning rate: 0.00011159773448089607
Re-generating waveforms for posterior prior.
Train Epoch: 927 [0/90000 (0%)]	Loss: -2.7713	Cost: 24.73s
Train Epoch: 927 [20480/90000 (23%)]	Loss: -12.0621	Cost: 6.12s
Train Epoch: 927 [40960/90000 (45%)]	Loss: -11.5886	Cost: 6.91s
Train Epoch: 927 [61440/90000 (68%)]	Loss: -12.1169	Cost: 5.83s
Train Epoch: 927 [81920/90000 (91%)]	Loss: -12.1322	Cost: 5.91s
Train Epoch: 927 	Average Loss: -11.3743
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.2022

Learning rate: 0.00011144170059975152
Re-generating waveforms for posterior prior.
Train Epoch: 928 [0/90000 (0%)]	Loss: -3.7160	Cost: 24.77s
Train Epoch: 928 [20480/90000 (23%)]	Loss: -12.0615	Cost: 6.09s
Train Epoch: 928 [40960/90000 (45%)]	Loss: -11.6990	Cost: 7.43s
Train Epoch: 928 [61440/90000 (68%)]	Loss: -11.9511	Cost: 5.82s
Train Epoch: 928 [81920/90000 (91%)]	Loss: -12.2331	Cost: 5.87s
Train Epoch: 928 	Average Loss: -11.3426
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.2741

Learning rate: 0.00011128563848734808
Re-generating waveforms for posterior prior.
Train Epoch: 929 [0/90000 (0%)]	Loss: -3.1457	Cost: 24.50s
Train Epoch: 929 [20480/90000 (23%)]	Loss: -12.1262	Cost: 6.12s
Train Epoch: 929 [40960/90000 (45%)]	Loss: -11.7776	Cost: 7.08s
Train Epoch: 929 [61440/90000 (68%)]	Loss: -12.0852	Cost: 5.85s
Train Epoch: 929 [81920/90000 (91%)]	Loss: -12.1893	Cost: 6.00s
Train Epoch: 929 	Average Loss: -11.3891
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.1484

Learning rate: 0.0001111295485287536
Re-generating waveforms for posterior prior.
Train Epoch: 930 [0/90000 (0%)]	Loss: -3.5488	Cost: 25.19s
Train Epoch: 930 [20480/90000 (23%)]	Loss: -12.2460	Cost: 6.20s
Train Epoch: 930 [40960/90000 (45%)]	Loss: -11.8027	Cost: 7.35s
Train Epoch: 930 [61440/90000 (68%)]	Loss: -11.9295	Cost: 5.84s
Train Epoch: 930 [81920/90000 (91%)]	Loss: -12.1958	Cost: 6.02s
Train Epoch: 930 	Average Loss: -11.3847
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.2111

Learning rate: 0.00011097343110910447
Re-generating waveforms for posterior prior.
Train Epoch: 931 [0/90000 (0%)]	Loss: -2.9712	Cost: 25.85s
Train Epoch: 931 [20480/90000 (23%)]	Loss: -12.1570	Cost: 6.09s
Train Epoch: 931 [40960/90000 (45%)]	Loss: -11.6204	Cost: 7.01s
Train Epoch: 931 [61440/90000 (68%)]	Loss: -12.1266	Cost: 5.84s
Train Epoch: 931 [81920/90000 (91%)]	Loss: -12.1095	Cost: 5.80s
Train Epoch: 931 	Average Loss: -11.4195
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.2430

Learning rate: 0.0001108172866136049
Re-generating waveforms for posterior prior.
Train Epoch: 932 [0/90000 (0%)]	Loss: -3.5217	Cost: 25.31s
Train Epoch: 932 [20480/90000 (23%)]	Loss: -12.2654	Cost: 6.24s
Train Epoch: 932 [40960/90000 (45%)]	Loss: -11.7442	Cost: 7.29s
Train Epoch: 932 [61440/90000 (68%)]	Loss: -11.9990	Cost: 5.85s
Train Epoch: 932 [81920/90000 (91%)]	Loss: -12.0520	Cost: 5.86s
Train Epoch: 932 	Average Loss: -11.3386
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.1431

Learning rate: 0.00011066111542752591
Re-generating waveforms for posterior prior.
Train Epoch: 933 [0/90000 (0%)]	Loss: -3.4589	Cost: 25.03s
Train Epoch: 933 [20480/90000 (23%)]	Loss: -11.9530	Cost: 6.14s
Train Epoch: 933 [40960/90000 (45%)]	Loss: -11.6712	Cost: 7.07s
Train Epoch: 933 [61440/90000 (68%)]	Loss: -11.7812	Cost: 5.85s
Train Epoch: 933 [81920/90000 (91%)]	Loss: -12.0746	Cost: 6.03s
Train Epoch: 933 	Average Loss: -11.2287
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.2910

Learning rate: 0.00011050491793620445
Re-generating waveforms for posterior prior.
Train Epoch: 934 [0/90000 (0%)]	Loss: -3.0850	Cost: 25.61s
Train Epoch: 934 [20480/90000 (23%)]	Loss: -12.1598	Cost: 6.13s
Train Epoch: 934 [40960/90000 (45%)]	Loss: -11.4460	Cost: 6.98s
Train Epoch: 934 [61440/90000 (68%)]	Loss: -12.1847	Cost: 5.88s
Train Epoch: 934 [81920/90000 (91%)]	Loss: -12.3729	Cost: 5.74s
Train Epoch: 934 	Average Loss: -11.4312
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.2980

Learning rate: 0.0001103486945250422
Re-generating waveforms for posterior prior.
Train Epoch: 935 [0/90000 (0%)]	Loss: -3.4786	Cost: 24.71s
Train Epoch: 935 [20480/90000 (23%)]	Loss: -12.3029	Cost: 6.14s
Train Epoch: 935 [40960/90000 (45%)]	Loss: -11.6359	Cost: 7.45s
Train Epoch: 935 [61440/90000 (68%)]	Loss: -11.9725	Cost: 5.85s
Train Epoch: 935 [81920/90000 (91%)]	Loss: -12.2903	Cost: 5.87s
Train Epoch: 935 	Average Loss: -11.4487
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.4424

Learning rate: 0.00011019244557950494
Re-generating waveforms for posterior prior.
Train Epoch: 936 [0/90000 (0%)]	Loss: -3.4408	Cost: 25.24s
Train Epoch: 936 [20480/90000 (23%)]	Loss: -12.1944	Cost: 6.16s
Train Epoch: 936 [40960/90000 (45%)]	Loss: -11.9212	Cost: 7.29s
Train Epoch: 936 [61440/90000 (68%)]	Loss: -12.2896	Cost: 5.84s
Train Epoch: 936 [81920/90000 (91%)]	Loss: -12.1523	Cost: 6.00s
Train Epoch: 936 	Average Loss: -11.5666
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.2252

Learning rate: 0.00011003617148512142
Re-generating waveforms for posterior prior.
Train Epoch: 937 [0/90000 (0%)]	Loss: -3.3733	Cost: 24.29s
Train Epoch: 937 [20480/90000 (23%)]	Loss: -12.0958	Cost: 6.15s
Train Epoch: 937 [40960/90000 (45%)]	Loss: -11.0680	Cost: 6.97s
Train Epoch: 937 [61440/90000 (68%)]	Loss: -11.3693	Cost: 5.85s
Train Epoch: 937 [81920/90000 (91%)]	Loss: -11.5251	Cost: 5.87s
Train Epoch: 937 	Average Loss: -11.0966
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.6399

Learning rate: 0.00010987987262748245
Re-generating waveforms for posterior prior.
Train Epoch: 938 [0/90000 (0%)]	Loss: -2.5766	Cost: 24.86s
Train Epoch: 938 [20480/90000 (23%)]	Loss: -11.6354	Cost: 6.13s
Train Epoch: 938 [40960/90000 (45%)]	Loss: -11.2483	Cost: 6.90s
Train Epoch: 938 [61440/90000 (68%)]	Loss: -11.8706	Cost: 5.89s
Train Epoch: 938 [81920/90000 (91%)]	Loss: -12.1269	Cost: 5.99s
Train Epoch: 938 	Average Loss: -11.0352
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.1970

Learning rate: 0.00010972354939223989
Re-generating waveforms for posterior prior.
Train Epoch: 939 [0/90000 (0%)]	Loss: -3.2560	Cost: 24.30s
Train Epoch: 939 [20480/90000 (23%)]	Loss: -12.2472	Cost: 6.15s
Train Epoch: 939 [40960/90000 (45%)]	Loss: -11.8847	Cost: 7.08s
Train Epoch: 939 [61440/90000 (68%)]	Loss: -12.0648	Cost: 5.92s
Train Epoch: 939 [81920/90000 (91%)]	Loss: -12.4306	Cost: 5.86s
Train Epoch: 939 	Average Loss: -11.4908
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.4890

Learning rate: 0.00010956720216510579
Re-generating waveforms for posterior prior.
Train Epoch: 940 [0/90000 (0%)]	Loss: -3.5641	Cost: 23.98s
Train Epoch: 940 [20480/90000 (23%)]	Loss: -12.4433	Cost: 6.18s
Train Epoch: 940 [40960/90000 (45%)]	Loss: -12.0372	Cost: 7.46s
Train Epoch: 940 [61440/90000 (68%)]	Loss: -12.3627	Cost: 5.81s
Train Epoch: 940 [81920/90000 (91%)]	Loss: -12.4907	Cost: 6.09s
Train Epoch: 940 	Average Loss: -11.6806
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.3221

Learning rate: 0.00010941083133185137
Re-generating waveforms for posterior prior.
Train Epoch: 941 [0/90000 (0%)]	Loss: -2.8255	Cost: 24.81s
Train Epoch: 941 [20480/90000 (23%)]	Loss: -12.3271	Cost: 6.11s
Train Epoch: 941 [40960/90000 (45%)]	Loss: -11.8848	Cost: 7.48s
Train Epoch: 941 [61440/90000 (68%)]	Loss: -12.2104	Cost: 5.81s
Train Epoch: 941 [81920/90000 (91%)]	Loss: -12.2382	Cost: 5.89s
Train Epoch: 941 	Average Loss: -11.5686
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.4250

Learning rate: 0.00010925443727830617
Re-generating waveforms for posterior prior.
Train Epoch: 942 [0/90000 (0%)]	Loss: -3.1629	Cost: 24.87s
Train Epoch: 942 [20480/90000 (23%)]	Loss: -12.2543	Cost: 6.21s
Train Epoch: 942 [40960/90000 (45%)]	Loss: -12.0554	Cost: 7.33s
Train Epoch: 942 [61440/90000 (68%)]	Loss: -12.2539	Cost: 5.85s
Train Epoch: 942 [81920/90000 (91%)]	Loss: -12.3999	Cost: 6.12s
Train Epoch: 942 	Average Loss: -11.5941
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.1835

Learning rate: 0.00010909802039035693
Re-generating waveforms for posterior prior.
Train Epoch: 943 [0/90000 (0%)]	Loss: -3.0378	Cost: 25.94s
Train Epoch: 943 [20480/90000 (23%)]	Loss: -11.0048	Cost: 6.06s
Train Epoch: 943 [40960/90000 (45%)]	Loss: -10.7351	Cost: 7.12s
Train Epoch: 943 [61440/90000 (68%)]	Loss: -11.4311	Cost: 5.86s
Train Epoch: 943 [81920/90000 (91%)]	Loss: -11.7247	Cost: 5.92s
Train Epoch: 943 	Average Loss: -10.4708
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.8000

Learning rate: 0.00010894158105394678
Re-generating waveforms for posterior prior.
Train Epoch: 944 [0/90000 (0%)]	Loss: -1.3841	Cost: 24.07s
Train Epoch: 944 [20480/90000 (23%)]	Loss: -11.9958	Cost: 6.20s
Train Epoch: 944 [40960/90000 (45%)]	Loss: -11.6754	Cost: 7.39s
Train Epoch: 944 [61440/90000 (68%)]	Loss: -11.9852	Cost: 5.89s
Train Epoch: 944 [81920/90000 (91%)]	Loss: -12.3068	Cost: 5.71s
Train Epoch: 944 	Average Loss: -11.2626
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.3312

Learning rate: 0.00010878511965507427
Re-generating waveforms for posterior prior.
Train Epoch: 945 [0/90000 (0%)]	Loss: -3.2147	Cost: 25.90s
Train Epoch: 945 [20480/90000 (23%)]	Loss: -12.1925	Cost: 6.10s
Train Epoch: 945 [40960/90000 (45%)]	Loss: -11.7680	Cost: 6.85s
Train Epoch: 945 [61440/90000 (68%)]	Loss: -12.0616	Cost: 5.91s
Train Epoch: 945 [81920/90000 (91%)]	Loss: -12.3869	Cost: 5.75s
Train Epoch: 945 	Average Loss: -11.5117
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.2592

Learning rate: 0.00010862863657979229
Re-generating waveforms for posterior prior.
Train Epoch: 946 [0/90000 (0%)]	Loss: -3.2713	Cost: 25.30s
Train Epoch: 946 [20480/90000 (23%)]	Loss: -12.1725	Cost: 6.08s
Train Epoch: 946 [40960/90000 (45%)]	Loss: -11.6817	Cost: 7.29s
Train Epoch: 946 [61440/90000 (68%)]	Loss: -12.2221	Cost: 5.82s
Train Epoch: 946 [81920/90000 (91%)]	Loss: -12.4777	Cost: 6.10s
Train Epoch: 946 	Average Loss: -11.5131
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.5124

Learning rate: 0.00010847213221420725
Re-generating waveforms for posterior prior.
Train Epoch: 947 [0/90000 (0%)]	Loss: -3.5226	Cost: 24.83s
Train Epoch: 947 [20480/90000 (23%)]	Loss: -12.3187	Cost: 6.18s
Train Epoch: 947 [40960/90000 (45%)]	Loss: -11.4535	Cost: 7.25s
Train Epoch: 947 [61440/90000 (68%)]	Loss: -11.4901	Cost: 5.87s
Train Epoch: 947 [81920/90000 (91%)]	Loss: -11.9056	Cost: 6.01s
Train Epoch: 947 	Average Loss: -11.2737
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.0726

Learning rate: 0.00010831560694447822
Re-generating waveforms for posterior prior.
Train Epoch: 948 [0/90000 (0%)]	Loss: -2.5160	Cost: 25.00s
Train Epoch: 948 [20480/90000 (23%)]	Loss: -11.9385	Cost: 6.17s
Train Epoch: 948 [40960/90000 (45%)]	Loss: -11.6582	Cost: 7.37s
Train Epoch: 948 [61440/90000 (68%)]	Loss: -12.0180	Cost: 5.82s
Train Epoch: 948 [81920/90000 (91%)]	Loss: -12.3248	Cost: 6.03s
Train Epoch: 948 	Average Loss: -11.3468
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.3381

Learning rate: 0.00010815906115681569
Re-generating waveforms for posterior prior.
Train Epoch: 949 [0/90000 (0%)]	Loss: -3.1806	Cost: 25.65s
Train Epoch: 949 [20480/90000 (23%)]	Loss: -12.3229	Cost: 6.11s
Train Epoch: 949 [40960/90000 (45%)]	Loss: -12.0127	Cost: 7.34s
Train Epoch: 949 [61440/90000 (68%)]	Loss: -12.2735	Cost: 5.83s
Train Epoch: 949 [81920/90000 (91%)]	Loss: -12.5305	Cost: 6.04s
Train Epoch: 949 	Average Loss: -11.5890
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.3668

Learning rate: 0.0001080024952374808
Re-generating waveforms for posterior prior.
Train Epoch: 950 [0/90000 (0%)]	Loss: -3.1606	Cost: 24.26s
Train Epoch: 950 [20480/90000 (23%)]	Loss: -12.5362	Cost: 6.11s
Train Epoch: 950 [40960/90000 (45%)]	Loss: -12.1592	Cost: 6.86s
Train Epoch: 950 [61440/90000 (68%)]	Loss: -12.4250	Cost: 5.97s
Train Epoch: 950 [81920/90000 (91%)]	Loss: -12.5012	Cost: 5.93s
Train Epoch: 950 	Average Loss: -11.6993
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.5307

Saving model as model_sample_from_all_posterior.pt_e950 & waveforms_supplementary_sample_from_all_posterior.hdf5_e950
Learning rate: 0.00010784590957278442
Re-generating waveforms for posterior prior.
Train Epoch: 951 [0/90000 (0%)]	Loss: -3.0921	Cost: 24.55s
Train Epoch: 951 [20480/90000 (23%)]	Loss: -12.6454	Cost: 6.19s
Train Epoch: 951 [40960/90000 (45%)]	Loss: -12.2710	Cost: 7.34s
Train Epoch: 951 [61440/90000 (68%)]	Loss: -12.4567	Cost: 5.87s
Train Epoch: 951 [81920/90000 (91%)]	Loss: -12.5755	Cost: 5.89s
Train Epoch: 951 	Average Loss: -11.7837
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.6195

Learning rate: 0.00010768930454908614
Re-generating waveforms for posterior prior.
Train Epoch: 952 [0/90000 (0%)]	Loss: -3.4221	Cost: 25.22s
Train Epoch: 952 [20480/90000 (23%)]	Loss: -12.5474	Cost: 6.13s
Train Epoch: 952 [40960/90000 (45%)]	Loss: -12.1983	Cost: 7.14s
Train Epoch: 952 [61440/90000 (68%)]	Loss: -12.5032	Cost: 5.86s
Train Epoch: 952 [81920/90000 (91%)]	Loss: -12.4151	Cost: 5.71s
Train Epoch: 952 	Average Loss: -11.7871
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.5637

Learning rate: 0.00010753268055279321
Re-generating waveforms for posterior prior.
Train Epoch: 953 [0/90000 (0%)]	Loss: -3.5564	Cost: 24.41s
Train Epoch: 953 [20480/90000 (23%)]	Loss: -12.2821	Cost: 6.14s
Train Epoch: 953 [40960/90000 (45%)]	Loss: -12.2361	Cost: 7.28s
Train Epoch: 953 [61440/90000 (68%)]	Loss: -12.5041	Cost: 5.80s
Train Epoch: 953 [81920/90000 (91%)]	Loss: -12.6926	Cost: 5.91s
Train Epoch: 953 	Average Loss: -11.8618
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.1909

Learning rate: 0.00010737603797035982
Re-generating waveforms for posterior prior.
Train Epoch: 954 [0/90000 (0%)]	Loss: -3.4265	Cost: 24.34s
Train Epoch: 954 [20480/90000 (23%)]	Loss: -11.6422	Cost: 6.12s
Train Epoch: 954 [40960/90000 (45%)]	Loss: -11.3723	Cost: 7.55s
Train Epoch: 954 [61440/90000 (68%)]	Loss: -12.0514	Cost: 5.81s
Train Epoch: 954 [81920/90000 (91%)]	Loss: -12.4696	Cost: 5.89s
Train Epoch: 954 	Average Loss: -11.2271
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.4723

Learning rate: 0.00010721937718828601
Re-generating waveforms for posterior prior.
Train Epoch: 955 [0/90000 (0%)]	Loss: -2.8025	Cost: 24.69s
Train Epoch: 955 [20480/90000 (23%)]	Loss: -12.4680	Cost: 6.15s
Train Epoch: 955 [40960/90000 (45%)]	Loss: -12.2367	Cost: 7.47s
Train Epoch: 955 [61440/90000 (68%)]	Loss: -12.5978	Cost: 5.86s
Train Epoch: 955 [81920/90000 (91%)]	Loss: -12.6418	Cost: 5.83s
Train Epoch: 955 	Average Loss: -11.7726
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.4883

Learning rate: 0.00010706269859311662
Re-generating waveforms for posterior prior.
Train Epoch: 956 [0/90000 (0%)]	Loss: -3.7477	Cost: 24.58s
Train Epoch: 956 [20480/90000 (23%)]	Loss: -12.4247	Cost: 6.13s
Train Epoch: 956 [40960/90000 (45%)]	Loss: -12.1218	Cost: 7.08s
Train Epoch: 956 [61440/90000 (68%)]	Loss: -12.5769	Cost: 5.87s
Train Epoch: 956 [81920/90000 (91%)]	Loss: -12.6559	Cost: 5.83s
Train Epoch: 956 	Average Loss: -11.8470
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.6354

Learning rate: 0.00010690600257144056
Re-generating waveforms for posterior prior.
Train Epoch: 957 [0/90000 (0%)]	Loss: -3.7899	Cost: 24.61s
Train Epoch: 957 [20480/90000 (23%)]	Loss: -12.6313	Cost: 6.16s
Train Epoch: 957 [40960/90000 (45%)]	Loss: -12.0612	Cost: 7.31s
Train Epoch: 957 [61440/90000 (68%)]	Loss: -12.5961	Cost: 5.83s
Train Epoch: 957 [81920/90000 (91%)]	Loss: -12.7103	Cost: 6.17s
Train Epoch: 957 	Average Loss: -11.8538
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.5465

Learning rate: 0.00010674928950988962
Re-generating waveforms for posterior prior.
Train Epoch: 958 [0/90000 (0%)]	Loss: -4.1626	Cost: 24.49s
Train Epoch: 958 [20480/90000 (23%)]	Loss: -12.5937	Cost: 6.16s
Train Epoch: 958 [40960/90000 (45%)]	Loss: -11.9627	Cost: 6.83s
Train Epoch: 958 [61440/90000 (68%)]	Loss: -12.4440	Cost: 5.94s
Train Epoch: 958 [81920/90000 (91%)]	Loss: -12.5060	Cost: 5.86s
Train Epoch: 958 	Average Loss: -11.7900
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.4323

Learning rate: 0.00010659255979513773
Re-generating waveforms for posterior prior.
Train Epoch: 959 [0/90000 (0%)]	Loss: -3.2935	Cost: 24.65s
Train Epoch: 959 [20480/90000 (23%)]	Loss: -12.5741	Cost: 6.14s
Train Epoch: 959 [40960/90000 (45%)]	Loss: -12.1827	Cost: 7.23s
Train Epoch: 959 [61440/90000 (68%)]	Loss: -12.3993	Cost: 5.85s
Train Epoch: 959 [81920/90000 (91%)]	Loss: -12.7979	Cost: 5.89s
Train Epoch: 959 	Average Loss: -11.8064
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.5230

Learning rate: 0.00010643581381389993
Re-generating waveforms for posterior prior.
Train Epoch: 960 [0/90000 (0%)]	Loss: -3.1110	Cost: 24.70s
Train Epoch: 960 [20480/90000 (23%)]	Loss: -12.6035	Cost: 6.15s
Train Epoch: 960 [40960/90000 (45%)]	Loss: -12.0956	Cost: 6.85s
Train Epoch: 960 [61440/90000 (68%)]	Loss: -12.5682	Cost: 5.92s
Train Epoch: 960 [81920/90000 (91%)]	Loss: -12.8272	Cost: 5.79s
Train Epoch: 960 	Average Loss: -11.8670
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.6020

Learning rate: 0.00010627905195293131
Re-generating waveforms for posterior prior.
Train Epoch: 961 [0/90000 (0%)]	Loss: -3.1692	Cost: 25.07s
Train Epoch: 961 [20480/90000 (23%)]	Loss: -12.7176	Cost: 6.15s
Train Epoch: 961 [40960/90000 (45%)]	Loss: -12.3906	Cost: 6.84s
Train Epoch: 961 [61440/90000 (68%)]	Loss: -12.6844	Cost: 5.86s
Train Epoch: 961 [81920/90000 (91%)]	Loss: -12.8699	Cost: 5.98s
Train Epoch: 961 	Average Loss: -11.9512
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.7314

Learning rate: 0.00010612227459902615
Re-generating waveforms for posterior prior.
Train Epoch: 962 [0/90000 (0%)]	Loss: -3.9146	Cost: 24.93s
Train Epoch: 962 [20480/90000 (23%)]	Loss: -12.8514	Cost: 6.09s
Train Epoch: 962 [40960/90000 (45%)]	Loss: -12.5554	Cost: 7.49s
Train Epoch: 962 [61440/90000 (68%)]	Loss: -12.6425	Cost: 5.83s
Train Epoch: 962 [81920/90000 (91%)]	Loss: -12.5565	Cost: 5.91s
Train Epoch: 962 	Average Loss: -11.9397
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.6964

Learning rate: 0.00010596548213901704
Re-generating waveforms for posterior prior.
Train Epoch: 963 [0/90000 (0%)]	Loss: -3.1246	Cost: 24.56s
Train Epoch: 963 [20480/90000 (23%)]	Loss: -12.3987	Cost: 6.17s
Train Epoch: 963 [40960/90000 (45%)]	Loss: -12.0181	Cost: 7.26s
Train Epoch: 963 [61440/90000 (68%)]	Loss: -12.5929	Cost: 5.84s
Train Epoch: 963 [81920/90000 (91%)]	Loss: -12.8400	Cost: 6.16s
Train Epoch: 963 	Average Loss: -11.7704
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.6833

Learning rate: 0.00010580867495977376
Re-generating waveforms for posterior prior.
Train Epoch: 964 [0/90000 (0%)]	Loss: -3.4506	Cost: 25.51s
Train Epoch: 964 [20480/90000 (23%)]	Loss: -12.6790	Cost: 6.07s
Train Epoch: 964 [40960/90000 (45%)]	Loss: -12.2738	Cost: 6.46s
Train Epoch: 964 [61440/90000 (68%)]	Loss: -12.7240	Cost: 5.93s
Train Epoch: 964 [81920/90000 (91%)]	Loss: -12.8135	Cost: 5.96s
Train Epoch: 964 	Average Loss: -11.9638
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.3131

Learning rate: 0.00010565185344820242
Re-generating waveforms for posterior prior.
Train Epoch: 965 [0/90000 (0%)]	Loss: -3.7406	Cost: 25.18s
Train Epoch: 965 [20480/90000 (23%)]	Loss: -12.0798	Cost: 6.23s
Train Epoch: 965 [40960/90000 (45%)]	Loss: -11.7044	Cost: 7.33s
Train Epoch: 965 [61440/90000 (68%)]	Loss: -12.3439	Cost: 5.84s
Train Epoch: 965 [81920/90000 (91%)]	Loss: -12.7552	Cost: 5.87s
Train Epoch: 965 	Average Loss: -11.5355
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.6377

Learning rate: 0.00010549501799124454
Re-generating waveforms for posterior prior.
Train Epoch: 966 [0/90000 (0%)]	Loss: -3.5986	Cost: 24.51s
Train Epoch: 966 [20480/90000 (23%)]	Loss: -12.6341	Cost: 6.13s
Train Epoch: 966 [40960/90000 (45%)]	Loss: -12.3392	Cost: 7.52s
Train Epoch: 966 [61440/90000 (68%)]	Loss: -12.5997	Cost: 5.84s
Train Epoch: 966 [81920/90000 (91%)]	Loss: -12.6478	Cost: 5.70s
Train Epoch: 966 	Average Loss: -11.9112
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.4850

Learning rate: 0.00010533816897587602
Re-generating waveforms for posterior prior.
Train Epoch: 967 [0/90000 (0%)]	Loss: -3.4316	Cost: 24.41s
Train Epoch: 967 [20480/90000 (23%)]	Loss: -12.8135	Cost: 6.17s
Train Epoch: 967 [40960/90000 (45%)]	Loss: -12.4635	Cost: 7.17s
Train Epoch: 967 [61440/90000 (68%)]	Loss: -12.5903	Cost: 5.85s
Train Epoch: 967 [81920/90000 (91%)]	Loss: -12.8066	Cost: 6.11s
Train Epoch: 967 	Average Loss: -11.9759
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.6411

Learning rate: 0.00010518130678910621
Re-generating waveforms for posterior prior.
Train Epoch: 968 [0/90000 (0%)]	Loss: -3.4232	Cost: 25.21s
Train Epoch: 968 [20480/90000 (23%)]	Loss: -11.7140	Cost: 6.36s
Train Epoch: 968 [40960/90000 (45%)]	Loss: -11.3242	Cost: 7.14s
Train Epoch: 968 [61440/90000 (68%)]	Loss: -11.9975	Cost: 6.27s
Train Epoch: 968 [81920/90000 (91%)]	Loss: -12.2969	Cost: 6.16s
Train Epoch: 968 	Average Loss: -11.3119
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.5890

Learning rate: 0.00010502443181797693
Re-generating waveforms for posterior prior.
Train Epoch: 969 [0/90000 (0%)]	Loss: -3.8541	Cost: 24.78s
Train Epoch: 969 [20480/90000 (23%)]	Loss: -12.6872	Cost: 6.15s
Train Epoch: 969 [40960/90000 (45%)]	Loss: -12.1575	Cost: 7.19s
Train Epoch: 969 [61440/90000 (68%)]	Loss: -12.7910	Cost: 5.86s
Train Epoch: 969 [81920/90000 (91%)]	Loss: -12.9345	Cost: 5.84s
Train Epoch: 969 	Average Loss: -11.9073
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.5749

Learning rate: 0.00010486754444956162
Re-generating waveforms for posterior prior.
Train Epoch: 970 [0/90000 (0%)]	Loss: -3.1449	Cost: 24.87s
Train Epoch: 970 [20480/90000 (23%)]	Loss: -12.9389	Cost: 6.11s
Train Epoch: 970 [40960/90000 (45%)]	Loss: -12.3239	Cost: 7.27s
Train Epoch: 970 [61440/90000 (68%)]	Loss: -12.6983	Cost: 5.81s
Train Epoch: 970 [81920/90000 (91%)]	Loss: -13.0223	Cost: 6.20s
Train Epoch: 970 	Average Loss: -12.0812
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.9790

Learning rate: 0.00010471064507096422
Re-generating waveforms for posterior prior.
Train Epoch: 971 [0/90000 (0%)]	Loss: -4.2201	Cost: 25.17s
Train Epoch: 971 [20480/90000 (23%)]	Loss: -12.9306	Cost: 6.21s
Train Epoch: 971 [40960/90000 (45%)]	Loss: -12.5771	Cost: 7.32s
Train Epoch: 971 [61440/90000 (68%)]	Loss: -12.8992	Cost: 5.86s
Train Epoch: 971 [81920/90000 (91%)]	Loss: -13.0838	Cost: 6.34s
Train Epoch: 971 	Average Loss: -12.1930
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.8210

Learning rate: 0.0001045537340693184
Re-generating waveforms for posterior prior.
Train Epoch: 972 [0/90000 (0%)]	Loss: -4.1513	Cost: 24.19s
Train Epoch: 972 [20480/90000 (23%)]	Loss: -12.9272	Cost: 6.15s
Train Epoch: 972 [40960/90000 (45%)]	Loss: -12.5691	Cost: 7.04s
Train Epoch: 972 [61440/90000 (68%)]	Loss: -12.8173	Cost: 6.05s
Train Epoch: 972 [81920/90000 (91%)]	Loss: -13.0359	Cost: 6.05s
Train Epoch: 972 	Average Loss: -12.2362
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.6586

Learning rate: 0.00010439681183178644
Re-generating waveforms for posterior prior.
Train Epoch: 973 [0/90000 (0%)]	Loss: -3.7977	Cost: 24.57s
Train Epoch: 973 [20480/90000 (23%)]	Loss: -13.0642	Cost: 6.15s
Train Epoch: 973 [40960/90000 (45%)]	Loss: -12.5511	Cost: 7.22s
Train Epoch: 973 [61440/90000 (68%)]	Loss: -12.8013	Cost: 5.86s
Train Epoch: 973 [81920/90000 (91%)]	Loss: -12.5974	Cost: 5.98s
Train Epoch: 973 	Average Loss: -12.0484
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.6729

Learning rate: 0.00010423987874555839
Re-generating waveforms for posterior prior.
Train Epoch: 974 [0/90000 (0%)]	Loss: -3.5382	Cost: 24.81s
Train Epoch: 974 [20480/90000 (23%)]	Loss: -12.8078	Cost: 6.19s
Train Epoch: 974 [40960/90000 (45%)]	Loss: -12.3166	Cost: 6.65s
Train Epoch: 974 [61440/90000 (68%)]	Loss: -12.7615	Cost: 5.91s
Train Epoch: 974 [81920/90000 (91%)]	Loss: -12.4425	Cost: 6.20s
Train Epoch: 974 	Average Loss: -11.9702
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.3818

Learning rate: 0.00010408293519785097
Re-generating waveforms for posterior prior.
Train Epoch: 975 [0/90000 (0%)]	Loss: -3.7271	Cost: 24.39s
Train Epoch: 975 [20480/90000 (23%)]	Loss: -12.6528	Cost: 6.15s
Train Epoch: 975 [40960/90000 (45%)]	Loss: -12.2363	Cost: 6.41s
Train Epoch: 975 [61440/90000 (68%)]	Loss: -12.6415	Cost: 6.00s
Train Epoch: 975 [81920/90000 (91%)]	Loss: -12.8756	Cost: 5.70s
Train Epoch: 975 	Average Loss: -11.9075
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.7362

Learning rate: 0.00010392598157590682
Re-generating waveforms for posterior prior.
Train Epoch: 976 [0/90000 (0%)]	Loss: -3.5132	Cost: 24.86s
Train Epoch: 976 [20480/90000 (23%)]	Loss: -12.8997	Cost: 6.12s
Train Epoch: 976 [40960/90000 (45%)]	Loss: -12.3811	Cost: 6.59s
Train Epoch: 976 [61440/90000 (68%)]	Loss: -12.7122	Cost: 5.94s
Train Epoch: 976 [81920/90000 (91%)]	Loss: -12.5654	Cost: 5.85s
Train Epoch: 976 	Average Loss: -12.0248
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.6054

Learning rate: 0.0001037690182669934
Re-generating waveforms for posterior prior.
Train Epoch: 977 [0/90000 (0%)]	Loss: -3.6100	Cost: 41.95s
Train Epoch: 977 [20480/90000 (23%)]	Loss: -12.8430	Cost: 6.28s
Train Epoch: 977 [40960/90000 (45%)]	Loss: -12.4684	Cost: 21.73s
Train Epoch: 977 [61440/90000 (68%)]	Loss: -12.8942	Cost: 5.75s
Train Epoch: 977 [81920/90000 (91%)]	Loss: -13.0297	Cost: 5.72s
Train Epoch: 977 	Average Loss: -12.1000
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.8410

Learning rate: 0.00010361204565840209
Re-generating waveforms for posterior prior.
Train Epoch: 978 [0/90000 (0%)]	Loss: -3.7612	Cost: 24.66s
Train Epoch: 978 [20480/90000 (23%)]	Loss: -13.0989	Cost: 6.15s
Train Epoch: 978 [40960/90000 (45%)]	Loss: -12.0235	Cost: 7.46s
Train Epoch: 978 [61440/90000 (68%)]	Loss: -12.5246	Cost: 5.85s
Train Epoch: 978 [81920/90000 (91%)]	Loss: -12.6169	Cost: 5.74s
Train Epoch: 978 	Average Loss: -11.9658
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.7519

Learning rate: 0.0001034550641374472
Re-generating waveforms for posterior prior.
Train Epoch: 979 [0/90000 (0%)]	Loss: -4.1719	Cost: 25.06s
Train Epoch: 979 [20480/90000 (23%)]	Loss: -12.9049	Cost: 6.12s
Train Epoch: 979 [40960/90000 (45%)]	Loss: -12.4221	Cost: 7.48s
Train Epoch: 979 [61440/90000 (68%)]	Loss: -12.8374	Cost: 5.83s
Train Epoch: 979 [81920/90000 (91%)]	Loss: -12.9588	Cost: 6.02s
Train Epoch: 979 	Average Loss: -12.1310
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.8350

Learning rate: 0.00010329807409146496
Re-generating waveforms for posterior prior.
Train Epoch: 980 [0/90000 (0%)]	Loss: -4.0637	Cost: 24.91s
Train Epoch: 980 [20480/90000 (23%)]	Loss: -13.0501	Cost: 6.12s
Train Epoch: 980 [40960/90000 (45%)]	Loss: -12.6883	Cost: 7.44s
Train Epoch: 980 [61440/90000 (68%)]	Loss: -12.9088	Cost: 5.81s
Train Epoch: 980 [81920/90000 (91%)]	Loss: -13.0389	Cost: 5.88s
Train Epoch: 980 	Average Loss: -12.2602
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.8532

Learning rate: 0.00010314107590781278
Re-generating waveforms for posterior prior.
Train Epoch: 981 [0/90000 (0%)]	Loss: -4.0180	Cost: 24.74s
Train Epoch: 981 [20480/90000 (23%)]	Loss: -13.0240	Cost: 6.13s
Train Epoch: 981 [40960/90000 (45%)]	Loss: -12.8829	Cost: 7.28s
Train Epoch: 981 [61440/90000 (68%)]	Loss: -13.1637	Cost: 5.84s
Train Epoch: 981 [81920/90000 (91%)]	Loss: -13.2490	Cost: 5.96s
Train Epoch: 981 	Average Loss: -12.4162
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.0484

Learning rate: 0.00010298406997386806
Re-generating waveforms for posterior prior.
Train Epoch: 982 [0/90000 (0%)]	Loss: -4.2628	Cost: 25.33s
Train Epoch: 982 [20480/90000 (23%)]	Loss: -13.1275	Cost: 6.12s
Train Epoch: 982 [40960/90000 (45%)]	Loss: -12.5272	Cost: 7.37s
Train Epoch: 982 [61440/90000 (68%)]	Loss: -12.9319	Cost: 5.86s
Train Epoch: 982 [81920/90000 (91%)]	Loss: -13.1707	Cost: 6.06s
Train Epoch: 982 	Average Loss: -12.2761
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.8062

Learning rate: 0.00010282705667702727
Re-generating waveforms for posterior prior.
Train Epoch: 983 [0/90000 (0%)]	Loss: -4.1681	Cost: 24.96s
Train Epoch: 983 [20480/90000 (23%)]	Loss: -13.1982	Cost: 6.15s
Train Epoch: 983 [40960/90000 (45%)]	Loss: -12.7846	Cost: 7.36s
Train Epoch: 983 [61440/90000 (68%)]	Loss: -13.1599	Cost: 5.81s
Train Epoch: 983 [81920/90000 (91%)]	Loss: -13.1396	Cost: 6.11s
Train Epoch: 983 	Average Loss: -12.3724
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.9093

Learning rate: 0.0001026700364047052
Re-generating waveforms for posterior prior.
Train Epoch: 984 [0/90000 (0%)]	Loss: -4.0844	Cost: 25.05s
Train Epoch: 984 [20480/90000 (23%)]	Loss: -13.1194	Cost: 6.13s
Train Epoch: 984 [40960/90000 (45%)]	Loss: -12.7592	Cost: 7.22s
Train Epoch: 984 [61440/90000 (68%)]	Loss: -12.8757	Cost: 5.87s
Train Epoch: 984 [81920/90000 (91%)]	Loss: -13.1619	Cost: 5.79s
Train Epoch: 984 	Average Loss: -12.3400
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.0320

Learning rate: 0.0001025130095443337
Re-generating waveforms for posterior prior.
Train Epoch: 985 [0/90000 (0%)]	Loss: -4.1373	Cost: 25.33s
Train Epoch: 985 [20480/90000 (23%)]	Loss: -13.3181	Cost: 6.12s
Train Epoch: 985 [40960/90000 (45%)]	Loss: -12.6548	Cost: 7.10s
Train Epoch: 985 [61440/90000 (68%)]	Loss: -13.2275	Cost: 5.90s
Train Epoch: 985 [81920/90000 (91%)]	Loss: -13.1220	Cost: 5.75s
Train Epoch: 985 	Average Loss: -12.3907
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.7208

Learning rate: 0.00010235597648336099
Re-generating waveforms for posterior prior.
Train Epoch: 986 [0/90000 (0%)]	Loss: -3.4083	Cost: 24.84s
Train Epoch: 986 [20480/90000 (23%)]	Loss: -13.1035	Cost: 6.22s
Train Epoch: 986 [40960/90000 (45%)]	Loss: -12.7641	Cost: 7.23s
Train Epoch: 986 [61440/90000 (68%)]	Loss: -13.0447	Cost: 5.87s
Train Epoch: 986 [81920/90000 (91%)]	Loss: -13.2267	Cost: 6.08s
Train Epoch: 986 	Average Loss: -12.3624
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.9285

Learning rate: 0.00010219893760925047
Re-generating waveforms for posterior prior.
Train Epoch: 987 [0/90000 (0%)]	Loss: -3.8592	Cost: 25.04s
Train Epoch: 987 [20480/90000 (23%)]	Loss: -13.1963	Cost: 6.14s
Train Epoch: 987 [40960/90000 (45%)]	Loss: -12.8696	Cost: 7.26s
Train Epoch: 987 [61440/90000 (68%)]	Loss: -13.1079	Cost: 5.82s
Train Epoch: 987 [81920/90000 (91%)]	Loss: -13.1740	Cost: 5.98s
Train Epoch: 987 	Average Loss: -12.4559
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.8549

Learning rate: 0.00010204189330948001
Re-generating waveforms for posterior prior.
Train Epoch: 988 [0/90000 (0%)]	Loss: -3.7569	Cost: 24.94s
Train Epoch: 988 [20480/90000 (23%)]	Loss: -13.0225	Cost: 6.09s
Train Epoch: 988 [40960/90000 (45%)]	Loss: -12.9188	Cost: 6.76s
Train Epoch: 988 [61440/90000 (68%)]	Loss: -13.1797	Cost: 5.89s
Train Epoch: 988 [81920/90000 (91%)]	Loss: -13.1623	Cost: 5.95s
Train Epoch: 988 	Average Loss: -12.4125
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.9253

Learning rate: 0.00010188484397154078
Re-generating waveforms for posterior prior.
Train Epoch: 989 [0/90000 (0%)]	Loss: -4.1945	Cost: 24.73s
Train Epoch: 989 [20480/90000 (23%)]	Loss: -13.2618	Cost: 6.12s
Train Epoch: 989 [40960/90000 (45%)]	Loss: -12.6606	Cost: 7.18s
Train Epoch: 989 [61440/90000 (68%)]	Loss: -13.2342	Cost: 5.83s
Train Epoch: 989 [81920/90000 (91%)]	Loss: -13.2572	Cost: 6.17s
Train Epoch: 989 	Average Loss: -12.4798
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.9948

Learning rate: 0.0001017277899829364
Re-generating waveforms for posterior prior.
Train Epoch: 990 [0/90000 (0%)]	Loss: -4.1983	Cost: 24.60s
Train Epoch: 990 [20480/90000 (23%)]	Loss: -13.3790	Cost: 6.14s
Train Epoch: 990 [40960/90000 (45%)]	Loss: -12.6619	Cost: 7.43s
Train Epoch: 990 [61440/90000 (68%)]	Loss: -13.0371	Cost: 5.91s
Train Epoch: 990 [81920/90000 (91%)]	Loss: -13.2156	Cost: 6.00s
Train Epoch: 990 	Average Loss: -12.4970
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.8848

Learning rate: 0.00010157073173118201
Re-generating waveforms for posterior prior.
Train Epoch: 991 [0/90000 (0%)]	Loss: -4.4832	Cost: 24.47s
Train Epoch: 991 [20480/90000 (23%)]	Loss: -13.1291	Cost: 6.18s
Train Epoch: 991 [40960/90000 (45%)]	Loss: -12.7412	Cost: 6.89s
Train Epoch: 991 [61440/90000 (68%)]	Loss: -13.1388	Cost: 5.88s
Train Epoch: 991 [81920/90000 (91%)]	Loss: -13.2019	Cost: 5.96s
Train Epoch: 991 	Average Loss: -12.4703
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.0904

Learning rate: 0.00010141366960380323
Re-generating waveforms for posterior prior.
Train Epoch: 992 [0/90000 (0%)]	Loss: -3.6104	Cost: 25.05s
Train Epoch: 992 [20480/90000 (23%)]	Loss: -13.2654	Cost: 6.15s
Train Epoch: 992 [40960/90000 (45%)]	Loss: -12.9154	Cost: 7.34s
Train Epoch: 992 [61440/90000 (68%)]	Loss: -13.2766	Cost: 5.81s
Train Epoch: 992 [81920/90000 (91%)]	Loss: -13.4068	Cost: 6.14s
Train Epoch: 992 	Average Loss: -12.5888
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.0731

Learning rate: 0.00010125660398833521
Re-generating waveforms for posterior prior.
Train Epoch: 993 [0/90000 (0%)]	Loss: -4.1752	Cost: 24.99s
Train Epoch: 993 [20480/90000 (23%)]	Loss: -13.3486	Cost: 6.13s
Train Epoch: 993 [40960/90000 (45%)]	Loss: -12.5401	Cost: 7.46s
Train Epoch: 993 [61440/90000 (68%)]	Loss: -13.0915	Cost: 5.85s
Train Epoch: 993 [81920/90000 (91%)]	Loss: -13.1146	Cost: 6.19s
Train Epoch: 993 	Average Loss: -12.4337
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.8632

Learning rate: 0.00010109953527232178
Re-generating waveforms for posterior prior.
Train Epoch: 994 [0/90000 (0%)]	Loss: -4.3015	Cost: 24.43s
Train Epoch: 994 [20480/90000 (23%)]	Loss: -13.0609	Cost: 6.15s
Train Epoch: 994 [40960/90000 (45%)]	Loss: -12.7432	Cost: 7.22s
Train Epoch: 994 [61440/90000 (68%)]	Loss: -12.9269	Cost: 5.84s
Train Epoch: 994 [81920/90000 (91%)]	Loss: -13.1193	Cost: 6.07s
Train Epoch: 994 	Average Loss: -12.3140
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.7782

Learning rate: 0.00010094246384331434
Re-generating waveforms for posterior prior.
Train Epoch: 995 [0/90000 (0%)]	Loss: -3.9038	Cost: 24.57s
Train Epoch: 995 [20480/90000 (23%)]	Loss: -12.3817	Cost: 6.23s
Train Epoch: 995 [40960/90000 (45%)]	Loss: -12.2408	Cost: 7.01s
Train Epoch: 995 [61440/90000 (68%)]	Loss: -12.4789	Cost: 5.90s
Train Epoch: 995 [81920/90000 (91%)]	Loss: -12.7651	Cost: 6.04s
Train Epoch: 995 	Average Loss: -11.9134
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.7911

Learning rate: 0.00010078539008887107
Re-generating waveforms for posterior prior.
Train Epoch: 996 [0/90000 (0%)]	Loss: -3.3881	Cost: 26.01s
Train Epoch: 996 [20480/90000 (23%)]	Loss: -13.1622	Cost: 6.11s
Train Epoch: 996 [40960/90000 (45%)]	Loss: -12.8061	Cost: 7.04s
Train Epoch: 996 [61440/90000 (68%)]	Loss: -13.0926	Cost: 5.88s
Train Epoch: 996 [81920/90000 (91%)]	Loss: -13.4928	Cost: 5.95s
Train Epoch: 996 	Average Loss: -12.3472
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.0209

Learning rate: 0.00010062831439655584
Re-generating waveforms for posterior prior.
Train Epoch: 997 [0/90000 (0%)]	Loss: -4.2356	Cost: 24.92s
Train Epoch: 997 [20480/90000 (23%)]	Loss: -12.8926	Cost: 6.12s
Train Epoch: 997 [40960/90000 (45%)]	Loss: -12.6056	Cost: 7.22s
Train Epoch: 997 [61440/90000 (68%)]	Loss: -13.1271	Cost: 5.81s
Train Epoch: 997 [81920/90000 (91%)]	Loss: -13.2209	Cost: 6.18s
Train Epoch: 997 	Average Loss: -12.3513
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.1056

Learning rate: 0.00010047123715393726
Re-generating waveforms for posterior prior.
Train Epoch: 998 [0/90000 (0%)]	Loss: -4.3200	Cost: 24.66s
Train Epoch: 998 [20480/90000 (23%)]	Loss: -13.2818	Cost: 6.15s
Train Epoch: 998 [40960/90000 (45%)]	Loss: -12.7750	Cost: 6.70s
Train Epoch: 998 [61440/90000 (68%)]	Loss: -13.1353	Cost: 5.91s
Train Epoch: 998 [81920/90000 (91%)]	Loss: -13.2448	Cost: 6.28s
Train Epoch: 998 	Average Loss: -12.5601
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.0197

Learning rate: 0.00010031415874858787
Re-generating waveforms for posterior prior.
Train Epoch: 999 [0/90000 (0%)]	Loss: -4.6985	Cost: 25.01s
Train Epoch: 999 [20480/90000 (23%)]	Loss: -13.3107	Cost: 6.19s
Train Epoch: 999 [40960/90000 (45%)]	Loss: -13.0116	Cost: 7.01s
Train Epoch: 999 [61440/90000 (68%)]	Loss: -13.4054	Cost: 5.88s
Train Epoch: 999 [81920/90000 (91%)]	Loss: -13.4209	Cost: 5.76s
Train Epoch: 999 	Average Loss: -12.6549
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.9331

Learning rate: 0.00010015707956808302
Re-generating waveforms for posterior prior.
Train Epoch: 1000 [0/90000 (0%)]	Loss: -4.2464	Cost: 25.23s
Train Epoch: 1000 [20480/90000 (23%)]	Loss: -13.3779	Cost: 6.18s
Train Epoch: 1000 [40960/90000 (45%)]	Loss: -12.8519	Cost: 6.76s
Train Epoch: 1000 [61440/90000 (68%)]	Loss: -13.3468	Cost: 5.96s
Train Epoch: 1000 [81920/90000 (91%)]	Loss: -13.3260	Cost: 5.79s
Train Epoch: 1000 	Average Loss: -12.5334
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.0892

Saving model as model_sample_from_all_posterior.pt_e1000 & waveforms_supplementary_sample_from_all_posterior.hdf5_e1000
Learning rate: 9.999999999999991e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1001 [0/90000 (0%)]	Loss: -4.1555	Cost: 24.99s
Train Epoch: 1001 [20480/90000 (23%)]	Loss: -13.3894	Cost: 6.18s
Train Epoch: 1001 [40960/90000 (45%)]	Loss: -12.9483	Cost: 6.96s
Train Epoch: 1001 [61440/90000 (68%)]	Loss: -13.4049	Cost: 5.94s
Train Epoch: 1001 [81920/90000 (91%)]	Loss: -13.4656	Cost: 5.75s
Train Epoch: 1001 	Average Loss: -12.6585
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.1099

Learning rate: 9.984292043191681e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1002 [0/90000 (0%)]	Loss: -4.3934	Cost: 25.64s
Train Epoch: 1002 [20480/90000 (23%)]	Loss: -13.6537	Cost: 6.10s
Train Epoch: 1002 [40960/90000 (45%)]	Loss: -12.8987	Cost: 7.10s
Train Epoch: 1002 [61440/90000 (68%)]	Loss: -13.3089	Cost: 5.81s
Train Epoch: 1002 [81920/90000 (91%)]	Loss: -13.6280	Cost: 5.99s
Train Epoch: 1002 	Average Loss: -12.7464
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.2352

Learning rate: 9.968584125141195e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1003 [0/90000 (0%)]	Loss: -4.1561	Cost: 25.39s
Train Epoch: 1003 [20480/90000 (23%)]	Loss: -13.4736	Cost: 6.10s
Train Epoch: 1003 [40960/90000 (45%)]	Loss: -12.9799	Cost: 7.04s
Train Epoch: 1003 [61440/90000 (68%)]	Loss: -13.1916	Cost: 5.84s
Train Epoch: 1003 [81920/90000 (91%)]	Loss: -13.2054	Cost: 6.03s
Train Epoch: 1003 	Average Loss: -12.6379
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.1318

Learning rate: 9.952876284606256e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1004 [0/90000 (0%)]	Loss: -3.4722	Cost: 24.60s
Train Epoch: 1004 [20480/90000 (23%)]	Loss: -13.3761	Cost: 6.12s
Train Epoch: 1004 [40960/90000 (45%)]	Loss: -13.1141	Cost: 7.26s
Train Epoch: 1004 [61440/90000 (68%)]	Loss: -13.4621	Cost: 5.85s
Train Epoch: 1004 [81920/90000 (91%)]	Loss: -13.5282	Cost: 5.86s
Train Epoch: 1004 	Average Loss: -12.7002
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.1502

Learning rate: 9.937168560344399e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1005 [0/90000 (0%)]	Loss: -4.8587	Cost: 24.90s
Train Epoch: 1005 [20480/90000 (23%)]	Loss: -13.6215	Cost: 6.11s
Train Epoch: 1005 [40960/90000 (45%)]	Loss: -13.0530	Cost: 7.33s
Train Epoch: 1005 [61440/90000 (68%)]	Loss: -13.4855	Cost: 5.82s
Train Epoch: 1005 [81920/90000 (91%)]	Loss: -13.6791	Cost: 6.17s
Train Epoch: 1005 	Average Loss: -12.7681
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.1534

Learning rate: 9.921460991112877e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1006 [0/90000 (0%)]	Loss: -4.3542	Cost: 25.23s
Train Epoch: 1006 [20480/90000 (23%)]	Loss: -13.7032	Cost: 6.13s
Train Epoch: 1006 [40960/90000 (45%)]	Loss: -12.8514	Cost: 7.22s
Train Epoch: 1006 [61440/90000 (68%)]	Loss: -13.3760	Cost: 5.83s
Train Epoch: 1006 [81920/90000 (91%)]	Loss: -12.9863	Cost: 5.97s
Train Epoch: 1006 	Average Loss: -12.5998
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.6772

Learning rate: 9.905753615668548e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1007 [0/90000 (0%)]	Loss: -4.0325	Cost: 26.07s
Train Epoch: 1007 [20480/90000 (23%)]	Loss: -12.6337	Cost: 6.16s
Train Epoch: 1007 [40960/90000 (45%)]	Loss: -12.3321	Cost: 6.85s
Train Epoch: 1007 [61440/90000 (68%)]	Loss: -13.0049	Cost: 5.85s
Train Epoch: 1007 [81920/90000 (91%)]	Loss: -13.2670	Cost: 6.07s
Train Epoch: 1007 	Average Loss: -12.1508
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.0713

Learning rate: 9.890046472767807e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1008 [0/90000 (0%)]	Loss: -3.5841	Cost: 25.37s
Train Epoch: 1008 [20480/90000 (23%)]	Loss: -13.3252	Cost: 6.13s
Train Epoch: 1008 [40960/90000 (45%)]	Loss: -12.8960	Cost: 7.17s
Train Epoch: 1008 [61440/90000 (68%)]	Loss: -13.5302	Cost: 5.83s
Train Epoch: 1008 [81920/90000 (91%)]	Loss: -12.7994	Cost: 5.82s
Train Epoch: 1008 	Average Loss: -12.5516
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.8276

Learning rate: 9.874339601166461e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1009 [0/90000 (0%)]	Loss: -3.1782	Cost: 24.93s
Train Epoch: 1009 [20480/90000 (23%)]	Loss: -13.2361	Cost: 6.14s
Train Epoch: 1009 [40960/90000 (45%)]	Loss: -13.0337	Cost: 7.18s
Train Epoch: 1009 [61440/90000 (68%)]	Loss: -13.4064	Cost: 5.85s
Train Epoch: 1009 [81920/90000 (91%)]	Loss: -13.3874	Cost: 5.81s
Train Epoch: 1009 	Average Loss: -12.5151
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.1250

Learning rate: 9.858633039619662e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1010 [0/90000 (0%)]	Loss: -3.8910	Cost: 26.51s
Train Epoch: 1010 [20480/90000 (23%)]	Loss: -13.5567	Cost: 6.08s
Train Epoch: 1010 [40960/90000 (45%)]	Loss: -12.9024	Cost: 6.34s
Train Epoch: 1010 [61440/90000 (68%)]	Loss: -13.3803	Cost: 5.96s
Train Epoch: 1010 [81920/90000 (91%)]	Loss: -13.5857	Cost: 5.88s
Train Epoch: 1010 	Average Loss: -12.7792
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.3155

Learning rate: 9.842926826881783e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1011 [0/90000 (0%)]	Loss: -5.0227	Cost: 24.36s
Train Epoch: 1011 [20480/90000 (23%)]	Loss: -13.8348	Cost: 6.18s
Train Epoch: 1011 [40960/90000 (45%)]	Loss: -12.9662	Cost: 7.33s
Train Epoch: 1011 [61440/90000 (68%)]	Loss: -13.5275	Cost: 5.83s
Train Epoch: 1011 [81920/90000 (91%)]	Loss: -13.6880	Cost: 5.98s
Train Epoch: 1011 	Average Loss: -12.9229
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.2458

Learning rate: 9.827221001706344e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1012 [0/90000 (0%)]	Loss: -4.6500	Cost: 24.98s
Train Epoch: 1012 [20480/90000 (23%)]	Loss: -13.6017	Cost: 6.14s
Train Epoch: 1012 [40960/90000 (45%)]	Loss: -13.0414	Cost: 7.42s
Train Epoch: 1012 [61440/90000 (68%)]	Loss: -13.1649	Cost: 5.81s
Train Epoch: 1012 [81920/90000 (91%)]	Loss: -13.4271	Cost: 5.98s
Train Epoch: 1012 	Average Loss: -12.6739
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.2113

Learning rate: 9.811515602845904e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1013 [0/90000 (0%)]	Loss: -3.9569	Cost: 25.51s
Train Epoch: 1013 [20480/90000 (23%)]	Loss: -13.3457	Cost: 6.10s
Train Epoch: 1013 [40960/90000 (45%)]	Loss: -13.1076	Cost: 7.20s
Train Epoch: 1013 [61440/90000 (68%)]	Loss: -13.5297	Cost: 5.82s
Train Epoch: 1013 [81920/90000 (91%)]	Loss: -13.7920	Cost: 5.98s
Train Epoch: 1013 	Average Loss: -12.8178
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.4088

Learning rate: 9.795810669051982e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1014 [0/90000 (0%)]	Loss: -5.1459	Cost: 25.17s
Train Epoch: 1014 [20480/90000 (23%)]	Loss: -13.7881	Cost: 6.11s
Train Epoch: 1014 [40960/90000 (45%)]	Loss: -13.3943	Cost: 6.77s
Train Epoch: 1014 [61440/90000 (68%)]	Loss: -13.7354	Cost: 5.87s
Train Epoch: 1014 [81920/90000 (91%)]	Loss: -13.8902	Cost: 5.80s
Train Epoch: 1014 	Average Loss: -13.0105
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.3036

Learning rate: 9.780106239074937e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1015 [0/90000 (0%)]	Loss: -4.7458	Cost: 25.09s
Train Epoch: 1015 [20480/90000 (23%)]	Loss: -13.6975	Cost: 6.12s
Train Epoch: 1015 [40960/90000 (45%)]	Loss: -13.1329	Cost: 7.04s
Train Epoch: 1015 [61440/90000 (68%)]	Loss: -13.6311	Cost: 5.86s
Train Epoch: 1015 [81920/90000 (91%)]	Loss: -13.5848	Cost: 5.80s
Train Epoch: 1015 	Average Loss: -12.9064
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.2745

Learning rate: 9.764402351663885e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1016 [0/90000 (0%)]	Loss: -3.4314	Cost: 25.93s
Train Epoch: 1016 [20480/90000 (23%)]	Loss: -13.8308	Cost: 6.02s
Train Epoch: 1016 [40960/90000 (45%)]	Loss: -13.4087	Cost: 7.39s
Train Epoch: 1016 [61440/90000 (68%)]	Loss: -13.7486	Cost: 5.82s
Train Epoch: 1016 [81920/90000 (91%)]	Loss: -13.8532	Cost: 5.68s
Train Epoch: 1016 	Average Loss: -13.0297
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.4087

Learning rate: 9.748699045566611e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1017 [0/90000 (0%)]	Loss: -4.6805	Cost: 24.82s
Train Epoch: 1017 [20480/90000 (23%)]	Loss: -13.8566	Cost: 6.09s
Train Epoch: 1017 [40960/90000 (45%)]	Loss: -13.4647	Cost: 7.17s
Train Epoch: 1017 [61440/90000 (68%)]	Loss: -13.7286	Cost: 5.85s
Train Epoch: 1017 [81920/90000 (91%)]	Loss: -13.7352	Cost: 5.83s
Train Epoch: 1017 	Average Loss: -13.0014
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.3007

Learning rate: 9.732996359529464e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1018 [0/90000 (0%)]	Loss: -3.7585	Cost: 25.24s
Train Epoch: 1018 [20480/90000 (23%)]	Loss: -13.8771	Cost: 6.14s
Train Epoch: 1018 [40960/90000 (45%)]	Loss: -13.4687	Cost: 7.16s
Train Epoch: 1018 [61440/90000 (68%)]	Loss: -13.7287	Cost: 5.83s
Train Epoch: 1018 [81920/90000 (91%)]	Loss: -13.9256	Cost: 5.78s
Train Epoch: 1018 	Average Loss: -13.0246
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.3510

Learning rate: 9.717294332297253e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1019 [0/90000 (0%)]	Loss: -4.9985	Cost: 26.06s
Train Epoch: 1019 [20480/90000 (23%)]	Loss: -13.9235	Cost: 6.07s
Train Epoch: 1019 [40960/90000 (45%)]	Loss: -13.3438	Cost: 7.04s
Train Epoch: 1019 [61440/90000 (68%)]	Loss: -13.8346	Cost: 5.88s
Train Epoch: 1019 [81920/90000 (91%)]	Loss: -13.5446	Cost: 6.03s
Train Epoch: 1019 	Average Loss: -13.0378
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.3780

Learning rate: 9.701593002613176e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1020 [0/90000 (0%)]	Loss: -4.5364	Cost: 24.66s
Train Epoch: 1020 [20480/90000 (23%)]	Loss: -13.6349	Cost: 6.13s
Train Epoch: 1020 [40960/90000 (45%)]	Loss: -13.2988	Cost: 6.37s
Train Epoch: 1020 [61440/90000 (68%)]	Loss: -13.7807	Cost: 5.95s
Train Epoch: 1020 [81920/90000 (91%)]	Loss: -13.7789	Cost: 5.80s
Train Epoch: 1020 	Average Loss: -12.9837
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.4272

Learning rate: 9.685892409218702e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1021 [0/90000 (0%)]	Loss: -4.5757	Cost: 25.07s
Train Epoch: 1021 [20480/90000 (23%)]	Loss: -13.7817	Cost: 6.19s
Train Epoch: 1021 [40960/90000 (45%)]	Loss: -13.2604	Cost: 7.28s
Train Epoch: 1021 [61440/90000 (68%)]	Loss: -13.8223	Cost: 5.83s
Train Epoch: 1021 [81920/90000 (91%)]	Loss: -13.8712	Cost: 5.94s
Train Epoch: 1021 	Average Loss: -13.0116
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.2699

Learning rate: 9.670192590853486e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1022 [0/90000 (0%)]	Loss: -4.7160	Cost: 24.45s
Train Epoch: 1022 [20480/90000 (23%)]	Loss: -13.8359	Cost: 6.16s
Train Epoch: 1022 [40960/90000 (45%)]	Loss: -13.4207	Cost: 7.29s
Train Epoch: 1022 [61440/90000 (68%)]	Loss: -13.8901	Cost: 5.89s
Train Epoch: 1022 [81920/90000 (91%)]	Loss: -13.6852	Cost: 6.07s
Train Epoch: 1022 	Average Loss: -13.0661
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.4973

Learning rate: 9.654493586255264e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1023 [0/90000 (0%)]	Loss: -5.1080	Cost: 25.20s
Train Epoch: 1023 [20480/90000 (23%)]	Loss: -13.6714	Cost: 6.12s
Train Epoch: 1023 [40960/90000 (45%)]	Loss: -12.5696	Cost: 7.39s
Train Epoch: 1023 [61440/90000 (68%)]	Loss: -12.9396	Cost: 5.92s
Train Epoch: 1023 [81920/90000 (91%)]	Loss: -13.3064	Cost: 5.91s
Train Epoch: 1023 	Average Loss: -12.4965
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.0626

Learning rate: 9.638795434159772e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1024 [0/90000 (0%)]	Loss: -4.1940	Cost: 24.36s
Train Epoch: 1024 [20480/90000 (23%)]	Loss: -13.6405	Cost: 6.16s
Train Epoch: 1024 [40960/90000 (45%)]	Loss: -12.9377	Cost: 6.73s
Train Epoch: 1024 [61440/90000 (68%)]	Loss: -13.5553	Cost: 6.03s
Train Epoch: 1024 [81920/90000 (91%)]	Loss: -13.8380	Cost: 6.19s
Train Epoch: 1024 	Average Loss: -12.7694
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.4555

Learning rate: 9.623098173300638e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1025 [0/90000 (0%)]	Loss: -4.7647	Cost: 26.21s
Train Epoch: 1025 [20480/90000 (23%)]	Loss: -13.8793	Cost: 6.11s
Train Epoch: 1025 [40960/90000 (45%)]	Loss: -13.4335	Cost: 6.98s
Train Epoch: 1025 [61440/90000 (68%)]	Loss: -13.7030	Cost: 5.88s
Train Epoch: 1025 [81920/90000 (91%)]	Loss: -14.0042	Cost: 6.00s
Train Epoch: 1025 	Average Loss: -13.1153
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.4804

Learning rate: 9.607401842409298e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1026 [0/90000 (0%)]	Loss: -5.0077	Cost: 25.20s
Train Epoch: 1026 [20480/90000 (23%)]	Loss: -13.8719	Cost: 6.17s
Train Epoch: 1026 [40960/90000 (45%)]	Loss: -13.4506	Cost: 7.31s
Train Epoch: 1026 [61440/90000 (68%)]	Loss: -13.7024	Cost: 5.83s
Train Epoch: 1026 [81920/90000 (91%)]	Loss: -14.0506	Cost: 6.22s
Train Epoch: 1026 	Average Loss: -13.1866
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.3760

Learning rate: 9.591706480214883e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1027 [0/90000 (0%)]	Loss: -4.9078	Cost: 26.44s
Train Epoch: 1027 [20480/90000 (23%)]	Loss: -14.0119	Cost: 6.06s
Train Epoch: 1027 [40960/90000 (45%)]	Loss: -13.1881	Cost: 6.62s
Train Epoch: 1027 [61440/90000 (68%)]	Loss: -13.6490	Cost: 5.89s
Train Epoch: 1027 [81920/90000 (91%)]	Loss: -13.9133	Cost: 5.71s
Train Epoch: 1027 	Average Loss: -13.0723
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.3866

Learning rate: 9.576012125444143e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1028 [0/90000 (0%)]	Loss: -5.0415	Cost: 24.73s
Train Epoch: 1028 [20480/90000 (23%)]	Loss: -13.8104	Cost: 6.14s
Train Epoch: 1028 [40960/90000 (45%)]	Loss: -13.5730	Cost: 6.63s
Train Epoch: 1028 [61440/90000 (68%)]	Loss: -13.8076	Cost: 5.92s
Train Epoch: 1028 [81920/90000 (91%)]	Loss: -13.8492	Cost: 6.10s
Train Epoch: 1028 	Average Loss: -13.1241
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.2842

Learning rate: 9.560318816821336e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1029 [0/90000 (0%)]	Loss: -4.4399	Cost: 24.21s
Train Epoch: 1029 [20480/90000 (23%)]	Loss: -13.8341	Cost: 6.20s
Train Epoch: 1029 [40960/90000 (45%)]	Loss: -13.3409	Cost: 7.22s
Train Epoch: 1029 [61440/90000 (68%)]	Loss: -13.6421	Cost: 5.93s
Train Epoch: 1029 [81920/90000 (91%)]	Loss: -13.6200	Cost: 5.87s
Train Epoch: 1029 	Average Loss: -12.9857
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.2197

Learning rate: 9.544626593068141e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1030 [0/90000 (0%)]	Loss: -4.3189	Cost: 26.73s
Train Epoch: 1030 [20480/90000 (23%)]	Loss: -13.7320	Cost: 6.04s
Train Epoch: 1030 [40960/90000 (45%)]	Loss: -13.3879	Cost: 7.06s
Train Epoch: 1030 [61440/90000 (68%)]	Loss: -13.5629	Cost: 5.84s
Train Epoch: 1030 [81920/90000 (91%)]	Loss: -14.1251	Cost: 6.06s
Train Epoch: 1030 	Average Loss: -13.0590
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.6019

Learning rate: 9.528935492903556e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1031 [0/90000 (0%)]	Loss: -5.2604	Cost: 24.90s
Train Epoch: 1031 [20480/90000 (23%)]	Loss: -14.1736	Cost: 6.14s
Train Epoch: 1031 [40960/90000 (45%)]	Loss: -13.6540	Cost: 7.22s
Train Epoch: 1031 [61440/90000 (68%)]	Loss: -13.9871	Cost: 5.85s
Train Epoch: 1031 [81920/90000 (91%)]	Loss: -14.1450	Cost: 5.96s
Train Epoch: 1031 	Average Loss: -13.2934
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.5519

Learning rate: 9.51324555504382e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1032 [0/90000 (0%)]	Loss: -5.3848	Cost: 25.75s
Train Epoch: 1032 [20480/90000 (23%)]	Loss: -14.0343	Cost: 6.09s
Train Epoch: 1032 [40960/90000 (45%)]	Loss: -13.6274	Cost: 7.26s
Train Epoch: 1032 [61440/90000 (68%)]	Loss: -14.0528	Cost: 5.84s
Train Epoch: 1032 [81920/90000 (91%)]	Loss: -14.0017	Cost: 5.82s
Train Epoch: 1032 	Average Loss: -13.2935
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.4075

Learning rate: 9.497556818202289e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1033 [0/90000 (0%)]	Loss: -4.4473	Cost: 25.33s
Train Epoch: 1033 [20480/90000 (23%)]	Loss: -14.0778	Cost: 6.13s
Train Epoch: 1033 [40960/90000 (45%)]	Loss: -13.2909	Cost: 6.39s
Train Epoch: 1033 [61440/90000 (68%)]	Loss: -13.7492	Cost: 5.98s
Train Epoch: 1033 [81920/90000 (91%)]	Loss: -13.8868	Cost: 5.71s
Train Epoch: 1033 	Average Loss: -13.0734
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.3733

Learning rate: 9.481869321089362e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1034 [0/90000 (0%)]	Loss: -4.6332	Cost: 24.48s
Train Epoch: 1034 [20480/90000 (23%)]	Loss: -14.0177	Cost: 6.17s
Train Epoch: 1034 [40960/90000 (45%)]	Loss: -13.4725	Cost: 7.15s
Train Epoch: 1034 [61440/90000 (68%)]	Loss: -14.0963	Cost: 5.86s
Train Epoch: 1034 [81920/90000 (91%)]	Loss: -13.9559	Cost: 5.91s
Train Epoch: 1034 	Average Loss: -13.2399
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.5440

Learning rate: 9.466183102412379e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1035 [0/90000 (0%)]	Loss: -4.6274	Cost: 24.76s
Train Epoch: 1035 [20480/90000 (23%)]	Loss: -14.0237	Cost: 6.11s
Train Epoch: 1035 [40960/90000 (45%)]	Loss: -13.4003	Cost: 7.04s
Train Epoch: 1035 [61440/90000 (68%)]	Loss: -13.9014	Cost: 5.85s
Train Epoch: 1035 [81920/90000 (91%)]	Loss: -14.0474	Cost: 6.03s
Train Epoch: 1035 	Average Loss: -13.2101
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.6366

Learning rate: 9.450498200875528e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1036 [0/90000 (0%)]	Loss: -4.7026	Cost: 24.64s
Train Epoch: 1036 [20480/90000 (23%)]	Loss: -14.1619	Cost: 6.16s
Train Epoch: 1036 [40960/90000 (45%)]	Loss: -13.5537	Cost: 7.32s
Train Epoch: 1036 [61440/90000 (68%)]	Loss: -14.0254	Cost: 5.85s
Train Epoch: 1036 [81920/90000 (91%)]	Loss: -14.0644	Cost: 5.85s
Train Epoch: 1036 	Average Loss: -13.2961
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.6261

Learning rate: 9.434814655179739e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1037 [0/90000 (0%)]	Loss: -4.5985	Cost: 24.41s
Train Epoch: 1037 [20480/90000 (23%)]	Loss: -13.9455	Cost: 6.14s
Train Epoch: 1037 [40960/90000 (45%)]	Loss: -13.3646	Cost: 6.56s
Train Epoch: 1037 [61440/90000 (68%)]	Loss: -14.0429	Cost: 5.89s
Train Epoch: 1037 [81920/90000 (91%)]	Loss: -14.0677	Cost: 6.15s
Train Epoch: 1037 	Average Loss: -13.1640
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.5600

Learning rate: 9.419132504022604e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1038 [0/90000 (0%)]	Loss: -4.7311	Cost: 25.61s
Train Epoch: 1038 [20480/90000 (23%)]	Loss: -14.0024	Cost: 6.12s
Train Epoch: 1038 [40960/90000 (45%)]	Loss: -13.5283	Cost: 7.36s
Train Epoch: 1038 [61440/90000 (68%)]	Loss: -13.9631	Cost: 5.84s
Train Epoch: 1038 [81920/90000 (91%)]	Loss: -13.9998	Cost: 5.89s
Train Epoch: 1038 	Average Loss: -13.2553
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.5550

Learning rate: 9.403451786098276e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1039 [0/90000 (0%)]	Loss: -4.4061	Cost: 25.72s
Train Epoch: 1039 [20480/90000 (23%)]	Loss: -14.1562	Cost: 6.11s
Train Epoch: 1039 [40960/90000 (45%)]	Loss: -13.4609	Cost: 6.62s
Train Epoch: 1039 [61440/90000 (68%)]	Loss: -13.9674	Cost: 6.21s
Train Epoch: 1039 [81920/90000 (91%)]	Loss: -14.0916	Cost: 5.91s
Train Epoch: 1039 	Average Loss: -13.2704
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.5223

Learning rate: 9.387772540097365e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1040 [0/90000 (0%)]	Loss: -4.5827	Cost: 26.54s
Train Epoch: 1040 [20480/90000 (23%)]	Loss: -14.1615	Cost: 6.39s
Train Epoch: 1040 [40960/90000 (45%)]	Loss: -13.4469	Cost: 6.55s
Train Epoch: 1040 [61440/90000 (68%)]	Loss: -14.0100	Cost: 6.02s
Train Epoch: 1040 [81920/90000 (91%)]	Loss: -14.2252	Cost: 6.00s
Train Epoch: 1040 	Average Loss: -13.3154
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.6544

Learning rate: 9.37209480470685e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1041 [0/90000 (0%)]	Loss: -4.5233	Cost: 24.64s
Train Epoch: 1041 [20480/90000 (23%)]	Loss: -14.1780	Cost: 6.23s
Train Epoch: 1041 [40960/90000 (45%)]	Loss: -13.4666	Cost: 7.32s
Train Epoch: 1041 [61440/90000 (68%)]	Loss: -13.8222	Cost: 5.83s
Train Epoch: 1041 [81920/90000 (91%)]	Loss: -13.5080	Cost: 6.03s
Train Epoch: 1041 	Average Loss: -13.1023
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.1654

Learning rate: 9.356418618609986e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1042 [0/90000 (0%)]	Loss: -4.0941	Cost: 24.75s
Train Epoch: 1042 [20480/90000 (23%)]	Loss: -13.7099	Cost: 6.20s
Train Epoch: 1042 [40960/90000 (45%)]	Loss: -12.4523	Cost: 6.73s
Train Epoch: 1042 [61440/90000 (68%)]	Loss: -13.0163	Cost: 5.88s
Train Epoch: 1042 [81920/90000 (91%)]	Loss: -13.4913	Cost: 6.32s
Train Epoch: 1042 	Average Loss: -12.5763
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.4230

Learning rate: 9.340744020486203e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1043 [0/90000 (0%)]	Loss: -5.1385	Cost: 24.80s
Train Epoch: 1043 [20480/90000 (23%)]	Loss: -13.7721	Cost: 6.14s
Train Epoch: 1043 [40960/90000 (45%)]	Loss: -13.2702	Cost: 7.17s
Train Epoch: 1043 [61440/90000 (68%)]	Loss: -12.9006	Cost: 5.87s
Train Epoch: 1043 [81920/90000 (91%)]	Loss: -13.5461	Cost: 6.00s
Train Epoch: 1043 	Average Loss: -12.7637
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.1338

Learning rate: 9.325071049011018e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1044 [0/90000 (0%)]	Loss: -3.9185	Cost: 25.93s
Train Epoch: 1044 [20480/90000 (23%)]	Loss: -13.8467	Cost: 6.10s
Train Epoch: 1044 [40960/90000 (45%)]	Loss: -13.3268	Cost: 6.99s
Train Epoch: 1044 [61440/90000 (68%)]	Loss: -13.7938	Cost: 5.85s
Train Epoch: 1044 [81920/90000 (91%)]	Loss: -13.9524	Cost: 5.91s
Train Epoch: 1044 	Average Loss: -13.0492
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.3561

Learning rate: 9.309399742855926e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1045 [0/90000 (0%)]	Loss: -5.2651	Cost: 25.10s
Train Epoch: 1045 [20480/90000 (23%)]	Loss: -13.8833	Cost: 6.13s
Train Epoch: 1045 [40960/90000 (45%)]	Loss: -13.6163	Cost: 7.12s
Train Epoch: 1045 [61440/90000 (68%)]	Loss: -13.8754	Cost: 5.91s
Train Epoch: 1045 [81920/90000 (91%)]	Loss: -14.0894	Cost: 6.09s
Train Epoch: 1045 	Average Loss: -13.2694
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.5914

Learning rate: 9.293730140688316e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1046 [0/90000 (0%)]	Loss: -5.2411	Cost: 24.84s
Train Epoch: 1046 [20480/90000 (23%)]	Loss: -14.3334	Cost: 6.14s
Train Epoch: 1046 [40960/90000 (45%)]	Loss: -13.7048	Cost: 7.21s
Train Epoch: 1046 [61440/90000 (68%)]	Loss: -14.0696	Cost: 5.87s
Train Epoch: 1046 [81920/90000 (91%)]	Loss: -14.1585	Cost: 6.16s
Train Epoch: 1046 	Average Loss: -13.4087
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.7453

Learning rate: 9.278062281171377e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1047 [0/90000 (0%)]	Loss: -5.1720	Cost: 25.64s
Train Epoch: 1047 [20480/90000 (23%)]	Loss: -14.3274	Cost: 6.15s
Train Epoch: 1047 [40960/90000 (45%)]	Loss: -13.7736	Cost: 7.24s
Train Epoch: 1047 [61440/90000 (68%)]	Loss: -14.1358	Cost: 5.84s
Train Epoch: 1047 [81920/90000 (91%)]	Loss: -14.3940	Cost: 6.20s
Train Epoch: 1047 	Average Loss: -13.4581
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.6050

Learning rate: 9.262396202963995e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1048 [0/90000 (0%)]	Loss: -5.0255	Cost: 25.69s
Train Epoch: 1048 [20480/90000 (23%)]	Loss: -14.0601	Cost: 6.13s
Train Epoch: 1048 [40960/90000 (45%)]	Loss: -13.9673	Cost: 7.12s
Train Epoch: 1048 [61440/90000 (68%)]	Loss: -14.0678	Cost: 5.87s
Train Epoch: 1048 [81920/90000 (91%)]	Loss: -14.2315	Cost: 5.79s
Train Epoch: 1048 	Average Loss: -13.4267
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.5955

Learning rate: 9.246731944720654e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1049 [0/90000 (0%)]	Loss: -5.3514	Cost: 24.71s
Train Epoch: 1049 [20480/90000 (23%)]	Loss: -14.3191	Cost: 6.14s
Train Epoch: 1049 [40960/90000 (45%)]	Loss: -13.9075	Cost: 7.21s
Train Epoch: 1049 [61440/90000 (68%)]	Loss: -14.1838	Cost: 5.83s
Train Epoch: 1049 [81920/90000 (91%)]	Loss: -14.3877	Cost: 6.09s
Train Epoch: 1049 	Average Loss: -13.5575
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.7099

Learning rate: 9.231069545091363e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1050 [0/90000 (0%)]	Loss: -4.7760	Cost: 24.89s
Train Epoch: 1050 [20480/90000 (23%)]	Loss: -14.1945	Cost: 6.18s
Train Epoch: 1050 [40960/90000 (45%)]	Loss: -13.6316	Cost: 6.79s
Train Epoch: 1050 [61440/90000 (68%)]	Loss: -12.9365	Cost: 5.93s
Train Epoch: 1050 [81920/90000 (91%)]	Loss: -13.2736	Cost: 5.74s
Train Epoch: 1050 	Average Loss: -13.0034
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.9629

Saving model as model_sample_from_all_posterior.pt_e1050 & waveforms_supplementary_sample_from_all_posterior.hdf5_e1050
Learning rate: 9.215409042721533e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1051 [0/90000 (0%)]	Loss: -3.1974	Cost: 25.44s
Train Epoch: 1051 [20480/90000 (23%)]	Loss: -13.6659	Cost: 6.13s
Train Epoch: 1051 [40960/90000 (45%)]	Loss: -13.4341	Cost: 7.42s
Train Epoch: 1051 [61440/90000 (68%)]	Loss: -13.7381	Cost: 5.86s
Train Epoch: 1051 [81920/90000 (91%)]	Loss: -13.9420	Cost: 5.71s
Train Epoch: 1051 	Average Loss: -12.9753
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.4466

Learning rate: 9.199750476251895e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1052 [0/90000 (0%)]	Loss: -4.4076	Cost: 24.60s
Train Epoch: 1052 [20480/90000 (23%)]	Loss: -14.1720	Cost: 6.10s
Train Epoch: 1052 [40960/90000 (45%)]	Loss: -13.6964	Cost: 6.67s
Train Epoch: 1052 [61440/90000 (68%)]	Loss: -14.2171	Cost: 5.98s
Train Epoch: 1052 [81920/90000 (91%)]	Loss: -14.4138	Cost: 5.72s
Train Epoch: 1052 	Average Loss: -13.3716
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.9281

Learning rate: 9.184093884318406e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1053 [0/90000 (0%)]	Loss: -4.9026	Cost: 25.01s
Train Epoch: 1053 [20480/90000 (23%)]	Loss: -14.1708	Cost: 6.18s
Train Epoch: 1053 [40960/90000 (45%)]	Loss: -13.7193	Cost: 7.11s
Train Epoch: 1053 [61440/90000 (68%)]	Loss: -14.1008	Cost: 5.84s
Train Epoch: 1053 [81920/90000 (91%)]	Loss: -14.1853	Cost: 5.94s
Train Epoch: 1053 	Average Loss: -13.3444
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.4834

Learning rate: 9.168439305552152e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1054 [0/90000 (0%)]	Loss: -4.6624	Cost: 25.43s
Train Epoch: 1054 [20480/90000 (23%)]	Loss: -14.1378	Cost: 6.12s
Train Epoch: 1054 [40960/90000 (45%)]	Loss: -13.6418	Cost: 7.05s
Train Epoch: 1054 [61440/90000 (68%)]	Loss: -14.2047	Cost: 5.85s
Train Epoch: 1054 [81920/90000 (91%)]	Loss: -14.3769	Cost: 5.90s
Train Epoch: 1054 	Average Loss: -13.3865
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.7315

Learning rate: 9.152786778579248e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1055 [0/90000 (0%)]	Loss: -5.1732	Cost: 26.80s
Train Epoch: 1055 [20480/90000 (23%)]	Loss: -14.3009	Cost: 6.04s
Train Epoch: 1055 [40960/90000 (45%)]	Loss: -13.8678	Cost: 7.04s
Train Epoch: 1055 [61440/90000 (68%)]	Loss: -14.1156	Cost: 5.87s
Train Epoch: 1055 [81920/90000 (91%)]	Loss: -14.5180	Cost: 6.00s
Train Epoch: 1055 	Average Loss: -13.5388
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.8773

Learning rate: 9.137136342020749e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1056 [0/90000 (0%)]	Loss: -5.0629	Cost: 24.82s
Train Epoch: 1056 [20480/90000 (23%)]	Loss: -14.3163	Cost: 6.10s
Train Epoch: 1056 [40960/90000 (45%)]	Loss: -14.0583	Cost: 7.43s
Train Epoch: 1056 [61440/90000 (68%)]	Loss: -14.2358	Cost: 5.86s
Train Epoch: 1056 [81920/90000 (91%)]	Loss: -14.3267	Cost: 5.73s
Train Epoch: 1056 	Average Loss: -13.6654
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.9041

Learning rate: 9.121488034492551e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1057 [0/90000 (0%)]	Loss: -4.6647	Cost: 24.90s
Train Epoch: 1057 [20480/90000 (23%)]	Loss: -14.5529	Cost: 6.14s
Train Epoch: 1057 [40960/90000 (45%)]	Loss: -14.0744	Cost: 7.45s
Train Epoch: 1057 [61440/90000 (68%)]	Loss: -14.0819	Cost: 5.82s
Train Epoch: 1057 [81920/90000 (91%)]	Loss: -12.1675	Cost: 5.98s
Train Epoch: 1057 	Average Loss: -13.1794
Re-generating waveforms for posterior prior.
Test set: Average loss: -2.9886

Learning rate: 9.105841894605297e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1058 [0/90000 (0%)]	Loss: -3.1792	Cost: 25.55s
Train Epoch: 1058 [20480/90000 (23%)]	Loss: -12.5842	Cost: 6.15s
Train Epoch: 1058 [40960/90000 (45%)]	Loss: -12.7461	Cost: 7.02s
Train Epoch: 1058 [61440/90000 (68%)]	Loss: -13.2568	Cost: 5.84s
Train Epoch: 1058 [81920/90000 (91%)]	Loss: -13.4851	Cost: 6.00s
Train Epoch: 1058 	Average Loss: -12.1402
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.3848

Learning rate: 9.090197960964284e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1059 [0/90000 (0%)]	Loss: -4.6028	Cost: 24.80s
Train Epoch: 1059 [20480/90000 (23%)]	Loss: -13.8253	Cost: 6.13s
Train Epoch: 1059 [40960/90000 (45%)]	Loss: -13.7431	Cost: 7.29s
Train Epoch: 1059 [61440/90000 (68%)]	Loss: -13.8202	Cost: 5.84s
Train Epoch: 1059 [81920/90000 (91%)]	Loss: -13.8979	Cost: 5.89s
Train Epoch: 1059 	Average Loss: -13.1190
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.2863

Learning rate: 9.07455627216936e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1060 [0/90000 (0%)]	Loss: -3.8764	Cost: 25.64s
Train Epoch: 1060 [20480/90000 (23%)]	Loss: -13.7617	Cost: 6.14s
Train Epoch: 1060 [40960/90000 (45%)]	Loss: -13.5438	Cost: 7.22s
Train Epoch: 1060 [61440/90000 (68%)]	Loss: -13.9139	Cost: 5.85s
Train Epoch: 1060 [81920/90000 (91%)]	Loss: -14.1198	Cost: 5.77s
Train Epoch: 1060 	Average Loss: -13.1004
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.6936

Learning rate: 9.058916866814837e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1061 [0/90000 (0%)]	Loss: -4.4114	Cost: 26.52s
Train Epoch: 1061 [20480/90000 (23%)]	Loss: -14.2915	Cost: 6.09s
Train Epoch: 1061 [40960/90000 (45%)]	Loss: -13.8406	Cost: 7.13s
Train Epoch: 1061 [61440/90000 (68%)]	Loss: -14.2013	Cost: 5.83s
Train Epoch: 1061 [81920/90000 (91%)]	Loss: -14.4588	Cost: 6.16s
Train Epoch: 1061 	Average Loss: -13.5199
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.7357

Learning rate: 9.043279783489398e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1062 [0/90000 (0%)]	Loss: -5.1620	Cost: 26.34s
Train Epoch: 1062 [20480/90000 (23%)]	Loss: -14.4707	Cost: 6.10s
Train Epoch: 1062 [40960/90000 (45%)]	Loss: -14.0358	Cost: 7.01s
Train Epoch: 1062 [61440/90000 (68%)]	Loss: -14.4355	Cost: 5.87s
Train Epoch: 1062 [81920/90000 (91%)]	Loss: -14.5153	Cost: 5.75s
Train Epoch: 1062 	Average Loss: -13.6430
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.8314

Learning rate: 9.027645060775989e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1063 [0/90000 (0%)]	Loss: -5.2289	Cost: 25.36s
Train Epoch: 1063 [20480/90000 (23%)]	Loss: -14.5909	Cost: 6.10s
Train Epoch: 1063 [40960/90000 (45%)]	Loss: -14.2624	Cost: 7.25s
Train Epoch: 1063 [61440/90000 (68%)]	Loss: -14.5252	Cost: 5.89s
Train Epoch: 1063 [81920/90000 (91%)]	Loss: -14.5566	Cost: 5.91s
Train Epoch: 1063 	Average Loss: -13.7755
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.9309

Learning rate: 9.01201273725173e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1064 [0/90000 (0%)]	Loss: -5.2230	Cost: 24.67s
Train Epoch: 1064 [20480/90000 (23%)]	Loss: -14.4607	Cost: 6.18s
Train Epoch: 1064 [40960/90000 (45%)]	Loss: -14.0404	Cost: 7.04s
Train Epoch: 1064 [61440/90000 (68%)]	Loss: -14.2434	Cost: 5.86s
Train Epoch: 1064 [81920/90000 (91%)]	Loss: -14.6925	Cost: 6.23s
Train Epoch: 1064 	Average Loss: -13.7583
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.0400

Learning rate: 8.996382851487832e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1065 [0/90000 (0%)]	Loss: -4.8570	Cost: 24.75s
Train Epoch: 1065 [20480/90000 (23%)]	Loss: -14.6906	Cost: 6.15s
Train Epoch: 1065 [40960/90000 (45%)]	Loss: -14.2138	Cost: 7.12s
Train Epoch: 1065 [61440/90000 (68%)]	Loss: -14.3652	Cost: 5.88s
Train Epoch: 1065 [81920/90000 (91%)]	Loss: -14.3384	Cost: 5.79s
Train Epoch: 1065 	Average Loss: -13.7943
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.7843

Learning rate: 8.980755442049481e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1066 [0/90000 (0%)]	Loss: -4.6478	Cost: 26.00s
Train Epoch: 1066 [20480/90000 (23%)]	Loss: -14.5916	Cost: 6.10s
Train Epoch: 1066 [40960/90000 (45%)]	Loss: -14.0863	Cost: 7.05s
Train Epoch: 1066 [61440/90000 (68%)]	Loss: -14.4539	Cost: 5.86s
Train Epoch: 1066 [81920/90000 (91%)]	Loss: -14.6431	Cost: 6.00s
Train Epoch: 1066 	Average Loss: -13.7515
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.8678

Learning rate: 8.965130547495756e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1067 [0/90000 (0%)]	Loss: -4.9712	Cost: 25.05s
Train Epoch: 1067 [20480/90000 (23%)]	Loss: -14.6914	Cost: 6.11s
Train Epoch: 1067 [40960/90000 (45%)]	Loss: -14.2536	Cost: 6.32s
Train Epoch: 1067 [61440/90000 (68%)]	Loss: -14.5804	Cost: 5.92s
Train Epoch: 1067 [81920/90000 (91%)]	Loss: -12.6129	Cost: 5.73s
Train Epoch: 1067 	Average Loss: -13.4640
Re-generating waveforms for posterior prior.
Test set: Average loss: -3.3662

Learning rate: 8.94950820637953e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1068 [0/90000 (0%)]	Loss: -4.1135	Cost: 25.36s
Train Epoch: 1068 [20480/90000 (23%)]	Loss: -12.9856	Cost: 6.34s
Train Epoch: 1068 [40960/90000 (45%)]	Loss: -12.8342	Cost: 7.47s
Train Epoch: 1068 [61440/90000 (68%)]	Loss: -13.3260	Cost: 6.06s
Train Epoch: 1068 [81920/90000 (91%)]	Loss: -13.8318	Cost: 6.12s
Train Epoch: 1068 	Average Loss: -12.5425
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.5898

Learning rate: 8.93388845724738e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1069 [0/90000 (0%)]	Loss: -4.8755	Cost: 26.79s
Train Epoch: 1069 [20480/90000 (23%)]	Loss: -14.0838	Cost: 6.47s
Train Epoch: 1069 [40960/90000 (45%)]	Loss: -13.9227	Cost: 7.19s
Train Epoch: 1069 [61440/90000 (68%)]	Loss: -14.1618	Cost: 6.13s
Train Epoch: 1069 [81920/90000 (91%)]	Loss: -14.2601	Cost: 6.90s
Train Epoch: 1069 	Average Loss: -13.4136
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.9613

Learning rate: 8.918271338639484e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1070 [0/90000 (0%)]	Loss: -5.2777	Cost: 26.73s
Train Epoch: 1070 [20480/90000 (23%)]	Loss: -14.4946	Cost: 6.45s
Train Epoch: 1070 [40960/90000 (45%)]	Loss: -14.2502	Cost: 7.22s
Train Epoch: 1070 [61440/90000 (68%)]	Loss: -14.6223	Cost: 6.39s
Train Epoch: 1070 [81920/90000 (91%)]	Loss: -14.6076	Cost: 6.36s
Train Epoch: 1070 	Average Loss: -13.7504
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.0323

Learning rate: 8.902656889089527e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1071 [0/90000 (0%)]	Loss: -5.4216	Cost: 26.76s
Train Epoch: 1071 [20480/90000 (23%)]	Loss: -14.7527	Cost: 6.37s
Train Epoch: 1071 [40960/90000 (45%)]	Loss: -14.2794	Cost: 7.39s
Train Epoch: 1071 [61440/90000 (68%)]	Loss: -14.5568	Cost: 6.06s
Train Epoch: 1071 [81920/90000 (91%)]	Loss: -14.6747	Cost: 6.32s
Train Epoch: 1071 	Average Loss: -13.8375
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.9638

Learning rate: 8.887045147124615e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1072 [0/90000 (0%)]	Loss: -4.4740	Cost: 27.13s
Train Epoch: 1072 [20480/90000 (23%)]	Loss: -14.5772	Cost: 6.25s
Train Epoch: 1072 [40960/90000 (45%)]	Loss: -14.3179	Cost: 7.34s
Train Epoch: 1072 [61440/90000 (68%)]	Loss: -14.6481	Cost: 6.23s
Train Epoch: 1072 [81920/90000 (91%)]	Loss: -14.8471	Cost: 6.35s
Train Epoch: 1072 	Average Loss: -13.8557
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.9907

Learning rate: 8.871436151265163e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1073 [0/90000 (0%)]	Loss: -5.2282	Cost: 26.37s
Train Epoch: 1073 [20480/90000 (23%)]	Loss: -14.6436	Cost: 6.40s
Train Epoch: 1073 [40960/90000 (45%)]	Loss: -14.3479	Cost: 7.02s
Train Epoch: 1073 [61440/90000 (68%)]	Loss: -14.5871	Cost: 6.02s
Train Epoch: 1073 [81920/90000 (91%)]	Loss: -14.7941	Cost: 6.59s
Train Epoch: 1073 	Average Loss: -13.9146
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.9224

Learning rate: 8.855829940024823e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1074 [0/90000 (0%)]	Loss: -4.9371	Cost: 25.21s
Train Epoch: 1074 [20480/90000 (23%)]	Loss: -14.6843	Cost: 6.38s
Train Epoch: 1074 [40960/90000 (45%)]	Loss: -14.2533	Cost: 7.02s
Train Epoch: 1074 [61440/90000 (68%)]	Loss: -14.5510	Cost: 5.96s
Train Epoch: 1074 [81920/90000 (91%)]	Loss: -14.7513	Cost: 5.85s
Train Epoch: 1074 	Average Loss: -13.8798
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.9380

Learning rate: 8.840226551910366e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1075 [0/90000 (0%)]	Loss: -5.4778	Cost: 25.34s
Train Epoch: 1075 [20480/90000 (23%)]	Loss: -14.7868	Cost: 6.20s
Train Epoch: 1075 [40960/90000 (45%)]	Loss: -14.1920	Cost: 7.38s
Train Epoch: 1075 [61440/90000 (68%)]	Loss: -14.6874	Cost: 5.83s
Train Epoch: 1075 [81920/90000 (91%)]	Loss: -14.6602	Cost: 5.84s
Train Epoch: 1075 	Average Loss: -13.9205
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.1598

Learning rate: 8.824626025421605e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1076 [0/90000 (0%)]	Loss: -5.1539	Cost: 24.87s
Train Epoch: 1076 [20480/90000 (23%)]	Loss: -14.6386	Cost: 6.13s
Train Epoch: 1076 [40960/90000 (45%)]	Loss: -14.1662	Cost: 6.99s
Train Epoch: 1076 [61440/90000 (68%)]	Loss: -14.6401	Cost: 5.85s
Train Epoch: 1076 [81920/90000 (91%)]	Loss: -14.7603	Cost: 6.04s
Train Epoch: 1076 	Average Loss: -13.8559
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.0172

Learning rate: 8.809028399051285e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1077 [0/90000 (0%)]	Loss: -4.8903	Cost: 24.69s
Train Epoch: 1077 [20480/90000 (23%)]	Loss: -14.7252	Cost: 6.19s
Train Epoch: 1077 [40960/90000 (45%)]	Loss: -14.4222	Cost: 6.48s
Train Epoch: 1077 [61440/90000 (68%)]	Loss: -14.7539	Cost: 5.91s
Train Epoch: 1077 [81920/90000 (91%)]	Loss: -14.9044	Cost: 5.67s
Train Epoch: 1077 	Average Loss: -14.0454
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.0669

Learning rate: 8.793433711285001e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1078 [0/90000 (0%)]	Loss: -5.5050	Cost: 25.44s
Train Epoch: 1078 [20480/90000 (23%)]	Loss: -14.9465	Cost: 6.15s
Train Epoch: 1078 [40960/90000 (45%)]	Loss: -14.2606	Cost: 7.08s
Train Epoch: 1078 [61440/90000 (68%)]	Loss: -14.7639	Cost: 5.83s
Train Epoch: 1078 [81920/90000 (91%)]	Loss: -14.7454	Cost: 5.70s
Train Epoch: 1078 	Average Loss: -14.0576
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.1407

Learning rate: 8.777842000601086e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1079 [0/90000 (0%)]	Loss: -5.2143	Cost: 25.92s
Train Epoch: 1079 [20480/90000 (23%)]	Loss: -15.0018	Cost: 6.15s
Train Epoch: 1079 [40960/90000 (45%)]	Loss: -14.5381	Cost: 6.89s
Train Epoch: 1079 [61440/90000 (68%)]	Loss: -14.7041	Cost: 5.88s
Train Epoch: 1079 [81920/90000 (91%)]	Loss: -14.4611	Cost: 5.76s
Train Epoch: 1079 	Average Loss: -13.9896
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.7776

Learning rate: 8.762253305470549e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1080 [0/90000 (0%)]	Loss: -4.8044	Cost: 25.93s
Train Epoch: 1080 [20480/90000 (23%)]	Loss: -14.4917	Cost: 6.10s
Train Epoch: 1080 [40960/90000 (45%)]	Loss: -14.2332	Cost: 6.89s
Train Epoch: 1080 [61440/90000 (68%)]	Loss: -14.5147	Cost: 5.99s
Train Epoch: 1080 [81920/90000 (91%)]	Loss: -14.6428	Cost: 5.71s
Train Epoch: 1080 	Average Loss: -13.7566
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.0395

Learning rate: 8.74666766435694e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1081 [0/90000 (0%)]	Loss: -5.6451	Cost: 25.43s
Train Epoch: 1081 [20480/90000 (23%)]	Loss: -14.8591	Cost: 6.12s
Train Epoch: 1081 [40960/90000 (45%)]	Loss: -14.5524	Cost: 6.75s
Train Epoch: 1081 [61440/90000 (68%)]	Loss: -14.7180	Cost: 5.89s
Train Epoch: 1081 [81920/90000 (91%)]	Loss: -14.9143	Cost: 5.87s
Train Epoch: 1081 	Average Loss: -14.0124
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.0550

Learning rate: 8.731085115716277e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1082 [0/90000 (0%)]	Loss: -5.3804	Cost: 26.43s
Train Epoch: 1082 [20480/90000 (23%)]	Loss: -14.8517	Cost: 6.19s
Train Epoch: 1082 [40960/90000 (45%)]	Loss: -14.6586	Cost: 6.84s
Train Epoch: 1082 [61440/90000 (68%)]	Loss: -14.8211	Cost: 5.87s
Train Epoch: 1082 [81920/90000 (91%)]	Loss: -14.8442	Cost: 5.81s
Train Epoch: 1082 	Average Loss: -14.0908
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.1652

Learning rate: 8.715505697996955e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1083 [0/90000 (0%)]	Loss: -5.1992	Cost: 26.00s
Train Epoch: 1083 [20480/90000 (23%)]	Loss: -14.9381	Cost: 6.09s
Train Epoch: 1083 [40960/90000 (45%)]	Loss: -14.3030	Cost: 7.13s
Train Epoch: 1083 [61440/90000 (68%)]	Loss: -14.6266	Cost: 5.86s
Train Epoch: 1083 [81920/90000 (91%)]	Loss: -14.9788	Cost: 6.01s
Train Epoch: 1083 	Average Loss: -14.0801
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.2196

Learning rate: 8.699929449639634e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1084 [0/90000 (0%)]	Loss: -5.5660	Cost: 25.93s
Train Epoch: 1084 [20480/90000 (23%)]	Loss: -14.9829	Cost: 6.18s
Train Epoch: 1084 [40960/90000 (45%)]	Loss: -14.4569	Cost: 6.99s
Train Epoch: 1084 [61440/90000 (68%)]	Loss: -14.8306	Cost: 5.82s
Train Epoch: 1084 [81920/90000 (91%)]	Loss: -14.8501	Cost: 5.83s
Train Epoch: 1084 	Average Loss: -14.0893
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.0911

Learning rate: 8.684356409077158e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1085 [0/90000 (0%)]	Loss: -5.2005	Cost: 25.91s
Train Epoch: 1085 [20480/90000 (23%)]	Loss: -14.9796	Cost: 6.12s
Train Epoch: 1085 [40960/90000 (45%)]	Loss: -14.2839	Cost: 7.07s
Train Epoch: 1085 [61440/90000 (68%)]	Loss: -14.7447	Cost: 5.86s
Train Epoch: 1085 [81920/90000 (91%)]	Loss: -14.7748	Cost: 5.69s
Train Epoch: 1085 	Average Loss: -14.0485
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.0956

Learning rate: 8.66878661473446e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1086 [0/90000 (0%)]	Loss: -4.7745	Cost: 24.50s
Train Epoch: 1086 [20480/90000 (23%)]	Loss: -14.8638	Cost: 6.16s
Train Epoch: 1086 [40960/90000 (45%)]	Loss: -14.4562	Cost: 7.47s
Train Epoch: 1086 [61440/90000 (68%)]	Loss: -14.7710	Cost: 5.85s
Train Epoch: 1086 [81920/90000 (91%)]	Loss: -14.7375	Cost: 5.71s
Train Epoch: 1086 	Average Loss: -14.0410
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.0639

Learning rate: 8.653220105028458e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1087 [0/90000 (0%)]	Loss: -4.7911	Cost: 26.05s
Train Epoch: 1087 [20480/90000 (23%)]	Loss: -14.8200	Cost: 6.12s
Train Epoch: 1087 [40960/90000 (45%)]	Loss: -14.5001	Cost: 7.03s
Train Epoch: 1087 [61440/90000 (68%)]	Loss: -14.8132	Cost: 5.85s
Train Epoch: 1087 [81920/90000 (91%)]	Loss: -15.0333	Cost: 6.23s
Train Epoch: 1087 	Average Loss: -14.0364
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.2161

Learning rate: 8.637656918367968e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1088 [0/90000 (0%)]	Loss: -5.2741	Cost: 25.48s
Train Epoch: 1088 [20480/90000 (23%)]	Loss: -15.1424	Cost: 6.15s
Train Epoch: 1088 [40960/90000 (45%)]	Loss: -14.6400	Cost: 7.02s
Train Epoch: 1088 [61440/90000 (68%)]	Loss: -14.7150	Cost: 5.87s
Train Epoch: 1088 [81920/90000 (91%)]	Loss: -15.0475	Cost: 5.76s
Train Epoch: 1088 	Average Loss: -14.2271
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.2363

Learning rate: 8.622097093153604e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1089 [0/90000 (0%)]	Loss: -5.7995	Cost: 24.59s
Train Epoch: 1089 [20480/90000 (23%)]	Loss: -15.0884	Cost: 6.12s
Train Epoch: 1089 [40960/90000 (45%)]	Loss: -14.4493	Cost: 7.22s
Train Epoch: 1089 [61440/90000 (68%)]	Loss: -14.9359	Cost: 5.87s
Train Epoch: 1089 [81920/90000 (91%)]	Loss: -15.1226	Cost: 5.84s
Train Epoch: 1089 	Average Loss: -14.1673
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.3238

Learning rate: 8.606540667777691e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1090 [0/90000 (0%)]	Loss: -6.0855	Cost: 25.18s
Train Epoch: 1090 [20480/90000 (23%)]	Loss: -15.0555	Cost: 6.13s
Train Epoch: 1090 [40960/90000 (45%)]	Loss: -14.5934	Cost: 7.17s
Train Epoch: 1090 [61440/90000 (68%)]	Loss: -14.8959	Cost: 5.83s
Train Epoch: 1090 [81920/90000 (91%)]	Loss: -15.1746	Cost: 5.96s
Train Epoch: 1090 	Average Loss: -14.2871
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.2882

Learning rate: 8.590987680624158e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1091 [0/90000 (0%)]	Loss: -4.4457	Cost: 25.41s
Train Epoch: 1091 [20480/90000 (23%)]	Loss: -15.2622	Cost: 6.19s
Train Epoch: 1091 [40960/90000 (45%)]	Loss: -14.8752	Cost: 7.18s
Train Epoch: 1091 [61440/90000 (68%)]	Loss: -14.9024	Cost: 5.88s
Train Epoch: 1091 [81920/90000 (91%)]	Loss: -14.9054	Cost: 5.71s
Train Epoch: 1091 	Average Loss: -14.2812
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.1758

Learning rate: 8.575438170068459e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1092 [0/90000 (0%)]	Loss: -5.1190	Cost: 25.47s
Train Epoch: 1092 [20480/90000 (23%)]	Loss: -15.0136	Cost: 6.14s
Train Epoch: 1092 [40960/90000 (45%)]	Loss: -14.6794	Cost: 7.08s
Train Epoch: 1092 [61440/90000 (68%)]	Loss: -14.8816	Cost: 5.87s
Train Epoch: 1092 [81920/90000 (91%)]	Loss: -15.1839	Cost: 6.05s
Train Epoch: 1092 	Average Loss: -14.2758
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.3241

Learning rate: 8.559892174477463e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1093 [0/90000 (0%)]	Loss: -5.9919	Cost: 25.10s
Train Epoch: 1093 [20480/90000 (23%)]	Loss: -15.2567	Cost: 6.13s
Train Epoch: 1093 [40960/90000 (45%)]	Loss: -14.7136	Cost: 7.29s
Train Epoch: 1093 [61440/90000 (68%)]	Loss: -15.0448	Cost: 5.85s
Train Epoch: 1093 [81920/90000 (91%)]	Loss: -15.2000	Cost: 5.69s
Train Epoch: 1093 	Average Loss: -14.3481
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.3469

Learning rate: 8.544349732209372e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1094 [0/90000 (0%)]	Loss: -4.8706	Cost: 26.43s
Train Epoch: 1094 [20480/90000 (23%)]	Loss: -15.0756	Cost: 6.08s
Train Epoch: 1094 [40960/90000 (45%)]	Loss: -14.7876	Cost: 6.89s
Train Epoch: 1094 [61440/90000 (68%)]	Loss: -14.8870	Cost: 5.87s
Train Epoch: 1094 [81920/90000 (91%)]	Loss: -15.1701	Cost: 5.75s
Train Epoch: 1094 	Average Loss: -14.3127
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.4018

Learning rate: 8.528810881613613e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1095 [0/90000 (0%)]	Loss: -5.8463	Cost: 24.83s
Train Epoch: 1095 [20480/90000 (23%)]	Loss: -15.1918	Cost: 6.15s
Train Epoch: 1095 [40960/90000 (45%)]	Loss: -14.8523	Cost: 7.40s
Train Epoch: 1095 [61440/90000 (68%)]	Loss: -14.9953	Cost: 5.84s
Train Epoch: 1095 [81920/90000 (91%)]	Loss: -14.7597	Cost: 6.00s
Train Epoch: 1095 	Average Loss: -14.2540
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.1089

Learning rate: 8.513275661030758e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1096 [0/90000 (0%)]	Loss: -4.9040	Cost: 24.98s
Train Epoch: 1096 [20480/90000 (23%)]	Loss: -15.0482	Cost: 6.18s
Train Epoch: 1096 [40960/90000 (45%)]	Loss: -14.5744	Cost: 6.81s
Train Epoch: 1096 [61440/90000 (68%)]	Loss: -14.9441	Cost: 5.91s
Train Epoch: 1096 [81920/90000 (91%)]	Loss: -14.9220	Cost: 5.96s
Train Epoch: 1096 	Average Loss: -14.1868
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.3098

Learning rate: 8.497744108792414e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1097 [0/90000 (0%)]	Loss: -5.5533	Cost: 25.37s
Train Epoch: 1097 [20480/90000 (23%)]	Loss: -15.0470	Cost: 6.13s
Train Epoch: 1097 [40960/90000 (45%)]	Loss: -14.8420	Cost: 7.13s
Train Epoch: 1097 [61440/90000 (68%)]	Loss: -15.0569	Cost: 5.85s
Train Epoch: 1097 [81920/90000 (91%)]	Loss: -14.9793	Cost: 5.76s
Train Epoch: 1097 	Average Loss: -14.2879
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.1797

Learning rate: 8.48221626322115e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1098 [0/90000 (0%)]	Loss: -5.3397	Cost: 25.43s
Train Epoch: 1098 [20480/90000 (23%)]	Loss: -15.0439	Cost: 6.13s
Train Epoch: 1098 [40960/90000 (45%)]	Loss: -14.7888	Cost: 7.23s
Train Epoch: 1098 [61440/90000 (68%)]	Loss: -14.9803	Cost: 5.84s
Train Epoch: 1098 [81920/90000 (91%)]	Loss: -15.3455	Cost: 5.83s
Train Epoch: 1098 	Average Loss: -14.3356
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.3718

Learning rate: 8.46669216263038e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1099 [0/90000 (0%)]	Loss: -5.7297	Cost: 25.52s
Train Epoch: 1099 [20480/90000 (23%)]	Loss: -15.4296	Cost: 6.13s
Train Epoch: 1099 [40960/90000 (45%)]	Loss: -14.9236	Cost: 6.35s
Train Epoch: 1099 [61440/90000 (68%)]	Loss: -14.5682	Cost: 5.91s
Train Epoch: 1099 [81920/90000 (91%)]	Loss: -14.4656	Cost: 5.72s
Train Epoch: 1099 	Average Loss: -14.1975
Re-generating waveforms for posterior prior.
Test set: Average loss: -4.9203

Learning rate: 8.451171845324274e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1100 [0/90000 (0%)]	Loss: -4.8766	Cost: 24.91s
Train Epoch: 1100 [20480/90000 (23%)]	Loss: -14.7885	Cost: 6.10s
Train Epoch: 1100 [40960/90000 (45%)]	Loss: -14.4625	Cost: 6.96s
Train Epoch: 1100 [61440/90000 (68%)]	Loss: -14.8674	Cost: 5.85s
Train Epoch: 1100 [81920/90000 (91%)]	Loss: -15.0151	Cost: 5.95s
Train Epoch: 1100 	Average Loss: -14.0711
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.0849

Saving model as model_sample_from_all_posterior.pt_e1100 & waveforms_supplementary_sample_from_all_posterior.hdf5_e1100
Learning rate: 8.435655349597677e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1101 [0/90000 (0%)]	Loss: -5.0979	Cost: 25.50s
Train Epoch: 1101 [20480/90000 (23%)]	Loss: -15.3051	Cost: 6.15s
Train Epoch: 1101 [40960/90000 (45%)]	Loss: -14.6498	Cost: 7.18s
Train Epoch: 1101 [61440/90000 (68%)]	Loss: -15.0812	Cost: 5.86s
Train Epoch: 1101 [81920/90000 (91%)]	Loss: -15.0041	Cost: 5.99s
Train Epoch: 1101 	Average Loss: -14.3120
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.2837

Learning rate: 8.420142713735999e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1102 [0/90000 (0%)]	Loss: -5.0848	Cost: 26.30s
Train Epoch: 1102 [20480/90000 (23%)]	Loss: -15.0528	Cost: 6.07s
Train Epoch: 1102 [40960/90000 (45%)]	Loss: -14.7851	Cost: 7.08s
Train Epoch: 1102 [61440/90000 (68%)]	Loss: -15.0444	Cost: 5.82s
Train Epoch: 1102 [81920/90000 (91%)]	Loss: -15.2280	Cost: 6.13s
Train Epoch: 1102 	Average Loss: -14.3005
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.3842

Learning rate: 8.404633976015122e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1103 [0/90000 (0%)]	Loss: -6.0431	Cost: 25.20s
Train Epoch: 1103 [20480/90000 (23%)]	Loss: -15.2596	Cost: 6.13s
Train Epoch: 1103 [40960/90000 (45%)]	Loss: -14.8681	Cost: 6.74s
Train Epoch: 1103 [61440/90000 (68%)]	Loss: -15.0862	Cost: 5.94s
Train Epoch: 1103 [81920/90000 (91%)]	Loss: -15.2270	Cost: 5.71s
Train Epoch: 1103 	Average Loss: -14.3717
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.3525

Learning rate: 8.38912917470132e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1104 [0/90000 (0%)]	Loss: -5.3078	Cost: 25.55s
Train Epoch: 1104 [20480/90000 (23%)]	Loss: -15.2975	Cost: 6.17s
Train Epoch: 1104 [40960/90000 (45%)]	Loss: -14.8976	Cost: 7.03s
Train Epoch: 1104 [61440/90000 (68%)]	Loss: -15.1142	Cost: 5.91s
Train Epoch: 1104 [81920/90000 (91%)]	Loss: -15.3838	Cost: 5.70s
Train Epoch: 1104 	Average Loss: -14.4531
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.4501

Learning rate: 8.37362834805115e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1105 [0/90000 (0%)]	Loss: -5.8883	Cost: 26.49s
Train Epoch: 1105 [20480/90000 (23%)]	Loss: -15.4929	Cost: 6.12s
Train Epoch: 1105 [40960/90000 (45%)]	Loss: -14.9237	Cost: 7.06s
Train Epoch: 1105 [61440/90000 (68%)]	Loss: -15.3224	Cost: 5.89s
Train Epoch: 1105 [81920/90000 (91%)]	Loss: -15.2511	Cost: 6.29s
Train Epoch: 1105 	Average Loss: -14.4972
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.3426

Learning rate: 8.358131534311357e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1106 [0/90000 (0%)]	Loss: -6.4286	Cost: 25.91s
Train Epoch: 1106 [20480/90000 (23%)]	Loss: -15.3862	Cost: 6.23s
Train Epoch: 1106 [40960/90000 (45%)]	Loss: -15.0942	Cost: 7.07s
Train Epoch: 1106 [61440/90000 (68%)]	Loss: -15.2166	Cost: 5.91s
Train Epoch: 1106 [81920/90000 (91%)]	Loss: -15.4755	Cost: 5.88s
Train Epoch: 1106 	Average Loss: -14.5699
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.5442

Learning rate: 8.34263877171879e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1107 [0/90000 (0%)]	Loss: -5.6329	Cost: 25.70s
Train Epoch: 1107 [20480/90000 (23%)]	Loss: -15.2272	Cost: 6.13s
Train Epoch: 1107 [40960/90000 (45%)]	Loss: -15.0049	Cost: 6.99s
Train Epoch: 1107 [61440/90000 (68%)]	Loss: -15.0684	Cost: 5.84s
Train Epoch: 1107 [81920/90000 (91%)]	Loss: -15.3695	Cost: 5.87s
Train Epoch: 1107 	Average Loss: -14.4581
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.5216

Learning rate: 8.327150098500299e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1108 [0/90000 (0%)]	Loss: -5.5015	Cost: 24.98s
Train Epoch: 1108 [20480/90000 (23%)]	Loss: -15.3045	Cost: 6.12s
Train Epoch: 1108 [40960/90000 (45%)]	Loss: -14.8804	Cost: 7.18s
Train Epoch: 1108 [61440/90000 (68%)]	Loss: -15.2029	Cost: 5.85s
Train Epoch: 1108 [81920/90000 (91%)]	Loss: -15.3697	Cost: 5.89s
Train Epoch: 1108 	Average Loss: -14.4784
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.4371

Learning rate: 8.311665552872647e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1109 [0/90000 (0%)]	Loss: -5.1144	Cost: 26.17s
Train Epoch: 1109 [20480/90000 (23%)]	Loss: -15.4051	Cost: 6.16s
Train Epoch: 1109 [40960/90000 (45%)]	Loss: -14.8098	Cost: 6.84s
Train Epoch: 1109 [61440/90000 (68%)]	Loss: -15.1156	Cost: 5.94s
Train Epoch: 1109 [81920/90000 (91%)]	Loss: -15.4727	Cost: 5.95s
Train Epoch: 1109 	Average Loss: -14.5298
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.5756

Learning rate: 8.296185173042413e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1110 [0/90000 (0%)]	Loss: -5.6015	Cost: 24.89s
Train Epoch: 1110 [20480/90000 (23%)]	Loss: -15.3242	Cost: 6.16s
Train Epoch: 1110 [40960/90000 (45%)]	Loss: -15.0401	Cost: 7.29s
Train Epoch: 1110 [61440/90000 (68%)]	Loss: -15.1796	Cost: 5.81s
Train Epoch: 1110 [81920/90000 (91%)]	Loss: -15.3543	Cost: 5.99s
Train Epoch: 1110 	Average Loss: -14.5298
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.5729

Learning rate: 8.28070899720589e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1111 [0/90000 (0%)]	Loss: -5.1149	Cost: 25.26s
Train Epoch: 1111 [20480/90000 (23%)]	Loss: -15.3488	Cost: 6.15s
Train Epoch: 1111 [40960/90000 (45%)]	Loss: -15.0463	Cost: 6.95s
Train Epoch: 1111 [61440/90000 (68%)]	Loss: -15.4575	Cost: 5.85s
Train Epoch: 1111 [81920/90000 (91%)]	Loss: -15.5717	Cost: 6.06s
Train Epoch: 1111 	Average Loss: -14.6006
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.6632

Learning rate: 8.265237063549011e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1112 [0/90000 (0%)]	Loss: -5.5317	Cost: 25.75s
Train Epoch: 1112 [20480/90000 (23%)]	Loss: -15.4567	Cost: 6.14s
Train Epoch: 1112 [40960/90000 (45%)]	Loss: -15.2166	Cost: 6.81s
Train Epoch: 1112 [61440/90000 (68%)]	Loss: -15.2748	Cost: 5.88s
Train Epoch: 1112 [81920/90000 (91%)]	Loss: -15.2522	Cost: 5.78s
Train Epoch: 1112 	Average Loss: -14.6247
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.6015

Learning rate: 8.249769410247228e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1113 [0/90000 (0%)]	Loss: -5.6552	Cost: 25.28s
Train Epoch: 1113 [20480/90000 (23%)]	Loss: -15.4164	Cost: 6.15s
Train Epoch: 1113 [40960/90000 (45%)]	Loss: -15.1052	Cost: 7.15s
Train Epoch: 1113 [61440/90000 (68%)]	Loss: -15.3360	Cost: 5.85s
Train Epoch: 1113 [81920/90000 (91%)]	Loss: -15.2972	Cost: 6.03s
Train Epoch: 1113 	Average Loss: -14.5567
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.4076

Learning rate: 8.234306075465441e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1114 [0/90000 (0%)]	Loss: -5.4512	Cost: 24.95s
Train Epoch: 1114 [20480/90000 (23%)]	Loss: -14.8586	Cost: 6.14s
Train Epoch: 1114 [40960/90000 (45%)]	Loss: -14.5001	Cost: 7.14s
Train Epoch: 1114 [61440/90000 (68%)]	Loss: -14.7600	Cost: 5.85s
Train Epoch: 1114 [81920/90000 (91%)]	Loss: -14.9013	Cost: 5.79s
Train Epoch: 1114 	Average Loss: -14.0853
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.5145

Learning rate: 8.218847097357886e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1115 [0/90000 (0%)]	Loss: -4.6631	Cost: 25.45s
Train Epoch: 1115 [20480/90000 (23%)]	Loss: -15.1249	Cost: 6.11s
Train Epoch: 1115 [40960/90000 (45%)]	Loss: -14.7466	Cost: 7.32s
Train Epoch: 1115 [61440/90000 (68%)]	Loss: -15.0678	Cost: 5.82s
Train Epoch: 1115 [81920/90000 (91%)]	Loss: -15.2543	Cost: 5.83s
Train Epoch: 1115 	Average Loss: -14.3962
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.5890

Learning rate: 8.203392514068062e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1116 [0/90000 (0%)]	Loss: -5.9389	Cost: 25.39s
Train Epoch: 1116 [20480/90000 (23%)]	Loss: -15.3131	Cost: 6.19s
Train Epoch: 1116 [40960/90000 (45%)]	Loss: -14.8021	Cost: 6.78s
Train Epoch: 1116 [61440/90000 (68%)]	Loss: -15.2740	Cost: 5.86s
Train Epoch: 1116 [81920/90000 (91%)]	Loss: -15.3618	Cost: 5.94s
Train Epoch: 1116 	Average Loss: -14.4941
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.5851

Learning rate: 8.187942363728616e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1117 [0/90000 (0%)]	Loss: -5.3815	Cost: 25.58s
Train Epoch: 1117 [20480/90000 (23%)]	Loss: -15.4902	Cost: 6.11s
Train Epoch: 1117 [40960/90000 (45%)]	Loss: -15.0986	Cost: 7.35s
Train Epoch: 1117 [61440/90000 (68%)]	Loss: -15.4906	Cost: 5.88s
Train Epoch: 1117 [81920/90000 (91%)]	Loss: -15.4963	Cost: 5.70s
Train Epoch: 1117 	Average Loss: -14.6369
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.4820

Learning rate: 8.172496684461254e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1118 [0/90000 (0%)]	Loss: -6.1451	Cost: 25.16s
Train Epoch: 1118 [20480/90000 (23%)]	Loss: -15.5568	Cost: 6.12s
Train Epoch: 1118 [40960/90000 (45%)]	Loss: -15.2170	Cost: 6.44s
Train Epoch: 1118 [61440/90000 (68%)]	Loss: -15.4594	Cost: 5.94s
Train Epoch: 1118 [81920/90000 (91%)]	Loss: -15.7407	Cost: 5.69s
Train Epoch: 1118 	Average Loss: -14.7233
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.6393

Learning rate: 8.157055514376656e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1119 [0/90000 (0%)]	Loss: -5.3044	Cost: 25.26s
Train Epoch: 1119 [20480/90000 (23%)]	Loss: -15.5941	Cost: 6.16s
Train Epoch: 1119 [40960/90000 (45%)]	Loss: -14.9231	Cost: 7.35s
Train Epoch: 1119 [61440/90000 (68%)]	Loss: -15.4684	Cost: 5.79s
Train Epoch: 1119 [81920/90000 (91%)]	Loss: -15.5278	Cost: 5.95s
Train Epoch: 1119 	Average Loss: -14.7011
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.6376

Learning rate: 8.141618891574376e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1120 [0/90000 (0%)]	Loss: -5.2893	Cost: 25.38s
Train Epoch: 1120 [20480/90000 (23%)]	Loss: -15.6122	Cost: 6.12s
Train Epoch: 1120 [40960/90000 (45%)]	Loss: -15.1202	Cost: 7.44s
Train Epoch: 1120 [61440/90000 (68%)]	Loss: -15.5520	Cost: 5.82s
Train Epoch: 1120 [81920/90000 (91%)]	Loss: -15.6269	Cost: 5.97s
Train Epoch: 1120 	Average Loss: -14.7076
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.7387

Learning rate: 8.126186854142744e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1121 [0/90000 (0%)]	Loss: -5.6219	Cost: 25.45s
Train Epoch: 1121 [20480/90000 (23%)]	Loss: -15.6894	Cost: 6.08s
Train Epoch: 1121 [40960/90000 (45%)]	Loss: -15.2049	Cost: 7.44s
Train Epoch: 1121 [61440/90000 (68%)]	Loss: -15.5389	Cost: 5.79s
Train Epoch: 1121 [81920/90000 (91%)]	Loss: -15.4506	Cost: 5.83s
Train Epoch: 1121 	Average Loss: -14.7340
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.6417

Learning rate: 8.110759440158779e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1122 [0/90000 (0%)]	Loss: -5.8323	Cost: 24.94s
Train Epoch: 1122 [20480/90000 (23%)]	Loss: -15.4777	Cost: 6.11s
Train Epoch: 1122 [40960/90000 (45%)]	Loss: -15.0647	Cost: 6.43s
Train Epoch: 1122 [61440/90000 (68%)]	Loss: -15.5147	Cost: 5.92s
Train Epoch: 1122 [81920/90000 (91%)]	Loss: -15.5720	Cost: 6.06s
Train Epoch: 1122 	Average Loss: -14.6756
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.7303

Learning rate: 8.095336687688092e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1123 [0/90000 (0%)]	Loss: -6.1699	Cost: 25.56s
Train Epoch: 1123 [20480/90000 (23%)]	Loss: -15.7062	Cost: 6.15s
Train Epoch: 1123 [40960/90000 (45%)]	Loss: -15.2912	Cost: 6.50s
Train Epoch: 1123 [61440/90000 (68%)]	Loss: -15.5850	Cost: 6.02s
Train Epoch: 1123 [81920/90000 (91%)]	Loss: -15.8182	Cost: 5.77s
Train Epoch: 1123 	Average Loss: -14.8842
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.6827

Learning rate: 8.079918634784792e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1124 [0/90000 (0%)]	Loss: -5.2520	Cost: 24.88s
Train Epoch: 1124 [20480/90000 (23%)]	Loss: -15.7083	Cost: 6.17s
Train Epoch: 1124 [40960/90000 (45%)]	Loss: -15.1103	Cost: 7.14s
Train Epoch: 1124 [61440/90000 (68%)]	Loss: -15.6224	Cost: 5.88s
Train Epoch: 1124 [81920/90000 (91%)]	Loss: -15.5163	Cost: 5.87s
Train Epoch: 1124 	Average Loss: -14.8385
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.6130

Learning rate: 8.06450531949139e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1125 [0/90000 (0%)]	Loss: -5.9297	Cost: 25.49s
Train Epoch: 1125 [20480/90000 (23%)]	Loss: -15.5161	Cost: 6.22s
Train Epoch: 1125 [40960/90000 (45%)]	Loss: -15.3611	Cost: 7.11s
Train Epoch: 1125 [61440/90000 (68%)]	Loss: -15.4577	Cost: 5.85s
Train Epoch: 1125 [81920/90000 (91%)]	Loss: -15.7207	Cost: 5.93s
Train Epoch: 1125 	Average Loss: -14.8257
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.7750

Learning rate: 8.049096779838708e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1126 [0/90000 (0%)]	Loss: -5.9952	Cost: 25.72s
Train Epoch: 1126 [20480/90000 (23%)]	Loss: -15.6500	Cost: 6.08s
Train Epoch: 1126 [40960/90000 (45%)]	Loss: -15.2343	Cost: 7.13s
Train Epoch: 1126 [61440/90000 (68%)]	Loss: -15.7097	Cost: 5.87s
Train Epoch: 1126 [81920/90000 (91%)]	Loss: -15.7730	Cost: 5.68s
Train Epoch: 1126 	Average Loss: -14.8824
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.8258

Learning rate: 8.033693053845788e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1127 [0/90000 (0%)]	Loss: -6.4511	Cost: 25.10s
Train Epoch: 1127 [20480/90000 (23%)]	Loss: -15.7972	Cost: 6.17s
Train Epoch: 1127 [40960/90000 (45%)]	Loss: -15.2892	Cost: 6.73s
Train Epoch: 1127 [61440/90000 (68%)]	Loss: -15.4770	Cost: 5.93s
Train Epoch: 1127 [81920/90000 (91%)]	Loss: -15.6955	Cost: 5.70s
Train Epoch: 1127 	Average Loss: -14.8105
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.6242

Learning rate: 8.018294179519797e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1128 [0/90000 (0%)]	Loss: -6.1101	Cost: 25.12s
Train Epoch: 1128 [20480/90000 (23%)]	Loss: -15.7390	Cost: 6.16s
Train Epoch: 1128 [40960/90000 (45%)]	Loss: -15.2646	Cost: 7.28s
Train Epoch: 1128 [61440/90000 (68%)]	Loss: -15.5542	Cost: 5.90s
Train Epoch: 1128 [81920/90000 (91%)]	Loss: -14.8191	Cost: 5.84s
Train Epoch: 1128 	Average Loss: -14.6919
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.1797

Learning rate: 8.002900194855921e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1129 [0/90000 (0%)]	Loss: -4.6592	Cost: 25.84s
Train Epoch: 1129 [20480/90000 (23%)]	Loss: -15.1198	Cost: 6.12s
Train Epoch: 1129 [40960/90000 (45%)]	Loss: -14.9590	Cost: 7.09s
Train Epoch: 1129 [61440/90000 (68%)]	Loss: -15.4045	Cost: 5.88s
Train Epoch: 1129 [81920/90000 (91%)]	Loss: -15.6277	Cost: 5.80s
Train Epoch: 1129 	Average Loss: -14.4425
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.6137

Learning rate: 7.987511137837286e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1130 [0/90000 (0%)]	Loss: -5.6401	Cost: 25.38s
Train Epoch: 1130 [20480/90000 (23%)]	Loss: -15.7380	Cost: 6.16s
Train Epoch: 1130 [40960/90000 (45%)]	Loss: -15.3935	Cost: 7.20s
Train Epoch: 1130 [61440/90000 (68%)]	Loss: -15.6126	Cost: 5.86s
Train Epoch: 1130 [81920/90000 (91%)]	Loss: -15.8810	Cost: 5.72s
Train Epoch: 1130 	Average Loss: -14.8957
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.9082

Learning rate: 7.972127046434866e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1131 [0/90000 (0%)]	Loss: -5.5414	Cost: 26.00s
Train Epoch: 1131 [20480/90000 (23%)]	Loss: -15.9951	Cost: 6.12s
Train Epoch: 1131 [40960/90000 (45%)]	Loss: -15.4016	Cost: 7.16s
Train Epoch: 1131 [61440/90000 (68%)]	Loss: -15.6238	Cost: 5.84s
Train Epoch: 1131 [81920/90000 (91%)]	Loss: -15.9793	Cost: 5.74s
Train Epoch: 1131 	Average Loss: -14.9974
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.7637

Learning rate: 7.956747958607374e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1132 [0/90000 (0%)]	Loss: -6.6873	Cost: 25.73s
Train Epoch: 1132 [20480/90000 (23%)]	Loss: -16.0074	Cost: 6.26s
Train Epoch: 1132 [40960/90000 (45%)]	Loss: -15.4844	Cost: 6.91s
Train Epoch: 1132 [61440/90000 (68%)]	Loss: -15.7201	Cost: 6.00s
Train Epoch: 1132 [81920/90000 (91%)]	Loss: -15.7508	Cost: 5.85s
Train Epoch: 1132 	Average Loss: -15.0530
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.7644

Learning rate: 7.941373912301174e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1133 [0/90000 (0%)]	Loss: -5.6490	Cost: 26.39s
Train Epoch: 1133 [20480/90000 (23%)]	Loss: -15.7054	Cost: 6.17s
Train Epoch: 1133 [40960/90000 (45%)]	Loss: -15.4039	Cost: 6.83s
Train Epoch: 1133 [61440/90000 (68%)]	Loss: -15.6332	Cost: 6.31s
Train Epoch: 1133 [81920/90000 (91%)]	Loss: -15.9549	Cost: 6.57s
Train Epoch: 1133 	Average Loss: -14.9637
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.0094

Learning rate: 7.92600494545021e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1134 [0/90000 (0%)]	Loss: -6.3533	Cost: 24.95s
Train Epoch: 1134 [20480/90000 (23%)]	Loss: -16.0342	Cost: 6.20s
Train Epoch: 1134 [40960/90000 (45%)]	Loss: -15.3729	Cost: 7.16s
Train Epoch: 1134 [61440/90000 (68%)]	Loss: -15.6725	Cost: 5.91s
Train Epoch: 1134 [81920/90000 (91%)]	Loss: -15.8981	Cost: 6.06s
Train Epoch: 1134 	Average Loss: -15.0685
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.0262

Learning rate: 7.910641095975872e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1135 [0/90000 (0%)]	Loss: -6.4101	Cost: 25.35s
Train Epoch: 1135 [20480/90000 (23%)]	Loss: -15.9743	Cost: 6.22s
Train Epoch: 1135 [40960/90000 (45%)]	Loss: -15.5402	Cost: 7.04s
Train Epoch: 1135 [61440/90000 (68%)]	Loss: -15.7167	Cost: 5.84s
Train Epoch: 1135 [81920/90000 (91%)]	Loss: -16.0139	Cost: 6.08s
Train Epoch: 1135 	Average Loss: -15.0479
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.8444

Learning rate: 7.895282401786933e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1136 [0/90000 (0%)]	Loss: -6.0381	Cost: 25.50s
Train Epoch: 1136 [20480/90000 (23%)]	Loss: -16.0096	Cost: 6.19s
Train Epoch: 1136 [40960/90000 (45%)]	Loss: -15.5937	Cost: 6.60s
Train Epoch: 1136 [61440/90000 (68%)]	Loss: -15.8585	Cost: 5.88s
Train Epoch: 1136 [81920/90000 (91%)]	Loss: -15.7555	Cost: 5.86s
Train Epoch: 1136 	Average Loss: -15.1042
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.9326

Learning rate: 7.879928900779442e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1137 [0/90000 (0%)]	Loss: -5.5178	Cost: 24.83s
Train Epoch: 1137 [20480/90000 (23%)]	Loss: -15.8925	Cost: 6.14s
Train Epoch: 1137 [40960/90000 (45%)]	Loss: -15.3998	Cost: 6.95s
Train Epoch: 1137 [61440/90000 (68%)]	Loss: -15.7104	Cost: 5.93s
Train Epoch: 1137 [81920/90000 (91%)]	Loss: -15.9809	Cost: 5.91s
Train Epoch: 1137 	Average Loss: -14.9187
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.8298

Learning rate: 7.864580630836642e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1138 [0/90000 (0%)]	Loss: -6.0178	Cost: 25.29s
Train Epoch: 1138 [20480/90000 (23%)]	Loss: -15.8941	Cost: 6.13s
Train Epoch: 1138 [40960/90000 (45%)]	Loss: -15.1059	Cost: 7.37s
Train Epoch: 1138 [61440/90000 (68%)]	Loss: -15.5721	Cost: 5.86s
Train Epoch: 1138 [81920/90000 (91%)]	Loss: -15.8692	Cost: 5.75s
Train Epoch: 1138 	Average Loss: -14.9297
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.7982

Learning rate: 7.849237629828856e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1139 [0/90000 (0%)]	Loss: -6.0417	Cost: 26.63s
Train Epoch: 1139 [20480/90000 (23%)]	Loss: -15.8796	Cost: 6.07s
Train Epoch: 1139 [40960/90000 (45%)]	Loss: -15.3655	Cost: 7.05s
Train Epoch: 1139 [61440/90000 (68%)]	Loss: -15.7718	Cost: 5.87s
Train Epoch: 1139 [81920/90000 (91%)]	Loss: -16.0580	Cost: 5.87s
Train Epoch: 1139 	Average Loss: -15.0484
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.9019

Learning rate: 7.833899935613419e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1140 [0/90000 (0%)]	Loss: -5.2336	Cost: 25.83s
Train Epoch: 1140 [20480/90000 (23%)]	Loss: -15.9644	Cost: 6.17s
Train Epoch: 1140 [40960/90000 (45%)]	Loss: -15.5796	Cost: 7.17s
Train Epoch: 1140 [61440/90000 (68%)]	Loss: -16.0571	Cost: 5.85s
Train Epoch: 1140 [81920/90000 (91%)]	Loss: -16.3420	Cost: 6.03s
Train Epoch: 1140 	Average Loss: -15.1683
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.1247

Learning rate: 7.818567586034565e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1141 [0/90000 (0%)]	Loss: -5.9257	Cost: 25.74s
Train Epoch: 1141 [20480/90000 (23%)]	Loss: -16.2822	Cost: 6.20s
Train Epoch: 1141 [40960/90000 (45%)]	Loss: -15.6281	Cost: 6.67s
Train Epoch: 1141 [61440/90000 (68%)]	Loss: -15.8311	Cost: 5.91s
Train Epoch: 1141 [81920/90000 (91%)]	Loss: -16.0853	Cost: 5.80s
Train Epoch: 1141 	Average Loss: -15.1888
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.8917

Learning rate: 7.803240618923343e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1142 [0/90000 (0%)]	Loss: -5.9640	Cost: 25.59s
Train Epoch: 1142 [20480/90000 (23%)]	Loss: -16.2657	Cost: 6.16s
Train Epoch: 1142 [40960/90000 (45%)]	Loss: -15.6155	Cost: 7.01s
Train Epoch: 1142 [61440/90000 (68%)]	Loss: -15.8276	Cost: 5.85s
Train Epoch: 1142 [81920/90000 (91%)]	Loss: -16.1509	Cost: 6.14s
Train Epoch: 1142 	Average Loss: -15.2368
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.1869

Learning rate: 7.787919072097522e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1143 [0/90000 (0%)]	Loss: -6.4944	Cost: 25.55s
Train Epoch: 1143 [20480/90000 (23%)]	Loss: -16.0702	Cost: 6.12s
Train Epoch: 1143 [40960/90000 (45%)]	Loss: -15.4860	Cost: 7.24s
Train Epoch: 1143 [61440/90000 (68%)]	Loss: -15.8252	Cost: 5.85s
Train Epoch: 1143 [81920/90000 (91%)]	Loss: -16.2035	Cost: 5.83s
Train Epoch: 1143 	Average Loss: -15.2180
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.9967

Learning rate: 7.77260298336149e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1144 [0/90000 (0%)]	Loss: -6.3267	Cost: 25.68s
Train Epoch: 1144 [20480/90000 (23%)]	Loss: -16.2297	Cost: 6.12s
Train Epoch: 1144 [40960/90000 (45%)]	Loss: -15.8029	Cost: 7.08s
Train Epoch: 1144 [61440/90000 (68%)]	Loss: -16.0602	Cost: 5.86s
Train Epoch: 1144 [81920/90000 (91%)]	Loss: -16.0892	Cost: 5.99s
Train Epoch: 1144 	Average Loss: -15.2820
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.8829

Learning rate: 7.757292390506177e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1145 [0/90000 (0%)]	Loss: -5.5128	Cost: 25.38s
Train Epoch: 1145 [20480/90000 (23%)]	Loss: -16.0725	Cost: 6.15s
Train Epoch: 1145 [40960/90000 (45%)]	Loss: -15.7651	Cost: 7.29s
Train Epoch: 1145 [61440/90000 (68%)]	Loss: -15.9336	Cost: 5.92s
Train Epoch: 1145 [81920/90000 (91%)]	Loss: -16.1993	Cost: 5.91s
Train Epoch: 1145 	Average Loss: -15.2867
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.0251

Learning rate: 7.741987331308954e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1146 [0/90000 (0%)]	Loss: -6.0115	Cost: 26.87s
Train Epoch: 1146 [20480/90000 (23%)]	Loss: -16.1535	Cost: 6.09s
Train Epoch: 1146 [40960/90000 (45%)]	Loss: -15.7127	Cost: 6.30s
Train Epoch: 1146 [61440/90000 (68%)]	Loss: -15.8757	Cost: 6.21s
Train Epoch: 1146 [81920/90000 (91%)]	Loss: -15.9797	Cost: 6.32s
Train Epoch: 1146 	Average Loss: -15.2410
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.8732

Learning rate: 7.726687843533527e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1147 [0/90000 (0%)]	Loss: -6.5315	Cost: 24.82s
Train Epoch: 1147 [20480/90000 (23%)]	Loss: -16.0850	Cost: 6.17s
Train Epoch: 1147 [40960/90000 (45%)]	Loss: -15.3835	Cost: 7.19s
Train Epoch: 1147 [61440/90000 (68%)]	Loss: -15.8581	Cost: 6.36s
Train Epoch: 1147 [81920/90000 (91%)]	Loss: -16.1520	Cost: 5.76s
Train Epoch: 1147 	Average Loss: -15.1467
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.9144

Learning rate: 7.711393964929862e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1148 [0/90000 (0%)]	Loss: -6.7333	Cost: 25.40s
Train Epoch: 1148 [20480/90000 (23%)]	Loss: -15.9119	Cost: 6.20s
Train Epoch: 1148 [40960/90000 (45%)]	Loss: -15.0901	Cost: 7.27s
Train Epoch: 1148 [61440/90000 (68%)]	Loss: -15.6662	Cost: 5.84s
Train Epoch: 1148 [81920/90000 (91%)]	Loss: -15.9254	Cost: 5.84s
Train Epoch: 1148 	Average Loss: -15.0432
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.8879

Learning rate: 7.696105733234086e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1149 [0/90000 (0%)]	Loss: -5.9944	Cost: 25.24s
Train Epoch: 1149 [20480/90000 (23%)]	Loss: -16.2360	Cost: 6.17s
Train Epoch: 1149 [40960/90000 (45%)]	Loss: -15.5047	Cost: 7.34s
Train Epoch: 1149 [61440/90000 (68%)]	Loss: -15.8607	Cost: 5.84s
Train Epoch: 1149 [81920/90000 (91%)]	Loss: -16.2069	Cost: 5.79s
Train Epoch: 1149 	Average Loss: -15.1892
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.9917

Learning rate: 7.680823186168389e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1150 [0/90000 (0%)]	Loss: -5.6790	Cost: 25.64s
Train Epoch: 1150 [20480/90000 (23%)]	Loss: -16.0317	Cost: 6.16s
Train Epoch: 1150 [40960/90000 (45%)]	Loss: -15.4494	Cost: 7.38s
Train Epoch: 1150 [61440/90000 (68%)]	Loss: -15.7184	Cost: 5.91s
Train Epoch: 1150 [81920/90000 (91%)]	Loss: -16.0571	Cost: 5.96s
Train Epoch: 1150 	Average Loss: -15.0966
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.0169

Saving model as model_sample_from_all_posterior.pt_e1150 & waveforms_supplementary_sample_from_all_posterior.hdf5_e1150
Learning rate: 7.665546361440936e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1151 [0/90000 (0%)]	Loss: -5.7103	Cost: 25.55s
Train Epoch: 1151 [20480/90000 (23%)]	Loss: -16.0915	Cost: 6.25s
Train Epoch: 1151 [40960/90000 (45%)]	Loss: -15.4108	Cost: 7.06s
Train Epoch: 1151 [61440/90000 (68%)]	Loss: -15.6289	Cost: 5.87s
Train Epoch: 1151 [81920/90000 (91%)]	Loss: -15.9654	Cost: 5.71s
Train Epoch: 1151 	Average Loss: -15.0622
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.9043

Learning rate: 7.650275296745775e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1152 [0/90000 (0%)]	Loss: -6.2434	Cost: 25.53s
Train Epoch: 1152 [20480/90000 (23%)]	Loss: -16.1335	Cost: 6.09s
Train Epoch: 1152 [40960/90000 (45%)]	Loss: -15.7653	Cost: 7.39s
Train Epoch: 1152 [61440/90000 (68%)]	Loss: -15.8292	Cost: 5.79s
Train Epoch: 1152 [81920/90000 (91%)]	Loss: -16.2091	Cost: 5.87s
Train Epoch: 1152 	Average Loss: -15.2676
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.3005

Learning rate: 7.635010029762742e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1153 [0/90000 (0%)]	Loss: -5.1240	Cost: 25.26s
Train Epoch: 1153 [20480/90000 (23%)]	Loss: -16.3340	Cost: 6.12s
Train Epoch: 1153 [40960/90000 (45%)]	Loss: -15.7512	Cost: 6.35s
Train Epoch: 1153 [61440/90000 (68%)]	Loss: -16.1412	Cost: 5.90s
Train Epoch: 1153 [81920/90000 (91%)]	Loss: -16.1811	Cost: 5.88s
Train Epoch: 1153 	Average Loss: -15.3268
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.0936

Learning rate: 7.619750598157365e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1154 [0/90000 (0%)]	Loss: -5.7498	Cost: 25.23s
Train Epoch: 1154 [20480/90000 (23%)]	Loss: -16.2949	Cost: 6.22s
Train Epoch: 1154 [40960/90000 (45%)]	Loss: -15.7127	Cost: 7.41s
Train Epoch: 1154 [61440/90000 (68%)]	Loss: -16.1516	Cost: 5.87s
Train Epoch: 1154 [81920/90000 (91%)]	Loss: -16.2592	Cost: 6.01s
Train Epoch: 1154 	Average Loss: -15.3783
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.0395

Learning rate: 7.604497039580771e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1155 [0/90000 (0%)]	Loss: -6.3525	Cost: 26.19s
Train Epoch: 1155 [20480/90000 (23%)]	Loss: -16.2011	Cost: 6.11s
Train Epoch: 1155 [40960/90000 (45%)]	Loss: -15.7566	Cost: 7.04s
Train Epoch: 1155 [61440/90000 (68%)]	Loss: -16.0770	Cost: 5.87s
Train Epoch: 1155 [81920/90000 (91%)]	Loss: -16.3139	Cost: 5.95s
Train Epoch: 1155 	Average Loss: -15.3626
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.2216

Learning rate: 7.589249391669603e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1156 [0/90000 (0%)]	Loss: -6.1224	Cost: 25.87s
Train Epoch: 1156 [20480/90000 (23%)]	Loss: -16.3013	Cost: 6.14s
Train Epoch: 1156 [40960/90000 (45%)]	Loss: -15.9164	Cost: 6.51s
Train Epoch: 1156 [61440/90000 (68%)]	Loss: -16.2408	Cost: 5.95s
Train Epoch: 1156 [81920/90000 (91%)]	Loss: -16.3045	Cost: 5.72s
Train Epoch: 1156 	Average Loss: -15.4109
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.0138

Learning rate: 7.574007692045914e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1157 [0/90000 (0%)]	Loss: -5.5441	Cost: 25.38s
Train Epoch: 1157 [20480/90000 (23%)]	Loss: -16.4800	Cost: 6.17s
Train Epoch: 1157 [40960/90000 (45%)]	Loss: -16.0774	Cost: 7.20s
Train Epoch: 1157 [61440/90000 (68%)]	Loss: -16.2141	Cost: 5.85s
Train Epoch: 1157 [81920/90000 (91%)]	Loss: -16.3340	Cost: 5.93s
Train Epoch: 1157 	Average Loss: -15.5057
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.2202

Learning rate: 7.558771978317087e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1158 [0/90000 (0%)]	Loss: -5.7061	Cost: 25.63s
Train Epoch: 1158 [20480/90000 (23%)]	Loss: -16.4093	Cost: 6.15s
Train Epoch: 1158 [40960/90000 (45%)]	Loss: -15.8812	Cost: 7.39s
Train Epoch: 1158 [61440/90000 (68%)]	Loss: -16.1345	Cost: 6.17s
Train Epoch: 1158 [81920/90000 (91%)]	Loss: -16.1659	Cost: 5.74s
Train Epoch: 1158 	Average Loss: -15.4183
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.9956

Learning rate: 7.543542288075725e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1159 [0/90000 (0%)]	Loss: -5.4822	Cost: 25.44s
Train Epoch: 1159 [20480/90000 (23%)]	Loss: -16.1672	Cost: 6.13s
Train Epoch: 1159 [40960/90000 (45%)]	Loss: -15.7112	Cost: 7.08s
Train Epoch: 1159 [61440/90000 (68%)]	Loss: -16.0932	Cost: 5.86s
Train Epoch: 1159 [81920/90000 (91%)]	Loss: -16.3516	Cost: 5.96s
Train Epoch: 1159 	Average Loss: -15.3409
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.2340

Learning rate: 7.52831865889958e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1160 [0/90000 (0%)]	Loss: -6.4525	Cost: 25.12s
Train Epoch: 1160 [20480/90000 (23%)]	Loss: -16.4025	Cost: 6.15s
Train Epoch: 1160 [40960/90000 (45%)]	Loss: -15.9895	Cost: 7.27s
Train Epoch: 1160 [61440/90000 (68%)]	Loss: -16.1942	Cost: 5.84s
Train Epoch: 1160 [81920/90000 (91%)]	Loss: -16.4422	Cost: 6.07s
Train Epoch: 1160 	Average Loss: -15.4761
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.2962

Learning rate: 7.513101128351442e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1161 [0/90000 (0%)]	Loss: -6.5154	Cost: 25.13s
Train Epoch: 1161 [20480/90000 (23%)]	Loss: -16.3740	Cost: 6.18s
Train Epoch: 1161 [40960/90000 (45%)]	Loss: -15.8792	Cost: 7.09s
Train Epoch: 1161 [61440/90000 (68%)]	Loss: -16.1086	Cost: 5.86s
Train Epoch: 1161 [81920/90000 (91%)]	Loss: -16.4299	Cost: 5.86s
Train Epoch: 1161 	Average Loss: -15.4928
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.1384

Learning rate: 7.497889733979054e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1162 [0/90000 (0%)]	Loss: -6.5494	Cost: 26.63s
Train Epoch: 1162 [20480/90000 (23%)]	Loss: -16.6159	Cost: 6.08s
Train Epoch: 1162 [40960/90000 (45%)]	Loss: -15.8012	Cost: 7.00s
Train Epoch: 1162 [61440/90000 (68%)]	Loss: -16.1084	Cost: 5.87s
Train Epoch: 1162 [81920/90000 (91%)]	Loss: -16.1294	Cost: 5.96s
Train Epoch: 1162 	Average Loss: -15.5143
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.0961

Learning rate: 7.482684513315015e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1163 [0/90000 (0%)]	Loss: -6.3373	Cost: 26.73s
Train Epoch: 1163 [20480/90000 (23%)]	Loss: -16.2681	Cost: 6.05s
Train Epoch: 1163 [40960/90000 (45%)]	Loss: -15.8494	Cost: 7.18s
Train Epoch: 1163 [61440/90000 (68%)]	Loss: -16.0693	Cost: 5.84s
Train Epoch: 1163 [81920/90000 (91%)]	Loss: -16.3570	Cost: 5.96s
Train Epoch: 1163 	Average Loss: -15.4867
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.1548

Learning rate: 7.467485503876707e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1164 [0/90000 (0%)]	Loss: -6.1856	Cost: 26.38s
Train Epoch: 1164 [20480/90000 (23%)]	Loss: -16.4770	Cost: 6.09s
Train Epoch: 1164 [40960/90000 (45%)]	Loss: -16.0283	Cost: 7.27s
Train Epoch: 1164 [61440/90000 (68%)]	Loss: -15.4163	Cost: 5.87s
Train Epoch: 1164 [81920/90000 (91%)]	Loss: -15.7771	Cost: 6.11s
Train Epoch: 1164 	Average Loss: -15.2051
Re-generating waveforms for posterior prior.
Test set: Average loss: -5.8275

Learning rate: 7.452292743166169e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1165 [0/90000 (0%)]	Loss: -6.1933	Cost: 25.55s
Train Epoch: 1165 [20480/90000 (23%)]	Loss: -16.2469	Cost: 6.14s
Train Epoch: 1165 [40960/90000 (45%)]	Loss: -15.8134	Cost: 7.29s
Train Epoch: 1165 [61440/90000 (68%)]	Loss: -15.8068	Cost: 5.91s
Train Epoch: 1165 [81920/90000 (91%)]	Loss: -16.0656	Cost: 6.15s
Train Epoch: 1165 	Average Loss: -15.1859
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.2350

Learning rate: 7.437106268670021e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1166 [0/90000 (0%)]	Loss: -6.0524	Cost: 26.02s
Train Epoch: 1166 [20480/90000 (23%)]	Loss: -16.1231	Cost: 6.20s
Train Epoch: 1166 [40960/90000 (45%)]	Loss: -15.7110	Cost: 6.72s
Train Epoch: 1166 [61440/90000 (68%)]	Loss: -16.0439	Cost: 5.87s
Train Epoch: 1166 [81920/90000 (91%)]	Loss: -16.3262	Cost: 5.68s
Train Epoch: 1166 	Average Loss: -15.2410
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.1342

Learning rate: 7.42192611785939e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1167 [0/90000 (0%)]	Loss: -6.1882	Cost: 25.16s
Train Epoch: 1167 [20480/90000 (23%)]	Loss: -16.0374	Cost: 6.12s
Train Epoch: 1167 [40960/90000 (45%)]	Loss: -15.7991	Cost: 7.34s
Train Epoch: 1167 [61440/90000 (68%)]	Loss: -16.0152	Cost: 5.86s
Train Epoch: 1167 [81920/90000 (91%)]	Loss: -16.5084	Cost: 5.99s
Train Epoch: 1167 	Average Loss: -15.3141
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.2213

Learning rate: 7.406752328189784e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1168 [0/90000 (0%)]	Loss: -6.5338	Cost: 25.58s
Train Epoch: 1168 [20480/90000 (23%)]	Loss: -16.5285	Cost: 6.16s
Train Epoch: 1168 [40960/90000 (45%)]	Loss: -16.0029	Cost: 7.34s
Train Epoch: 1168 [61440/90000 (68%)]	Loss: -16.3636	Cost: 5.84s
Train Epoch: 1168 [81920/90000 (91%)]	Loss: -16.4476	Cost: 5.78s
Train Epoch: 1168 	Average Loss: -15.6039
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.2570

Learning rate: 7.39158493710102e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1169 [0/90000 (0%)]	Loss: -6.3349	Cost: 25.28s
Train Epoch: 1169 [20480/90000 (23%)]	Loss: -16.5313	Cost: 6.13s
Train Epoch: 1169 [40960/90000 (45%)]	Loss: -16.0674	Cost: 7.26s
Train Epoch: 1169 [61440/90000 (68%)]	Loss: -16.3762	Cost: 5.84s
Train Epoch: 1169 [81920/90000 (91%)]	Loss: -16.6418	Cost: 6.07s
Train Epoch: 1169 	Average Loss: -15.6575
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.4049

Learning rate: 7.376423982017128e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1170 [0/90000 (0%)]	Loss: -6.8096	Cost: 25.31s
Train Epoch: 1170 [20480/90000 (23%)]	Loss: -16.6735	Cost: 6.13s
Train Epoch: 1170 [40960/90000 (45%)]	Loss: -16.0691	Cost: 7.30s
Train Epoch: 1170 [61440/90000 (68%)]	Loss: -16.3914	Cost: 5.83s
Train Epoch: 1170 [81920/90000 (91%)]	Loss: -16.6007	Cost: 5.95s
Train Epoch: 1170 	Average Loss: -15.6881
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.2230

Learning rate: 7.36126950034626e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1171 [0/90000 (0%)]	Loss: -5.7818	Cost: 25.53s
Train Epoch: 1171 [20480/90000 (23%)]	Loss: -16.5936	Cost: 6.13s
Train Epoch: 1171 [40960/90000 (45%)]	Loss: -16.2859	Cost: 7.30s
Train Epoch: 1171 [61440/90000 (68%)]	Loss: -16.3009	Cost: 5.86s
Train Epoch: 1171 [81920/90000 (91%)]	Loss: -16.5364	Cost: 6.14s
Train Epoch: 1171 	Average Loss: -15.7247
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.3918

Learning rate: 7.346121529480592e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1172 [0/90000 (0%)]	Loss: -6.6356	Cost: 25.86s
Train Epoch: 1172 [20480/90000 (23%)]	Loss: -16.5727	Cost: 6.11s
Train Epoch: 1172 [40960/90000 (45%)]	Loss: -15.7578	Cost: 7.23s
Train Epoch: 1172 [61440/90000 (68%)]	Loss: -16.2831	Cost: 5.84s
Train Epoch: 1172 [81920/90000 (91%)]	Loss: -16.3621	Cost: 5.90s
Train Epoch: 1172 	Average Loss: -15.6000
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.1170

Learning rate: 7.330980106796236e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1173 [0/90000 (0%)]	Loss: -6.5000	Cost: 25.29s
Train Epoch: 1173 [20480/90000 (23%)]	Loss: -16.5529	Cost: 6.15s
Train Epoch: 1173 [40960/90000 (45%)]	Loss: -15.9208	Cost: 7.36s
Train Epoch: 1173 [61440/90000 (68%)]	Loss: -16.1770	Cost: 5.83s
Train Epoch: 1173 [81920/90000 (91%)]	Loss: -16.4895	Cost: 6.05s
Train Epoch: 1173 	Average Loss: -15.6089
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.2087

Learning rate: 7.315845269653145e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1174 [0/90000 (0%)]	Loss: -6.0801	Cost: 25.43s
Train Epoch: 1174 [20480/90000 (23%)]	Loss: -16.5176	Cost: 6.12s
Train Epoch: 1174 [40960/90000 (45%)]	Loss: -16.0997	Cost: 6.87s
Train Epoch: 1174 [61440/90000 (68%)]	Loss: -16.2464	Cost: 5.91s
Train Epoch: 1174 [81920/90000 (91%)]	Loss: -16.5064	Cost: 5.96s
Train Epoch: 1174 	Average Loss: -15.6487
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.2900

Learning rate: 7.300717055395025e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1175 [0/90000 (0%)]	Loss: -5.7725	Cost: 25.55s
Train Epoch: 1175 [20480/90000 (23%)]	Loss: -16.5416	Cost: 6.11s
Train Epoch: 1175 [40960/90000 (45%)]	Loss: -16.1125	Cost: 6.42s
Train Epoch: 1175 [61440/90000 (68%)]	Loss: -16.4141	Cost: 5.92s
Train Epoch: 1175 [81920/90000 (91%)]	Loss: -16.6588	Cost: 6.00s
Train Epoch: 1175 	Average Loss: -15.6985
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.6403

Learning rate: 7.285595501349247e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1176 [0/90000 (0%)]	Loss: -6.2851	Cost: 24.98s
Train Epoch: 1176 [20480/90000 (23%)]	Loss: -16.6754	Cost: 6.15s
Train Epoch: 1176 [40960/90000 (45%)]	Loss: -16.2056	Cost: 7.18s
Train Epoch: 1176 [61440/90000 (68%)]	Loss: -16.4629	Cost: 5.89s
Train Epoch: 1176 [81920/90000 (91%)]	Loss: -16.8205	Cost: 5.90s
Train Epoch: 1176 	Average Loss: -15.7412
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.4430

Learning rate: 7.270480644826736e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1177 [0/90000 (0%)]	Loss: -6.2435	Cost: 25.11s
Train Epoch: 1177 [20480/90000 (23%)]	Loss: -16.8427	Cost: 6.14s
Train Epoch: 1177 [40960/90000 (45%)]	Loss: -16.1692	Cost: 7.10s
Train Epoch: 1177 [61440/90000 (68%)]	Loss: -16.4836	Cost: 5.85s
Train Epoch: 1177 [81920/90000 (91%)]	Loss: -16.8580	Cost: 5.98s
Train Epoch: 1177 	Average Loss: -15.7827
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.4762

Learning rate: 7.255372523121904e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1178 [0/90000 (0%)]	Loss: -6.2316	Cost: 25.04s
Train Epoch: 1178 [20480/90000 (23%)]	Loss: -16.7995	Cost: 6.12s
Train Epoch: 1178 [40960/90000 (45%)]	Loss: -16.4144	Cost: 7.25s
Train Epoch: 1178 [61440/90000 (68%)]	Loss: -16.4426	Cost: 5.95s
Train Epoch: 1178 [81920/90000 (91%)]	Loss: -16.6327	Cost: 5.99s
Train Epoch: 1178 	Average Loss: -15.8491
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.3715

Learning rate: 7.240271173512535e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1179 [0/90000 (0%)]	Loss: -6.3676	Cost: 24.92s
Train Epoch: 1179 [20480/90000 (23%)]	Loss: -16.7156	Cost: 6.19s
Train Epoch: 1179 [40960/90000 (45%)]	Loss: -16.4321	Cost: 7.33s
Train Epoch: 1179 [61440/90000 (68%)]	Loss: -16.3065	Cost: 5.85s
Train Epoch: 1179 [81920/90000 (91%)]	Loss: -16.5157	Cost: 6.02s
Train Epoch: 1179 	Average Loss: -15.8193
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.3658

Learning rate: 7.225176633259708e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1180 [0/90000 (0%)]	Loss: -6.9243	Cost: 25.02s
Train Epoch: 1180 [20480/90000 (23%)]	Loss: -16.6507	Cost: 6.16s
Train Epoch: 1180 [40960/90000 (45%)]	Loss: -15.4762	Cost: 7.23s
Train Epoch: 1180 [61440/90000 (68%)]	Loss: -15.8073	Cost: 5.84s
Train Epoch: 1180 [81920/90000 (91%)]	Loss: -16.2517	Cost: 6.06s
Train Epoch: 1180 	Average Loss: -15.3738
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.3028

Learning rate: 7.210088939607696e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1181 [0/90000 (0%)]	Loss: -5.8326	Cost: 25.56s
Train Epoch: 1181 [20480/90000 (23%)]	Loss: -16.6094	Cost: 6.11s
Train Epoch: 1181 [40960/90000 (45%)]	Loss: -15.9881	Cost: 6.85s
Train Epoch: 1181 [61440/90000 (68%)]	Loss: -16.4408	Cost: 5.86s
Train Epoch: 1181 [81920/90000 (91%)]	Loss: -16.6844	Cost: 6.01s
Train Epoch: 1181 	Average Loss: -15.6280
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.3465

Learning rate: 7.195008129783893e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1182 [0/90000 (0%)]	Loss: -7.2572	Cost: 25.97s
Train Epoch: 1182 [20480/90000 (23%)]	Loss: -16.7525	Cost: 6.11s
Train Epoch: 1182 [40960/90000 (45%)]	Loss: -16.0902	Cost: 7.24s
Train Epoch: 1182 [61440/90000 (68%)]	Loss: -16.3976	Cost: 5.82s
Train Epoch: 1182 [81920/90000 (91%)]	Loss: -16.5843	Cost: 5.97s
Train Epoch: 1182 	Average Loss: -15.7240
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.3747

Learning rate: 7.179934240998696e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1183 [0/90000 (0%)]	Loss: -6.3898	Cost: 25.43s
Train Epoch: 1183 [20480/90000 (23%)]	Loss: -16.6350	Cost: 6.15s
Train Epoch: 1183 [40960/90000 (45%)]	Loss: -16.1862	Cost: 7.11s
Train Epoch: 1183 [61440/90000 (68%)]	Loss: -16.5412	Cost: 5.84s
Train Epoch: 1183 [81920/90000 (91%)]	Loss: -16.6125	Cost: 6.18s
Train Epoch: 1183 	Average Loss: -15.7502
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.2717

Learning rate: 7.164867310445423e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1184 [0/90000 (0%)]	Loss: -6.6232	Cost: 26.03s
Train Epoch: 1184 [20480/90000 (23%)]	Loss: -16.4238	Cost: 6.10s
Train Epoch: 1184 [40960/90000 (45%)]	Loss: -16.1086	Cost: 7.33s
Train Epoch: 1184 [61440/90000 (68%)]	Loss: -16.2897	Cost: 5.81s
Train Epoch: 1184 [81920/90000 (91%)]	Loss: -16.4510	Cost: 5.90s
Train Epoch: 1184 	Average Loss: -15.5960
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.3016

Learning rate: 7.149807375300228e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1185 [0/90000 (0%)]	Loss: -6.5617	Cost: 25.46s
Train Epoch: 1185 [20480/90000 (23%)]	Loss: -16.7256	Cost: 6.09s
Train Epoch: 1185 [40960/90000 (45%)]	Loss: -16.3173	Cost: 7.29s
Train Epoch: 1185 [61440/90000 (68%)]	Loss: -16.6486	Cost: 5.82s
Train Epoch: 1185 [81920/90000 (91%)]	Loss: -16.6865	Cost: 6.07s
Train Epoch: 1185 	Average Loss: -15.8560
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.6204

Learning rate: 7.134754472722007e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1186 [0/90000 (0%)]	Loss: -6.1487	Cost: 25.46s
Train Epoch: 1186 [20480/90000 (23%)]	Loss: -16.7954	Cost: 6.13s
Train Epoch: 1186 [40960/90000 (45%)]	Loss: -16.3595	Cost: 7.18s
Train Epoch: 1186 [61440/90000 (68%)]	Loss: -16.7485	Cost: 5.82s
Train Epoch: 1186 [81920/90000 (91%)]	Loss: -16.7533	Cost: 6.18s
Train Epoch: 1186 	Average Loss: -15.8655
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.4060

Learning rate: 7.119708639852298e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1187 [0/90000 (0%)]	Loss: -6.0362	Cost: 26.53s
Train Epoch: 1187 [20480/90000 (23%)]	Loss: -16.7576	Cost: 6.14s
Train Epoch: 1187 [40960/90000 (45%)]	Loss: -16.2768	Cost: 6.19s
Train Epoch: 1187 [61440/90000 (68%)]	Loss: -16.5943	Cost: 5.92s
Train Epoch: 1187 [81920/90000 (91%)]	Loss: -16.7431	Cost: 6.30s
Train Epoch: 1187 	Average Loss: -15.8432
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.7343

Learning rate: 7.104669913815196e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1188 [0/90000 (0%)]	Loss: -7.0177	Cost: 25.08s
Train Epoch: 1188 [20480/90000 (23%)]	Loss: -16.7283	Cost: 6.16s
Train Epoch: 1188 [40960/90000 (45%)]	Loss: -16.3496	Cost: 7.17s
Train Epoch: 1188 [61440/90000 (68%)]	Loss: -16.4844	Cost: 5.87s
Train Epoch: 1188 [81920/90000 (91%)]	Loss: -16.6322	Cost: 5.91s
Train Epoch: 1188 	Average Loss: -15.8045
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.4036

Learning rate: 7.08963833171727e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1189 [0/90000 (0%)]	Loss: -6.3344	Cost: 25.78s
Train Epoch: 1189 [20480/90000 (23%)]	Loss: -16.5572	Cost: 6.13s
Train Epoch: 1189 [40960/90000 (45%)]	Loss: -16.3892	Cost: 7.16s
Train Epoch: 1189 [61440/90000 (68%)]	Loss: -16.7004	Cost: 5.85s
Train Epoch: 1189 [81920/90000 (91%)]	Loss: -16.7573	Cost: 5.97s
Train Epoch: 1189 	Average Loss: -15.8872
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.4700

Learning rate: 7.07461393064745e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1190 [0/90000 (0%)]	Loss: -6.4277	Cost: 25.48s
Train Epoch: 1190 [20480/90000 (23%)]	Loss: -16.8560	Cost: 6.14s
Train Epoch: 1190 [40960/90000 (45%)]	Loss: -16.5207	Cost: 7.17s
Train Epoch: 1190 [61440/90000 (68%)]	Loss: -16.8236	Cost: 6.15s
Train Epoch: 1190 [81920/90000 (91%)]	Loss: -16.8326	Cost: 5.88s
Train Epoch: 1190 	Average Loss: -16.0143
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.5441

Learning rate: 7.05959674767695e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1191 [0/90000 (0%)]	Loss: -5.9897	Cost: 25.57s
Train Epoch: 1191 [20480/90000 (23%)]	Loss: -16.9358	Cost: 6.36s
Train Epoch: 1191 [40960/90000 (45%)]	Loss: -16.4477	Cost: 7.01s
Train Epoch: 1191 [61440/90000 (68%)]	Loss: -16.6232	Cost: 6.11s
Train Epoch: 1191 [81920/90000 (91%)]	Loss: -16.7497	Cost: 5.82s
Train Epoch: 1191 	Average Loss: -15.9356
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.7082

Learning rate: 7.044586819859178e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1192 [0/90000 (0%)]	Loss: -6.6730	Cost: 25.51s
Train Epoch: 1192 [20480/90000 (23%)]	Loss: -16.7776	Cost: 6.15s
Train Epoch: 1192 [40960/90000 (45%)]	Loss: -16.2101	Cost: 7.07s
Train Epoch: 1192 [61440/90000 (68%)]	Loss: -16.7244	Cost: 5.87s
Train Epoch: 1192 [81920/90000 (91%)]	Loss: -16.7239	Cost: 5.77s
Train Epoch: 1192 	Average Loss: -15.8830
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.6830

Learning rate: 7.029584184229638e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1193 [0/90000 (0%)]	Loss: -6.5231	Cost: 25.59s
Train Epoch: 1193 [20480/90000 (23%)]	Loss: -16.9908	Cost: 6.17s
Train Epoch: 1193 [40960/90000 (45%)]	Loss: -16.4821	Cost: 6.60s
Train Epoch: 1193 [61440/90000 (68%)]	Loss: -16.6580	Cost: 5.94s
Train Epoch: 1193 [81920/90000 (91%)]	Loss: -16.8810	Cost: 5.88s
Train Epoch: 1193 	Average Loss: -16.0207
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.6879

Learning rate: 7.014588877805846e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1194 [0/90000 (0%)]	Loss: -6.6285	Cost: 25.70s
Train Epoch: 1194 [20480/90000 (23%)]	Loss: -17.2231	Cost: 6.13s
Train Epoch: 1194 [40960/90000 (45%)]	Loss: -16.6315	Cost: 7.12s
Train Epoch: 1194 [61440/90000 (68%)]	Loss: -16.8753	Cost: 5.89s
Train Epoch: 1194 [81920/90000 (91%)]	Loss: -16.8566	Cost: 5.94s
Train Epoch: 1194 	Average Loss: -16.1360
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.7674

Learning rate: 6.999600937587227e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1195 [0/90000 (0%)]	Loss: -6.4606	Cost: 26.56s
Train Epoch: 1195 [20480/90000 (23%)]	Loss: -16.9549	Cost: 6.08s
Train Epoch: 1195 [40960/90000 (45%)]	Loss: -16.5311	Cost: 7.26s
Train Epoch: 1195 [61440/90000 (68%)]	Loss: -16.9378	Cost: 5.79s
Train Epoch: 1195 [81920/90000 (91%)]	Loss: -16.8299	Cost: 6.16s
Train Epoch: 1195 	Average Loss: -16.0748
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.5770

Learning rate: 6.984620400555032e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1196 [0/90000 (0%)]	Loss: -5.6709	Cost: 26.25s
Train Epoch: 1196 [20480/90000 (23%)]	Loss: -16.9005	Cost: 6.13s
Train Epoch: 1196 [40960/90000 (45%)]	Loss: -16.5237	Cost: 6.93s
Train Epoch: 1196 [61440/90000 (68%)]	Loss: -16.9709	Cost: 5.87s
Train Epoch: 1196 [81920/90000 (91%)]	Loss: -17.0004	Cost: 6.09s
Train Epoch: 1196 	Average Loss: -16.0545
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.7142

Learning rate: 6.96964730367225e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1197 [0/90000 (0%)]	Loss: -6.1389	Cost: 25.42s
Train Epoch: 1197 [20480/90000 (23%)]	Loss: -17.0706	Cost: 6.14s
Train Epoch: 1197 [40960/90000 (45%)]	Loss: -16.4743	Cost: 7.44s
Train Epoch: 1197 [61440/90000 (68%)]	Loss: -16.4114	Cost: 5.82s
Train Epoch: 1197 [81920/90000 (91%)]	Loss: -16.7161	Cost: 5.96s
Train Epoch: 1197 	Average Loss: -16.0154
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.5325

Learning rate: 6.954681683883507e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1198 [0/90000 (0%)]	Loss: -6.4551	Cost: 25.54s
Train Epoch: 1198 [20480/90000 (23%)]	Loss: -16.8986	Cost: 6.14s
Train Epoch: 1198 [40960/90000 (45%)]	Loss: -16.4276	Cost: 6.84s
Train Epoch: 1198 [61440/90000 (68%)]	Loss: -16.5570	Cost: 5.87s
Train Epoch: 1198 [81920/90000 (91%)]	Loss: -16.4107	Cost: 5.83s
Train Epoch: 1198 	Average Loss: -15.8876
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.3629

Learning rate: 6.93972357811498e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1199 [0/90000 (0%)]	Loss: -7.2395	Cost: 25.52s
Train Epoch: 1199 [20480/90000 (23%)]	Loss: -16.7104	Cost: 6.10s
Train Epoch: 1199 [40960/90000 (45%)]	Loss: -16.0725	Cost: 7.08s
Train Epoch: 1199 [61440/90000 (68%)]	Loss: -16.4709	Cost: 5.86s
Train Epoch: 1199 [81920/90000 (91%)]	Loss: -16.8751	Cost: 5.95s
Train Epoch: 1199 	Average Loss: -15.8374
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.5732

Learning rate: 6.924773023274315e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1200 [0/90000 (0%)]	Loss: -7.1665	Cost: 25.30s
Train Epoch: 1200 [20480/90000 (23%)]	Loss: -17.0125	Cost: 6.13s
Train Epoch: 1200 [40960/90000 (45%)]	Loss: -16.3860	Cost: 7.26s
Train Epoch: 1200 [61440/90000 (68%)]	Loss: -16.6929	Cost: 5.84s
Train Epoch: 1200 [81920/90000 (91%)]	Loss: -16.6294	Cost: 6.14s
Train Epoch: 1200 	Average Loss: -16.0367
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.7227

Saving model as model_sample_from_all_posterior.pt_e1200 & waveforms_supplementary_sample_from_all_posterior.hdf5_e1200
Learning rate: 6.909830056250515e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1201 [0/90000 (0%)]	Loss: -7.1968	Cost: 26.22s
Train Epoch: 1201 [20480/90000 (23%)]	Loss: -16.8485	Cost: 6.11s
Train Epoch: 1201 [40960/90000 (45%)]	Loss: -15.8549	Cost: 7.17s
Train Epoch: 1201 [61440/90000 (68%)]	Loss: -16.3926	Cost: 5.78s
Train Epoch: 1201 [81920/90000 (91%)]	Loss: -16.6759	Cost: 5.86s
Train Epoch: 1201 	Average Loss: -15.7761
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.5938

Learning rate: 6.894894713913866e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1202 [0/90000 (0%)]	Loss: -6.8205	Cost: 25.79s
Train Epoch: 1202 [20480/90000 (23%)]	Loss: -16.7992	Cost: 6.09s
Train Epoch: 1202 [40960/90000 (45%)]	Loss: -16.4373	Cost: 7.03s
Train Epoch: 1202 [61440/90000 (68%)]	Loss: -16.8219	Cost: 5.81s
Train Epoch: 1202 [81920/90000 (91%)]	Loss: -16.3661	Cost: 6.13s
Train Epoch: 1202 	Average Loss: -15.9681
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.0203

Learning rate: 6.87996703311584e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1203 [0/90000 (0%)]	Loss: -6.1001	Cost: 25.79s
Train Epoch: 1203 [20480/90000 (23%)]	Loss: -16.2276	Cost: 6.07s
Train Epoch: 1203 [40960/90000 (45%)]	Loss: -15.9974	Cost: 7.19s
Train Epoch: 1203 [61440/90000 (68%)]	Loss: -16.5403	Cost: 5.89s
Train Epoch: 1203 [81920/90000 (91%)]	Loss: -16.8426	Cost: 5.75s
Train Epoch: 1203 	Average Loss: -15.6103
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.6525

Learning rate: 6.865047050689007e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1204 [0/90000 (0%)]	Loss: -6.7200	Cost: 25.62s
Train Epoch: 1204 [20480/90000 (23%)]	Loss: -16.7608	Cost: 6.15s
Train Epoch: 1204 [40960/90000 (45%)]	Loss: -16.3102	Cost: 7.04s
Train Epoch: 1204 [61440/90000 (68%)]	Loss: -16.8201	Cost: 5.98s
Train Epoch: 1204 [81920/90000 (91%)]	Loss: -16.8939	Cost: 5.95s
Train Epoch: 1204 	Average Loss: -15.9581
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.7605

Learning rate: 6.85013480344694e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1205 [0/90000 (0%)]	Loss: -6.7676	Cost: 25.76s
Train Epoch: 1205 [20480/90000 (23%)]	Loss: -16.6579	Cost: 6.16s
Train Epoch: 1205 [40960/90000 (45%)]	Loss: -16.2157	Cost: 7.02s
Train Epoch: 1205 [61440/90000 (68%)]	Loss: -16.4839	Cost: 5.89s
Train Epoch: 1205 [81920/90000 (91%)]	Loss: -16.9441	Cost: 5.69s
Train Epoch: 1205 	Average Loss: -15.8454
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.6259

Learning rate: 6.835230328184126e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1206 [0/90000 (0%)]	Loss: -5.9900	Cost: 25.75s
Train Epoch: 1206 [20480/90000 (23%)]	Loss: -17.1474	Cost: 6.16s
Train Epoch: 1206 [40960/90000 (45%)]	Loss: -16.6700	Cost: 7.28s
Train Epoch: 1206 [61440/90000 (68%)]	Loss: -16.9668	Cost: 5.84s
Train Epoch: 1206 [81920/90000 (91%)]	Loss: -17.1054	Cost: 5.94s
Train Epoch: 1206 	Average Loss: -16.1739
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.6284

Learning rate: 6.820333661675877e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1207 [0/90000 (0%)]	Loss: -6.9591	Cost: 24.84s
Train Epoch: 1207 [20480/90000 (23%)]	Loss: -17.1802	Cost: 6.11s
Train Epoch: 1207 [40960/90000 (45%)]	Loss: -16.8171	Cost: 7.39s
Train Epoch: 1207 [61440/90000 (68%)]	Loss: -16.9828	Cost: 5.86s
Train Epoch: 1207 [81920/90000 (91%)]	Loss: -17.3491	Cost: 5.92s
Train Epoch: 1207 	Average Loss: -16.2677
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.8344

Learning rate: 6.805444840678239e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1208 [0/90000 (0%)]	Loss: -7.0734	Cost: 27.14s
Train Epoch: 1208 [20480/90000 (23%)]	Loss: -17.0944	Cost: 6.12s
Train Epoch: 1208 [40960/90000 (45%)]	Loss: -16.7850	Cost: 6.92s
Train Epoch: 1208 [61440/90000 (68%)]	Loss: -17.2227	Cost: 5.84s
Train Epoch: 1208 [81920/90000 (91%)]	Loss: -17.1838	Cost: 5.85s
Train Epoch: 1208 	Average Loss: -16.3526
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.8936

Learning rate: 6.790563901927893e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1209 [0/90000 (0%)]	Loss: -6.5863	Cost: 25.13s
Train Epoch: 1209 [20480/90000 (23%)]	Loss: -17.2171	Cost: 6.16s
Train Epoch: 1209 [40960/90000 (45%)]	Loss: -16.7454	Cost: 7.21s
Train Epoch: 1209 [61440/90000 (68%)]	Loss: -17.1913	Cost: 5.85s
Train Epoch: 1209 [81920/90000 (91%)]	Loss: -17.1716	Cost: 5.73s
Train Epoch: 1209 	Average Loss: -16.3703
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.9220

Learning rate: 6.775690882142078e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1210 [0/90000 (0%)]	Loss: -7.3674	Cost: 25.44s
Train Epoch: 1210 [20480/90000 (23%)]	Loss: -17.2970	Cost: 6.13s
Train Epoch: 1210 [40960/90000 (45%)]	Loss: -16.8218	Cost: 6.38s
Train Epoch: 1210 [61440/90000 (68%)]	Loss: -17.0828	Cost: 5.89s
Train Epoch: 1210 [81920/90000 (91%)]	Loss: -17.2622	Cost: 5.70s
Train Epoch: 1210 	Average Loss: -16.3993
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.8813

Learning rate: 6.760825818018492e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1211 [0/90000 (0%)]	Loss: -7.7011	Cost: 25.37s
Train Epoch: 1211 [20480/90000 (23%)]	Loss: -17.2891	Cost: 6.13s
Train Epoch: 1211 [40960/90000 (45%)]	Loss: -16.5867	Cost: 7.50s
Train Epoch: 1211 [61440/90000 (68%)]	Loss: -17.1745	Cost: 5.81s
Train Epoch: 1211 [81920/90000 (91%)]	Loss: -17.3133	Cost: 6.17s
Train Epoch: 1211 	Average Loss: -16.4239
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.8183

Learning rate: 6.745968746235204e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1212 [0/90000 (0%)]	Loss: -6.2690	Cost: 25.71s
Train Epoch: 1212 [20480/90000 (23%)]	Loss: -17.3740	Cost: 6.21s
Train Epoch: 1212 [40960/90000 (45%)]	Loss: -16.9353	Cost: 7.20s
Train Epoch: 1212 [61440/90000 (68%)]	Loss: -17.0926	Cost: 5.90s
Train Epoch: 1212 [81920/90000 (91%)]	Loss: -17.2190	Cost: 6.22s
Train Epoch: 1212 	Average Loss: -16.3823
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.9212

Learning rate: 6.731119703450562e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1213 [0/90000 (0%)]	Loss: -7.0488	Cost: 25.82s
Train Epoch: 1213 [20480/90000 (23%)]	Loss: -17.3080	Cost: 6.10s
Train Epoch: 1213 [40960/90000 (45%)]	Loss: -16.7999	Cost: 7.31s
Train Epoch: 1213 [61440/90000 (68%)]	Loss: -17.1400	Cost: 5.83s
Train Epoch: 1213 [81920/90000 (91%)]	Loss: -16.9450	Cost: 5.66s
Train Epoch: 1213 	Average Loss: -16.3746
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.8361

Learning rate: 6.7162787263031e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1214 [0/90000 (0%)]	Loss: -6.6834	Cost: 25.68s
Train Epoch: 1214 [20480/90000 (23%)]	Loss: -17.4764	Cost: 6.13s
Train Epoch: 1214 [40960/90000 (45%)]	Loss: -16.9493	Cost: 7.30s
Train Epoch: 1214 [61440/90000 (68%)]	Loss: -17.2065	Cost: 5.91s
Train Epoch: 1214 [81920/90000 (91%)]	Loss: -17.3090	Cost: 5.89s
Train Epoch: 1214 	Average Loss: -16.4111
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.9280

Learning rate: 6.701445851411458e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1215 [0/90000 (0%)]	Loss: -7.4096	Cost: 25.70s
Train Epoch: 1215 [20480/90000 (23%)]	Loss: -17.5290	Cost: 6.14s
Train Epoch: 1215 [40960/90000 (45%)]	Loss: -16.6740	Cost: 7.40s
Train Epoch: 1215 [61440/90000 (68%)]	Loss: -17.2801	Cost: 5.86s
Train Epoch: 1215 [81920/90000 (91%)]	Loss: -17.4518	Cost: 5.94s
Train Epoch: 1215 	Average Loss: -16.5258
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.9553

Learning rate: 6.686621115374279e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1216 [0/90000 (0%)]	Loss: -6.1596	Cost: 24.83s
Train Epoch: 1216 [20480/90000 (23%)]	Loss: -17.4365	Cost: 6.14s
Train Epoch: 1216 [40960/90000 (45%)]	Loss: -16.9998	Cost: 7.25s
Train Epoch: 1216 [61440/90000 (68%)]	Loss: -17.2751	Cost: 5.86s
Train Epoch: 1216 [81920/90000 (91%)]	Loss: -17.4463	Cost: 5.83s
Train Epoch: 1216 	Average Loss: -16.5490
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.9896

Learning rate: 6.671804554770121e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1217 [0/90000 (0%)]	Loss: -6.1200	Cost: 25.57s
Train Epoch: 1217 [20480/90000 (23%)]	Loss: -17.4639	Cost: 6.15s
Train Epoch: 1217 [40960/90000 (45%)]	Loss: -16.8865	Cost: 7.28s
Train Epoch: 1217 [61440/90000 (68%)]	Loss: -17.3791	Cost: 5.87s
Train Epoch: 1217 [81920/90000 (91%)]	Loss: -17.4287	Cost: 5.91s
Train Epoch: 1217 	Average Loss: -16.5309
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.9842

Learning rate: 6.656996206157379e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1218 [0/90000 (0%)]	Loss: -7.6298	Cost: 26.70s
Train Epoch: 1218 [20480/90000 (23%)]	Loss: -17.3969	Cost: 6.04s
Train Epoch: 1218 [40960/90000 (45%)]	Loss: -16.9549	Cost: 7.26s
Train Epoch: 1218 [61440/90000 (68%)]	Loss: -17.0679	Cost: 5.87s
Train Epoch: 1218 [81920/90000 (91%)]	Loss: -17.4731	Cost: 6.03s
Train Epoch: 1218 	Average Loss: -16.5643
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.9998

Learning rate: 6.642196106074182e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1219 [0/90000 (0%)]	Loss: -6.5564	Cost: 25.00s
Train Epoch: 1219 [20480/90000 (23%)]	Loss: -17.4040	Cost: 6.17s
Train Epoch: 1219 [40960/90000 (45%)]	Loss: -16.9624	Cost: 7.29s
Train Epoch: 1219 [61440/90000 (68%)]	Loss: -17.3379	Cost: 5.91s
Train Epoch: 1219 [81920/90000 (91%)]	Loss: -17.4447	Cost: 6.06s
Train Epoch: 1219 	Average Loss: -16.5757
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.0303

Learning rate: 6.627404291038302e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1220 [0/90000 (0%)]	Loss: -6.4750	Cost: 25.45s
Train Epoch: 1220 [20480/90000 (23%)]	Loss: -17.4396	Cost: 6.15s
Train Epoch: 1220 [40960/90000 (45%)]	Loss: -17.0602	Cost: 7.37s
Train Epoch: 1220 [61440/90000 (68%)]	Loss: -17.3672	Cost: 5.85s
Train Epoch: 1220 [81920/90000 (91%)]	Loss: -17.5297	Cost: 6.00s
Train Epoch: 1220 	Average Loss: -16.5656
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.9351

Learning rate: 6.612620797547074e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1221 [0/90000 (0%)]	Loss: -7.2165	Cost: 26.45s
Train Epoch: 1221 [20480/90000 (23%)]	Loss: -17.3629	Cost: 6.07s
Train Epoch: 1221 [40960/90000 (45%)]	Loss: -16.2235	Cost: 7.26s
Train Epoch: 1221 [61440/90000 (68%)]	Loss: -16.6509	Cost: 5.82s
Train Epoch: 1221 [81920/90000 (91%)]	Loss: -16.8595	Cost: 6.07s
Train Epoch: 1221 	Average Loss: -16.1763
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.7508

Learning rate: 6.597845662077301e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1222 [0/90000 (0%)]	Loss: -7.6137	Cost: 26.49s
Train Epoch: 1222 [20480/90000 (23%)]	Loss: -17.0965	Cost: 6.09s
Train Epoch: 1222 [40960/90000 (45%)]	Loss: -16.5979	Cost: 7.27s
Train Epoch: 1222 [61440/90000 (68%)]	Loss: -17.0221	Cost: 5.82s
Train Epoch: 1222 [81920/90000 (91%)]	Loss: -17.3204	Cost: 5.70s
Train Epoch: 1222 	Average Loss: -16.3049
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.9386

Learning rate: 6.583078921085155e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1223 [0/90000 (0%)]	Loss: -6.6352	Cost: 26.89s
Train Epoch: 1223 [20480/90000 (23%)]	Loss: -17.2435	Cost: 6.09s
Train Epoch: 1223 [40960/90000 (45%)]	Loss: -16.9227	Cost: 7.08s
Train Epoch: 1223 [61440/90000 (68%)]	Loss: -17.3456	Cost: 5.86s
Train Epoch: 1223 [81920/90000 (91%)]	Loss: -17.4509	Cost: 5.80s
Train Epoch: 1223 	Average Loss: -16.4715
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.0419

Learning rate: 6.568320611006108e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1224 [0/90000 (0%)]	Loss: -7.3417	Cost: 25.19s
Train Epoch: 1224 [20480/90000 (23%)]	Loss: -17.3638	Cost: 6.13s
Train Epoch: 1224 [40960/90000 (45%)]	Loss: -16.4995	Cost: 7.45s
Train Epoch: 1224 [61440/90000 (68%)]	Loss: -16.8102	Cost: 5.82s
Train Epoch: 1224 [81920/90000 (91%)]	Loss: -17.0066	Cost: 6.06s
Train Epoch: 1224 	Average Loss: -16.2055
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.8641

Learning rate: 6.553570768254818e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1225 [0/90000 (0%)]	Loss: -6.9627	Cost: 26.66s
Train Epoch: 1225 [20480/90000 (23%)]	Loss: -17.2926	Cost: 6.09s
Train Epoch: 1225 [40960/90000 (45%)]	Loss: -16.8581	Cost: 7.36s
Train Epoch: 1225 [61440/90000 (68%)]	Loss: -17.2053	Cost: 5.81s
Train Epoch: 1225 [81920/90000 (91%)]	Loss: -17.4173	Cost: 5.85s
Train Epoch: 1225 	Average Loss: -16.4476
Re-generating waveforms for posterior prior.
Test set: Average loss: -6.9895

Learning rate: 6.53882942922506e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1226 [0/90000 (0%)]	Loss: -6.0982	Cost: 25.62s
Train Epoch: 1226 [20480/90000 (23%)]	Loss: -17.4081	Cost: 6.13s
Train Epoch: 1226 [40960/90000 (45%)]	Loss: -16.8885	Cost: 7.06s
Train Epoch: 1226 [61440/90000 (68%)]	Loss: -17.3345	Cost: 5.90s
Train Epoch: 1226 [81920/90000 (91%)]	Loss: -17.5227	Cost: 5.98s
Train Epoch: 1226 	Average Loss: -16.5519
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.1166

Learning rate: 6.52409663028962e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1227 [0/90000 (0%)]	Loss: -6.9173	Cost: 26.11s
Train Epoch: 1227 [20480/90000 (23%)]	Loss: -17.6610	Cost: 6.13s
Train Epoch: 1227 [40960/90000 (45%)]	Loss: -17.1681	Cost: 7.16s
Train Epoch: 1227 [61440/90000 (68%)]	Loss: -17.3729	Cost: 5.86s
Train Epoch: 1227 [81920/90000 (91%)]	Loss: -17.5760	Cost: 5.96s
Train Epoch: 1227 	Average Loss: -16.6321
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.1666

Learning rate: 6.509372407800214e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1228 [0/90000 (0%)]	Loss: -6.8518	Cost: 25.33s
Train Epoch: 1228 [20480/90000 (23%)]	Loss: -17.4816	Cost: 6.13s
Train Epoch: 1228 [40960/90000 (45%)]	Loss: -16.8946	Cost: 7.37s
Train Epoch: 1228 [61440/90000 (68%)]	Loss: -17.4077	Cost: 5.85s
Train Epoch: 1228 [81920/90000 (91%)]	Loss: -17.4710	Cost: 5.86s
Train Epoch: 1228 	Average Loss: -16.5793
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.1103

Learning rate: 6.494656798087399e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1229 [0/90000 (0%)]	Loss: -6.5125	Cost: 25.50s
Train Epoch: 1229 [20480/90000 (23%)]	Loss: -17.6316	Cost: 6.14s
Train Epoch: 1229 [40960/90000 (45%)]	Loss: -17.1387	Cost: 7.36s
Train Epoch: 1229 [61440/90000 (68%)]	Loss: -17.2821	Cost: 5.82s
Train Epoch: 1229 [81920/90000 (91%)]	Loss: -17.6747	Cost: 5.93s
Train Epoch: 1229 	Average Loss: -16.6326
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.0427

Learning rate: 6.47994983746048e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1230 [0/90000 (0%)]	Loss: -7.1616	Cost: 26.03s
Train Epoch: 1230 [20480/90000 (23%)]	Loss: -17.7053	Cost: 6.11s
Train Epoch: 1230 [40960/90000 (45%)]	Loss: -17.0899	Cost: 7.33s
Train Epoch: 1230 [61440/90000 (68%)]	Loss: -17.4596	Cost: 5.83s
Train Epoch: 1230 [81920/90000 (91%)]	Loss: -17.5791	Cost: 5.84s
Train Epoch: 1230 	Average Loss: -16.6621
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.1345

Learning rate: 6.465251562207419e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1231 [0/90000 (0%)]	Loss: -6.6537	Cost: 25.98s
Train Epoch: 1231 [20480/90000 (23%)]	Loss: -17.7454	Cost: 6.13s
Train Epoch: 1231 [40960/90000 (45%)]	Loss: -17.1280	Cost: 6.44s
Train Epoch: 1231 [61440/90000 (68%)]	Loss: -17.4638	Cost: 5.96s
Train Epoch: 1231 [81920/90000 (91%)]	Loss: -17.6505	Cost: 6.02s
Train Epoch: 1231 	Average Loss: -16.6862
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.1515

Learning rate: 6.450562008594747e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1232 [0/90000 (0%)]	Loss: -6.8916	Cost: 25.72s
Train Epoch: 1232 [20480/90000 (23%)]	Loss: -17.8375	Cost: 6.16s
Train Epoch: 1232 [40960/90000 (45%)]	Loss: -17.2852	Cost: 7.26s
Train Epoch: 1232 [61440/90000 (68%)]	Loss: -17.6620	Cost: 5.85s
Train Epoch: 1232 [81920/90000 (91%)]	Loss: -17.5202	Cost: 6.10s
Train Epoch: 1232 	Average Loss: -16.7231
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.1787

Learning rate: 6.435881212867483e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1233 [0/90000 (0%)]	Loss: -7.8161	Cost: 26.94s
Train Epoch: 1233 [20480/90000 (23%)]	Loss: -17.7808	Cost: 6.11s
Train Epoch: 1233 [40960/90000 (45%)]	Loss: -17.1165	Cost: 7.16s
Train Epoch: 1233 [61440/90000 (68%)]	Loss: -17.6542	Cost: 5.86s
Train Epoch: 1233 [81920/90000 (91%)]	Loss: -17.6724	Cost: 5.90s
Train Epoch: 1233 	Average Loss: -16.7276
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.2769

Learning rate: 6.421209211249026e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1234 [0/90000 (0%)]	Loss: -6.9348	Cost: 25.72s
Train Epoch: 1234 [20480/90000 (23%)]	Loss: -17.7058	Cost: 6.13s
Train Epoch: 1234 [40960/90000 (45%)]	Loss: -17.2381	Cost: 7.30s
Train Epoch: 1234 [61440/90000 (68%)]	Loss: -17.6083	Cost: 5.83s
Train Epoch: 1234 [81920/90000 (91%)]	Loss: -17.7415	Cost: 5.94s
Train Epoch: 1234 	Average Loss: -16.8223
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.1213

Learning rate: 6.406546039941083e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1235 [0/90000 (0%)]	Loss: -7.3339	Cost: 25.65s
Train Epoch: 1235 [20480/90000 (23%)]	Loss: -17.9618	Cost: 6.12s
Train Epoch: 1235 [40960/90000 (45%)]	Loss: -17.3026	Cost: 7.16s
Train Epoch: 1235 [61440/90000 (68%)]	Loss: -17.5871	Cost: 5.85s
Train Epoch: 1235 [81920/90000 (91%)]	Loss: -17.5881	Cost: 6.25s
Train Epoch: 1235 	Average Loss: -16.7949
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.1783

Learning rate: 6.39189173512357e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1236 [0/90000 (0%)]	Loss: -6.6762	Cost: 26.41s
Train Epoch: 1236 [20480/90000 (23%)]	Loss: -17.8034	Cost: 6.10s
Train Epoch: 1236 [40960/90000 (45%)]	Loss: -17.0897	Cost: 7.01s
Train Epoch: 1236 [61440/90000 (68%)]	Loss: -17.4182	Cost: 5.82s
Train Epoch: 1236 [81920/90000 (91%)]	Loss: -17.7770	Cost: 6.24s
Train Epoch: 1236 	Average Loss: -16.7615
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.3007

Learning rate: 6.377246332954532e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1237 [0/90000 (0%)]	Loss: -7.5652	Cost: 25.60s
Train Epoch: 1237 [20480/90000 (23%)]	Loss: -17.1170	Cost: 6.14s
Train Epoch: 1237 [40960/90000 (45%)]	Loss: -16.3368	Cost: 7.46s
Train Epoch: 1237 [61440/90000 (68%)]	Loss: -16.8989	Cost: 5.84s
Train Epoch: 1237 [81920/90000 (91%)]	Loss: -17.2736	Cost: 6.17s
Train Epoch: 1237 	Average Loss: -16.3474
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.0820

Learning rate: 6.362609869570039e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1238 [0/90000 (0%)]	Loss: -6.9888	Cost: 25.84s
Train Epoch: 1238 [20480/90000 (23%)]	Loss: -17.6520	Cost: 6.16s
Train Epoch: 1238 [40960/90000 (45%)]	Loss: -17.0837	Cost: 7.23s
Train Epoch: 1238 [61440/90000 (68%)]	Loss: -17.4120	Cost: 5.87s
Train Epoch: 1238 [81920/90000 (91%)]	Loss: -17.8153	Cost: 5.91s
Train Epoch: 1238 	Average Loss: -16.7018
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.2347

Learning rate: 6.347982381084111e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1239 [0/90000 (0%)]	Loss: -7.6181	Cost: 27.07s
Train Epoch: 1239 [20480/90000 (23%)]	Loss: -17.8468	Cost: 6.05s
Train Epoch: 1239 [40960/90000 (45%)]	Loss: -17.2589	Cost: 7.12s
Train Epoch: 1239 [61440/90000 (68%)]	Loss: -17.4953	Cost: 5.86s
Train Epoch: 1239 [81920/90000 (91%)]	Loss: -17.5964	Cost: 5.80s
Train Epoch: 1239 	Average Loss: -16.8139
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.3550

Learning rate: 6.333363903588622e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1240 [0/90000 (0%)]	Loss: -6.6937	Cost: 25.32s
Train Epoch: 1240 [20480/90000 (23%)]	Loss: -17.7009	Cost: 6.16s
Train Epoch: 1240 [40960/90000 (45%)]	Loss: -17.2462	Cost: 7.27s
Train Epoch: 1240 [61440/90000 (68%)]	Loss: -17.6023	Cost: 5.83s
Train Epoch: 1240 [81920/90000 (91%)]	Loss: -17.8449	Cost: 5.77s
Train Epoch: 1240 	Average Loss: -16.8805
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.2783

Learning rate: 6.318754473153209e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1241 [0/90000 (0%)]	Loss: -7.3324	Cost: 25.19s
Train Epoch: 1241 [20480/90000 (23%)]	Loss: -17.7456	Cost: 6.19s
Train Epoch: 1241 [40960/90000 (45%)]	Loss: -17.2406	Cost: 7.12s
Train Epoch: 1241 [61440/90000 (68%)]	Loss: -17.2530	Cost: 5.84s
Train Epoch: 1241 [81920/90000 (91%)]	Loss: -17.6570	Cost: 6.15s
Train Epoch: 1241 	Average Loss: -16.7409
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.2323

Learning rate: 6.304154125825193e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1242 [0/90000 (0%)]	Loss: -7.9251	Cost: 25.88s
Train Epoch: 1242 [20480/90000 (23%)]	Loss: -17.6914	Cost: 6.14s
Train Epoch: 1242 [40960/90000 (45%)]	Loss: -17.2329	Cost: 7.15s
Train Epoch: 1242 [61440/90000 (68%)]	Loss: -17.5195	Cost: 5.84s
Train Epoch: 1242 [81920/90000 (91%)]	Loss: -17.7730	Cost: 5.93s
Train Epoch: 1242 	Average Loss: -16.7557
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.1155

Learning rate: 6.289562897629477e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1243 [0/90000 (0%)]	Loss: -7.8687	Cost: 26.13s
Train Epoch: 1243 [20480/90000 (23%)]	Loss: -17.7402	Cost: 6.12s
Train Epoch: 1243 [40960/90000 (45%)]	Loss: -17.0982	Cost: 6.94s
Train Epoch: 1243 [61440/90000 (68%)]	Loss: -17.5949	Cost: 5.87s
Train Epoch: 1243 [81920/90000 (91%)]	Loss: -17.8350	Cost: 5.82s
Train Epoch: 1243 	Average Loss: -16.8742
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.4252

Learning rate: 6.27498082456847e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1244 [0/90000 (0%)]	Loss: -7.7841	Cost: 25.32s
Train Epoch: 1244 [20480/90000 (23%)]	Loss: -17.8481	Cost: 6.19s
Train Epoch: 1244 [40960/90000 (45%)]	Loss: -17.2719	Cost: 7.22s
Train Epoch: 1244 [61440/90000 (68%)]	Loss: -17.6957	Cost: 5.88s
Train Epoch: 1244 [81920/90000 (91%)]	Loss: -17.8429	Cost: 5.78s
Train Epoch: 1244 	Average Loss: -16.9224
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.2063

Learning rate: 6.260407942621985e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1245 [0/90000 (0%)]	Loss: -7.3748	Cost: 26.06s
Train Epoch: 1245 [20480/90000 (23%)]	Loss: -17.8941	Cost: 6.14s
Train Epoch: 1245 [40960/90000 (45%)]	Loss: -17.3454	Cost: 6.15s
Train Epoch: 1245 [61440/90000 (68%)]	Loss: -17.3931	Cost: 5.96s
Train Epoch: 1245 [81920/90000 (91%)]	Loss: -17.4232	Cost: 5.72s
Train Epoch: 1245 	Average Loss: -16.7656
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.0186

Learning rate: 6.245844287747158e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1246 [0/90000 (0%)]	Loss: -7.3061	Cost: 25.65s
Train Epoch: 1246 [20480/90000 (23%)]	Loss: -17.5823	Cost: 6.14s
Train Epoch: 1246 [40960/90000 (45%)]	Loss: -17.2032	Cost: 7.25s
Train Epoch: 1246 [61440/90000 (68%)]	Loss: -17.2424	Cost: 5.86s
Train Epoch: 1246 [81920/90000 (91%)]	Loss: -17.3416	Cost: 5.99s
Train Epoch: 1246 	Average Loss: -16.5751
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.0797

Learning rate: 6.23128989587836e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1247 [0/90000 (0%)]	Loss: -7.7445	Cost: 25.64s
Train Epoch: 1247 [20480/90000 (23%)]	Loss: -17.7909	Cost: 6.20s
Train Epoch: 1247 [40960/90000 (45%)]	Loss: -17.2544	Cost: 6.83s
Train Epoch: 1247 [61440/90000 (68%)]	Loss: -17.5255	Cost: 5.86s
Train Epoch: 1247 [81920/90000 (91%)]	Loss: -17.6040	Cost: 6.09s
Train Epoch: 1247 	Average Loss: -16.7915
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.1749

Learning rate: 6.216744802927112e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1248 [0/90000 (0%)]	Loss: -6.8863	Cost: 25.87s
Train Epoch: 1248 [20480/90000 (23%)]	Loss: -17.8675	Cost: 6.13s
Train Epoch: 1248 [40960/90000 (45%)]	Loss: -17.1818	Cost: 7.12s
Train Epoch: 1248 [61440/90000 (68%)]	Loss: -17.6321	Cost: 5.86s
Train Epoch: 1248 [81920/90000 (91%)]	Loss: -17.9395	Cost: 5.84s
Train Epoch: 1248 	Average Loss: -16.8670
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.4416

Learning rate: 6.202209044781979e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1249 [0/90000 (0%)]	Loss: -7.2906	Cost: 26.90s
Train Epoch: 1249 [20480/90000 (23%)]	Loss: -17.9631	Cost: 6.08s
Train Epoch: 1249 [40960/90000 (45%)]	Loss: -17.4198	Cost: 7.05s
Train Epoch: 1249 [61440/90000 (68%)]	Loss: -17.7158	Cost: 5.85s
Train Epoch: 1249 [81920/90000 (91%)]	Loss: -17.7625	Cost: 5.92s
Train Epoch: 1249 	Average Loss: -17.0085
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.3663

Learning rate: 6.187682657308499e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1250 [0/90000 (0%)]	Loss: -7.0417	Cost: 26.60s
Train Epoch: 1250 [20480/90000 (23%)]	Loss: -17.8468	Cost: 6.09s
Train Epoch: 1250 [40960/90000 (45%)]	Loss: -17.4561	Cost: 7.11s
Train Epoch: 1250 [61440/90000 (68%)]	Loss: -17.7762	Cost: 5.84s
Train Epoch: 1250 [81920/90000 (91%)]	Loss: -17.9861	Cost: 5.82s
Train Epoch: 1250 	Average Loss: -16.9262
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.2810

Saving model as model_sample_from_all_posterior.pt_e1250 & waveforms_supplementary_sample_from_all_posterior.hdf5_e1250
Learning rate: 6.173165676349092e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1251 [0/90000 (0%)]	Loss: -7.0003	Cost: 25.82s
Train Epoch: 1251 [20480/90000 (23%)]	Loss: -17.9204	Cost: 6.15s
Train Epoch: 1251 [40960/90000 (45%)]	Loss: -17.4652	Cost: 7.07s
Train Epoch: 1251 [61440/90000 (68%)]	Loss: -17.6825	Cost: 5.86s
Train Epoch: 1251 [81920/90000 (91%)]	Loss: -18.0055	Cost: 5.83s
Train Epoch: 1251 	Average Loss: -17.0319
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.4461

Learning rate: 6.158658137722965e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1252 [0/90000 (0%)]	Loss: -6.8045	Cost: 25.77s
Train Epoch: 1252 [20480/90000 (23%)]	Loss: -17.9521	Cost: 6.14s
Train Epoch: 1252 [40960/90000 (45%)]	Loss: -17.5210	Cost: 7.27s
Train Epoch: 1252 [61440/90000 (68%)]	Loss: -17.7585	Cost: 5.90s
Train Epoch: 1252 [81920/90000 (91%)]	Loss: -17.8245	Cost: 5.71s
Train Epoch: 1252 	Average Loss: -17.0676
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.5699

Learning rate: 6.144160077226024e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1253 [0/90000 (0%)]	Loss: -6.8657	Cost: 25.26s
Train Epoch: 1253 [20480/90000 (23%)]	Loss: -18.0519	Cost: 6.18s
Train Epoch: 1253 [40960/90000 (45%)]	Loss: -17.5907	Cost: 6.98s
Train Epoch: 1253 [61440/90000 (68%)]	Loss: -17.7755	Cost: 5.91s
Train Epoch: 1253 [81920/90000 (91%)]	Loss: -18.0465	Cost: 6.07s
Train Epoch: 1253 	Average Loss: -17.0559
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.3285

Learning rate: 6.129671530630794e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1254 [0/90000 (0%)]	Loss: -7.1625	Cost: 25.99s
Train Epoch: 1254 [20480/90000 (23%)]	Loss: -17.8318	Cost: 6.13s
Train Epoch: 1254 [40960/90000 (45%)]	Loss: -17.5088	Cost: 7.20s
Train Epoch: 1254 [61440/90000 (68%)]	Loss: -17.7070	Cost: 5.85s
Train Epoch: 1254 [81920/90000 (91%)]	Loss: -17.9772	Cost: 5.83s
Train Epoch: 1254 	Average Loss: -17.0161
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.2278

Learning rate: 6.115192533686328e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1255 [0/90000 (0%)]	Loss: -6.1047	Cost: 26.05s
Train Epoch: 1255 [20480/90000 (23%)]	Loss: -18.1172	Cost: 6.18s
Train Epoch: 1255 [40960/90000 (45%)]	Loss: -17.4985	Cost: 7.11s
Train Epoch: 1255 [61440/90000 (68%)]	Loss: -17.7135	Cost: 5.84s
Train Epoch: 1255 [81920/90000 (91%)]	Loss: -17.9693	Cost: 5.93s
Train Epoch: 1255 	Average Loss: -17.0209
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.5035

Learning rate: 6.100723122118107e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1256 [0/90000 (0%)]	Loss: -7.6880	Cost: 25.85s
Train Epoch: 1256 [20480/90000 (23%)]	Loss: -18.1778	Cost: 6.11s
Train Epoch: 1256 [40960/90000 (45%)]	Loss: -17.5565	Cost: 6.55s
Train Epoch: 1256 [61440/90000 (68%)]	Loss: -17.7391	Cost: 5.93s
Train Epoch: 1256 [81920/90000 (91%)]	Loss: -17.9520	Cost: 5.85s
Train Epoch: 1256 	Average Loss: -17.1130
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.4791

Learning rate: 6.0862633316279656e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1257 [0/90000 (0%)]	Loss: -7.4510	Cost: 25.59s
Train Epoch: 1257 [20480/90000 (23%)]	Loss: -18.1712	Cost: 6.19s
Train Epoch: 1257 [40960/90000 (45%)]	Loss: -17.3991	Cost: 7.17s
Train Epoch: 1257 [61440/90000 (68%)]	Loss: -17.8061	Cost: 5.84s
Train Epoch: 1257 [81920/90000 (91%)]	Loss: -17.9368	Cost: 6.15s
Train Epoch: 1257 	Average Loss: -17.0880
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.2169

Learning rate: 6.071813197893999e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1258 [0/90000 (0%)]	Loss: -6.9680	Cost: 25.56s
Train Epoch: 1258 [20480/90000 (23%)]	Loss: -18.0050	Cost: 6.13s
Train Epoch: 1258 [40960/90000 (45%)]	Loss: -17.4831	Cost: 6.78s
Train Epoch: 1258 [61440/90000 (68%)]	Loss: -17.8286	Cost: 6.11s
Train Epoch: 1258 [81920/90000 (91%)]	Loss: -17.9713	Cost: 5.86s
Train Epoch: 1258 	Average Loss: -17.0596
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.6474

Learning rate: 6.0573727565704763e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1259 [0/90000 (0%)]	Loss: -6.8806	Cost: 25.60s
Train Epoch: 1259 [20480/90000 (23%)]	Loss: -18.2213	Cost: 6.17s
Train Epoch: 1259 [40960/90000 (45%)]	Loss: -17.6200	Cost: 7.16s
Train Epoch: 1259 [61440/90000 (68%)]	Loss: -18.0277	Cost: 5.87s
Train Epoch: 1259 [81920/90000 (91%)]	Loss: -18.2465	Cost: 5.79s
Train Epoch: 1259 	Average Loss: -17.2144
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.6812

Learning rate: 6.042942043287756e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1260 [0/90000 (0%)]	Loss: -6.9790	Cost: 26.43s
Train Epoch: 1260 [20480/90000 (23%)]	Loss: -18.0108	Cost: 6.09s
Train Epoch: 1260 [40960/90000 (45%)]	Loss: -17.6528	Cost: 7.16s
Train Epoch: 1260 [61440/90000 (68%)]	Loss: -17.9692	Cost: 5.83s
Train Epoch: 1260 [81920/90000 (91%)]	Loss: -18.0241	Cost: 5.79s
Train Epoch: 1260 	Average Loss: -17.2021
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.4761

Learning rate: 6.02852109365218e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1261 [0/90000 (0%)]	Loss: -8.0300	Cost: 26.17s
Train Epoch: 1261 [20480/90000 (23%)]	Loss: -18.0333	Cost: 6.21s
Train Epoch: 1261 [40960/90000 (45%)]	Loss: -17.5998	Cost: 6.97s
Train Epoch: 1261 [61440/90000 (68%)]	Loss: -17.9376	Cost: 5.88s
Train Epoch: 1261 [81920/90000 (91%)]	Loss: -17.9977	Cost: 5.89s
Train Epoch: 1261 	Average Loss: -17.1817
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.5520

Learning rate: 6.014109943246016e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1262 [0/90000 (0%)]	Loss: -7.0235	Cost: 26.87s
Train Epoch: 1262 [20480/90000 (23%)]	Loss: -18.2020	Cost: 6.12s
Train Epoch: 1262 [40960/90000 (45%)]	Loss: -17.6419	Cost: 6.77s
Train Epoch: 1262 [61440/90000 (68%)]	Loss: -18.0834	Cost: 5.88s
Train Epoch: 1262 [81920/90000 (91%)]	Loss: -18.1736	Cost: 6.16s
Train Epoch: 1262 	Average Loss: -17.2315
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.5086

Learning rate: 5.999708627627341e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1263 [0/90000 (0%)]	Loss: -7.0701	Cost: 26.81s
Train Epoch: 1263 [20480/90000 (23%)]	Loss: -18.1919	Cost: 6.10s
Train Epoch: 1263 [40960/90000 (45%)]	Loss: -17.4927	Cost: 6.89s
Train Epoch: 1263 [61440/90000 (68%)]	Loss: -17.9385	Cost: 5.86s
Train Epoch: 1263 [81920/90000 (91%)]	Loss: -18.0543	Cost: 5.80s
Train Epoch: 1263 	Average Loss: -17.1468
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.2762

Learning rate: 5.9853171823299706e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1264 [0/90000 (0%)]	Loss: -6.6274	Cost: 26.30s
Train Epoch: 1264 [20480/90000 (23%)]	Loss: -18.0398	Cost: 6.17s
Train Epoch: 1264 [40960/90000 (45%)]	Loss: -17.4096	Cost: 7.23s
Train Epoch: 1264 [61440/90000 (68%)]	Loss: -17.8446	Cost: 5.87s
Train Epoch: 1264 [81920/90000 (91%)]	Loss: -18.0745	Cost: 5.71s
Train Epoch: 1264 	Average Loss: -17.1287
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.5348

Learning rate: 5.9709356428633604e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1265 [0/90000 (0%)]	Loss: -8.1640	Cost: 27.14s
Train Epoch: 1265 [20480/90000 (23%)]	Loss: -18.2054	Cost: 6.08s
Train Epoch: 1265 [40960/90000 (45%)]	Loss: -17.5485	Cost: 7.02s
Train Epoch: 1265 [61440/90000 (68%)]	Loss: -18.0018	Cost: 5.87s
Train Epoch: 1265 [81920/90000 (91%)]	Loss: -18.0290	Cost: 5.71s
Train Epoch: 1265 	Average Loss: -17.2360
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.6069

Learning rate: 5.956564044712537e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1266 [0/90000 (0%)]	Loss: -7.8397	Cost: 25.25s
Train Epoch: 1266 [20480/90000 (23%)]	Loss: -18.3629	Cost: 6.14s
Train Epoch: 1266 [40960/90000 (45%)]	Loss: -17.5750	Cost: 7.05s
Train Epoch: 1266 [61440/90000 (68%)]	Loss: -17.7300	Cost: 6.05s
Train Epoch: 1266 [81920/90000 (91%)]	Loss: -18.0093	Cost: 5.75s
Train Epoch: 1266 	Average Loss: -17.2266
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.3977

Learning rate: 5.942202423337988e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1267 [0/90000 (0%)]	Loss: -7.1741	Cost: 25.22s
Train Epoch: 1267 [20480/90000 (23%)]	Loss: -18.1299	Cost: 6.17s
Train Epoch: 1267 [40960/90000 (45%)]	Loss: -17.6473	Cost: 7.02s
Train Epoch: 1267 [61440/90000 (68%)]	Loss: -18.0560	Cost: 5.88s
Train Epoch: 1267 [81920/90000 (91%)]	Loss: -18.2863	Cost: 5.90s
Train Epoch: 1267 	Average Loss: -17.2665
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.5604

Learning rate: 5.927850814175586e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1268 [0/90000 (0%)]	Loss: -7.2258	Cost: 25.42s
Train Epoch: 1268 [20480/90000 (23%)]	Loss: -18.4058	Cost: 6.15s
Train Epoch: 1268 [40960/90000 (45%)]	Loss: -17.7868	Cost: 7.01s
Train Epoch: 1268 [61440/90000 (68%)]	Loss: -18.0812	Cost: 5.89s
Train Epoch: 1268 [81920/90000 (91%)]	Loss: -18.2973	Cost: 5.90s
Train Epoch: 1268 	Average Loss: -17.3763
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.3532

Learning rate: 5.9135092526364976e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1269 [0/90000 (0%)]	Loss: -6.8451	Cost: 25.76s
Train Epoch: 1269 [20480/90000 (23%)]	Loss: -18.4480	Cost: 6.17s
Train Epoch: 1269 [40960/90000 (45%)]	Loss: -17.7913	Cost: 7.24s
Train Epoch: 1269 [61440/90000 (68%)]	Loss: -18.0291	Cost: 5.81s
Train Epoch: 1269 [81920/90000 (91%)]	Loss: -18.1141	Cost: 5.74s
Train Epoch: 1269 	Average Loss: -17.3010
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.5248

Learning rate: 5.899177774107103e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1270 [0/90000 (0%)]	Loss: -7.6489	Cost: 25.50s
Train Epoch: 1270 [20480/90000 (23%)]	Loss: -18.2255	Cost: 6.17s
Train Epoch: 1270 [40960/90000 (45%)]	Loss: -17.6816	Cost: 7.09s
Train Epoch: 1270 [61440/90000 (68%)]	Loss: -17.8689	Cost: 5.89s
Train Epoch: 1270 [81920/90000 (91%)]	Loss: -17.8685	Cost: 5.87s
Train Epoch: 1270 	Average Loss: -17.1903
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.2637

Learning rate: 5.8848564139489e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1271 [0/90000 (0%)]	Loss: -7.3830	Cost: 25.27s
Train Epoch: 1271 [20480/90000 (23%)]	Loss: -18.1004	Cost: 6.17s
Train Epoch: 1271 [40960/90000 (45%)]	Loss: -17.6295	Cost: 7.24s
Train Epoch: 1271 [61440/90000 (68%)]	Loss: -18.1043	Cost: 5.84s
Train Epoch: 1271 [81920/90000 (91%)]	Loss: -18.2718	Cost: 5.79s
Train Epoch: 1271 	Average Loss: -17.2261
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.5255

Learning rate: 5.87054520749842e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1272 [0/90000 (0%)]	Loss: -7.5869	Cost: 25.61s
Train Epoch: 1272 [20480/90000 (23%)]	Loss: -18.3780	Cost: 6.14s
Train Epoch: 1272 [40960/90000 (45%)]	Loss: -17.8431	Cost: 7.13s
Train Epoch: 1272 [61440/90000 (68%)]	Loss: -18.1501	Cost: 5.85s
Train Epoch: 1272 [81920/90000 (91%)]	Loss: -18.2164	Cost: 5.85s
Train Epoch: 1272 	Average Loss: -17.3985
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7619

Learning rate: 5.856244190067147e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1273 [0/90000 (0%)]	Loss: -7.0551	Cost: 25.81s
Train Epoch: 1273 [20480/90000 (23%)]	Loss: -18.3938	Cost: 6.13s
Train Epoch: 1273 [40960/90000 (45%)]	Loss: -17.8947	Cost: 7.33s
Train Epoch: 1273 [61440/90000 (68%)]	Loss: -18.2579	Cost: 5.82s
Train Epoch: 1273 [81920/90000 (91%)]	Loss: -18.4365	Cost: 5.71s
Train Epoch: 1273 	Average Loss: -17.4318
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.6816

Learning rate: 5.841953396941414e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1274 [0/90000 (0%)]	Loss: -7.5595	Cost: 26.81s
Train Epoch: 1274 [20480/90000 (23%)]	Loss: -18.3152	Cost: 6.09s
Train Epoch: 1274 [40960/90000 (45%)]	Loss: -17.6623	Cost: 6.63s
Train Epoch: 1274 [61440/90000 (68%)]	Loss: -18.2404	Cost: 5.89s
Train Epoch: 1274 [81920/90000 (91%)]	Loss: -18.3691	Cost: 5.86s
Train Epoch: 1274 	Average Loss: -17.4242
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7004

Learning rate: 5.827672863382338e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1275 [0/90000 (0%)]	Loss: -7.5775	Cost: 25.45s
Train Epoch: 1275 [20480/90000 (23%)]	Loss: -18.4751	Cost: 6.14s
Train Epoch: 1275 [40960/90000 (45%)]	Loss: -18.0203	Cost: 7.38s
Train Epoch: 1275 [61440/90000 (68%)]	Loss: -18.3446	Cost: 5.85s
Train Epoch: 1275 [81920/90000 (91%)]	Loss: -18.2725	Cost: 5.79s
Train Epoch: 1275 	Average Loss: -17.4929
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7598

Learning rate: 5.8134026246257056e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1276 [0/90000 (0%)]	Loss: -6.9127	Cost: 25.71s
Train Epoch: 1276 [20480/90000 (23%)]	Loss: -18.4118	Cost: 6.13s
Train Epoch: 1276 [40960/90000 (45%)]	Loss: -17.8542	Cost: 7.37s
Train Epoch: 1276 [61440/90000 (68%)]	Loss: -18.2456	Cost: 5.83s
Train Epoch: 1276 [81920/90000 (91%)]	Loss: -18.3615	Cost: 5.92s
Train Epoch: 1276 	Average Loss: -17.3994
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.6968

Learning rate: 5.7991427158819256e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1277 [0/90000 (0%)]	Loss: -7.6074	Cost: 25.62s
Train Epoch: 1277 [20480/90000 (23%)]	Loss: -18.5201	Cost: 6.17s
Train Epoch: 1277 [40960/90000 (45%)]	Loss: -17.8346	Cost: 6.81s
Train Epoch: 1277 [61440/90000 (68%)]	Loss: -18.2874	Cost: 5.88s
Train Epoch: 1277 [81920/90000 (91%)]	Loss: -18.4300	Cost: 5.70s
Train Epoch: 1277 	Average Loss: -17.5011
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.6901

Learning rate: 5.784893172335898e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1278 [0/90000 (0%)]	Loss: -6.9221	Cost: 25.99s
Train Epoch: 1278 [20480/90000 (23%)]	Loss: -18.3838	Cost: 6.14s
Train Epoch: 1278 [40960/90000 (45%)]	Loss: -17.9174	Cost: 6.82s
Train Epoch: 1278 [61440/90000 (68%)]	Loss: -18.2225	Cost: 5.86s
Train Epoch: 1278 [81920/90000 (91%)]	Loss: -18.2892	Cost: 5.87s
Train Epoch: 1278 	Average Loss: -17.4171
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7746

Learning rate: 5.770654029146957e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1279 [0/90000 (0%)]	Loss: -7.0289	Cost: 26.71s
Train Epoch: 1279 [20480/90000 (23%)]	Loss: -18.5972	Cost: 6.04s
Train Epoch: 1279 [40960/90000 (45%)]	Loss: -18.0493	Cost: 6.95s
Train Epoch: 1279 [61440/90000 (68%)]	Loss: -18.3303	Cost: 5.88s
Train Epoch: 1279 [81920/90000 (91%)]	Loss: -18.3150	Cost: 5.73s
Train Epoch: 1279 	Average Loss: -17.4953
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.6542

Learning rate: 5.7564253214487674e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1280 [0/90000 (0%)]	Loss: -6.4709	Cost: 25.58s
Train Epoch: 1280 [20480/90000 (23%)]	Loss: -18.4051	Cost: 6.16s
Train Epoch: 1280 [40960/90000 (45%)]	Loss: -17.5713	Cost: 6.80s
Train Epoch: 1280 [61440/90000 (68%)]	Loss: -17.7996	Cost: 5.94s
Train Epoch: 1280 [81920/90000 (91%)]	Loss: -18.1098	Cost: 5.70s
Train Epoch: 1280 	Average Loss: -17.2430
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7371

Learning rate: 5.742207084349262e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1281 [0/90000 (0%)]	Loss: -7.7131	Cost: 24.79s
Train Epoch: 1281 [20480/90000 (23%)]	Loss: -18.3167	Cost: 6.20s
Train Epoch: 1281 [40960/90000 (45%)]	Loss: -17.8304	Cost: 7.39s
Train Epoch: 1281 [61440/90000 (68%)]	Loss: -18.2860	Cost: 5.90s
Train Epoch: 1281 [81920/90000 (91%)]	Loss: -18.3905	Cost: 5.81s
Train Epoch: 1281 	Average Loss: -17.4244
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7534

Learning rate: 5.727999352930519e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1282 [0/90000 (0%)]	Loss: -7.5293	Cost: 25.91s
Train Epoch: 1282 [20480/90000 (23%)]	Loss: -18.5062	Cost: 6.12s
Train Epoch: 1282 [40960/90000 (45%)]	Loss: -18.0200	Cost: 7.22s
Train Epoch: 1282 [61440/90000 (68%)]	Loss: -18.4529	Cost: 5.83s
Train Epoch: 1282 [81920/90000 (91%)]	Loss: -18.4128	Cost: 5.75s
Train Epoch: 1282 	Average Loss: -17.5807
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7675

Learning rate: 5.7138021622487066e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1283 [0/90000 (0%)]	Loss: -6.9643	Cost: 26.75s
Train Epoch: 1283 [20480/90000 (23%)]	Loss: -18.4747	Cost: 6.11s
Train Epoch: 1283 [40960/90000 (45%)]	Loss: -17.7597	Cost: 7.17s
Train Epoch: 1283 [61440/90000 (68%)]	Loss: -18.3095	Cost: 5.92s
Train Epoch: 1283 [81920/90000 (91%)]	Loss: -18.5441	Cost: 5.87s
Train Epoch: 1283 	Average Loss: -17.5025
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7632

Learning rate: 5.6996155473339804e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1284 [0/90000 (0%)]	Loss: -7.4177	Cost: 25.99s
Train Epoch: 1284 [20480/90000 (23%)]	Loss: -18.3894	Cost: 6.16s
Train Epoch: 1284 [40960/90000 (45%)]	Loss: -17.6799	Cost: 7.22s
Train Epoch: 1284 [61440/90000 (68%)]	Loss: -18.1705	Cost: 5.86s
Train Epoch: 1284 [81920/90000 (91%)]	Loss: -18.3831	Cost: 5.72s
Train Epoch: 1284 	Average Loss: -17.4389
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.6602

Learning rate: 5.6854395431904026e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1285 [0/90000 (0%)]	Loss: -7.1459	Cost: 25.50s
Train Epoch: 1285 [20480/90000 (23%)]	Loss: -18.2383	Cost: 6.21s
Train Epoch: 1285 [40960/90000 (45%)]	Loss: -17.7782	Cost: 7.02s
Train Epoch: 1285 [61440/90000 (68%)]	Loss: -18.2550	Cost: 5.88s
Train Epoch: 1285 [81920/90000 (91%)]	Loss: -18.4297	Cost: 5.92s
Train Epoch: 1285 	Average Loss: -17.4027
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7735

Learning rate: 5.671274184795849e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1286 [0/90000 (0%)]	Loss: -6.7892	Cost: 26.00s
Train Epoch: 1286 [20480/90000 (23%)]	Loss: -18.4712	Cost: 6.14s
Train Epoch: 1286 [40960/90000 (45%)]	Loss: -17.9702	Cost: 6.78s
Train Epoch: 1286 [61440/90000 (68%)]	Loss: -18.2138	Cost: 5.94s
Train Epoch: 1286 [81920/90000 (91%)]	Loss: -18.5904	Cost: 5.73s
Train Epoch: 1286 	Average Loss: -17.4877
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.9752

Learning rate: 5.6571195071019434e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1287 [0/90000 (0%)]	Loss: -7.2985	Cost: 24.98s
Train Epoch: 1287 [20480/90000 (23%)]	Loss: -18.5494	Cost: 6.24s
Train Epoch: 1287 [40960/90000 (45%)]	Loss: -17.7817	Cost: 7.22s
Train Epoch: 1287 [61440/90000 (68%)]	Loss: -18.2879	Cost: 5.87s
Train Epoch: 1287 [81920/90000 (91%)]	Loss: -18.5090	Cost: 5.99s
Train Epoch: 1287 	Average Loss: -17.5268
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.6563

Learning rate: 5.642975545033942e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1288 [0/90000 (0%)]	Loss: -7.4936	Cost: 26.18s
Train Epoch: 1288 [20480/90000 (23%)]	Loss: -18.3357	Cost: 6.12s
Train Epoch: 1288 [40960/90000 (45%)]	Loss: -17.7477	Cost: 6.63s
Train Epoch: 1288 [61440/90000 (68%)]	Loss: -18.1836	Cost: 5.88s
Train Epoch: 1288 [81920/90000 (91%)]	Loss: -18.4510	Cost: 5.89s
Train Epoch: 1288 	Average Loss: -17.4039
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.6427

Learning rate: 5.628842333490663e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1289 [0/90000 (0%)]	Loss: -7.8892	Cost: 25.84s
Train Epoch: 1289 [20480/90000 (23%)]	Loss: -18.5371	Cost: 6.13s
Train Epoch: 1289 [40960/90000 (45%)]	Loss: -17.9840	Cost: 7.13s
Train Epoch: 1289 [61440/90000 (68%)]	Loss: -18.4005	Cost: 5.84s
Train Epoch: 1289 [81920/90000 (91%)]	Loss: -18.7547	Cost: 5.95s
Train Epoch: 1289 	Average Loss: -17.6085
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.8087

Learning rate: 5.614719907344402e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1290 [0/90000 (0%)]	Loss: -7.7966	Cost: 25.18s
Train Epoch: 1290 [20480/90000 (23%)]	Loss: -18.7778	Cost: 6.18s
Train Epoch: 1290 [40960/90000 (45%)]	Loss: -18.1390	Cost: 7.24s
Train Epoch: 1290 [61440/90000 (68%)]	Loss: -18.2949	Cost: 5.86s
Train Epoch: 1290 [81920/90000 (91%)]	Loss: -18.4956	Cost: 6.01s
Train Epoch: 1290 	Average Loss: -17.6638
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.5962

Learning rate: 5.600608301440838e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1291 [0/90000 (0%)]	Loss: -6.6628	Cost: 25.87s
Train Epoch: 1291 [20480/90000 (23%)]	Loss: -18.5642	Cost: 6.12s
Train Epoch: 1291 [40960/90000 (45%)]	Loss: -18.1243	Cost: 7.14s
Train Epoch: 1291 [61440/90000 (68%)]	Loss: -18.4759	Cost: 5.84s
Train Epoch: 1291 [81920/90000 (91%)]	Loss: -18.5965	Cost: 5.91s
Train Epoch: 1291 	Average Loss: -17.6519
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7770

Learning rate: 5.586507550598964e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1292 [0/90000 (0%)]	Loss: -7.8371	Cost: 26.10s
Train Epoch: 1292 [20480/90000 (23%)]	Loss: -18.7098	Cost: 6.11s
Train Epoch: 1292 [40960/90000 (45%)]	Loss: -18.1176	Cost: 7.21s
Train Epoch: 1292 [61440/90000 (68%)]	Loss: -18.4895	Cost: 5.83s
Train Epoch: 1292 [81920/90000 (91%)]	Loss: -18.5524	Cost: 5.79s
Train Epoch: 1292 	Average Loss: -17.6991
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.8037

Learning rate: 5.572417689610977e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1293 [0/90000 (0%)]	Loss: -6.3083	Cost: 25.57s
Train Epoch: 1293 [20480/90000 (23%)]	Loss: -18.5208	Cost: 6.15s
Train Epoch: 1293 [40960/90000 (45%)]	Loss: -18.0038	Cost: 6.93s
Train Epoch: 1293 [61440/90000 (68%)]	Loss: -18.4137	Cost: 5.86s
Train Epoch: 1293 [81920/90000 (91%)]	Loss: -18.4973	Cost: 6.09s
Train Epoch: 1293 	Average Loss: -17.5400
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7937

Learning rate: 5.5583387532422025e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1294 [0/90000 (0%)]	Loss: -7.6232	Cost: 25.34s
Train Epoch: 1294 [20480/90000 (23%)]	Loss: -18.4211	Cost: 6.16s
Train Epoch: 1294 [40960/90000 (45%)]	Loss: -17.7624	Cost: 6.97s
Train Epoch: 1294 [61440/90000 (68%)]	Loss: -18.4578	Cost: 5.89s
Train Epoch: 1294 [81920/90000 (91%)]	Loss: -18.5921	Cost: 6.10s
Train Epoch: 1294 	Average Loss: -17.5546
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.8188

Learning rate: 5.5442707762310275e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1295 [0/90000 (0%)]	Loss: -7.6621	Cost: 25.61s
Train Epoch: 1295 [20480/90000 (23%)]	Loss: -18.6070	Cost: 6.09s
Train Epoch: 1295 [40960/90000 (45%)]	Loss: -17.9521	Cost: 7.26s
Train Epoch: 1295 [61440/90000 (68%)]	Loss: -18.6101	Cost: 5.81s
Train Epoch: 1295 [81920/90000 (91%)]	Loss: -18.7419	Cost: 6.05s
Train Epoch: 1295 	Average Loss: -17.7293
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.8783

Learning rate: 5.5302137932887795e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1296 [0/90000 (0%)]	Loss: -7.2606	Cost: 25.26s
Train Epoch: 1296 [20480/90000 (23%)]	Loss: -18.8012	Cost: 6.18s
Train Epoch: 1296 [40960/90000 (45%)]	Loss: -18.1116	Cost: 6.99s
Train Epoch: 1296 [61440/90000 (68%)]	Loss: -18.4709	Cost: 5.87s
Train Epoch: 1296 [81920/90000 (91%)]	Loss: -18.7466	Cost: 5.94s
Train Epoch: 1296 	Average Loss: -17.7249
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.8535

Learning rate: 5.5161678390996694e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1297 [0/90000 (0%)]	Loss: -7.3912	Cost: 25.51s
Train Epoch: 1297 [20480/90000 (23%)]	Loss: -18.8639	Cost: 6.21s
Train Epoch: 1297 [40960/90000 (45%)]	Loss: -18.0903	Cost: 6.90s
Train Epoch: 1297 [61440/90000 (68%)]	Loss: -18.5227	Cost: 5.87s
Train Epoch: 1297 [81920/90000 (91%)]	Loss: -18.5207	Cost: 6.08s
Train Epoch: 1297 	Average Loss: -17.7252
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.8553

Learning rate: 5.502132948320687e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1298 [0/90000 (0%)]	Loss: -7.7153	Cost: 25.52s
Train Epoch: 1298 [20480/90000 (23%)]	Loss: -18.8164	Cost: 6.15s
Train Epoch: 1298 [40960/90000 (45%)]	Loss: -18.1400	Cost: 7.17s
Train Epoch: 1298 [61440/90000 (68%)]	Loss: -18.5490	Cost: 6.32s
Train Epoch: 1298 [81920/90000 (91%)]	Loss: -18.6679	Cost: 5.75s
Train Epoch: 1298 	Average Loss: -17.7339
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.0741

Learning rate: 5.488109155581539e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1299 [0/90000 (0%)]	Loss: -7.5791	Cost: 25.16s
Train Epoch: 1299 [20480/90000 (23%)]	Loss: -18.8014	Cost: 6.22s
Train Epoch: 1299 [40960/90000 (45%)]	Loss: -18.1203	Cost: 6.79s
Train Epoch: 1299 [61440/90000 (68%)]	Loss: -18.6194	Cost: 5.89s
Train Epoch: 1299 [81920/90000 (91%)]	Loss: -18.7868	Cost: 6.14s
Train Epoch: 1299 	Average Loss: -17.7956
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.9156

Learning rate: 5.4740964954845366e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1300 [0/90000 (0%)]	Loss: -7.3108	Cost: 26.41s
Train Epoch: 1300 [20480/90000 (23%)]	Loss: -18.8414	Cost: 6.10s
Train Epoch: 1300 [40960/90000 (45%)]	Loss: -18.1128	Cost: 7.36s
Train Epoch: 1300 [61440/90000 (68%)]	Loss: -18.5473	Cost: 5.88s
Train Epoch: 1300 [81920/90000 (91%)]	Loss: -18.5968	Cost: 6.05s
Train Epoch: 1300 	Average Loss: -17.7454
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.5450

Saving model as model_sample_from_all_posterior.pt_e1300 & waveforms_supplementary_sample_from_all_posterior.hdf5_e1300
Learning rate: 5.460095002604523e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1301 [0/90000 (0%)]	Loss: -8.1829	Cost: 25.43s
Train Epoch: 1301 [20480/90000 (23%)]	Loss: -18.8474	Cost: 6.20s
Train Epoch: 1301 [40960/90000 (45%)]	Loss: -18.0881	Cost: 7.16s
Train Epoch: 1301 [61440/90000 (68%)]	Loss: -18.6704	Cost: 5.89s
Train Epoch: 1301 [81920/90000 (91%)]	Loss: -18.8322	Cost: 5.85s
Train Epoch: 1301 	Average Loss: -17.8168
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7831

Learning rate: 5.446104711488794e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1302 [0/90000 (0%)]	Loss: -7.6085	Cost: 25.84s
Train Epoch: 1302 [20480/90000 (23%)]	Loss: -18.6945	Cost: 6.12s
Train Epoch: 1302 [40960/90000 (45%)]	Loss: -18.3561	Cost: 7.35s
Train Epoch: 1302 [61440/90000 (68%)]	Loss: -18.4750	Cost: 5.85s
Train Epoch: 1302 [81920/90000 (91%)]	Loss: -18.8313	Cost: 6.08s
Train Epoch: 1302 	Average Loss: -17.7963
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.9148

Learning rate: 5.432125656656998e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1303 [0/90000 (0%)]	Loss: -7.7439	Cost: 25.93s
Train Epoch: 1303 [20480/90000 (23%)]	Loss: -18.8202	Cost: 6.14s
Train Epoch: 1303 [40960/90000 (45%)]	Loss: -18.2492	Cost: 7.19s
Train Epoch: 1303 [61440/90000 (68%)]	Loss: -18.5583	Cost: 5.84s
Train Epoch: 1303 [81920/90000 (91%)]	Loss: -18.7640	Cost: 5.99s
Train Epoch: 1303 	Average Loss: -17.8428
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.6971

Learning rate: 5.4181578726010624e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1304 [0/90000 (0%)]	Loss: -7.1074	Cost: 25.71s
Train Epoch: 1304 [20480/90000 (23%)]	Loss: -18.8510	Cost: 6.14s
Train Epoch: 1304 [40960/90000 (45%)]	Loss: -16.8215	Cost: 6.91s
Train Epoch: 1304 [61440/90000 (68%)]	Loss: -17.6544	Cost: 5.84s
Train Epoch: 1304 [81920/90000 (91%)]	Loss: -18.0936	Cost: 6.00s
Train Epoch: 1304 	Average Loss: -17.1409
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.5394

Learning rate: 5.4042013937851126e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1305 [0/90000 (0%)]	Loss: -7.5770	Cost: 27.16s
Train Epoch: 1305 [20480/90000 (23%)]	Loss: -18.2946	Cost: 6.07s
Train Epoch: 1305 [40960/90000 (45%)]	Loss: -17.5945	Cost: 7.21s
Train Epoch: 1305 [61440/90000 (68%)]	Loss: -18.1250	Cost: 5.82s
Train Epoch: 1305 [81920/90000 (91%)]	Loss: -18.4611	Cost: 5.92s
Train Epoch: 1305 	Average Loss: -17.3236
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.8706

Learning rate: 5.390256254645369e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1306 [0/90000 (0%)]	Loss: -7.9462	Cost: 26.81s
Train Epoch: 1306 [20480/90000 (23%)]	Loss: -18.6640	Cost: 6.14s
Train Epoch: 1306 [40960/90000 (45%)]	Loss: -18.0905	Cost: 6.84s
Train Epoch: 1306 [61440/90000 (68%)]	Loss: -18.7152	Cost: 5.87s
Train Epoch: 1306 [81920/90000 (91%)]	Loss: -18.8022	Cost: 5.73s
Train Epoch: 1306 	Average Loss: -17.7037
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7355

Learning rate: 5.37632248959007e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1307 [0/90000 (0%)]	Loss: -7.8268	Cost: 26.74s
Train Epoch: 1307 [20480/90000 (23%)]	Loss: -19.0120	Cost: 6.06s
Train Epoch: 1307 [40960/90000 (45%)]	Loss: -18.3051	Cost: 7.19s
Train Epoch: 1307 [61440/90000 (68%)]	Loss: -18.5699	Cost: 5.83s
Train Epoch: 1307 [81920/90000 (91%)]	Loss: -18.8668	Cost: 5.85s
Train Epoch: 1307 	Average Loss: -17.8536
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7153

Learning rate: 5.362400132999412e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1308 [0/90000 (0%)]	Loss: -8.2125	Cost: 26.78s
Train Epoch: 1308 [20480/90000 (23%)]	Loss: -18.8349	Cost: 6.06s
Train Epoch: 1308 [40960/90000 (45%)]	Loss: -18.4195	Cost: 7.08s
Train Epoch: 1308 [61440/90000 (68%)]	Loss: -18.5317	Cost: 5.86s
Train Epoch: 1308 [81920/90000 (91%)]	Loss: -18.8370	Cost: 6.07s
Train Epoch: 1308 	Average Loss: -17.9013
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.0509

Learning rate: 5.3484892192254075e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1309 [0/90000 (0%)]	Loss: -9.0715	Cost: 26.40s
Train Epoch: 1309 [20480/90000 (23%)]	Loss: -18.7608	Cost: 6.14s
Train Epoch: 1309 [40960/90000 (45%)]	Loss: -18.3410	Cost: 7.15s
Train Epoch: 1309 [61440/90000 (68%)]	Loss: -18.5380	Cost: 5.88s
Train Epoch: 1309 [81920/90000 (91%)]	Loss: -19.0060	Cost: 6.16s
Train Epoch: 1309 	Average Loss: -17.8976
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.9441

Learning rate: 5.334589782591865e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1310 [0/90000 (0%)]	Loss: -7.6646	Cost: 25.51s
Train Epoch: 1310 [20480/90000 (23%)]	Loss: -18.8211	Cost: 6.19s
Train Epoch: 1310 [40960/90000 (45%)]	Loss: -18.0127	Cost: 7.28s
Train Epoch: 1310 [61440/90000 (68%)]	Loss: -18.3453	Cost: 5.84s
Train Epoch: 1310 [81920/90000 (91%)]	Loss: -18.5017	Cost: 6.08s
Train Epoch: 1310 	Average Loss: -17.6601
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7500

Learning rate: 5.320701857394259e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1311 [0/90000 (0%)]	Loss: -6.5108	Cost: 25.45s
Train Epoch: 1311 [20480/90000 (23%)]	Loss: -18.8008	Cost: 6.09s
Train Epoch: 1311 [40960/90000 (45%)]	Loss: -18.3024	Cost: 7.30s
Train Epoch: 1311 [61440/90000 (68%)]	Loss: -18.3497	Cost: 5.81s
Train Epoch: 1311 [81920/90000 (91%)]	Loss: -18.6345	Cost: 6.20s
Train Epoch: 1311 	Average Loss: -17.7349
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.8121

Learning rate: 5.306825477899661e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1312 [0/90000 (0%)]	Loss: -7.6392	Cost: 25.63s
Train Epoch: 1312 [20480/90000 (23%)]	Loss: -18.5503	Cost: 6.13s
Train Epoch: 1312 [40960/90000 (45%)]	Loss: -18.3169	Cost: 6.42s
Train Epoch: 1312 [61440/90000 (68%)]	Loss: -18.4464	Cost: 5.93s
Train Epoch: 1312 [81920/90000 (91%)]	Loss: -18.8797	Cost: 5.71s
Train Epoch: 1312 	Average Loss: -17.8341
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.9969

Learning rate: 5.2929606783466694e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1313 [0/90000 (0%)]	Loss: -7.9011	Cost: 26.68s
Train Epoch: 1313 [20480/90000 (23%)]	Loss: -18.9199	Cost: 6.10s
Train Epoch: 1313 [40960/90000 (45%)]	Loss: -18.4145	Cost: 7.09s
Train Epoch: 1313 [61440/90000 (68%)]	Loss: -18.6351	Cost: 5.94s
Train Epoch: 1313 [81920/90000 (91%)]	Loss: -19.0085	Cost: 5.74s
Train Epoch: 1313 	Average Loss: -17.9731
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.9575

Learning rate: 5.279107492945284e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1314 [0/90000 (0%)]	Loss: -7.7221	Cost: 25.94s
Train Epoch: 1314 [20480/90000 (23%)]	Loss: -18.7603	Cost: 6.19s
Train Epoch: 1314 [40960/90000 (45%)]	Loss: -18.3012	Cost: 6.97s
Train Epoch: 1314 [61440/90000 (68%)]	Loss: -18.7278	Cost: 6.23s
Train Epoch: 1314 [81920/90000 (91%)]	Loss: -18.9674	Cost: 5.82s
Train Epoch: 1314 	Average Loss: -17.9129
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.7752

Learning rate: 5.26526595587687e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1315 [0/90000 (0%)]	Loss: -8.3539	Cost: 26.58s
Train Epoch: 1315 [20480/90000 (23%)]	Loss: -18.8146	Cost: 6.12s
Train Epoch: 1315 [40960/90000 (45%)]	Loss: -18.2952	Cost: 6.27s
Train Epoch: 1315 [61440/90000 (68%)]	Loss: -18.4707	Cost: 5.97s
Train Epoch: 1315 [81920/90000 (91%)]	Loss: -18.6903	Cost: 5.74s
Train Epoch: 1315 	Average Loss: -17.8573
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.9678

Learning rate: 5.251436101294047e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1316 [0/90000 (0%)]	Loss: -7.8505	Cost: 25.91s
Train Epoch: 1316 [20480/90000 (23%)]	Loss: -18.8862	Cost: 6.13s
Train Epoch: 1316 [40960/90000 (45%)]	Loss: -18.3729	Cost: 7.51s
Train Epoch: 1316 [61440/90000 (68%)]	Loss: -18.5938	Cost: 5.83s
Train Epoch: 1316 [81920/90000 (91%)]	Loss: -18.7577	Cost: 5.84s
Train Epoch: 1316 	Average Loss: -17.8589
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.0340

Learning rate: 5.237617963320599e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1317 [0/90000 (0%)]	Loss: -7.2510	Cost: 27.62s
Train Epoch: 1317 [20480/90000 (23%)]	Loss: -18.9747	Cost: 6.08s
Train Epoch: 1317 [40960/90000 (45%)]	Loss: -18.3365	Cost: 7.11s
Train Epoch: 1317 [61440/90000 (68%)]	Loss: -18.8259	Cost: 6.18s
Train Epoch: 1317 [81920/90000 (91%)]	Loss: -18.7546	Cost: 5.93s
Train Epoch: 1317 	Average Loss: -17.8918
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.9558

Learning rate: 5.223811576051416e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1318 [0/90000 (0%)]	Loss: -7.1520	Cost: 26.76s
Train Epoch: 1318 [20480/90000 (23%)]	Loss: -18.7985	Cost: 6.12s
Train Epoch: 1318 [40960/90000 (45%)]	Loss: -18.4879	Cost: 7.06s
Train Epoch: 1318 [61440/90000 (68%)]	Loss: -18.9258	Cost: 5.89s
Train Epoch: 1318 [81920/90000 (91%)]	Loss: -18.7880	Cost: 5.71s
Train Epoch: 1318 	Average Loss: -17.9540
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.0292

Learning rate: 5.210016973552382e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1319 [0/90000 (0%)]	Loss: -8.7658	Cost: 25.94s
Train Epoch: 1319 [20480/90000 (23%)]	Loss: -18.8850	Cost: 6.13s
Train Epoch: 1319 [40960/90000 (45%)]	Loss: -18.3974	Cost: 7.05s
Train Epoch: 1319 [61440/90000 (68%)]	Loss: -18.6575	Cost: 5.86s
Train Epoch: 1319 [81920/90000 (91%)]	Loss: -18.7331	Cost: 5.69s
Train Epoch: 1319 	Average Loss: -17.9458
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.8863

Learning rate: 5.196234189860307e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1320 [0/90000 (0%)]	Loss: -7.6879	Cost: 26.77s
Train Epoch: 1320 [20480/90000 (23%)]	Loss: -18.8649	Cost: 6.15s
Train Epoch: 1320 [40960/90000 (45%)]	Loss: -18.3844	Cost: 7.19s
Train Epoch: 1320 [61440/90000 (68%)]	Loss: -18.8187	Cost: 5.84s
Train Epoch: 1320 [81920/90000 (91%)]	Loss: -18.8879	Cost: 5.91s
Train Epoch: 1320 	Average Loss: -17.9493
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.1392

Learning rate: 5.182463258982842e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1321 [0/90000 (0%)]	Loss: -7.4550	Cost: 25.32s
Train Epoch: 1321 [20480/90000 (23%)]	Loss: -19.0189	Cost: 6.09s
Train Epoch: 1321 [40960/90000 (45%)]	Loss: -18.5096	Cost: 7.63s
Train Epoch: 1321 [61440/90000 (68%)]	Loss: -18.9930	Cost: 5.82s
Train Epoch: 1321 [81920/90000 (91%)]	Loss: -18.9282	Cost: 6.08s
Train Epoch: 1321 	Average Loss: -18.0285
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.0913

Learning rate: 5.168704214898383e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1322 [0/90000 (0%)]	Loss: -7.2831	Cost: 25.68s
Train Epoch: 1322 [20480/90000 (23%)]	Loss: -18.9378	Cost: 6.11s
Train Epoch: 1322 [40960/90000 (45%)]	Loss: -18.4181	Cost: 7.44s
Train Epoch: 1322 [61440/90000 (68%)]	Loss: -18.9704	Cost: 5.82s
Train Epoch: 1322 [81920/90000 (91%)]	Loss: -18.7403	Cost: 6.08s
Train Epoch: 1322 	Average Loss: -17.9368
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.9948

Learning rate: 5.1549570915560125e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1323 [0/90000 (0%)]	Loss: -8.0416	Cost: 26.70s
Train Epoch: 1323 [20480/90000 (23%)]	Loss: -18.9696	Cost: 6.10s
Train Epoch: 1323 [40960/90000 (45%)]	Loss: -18.3846	Cost: 6.48s
Train Epoch: 1323 [61440/90000 (68%)]	Loss: -18.9345	Cost: 5.87s
Train Epoch: 1323 [81920/90000 (91%)]	Loss: -18.9003	Cost: 5.81s
Train Epoch: 1323 	Average Loss: -17.9658
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.1003

Learning rate: 5.141221922875387e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1324 [0/90000 (0%)]	Loss: -8.3361	Cost: 25.62s
Train Epoch: 1324 [20480/90000 (23%)]	Loss: -18.8540	Cost: 6.16s
Train Epoch: 1324 [40960/90000 (45%)]	Loss: -18.0799	Cost: 7.00s
Train Epoch: 1324 [61440/90000 (68%)]	Loss: -18.8023	Cost: 5.87s
Train Epoch: 1324 [81920/90000 (91%)]	Loss: -18.8495	Cost: 5.97s
Train Epoch: 1324 	Average Loss: -17.8747
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.0400

Learning rate: 5.127498742746671e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1325 [0/90000 (0%)]	Loss: -7.9572	Cost: 26.18s
Train Epoch: 1325 [20480/90000 (23%)]	Loss: -19.0066	Cost: 6.13s
Train Epoch: 1325 [40960/90000 (45%)]	Loss: -18.3821	Cost: 7.34s
Train Epoch: 1325 [61440/90000 (68%)]	Loss: -18.8561	Cost: 5.84s
Train Epoch: 1325 [81920/90000 (91%)]	Loss: -19.0858	Cost: 6.01s
Train Epoch: 1325 	Average Loss: -17.9673
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.1141

Learning rate: 5.113787585030441e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1326 [0/90000 (0%)]	Loss: -7.8368	Cost: 27.05s
Train Epoch: 1326 [20480/90000 (23%)]	Loss: -19.2526	Cost: 6.05s
Train Epoch: 1326 [40960/90000 (45%)]	Loss: -18.6407	Cost: 7.03s
Train Epoch: 1326 [61440/90000 (68%)]	Loss: -18.9545	Cost: 5.89s
Train Epoch: 1326 [81920/90000 (91%)]	Loss: -18.5399	Cost: 5.78s
Train Epoch: 1326 	Average Loss: -18.0806
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.4206

Learning rate: 5.100088483557629e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1327 [0/90000 (0%)]	Loss: -7.3556	Cost: 26.18s
Train Epoch: 1327 [20480/90000 (23%)]	Loss: -18.2915	Cost: 6.15s
Train Epoch: 1327 [40960/90000 (45%)]	Loss: -17.7093	Cost: 7.02s
Train Epoch: 1327 [61440/90000 (68%)]	Loss: -18.4470	Cost: 5.86s
Train Epoch: 1327 [81920/90000 (91%)]	Loss: -19.0859	Cost: 6.04s
Train Epoch: 1327 	Average Loss: -17.5967
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.9635

Learning rate: 5.0864014721293906e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1328 [0/90000 (0%)]	Loss: -7.2420	Cost: 25.95s
Train Epoch: 1328 [20480/90000 (23%)]	Loss: -18.7631	Cost: 6.13s
Train Epoch: 1328 [40960/90000 (45%)]	Loss: -18.1459	Cost: 7.23s
Train Epoch: 1328 [61440/90000 (68%)]	Loss: -18.8065	Cost: 5.90s
Train Epoch: 1328 [81920/90000 (91%)]	Loss: -19.0750	Cost: 5.86s
Train Epoch: 1328 	Average Loss: -17.8710
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.1551

Learning rate: 5.072726584517074e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1329 [0/90000 (0%)]	Loss: -8.6669	Cost: 25.41s
Train Epoch: 1329 [20480/90000 (23%)]	Loss: -19.1429	Cost: 6.13s
Train Epoch: 1329 [40960/90000 (45%)]	Loss: -18.5105	Cost: 6.91s
Train Epoch: 1329 [61440/90000 (68%)]	Loss: -18.6184	Cost: 5.90s
Train Epoch: 1329 [81920/90000 (91%)]	Loss: -18.7110	Cost: 5.86s
Train Epoch: 1329 	Average Loss: -18.0758
Re-generating waveforms for posterior prior.
Test set: Average loss: -7.8708

Learning rate: 5.059063854462111e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1330 [0/90000 (0%)]	Loss: -7.0702	Cost: 25.49s
Train Epoch: 1330 [20480/90000 (23%)]	Loss: -19.0159	Cost: 6.20s
Train Epoch: 1330 [40960/90000 (45%)]	Loss: -18.5172	Cost: 7.09s
Train Epoch: 1330 [61440/90000 (68%)]	Loss: -18.9290	Cost: 5.88s
Train Epoch: 1330 [81920/90000 (91%)]	Loss: -19.0235	Cost: 5.96s
Train Epoch: 1330 	Average Loss: -18.0646
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.0728

Learning rate: 5.045413315675916e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1331 [0/90000 (0%)]	Loss: -7.8057	Cost: 25.21s
Train Epoch: 1331 [20480/90000 (23%)]	Loss: -19.2318	Cost: 6.15s
Train Epoch: 1331 [40960/90000 (45%)]	Loss: -18.9661	Cost: 7.18s
Train Epoch: 1331 [61440/90000 (68%)]	Loss: -19.0350	Cost: 5.85s
Train Epoch: 1331 [81920/90000 (91%)]	Loss: -19.1485	Cost: 5.98s
Train Epoch: 1331 	Average Loss: -18.2630
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.0827

Learning rate: 5.031775001839851e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1332 [0/90000 (0%)]	Loss: -8.1772	Cost: 26.04s
Train Epoch: 1332 [20480/90000 (23%)]	Loss: -19.2394	Cost: 6.12s
Train Epoch: 1332 [40960/90000 (45%)]	Loss: -18.8609	Cost: 7.11s
Train Epoch: 1332 [61440/90000 (68%)]	Loss: -19.0341	Cost: 5.85s
Train Epoch: 1332 [81920/90000 (91%)]	Loss: -19.4193	Cost: 5.97s
Train Epoch: 1332 	Average Loss: -18.2639
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.2398

Learning rate: 5.018148946605085e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1333 [0/90000 (0%)]	Loss: -7.8738	Cost: 26.39s
Train Epoch: 1333 [20480/90000 (23%)]	Loss: -19.4196	Cost: 6.09s
Train Epoch: 1333 [40960/90000 (45%)]	Loss: -18.8279	Cost: 7.04s
Train Epoch: 1333 [61440/90000 (68%)]	Loss: -19.1384	Cost: 5.84s
Train Epoch: 1333 [81920/90000 (91%)]	Loss: -19.4232	Cost: 6.30s
Train Epoch: 1333 	Average Loss: -18.3522
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.2890

Learning rate: 5.0045351835925614e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1334 [0/90000 (0%)]	Loss: -8.1495	Cost: 26.11s
Train Epoch: 1334 [20480/90000 (23%)]	Loss: -19.4881	Cost: 6.14s
Train Epoch: 1334 [40960/90000 (45%)]	Loss: -18.7283	Cost: 7.00s
Train Epoch: 1334 [61440/90000 (68%)]	Loss: -19.2484	Cost: 5.87s
Train Epoch: 1334 [81920/90000 (91%)]	Loss: -19.4224	Cost: 6.00s
Train Epoch: 1334 	Average Loss: -18.4006
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.0261

Learning rate: 4.9909337463928966e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1335 [0/90000 (0%)]	Loss: -8.3910	Cost: 25.93s
Train Epoch: 1335 [20480/90000 (23%)]	Loss: -19.4077	Cost: 6.11s
Train Epoch: 1335 [40960/90000 (45%)]	Loss: -18.6566	Cost: 7.50s
Train Epoch: 1335 [61440/90000 (68%)]	Loss: -19.2040	Cost: 5.83s
Train Epoch: 1335 [81920/90000 (91%)]	Loss: -19.4173	Cost: 5.94s
Train Epoch: 1335 	Average Loss: -18.4026
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.2870

Learning rate: 4.977344668566268e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1336 [0/90000 (0%)]	Loss: -6.9651	Cost: 26.59s
Train Epoch: 1336 [20480/90000 (23%)]	Loss: -19.3937	Cost: 6.10s
Train Epoch: 1336 [40960/90000 (45%)]	Loss: -18.8432	Cost: 6.41s
Train Epoch: 1336 [61440/90000 (68%)]	Loss: -19.0892	Cost: 6.23s
Train Epoch: 1336 [81920/90000 (91%)]	Loss: -19.4884	Cost: 6.62s
Train Epoch: 1336 	Average Loss: -18.3989
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.2616

Learning rate: 4.963767983642385e-05
Re-generating waveforms for posterior prior.
Train Epoch: 1337 [0/90000 (0%)]	Loss: -7.8375	Cost: 25.70s
Train Epoch: 1337 [20480/90000 (23%)]	Loss: -19.6326	Cost: 6.17s
Train Epoch: 1337 [40960/90000 (45%)]	Loss: -18.9657	Cost: 7.30s
Train Epoch: 1337 [61440/90000 (68%)]	Loss: -19.2145	Cost: 5.85s
Train Epoch: 1337 [81920/90000 (91%)]	Loss: -19.5320	Cost: 5.95s
Train Epoch: 1337 	Average Loss: -18.4806
Re-generating waveforms for posterior prior.
Test set: Average loss: -8.3003

Learning rate: 4.950203725120366e-05
