Nestedspace(basis_dir='data/GW150914_sample_prior_basis/', batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, epochs=2000, flow_lr=None, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_posterior_prior/', model_source='existing', nsample=100000, nsamples_target_event=1000, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']
Loading existing model

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 2000 epochs
Starting timer
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2001 [0/90000 (0%)]	Loss: -5.4627	Cost: 23.75s
Train Epoch: 2001 [20480/90000 (23%)]	Loss: -6.4968	Cost: 6.09s
Train Epoch: 2001 [40960/90000 (45%)]	Loss: -6.3346	Cost: 7.44s
Train Epoch: 2001 [61440/90000 (68%)]	Loss: -7.0391	Cost: 5.87s
Train Epoch: 2001 [81920/90000 (91%)]	Loss: -6.8139	Cost: 6.07s
Train Epoch: 2001 	Average Loss: -7.0130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5057

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2002 [0/90000 (0%)]	Loss: -7.8009	Cost: 23.46s
Train Epoch: 2002 [20480/90000 (23%)]	Loss: -6.4085	Cost: 6.10s
Train Epoch: 2002 [40960/90000 (45%)]	Loss: -6.3996	Cost: 7.85s
Train Epoch: 2002 [61440/90000 (68%)]	Loss: -6.9975	Cost: 5.89s
Train Epoch: 2002 [81920/90000 (91%)]	Loss: -6.6446	Cost: 5.95s
Train Epoch: 2002 	Average Loss: -7.0387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7201

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2003 [0/90000 (0%)]	Loss: -6.1973	Cost: 23.31s
Train Epoch: 2003 [20480/90000 (23%)]	Loss: -6.2871	Cost: 6.48s
Train Epoch: 2003 [40960/90000 (45%)]	Loss: -6.3725	Cost: 7.42s
Train Epoch: 2003 [61440/90000 (68%)]	Loss: -6.9867	Cost: 5.92s
Train Epoch: 2003 [81920/90000 (91%)]	Loss: -6.6373	Cost: 6.03s
Train Epoch: 2003 	Average Loss: -7.0262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6361

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2004 [0/90000 (0%)]	Loss: -6.2582	Cost: 23.43s
Train Epoch: 2004 [20480/90000 (23%)]	Loss: -6.5870	Cost: 6.13s
Train Epoch: 2004 [40960/90000 (45%)]	Loss: -6.3082	Cost: 8.05s
Train Epoch: 2004 [61440/90000 (68%)]	Loss: -6.8176	Cost: 5.86s
Train Epoch: 2004 [81920/90000 (91%)]	Loss: -6.6974	Cost: 6.18s
Train Epoch: 2004 	Average Loss: -6.9395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7209

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2005 [0/90000 (0%)]	Loss: -6.5892	Cost: 23.58s
Train Epoch: 2005 [20480/90000 (23%)]	Loss: -6.4422	Cost: 6.13s
Train Epoch: 2005 [40960/90000 (45%)]	Loss: -6.2833	Cost: 8.04s
Train Epoch: 2005 [61440/90000 (68%)]	Loss: -7.1281	Cost: 5.88s
Train Epoch: 2005 [81920/90000 (91%)]	Loss: -6.7187	Cost: 6.07s
Train Epoch: 2005 	Average Loss: -7.0484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7356

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2006 [0/90000 (0%)]	Loss: -7.2004	Cost: 23.45s
Train Epoch: 2006 [20480/90000 (23%)]	Loss: -6.4638	Cost: 6.09s
Train Epoch: 2006 [40960/90000 (45%)]	Loss: -6.3426	Cost: 7.98s
Train Epoch: 2006 [61440/90000 (68%)]	Loss: -6.8737	Cost: 5.90s
Train Epoch: 2006 [81920/90000 (91%)]	Loss: -6.8302	Cost: 6.21s
Train Epoch: 2006 	Average Loss: -7.0469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7557

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2007 [0/90000 (0%)]	Loss: -6.1283	Cost: 23.35s
Train Epoch: 2007 [20480/90000 (23%)]	Loss: -6.4532	Cost: 6.04s
Train Epoch: 2007 [40960/90000 (45%)]	Loss: -6.2841	Cost: 8.09s
Train Epoch: 2007 [61440/90000 (68%)]	Loss: -7.1311	Cost: 5.84s
Train Epoch: 2007 [81920/90000 (91%)]	Loss: -6.6020	Cost: 5.85s
Train Epoch: 2007 	Average Loss: -7.0332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5048

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2008 [0/90000 (0%)]	Loss: -6.9256	Cost: 23.38s
Train Epoch: 2008 [20480/90000 (23%)]	Loss: -6.5629	Cost: 6.06s
Train Epoch: 2008 [40960/90000 (45%)]	Loss: -6.5282	Cost: 8.12s
Train Epoch: 2008 [61440/90000 (68%)]	Loss: -7.0270	Cost: 5.83s
Train Epoch: 2008 [81920/90000 (91%)]	Loss: -6.7552	Cost: 6.23s
Train Epoch: 2008 	Average Loss: -7.0551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8546

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2009 [0/90000 (0%)]	Loss: -6.2143	Cost: 23.85s
Train Epoch: 2009 [20480/90000 (23%)]	Loss: -6.4290	Cost: 6.03s
Train Epoch: 2009 [40960/90000 (45%)]	Loss: -6.3528	Cost: 8.12s
Train Epoch: 2009 [61440/90000 (68%)]	Loss: -6.8623	Cost: 5.86s
Train Epoch: 2009 [81920/90000 (91%)]	Loss: -6.7049	Cost: 6.12s
Train Epoch: 2009 	Average Loss: -7.0199
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7974

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2010 [0/90000 (0%)]	Loss: -7.4751	Cost: 23.64s
Train Epoch: 2010 [20480/90000 (23%)]	Loss: -6.5258	Cost: 6.07s
Train Epoch: 2010 [40960/90000 (45%)]	Loss: -6.4361	Cost: 7.86s
Train Epoch: 2010 [61440/90000 (68%)]	Loss: -7.0842	Cost: 5.82s
Train Epoch: 2010 [81920/90000 (91%)]	Loss: -6.7178	Cost: 6.06s
Train Epoch: 2010 	Average Loss: -7.0096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7664

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2011 [0/90000 (0%)]	Loss: -6.4881	Cost: 23.66s
Train Epoch: 2011 [20480/90000 (23%)]	Loss: -6.5452	Cost: 6.10s
Train Epoch: 2011 [40960/90000 (45%)]	Loss: -6.4692	Cost: 8.12s
Train Epoch: 2011 [61440/90000 (68%)]	Loss: -7.0577	Cost: 5.86s
Train Epoch: 2011 [81920/90000 (91%)]	Loss: -6.6318	Cost: 5.95s
Train Epoch: 2011 	Average Loss: -7.0606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8366

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2012 [0/90000 (0%)]	Loss: -6.0254	Cost: 23.34s
Train Epoch: 2012 [20480/90000 (23%)]	Loss: -6.4682	Cost: 6.10s
Train Epoch: 2012 [40960/90000 (45%)]	Loss: -6.2952	Cost: 7.98s
Train Epoch: 2012 [61440/90000 (68%)]	Loss: -6.9104	Cost: 5.85s
Train Epoch: 2012 [81920/90000 (91%)]	Loss: -6.6347	Cost: 6.10s
Train Epoch: 2012 	Average Loss: -7.0384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6837

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2013 [0/90000 (0%)]	Loss: -8.0062	Cost: 23.40s
Train Epoch: 2013 [20480/90000 (23%)]	Loss: -6.4906	Cost: 6.01s
Train Epoch: 2013 [40960/90000 (45%)]	Loss: -6.3847	Cost: 8.31s
Train Epoch: 2013 [61440/90000 (68%)]	Loss: -6.9812	Cost: 5.79s
Train Epoch: 2013 [81920/90000 (91%)]	Loss: -6.6045	Cost: 6.01s
Train Epoch: 2013 	Average Loss: -7.1160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6664

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2014 [0/90000 (0%)]	Loss: -7.2912	Cost: 23.53s
Train Epoch: 2014 [20480/90000 (23%)]	Loss: -6.4504	Cost: 6.03s
Train Epoch: 2014 [40960/90000 (45%)]	Loss: -6.3641	Cost: 8.08s
Train Epoch: 2014 [61440/90000 (68%)]	Loss: -7.1625	Cost: 5.84s
Train Epoch: 2014 [81920/90000 (91%)]	Loss: -6.6271	Cost: 6.05s
Train Epoch: 2014 	Average Loss: -7.0355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6018

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2015 [0/90000 (0%)]	Loss: -6.6606	Cost: 23.53s
Train Epoch: 2015 [20480/90000 (23%)]	Loss: -6.4079	Cost: 6.06s
Train Epoch: 2015 [40960/90000 (45%)]	Loss: -6.3036	Cost: 8.24s
Train Epoch: 2015 [61440/90000 (68%)]	Loss: -7.0346	Cost: 5.84s
Train Epoch: 2015 [81920/90000 (91%)]	Loss: -6.7321	Cost: 6.02s
Train Epoch: 2015 	Average Loss: -7.0183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5727

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2016 [0/90000 (0%)]	Loss: -6.1321	Cost: 23.85s
Train Epoch: 2016 [20480/90000 (23%)]	Loss: -6.5095	Cost: 6.09s
Train Epoch: 2016 [40960/90000 (45%)]	Loss: -6.3356	Cost: 7.80s
Train Epoch: 2016 [61440/90000 (68%)]	Loss: -7.0694	Cost: 5.90s
Train Epoch: 2016 [81920/90000 (91%)]	Loss: -6.7594	Cost: 5.98s
Train Epoch: 2016 	Average Loss: -7.0252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8536

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2017 [0/90000 (0%)]	Loss: -6.9389	Cost: 23.81s
Train Epoch: 2017 [20480/90000 (23%)]	Loss: -6.5610	Cost: 6.22s
Train Epoch: 2017 [40960/90000 (45%)]	Loss: -6.4580	Cost: 7.83s
Train Epoch: 2017 [61440/90000 (68%)]	Loss: -6.9385	Cost: 5.88s
Train Epoch: 2017 [81920/90000 (91%)]	Loss: -6.6871	Cost: 5.82s
Train Epoch: 2017 	Average Loss: -7.0327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7747

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2018 [0/90000 (0%)]	Loss: -5.1756	Cost: 23.61s
Train Epoch: 2018 [20480/90000 (23%)]	Loss: -6.5368	Cost: 6.12s
Train Epoch: 2018 [40960/90000 (45%)]	Loss: -6.3978	Cost: 7.76s
Train Epoch: 2018 [61440/90000 (68%)]	Loss: -6.9537	Cost: 5.87s
Train Epoch: 2018 [81920/90000 (91%)]	Loss: -6.7232	Cost: 6.11s
Train Epoch: 2018 	Average Loss: -6.9906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8099

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2019 [0/90000 (0%)]	Loss: -7.6817	Cost: 23.67s
Train Epoch: 2019 [20480/90000 (23%)]	Loss: -6.5425	Cost: 6.07s
Train Epoch: 2019 [40960/90000 (45%)]	Loss: -6.2878	Cost: 8.17s
Train Epoch: 2019 [61440/90000 (68%)]	Loss: -6.9922	Cost: 5.85s
Train Epoch: 2019 [81920/90000 (91%)]	Loss: -6.8121	Cost: 6.22s
Train Epoch: 2019 	Average Loss: -7.0514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6817

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2020 [0/90000 (0%)]	Loss: -7.8162	Cost: 24.00s
Train Epoch: 2020 [20480/90000 (23%)]	Loss: -6.6432	Cost: 6.07s
Train Epoch: 2020 [40960/90000 (45%)]	Loss: -6.3564	Cost: 7.57s
Train Epoch: 2020 [61440/90000 (68%)]	Loss: -7.0663	Cost: 5.88s
Train Epoch: 2020 [81920/90000 (91%)]	Loss: -6.8028	Cost: 6.26s
Train Epoch: 2020 	Average Loss: -7.0409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5920

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2021 [0/90000 (0%)]	Loss: -7.4954	Cost: 23.63s
Train Epoch: 2021 [20480/90000 (23%)]	Loss: -6.6906	Cost: 6.07s
Train Epoch: 2021 [40960/90000 (45%)]	Loss: -6.4220	Cost: 8.19s
Train Epoch: 2021 [61440/90000 (68%)]	Loss: -6.8422	Cost: 5.88s
Train Epoch: 2021 [81920/90000 (91%)]	Loss: -6.7516	Cost: 5.87s
Train Epoch: 2021 	Average Loss: -7.0598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5973

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2022 [0/90000 (0%)]	Loss: -7.4068	Cost: 23.33s
Train Epoch: 2022 [20480/90000 (23%)]	Loss: -6.4250	Cost: 6.12s
Train Epoch: 2022 [40960/90000 (45%)]	Loss: -6.3252	Cost: 7.65s
Train Epoch: 2022 [61440/90000 (68%)]	Loss: -7.0498	Cost: 5.85s
Train Epoch: 2022 [81920/90000 (91%)]	Loss: -6.5848	Cost: 6.21s
Train Epoch: 2022 	Average Loss: -7.0718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6471

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2023 [0/90000 (0%)]	Loss: -5.6299	Cost: 23.34s
Train Epoch: 2023 [20480/90000 (23%)]	Loss: -6.5120	Cost: 6.14s
Train Epoch: 2023 [40960/90000 (45%)]	Loss: -6.5167	Cost: 8.17s
Train Epoch: 2023 [61440/90000 (68%)]	Loss: -7.0602	Cost: 5.84s
Train Epoch: 2023 [81920/90000 (91%)]	Loss: -6.6905	Cost: 6.06s
Train Epoch: 2023 	Average Loss: -7.0575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8088

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2024 [0/90000 (0%)]	Loss: -6.6790	Cost: 23.40s
Train Epoch: 2024 [20480/90000 (23%)]	Loss: -6.4518	Cost: 6.15s
Train Epoch: 2024 [40960/90000 (45%)]	Loss: -6.3008	Cost: 7.86s
Train Epoch: 2024 [61440/90000 (68%)]	Loss: -7.0586	Cost: 5.82s
Train Epoch: 2024 [81920/90000 (91%)]	Loss: -6.7075	Cost: 6.27s
Train Epoch: 2024 	Average Loss: -6.9931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8321

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2025 [0/90000 (0%)]	Loss: -6.8601	Cost: 23.53s
Train Epoch: 2025 [20480/90000 (23%)]	Loss: -6.4206	Cost: 6.11s
Train Epoch: 2025 [40960/90000 (45%)]	Loss: -6.4713	Cost: 8.44s
Train Epoch: 2025 [61440/90000 (68%)]	Loss: -6.9793	Cost: 5.96s
Train Epoch: 2025 [81920/90000 (91%)]	Loss: -6.8261	Cost: 5.78s
Train Epoch: 2025 	Average Loss: -7.0567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6645

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2026 [0/90000 (0%)]	Loss: -6.7305	Cost: 23.14s
Train Epoch: 2026 [20480/90000 (23%)]	Loss: -6.4952	Cost: 6.10s
Train Epoch: 2026 [40960/90000 (45%)]	Loss: -6.2042	Cost: 7.94s
Train Epoch: 2026 [61440/90000 (68%)]	Loss: -7.0120	Cost: 5.84s
Train Epoch: 2026 [81920/90000 (91%)]	Loss: -6.5952	Cost: 6.22s
Train Epoch: 2026 	Average Loss: -6.9872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6474

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2027 [0/90000 (0%)]	Loss: -5.2485	Cost: 23.75s
Train Epoch: 2027 [20480/90000 (23%)]	Loss: -6.4817	Cost: 6.17s
Train Epoch: 2027 [40960/90000 (45%)]	Loss: -6.4838	Cost: 8.18s
Train Epoch: 2027 [61440/90000 (68%)]	Loss: -6.8781	Cost: 5.85s
Train Epoch: 2027 [81920/90000 (91%)]	Loss: -6.7009	Cost: 5.80s
Train Epoch: 2027 	Average Loss: -7.0065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7070

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2028 [0/90000 (0%)]	Loss: -6.8581	Cost: 23.66s
Train Epoch: 2028 [20480/90000 (23%)]	Loss: -6.3617	Cost: 6.19s
Train Epoch: 2028 [40960/90000 (45%)]	Loss: -6.4208	Cost: 7.81s
Train Epoch: 2028 [61440/90000 (68%)]	Loss: -6.9484	Cost: 5.92s
Train Epoch: 2028 [81920/90000 (91%)]	Loss: -6.6937	Cost: 6.14s
Train Epoch: 2028 	Average Loss: -6.9807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6487

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2029 [0/90000 (0%)]	Loss: -6.8109	Cost: 23.75s
Train Epoch: 2029 [20480/90000 (23%)]	Loss: -6.4931	Cost: 6.15s
Train Epoch: 2029 [40960/90000 (45%)]	Loss: -6.3526	Cost: 8.11s
Train Epoch: 2029 [61440/90000 (68%)]	Loss: -7.1175	Cost: 6.03s
Train Epoch: 2029 [81920/90000 (91%)]	Loss: -6.7487	Cost: 5.94s
Train Epoch: 2029 	Average Loss: -7.0637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7179

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2030 [0/90000 (0%)]	Loss: -7.2373	Cost: 23.72s
Train Epoch: 2030 [20480/90000 (23%)]	Loss: -6.5454	Cost: 6.10s
Train Epoch: 2030 [40960/90000 (45%)]	Loss: -6.3327	Cost: 7.92s
Train Epoch: 2030 [61440/90000 (68%)]	Loss: -7.1013	Cost: 5.87s
Train Epoch: 2030 [81920/90000 (91%)]	Loss: -6.7005	Cost: 5.99s
Train Epoch: 2030 	Average Loss: -7.0223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7974

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2031 [0/90000 (0%)]	Loss: -6.1750	Cost: 23.58s
Train Epoch: 2031 [20480/90000 (23%)]	Loss: -6.4845	Cost: 6.17s
Train Epoch: 2031 [40960/90000 (45%)]	Loss: -6.4198	Cost: 8.06s
Train Epoch: 2031 [61440/90000 (68%)]	Loss: -6.9152	Cost: 5.84s
Train Epoch: 2031 [81920/90000 (91%)]	Loss: -6.4338	Cost: 5.89s
Train Epoch: 2031 	Average Loss: -6.9821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7856

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2032 [0/90000 (0%)]	Loss: -7.7854	Cost: 23.86s
Train Epoch: 2032 [20480/90000 (23%)]	Loss: -6.5008	Cost: 6.07s
Train Epoch: 2032 [40960/90000 (45%)]	Loss: -6.4122	Cost: 7.95s
Train Epoch: 2032 [61440/90000 (68%)]	Loss: -7.1918	Cost: 5.85s
Train Epoch: 2032 [81920/90000 (91%)]	Loss: -6.6607	Cost: 6.14s
Train Epoch: 2032 	Average Loss: -7.0022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8114

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2033 [0/90000 (0%)]	Loss: -7.4486	Cost: 23.48s
Train Epoch: 2033 [20480/90000 (23%)]	Loss: -6.4238	Cost: 6.06s
Train Epoch: 2033 [40960/90000 (45%)]	Loss: -6.3377	Cost: 7.91s
Train Epoch: 2033 [61440/90000 (68%)]	Loss: -7.0765	Cost: 5.88s
Train Epoch: 2033 [81920/90000 (91%)]	Loss: -6.7389	Cost: 6.17s
Train Epoch: 2033 	Average Loss: -6.9733
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7336

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2034 [0/90000 (0%)]	Loss: -8.9361	Cost: 23.39s
Train Epoch: 2034 [20480/90000 (23%)]	Loss: -6.4482	Cost: 6.13s
Train Epoch: 2034 [40960/90000 (45%)]	Loss: -6.3815	Cost: 8.00s
Train Epoch: 2034 [61440/90000 (68%)]	Loss: -7.1246	Cost: 5.90s
Train Epoch: 2034 [81920/90000 (91%)]	Loss: -6.6461	Cost: 6.12s
Train Epoch: 2034 	Average Loss: -7.0246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8189

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2035 [0/90000 (0%)]	Loss: -6.6355	Cost: 23.48s
Train Epoch: 2035 [20480/90000 (23%)]	Loss: -6.4445	Cost: 6.13s
Train Epoch: 2035 [40960/90000 (45%)]	Loss: -6.4113	Cost: 8.19s
Train Epoch: 2035 [61440/90000 (68%)]	Loss: -6.9669	Cost: 5.82s
Train Epoch: 2035 [81920/90000 (91%)]	Loss: -6.6329	Cost: 6.46s
Train Epoch: 2035 	Average Loss: -7.0948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7833

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2036 [0/90000 (0%)]	Loss: -5.8461	Cost: 23.36s
Train Epoch: 2036 [20480/90000 (23%)]	Loss: -6.3947	Cost: 6.01s
Train Epoch: 2036 [40960/90000 (45%)]	Loss: -6.4063	Cost: 7.95s
Train Epoch: 2036 [61440/90000 (68%)]	Loss: -6.9166	Cost: 5.90s
Train Epoch: 2036 [81920/90000 (91%)]	Loss: -6.6326	Cost: 6.01s
Train Epoch: 2036 	Average Loss: -7.0391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7290

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2037 [0/90000 (0%)]	Loss: -6.9036	Cost: 23.63s
Train Epoch: 2037 [20480/90000 (23%)]	Loss: -6.4627	Cost: 6.06s
Train Epoch: 2037 [40960/90000 (45%)]	Loss: -6.4038	Cost: 8.36s
Train Epoch: 2037 [61440/90000 (68%)]	Loss: -6.9490	Cost: 5.87s
Train Epoch: 2037 [81920/90000 (91%)]	Loss: -6.6315	Cost: 5.67s
Train Epoch: 2037 	Average Loss: -6.9915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7950

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2038 [0/90000 (0%)]	Loss: -4.8543	Cost: 23.33s
Train Epoch: 2038 [20480/90000 (23%)]	Loss: -6.5278	Cost: 6.02s
Train Epoch: 2038 [40960/90000 (45%)]	Loss: -6.4038	Cost: 8.10s
Train Epoch: 2038 [61440/90000 (68%)]	Loss: -6.8628	Cost: 5.88s
Train Epoch: 2038 [81920/90000 (91%)]	Loss: -6.6062	Cost: 6.26s
Train Epoch: 2038 	Average Loss: -6.9898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7145

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2039 [0/90000 (0%)]	Loss: -7.3760	Cost: 23.71s
Train Epoch: 2039 [20480/90000 (23%)]	Loss: -6.4303	Cost: 6.23s
Train Epoch: 2039 [40960/90000 (45%)]	Loss: -6.3327	Cost: 8.03s
Train Epoch: 2039 [61440/90000 (68%)]	Loss: -6.9542	Cost: 5.92s
Train Epoch: 2039 [81920/90000 (91%)]	Loss: -6.8254	Cost: 6.29s
Train Epoch: 2039 	Average Loss: -7.0766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8488

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2040 [0/90000 (0%)]	Loss: -7.7977	Cost: 23.56s
Train Epoch: 2040 [20480/90000 (23%)]	Loss: -6.6068	Cost: 6.06s
Train Epoch: 2040 [40960/90000 (45%)]	Loss: -6.5120	Cost: 8.00s
Train Epoch: 2040 [61440/90000 (68%)]	Loss: -6.9269	Cost: 5.83s
Train Epoch: 2040 [81920/90000 (91%)]	Loss: -6.7068	Cost: 6.11s
Train Epoch: 2040 	Average Loss: -7.0728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7121

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2041 [0/90000 (0%)]	Loss: -7.5948	Cost: 23.81s
Train Epoch: 2041 [20480/90000 (23%)]	Loss: -6.5108	Cost: 6.06s
Train Epoch: 2041 [40960/90000 (45%)]	Loss: -6.5483	Cost: 8.22s
Train Epoch: 2041 [61440/90000 (68%)]	Loss: -7.0311	Cost: 5.84s
Train Epoch: 2041 [81920/90000 (91%)]	Loss: -6.8073	Cost: 6.48s
Train Epoch: 2041 	Average Loss: -7.0990
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8267

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2042 [0/90000 (0%)]	Loss: -6.9221	Cost: 23.50s
Train Epoch: 2042 [20480/90000 (23%)]	Loss: -6.5335	Cost: 6.06s
Train Epoch: 2042 [40960/90000 (45%)]	Loss: -6.3426	Cost: 7.90s
Train Epoch: 2042 [61440/90000 (68%)]	Loss: -6.9211	Cost: 5.87s
Train Epoch: 2042 [81920/90000 (91%)]	Loss: -6.6787	Cost: 5.96s
Train Epoch: 2042 	Average Loss: -7.0367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5162

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2043 [0/90000 (0%)]	Loss: -6.0612	Cost: 23.53s
Train Epoch: 2043 [20480/90000 (23%)]	Loss: -6.4508	Cost: 6.08s
Train Epoch: 2043 [40960/90000 (45%)]	Loss: -6.5007	Cost: 8.16s
Train Epoch: 2043 [61440/90000 (68%)]	Loss: -6.9624	Cost: 5.83s
Train Epoch: 2043 [81920/90000 (91%)]	Loss: -6.8010	Cost: 6.01s
Train Epoch: 2043 	Average Loss: -6.9384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7282

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2044 [0/90000 (0%)]	Loss: -4.9682	Cost: 23.43s
Train Epoch: 2044 [20480/90000 (23%)]	Loss: -6.4963	Cost: 6.04s
Train Epoch: 2044 [40960/90000 (45%)]	Loss: -6.5297	Cost: 8.10s
Train Epoch: 2044 [61440/90000 (68%)]	Loss: -7.0002	Cost: 5.85s
Train Epoch: 2044 [81920/90000 (91%)]	Loss: -6.6010	Cost: 6.01s
Train Epoch: 2044 	Average Loss: -6.9674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6532

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2045 [0/90000 (0%)]	Loss: -7.6676	Cost: 23.71s
Train Epoch: 2045 [20480/90000 (23%)]	Loss: -6.6262	Cost: 6.10s
Train Epoch: 2045 [40960/90000 (45%)]	Loss: -6.4084	Cost: 7.66s
Train Epoch: 2045 [61440/90000 (68%)]	Loss: -7.0763	Cost: 5.89s
Train Epoch: 2045 [81920/90000 (91%)]	Loss: -6.8682	Cost: 5.94s
Train Epoch: 2045 	Average Loss: -7.0781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6488

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2046 [0/90000 (0%)]	Loss: -6.7679	Cost: 23.29s
Train Epoch: 2046 [20480/90000 (23%)]	Loss: -6.5591	Cost: 6.10s
Train Epoch: 2046 [40960/90000 (45%)]	Loss: -6.3615	Cost: 7.91s
Train Epoch: 2046 [61440/90000 (68%)]	Loss: -6.9767	Cost: 5.90s
Train Epoch: 2046 [81920/90000 (91%)]	Loss: -6.8601	Cost: 5.96s
Train Epoch: 2046 	Average Loss: -7.0305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6958

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2047 [0/90000 (0%)]	Loss: -7.2436	Cost: 24.02s
Train Epoch: 2047 [20480/90000 (23%)]	Loss: -6.4444	Cost: 6.07s
Train Epoch: 2047 [40960/90000 (45%)]	Loss: -6.4421	Cost: 8.39s
Train Epoch: 2047 [61440/90000 (68%)]	Loss: -7.0635	Cost: 5.97s
Train Epoch: 2047 [81920/90000 (91%)]	Loss: -6.6020	Cost: 5.77s
Train Epoch: 2047 	Average Loss: -7.0170
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7389

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2048 [0/90000 (0%)]	Loss: -8.5339	Cost: 23.68s
Train Epoch: 2048 [20480/90000 (23%)]	Loss: -6.5036	Cost: 6.11s
Train Epoch: 2048 [40960/90000 (45%)]	Loss: -6.4181	Cost: 7.63s
Train Epoch: 2048 [61440/90000 (68%)]	Loss: -6.8474	Cost: 5.85s
Train Epoch: 2048 [81920/90000 (91%)]	Loss: -6.6339	Cost: 6.18s
Train Epoch: 2048 	Average Loss: -7.0872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8077

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2049 [0/90000 (0%)]	Loss: -8.1266	Cost: 23.70s
Train Epoch: 2049 [20480/90000 (23%)]	Loss: -6.4696	Cost: 6.15s
Train Epoch: 2049 [40960/90000 (45%)]	Loss: -6.4138	Cost: 8.20s
Train Epoch: 2049 [61440/90000 (68%)]	Loss: -7.0493	Cost: 6.11s
Train Epoch: 2049 [81920/90000 (91%)]	Loss: -6.6779	Cost: 5.72s
Train Epoch: 2049 	Average Loss: -7.0053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6338

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2050 [0/90000 (0%)]	Loss: -7.3468	Cost: 23.64s
Train Epoch: 2050 [20480/90000 (23%)]	Loss: -6.5197	Cost: 6.25s
Train Epoch: 2050 [40960/90000 (45%)]	Loss: -6.3041	Cost: 7.83s
Train Epoch: 2050 [61440/90000 (68%)]	Loss: -6.9786	Cost: 5.91s
Train Epoch: 2050 [81920/90000 (91%)]	Loss: -6.8655	Cost: 6.11s
Train Epoch: 2050 	Average Loss: -7.0409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5598

Saving model as model.pt_e2050 & waveforms_supplementary.hdf5_e2050
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2051 [0/90000 (0%)]	Loss: -4.6127	Cost: 23.41s
Train Epoch: 2051 [20480/90000 (23%)]	Loss: -6.4113	Cost: 6.11s
Train Epoch: 2051 [40960/90000 (45%)]	Loss: -6.4981	Cost: 7.76s
Train Epoch: 2051 [61440/90000 (68%)]	Loss: -7.0199	Cost: 5.87s
Train Epoch: 2051 [81920/90000 (91%)]	Loss: -6.6246	Cost: 5.87s
Train Epoch: 2051 	Average Loss: -6.9462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7298

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2052 [0/90000 (0%)]	Loss: -6.3949	Cost: 23.64s
Train Epoch: 2052 [20480/90000 (23%)]	Loss: -6.3652	Cost: 5.98s
Train Epoch: 2052 [40960/90000 (45%)]	Loss: -6.5008	Cost: 8.10s
Train Epoch: 2052 [61440/90000 (68%)]	Loss: -7.0563	Cost: 5.92s
Train Epoch: 2052 [81920/90000 (91%)]	Loss: -6.7049	Cost: 6.04s
Train Epoch: 2052 	Average Loss: -7.0606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6316

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2053 [0/90000 (0%)]	Loss: -7.8964	Cost: 24.13s
Train Epoch: 2053 [20480/90000 (23%)]	Loss: -6.5390	Cost: 6.07s
Train Epoch: 2053 [40960/90000 (45%)]	Loss: -6.4042	Cost: 7.91s
Train Epoch: 2053 [61440/90000 (68%)]	Loss: -7.1274	Cost: 5.82s
Train Epoch: 2053 [81920/90000 (91%)]	Loss: -6.7463	Cost: 6.18s
Train Epoch: 2053 	Average Loss: -7.0447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8269

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2054 [0/90000 (0%)]	Loss: -6.8720	Cost: 23.24s
Train Epoch: 2054 [20480/90000 (23%)]	Loss: -6.3307	Cost: 6.10s
Train Epoch: 2054 [40960/90000 (45%)]	Loss: -6.3066	Cost: 7.84s
Train Epoch: 2054 [61440/90000 (68%)]	Loss: -6.9016	Cost: 5.84s
Train Epoch: 2054 [81920/90000 (91%)]	Loss: -6.7558	Cost: 6.12s
Train Epoch: 2054 	Average Loss: -7.0124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7650

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2055 [0/90000 (0%)]	Loss: -8.0295	Cost: 23.82s
Train Epoch: 2055 [20480/90000 (23%)]	Loss: -6.4140	Cost: 6.11s
Train Epoch: 2055 [40960/90000 (45%)]	Loss: -6.4408	Cost: 8.07s
Train Epoch: 2055 [61440/90000 (68%)]	Loss: -7.0827	Cost: 5.86s
Train Epoch: 2055 [81920/90000 (91%)]	Loss: -6.6966	Cost: 6.08s
Train Epoch: 2055 	Average Loss: -7.1245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6109

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2056 [0/90000 (0%)]	Loss: -8.4489	Cost: 23.74s
Train Epoch: 2056 [20480/90000 (23%)]	Loss: -6.5570	Cost: 6.11s
Train Epoch: 2056 [40960/90000 (45%)]	Loss: -6.3424	Cost: 7.91s
Train Epoch: 2056 [61440/90000 (68%)]	Loss: -7.0537	Cost: 5.83s
Train Epoch: 2056 [81920/90000 (91%)]	Loss: -6.7482	Cost: 6.37s
Train Epoch: 2056 	Average Loss: -7.0851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6862

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2057 [0/90000 (0%)]	Loss: -7.5459	Cost: 23.66s
Train Epoch: 2057 [20480/90000 (23%)]	Loss: -6.5173	Cost: 6.11s
Train Epoch: 2057 [40960/90000 (45%)]	Loss: -6.3415	Cost: 8.32s
Train Epoch: 2057 [61440/90000 (68%)]	Loss: -6.9630	Cost: 6.01s
Train Epoch: 2057 [81920/90000 (91%)]	Loss: -6.6798	Cost: 6.22s
Train Epoch: 2057 	Average Loss: -7.0246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6942

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2058 [0/90000 (0%)]	Loss: -7.7396	Cost: 23.60s
Train Epoch: 2058 [20480/90000 (23%)]	Loss: -6.6030	Cost: 6.05s
Train Epoch: 2058 [40960/90000 (45%)]	Loss: -6.3143	Cost: 7.90s
Train Epoch: 2058 [61440/90000 (68%)]	Loss: -6.8461	Cost: 5.82s
Train Epoch: 2058 [81920/90000 (91%)]	Loss: -6.7382	Cost: 6.22s
Train Epoch: 2058 	Average Loss: -7.0660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6042

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2059 [0/90000 (0%)]	Loss: -6.8478	Cost: 23.74s
Train Epoch: 2059 [20480/90000 (23%)]	Loss: -6.4440	Cost: 6.11s
Train Epoch: 2059 [40960/90000 (45%)]	Loss: -6.3867	Cost: 8.10s
Train Epoch: 2059 [61440/90000 (68%)]	Loss: -6.9713	Cost: 5.84s
Train Epoch: 2059 [81920/90000 (91%)]	Loss: -6.7356	Cost: 6.16s
Train Epoch: 2059 	Average Loss: -7.0090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7455

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2060 [0/90000 (0%)]	Loss: -5.1993	Cost: 23.55s
Train Epoch: 2060 [20480/90000 (23%)]	Loss: -6.4901	Cost: 6.10s
Train Epoch: 2060 [40960/90000 (45%)]	Loss: -6.3784	Cost: 8.04s
Train Epoch: 2060 [61440/90000 (68%)]	Loss: -7.2399	Cost: 5.84s
Train Epoch: 2060 [81920/90000 (91%)]	Loss: -6.7642	Cost: 6.32s
Train Epoch: 2060 	Average Loss: -7.0010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7060

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2061 [0/90000 (0%)]	Loss: -5.3482	Cost: 23.68s
Train Epoch: 2061 [20480/90000 (23%)]	Loss: -6.5632	Cost: 6.15s
Train Epoch: 2061 [40960/90000 (45%)]	Loss: -6.3685	Cost: 8.12s
Train Epoch: 2061 [61440/90000 (68%)]	Loss: -7.0522	Cost: 5.87s
Train Epoch: 2061 [81920/90000 (91%)]	Loss: -6.7090	Cost: 6.10s
Train Epoch: 2061 	Average Loss: -7.0242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6377

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2062 [0/90000 (0%)]	Loss: -7.5882	Cost: 23.07s
Train Epoch: 2062 [20480/90000 (23%)]	Loss: -6.5385	Cost: 6.07s
Train Epoch: 2062 [40960/90000 (45%)]	Loss: -6.3494	Cost: 8.18s
Train Epoch: 2062 [61440/90000 (68%)]	Loss: -7.0024	Cost: 5.93s
Train Epoch: 2062 [81920/90000 (91%)]	Loss: -6.6604	Cost: 5.93s
Train Epoch: 2062 	Average Loss: -7.0528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7184

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2063 [0/90000 (0%)]	Loss: -7.5720	Cost: 23.52s
Train Epoch: 2063 [20480/90000 (23%)]	Loss: -6.5197	Cost: 6.02s
Train Epoch: 2063 [40960/90000 (45%)]	Loss: -6.3655	Cost: 8.03s
Train Epoch: 2063 [61440/90000 (68%)]	Loss: -6.9279	Cost: 5.93s
Train Epoch: 2063 [81920/90000 (91%)]	Loss: -6.7540	Cost: 6.83s
Train Epoch: 2063 	Average Loss: -7.0171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6844

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2064 [0/90000 (0%)]	Loss: -8.0668	Cost: 23.75s
Train Epoch: 2064 [20480/90000 (23%)]	Loss: -6.6935	Cost: 6.22s
Train Epoch: 2064 [40960/90000 (45%)]	Loss: -6.4021	Cost: 7.68s
Train Epoch: 2064 [61440/90000 (68%)]	Loss: -6.8726	Cost: 5.88s
Train Epoch: 2064 [81920/90000 (91%)]	Loss: -6.8153	Cost: 5.93s
Train Epoch: 2064 	Average Loss: -7.1187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6972

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2065 [0/90000 (0%)]	Loss: -7.1723	Cost: 23.62s
Train Epoch: 2065 [20480/90000 (23%)]	Loss: -6.5747	Cost: 6.07s
Train Epoch: 2065 [40960/90000 (45%)]	Loss: -6.3399	Cost: 7.83s
Train Epoch: 2065 [61440/90000 (68%)]	Loss: -7.0936	Cost: 5.84s
Train Epoch: 2065 [81920/90000 (91%)]	Loss: -6.6342	Cost: 6.04s
Train Epoch: 2065 	Average Loss: -7.0316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8834

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2066 [0/90000 (0%)]	Loss: -5.7140	Cost: 23.25s
Train Epoch: 2066 [20480/90000 (23%)]	Loss: -6.6375	Cost: 6.05s
Train Epoch: 2066 [40960/90000 (45%)]	Loss: -6.3888	Cost: 7.93s
Train Epoch: 2066 [61440/90000 (68%)]	Loss: -6.8671	Cost: 5.88s
Train Epoch: 2066 [81920/90000 (91%)]	Loss: -6.6315	Cost: 6.08s
Train Epoch: 2066 	Average Loss: -7.0531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7515

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2067 [0/90000 (0%)]	Loss: -7.6023	Cost: 22.77s
Train Epoch: 2067 [20480/90000 (23%)]	Loss: -6.3923	Cost: 6.10s
Train Epoch: 2067 [40960/90000 (45%)]	Loss: -6.4640	Cost: 7.75s
Train Epoch: 2067 [61440/90000 (68%)]	Loss: -6.9826	Cost: 6.40s
Train Epoch: 2067 [81920/90000 (91%)]	Loss: -6.6664	Cost: 5.60s
Train Epoch: 2067 	Average Loss: -7.0294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6807

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2068 [0/90000 (0%)]	Loss: -5.0958	Cost: 24.16s
Train Epoch: 2068 [20480/90000 (23%)]	Loss: -6.4504	Cost: 6.18s
Train Epoch: 2068 [40960/90000 (45%)]	Loss: -6.3083	Cost: 8.08s
Train Epoch: 2068 [61440/90000 (68%)]	Loss: -7.0298	Cost: 5.89s
Train Epoch: 2068 [81920/90000 (91%)]	Loss: -6.8419	Cost: 6.27s
Train Epoch: 2068 	Average Loss: -7.0097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5796

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2069 [0/90000 (0%)]	Loss: -6.8582	Cost: 23.67s
Train Epoch: 2069 [20480/90000 (23%)]	Loss: -6.5576	Cost: 6.19s
Train Epoch: 2069 [40960/90000 (45%)]	Loss: -6.3456	Cost: 8.11s
Train Epoch: 2069 [61440/90000 (68%)]	Loss: -7.1357	Cost: 5.90s
Train Epoch: 2069 [81920/90000 (91%)]	Loss: -6.7457	Cost: 5.81s
Train Epoch: 2069 	Average Loss: -7.0328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7377

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2070 [0/90000 (0%)]	Loss: -6.7761	Cost: 23.56s
Train Epoch: 2070 [20480/90000 (23%)]	Loss: -6.3607	Cost: 6.08s
Train Epoch: 2070 [40960/90000 (45%)]	Loss: -6.4623	Cost: 8.17s
Train Epoch: 2070 [61440/90000 (68%)]	Loss: -6.9482	Cost: 5.90s
Train Epoch: 2070 [81920/90000 (91%)]	Loss: -6.8010	Cost: 5.90s
Train Epoch: 2070 	Average Loss: -7.0390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8552

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2071 [0/90000 (0%)]	Loss: -7.2661	Cost: 23.32s
Train Epoch: 2071 [20480/90000 (23%)]	Loss: -6.5519	Cost: 6.16s
Train Epoch: 2071 [40960/90000 (45%)]	Loss: -6.3187	Cost: 8.02s
Train Epoch: 2071 [61440/90000 (68%)]	Loss: -6.9674	Cost: 5.94s
Train Epoch: 2071 [81920/90000 (91%)]	Loss: -6.8006	Cost: 6.00s
Train Epoch: 2071 	Average Loss: -7.0442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6719

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2072 [0/90000 (0%)]	Loss: -6.3929	Cost: 23.75s
Train Epoch: 2072 [20480/90000 (23%)]	Loss: -6.3497	Cost: 6.19s
Train Epoch: 2072 [40960/90000 (45%)]	Loss: -6.2312	Cost: 8.08s
Train Epoch: 2072 [61440/90000 (68%)]	Loss: -7.0895	Cost: 6.06s
Train Epoch: 2072 [81920/90000 (91%)]	Loss: -6.6511	Cost: 6.04s
Train Epoch: 2072 	Average Loss: -6.9772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7562

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2073 [0/90000 (0%)]	Loss: -6.6210	Cost: 23.62s
Train Epoch: 2073 [20480/90000 (23%)]	Loss: -6.4261	Cost: 6.11s
Train Epoch: 2073 [40960/90000 (45%)]	Loss: -6.3281	Cost: 7.97s
Train Epoch: 2073 [61440/90000 (68%)]	Loss: -6.9587	Cost: 5.87s
Train Epoch: 2073 [81920/90000 (91%)]	Loss: -6.7706	Cost: 5.99s
Train Epoch: 2073 	Average Loss: -6.9933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6672

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2074 [0/90000 (0%)]	Loss: -7.8455	Cost: 23.70s
Train Epoch: 2074 [20480/90000 (23%)]	Loss: -6.3918	Cost: 6.07s
Train Epoch: 2074 [40960/90000 (45%)]	Loss: -6.4798	Cost: 8.25s
Train Epoch: 2074 [61440/90000 (68%)]	Loss: -7.0214	Cost: 5.86s
Train Epoch: 2074 [81920/90000 (91%)]	Loss: -6.6994	Cost: 6.30s
Train Epoch: 2074 	Average Loss: -7.0901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5617

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2075 [0/90000 (0%)]	Loss: -6.9303	Cost: 24.01s
Train Epoch: 2075 [20480/90000 (23%)]	Loss: -6.5289	Cost: 6.42s
Train Epoch: 2075 [40960/90000 (45%)]	Loss: -6.3325	Cost: 7.57s
Train Epoch: 2075 [61440/90000 (68%)]	Loss: -7.1291	Cost: 5.90s
Train Epoch: 2075 [81920/90000 (91%)]	Loss: -6.6822	Cost: 6.27s
Train Epoch: 2075 	Average Loss: -7.0609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6827

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2076 [0/90000 (0%)]	Loss: -6.6839	Cost: 23.75s
Train Epoch: 2076 [20480/90000 (23%)]	Loss: -6.4708	Cost: 6.21s
Train Epoch: 2076 [40960/90000 (45%)]	Loss: -6.4015	Cost: 7.76s
Train Epoch: 2076 [61440/90000 (68%)]	Loss: -6.9634	Cost: 5.88s
Train Epoch: 2076 [81920/90000 (91%)]	Loss: -6.8010	Cost: 6.20s
Train Epoch: 2076 	Average Loss: -7.0339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7658

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2077 [0/90000 (0%)]	Loss: -3.7764	Cost: 23.79s
Train Epoch: 2077 [20480/90000 (23%)]	Loss: -6.5002	Cost: 6.16s
Train Epoch: 2077 [40960/90000 (45%)]	Loss: -6.3982	Cost: 7.81s
Train Epoch: 2077 [61440/90000 (68%)]	Loss: -6.8969	Cost: 5.87s
Train Epoch: 2077 [81920/90000 (91%)]	Loss: -6.6883	Cost: 6.03s
Train Epoch: 2077 	Average Loss: -6.9195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6054

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2078 [0/90000 (0%)]	Loss: -7.6555	Cost: 23.70s
Train Epoch: 2078 [20480/90000 (23%)]	Loss: -6.4358	Cost: 6.14s
Train Epoch: 2078 [40960/90000 (45%)]	Loss: -6.4026	Cost: 7.72s
Train Epoch: 2078 [61440/90000 (68%)]	Loss: -6.8924	Cost: 5.88s
Train Epoch: 2078 [81920/90000 (91%)]	Loss: -6.8613	Cost: 6.40s
Train Epoch: 2078 	Average Loss: -7.0719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6812

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2079 [0/90000 (0%)]	Loss: -5.6376	Cost: 23.39s
Train Epoch: 2079 [20480/90000 (23%)]	Loss: -6.5658	Cost: 6.10s
Train Epoch: 2079 [40960/90000 (45%)]	Loss: -6.5859	Cost: 8.07s
Train Epoch: 2079 [61440/90000 (68%)]	Loss: -6.9287	Cost: 5.87s
Train Epoch: 2079 [81920/90000 (91%)]	Loss: -6.5969	Cost: 6.10s
Train Epoch: 2079 	Average Loss: -6.9964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7536

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2080 [0/90000 (0%)]	Loss: -7.1431	Cost: 23.76s
Train Epoch: 2080 [20480/90000 (23%)]	Loss: -6.6513	Cost: 6.20s
Train Epoch: 2080 [40960/90000 (45%)]	Loss: -6.5753	Cost: 7.65s
Train Epoch: 2080 [61440/90000 (68%)]	Loss: -7.0357	Cost: 5.87s
Train Epoch: 2080 [81920/90000 (91%)]	Loss: -6.7657	Cost: 6.07s
Train Epoch: 2080 	Average Loss: -7.1115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7241

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2081 [0/90000 (0%)]	Loss: -5.3298	Cost: 24.12s
Train Epoch: 2081 [20480/90000 (23%)]	Loss: -6.5034	Cost: 6.07s
Train Epoch: 2081 [40960/90000 (45%)]	Loss: -6.2954	Cost: 7.83s
Train Epoch: 2081 [61440/90000 (68%)]	Loss: -7.0310	Cost: 5.86s
Train Epoch: 2081 [81920/90000 (91%)]	Loss: -6.7298	Cost: 6.27s
Train Epoch: 2081 	Average Loss: -6.9882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7347

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2082 [0/90000 (0%)]	Loss: -7.8838	Cost: 24.88s
Train Epoch: 2082 [20480/90000 (23%)]	Loss: -6.5013	Cost: 6.09s
Train Epoch: 2082 [40960/90000 (45%)]	Loss: -6.4830	Cost: 7.57s
Train Epoch: 2082 [61440/90000 (68%)]	Loss: -7.0890	Cost: 5.87s
Train Epoch: 2082 [81920/90000 (91%)]	Loss: -6.7174	Cost: 5.96s
Train Epoch: 2082 	Average Loss: -7.0858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6521

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2083 [0/90000 (0%)]	Loss: -8.5449	Cost: 24.36s
Train Epoch: 2083 [20480/90000 (23%)]	Loss: -6.3857	Cost: 6.01s
Train Epoch: 2083 [40960/90000 (45%)]	Loss: -6.3413	Cost: 7.95s
Train Epoch: 2083 [61440/90000 (68%)]	Loss: -7.1225	Cost: 5.85s
Train Epoch: 2083 [81920/90000 (91%)]	Loss: -6.5742	Cost: 5.93s
Train Epoch: 2083 	Average Loss: -7.1225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7925

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2084 [0/90000 (0%)]	Loss: -6.6920	Cost: 23.48s
Train Epoch: 2084 [20480/90000 (23%)]	Loss: -6.3447	Cost: 6.16s
Train Epoch: 2084 [40960/90000 (45%)]	Loss: -6.4420	Cost: 8.04s
Train Epoch: 2084 [61440/90000 (68%)]	Loss: -6.8921	Cost: 5.84s
Train Epoch: 2084 [81920/90000 (91%)]	Loss: -6.7530	Cost: 6.14s
Train Epoch: 2084 	Average Loss: -7.0360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7425

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2085 [0/90000 (0%)]	Loss: -5.9776	Cost: 24.09s
Train Epoch: 2085 [20480/90000 (23%)]	Loss: -6.5710	Cost: 6.16s
Train Epoch: 2085 [40960/90000 (45%)]	Loss: -6.4392	Cost: 8.14s
Train Epoch: 2085 [61440/90000 (68%)]	Loss: -7.0540	Cost: 5.93s
Train Epoch: 2085 [81920/90000 (91%)]	Loss: -6.6871	Cost: 5.68s
Train Epoch: 2085 	Average Loss: -6.9966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8195

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2086 [0/90000 (0%)]	Loss: -7.1370	Cost: 23.12s
Train Epoch: 2086 [20480/90000 (23%)]	Loss: -6.4453	Cost: 6.14s
Train Epoch: 2086 [40960/90000 (45%)]	Loss: -6.5026	Cost: 8.05s
Train Epoch: 2086 [61440/90000 (68%)]	Loss: -6.9164	Cost: 5.93s
Train Epoch: 2086 [81920/90000 (91%)]	Loss: -6.6664	Cost: 5.96s
Train Epoch: 2086 	Average Loss: -7.0164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7218

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2087 [0/90000 (0%)]	Loss: -7.8566	Cost: 24.13s
Train Epoch: 2087 [20480/90000 (23%)]	Loss: -6.2660	Cost: 6.11s
Train Epoch: 2087 [40960/90000 (45%)]	Loss: -6.4230	Cost: 8.11s
Train Epoch: 2087 [61440/90000 (68%)]	Loss: -7.0170	Cost: 6.11s
Train Epoch: 2087 [81920/90000 (91%)]	Loss: -6.4211	Cost: 5.77s
Train Epoch: 2087 	Average Loss: -7.0535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6746

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2088 [0/90000 (0%)]	Loss: -8.0428	Cost: 23.25s
Train Epoch: 2088 [20480/90000 (23%)]	Loss: -6.4294	Cost: 6.06s
Train Epoch: 2088 [40960/90000 (45%)]	Loss: -6.4655	Cost: 8.13s
Train Epoch: 2088 [61440/90000 (68%)]	Loss: -7.1514	Cost: 5.86s
Train Epoch: 2088 [81920/90000 (91%)]	Loss: -6.5367	Cost: 5.99s
Train Epoch: 2088 	Average Loss: -7.0836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6945

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2089 [0/90000 (0%)]	Loss: -6.1220	Cost: 23.44s
Train Epoch: 2089 [20480/90000 (23%)]	Loss: -6.4856	Cost: 6.12s
Train Epoch: 2089 [40960/90000 (45%)]	Loss: -6.2811	Cost: 8.18s
Train Epoch: 2089 [61440/90000 (68%)]	Loss: -7.1175	Cost: 5.86s
Train Epoch: 2089 [81920/90000 (91%)]	Loss: -6.7675	Cost: 6.26s
Train Epoch: 2089 	Average Loss: -7.0256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6532

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2090 [0/90000 (0%)]	Loss: -6.3258	Cost: 23.48s
Train Epoch: 2090 [20480/90000 (23%)]	Loss: -6.4125	Cost: 6.09s
Train Epoch: 2090 [40960/90000 (45%)]	Loss: -6.5030	Cost: 7.93s
Train Epoch: 2090 [61440/90000 (68%)]	Loss: -7.0462	Cost: 5.85s
Train Epoch: 2090 [81920/90000 (91%)]	Loss: -6.7894	Cost: 6.04s
Train Epoch: 2090 	Average Loss: -7.0331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6644

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2091 [0/90000 (0%)]	Loss: -6.6727	Cost: 23.96s
Train Epoch: 2091 [20480/90000 (23%)]	Loss: -6.5583	Cost: 6.11s
Train Epoch: 2091 [40960/90000 (45%)]	Loss: -6.4264	Cost: 8.07s
Train Epoch: 2091 [61440/90000 (68%)]	Loss: -6.9942	Cost: 5.86s
Train Epoch: 2091 [81920/90000 (91%)]	Loss: -6.7345	Cost: 6.18s
Train Epoch: 2091 	Average Loss: -7.0496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6140

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2092 [0/90000 (0%)]	Loss: -7.9882	Cost: 24.13s
Train Epoch: 2092 [20480/90000 (23%)]	Loss: -6.3704	Cost: 6.07s
Train Epoch: 2092 [40960/90000 (45%)]	Loss: -6.2760	Cost: 7.86s
Train Epoch: 2092 [61440/90000 (68%)]	Loss: -6.9588	Cost: 5.86s
Train Epoch: 2092 [81920/90000 (91%)]	Loss: -6.6793	Cost: 6.16s
Train Epoch: 2092 	Average Loss: -7.1018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6866

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2093 [0/90000 (0%)]	Loss: -7.1867	Cost: 23.37s
Train Epoch: 2093 [20480/90000 (23%)]	Loss: -6.5331	Cost: 6.10s
Train Epoch: 2093 [40960/90000 (45%)]	Loss: -6.4474	Cost: 7.76s
Train Epoch: 2093 [61440/90000 (68%)]	Loss: -6.9211	Cost: 5.87s
Train Epoch: 2093 [81920/90000 (91%)]	Loss: -6.6978	Cost: 6.21s
Train Epoch: 2093 	Average Loss: -7.0438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7571

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2094 [0/90000 (0%)]	Loss: -5.9183	Cost: 23.75s
Train Epoch: 2094 [20480/90000 (23%)]	Loss: -6.5844	Cost: 6.11s
Train Epoch: 2094 [40960/90000 (45%)]	Loss: -6.3336	Cost: 7.90s
Train Epoch: 2094 [61440/90000 (68%)]	Loss: -6.9837	Cost: 5.84s
Train Epoch: 2094 [81920/90000 (91%)]	Loss: -6.7300	Cost: 6.05s
Train Epoch: 2094 	Average Loss: -6.9856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7580

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2095 [0/90000 (0%)]	Loss: -8.1586	Cost: 23.35s
Train Epoch: 2095 [20480/90000 (23%)]	Loss: -6.4582	Cost: 6.07s
Train Epoch: 2095 [40960/90000 (45%)]	Loss: -6.3471	Cost: 8.02s
Train Epoch: 2095 [61440/90000 (68%)]	Loss: -6.9028	Cost: 5.90s
Train Epoch: 2095 [81920/90000 (91%)]	Loss: -6.7692	Cost: 6.22s
Train Epoch: 2095 	Average Loss: -7.0862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6581

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2096 [0/90000 (0%)]	Loss: -7.9792	Cost: 23.30s
Train Epoch: 2096 [20480/90000 (23%)]	Loss: -6.4870	Cost: 6.18s
Train Epoch: 2096 [40960/90000 (45%)]	Loss: -6.5009	Cost: 7.94s
Train Epoch: 2096 [61440/90000 (68%)]	Loss: -6.9939	Cost: 5.91s
Train Epoch: 2096 [81920/90000 (91%)]	Loss: -6.6010	Cost: 6.13s
Train Epoch: 2096 	Average Loss: -7.0692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7834

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2097 [0/90000 (0%)]	Loss: -7.7265	Cost: 23.51s
Train Epoch: 2097 [20480/90000 (23%)]	Loss: -6.4937	Cost: 6.10s
Train Epoch: 2097 [40960/90000 (45%)]	Loss: -6.5044	Cost: 7.74s
Train Epoch: 2097 [61440/90000 (68%)]	Loss: -7.0883	Cost: 6.02s
Train Epoch: 2097 [81920/90000 (91%)]	Loss: -6.6674	Cost: 5.89s
Train Epoch: 2097 	Average Loss: -7.0668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6720

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2098 [0/90000 (0%)]	Loss: -4.9035	Cost: 23.99s
Train Epoch: 2098 [20480/90000 (23%)]	Loss: -6.4827	Cost: 6.09s
Train Epoch: 2098 [40960/90000 (45%)]	Loss: -6.4484	Cost: 7.85s
Train Epoch: 2098 [61440/90000 (68%)]	Loss: -6.9770	Cost: 5.89s
Train Epoch: 2098 [81920/90000 (91%)]	Loss: -6.8036	Cost: 6.28s
Train Epoch: 2098 	Average Loss: -6.9692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7936

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2099 [0/90000 (0%)]	Loss: -6.8527	Cost: 23.31s
Train Epoch: 2099 [20480/90000 (23%)]	Loss: -6.5347	Cost: 6.12s
Train Epoch: 2099 [40960/90000 (45%)]	Loss: -6.2169	Cost: 8.09s
Train Epoch: 2099 [61440/90000 (68%)]	Loss: -7.1420	Cost: 5.83s
Train Epoch: 2099 [81920/90000 (91%)]	Loss: -6.8228	Cost: 6.22s
Train Epoch: 2099 	Average Loss: -7.0421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8088

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2100 [0/90000 (0%)]	Loss: -7.5346	Cost: 23.59s
Train Epoch: 2100 [20480/90000 (23%)]	Loss: -6.5930	Cost: 6.10s
Train Epoch: 2100 [40960/90000 (45%)]	Loss: -6.4070	Cost: 8.30s
Train Epoch: 2100 [61440/90000 (68%)]	Loss: -7.0313	Cost: 5.85s
Train Epoch: 2100 [81920/90000 (91%)]	Loss: -6.7337	Cost: 6.08s
Train Epoch: 2100 	Average Loss: -7.0362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6307

Saving model as model.pt_e2100 & waveforms_supplementary.hdf5_e2100
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2101 [0/90000 (0%)]	Loss: -5.8583	Cost: 23.43s
Train Epoch: 2101 [20480/90000 (23%)]	Loss: -6.4835	Cost: 6.14s
Train Epoch: 2101 [40960/90000 (45%)]	Loss: -6.3713	Cost: 8.03s
Train Epoch: 2101 [61440/90000 (68%)]	Loss: -6.9834	Cost: 5.82s
Train Epoch: 2101 [81920/90000 (91%)]	Loss: -6.6600	Cost: 6.18s
Train Epoch: 2101 	Average Loss: -7.0478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7879

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2102 [0/90000 (0%)]	Loss: -5.9875	Cost: 23.91s
Train Epoch: 2102 [20480/90000 (23%)]	Loss: -6.4102	Cost: 6.11s
Train Epoch: 2102 [40960/90000 (45%)]	Loss: -6.3349	Cost: 8.19s
Train Epoch: 2102 [61440/90000 (68%)]	Loss: -6.9716	Cost: 5.85s
Train Epoch: 2102 [81920/90000 (91%)]	Loss: -6.6943	Cost: 6.18s
Train Epoch: 2102 	Average Loss: -7.0115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6752

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2103 [0/90000 (0%)]	Loss: -7.0261	Cost: 23.36s
Train Epoch: 2103 [20480/90000 (23%)]	Loss: -6.5513	Cost: 6.04s
Train Epoch: 2103 [40960/90000 (45%)]	Loss: -6.4160	Cost: 7.88s
Train Epoch: 2103 [61440/90000 (68%)]	Loss: -6.9285	Cost: 5.82s
Train Epoch: 2103 [81920/90000 (91%)]	Loss: -6.7431	Cost: 6.14s
Train Epoch: 2103 	Average Loss: -7.0342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7934

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2104 [0/90000 (0%)]	Loss: -7.8492	Cost: 24.06s
Train Epoch: 2104 [20480/90000 (23%)]	Loss: -6.5235	Cost: 6.10s
Train Epoch: 2104 [40960/90000 (45%)]	Loss: -6.4111	Cost: 7.95s
Train Epoch: 2104 [61440/90000 (68%)]	Loss: -7.1017	Cost: 5.94s
Train Epoch: 2104 [81920/90000 (91%)]	Loss: -6.7243	Cost: 5.96s
Train Epoch: 2104 	Average Loss: -7.0431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8709

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2105 [0/90000 (0%)]	Loss: -6.7808	Cost: 24.23s
Train Epoch: 2105 [20480/90000 (23%)]	Loss: -6.5903	Cost: 6.07s
Train Epoch: 2105 [40960/90000 (45%)]	Loss: -6.5805	Cost: 7.95s
Train Epoch: 2105 [61440/90000 (68%)]	Loss: -6.9618	Cost: 5.90s
Train Epoch: 2105 [81920/90000 (91%)]	Loss: -6.6231	Cost: 6.09s
Train Epoch: 2105 	Average Loss: -7.0042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8344

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2106 [0/90000 (0%)]	Loss: -7.0007	Cost: 23.39s
Train Epoch: 2106 [20480/90000 (23%)]	Loss: -6.5423	Cost: 6.12s
Train Epoch: 2106 [40960/90000 (45%)]	Loss: -6.4396	Cost: 8.09s
Train Epoch: 2106 [61440/90000 (68%)]	Loss: -6.9683	Cost: 5.96s
Train Epoch: 2106 [81920/90000 (91%)]	Loss: -6.8353	Cost: 6.42s
Train Epoch: 2106 	Average Loss: -7.0676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7100

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2107 [0/90000 (0%)]	Loss: -7.0923	Cost: 23.70s
Train Epoch: 2107 [20480/90000 (23%)]	Loss: -6.4762	Cost: 6.02s
Train Epoch: 2107 [40960/90000 (45%)]	Loss: -6.4426	Cost: 8.04s
Train Epoch: 2107 [61440/90000 (68%)]	Loss: -7.0567	Cost: 5.83s
Train Epoch: 2107 [81920/90000 (91%)]	Loss: -6.7073	Cost: 5.91s
Train Epoch: 2107 	Average Loss: -7.0580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9136

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2108 [0/90000 (0%)]	Loss: -7.2602	Cost: 23.69s
Train Epoch: 2108 [20480/90000 (23%)]	Loss: -6.4249	Cost: 6.11s
Train Epoch: 2108 [40960/90000 (45%)]	Loss: -6.4965	Cost: 8.07s
Train Epoch: 2108 [61440/90000 (68%)]	Loss: -6.9623	Cost: 5.87s
Train Epoch: 2108 [81920/90000 (91%)]	Loss: -6.7379	Cost: 6.37s
Train Epoch: 2108 	Average Loss: -7.0892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8077

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2109 [0/90000 (0%)]	Loss: -6.1527	Cost: 23.24s
Train Epoch: 2109 [20480/90000 (23%)]	Loss: -6.3647	Cost: 6.10s
Train Epoch: 2109 [40960/90000 (45%)]	Loss: -6.3180	Cost: 8.22s
Train Epoch: 2109 [61440/90000 (68%)]	Loss: -6.8887	Cost: 5.84s
Train Epoch: 2109 [81920/90000 (91%)]	Loss: -6.5879	Cost: 6.37s
Train Epoch: 2109 	Average Loss: -7.0169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6723

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2110 [0/90000 (0%)]	Loss: -5.7766	Cost: 23.84s
Train Epoch: 2110 [20480/90000 (23%)]	Loss: -6.3522	Cost: 6.05s
Train Epoch: 2110 [40960/90000 (45%)]	Loss: -6.4918	Cost: 8.28s
Train Epoch: 2110 [61440/90000 (68%)]	Loss: -7.0299	Cost: 5.81s
Train Epoch: 2110 [81920/90000 (91%)]	Loss: -6.8694	Cost: 6.03s
Train Epoch: 2110 	Average Loss: -6.9881
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6817

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2111 [0/90000 (0%)]	Loss: -8.1972	Cost: 23.27s
Train Epoch: 2111 [20480/90000 (23%)]	Loss: -6.4008	Cost: 6.03s
Train Epoch: 2111 [40960/90000 (45%)]	Loss: -6.4826	Cost: 7.99s
Train Epoch: 2111 [61440/90000 (68%)]	Loss: -7.0489	Cost: 5.94s
Train Epoch: 2111 [81920/90000 (91%)]	Loss: -6.6939	Cost: 5.80s
Train Epoch: 2111 	Average Loss: -7.1178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5926

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2112 [0/90000 (0%)]	Loss: -7.6888	Cost: 23.24s
Train Epoch: 2112 [20480/90000 (23%)]	Loss: -6.6449	Cost: 6.18s
Train Epoch: 2112 [40960/90000 (45%)]	Loss: -6.3728	Cost: 7.80s
Train Epoch: 2112 [61440/90000 (68%)]	Loss: -7.0559	Cost: 5.90s
Train Epoch: 2112 [81920/90000 (91%)]	Loss: -6.6767	Cost: 6.29s
Train Epoch: 2112 	Average Loss: -7.0662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6874

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2113 [0/90000 (0%)]	Loss: -6.8769	Cost: 23.56s
Train Epoch: 2113 [20480/90000 (23%)]	Loss: -6.5526	Cost: 6.17s
Train Epoch: 2113 [40960/90000 (45%)]	Loss: -6.4093	Cost: 7.66s
Train Epoch: 2113 [61440/90000 (68%)]	Loss: -7.2284	Cost: 5.91s
Train Epoch: 2113 [81920/90000 (91%)]	Loss: -6.8357	Cost: 6.07s
Train Epoch: 2113 	Average Loss: -7.0518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6628

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2114 [0/90000 (0%)]	Loss: -6.7471	Cost: 24.42s
Train Epoch: 2114 [20480/90000 (23%)]	Loss: -6.4902	Cost: 6.08s
Train Epoch: 2114 [40960/90000 (45%)]	Loss: -6.3538	Cost: 7.85s
Train Epoch: 2114 [61440/90000 (68%)]	Loss: -6.8873	Cost: 5.84s
Train Epoch: 2114 [81920/90000 (91%)]	Loss: -6.6978	Cost: 6.28s
Train Epoch: 2114 	Average Loss: -7.0513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5877

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2115 [0/90000 (0%)]	Loss: -7.8139	Cost: 23.78s
Train Epoch: 2115 [20480/90000 (23%)]	Loss: -6.4686	Cost: 6.11s
Train Epoch: 2115 [40960/90000 (45%)]	Loss: -6.3248	Cost: 7.85s
Train Epoch: 2115 [61440/90000 (68%)]	Loss: -6.9255	Cost: 5.94s
Train Epoch: 2115 [81920/90000 (91%)]	Loss: -6.6500	Cost: 5.90s
Train Epoch: 2115 	Average Loss: -7.0270
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7345

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2116 [0/90000 (0%)]	Loss: -6.2861	Cost: 23.55s
Train Epoch: 2116 [20480/90000 (23%)]	Loss: -6.5829	Cost: 6.14s
Train Epoch: 2116 [40960/90000 (45%)]	Loss: -6.4446	Cost: 8.03s
Train Epoch: 2116 [61440/90000 (68%)]	Loss: -7.0402	Cost: 5.88s
Train Epoch: 2116 [81920/90000 (91%)]	Loss: -6.6621	Cost: 5.93s
Train Epoch: 2116 	Average Loss: -6.9578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7279

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2117 [0/90000 (0%)]	Loss: -7.0709	Cost: 24.31s
Train Epoch: 2117 [20480/90000 (23%)]	Loss: -6.5332	Cost: 6.11s
Train Epoch: 2117 [40960/90000 (45%)]	Loss: -6.4832	Cost: 8.06s
Train Epoch: 2117 [61440/90000 (68%)]	Loss: -6.9741	Cost: 5.85s
Train Epoch: 2117 [81920/90000 (91%)]	Loss: -6.6594	Cost: 6.13s
Train Epoch: 2117 	Average Loss: -6.9873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7985

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2118 [0/90000 (0%)]	Loss: -6.6229	Cost: 23.44s
Train Epoch: 2118 [20480/90000 (23%)]	Loss: -6.7089	Cost: 6.06s
Train Epoch: 2118 [40960/90000 (45%)]	Loss: -6.4524	Cost: 7.83s
Train Epoch: 2118 [61440/90000 (68%)]	Loss: -7.0349	Cost: 5.91s
Train Epoch: 2118 [81920/90000 (91%)]	Loss: -6.9112	Cost: 6.18s
Train Epoch: 2118 	Average Loss: -7.0144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7210

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2119 [0/90000 (0%)]	Loss: -6.4801	Cost: 23.88s
Train Epoch: 2119 [20480/90000 (23%)]	Loss: -6.4815	Cost: 6.13s
Train Epoch: 2119 [40960/90000 (45%)]	Loss: -6.4359	Cost: 7.97s
Train Epoch: 2119 [61440/90000 (68%)]	Loss: -7.2003	Cost: 6.42s
Train Epoch: 2119 [81920/90000 (91%)]	Loss: -6.7009	Cost: 5.74s
Train Epoch: 2119 	Average Loss: -7.0092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6933

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2120 [0/90000 (0%)]	Loss: -6.5754	Cost: 24.17s
Train Epoch: 2120 [20480/90000 (23%)]	Loss: -6.5071	Cost: 6.07s
Train Epoch: 2120 [40960/90000 (45%)]	Loss: -6.2946	Cost: 7.81s
Train Epoch: 2120 [61440/90000 (68%)]	Loss: -6.8885	Cost: 5.88s
Train Epoch: 2120 [81920/90000 (91%)]	Loss: -6.8091	Cost: 6.40s
Train Epoch: 2120 	Average Loss: -7.0326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7949

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2121 [0/90000 (0%)]	Loss: -8.2341	Cost: 23.67s
Train Epoch: 2121 [20480/90000 (23%)]	Loss: -6.5633	Cost: 6.09s
Train Epoch: 2121 [40960/90000 (45%)]	Loss: -6.3124	Cost: 8.30s
Train Epoch: 2121 [61440/90000 (68%)]	Loss: -7.0505	Cost: 5.99s
Train Epoch: 2121 [81920/90000 (91%)]	Loss: -6.5990	Cost: 5.91s
Train Epoch: 2121 	Average Loss: -7.0670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5784

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2122 [0/90000 (0%)]	Loss: -7.4203	Cost: 23.95s
Train Epoch: 2122 [20480/90000 (23%)]	Loss: -6.3083	Cost: 6.07s
Train Epoch: 2122 [40960/90000 (45%)]	Loss: -6.4488	Cost: 7.98s
Train Epoch: 2122 [61440/90000 (68%)]	Loss: -6.9658	Cost: 5.83s
Train Epoch: 2122 [81920/90000 (91%)]	Loss: -6.6425	Cost: 6.12s
Train Epoch: 2122 	Average Loss: -7.1000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5594

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2123 [0/90000 (0%)]	Loss: -7.6574	Cost: 23.61s
Train Epoch: 2123 [20480/90000 (23%)]	Loss: -6.4278	Cost: 6.06s
Train Epoch: 2123 [40960/90000 (45%)]	Loss: -6.3925	Cost: 8.22s
Train Epoch: 2123 [61440/90000 (68%)]	Loss: -7.0562	Cost: 5.85s
Train Epoch: 2123 [81920/90000 (91%)]	Loss: -6.7543	Cost: 6.25s
Train Epoch: 2123 	Average Loss: -7.0841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8385

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2124 [0/90000 (0%)]	Loss: -7.2786	Cost: 23.85s
Train Epoch: 2124 [20480/90000 (23%)]	Loss: -6.5539	Cost: 6.05s
Train Epoch: 2124 [40960/90000 (45%)]	Loss: -6.4467	Cost: 7.88s
Train Epoch: 2124 [61440/90000 (68%)]	Loss: -7.1046	Cost: 5.84s
Train Epoch: 2124 [81920/90000 (91%)]	Loss: -6.6734	Cost: 6.53s
Train Epoch: 2124 	Average Loss: -7.0764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6693

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2125 [0/90000 (0%)]	Loss: -5.4550	Cost: 23.20s
Train Epoch: 2125 [20480/90000 (23%)]	Loss: -6.5599	Cost: 6.17s
Train Epoch: 2125 [40960/90000 (45%)]	Loss: -6.4194	Cost: 7.85s
Train Epoch: 2125 [61440/90000 (68%)]	Loss: -6.8777	Cost: 5.94s
Train Epoch: 2125 [81920/90000 (91%)]	Loss: -6.6108	Cost: 6.34s
Train Epoch: 2125 	Average Loss: -7.0362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6080

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2126 [0/90000 (0%)]	Loss: -7.3967	Cost: 23.42s
Train Epoch: 2126 [20480/90000 (23%)]	Loss: -6.4686	Cost: 6.12s
Train Epoch: 2126 [40960/90000 (45%)]	Loss: -6.3846	Cost: 7.88s
Train Epoch: 2126 [61440/90000 (68%)]	Loss: -6.9419	Cost: 5.90s
Train Epoch: 2126 [81920/90000 (91%)]	Loss: -6.9354	Cost: 6.04s
Train Epoch: 2126 	Average Loss: -7.0483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7330

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2127 [0/90000 (0%)]	Loss: -6.7878	Cost: 23.81s
Train Epoch: 2127 [20480/90000 (23%)]	Loss: -6.3775	Cost: 6.37s
Train Epoch: 2127 [40960/90000 (45%)]	Loss: -6.4641	Cost: 7.62s
Train Epoch: 2127 [61440/90000 (68%)]	Loss: -6.9822	Cost: 5.84s
Train Epoch: 2127 [81920/90000 (91%)]	Loss: -6.7707	Cost: 6.15s
Train Epoch: 2127 	Average Loss: -7.0657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6755

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2128 [0/90000 (0%)]	Loss: -7.9083	Cost: 23.17s
Train Epoch: 2128 [20480/90000 (23%)]	Loss: -6.6067	Cost: 6.19s
Train Epoch: 2128 [40960/90000 (45%)]	Loss: -6.2483	Cost: 7.79s
Train Epoch: 2128 [61440/90000 (68%)]	Loss: -6.9870	Cost: 5.87s
Train Epoch: 2128 [81920/90000 (91%)]	Loss: -6.7080	Cost: 6.08s
Train Epoch: 2128 	Average Loss: -7.0363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7798

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2129 [0/90000 (0%)]	Loss: -5.7474	Cost: 24.05s
Train Epoch: 2129 [20480/90000 (23%)]	Loss: -6.4439	Cost: 6.17s
Train Epoch: 2129 [40960/90000 (45%)]	Loss: -6.3757	Cost: 7.91s
Train Epoch: 2129 [61440/90000 (68%)]	Loss: -6.8450	Cost: 5.83s
Train Epoch: 2129 [81920/90000 (91%)]	Loss: -6.6582	Cost: 6.06s
Train Epoch: 2129 	Average Loss: -7.0744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8064

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2130 [0/90000 (0%)]	Loss: -7.1571	Cost: 23.20s
Train Epoch: 2130 [20480/90000 (23%)]	Loss: -6.5197	Cost: 6.07s
Train Epoch: 2130 [40960/90000 (45%)]	Loss: -6.4768	Cost: 7.88s
Train Epoch: 2130 [61440/90000 (68%)]	Loss: -6.8487	Cost: 5.86s
Train Epoch: 2130 [81920/90000 (91%)]	Loss: -6.6479	Cost: 6.07s
Train Epoch: 2130 	Average Loss: -7.0199
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7423

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2131 [0/90000 (0%)]	Loss: -7.5009	Cost: 24.35s
Train Epoch: 2131 [20480/90000 (23%)]	Loss: -6.4789	Cost: 6.08s
Train Epoch: 2131 [40960/90000 (45%)]	Loss: -6.5286	Cost: 7.80s
Train Epoch: 2131 [61440/90000 (68%)]	Loss: -7.0931	Cost: 5.85s
Train Epoch: 2131 [81920/90000 (91%)]	Loss: -6.5424	Cost: 5.97s
Train Epoch: 2131 	Average Loss: -7.0671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7383

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2132 [0/90000 (0%)]	Loss: -7.2198	Cost: 23.97s
Train Epoch: 2132 [20480/90000 (23%)]	Loss: -6.7022	Cost: 6.01s
Train Epoch: 2132 [40960/90000 (45%)]	Loss: -6.4007	Cost: 8.21s
Train Epoch: 2132 [61440/90000 (68%)]	Loss: -6.8681	Cost: 5.92s
Train Epoch: 2132 [81920/90000 (91%)]	Loss: -6.6884	Cost: 5.91s
Train Epoch: 2132 	Average Loss: -7.0217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8261

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2133 [0/90000 (0%)]	Loss: -4.9069	Cost: 23.26s
Train Epoch: 2133 [20480/90000 (23%)]	Loss: -6.6598	Cost: 6.20s
Train Epoch: 2133 [40960/90000 (45%)]	Loss: -6.3435	Cost: 7.68s
Train Epoch: 2133 [61440/90000 (68%)]	Loss: -6.9204	Cost: 5.94s
Train Epoch: 2133 [81920/90000 (91%)]	Loss: -6.7128	Cost: 6.06s
Train Epoch: 2133 	Average Loss: -6.9071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5281

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2134 [0/90000 (0%)]	Loss: -6.9929	Cost: 23.79s
Train Epoch: 2134 [20480/90000 (23%)]	Loss: -6.4672	Cost: 6.19s
Train Epoch: 2134 [40960/90000 (45%)]	Loss: -6.4476	Cost: 7.72s
Train Epoch: 2134 [61440/90000 (68%)]	Loss: -6.9579	Cost: 5.88s
Train Epoch: 2134 [81920/90000 (91%)]	Loss: -6.6752	Cost: 5.88s
Train Epoch: 2134 	Average Loss: -7.0346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6683

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2135 [0/90000 (0%)]	Loss: -7.8173	Cost: 25.07s
Train Epoch: 2135 [20480/90000 (23%)]	Loss: -6.5042	Cost: 5.94s
Train Epoch: 2135 [40960/90000 (45%)]	Loss: -6.5969	Cost: 7.64s
Train Epoch: 2135 [61440/90000 (68%)]	Loss: -7.0529	Cost: 5.88s
Train Epoch: 2135 [81920/90000 (91%)]	Loss: -6.8656	Cost: 6.20s
Train Epoch: 2135 	Average Loss: -7.0715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7332

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2136 [0/90000 (0%)]	Loss: -5.5873	Cost: 23.34s
Train Epoch: 2136 [20480/90000 (23%)]	Loss: -6.4995	Cost: 6.05s
Train Epoch: 2136 [40960/90000 (45%)]	Loss: -6.3296	Cost: 8.17s
Train Epoch: 2136 [61440/90000 (68%)]	Loss: -7.1121	Cost: 6.00s
Train Epoch: 2136 [81920/90000 (91%)]	Loss: -6.8683	Cost: 6.03s
Train Epoch: 2136 	Average Loss: -7.0348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6151

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2137 [0/90000 (0%)]	Loss: -8.1400	Cost: 23.40s
Train Epoch: 2137 [20480/90000 (23%)]	Loss: -6.3783	Cost: 6.17s
Train Epoch: 2137 [40960/90000 (45%)]	Loss: -6.3376	Cost: 7.76s
Train Epoch: 2137 [61440/90000 (68%)]	Loss: -7.0471	Cost: 5.84s
Train Epoch: 2137 [81920/90000 (91%)]	Loss: -6.6759	Cost: 6.42s
Train Epoch: 2137 	Average Loss: -7.1263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7154

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2138 [0/90000 (0%)]	Loss: -7.2443	Cost: 24.34s
Train Epoch: 2138 [20480/90000 (23%)]	Loss: -6.4611	Cost: 6.07s
Train Epoch: 2138 [40960/90000 (45%)]	Loss: -6.4384	Cost: 8.09s
Train Epoch: 2138 [61440/90000 (68%)]	Loss: -7.0678	Cost: 5.88s
Train Epoch: 2138 [81920/90000 (91%)]	Loss: -6.7539	Cost: 6.11s
Train Epoch: 2138 	Average Loss: -7.0381
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7901

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2139 [0/90000 (0%)]	Loss: -7.7597	Cost: 23.75s
Train Epoch: 2139 [20480/90000 (23%)]	Loss: -6.4756	Cost: 6.12s
Train Epoch: 2139 [40960/90000 (45%)]	Loss: -6.3379	Cost: 7.91s
Train Epoch: 2139 [61440/90000 (68%)]	Loss: -6.9841	Cost: 5.83s
Train Epoch: 2139 [81920/90000 (91%)]	Loss: -6.7455	Cost: 6.35s
Train Epoch: 2139 	Average Loss: -7.0775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7576

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2140 [0/90000 (0%)]	Loss: -8.5488	Cost: 23.41s
Train Epoch: 2140 [20480/90000 (23%)]	Loss: -6.4511	Cost: 6.10s
Train Epoch: 2140 [40960/90000 (45%)]	Loss: -6.4781	Cost: 8.20s
Train Epoch: 2140 [61440/90000 (68%)]	Loss: -7.1751	Cost: 5.83s
Train Epoch: 2140 [81920/90000 (91%)]	Loss: -6.7869	Cost: 6.31s
Train Epoch: 2140 	Average Loss: -7.1049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7210

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2141 [0/90000 (0%)]	Loss: -8.2949	Cost: 23.90s
Train Epoch: 2141 [20480/90000 (23%)]	Loss: -6.4836	Cost: 6.14s
Train Epoch: 2141 [40960/90000 (45%)]	Loss: -6.2783	Cost: 7.60s
Train Epoch: 2141 [61440/90000 (68%)]	Loss: -6.8218	Cost: 5.88s
Train Epoch: 2141 [81920/90000 (91%)]	Loss: -6.7559	Cost: 6.23s
Train Epoch: 2141 	Average Loss: -7.0339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7094

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2142 [0/90000 (0%)]	Loss: -7.8548	Cost: 23.75s
Train Epoch: 2142 [20480/90000 (23%)]	Loss: -6.5599	Cost: 6.20s
Train Epoch: 2142 [40960/90000 (45%)]	Loss: -6.3311	Cost: 8.04s
Train Epoch: 2142 [61440/90000 (68%)]	Loss: -7.0038	Cost: 5.85s
Train Epoch: 2142 [81920/90000 (91%)]	Loss: -6.6583	Cost: 6.31s
Train Epoch: 2142 	Average Loss: -6.9897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7222

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2143 [0/90000 (0%)]	Loss: -7.9769	Cost: 23.75s
Train Epoch: 2143 [20480/90000 (23%)]	Loss: -6.5453	Cost: 6.16s
Train Epoch: 2143 [40960/90000 (45%)]	Loss: -6.4946	Cost: 7.56s
Train Epoch: 2143 [61440/90000 (68%)]	Loss: -6.9602	Cost: 5.95s
Train Epoch: 2143 [81920/90000 (91%)]	Loss: -6.6205	Cost: 6.02s
Train Epoch: 2143 	Average Loss: -7.0348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6723

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2144 [0/90000 (0%)]	Loss: -7.2625	Cost: 23.89s
Train Epoch: 2144 [20480/90000 (23%)]	Loss: -6.5832	Cost: 6.28s
Train Epoch: 2144 [40960/90000 (45%)]	Loss: -6.6026	Cost: 7.69s
Train Epoch: 2144 [61440/90000 (68%)]	Loss: -7.0096	Cost: 5.90s
Train Epoch: 2144 [81920/90000 (91%)]	Loss: -6.6868	Cost: 6.31s
Train Epoch: 2144 	Average Loss: -7.0582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6583

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2145 [0/90000 (0%)]	Loss: -6.6573	Cost: 23.63s
Train Epoch: 2145 [20480/90000 (23%)]	Loss: -6.3489	Cost: 6.05s
Train Epoch: 2145 [40960/90000 (45%)]	Loss: -6.5399	Cost: 8.09s
Train Epoch: 2145 [61440/90000 (68%)]	Loss: -7.0599	Cost: 5.87s
Train Epoch: 2145 [81920/90000 (91%)]	Loss: -6.7540	Cost: 6.05s
Train Epoch: 2145 	Average Loss: -7.0233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5002

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2146 [0/90000 (0%)]	Loss: -7.5592	Cost: 24.49s
Train Epoch: 2146 [20480/90000 (23%)]	Loss: -6.6289	Cost: 6.08s
Train Epoch: 2146 [40960/90000 (45%)]	Loss: -6.4695	Cost: 7.77s
Train Epoch: 2146 [61440/90000 (68%)]	Loss: -7.0795	Cost: 5.86s
Train Epoch: 2146 [81920/90000 (91%)]	Loss: -6.4737	Cost: 6.28s
Train Epoch: 2146 	Average Loss: -7.0525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8145

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2147 [0/90000 (0%)]	Loss: -8.2295	Cost: 23.80s
Train Epoch: 2147 [20480/90000 (23%)]	Loss: -6.4384	Cost: 6.07s
Train Epoch: 2147 [40960/90000 (45%)]	Loss: -6.4075	Cost: 7.99s
Train Epoch: 2147 [61440/90000 (68%)]	Loss: -6.8315	Cost: 5.83s
Train Epoch: 2147 [81920/90000 (91%)]	Loss: -6.7752	Cost: 6.16s
Train Epoch: 2147 	Average Loss: -7.1115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6523

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2148 [0/90000 (0%)]	Loss: -5.5013	Cost: 23.70s
Train Epoch: 2148 [20480/90000 (23%)]	Loss: -6.6151	Cost: 6.19s
Train Epoch: 2148 [40960/90000 (45%)]	Loss: -6.4923	Cost: 7.79s
Train Epoch: 2148 [61440/90000 (68%)]	Loss: -7.0818	Cost: 5.88s
Train Epoch: 2148 [81920/90000 (91%)]	Loss: -6.7240	Cost: 6.37s
Train Epoch: 2148 	Average Loss: -7.0357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6817

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2149 [0/90000 (0%)]	Loss: -7.2903	Cost: 23.40s
Train Epoch: 2149 [20480/90000 (23%)]	Loss: -6.5034	Cost: 6.07s
Train Epoch: 2149 [40960/90000 (45%)]	Loss: -6.4004	Cost: 7.92s
Train Epoch: 2149 [61440/90000 (68%)]	Loss: -6.8829	Cost: 6.07s
Train Epoch: 2149 [81920/90000 (91%)]	Loss: -6.6735	Cost: 5.89s
Train Epoch: 2149 	Average Loss: -7.0382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8149

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2150 [0/90000 (0%)]	Loss: -7.0707	Cost: 23.44s
Train Epoch: 2150 [20480/90000 (23%)]	Loss: -6.5776	Cost: 6.15s
Train Epoch: 2150 [40960/90000 (45%)]	Loss: -6.2582	Cost: 8.22s
Train Epoch: 2150 [61440/90000 (68%)]	Loss: -6.9907	Cost: 6.02s
Train Epoch: 2150 [81920/90000 (91%)]	Loss: -6.6683	Cost: 6.17s
Train Epoch: 2150 	Average Loss: -7.0760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8463

Saving model as model.pt_e2150 & waveforms_supplementary.hdf5_e2150
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2151 [0/90000 (0%)]	Loss: -5.8417	Cost: 23.30s
Train Epoch: 2151 [20480/90000 (23%)]	Loss: -6.4535	Cost: 6.13s
Train Epoch: 2151 [40960/90000 (45%)]	Loss: -6.2675	Cost: 7.84s
Train Epoch: 2151 [61440/90000 (68%)]	Loss: -7.1634	Cost: 5.95s
Train Epoch: 2151 [81920/90000 (91%)]	Loss: -6.7140	Cost: 6.55s
Train Epoch: 2151 	Average Loss: -7.0248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6851

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2152 [0/90000 (0%)]	Loss: -7.4161	Cost: 24.15s
Train Epoch: 2152 [20480/90000 (23%)]	Loss: -6.4448	Cost: 6.11s
Train Epoch: 2152 [40960/90000 (45%)]	Loss: -6.3617	Cost: 7.95s
Train Epoch: 2152 [61440/90000 (68%)]	Loss: -6.8839	Cost: 5.87s
Train Epoch: 2152 [81920/90000 (91%)]	Loss: -6.7270	Cost: 6.08s
Train Epoch: 2152 	Average Loss: -6.9950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8282

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2153 [0/90000 (0%)]	Loss: -6.8447	Cost: 23.50s
Train Epoch: 2153 [20480/90000 (23%)]	Loss: -6.4604	Cost: 6.08s
Train Epoch: 2153 [40960/90000 (45%)]	Loss: -6.3727	Cost: 8.01s
Train Epoch: 2153 [61440/90000 (68%)]	Loss: -6.9298	Cost: 5.83s
Train Epoch: 2153 [81920/90000 (91%)]	Loss: -6.7248	Cost: 6.17s
Train Epoch: 2153 	Average Loss: -6.9620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6276

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2154 [0/90000 (0%)]	Loss: -6.6360	Cost: 24.00s
Train Epoch: 2154 [20480/90000 (23%)]	Loss: -6.5451	Cost: 6.14s
Train Epoch: 2154 [40960/90000 (45%)]	Loss: -6.3556	Cost: 7.79s
Train Epoch: 2154 [61440/90000 (68%)]	Loss: -6.9167	Cost: 5.86s
Train Epoch: 2154 [81920/90000 (91%)]	Loss: -6.5848	Cost: 6.32s
Train Epoch: 2154 	Average Loss: -6.9544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7515

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2155 [0/90000 (0%)]	Loss: -6.7501	Cost: 23.44s
Train Epoch: 2155 [20480/90000 (23%)]	Loss: -6.6062	Cost: 6.05s
Train Epoch: 2155 [40960/90000 (45%)]	Loss: -6.3263	Cost: 7.97s
Train Epoch: 2155 [61440/90000 (68%)]	Loss: -6.9860	Cost: 5.87s
Train Epoch: 2155 [81920/90000 (91%)]	Loss: -6.7759	Cost: 6.03s
Train Epoch: 2155 	Average Loss: -6.9839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7409

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2156 [0/90000 (0%)]	Loss: -7.3287	Cost: 23.16s
Train Epoch: 2156 [20480/90000 (23%)]	Loss: -6.6579	Cost: 6.15s
Train Epoch: 2156 [40960/90000 (45%)]	Loss: -6.6421	Cost: 8.35s
Train Epoch: 2156 [61440/90000 (68%)]	Loss: -7.0027	Cost: 6.50s
Train Epoch: 2156 [81920/90000 (91%)]	Loss: -6.6896	Cost: 6.36s
Train Epoch: 2156 	Average Loss: -7.0090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7199

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2157 [0/90000 (0%)]	Loss: -7.1595	Cost: 23.69s
Train Epoch: 2157 [20480/90000 (23%)]	Loss: -6.4041	Cost: 6.06s
Train Epoch: 2157 [40960/90000 (45%)]	Loss: -6.2556	Cost: 8.03s
Train Epoch: 2157 [61440/90000 (68%)]	Loss: -7.0294	Cost: 5.98s
Train Epoch: 2157 [81920/90000 (91%)]	Loss: -6.5958	Cost: 5.98s
Train Epoch: 2157 	Average Loss: -7.0053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7068

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2158 [0/90000 (0%)]	Loss: -6.5836	Cost: 23.43s
Train Epoch: 2158 [20480/90000 (23%)]	Loss: -6.5269	Cost: 6.15s
Train Epoch: 2158 [40960/90000 (45%)]	Loss: -6.2559	Cost: 8.07s
Train Epoch: 2158 [61440/90000 (68%)]	Loss: -7.0053	Cost: 5.89s
Train Epoch: 2158 [81920/90000 (91%)]	Loss: -6.7309	Cost: 6.49s
Train Epoch: 2158 	Average Loss: -7.0214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6702

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2159 [0/90000 (0%)]	Loss: -7.4751	Cost: 23.70s
Train Epoch: 2159 [20480/90000 (23%)]	Loss: -6.5994	Cost: 6.13s
Train Epoch: 2159 [40960/90000 (45%)]	Loss: -6.2436	Cost: 8.02s
Train Epoch: 2159 [61440/90000 (68%)]	Loss: -7.0690	Cost: 5.83s
Train Epoch: 2159 [81920/90000 (91%)]	Loss: -6.6590	Cost: 6.57s
Train Epoch: 2159 	Average Loss: -7.0324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5610

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2160 [0/90000 (0%)]	Loss: -7.1462	Cost: 23.72s
Train Epoch: 2160 [20480/90000 (23%)]	Loss: -6.3427	Cost: 6.03s
Train Epoch: 2160 [40960/90000 (45%)]	Loss: -6.4670	Cost: 8.13s
Train Epoch: 2160 [61440/90000 (68%)]	Loss: -7.0683	Cost: 5.87s
Train Epoch: 2160 [81920/90000 (91%)]	Loss: -6.7023	Cost: 6.24s
Train Epoch: 2160 	Average Loss: -7.0375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6351

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2161 [0/90000 (0%)]	Loss: -5.8888	Cost: 23.42s
Train Epoch: 2161 [20480/90000 (23%)]	Loss: -6.5772	Cost: 6.07s
Train Epoch: 2161 [40960/90000 (45%)]	Loss: -6.4050	Cost: 8.07s
Train Epoch: 2161 [61440/90000 (68%)]	Loss: -6.9329	Cost: 5.84s
Train Epoch: 2161 [81920/90000 (91%)]	Loss: -6.6633	Cost: 6.13s
Train Epoch: 2161 	Average Loss: -6.9877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7628

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2162 [0/90000 (0%)]	Loss: -7.2738	Cost: 23.74s
Train Epoch: 2162 [20480/90000 (23%)]	Loss: -6.6086	Cost: 6.09s
Train Epoch: 2162 [40960/90000 (45%)]	Loss: -6.4142	Cost: 8.10s
Train Epoch: 2162 [61440/90000 (68%)]	Loss: -6.9230	Cost: 5.86s
Train Epoch: 2162 [81920/90000 (91%)]	Loss: -6.6760	Cost: 6.17s
Train Epoch: 2162 	Average Loss: -7.0613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7281

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2163 [0/90000 (0%)]	Loss: -6.9168	Cost: 24.55s
Train Epoch: 2163 [20480/90000 (23%)]	Loss: -6.5576	Cost: 6.09s
Train Epoch: 2163 [40960/90000 (45%)]	Loss: -6.3414	Cost: 7.39s
Train Epoch: 2163 [61440/90000 (68%)]	Loss: -7.0474	Cost: 5.90s
Train Epoch: 2163 [81920/90000 (91%)]	Loss: -6.6781	Cost: 6.24s
Train Epoch: 2163 	Average Loss: -7.0588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6794

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2164 [0/90000 (0%)]	Loss: -5.7212	Cost: 23.56s
Train Epoch: 2164 [20480/90000 (23%)]	Loss: -6.6306	Cost: 6.10s
Train Epoch: 2164 [40960/90000 (45%)]	Loss: -6.1271	Cost: 7.90s
Train Epoch: 2164 [61440/90000 (68%)]	Loss: -7.1157	Cost: 6.30s
Train Epoch: 2164 [81920/90000 (91%)]	Loss: -6.7367	Cost: 5.88s
Train Epoch: 2164 	Average Loss: -7.0012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8503

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2165 [0/90000 (0%)]	Loss: -6.7769	Cost: 23.71s
Train Epoch: 2165 [20480/90000 (23%)]	Loss: -6.5743	Cost: 6.13s
Train Epoch: 2165 [40960/90000 (45%)]	Loss: -6.2795	Cost: 8.18s
Train Epoch: 2165 [61440/90000 (68%)]	Loss: -6.8448	Cost: 5.92s
Train Epoch: 2165 [81920/90000 (91%)]	Loss: -6.5407	Cost: 6.14s
Train Epoch: 2165 	Average Loss: -6.9588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6195

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2166 [0/90000 (0%)]	Loss: -7.7204	Cost: 23.38s
Train Epoch: 2166 [20480/90000 (23%)]	Loss: -6.4236	Cost: 6.10s
Train Epoch: 2166 [40960/90000 (45%)]	Loss: -6.3385	Cost: 8.17s
Train Epoch: 2166 [61440/90000 (68%)]	Loss: -7.0725	Cost: 5.89s
Train Epoch: 2166 [81920/90000 (91%)]	Loss: -6.6857	Cost: 6.37s
Train Epoch: 2166 	Average Loss: -7.1198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7026

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2167 [0/90000 (0%)]	Loss: -6.3808	Cost: 24.00s
Train Epoch: 2167 [20480/90000 (23%)]	Loss: -6.4378	Cost: 6.07s
Train Epoch: 2167 [40960/90000 (45%)]	Loss: -6.3458	Cost: 7.98s
Train Epoch: 2167 [61440/90000 (68%)]	Loss: -7.1252	Cost: 5.88s
Train Epoch: 2167 [81920/90000 (91%)]	Loss: -6.6830	Cost: 6.30s
Train Epoch: 2167 	Average Loss: -6.9978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7840

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2168 [0/90000 (0%)]	Loss: -6.0683	Cost: 23.74s
Train Epoch: 2168 [20480/90000 (23%)]	Loss: -6.4197	Cost: 6.05s
Train Epoch: 2168 [40960/90000 (45%)]	Loss: -6.3484	Cost: 8.17s
Train Epoch: 2168 [61440/90000 (68%)]	Loss: -6.9410	Cost: 5.81s
Train Epoch: 2168 [81920/90000 (91%)]	Loss: -6.6186	Cost: 6.38s
Train Epoch: 2168 	Average Loss: -7.0215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7184

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2169 [0/90000 (0%)]	Loss: -5.8488	Cost: 24.37s
Train Epoch: 2169 [20480/90000 (23%)]	Loss: -6.5178	Cost: 6.08s
Train Epoch: 2169 [40960/90000 (45%)]	Loss: -6.3564	Cost: 7.91s
Train Epoch: 2169 [61440/90000 (68%)]	Loss: -7.0548	Cost: 5.88s
Train Epoch: 2169 [81920/90000 (91%)]	Loss: -6.8108	Cost: 6.31s
Train Epoch: 2169 	Average Loss: -7.0283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5963

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2170 [0/90000 (0%)]	Loss: -7.4866	Cost: 23.74s
Train Epoch: 2170 [20480/90000 (23%)]	Loss: -6.5228	Cost: 6.09s
Train Epoch: 2170 [40960/90000 (45%)]	Loss: -6.4121	Cost: 8.05s
Train Epoch: 2170 [61440/90000 (68%)]	Loss: -7.0609	Cost: 5.89s
Train Epoch: 2170 [81920/90000 (91%)]	Loss: -6.7857	Cost: 6.50s
Train Epoch: 2170 	Average Loss: -7.0563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7236

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2171 [0/90000 (0%)]	Loss: -7.6641	Cost: 23.72s
Train Epoch: 2171 [20480/90000 (23%)]	Loss: -6.5800	Cost: 6.13s
Train Epoch: 2171 [40960/90000 (45%)]	Loss: -6.2520	Cost: 8.05s
Train Epoch: 2171 [61440/90000 (68%)]	Loss: -7.0281	Cost: 5.89s
Train Epoch: 2171 [81920/90000 (91%)]	Loss: -6.6987	Cost: 6.25s
Train Epoch: 2171 	Average Loss: -7.0314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7879

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2172 [0/90000 (0%)]	Loss: -7.5922	Cost: 23.94s
Train Epoch: 2172 [20480/90000 (23%)]	Loss: -6.4737	Cost: 6.14s
Train Epoch: 2172 [40960/90000 (45%)]	Loss: -6.3318	Cost: 7.98s
Train Epoch: 2172 [61440/90000 (68%)]	Loss: -6.9575	Cost: 5.91s
Train Epoch: 2172 [81920/90000 (91%)]	Loss: -6.6646	Cost: 6.52s
Train Epoch: 2172 	Average Loss: -7.0196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5917

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2173 [0/90000 (0%)]	Loss: -6.2626	Cost: 23.77s
Train Epoch: 2173 [20480/90000 (23%)]	Loss: -6.3787	Cost: 6.33s
Train Epoch: 2173 [40960/90000 (45%)]	Loss: -6.3798	Cost: 7.88s
Train Epoch: 2173 [61440/90000 (68%)]	Loss: -7.1167	Cost: 5.90s
Train Epoch: 2173 [81920/90000 (91%)]	Loss: -6.6639	Cost: 6.27s
Train Epoch: 2173 	Average Loss: -7.0262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7235

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2174 [0/90000 (0%)]	Loss: -7.0897	Cost: 23.70s
Train Epoch: 2174 [20480/90000 (23%)]	Loss: -6.4032	Cost: 6.13s
Train Epoch: 2174 [40960/90000 (45%)]	Loss: -6.5168	Cost: 7.99s
Train Epoch: 2174 [61440/90000 (68%)]	Loss: -7.0501	Cost: 5.85s
Train Epoch: 2174 [81920/90000 (91%)]	Loss: -6.8298	Cost: 6.57s
Train Epoch: 2174 	Average Loss: -7.0603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8070

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2175 [0/90000 (0%)]	Loss: -5.2740	Cost: 24.04s
Train Epoch: 2175 [20480/90000 (23%)]	Loss: -6.5410	Cost: 6.07s
Train Epoch: 2175 [40960/90000 (45%)]	Loss: -6.3725	Cost: 8.07s
Train Epoch: 2175 [61440/90000 (68%)]	Loss: -6.9766	Cost: 5.91s
Train Epoch: 2175 [81920/90000 (91%)]	Loss: -6.7465	Cost: 6.20s
Train Epoch: 2175 	Average Loss: -7.0199
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8110

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2176 [0/90000 (0%)]	Loss: -7.4112	Cost: 23.67s
Train Epoch: 2176 [20480/90000 (23%)]	Loss: -6.6013	Cost: 6.07s
Train Epoch: 2176 [40960/90000 (45%)]	Loss: -6.5132	Cost: 7.98s
Train Epoch: 2176 [61440/90000 (68%)]	Loss: -7.0781	Cost: 5.88s
Train Epoch: 2176 [81920/90000 (91%)]	Loss: -6.6084	Cost: 6.19s
Train Epoch: 2176 	Average Loss: -7.1410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7514

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2177 [0/90000 (0%)]	Loss: -5.5100	Cost: 23.34s
Train Epoch: 2177 [20480/90000 (23%)]	Loss: -6.5310	Cost: 6.07s
Train Epoch: 2177 [40960/90000 (45%)]	Loss: -6.3112	Cost: 8.07s
Train Epoch: 2177 [61440/90000 (68%)]	Loss: -7.0240	Cost: 5.82s
Train Epoch: 2177 [81920/90000 (91%)]	Loss: -6.4056	Cost: 6.34s
Train Epoch: 2177 	Average Loss: -7.0223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8295

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2178 [0/90000 (0%)]	Loss: -7.0415	Cost: 23.92s
Train Epoch: 2178 [20480/90000 (23%)]	Loss: -6.5201	Cost: 6.11s
Train Epoch: 2178 [40960/90000 (45%)]	Loss: -6.5076	Cost: 7.83s
Train Epoch: 2178 [61440/90000 (68%)]	Loss: -7.1789	Cost: 5.89s
Train Epoch: 2178 [81920/90000 (91%)]	Loss: -6.8414	Cost: 6.29s
Train Epoch: 2178 	Average Loss: -7.0151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7743

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2179 [0/90000 (0%)]	Loss: -6.7585	Cost: 23.66s
Train Epoch: 2179 [20480/90000 (23%)]	Loss: -6.4011	Cost: 6.09s
Train Epoch: 2179 [40960/90000 (45%)]	Loss: -6.4813	Cost: 7.92s
Train Epoch: 2179 [61440/90000 (68%)]	Loss: -7.0604	Cost: 5.93s
Train Epoch: 2179 [81920/90000 (91%)]	Loss: -6.7209	Cost: 6.26s
Train Epoch: 2179 	Average Loss: -6.9944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6996

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2180 [0/90000 (0%)]	Loss: -7.2201	Cost: 23.39s
Train Epoch: 2180 [20480/90000 (23%)]	Loss: -6.3106	Cost: 6.06s
Train Epoch: 2180 [40960/90000 (45%)]	Loss: -6.4736	Cost: 8.06s
Train Epoch: 2180 [61440/90000 (68%)]	Loss: -6.8831	Cost: 5.82s
Train Epoch: 2180 [81920/90000 (91%)]	Loss: -6.6681	Cost: 6.62s
Train Epoch: 2180 	Average Loss: -7.0236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7668

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2181 [0/90000 (0%)]	Loss: -4.8597	Cost: 24.38s
Train Epoch: 2181 [20480/90000 (23%)]	Loss: -6.6444	Cost: 6.13s
Train Epoch: 2181 [40960/90000 (45%)]	Loss: -6.4438	Cost: 7.86s
Train Epoch: 2181 [61440/90000 (68%)]	Loss: -7.1030	Cost: 5.92s
Train Epoch: 2181 [81920/90000 (91%)]	Loss: -6.7557	Cost: 6.16s
Train Epoch: 2181 	Average Loss: -6.9769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6496

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2182 [0/90000 (0%)]	Loss: -7.3450	Cost: 23.73s
Train Epoch: 2182 [20480/90000 (23%)]	Loss: -6.4442	Cost: 6.10s
Train Epoch: 2182 [40960/90000 (45%)]	Loss: -6.3324	Cost: 8.19s
Train Epoch: 2182 [61440/90000 (68%)]	Loss: -6.9445	Cost: 5.87s
Train Epoch: 2182 [81920/90000 (91%)]	Loss: -6.6274	Cost: 6.34s
Train Epoch: 2182 	Average Loss: -6.9844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7612

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2183 [0/90000 (0%)]	Loss: -5.6630	Cost: 23.68s
Train Epoch: 2183 [20480/90000 (23%)]	Loss: -6.6831	Cost: 6.12s
Train Epoch: 2183 [40960/90000 (45%)]	Loss: -6.3032	Cost: 7.93s
Train Epoch: 2183 [61440/90000 (68%)]	Loss: -7.0511	Cost: 5.91s
Train Epoch: 2183 [81920/90000 (91%)]	Loss: -6.6718	Cost: 5.95s
Train Epoch: 2183 	Average Loss: -6.9897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7516

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2184 [0/90000 (0%)]	Loss: -6.5459	Cost: 23.63s
Train Epoch: 2184 [20480/90000 (23%)]	Loss: -6.3310	Cost: 6.08s
Train Epoch: 2184 [40960/90000 (45%)]	Loss: -6.2892	Cost: 8.17s
Train Epoch: 2184 [61440/90000 (68%)]	Loss: -7.0628	Cost: 5.91s
Train Epoch: 2184 [81920/90000 (91%)]	Loss: -6.7655	Cost: 6.11s
Train Epoch: 2184 	Average Loss: -7.0453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6206

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2185 [0/90000 (0%)]	Loss: -6.1938	Cost: 23.23s
Train Epoch: 2185 [20480/90000 (23%)]	Loss: -6.3676	Cost: 6.12s
Train Epoch: 2185 [40960/90000 (45%)]	Loss: -6.3490	Cost: 8.06s
Train Epoch: 2185 [61440/90000 (68%)]	Loss: -7.0060	Cost: 5.88s
Train Epoch: 2185 [81920/90000 (91%)]	Loss: -6.5792	Cost: 6.40s
Train Epoch: 2185 	Average Loss: -6.9996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6287

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2186 [0/90000 (0%)]	Loss: -5.4588	Cost: 23.95s
Train Epoch: 2186 [20480/90000 (23%)]	Loss: -6.3447	Cost: 6.15s
Train Epoch: 2186 [40960/90000 (45%)]	Loss: -6.3867	Cost: 7.86s
Train Epoch: 2186 [61440/90000 (68%)]	Loss: -6.9102	Cost: 5.85s
Train Epoch: 2186 [81920/90000 (91%)]	Loss: -6.6171	Cost: 6.18s
Train Epoch: 2186 	Average Loss: -6.9771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6409

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2187 [0/90000 (0%)]	Loss: -6.7899	Cost: 23.63s
Train Epoch: 2187 [20480/90000 (23%)]	Loss: -6.5625	Cost: 6.06s
Train Epoch: 2187 [40960/90000 (45%)]	Loss: -6.5322	Cost: 8.11s
Train Epoch: 2187 [61440/90000 (68%)]	Loss: -7.0749	Cost: 5.81s
Train Epoch: 2187 [81920/90000 (91%)]	Loss: -6.7208	Cost: 6.12s
Train Epoch: 2187 	Average Loss: -7.0497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7725

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2188 [0/90000 (0%)]	Loss: -7.2805	Cost: 23.49s
Train Epoch: 2188 [20480/90000 (23%)]	Loss: -6.5087	Cost: 6.10s
Train Epoch: 2188 [40960/90000 (45%)]	Loss: -6.4689	Cost: 8.09s
Train Epoch: 2188 [61440/90000 (68%)]	Loss: -6.9203	Cost: 5.90s
Train Epoch: 2188 [81920/90000 (91%)]	Loss: -6.6542	Cost: 6.31s
Train Epoch: 2188 	Average Loss: -7.0711
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6649

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2189 [0/90000 (0%)]	Loss: -7.1227	Cost: 23.84s
Train Epoch: 2189 [20480/90000 (23%)]	Loss: -6.5180	Cost: 6.20s
Train Epoch: 2189 [40960/90000 (45%)]	Loss: -6.3356	Cost: 7.83s
Train Epoch: 2189 [61440/90000 (68%)]	Loss: -6.9089	Cost: 5.89s
Train Epoch: 2189 [81920/90000 (91%)]	Loss: -6.5788	Cost: 5.97s
Train Epoch: 2189 	Average Loss: -6.9753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9224

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2190 [0/90000 (0%)]	Loss: -8.4155	Cost: 23.87s
Train Epoch: 2190 [20480/90000 (23%)]	Loss: -6.4788	Cost: 6.18s
Train Epoch: 2190 [40960/90000 (45%)]	Loss: -6.2452	Cost: 7.74s
Train Epoch: 2190 [61440/90000 (68%)]	Loss: -6.8696	Cost: 5.88s
Train Epoch: 2190 [81920/90000 (91%)]	Loss: -6.7708	Cost: 6.45s
Train Epoch: 2190 	Average Loss: -7.0854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7755

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2191 [0/90000 (0%)]	Loss: -7.1142	Cost: 24.14s
Train Epoch: 2191 [20480/90000 (23%)]	Loss: -6.4877	Cost: 6.15s
Train Epoch: 2191 [40960/90000 (45%)]	Loss: -6.3827	Cost: 7.77s
Train Epoch: 2191 [61440/90000 (68%)]	Loss: -6.8979	Cost: 5.87s
Train Epoch: 2191 [81920/90000 (91%)]	Loss: -6.8015	Cost: 6.23s
Train Epoch: 2191 	Average Loss: -7.0428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6581

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2192 [0/90000 (0%)]	Loss: -7.5057	Cost: 24.01s
Train Epoch: 2192 [20480/90000 (23%)]	Loss: -6.5581	Cost: 6.12s
Train Epoch: 2192 [40960/90000 (45%)]	Loss: -6.4108	Cost: 7.64s
Train Epoch: 2192 [61440/90000 (68%)]	Loss: -6.9997	Cost: 5.88s
Train Epoch: 2192 [81920/90000 (91%)]	Loss: -6.6025	Cost: 6.34s
Train Epoch: 2192 	Average Loss: -7.0451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7224

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2193 [0/90000 (0%)]	Loss: -8.1713	Cost: 23.50s
Train Epoch: 2193 [20480/90000 (23%)]	Loss: -6.5805	Cost: 6.14s
Train Epoch: 2193 [40960/90000 (45%)]	Loss: -6.4728	Cost: 7.84s
Train Epoch: 2193 [61440/90000 (68%)]	Loss: -6.9897	Cost: 5.86s
Train Epoch: 2193 [81920/90000 (91%)]	Loss: -6.6975	Cost: 6.44s
Train Epoch: 2193 	Average Loss: -7.0375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8201

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2194 [0/90000 (0%)]	Loss: -6.2152	Cost: 23.71s
Train Epoch: 2194 [20480/90000 (23%)]	Loss: -6.4767	Cost: 6.18s
Train Epoch: 2194 [40960/90000 (45%)]	Loss: -6.4066	Cost: 7.76s
Train Epoch: 2194 [61440/90000 (68%)]	Loss: -6.8686	Cost: 5.93s
Train Epoch: 2194 [81920/90000 (91%)]	Loss: -6.7071	Cost: 6.65s
Train Epoch: 2194 	Average Loss: -6.9882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6643

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2195 [0/90000 (0%)]	Loss: -7.3192	Cost: 23.68s
Train Epoch: 2195 [20480/90000 (23%)]	Loss: -6.3833	Cost: 6.20s
Train Epoch: 2195 [40960/90000 (45%)]	Loss: -6.4008	Cost: 7.72s
Train Epoch: 2195 [61440/90000 (68%)]	Loss: -6.8179	Cost: 5.91s
Train Epoch: 2195 [81920/90000 (91%)]	Loss: -6.7220	Cost: 5.98s
Train Epoch: 2195 	Average Loss: -7.0642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6483

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2196 [0/90000 (0%)]	Loss: -4.9638	Cost: 23.59s
Train Epoch: 2196 [20480/90000 (23%)]	Loss: -6.4822	Cost: 6.22s
Train Epoch: 2196 [40960/90000 (45%)]	Loss: -6.3445	Cost: 8.18s
Train Epoch: 2196 [61440/90000 (68%)]	Loss: -6.9762	Cost: 5.83s
Train Epoch: 2196 [81920/90000 (91%)]	Loss: -6.6808	Cost: 6.25s
Train Epoch: 2196 	Average Loss: -6.9828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6687

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2197 [0/90000 (0%)]	Loss: -7.4252	Cost: 23.89s
Train Epoch: 2197 [20480/90000 (23%)]	Loss: -6.6228	Cost: 6.09s
Train Epoch: 2197 [40960/90000 (45%)]	Loss: -6.3050	Cost: 7.89s
Train Epoch: 2197 [61440/90000 (68%)]	Loss: -6.8191	Cost: 5.87s
Train Epoch: 2197 [81920/90000 (91%)]	Loss: -6.8926	Cost: 6.15s
Train Epoch: 2197 	Average Loss: -7.0380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7984

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2198 [0/90000 (0%)]	Loss: -2.9491	Cost: 23.48s
Train Epoch: 2198 [20480/90000 (23%)]	Loss: -6.5282	Cost: 6.08s
Train Epoch: 2198 [40960/90000 (45%)]	Loss: -6.4824	Cost: 8.12s
Train Epoch: 2198 [61440/90000 (68%)]	Loss: -6.8542	Cost: 5.85s
Train Epoch: 2198 [81920/90000 (91%)]	Loss: -6.7766	Cost: 6.27s
Train Epoch: 2198 	Average Loss: -6.9484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7310

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2199 [0/90000 (0%)]	Loss: -7.0338	Cost: 23.62s
Train Epoch: 2199 [20480/90000 (23%)]	Loss: -6.4796	Cost: 6.10s
Train Epoch: 2199 [40960/90000 (45%)]	Loss: -6.4074	Cost: 7.98s
Train Epoch: 2199 [61440/90000 (68%)]	Loss: -6.9381	Cost: 5.85s
Train Epoch: 2199 [81920/90000 (91%)]	Loss: -6.8513	Cost: 6.20s
Train Epoch: 2199 	Average Loss: -7.0811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7851

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2200 [0/90000 (0%)]	Loss: -6.8052	Cost: 23.16s
Train Epoch: 2200 [20480/90000 (23%)]	Loss: -6.5372	Cost: 6.13s
Train Epoch: 2200 [40960/90000 (45%)]	Loss: -6.2624	Cost: 8.14s
Train Epoch: 2200 [61440/90000 (68%)]	Loss: -6.8690	Cost: 5.90s
Train Epoch: 2200 [81920/90000 (91%)]	Loss: -6.5926	Cost: 6.47s
Train Epoch: 2200 	Average Loss: -7.0237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7782

Saving model as model.pt_e2200 & waveforms_supplementary.hdf5_e2200
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2201 [0/90000 (0%)]	Loss: -7.2975	Cost: 23.67s
Train Epoch: 2201 [20480/90000 (23%)]	Loss: -6.4895	Cost: 6.13s
Train Epoch: 2201 [40960/90000 (45%)]	Loss: -6.3430	Cost: 7.97s
Train Epoch: 2201 [61440/90000 (68%)]	Loss: -6.9447	Cost: 5.84s
Train Epoch: 2201 [81920/90000 (91%)]	Loss: -6.6061	Cost: 6.29s
Train Epoch: 2201 	Average Loss: -7.0696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8654

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2202 [0/90000 (0%)]	Loss: -6.5717	Cost: 24.33s
Train Epoch: 2202 [20480/90000 (23%)]	Loss: -6.6391	Cost: 6.07s
Train Epoch: 2202 [40960/90000 (45%)]	Loss: -6.4286	Cost: 7.80s
Train Epoch: 2202 [61440/90000 (68%)]	Loss: -7.0700	Cost: 5.86s
Train Epoch: 2202 [81920/90000 (91%)]	Loss: -6.7578	Cost: 6.09s
Train Epoch: 2202 	Average Loss: -7.0907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7720

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2203 [0/90000 (0%)]	Loss: -7.7663	Cost: 23.46s
Train Epoch: 2203 [20480/90000 (23%)]	Loss: -6.4424	Cost: 6.08s
Train Epoch: 2203 [40960/90000 (45%)]	Loss: -6.6044	Cost: 7.78s
Train Epoch: 2203 [61440/90000 (68%)]	Loss: -7.0703	Cost: 5.87s
Train Epoch: 2203 [81920/90000 (91%)]	Loss: -6.7793	Cost: 6.33s
Train Epoch: 2203 	Average Loss: -7.0730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7458

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2204 [0/90000 (0%)]	Loss: -6.6905	Cost: 23.49s
Train Epoch: 2204 [20480/90000 (23%)]	Loss: -6.2426	Cost: 6.11s
Train Epoch: 2204 [40960/90000 (45%)]	Loss: -6.2521	Cost: 8.28s
Train Epoch: 2204 [61440/90000 (68%)]	Loss: -7.0779	Cost: 5.85s
Train Epoch: 2204 [81920/90000 (91%)]	Loss: -6.6636	Cost: 6.27s
Train Epoch: 2204 	Average Loss: -7.0295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6773

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2205 [0/90000 (0%)]	Loss: -6.8624	Cost: 23.52s
Train Epoch: 2205 [20480/90000 (23%)]	Loss: -6.4606	Cost: 6.72s
Train Epoch: 2205 [40960/90000 (45%)]	Loss: -6.4119	Cost: 7.09s
Train Epoch: 2205 [61440/90000 (68%)]	Loss: -6.9869	Cost: 5.86s
Train Epoch: 2205 [81920/90000 (91%)]	Loss: -6.7368	Cost: 6.20s
Train Epoch: 2205 	Average Loss: -7.0353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7779

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2206 [0/90000 (0%)]	Loss: -6.5695	Cost: 23.80s
Train Epoch: 2206 [20480/90000 (23%)]	Loss: -6.6988	Cost: 5.99s
Train Epoch: 2206 [40960/90000 (45%)]	Loss: -6.3817	Cost: 8.54s
Train Epoch: 2206 [61440/90000 (68%)]	Loss: -6.7895	Cost: 6.05s
Train Epoch: 2206 [81920/90000 (91%)]	Loss: -6.6883	Cost: 5.74s
Train Epoch: 2206 	Average Loss: -7.0231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5972

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2207 [0/90000 (0%)]	Loss: -7.1440	Cost: 23.72s
Train Epoch: 2207 [20480/90000 (23%)]	Loss: -6.4430	Cost: 6.12s
Train Epoch: 2207 [40960/90000 (45%)]	Loss: -6.5001	Cost: 8.11s
Train Epoch: 2207 [61440/90000 (68%)]	Loss: -6.8549	Cost: 5.86s
Train Epoch: 2207 [81920/90000 (91%)]	Loss: -6.6940	Cost: 6.06s
Train Epoch: 2207 	Average Loss: -7.0803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7000

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2208 [0/90000 (0%)]	Loss: -6.9983	Cost: 23.70s
Train Epoch: 2208 [20480/90000 (23%)]	Loss: -6.5080	Cost: 6.08s
Train Epoch: 2208 [40960/90000 (45%)]	Loss: -6.4586	Cost: 8.19s
Train Epoch: 2208 [61440/90000 (68%)]	Loss: -7.0463	Cost: 5.86s
Train Epoch: 2208 [81920/90000 (91%)]	Loss: -6.6176	Cost: 6.27s
Train Epoch: 2208 	Average Loss: -7.0393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7469

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2209 [0/90000 (0%)]	Loss: -7.8346	Cost: 24.21s
Train Epoch: 2209 [20480/90000 (23%)]	Loss: -6.6531	Cost: 6.12s
Train Epoch: 2209 [40960/90000 (45%)]	Loss: -6.4640	Cost: 7.60s
Train Epoch: 2209 [61440/90000 (68%)]	Loss: -6.9903	Cost: 5.90s
Train Epoch: 2209 [81920/90000 (91%)]	Loss: -6.7674	Cost: 6.02s
Train Epoch: 2209 	Average Loss: -7.1102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7076

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2210 [0/90000 (0%)]	Loss: -6.2617	Cost: 23.68s
Train Epoch: 2210 [20480/90000 (23%)]	Loss: -6.5735	Cost: 6.04s
Train Epoch: 2210 [40960/90000 (45%)]	Loss: -6.2363	Cost: 8.00s
Train Epoch: 2210 [61440/90000 (68%)]	Loss: -6.8389	Cost: 5.84s
Train Epoch: 2210 [81920/90000 (91%)]	Loss: -6.7162	Cost: 6.34s
Train Epoch: 2210 	Average Loss: -7.0016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7701

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2211 [0/90000 (0%)]	Loss: -6.5412	Cost: 23.71s
Train Epoch: 2211 [20480/90000 (23%)]	Loss: -6.4996	Cost: 6.06s
Train Epoch: 2211 [40960/90000 (45%)]	Loss: -6.4371	Cost: 8.28s
Train Epoch: 2211 [61440/90000 (68%)]	Loss: -6.9658	Cost: 5.85s
Train Epoch: 2211 [81920/90000 (91%)]	Loss: -6.6624	Cost: 6.17s
Train Epoch: 2211 	Average Loss: -7.0458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6735

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2212 [0/90000 (0%)]	Loss: -6.6629	Cost: 23.26s
Train Epoch: 2212 [20480/90000 (23%)]	Loss: -6.4418	Cost: 6.11s
Train Epoch: 2212 [40960/90000 (45%)]	Loss: -6.2636	Cost: 7.88s
Train Epoch: 2212 [61440/90000 (68%)]	Loss: -7.0110	Cost: 5.86s
Train Epoch: 2212 [81920/90000 (91%)]	Loss: -6.6522	Cost: 6.58s
Train Epoch: 2212 	Average Loss: -7.0459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5998

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2213 [0/90000 (0%)]	Loss: -7.7525	Cost: 23.59s
Train Epoch: 2213 [20480/90000 (23%)]	Loss: -6.5091	Cost: 6.11s
Train Epoch: 2213 [40960/90000 (45%)]	Loss: -6.2884	Cost: 8.04s
Train Epoch: 2213 [61440/90000 (68%)]	Loss: -7.1294	Cost: 5.85s
Train Epoch: 2213 [81920/90000 (91%)]	Loss: -6.6649	Cost: 6.21s
Train Epoch: 2213 	Average Loss: -7.1009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6706

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2214 [0/90000 (0%)]	Loss: -6.1561	Cost: 23.77s
Train Epoch: 2214 [20480/90000 (23%)]	Loss: -6.5669	Cost: 6.15s
Train Epoch: 2214 [40960/90000 (45%)]	Loss: -6.3323	Cost: 7.76s
Train Epoch: 2214 [61440/90000 (68%)]	Loss: -6.8946	Cost: 5.92s
Train Epoch: 2214 [81920/90000 (91%)]	Loss: -6.7251	Cost: 6.22s
Train Epoch: 2214 	Average Loss: -7.0241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5720

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2215 [0/90000 (0%)]	Loss: -5.1843	Cost: 23.45s
Train Epoch: 2215 [20480/90000 (23%)]	Loss: -6.4798	Cost: 6.20s
Train Epoch: 2215 [40960/90000 (45%)]	Loss: -6.3155	Cost: 7.92s
Train Epoch: 2215 [61440/90000 (68%)]	Loss: -6.9209	Cost: 5.89s
Train Epoch: 2215 [81920/90000 (91%)]	Loss: -6.7257	Cost: 6.25s
Train Epoch: 2215 	Average Loss: -6.9949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6783

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2216 [0/90000 (0%)]	Loss: -7.6502	Cost: 21.30s
Train Epoch: 2216 [20480/90000 (23%)]	Loss: -6.6307	Cost: 5.84s
Train Epoch: 2216 [40960/90000 (45%)]	Loss: -6.2848	Cost: 9.95s
Train Epoch: 2216 [61440/90000 (68%)]	Loss: -7.2304	Cost: 6.02s
Train Epoch: 2216 [81920/90000 (91%)]	Loss: -6.7859	Cost: 7.33s
Train Epoch: 2216 	Average Loss: -7.0039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6193

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2217 [0/90000 (0%)]	Loss: -7.7601	Cost: 24.57s
Train Epoch: 2217 [20480/90000 (23%)]	Loss: -6.5452	Cost: 6.05s
Train Epoch: 2217 [40960/90000 (45%)]	Loss: -6.5317	Cost: 7.99s
Train Epoch: 2217 [61440/90000 (68%)]	Loss: -6.9307	Cost: 5.84s
Train Epoch: 2217 [81920/90000 (91%)]	Loss: -6.6586	Cost: 6.28s
Train Epoch: 2217 	Average Loss: -7.0758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7248

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2218 [0/90000 (0%)]	Loss: -7.5979	Cost: 23.69s
Train Epoch: 2218 [20480/90000 (23%)]	Loss: -6.4406	Cost: 6.05s
Train Epoch: 2218 [40960/90000 (45%)]	Loss: -6.2664	Cost: 8.16s
Train Epoch: 2218 [61440/90000 (68%)]	Loss: -7.0304	Cost: 5.85s
Train Epoch: 2218 [81920/90000 (91%)]	Loss: -6.6683	Cost: 6.53s
Train Epoch: 2218 	Average Loss: -7.0274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7343

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2219 [0/90000 (0%)]	Loss: -7.5667	Cost: 23.98s
Train Epoch: 2219 [20480/90000 (23%)]	Loss: -6.3324	Cost: 6.12s
Train Epoch: 2219 [40960/90000 (45%)]	Loss: -6.3211	Cost: 7.96s
Train Epoch: 2219 [61440/90000 (68%)]	Loss: -7.0434	Cost: 5.86s
Train Epoch: 2219 [81920/90000 (91%)]	Loss: -6.7215	Cost: 6.30s
Train Epoch: 2219 	Average Loss: -7.0281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6563

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2220 [0/90000 (0%)]	Loss: -6.5029	Cost: 23.58s
Train Epoch: 2220 [20480/90000 (23%)]	Loss: -6.4679	Cost: 6.06s
Train Epoch: 2220 [40960/90000 (45%)]	Loss: -6.4029	Cost: 8.15s
Train Epoch: 2220 [61440/90000 (68%)]	Loss: -7.0182	Cost: 5.84s
Train Epoch: 2220 [81920/90000 (91%)]	Loss: -6.7419	Cost: 6.41s
Train Epoch: 2220 	Average Loss: -6.9886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6289

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2221 [0/90000 (0%)]	Loss: -7.4562	Cost: 23.41s
Train Epoch: 2221 [20480/90000 (23%)]	Loss: -6.5155	Cost: 6.12s
Train Epoch: 2221 [40960/90000 (45%)]	Loss: -6.3327	Cost: 8.08s
Train Epoch: 2221 [61440/90000 (68%)]	Loss: -7.0411	Cost: 5.87s
Train Epoch: 2221 [81920/90000 (91%)]	Loss: -6.7909	Cost: 6.22s
Train Epoch: 2221 	Average Loss: -7.0577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6602

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2222 [0/90000 (0%)]	Loss: -7.5065	Cost: 23.76s
Train Epoch: 2222 [20480/90000 (23%)]	Loss: -6.4663	Cost: 6.10s
Train Epoch: 2222 [40960/90000 (45%)]	Loss: -6.3429	Cost: 8.05s
Train Epoch: 2222 [61440/90000 (68%)]	Loss: -6.9461	Cost: 5.82s
Train Epoch: 2222 [81920/90000 (91%)]	Loss: -6.8722	Cost: 6.66s
Train Epoch: 2222 	Average Loss: -7.0216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6992

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2223 [0/90000 (0%)]	Loss: -7.1901	Cost: 23.13s
Train Epoch: 2223 [20480/90000 (23%)]	Loss: -6.5938	Cost: 6.05s
Train Epoch: 2223 [40960/90000 (45%)]	Loss: -6.4601	Cost: 8.19s
Train Epoch: 2223 [61440/90000 (68%)]	Loss: -7.0796	Cost: 5.88s
Train Epoch: 2223 [81920/90000 (91%)]	Loss: -6.7635	Cost: 6.01s
Train Epoch: 2223 	Average Loss: -7.0771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8397

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2224 [0/90000 (0%)]	Loss: -8.2232	Cost: 23.27s
Train Epoch: 2224 [20480/90000 (23%)]	Loss: -6.4261	Cost: 6.09s
Train Epoch: 2224 [40960/90000 (45%)]	Loss: -6.3136	Cost: 8.23s
Train Epoch: 2224 [61440/90000 (68%)]	Loss: -6.8600	Cost: 5.93s
Train Epoch: 2224 [81920/90000 (91%)]	Loss: -6.7008	Cost: 6.37s
Train Epoch: 2224 	Average Loss: -7.0237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7277

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2225 [0/90000 (0%)]	Loss: -7.5982	Cost: 23.42s
Train Epoch: 2225 [20480/90000 (23%)]	Loss: -6.5471	Cost: 6.11s
Train Epoch: 2225 [40960/90000 (45%)]	Loss: -6.3625	Cost: 7.79s
Train Epoch: 2225 [61440/90000 (68%)]	Loss: -7.0643	Cost: 5.91s
Train Epoch: 2225 [81920/90000 (91%)]	Loss: -6.7296	Cost: 6.19s
Train Epoch: 2225 	Average Loss: -7.0194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8106

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2226 [0/90000 (0%)]	Loss: -7.2575	Cost: 23.28s
Train Epoch: 2226 [20480/90000 (23%)]	Loss: -6.5251	Cost: 6.10s
Train Epoch: 2226 [40960/90000 (45%)]	Loss: -6.2881	Cost: 7.78s
Train Epoch: 2226 [61440/90000 (68%)]	Loss: -6.9873	Cost: 5.88s
Train Epoch: 2226 [81920/90000 (91%)]	Loss: -6.7206	Cost: 6.38s
Train Epoch: 2226 	Average Loss: -7.0332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8393

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2227 [0/90000 (0%)]	Loss: -6.7577	Cost: 23.62s
Train Epoch: 2227 [20480/90000 (23%)]	Loss: -6.4681	Cost: 6.07s
Train Epoch: 2227 [40960/90000 (45%)]	Loss: -6.3430	Cost: 7.98s
Train Epoch: 2227 [61440/90000 (68%)]	Loss: -6.9571	Cost: 5.84s
Train Epoch: 2227 [81920/90000 (91%)]	Loss: -6.6175	Cost: 6.21s
Train Epoch: 2227 	Average Loss: -7.0363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7858

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2228 [0/90000 (0%)]	Loss: -6.7765	Cost: 23.68s
Train Epoch: 2228 [20480/90000 (23%)]	Loss: -6.5127	Cost: 6.11s
Train Epoch: 2228 [40960/90000 (45%)]	Loss: -6.2342	Cost: 7.96s
Train Epoch: 2228 [61440/90000 (68%)]	Loss: -7.1948	Cost: 5.86s
Train Epoch: 2228 [81920/90000 (91%)]	Loss: -6.6660	Cost: 6.46s
Train Epoch: 2228 	Average Loss: -7.0402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7266

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2229 [0/90000 (0%)]	Loss: -6.3905	Cost: 23.53s
Train Epoch: 2229 [20480/90000 (23%)]	Loss: -6.4778	Cost: 6.07s
Train Epoch: 2229 [40960/90000 (45%)]	Loss: -6.2122	Cost: 8.03s
Train Epoch: 2229 [61440/90000 (68%)]	Loss: -7.1111	Cost: 5.84s
Train Epoch: 2229 [81920/90000 (91%)]	Loss: -6.5771	Cost: 6.02s
Train Epoch: 2229 	Average Loss: -7.0058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8720

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2230 [0/90000 (0%)]	Loss: -7.3087	Cost: 23.41s
Train Epoch: 2230 [20480/90000 (23%)]	Loss: -6.4082	Cost: 6.05s
Train Epoch: 2230 [40960/90000 (45%)]	Loss: -6.4537	Cost: 7.96s
Train Epoch: 2230 [61440/90000 (68%)]	Loss: -7.0392	Cost: 5.99s
Train Epoch: 2230 [81920/90000 (91%)]	Loss: -6.6560	Cost: 6.43s
Train Epoch: 2230 	Average Loss: -7.0549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8428

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2231 [0/90000 (0%)]	Loss: -6.8113	Cost: 24.26s
Train Epoch: 2231 [20480/90000 (23%)]	Loss: -6.4964	Cost: 6.08s
Train Epoch: 2231 [40960/90000 (45%)]	Loss: -6.2804	Cost: 7.68s
Train Epoch: 2231 [61440/90000 (68%)]	Loss: -6.9634	Cost: 5.86s
Train Epoch: 2231 [81920/90000 (91%)]	Loss: -6.5815	Cost: 6.13s
Train Epoch: 2231 	Average Loss: -7.0356
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5960

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2232 [0/90000 (0%)]	Loss: -7.7284	Cost: 23.48s
Train Epoch: 2232 [20480/90000 (23%)]	Loss: -6.3864	Cost: 6.71s
Train Epoch: 2232 [40960/90000 (45%)]	Loss: -6.3182	Cost: 7.50s
Train Epoch: 2232 [61440/90000 (68%)]	Loss: -6.9085	Cost: 5.90s
Train Epoch: 2232 [81920/90000 (91%)]	Loss: -6.6709	Cost: 6.64s
Train Epoch: 2232 	Average Loss: -7.0153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6696

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2233 [0/90000 (0%)]	Loss: -7.5082	Cost: 23.90s
Train Epoch: 2233 [20480/90000 (23%)]	Loss: -6.6145	Cost: 6.08s
Train Epoch: 2233 [40960/90000 (45%)]	Loss: -6.3453	Cost: 7.92s
Train Epoch: 2233 [61440/90000 (68%)]	Loss: -6.8748	Cost: 5.87s
Train Epoch: 2233 [81920/90000 (91%)]	Loss: -6.5676	Cost: 6.09s
Train Epoch: 2233 	Average Loss: -7.1148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7154

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2234 [0/90000 (0%)]	Loss: -6.6608	Cost: 23.65s
Train Epoch: 2234 [20480/90000 (23%)]	Loss: -6.5144	Cost: 6.08s
Train Epoch: 2234 [40960/90000 (45%)]	Loss: -6.4532	Cost: 7.87s
Train Epoch: 2234 [61440/90000 (68%)]	Loss: -6.9565	Cost: 5.82s
Train Epoch: 2234 [81920/90000 (91%)]	Loss: -6.5636	Cost: 6.26s
Train Epoch: 2234 	Average Loss: -7.0468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8217

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2235 [0/90000 (0%)]	Loss: -7.2241	Cost: 23.88s
Train Epoch: 2235 [20480/90000 (23%)]	Loss: -6.3245	Cost: 6.12s
Train Epoch: 2235 [40960/90000 (45%)]	Loss: -6.3874	Cost: 7.89s
Train Epoch: 2235 [61440/90000 (68%)]	Loss: -7.1667	Cost: 5.85s
Train Epoch: 2235 [81920/90000 (91%)]	Loss: -6.6917	Cost: 6.14s
Train Epoch: 2235 	Average Loss: -7.0595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7337

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2236 [0/90000 (0%)]	Loss: -6.1011	Cost: 23.80s
Train Epoch: 2236 [20480/90000 (23%)]	Loss: -6.5277	Cost: 6.08s
Train Epoch: 2236 [40960/90000 (45%)]	Loss: -6.3953	Cost: 8.08s
Train Epoch: 2236 [61440/90000 (68%)]	Loss: -7.1255	Cost: 5.85s
Train Epoch: 2236 [81920/90000 (91%)]	Loss: -6.6662	Cost: 6.65s
Train Epoch: 2236 	Average Loss: -6.9801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6945

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2237 [0/90000 (0%)]	Loss: -7.3922	Cost: 24.18s
Train Epoch: 2237 [20480/90000 (23%)]	Loss: -6.4558	Cost: 6.11s
Train Epoch: 2237 [40960/90000 (45%)]	Loss: -6.4973	Cost: 7.72s
Train Epoch: 2237 [61440/90000 (68%)]	Loss: -7.1139	Cost: 5.87s
Train Epoch: 2237 [81920/90000 (91%)]	Loss: -6.6609	Cost: 5.96s
Train Epoch: 2237 	Average Loss: -6.9863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7063

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2238 [0/90000 (0%)]	Loss: -4.9456	Cost: 23.32s
Train Epoch: 2238 [20480/90000 (23%)]	Loss: -6.4053	Cost: 6.10s
Train Epoch: 2238 [40960/90000 (45%)]	Loss: -6.4853	Cost: 8.14s
Train Epoch: 2238 [61440/90000 (68%)]	Loss: -7.0195	Cost: 5.84s
Train Epoch: 2238 [81920/90000 (91%)]	Loss: -6.5718	Cost: 6.60s
Train Epoch: 2238 	Average Loss: -7.0016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8224

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2239 [0/90000 (0%)]	Loss: -6.8980	Cost: 23.54s
Train Epoch: 2239 [20480/90000 (23%)]	Loss: -6.3732	Cost: 6.07s
Train Epoch: 2239 [40960/90000 (45%)]	Loss: -6.4925	Cost: 7.80s
Train Epoch: 2239 [61440/90000 (68%)]	Loss: -6.9377	Cost: 5.85s
Train Epoch: 2239 [81920/90000 (91%)]	Loss: -6.7359	Cost: 6.49s
Train Epoch: 2239 	Average Loss: -7.0492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8224

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2240 [0/90000 (0%)]	Loss: -6.3639	Cost: 23.67s
Train Epoch: 2240 [20480/90000 (23%)]	Loss: -6.4390	Cost: 6.17s
Train Epoch: 2240 [40960/90000 (45%)]	Loss: -6.3901	Cost: 7.94s
Train Epoch: 2240 [61440/90000 (68%)]	Loss: -7.0346	Cost: 5.90s
Train Epoch: 2240 [81920/90000 (91%)]	Loss: -6.6108	Cost: 6.25s
Train Epoch: 2240 	Average Loss: -6.9640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6654

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2241 [0/90000 (0%)]	Loss: -8.0406	Cost: 23.58s
Train Epoch: 2241 [20480/90000 (23%)]	Loss: -6.6106	Cost: 6.07s
Train Epoch: 2241 [40960/90000 (45%)]	Loss: -6.3036	Cost: 7.81s
Train Epoch: 2241 [61440/90000 (68%)]	Loss: -7.0181	Cost: 5.86s
Train Epoch: 2241 [81920/90000 (91%)]	Loss: -6.7923	Cost: 6.20s
Train Epoch: 2241 	Average Loss: -7.0657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8006

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2242 [0/90000 (0%)]	Loss: -6.4127	Cost: 23.32s
Train Epoch: 2242 [20480/90000 (23%)]	Loss: -6.2930	Cost: 6.21s
Train Epoch: 2242 [40960/90000 (45%)]	Loss: -6.4007	Cost: 8.04s
Train Epoch: 2242 [61440/90000 (68%)]	Loss: -7.0145	Cost: 5.96s
Train Epoch: 2242 [81920/90000 (91%)]	Loss: -6.7448	Cost: 6.21s
Train Epoch: 2242 	Average Loss: -6.9863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6668

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2243 [0/90000 (0%)]	Loss: -7.0220	Cost: 24.07s
Train Epoch: 2243 [20480/90000 (23%)]	Loss: -6.4590	Cost: 6.01s
Train Epoch: 2243 [40960/90000 (45%)]	Loss: -6.4674	Cost: 8.28s
Train Epoch: 2243 [61440/90000 (68%)]	Loss: -7.0725	Cost: 5.94s
Train Epoch: 2243 [81920/90000 (91%)]	Loss: -6.6318	Cost: 5.65s
Train Epoch: 2243 	Average Loss: -7.0629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7022

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2244 [0/90000 (0%)]	Loss: -6.2723	Cost: 23.46s
Train Epoch: 2244 [20480/90000 (23%)]	Loss: -6.4573	Cost: 6.16s
Train Epoch: 2244 [40960/90000 (45%)]	Loss: -6.4300	Cost: 8.15s
Train Epoch: 2244 [61440/90000 (68%)]	Loss: -7.0744	Cost: 5.89s
Train Epoch: 2244 [81920/90000 (91%)]	Loss: -6.5554	Cost: 6.19s
Train Epoch: 2244 	Average Loss: -7.0470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6857

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2245 [0/90000 (0%)]	Loss: -7.9573	Cost: 23.46s
Train Epoch: 2245 [20480/90000 (23%)]	Loss: -6.5293	Cost: 6.25s
Train Epoch: 2245 [40960/90000 (45%)]	Loss: -6.4515	Cost: 7.99s
Train Epoch: 2245 [61440/90000 (68%)]	Loss: -6.9549	Cost: 5.92s
Train Epoch: 2245 [81920/90000 (91%)]	Loss: -6.5573	Cost: 6.01s
Train Epoch: 2245 	Average Loss: -7.0663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7922

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2246 [0/90000 (0%)]	Loss: -7.2059	Cost: 23.64s
Train Epoch: 2246 [20480/90000 (23%)]	Loss: -6.5947	Cost: 6.19s
Train Epoch: 2246 [40960/90000 (45%)]	Loss: -6.2810	Cost: 7.95s
Train Epoch: 2246 [61440/90000 (68%)]	Loss: -7.0183	Cost: 5.89s
Train Epoch: 2246 [81920/90000 (91%)]	Loss: -6.6489	Cost: 6.33s
Train Epoch: 2246 	Average Loss: -7.0821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6815

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2247 [0/90000 (0%)]	Loss: -7.1190	Cost: 24.29s
Train Epoch: 2247 [20480/90000 (23%)]	Loss: -6.5674	Cost: 6.10s
Train Epoch: 2247 [40960/90000 (45%)]	Loss: -6.2919	Cost: 7.68s
Train Epoch: 2247 [61440/90000 (68%)]	Loss: -7.0625	Cost: 5.87s
Train Epoch: 2247 [81920/90000 (91%)]	Loss: -6.6653	Cost: 6.34s
Train Epoch: 2247 	Average Loss: -7.0283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6573

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2248 [0/90000 (0%)]	Loss: -7.1536	Cost: 23.75s
Train Epoch: 2248 [20480/90000 (23%)]	Loss: -6.7148	Cost: 6.13s
Train Epoch: 2248 [40960/90000 (45%)]	Loss: -6.4789	Cost: 8.12s
Train Epoch: 2248 [61440/90000 (68%)]	Loss: -6.8979	Cost: 5.88s
Train Epoch: 2248 [81920/90000 (91%)]	Loss: -6.7698	Cost: 6.24s
Train Epoch: 2248 	Average Loss: -7.1031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6043

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2249 [0/90000 (0%)]	Loss: -5.4397	Cost: 23.90s
Train Epoch: 2249 [20480/90000 (23%)]	Loss: -6.3855	Cost: 6.15s
Train Epoch: 2249 [40960/90000 (45%)]	Loss: -6.3554	Cost: 8.07s
Train Epoch: 2249 [61440/90000 (68%)]	Loss: -6.9779	Cost: 5.86s
Train Epoch: 2249 [81920/90000 (91%)]	Loss: -6.7339	Cost: 6.44s
Train Epoch: 2249 	Average Loss: -7.0438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6701

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2250 [0/90000 (0%)]	Loss: -7.7792	Cost: 23.77s
Train Epoch: 2250 [20480/90000 (23%)]	Loss: -6.4307	Cost: 6.10s
Train Epoch: 2250 [40960/90000 (45%)]	Loss: -6.2242	Cost: 8.04s
Train Epoch: 2250 [61440/90000 (68%)]	Loss: -7.0068	Cost: 5.86s
Train Epoch: 2250 [81920/90000 (91%)]	Loss: -6.8394	Cost: 6.25s
Train Epoch: 2250 	Average Loss: -7.0666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6152

Saving model as model.pt_e2250 & waveforms_supplementary.hdf5_e2250
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2251 [0/90000 (0%)]	Loss: -6.8167	Cost: 23.79s
Train Epoch: 2251 [20480/90000 (23%)]	Loss: -6.4108	Cost: 6.04s
Train Epoch: 2251 [40960/90000 (45%)]	Loss: -6.4362	Cost: 8.10s
Train Epoch: 2251 [61440/90000 (68%)]	Loss: -7.1353	Cost: 5.83s
Train Epoch: 2251 [81920/90000 (91%)]	Loss: -6.5708	Cost: 6.18s
Train Epoch: 2251 	Average Loss: -7.0380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7863

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2252 [0/90000 (0%)]	Loss: -6.7907	Cost: 24.82s
Train Epoch: 2252 [20480/90000 (23%)]	Loss: -6.4570	Cost: 6.05s
Train Epoch: 2252 [40960/90000 (45%)]	Loss: -6.3647	Cost: 7.87s
Train Epoch: 2252 [61440/90000 (68%)]	Loss: -7.1279	Cost: 5.85s
Train Epoch: 2252 [81920/90000 (91%)]	Loss: -6.8290	Cost: 6.07s
Train Epoch: 2252 	Average Loss: -7.0312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7768

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2253 [0/90000 (0%)]	Loss: -8.1757	Cost: 23.40s
Train Epoch: 2253 [20480/90000 (23%)]	Loss: -6.5561	Cost: 6.04s
Train Epoch: 2253 [40960/90000 (45%)]	Loss: -6.5330	Cost: 8.20s
Train Epoch: 2253 [61440/90000 (68%)]	Loss: -7.0199	Cost: 5.85s
Train Epoch: 2253 [81920/90000 (91%)]	Loss: -6.6168	Cost: 6.30s
Train Epoch: 2253 	Average Loss: -7.0306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6310

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2254 [0/90000 (0%)]	Loss: -7.9618	Cost: 24.21s
Train Epoch: 2254 [20480/90000 (23%)]	Loss: -6.4068	Cost: 6.09s
Train Epoch: 2254 [40960/90000 (45%)]	Loss: -6.3845	Cost: 8.08s
Train Epoch: 2254 [61440/90000 (68%)]	Loss: -6.9788	Cost: 5.87s
Train Epoch: 2254 [81920/90000 (91%)]	Loss: -6.7517	Cost: 5.84s
Train Epoch: 2254 	Average Loss: -7.0337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7889

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2255 [0/90000 (0%)]	Loss: -5.9997	Cost: 23.69s
Train Epoch: 2255 [20480/90000 (23%)]	Loss: -6.4230	Cost: 6.12s
Train Epoch: 2255 [40960/90000 (45%)]	Loss: -6.3932	Cost: 8.17s
Train Epoch: 2255 [61440/90000 (68%)]	Loss: -7.0020	Cost: 5.85s
Train Epoch: 2255 [81920/90000 (91%)]	Loss: -6.5941	Cost: 6.29s
Train Epoch: 2255 	Average Loss: -6.9428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7795

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2256 [0/90000 (0%)]	Loss: -7.6572	Cost: 23.47s
Train Epoch: 2256 [20480/90000 (23%)]	Loss: -6.6164	Cost: 6.09s
Train Epoch: 2256 [40960/90000 (45%)]	Loss: -6.4706	Cost: 8.11s
Train Epoch: 2256 [61440/90000 (68%)]	Loss: -6.8672	Cost: 6.02s
Train Epoch: 2256 [81920/90000 (91%)]	Loss: -6.5606	Cost: 6.20s
Train Epoch: 2256 	Average Loss: -7.0808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5896

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2257 [0/90000 (0%)]	Loss: -6.3167	Cost: 24.09s
Train Epoch: 2257 [20480/90000 (23%)]	Loss: -6.5322	Cost: 6.04s
Train Epoch: 2257 [40960/90000 (45%)]	Loss: -6.3572	Cost: 8.00s
Train Epoch: 2257 [61440/90000 (68%)]	Loss: -7.1283	Cost: 5.83s
Train Epoch: 2257 [81920/90000 (91%)]	Loss: -6.7385	Cost: 6.16s
Train Epoch: 2257 	Average Loss: -7.0321
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7223

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2258 [0/90000 (0%)]	Loss: -5.9175	Cost: 23.44s
Train Epoch: 2258 [20480/90000 (23%)]	Loss: -6.5071	Cost: 6.16s
Train Epoch: 2258 [40960/90000 (45%)]	Loss: -6.3353	Cost: 8.15s
Train Epoch: 2258 [61440/90000 (68%)]	Loss: -6.9016	Cost: 5.88s
Train Epoch: 2258 [81920/90000 (91%)]	Loss: -6.5896	Cost: 6.28s
Train Epoch: 2258 	Average Loss: -6.9757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6980

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2259 [0/90000 (0%)]	Loss: -7.5229	Cost: 24.33s
Train Epoch: 2259 [20480/90000 (23%)]	Loss: -6.5346	Cost: 6.06s
Train Epoch: 2259 [40960/90000 (45%)]	Loss: -6.6053	Cost: 7.68s
Train Epoch: 2259 [61440/90000 (68%)]	Loss: -6.9680	Cost: 5.84s
Train Epoch: 2259 [81920/90000 (91%)]	Loss: -6.6077	Cost: 6.11s
Train Epoch: 2259 	Average Loss: -7.0375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8902

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2260 [0/90000 (0%)]	Loss: -7.1278	Cost: 23.64s
Train Epoch: 2260 [20480/90000 (23%)]	Loss: -6.4654	Cost: 6.10s
Train Epoch: 2260 [40960/90000 (45%)]	Loss: -6.4169	Cost: 8.22s
Train Epoch: 2260 [61440/90000 (68%)]	Loss: -6.8653	Cost: 5.86s
Train Epoch: 2260 [81920/90000 (91%)]	Loss: -6.6431	Cost: 6.45s
Train Epoch: 2260 	Average Loss: -7.0458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6880

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2261 [0/90000 (0%)]	Loss: -6.6193	Cost: 23.79s
Train Epoch: 2261 [20480/90000 (23%)]	Loss: -6.4812	Cost: 6.17s
Train Epoch: 2261 [40960/90000 (45%)]	Loss: -6.5531	Cost: 7.95s
Train Epoch: 2261 [61440/90000 (68%)]	Loss: -6.8810	Cost: 5.90s
Train Epoch: 2261 [81920/90000 (91%)]	Loss: -6.7600	Cost: 6.14s
Train Epoch: 2261 	Average Loss: -7.0456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5535

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2262 [0/90000 (0%)]	Loss: -8.6317	Cost: 23.87s
Train Epoch: 2262 [20480/90000 (23%)]	Loss: -6.5580	Cost: 6.26s
Train Epoch: 2262 [40960/90000 (45%)]	Loss: -6.2808	Cost: 7.97s
Train Epoch: 2262 [61440/90000 (68%)]	Loss: -7.0389	Cost: 5.85s
Train Epoch: 2262 [81920/90000 (91%)]	Loss: -6.6225	Cost: 6.33s
Train Epoch: 2262 	Average Loss: -7.0533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8142

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2263 [0/90000 (0%)]	Loss: -4.6821	Cost: 23.65s
Train Epoch: 2263 [20480/90000 (23%)]	Loss: -6.4792	Cost: 6.13s
Train Epoch: 2263 [40960/90000 (45%)]	Loss: -6.3209	Cost: 7.91s
Train Epoch: 2263 [61440/90000 (68%)]	Loss: -6.9989	Cost: 5.83s
Train Epoch: 2263 [81920/90000 (91%)]	Loss: -6.6356	Cost: 6.11s
Train Epoch: 2263 	Average Loss: -6.9683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6458

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2264 [0/90000 (0%)]	Loss: -4.3259	Cost: 23.64s
Train Epoch: 2264 [20480/90000 (23%)]	Loss: -6.5843	Cost: 6.10s
Train Epoch: 2264 [40960/90000 (45%)]	Loss: -6.3933	Cost: 8.09s
Train Epoch: 2264 [61440/90000 (68%)]	Loss: -6.9211	Cost: 5.86s
Train Epoch: 2264 [81920/90000 (91%)]	Loss: -6.7606	Cost: 6.14s
Train Epoch: 2264 	Average Loss: -6.9742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7432

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2265 [0/90000 (0%)]	Loss: -6.5985	Cost: 24.07s
Train Epoch: 2265 [20480/90000 (23%)]	Loss: -6.3383	Cost: 6.10s
Train Epoch: 2265 [40960/90000 (45%)]	Loss: -6.4396	Cost: 8.04s
Train Epoch: 2265 [61440/90000 (68%)]	Loss: -6.9896	Cost: 5.88s
Train Epoch: 2265 [81920/90000 (91%)]	Loss: -6.7086	Cost: 6.29s
Train Epoch: 2265 	Average Loss: -6.9522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7683

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2266 [0/90000 (0%)]	Loss: -6.0685	Cost: 23.78s
Train Epoch: 2266 [20480/90000 (23%)]	Loss: -6.3906	Cost: 6.15s
Train Epoch: 2266 [40960/90000 (45%)]	Loss: -6.3826	Cost: 8.05s
Train Epoch: 2266 [61440/90000 (68%)]	Loss: -7.0453	Cost: 5.85s
Train Epoch: 2266 [81920/90000 (91%)]	Loss: -6.5828	Cost: 6.46s
Train Epoch: 2266 	Average Loss: -7.0349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7683

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2267 [0/90000 (0%)]	Loss: -8.3975	Cost: 23.76s
Train Epoch: 2267 [20480/90000 (23%)]	Loss: -6.5263	Cost: 6.06s
Train Epoch: 2267 [40960/90000 (45%)]	Loss: -6.4342	Cost: 8.14s
Train Epoch: 2267 [61440/90000 (68%)]	Loss: -6.9436	Cost: 5.84s
Train Epoch: 2267 [81920/90000 (91%)]	Loss: -6.5959	Cost: 6.30s
Train Epoch: 2267 	Average Loss: -7.1090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8353

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2268 [0/90000 (0%)]	Loss: -6.7473	Cost: 24.08s
Train Epoch: 2268 [20480/90000 (23%)]	Loss: -6.6914	Cost: 6.15s
Train Epoch: 2268 [40960/90000 (45%)]	Loss: -6.3027	Cost: 8.15s
Train Epoch: 2268 [61440/90000 (68%)]	Loss: -7.0504	Cost: 5.84s
Train Epoch: 2268 [81920/90000 (91%)]	Loss: -6.4690	Cost: 6.19s
Train Epoch: 2268 	Average Loss: -7.0931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7801

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2269 [0/90000 (0%)]	Loss: -7.4870	Cost: 24.29s
Train Epoch: 2269 [20480/90000 (23%)]	Loss: -6.4783	Cost: 6.09s
Train Epoch: 2269 [40960/90000 (45%)]	Loss: -6.2970	Cost: 7.92s
Train Epoch: 2269 [61440/90000 (68%)]	Loss: -7.0410	Cost: 5.85s
Train Epoch: 2269 [81920/90000 (91%)]	Loss: -6.7199	Cost: 6.06s
Train Epoch: 2269 	Average Loss: -7.0389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8321

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2270 [0/90000 (0%)]	Loss: -7.3290	Cost: 23.42s
Train Epoch: 2270 [20480/90000 (23%)]	Loss: -6.4187	Cost: 6.09s
Train Epoch: 2270 [40960/90000 (45%)]	Loss: -6.2645	Cost: 8.13s
Train Epoch: 2270 [61440/90000 (68%)]	Loss: -6.9583	Cost: 5.85s
Train Epoch: 2270 [81920/90000 (91%)]	Loss: -6.6215	Cost: 6.33s
Train Epoch: 2270 	Average Loss: -7.0201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7774

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2271 [0/90000 (0%)]	Loss: -6.0917	Cost: 23.48s
Train Epoch: 2271 [20480/90000 (23%)]	Loss: -6.5874	Cost: 6.13s
Train Epoch: 2271 [40960/90000 (45%)]	Loss: -6.3437	Cost: 7.91s
Train Epoch: 2271 [61440/90000 (68%)]	Loss: -7.1157	Cost: 5.84s
Train Epoch: 2271 [81920/90000 (91%)]	Loss: -6.8467	Cost: 6.25s
Train Epoch: 2271 	Average Loss: -7.0002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7165

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2272 [0/90000 (0%)]	Loss: -6.8338	Cost: 23.56s
Train Epoch: 2272 [20480/90000 (23%)]	Loss: -6.4449	Cost: 6.10s
Train Epoch: 2272 [40960/90000 (45%)]	Loss: -6.4788	Cost: 8.12s
Train Epoch: 2272 [61440/90000 (68%)]	Loss: -7.0392	Cost: 5.86s
Train Epoch: 2272 [81920/90000 (91%)]	Loss: -6.6923	Cost: 6.37s
Train Epoch: 2272 	Average Loss: -7.0370
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8047

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2273 [0/90000 (0%)]	Loss: -6.2811	Cost: 23.84s
Train Epoch: 2273 [20480/90000 (23%)]	Loss: -6.4048	Cost: 6.07s
Train Epoch: 2273 [40960/90000 (45%)]	Loss: -6.5027	Cost: 7.84s
Train Epoch: 2273 [61440/90000 (68%)]	Loss: -6.9892	Cost: 5.85s
Train Epoch: 2273 [81920/90000 (91%)]	Loss: -6.6215	Cost: 6.16s
Train Epoch: 2273 	Average Loss: -6.9923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6940

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2274 [0/90000 (0%)]	Loss: -7.1301	Cost: 23.89s
Train Epoch: 2274 [20480/90000 (23%)]	Loss: -6.4324	Cost: 6.19s
Train Epoch: 2274 [40960/90000 (45%)]	Loss: -6.2610	Cost: 7.74s
Train Epoch: 2274 [61440/90000 (68%)]	Loss: -6.8968	Cost: 5.85s
Train Epoch: 2274 [81920/90000 (91%)]	Loss: -6.7576	Cost: 6.33s
Train Epoch: 2274 	Average Loss: -7.0638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6987

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2275 [0/90000 (0%)]	Loss: -6.7508	Cost: 23.52s
Train Epoch: 2275 [20480/90000 (23%)]	Loss: -6.6326	Cost: 6.11s
Train Epoch: 2275 [40960/90000 (45%)]	Loss: -6.1269	Cost: 7.93s
Train Epoch: 2275 [61440/90000 (68%)]	Loss: -7.1417	Cost: 5.86s
Train Epoch: 2275 [81920/90000 (91%)]	Loss: -6.5678	Cost: 6.10s
Train Epoch: 2275 	Average Loss: -6.9880
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7691

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2276 [0/90000 (0%)]	Loss: -6.8597	Cost: 23.54s
Train Epoch: 2276 [20480/90000 (23%)]	Loss: -6.5263	Cost: 6.18s
Train Epoch: 2276 [40960/90000 (45%)]	Loss: -6.3344	Cost: 7.86s
Train Epoch: 2276 [61440/90000 (68%)]	Loss: -6.8190	Cost: 5.89s
Train Epoch: 2276 [81920/90000 (91%)]	Loss: -6.6772	Cost: 6.28s
Train Epoch: 2276 	Average Loss: -6.9379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6167

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2277 [0/90000 (0%)]	Loss: -5.7069	Cost: 23.54s
Train Epoch: 2277 [20480/90000 (23%)]	Loss: -6.6137	Cost: 6.36s
Train Epoch: 2277 [40960/90000 (45%)]	Loss: -6.4243	Cost: 7.79s
Train Epoch: 2277 [61440/90000 (68%)]	Loss: -7.0877	Cost: 5.91s
Train Epoch: 2277 [81920/90000 (91%)]	Loss: -6.7434	Cost: 5.95s
Train Epoch: 2277 	Average Loss: -6.9522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6570

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2278 [0/90000 (0%)]	Loss: -7.7176	Cost: 23.79s
Train Epoch: 2278 [20480/90000 (23%)]	Loss: -6.4745	Cost: 6.19s
Train Epoch: 2278 [40960/90000 (45%)]	Loss: -6.3154	Cost: 8.12s
Train Epoch: 2278 [61440/90000 (68%)]	Loss: -6.9301	Cost: 6.14s
Train Epoch: 2278 [81920/90000 (91%)]	Loss: -6.7357	Cost: 6.00s
Train Epoch: 2278 	Average Loss: -7.0509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8382

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2279 [0/90000 (0%)]	Loss: -7.3337	Cost: 23.56s
Train Epoch: 2279 [20480/90000 (23%)]	Loss: -6.3344	Cost: 6.09s
Train Epoch: 2279 [40960/90000 (45%)]	Loss: -6.3438	Cost: 8.11s
Train Epoch: 2279 [61440/90000 (68%)]	Loss: -7.1676	Cost: 5.95s
Train Epoch: 2279 [81920/90000 (91%)]	Loss: -6.7329	Cost: 5.77s
Train Epoch: 2279 	Average Loss: -7.0555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8014

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2280 [0/90000 (0%)]	Loss: -7.1675	Cost: 23.49s
Train Epoch: 2280 [20480/90000 (23%)]	Loss: -6.4488	Cost: 6.22s
Train Epoch: 2280 [40960/90000 (45%)]	Loss: -6.3114	Cost: 8.06s
Train Epoch: 2280 [61440/90000 (68%)]	Loss: -6.9418	Cost: 5.87s
Train Epoch: 2280 [81920/90000 (91%)]	Loss: -6.7084	Cost: 6.41s
Train Epoch: 2280 	Average Loss: -7.0463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6824

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2281 [0/90000 (0%)]	Loss: -6.2353	Cost: 23.71s
Train Epoch: 2281 [20480/90000 (23%)]	Loss: -6.4365	Cost: 6.21s
Train Epoch: 2281 [40960/90000 (45%)]	Loss: -6.3372	Cost: 7.92s
Train Epoch: 2281 [61440/90000 (68%)]	Loss: -7.1134	Cost: 5.85s
Train Epoch: 2281 [81920/90000 (91%)]	Loss: -6.8183	Cost: 6.23s
Train Epoch: 2281 	Average Loss: -7.0630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7843

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2282 [0/90000 (0%)]	Loss: -5.8931	Cost: 23.53s
Train Epoch: 2282 [20480/90000 (23%)]	Loss: -6.5357	Cost: 6.18s
Train Epoch: 2282 [40960/90000 (45%)]	Loss: -6.4519	Cost: 7.96s
Train Epoch: 2282 [61440/90000 (68%)]	Loss: -6.9546	Cost: 5.87s
Train Epoch: 2282 [81920/90000 (91%)]	Loss: -6.6887	Cost: 6.29s
Train Epoch: 2282 	Average Loss: -6.9712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7376

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2283 [0/90000 (0%)]	Loss: -7.0640	Cost: 23.89s
Train Epoch: 2283 [20480/90000 (23%)]	Loss: -6.4279	Cost: 6.04s
Train Epoch: 2283 [40960/90000 (45%)]	Loss: -6.4645	Cost: 7.75s
Train Epoch: 2283 [61440/90000 (68%)]	Loss: -7.0896	Cost: 6.01s
Train Epoch: 2283 [81920/90000 (91%)]	Loss: -6.7081	Cost: 6.51s
Train Epoch: 2283 	Average Loss: -7.0617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6029

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2284 [0/90000 (0%)]	Loss: -7.5748	Cost: 24.00s
Train Epoch: 2284 [20480/90000 (23%)]	Loss: -6.5106	Cost: 6.74s
Train Epoch: 2284 [40960/90000 (45%)]	Loss: -6.5920	Cost: 7.32s
Train Epoch: 2284 [61440/90000 (68%)]	Loss: -6.9735	Cost: 5.89s
Train Epoch: 2284 [81920/90000 (91%)]	Loss: -6.6767	Cost: 6.38s
Train Epoch: 2284 	Average Loss: -7.0435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6208

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2285 [0/90000 (0%)]	Loss: -7.7755	Cost: 23.66s
Train Epoch: 2285 [20480/90000 (23%)]	Loss: -6.4508	Cost: 6.12s
Train Epoch: 2285 [40960/90000 (45%)]	Loss: -6.3665	Cost: 7.94s
Train Epoch: 2285 [61440/90000 (68%)]	Loss: -7.0265	Cost: 5.86s
Train Epoch: 2285 [81920/90000 (91%)]	Loss: -6.7588	Cost: 6.09s
Train Epoch: 2285 	Average Loss: -6.9635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7369

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2286 [0/90000 (0%)]	Loss: -6.5364	Cost: 23.43s
Train Epoch: 2286 [20480/90000 (23%)]	Loss: -6.6581	Cost: 6.06s
Train Epoch: 2286 [40960/90000 (45%)]	Loss: -6.5432	Cost: 8.21s
Train Epoch: 2286 [61440/90000 (68%)]	Loss: -6.9951	Cost: 5.87s
Train Epoch: 2286 [81920/90000 (91%)]	Loss: -6.6124	Cost: 6.37s
Train Epoch: 2286 	Average Loss: -7.0390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7015

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2287 [0/90000 (0%)]	Loss: -7.4869	Cost: 23.83s
Train Epoch: 2287 [20480/90000 (23%)]	Loss: -6.4590	Cost: 6.11s
Train Epoch: 2287 [40960/90000 (45%)]	Loss: -6.2774	Cost: 8.04s
Train Epoch: 2287 [61440/90000 (68%)]	Loss: -6.9381	Cost: 5.84s
Train Epoch: 2287 [81920/90000 (91%)]	Loss: -6.7706	Cost: 6.43s
Train Epoch: 2287 	Average Loss: -7.0830
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7204

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2288 [0/90000 (0%)]	Loss: -7.3357	Cost: 23.56s
Train Epoch: 2288 [20480/90000 (23%)]	Loss: -6.5055	Cost: 6.09s
Train Epoch: 2288 [40960/90000 (45%)]	Loss: -6.3587	Cost: 7.94s
Train Epoch: 2288 [61440/90000 (68%)]	Loss: -6.7827	Cost: 5.84s
Train Epoch: 2288 [81920/90000 (91%)]	Loss: -6.7503	Cost: 6.33s
Train Epoch: 2288 	Average Loss: -7.0632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7532

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2289 [0/90000 (0%)]	Loss: -7.3607	Cost: 23.88s
Train Epoch: 2289 [20480/90000 (23%)]	Loss: -6.3538	Cost: 6.14s
Train Epoch: 2289 [40960/90000 (45%)]	Loss: -6.3634	Cost: 7.83s
Train Epoch: 2289 [61440/90000 (68%)]	Loss: -6.8937	Cost: 5.91s
Train Epoch: 2289 [81920/90000 (91%)]	Loss: -6.6221	Cost: 6.39s
Train Epoch: 2289 	Average Loss: -7.0104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6762

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2290 [0/90000 (0%)]	Loss: -6.1952	Cost: 23.58s
Train Epoch: 2290 [20480/90000 (23%)]	Loss: -6.4068	Cost: 6.09s
Train Epoch: 2290 [40960/90000 (45%)]	Loss: -6.2923	Cost: 7.80s
Train Epoch: 2290 [61440/90000 (68%)]	Loss: -7.0242	Cost: 5.88s
Train Epoch: 2290 [81920/90000 (91%)]	Loss: -6.8147	Cost: 6.28s
Train Epoch: 2290 	Average Loss: -6.9704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7557

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2291 [0/90000 (0%)]	Loss: -7.6194	Cost: 23.19s
Train Epoch: 2291 [20480/90000 (23%)]	Loss: -6.5105	Cost: 6.18s
Train Epoch: 2291 [40960/90000 (45%)]	Loss: -6.4381	Cost: 7.70s
Train Epoch: 2291 [61440/90000 (68%)]	Loss: -7.0336	Cost: 5.88s
Train Epoch: 2291 [81920/90000 (91%)]	Loss: -6.6639	Cost: 6.14s
Train Epoch: 2291 	Average Loss: -7.0290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7159

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2292 [0/90000 (0%)]	Loss: -6.4202	Cost: 23.58s
Train Epoch: 2292 [20480/90000 (23%)]	Loss: -6.4993	Cost: 6.10s
Train Epoch: 2292 [40960/90000 (45%)]	Loss: -6.3555	Cost: 8.16s
Train Epoch: 2292 [61440/90000 (68%)]	Loss: -6.9523	Cost: 5.82s
Train Epoch: 2292 [81920/90000 (91%)]	Loss: -6.5248	Cost: 6.33s
Train Epoch: 2292 	Average Loss: -7.0415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8546

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2293 [0/90000 (0%)]	Loss: -7.3585	Cost: 23.65s
Train Epoch: 2293 [20480/90000 (23%)]	Loss: -6.4508	Cost: 6.06s
Train Epoch: 2293 [40960/90000 (45%)]	Loss: -6.2879	Cost: 8.03s
Train Epoch: 2293 [61440/90000 (68%)]	Loss: -6.9691	Cost: 5.83s
Train Epoch: 2293 [81920/90000 (91%)]	Loss: -6.7154	Cost: 6.02s
Train Epoch: 2293 	Average Loss: -7.0055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7272

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2294 [0/90000 (0%)]	Loss: -6.4888	Cost: 23.65s
Train Epoch: 2294 [20480/90000 (23%)]	Loss: -6.5403	Cost: 6.07s
Train Epoch: 2294 [40960/90000 (45%)]	Loss: -6.3146	Cost: 8.02s
Train Epoch: 2294 [61440/90000 (68%)]	Loss: -7.0224	Cost: 5.86s
Train Epoch: 2294 [81920/90000 (91%)]	Loss: -6.7681	Cost: 6.19s
Train Epoch: 2294 	Average Loss: -7.0586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8116

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2295 [0/90000 (0%)]	Loss: -8.0488	Cost: 23.90s
Train Epoch: 2295 [20480/90000 (23%)]	Loss: -6.5360	Cost: 6.12s
Train Epoch: 2295 [40960/90000 (45%)]	Loss: -6.3320	Cost: 7.72s
Train Epoch: 2295 [61440/90000 (68%)]	Loss: -6.9801	Cost: 5.89s
Train Epoch: 2295 [81920/90000 (91%)]	Loss: -6.7172	Cost: 6.13s
Train Epoch: 2295 	Average Loss: -7.0861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6382

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2296 [0/90000 (0%)]	Loss: -7.9721	Cost: 23.57s
Train Epoch: 2296 [20480/90000 (23%)]	Loss: -6.3894	Cost: 6.04s
Train Epoch: 2296 [40960/90000 (45%)]	Loss: -6.3611	Cost: 8.15s
Train Epoch: 2296 [61440/90000 (68%)]	Loss: -7.1130	Cost: 5.90s
Train Epoch: 2296 [81920/90000 (91%)]	Loss: -6.6871	Cost: 6.15s
Train Epoch: 2296 	Average Loss: -7.0240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7330

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2297 [0/90000 (0%)]	Loss: -7.4135	Cost: 23.59s
Train Epoch: 2297 [20480/90000 (23%)]	Loss: -6.6251	Cost: 6.09s
Train Epoch: 2297 [40960/90000 (45%)]	Loss: -6.3238	Cost: 8.00s
Train Epoch: 2297 [61440/90000 (68%)]	Loss: -6.8474	Cost: 5.87s
Train Epoch: 2297 [81920/90000 (91%)]	Loss: -6.6580	Cost: 6.07s
Train Epoch: 2297 	Average Loss: -7.0105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6901

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2298 [0/90000 (0%)]	Loss: -7.0370	Cost: 23.39s
Train Epoch: 2298 [20480/90000 (23%)]	Loss: -6.6260	Cost: 6.03s
Train Epoch: 2298 [40960/90000 (45%)]	Loss: -6.2532	Cost: 8.23s
Train Epoch: 2298 [61440/90000 (68%)]	Loss: -6.9521	Cost: 5.87s
Train Epoch: 2298 [81920/90000 (91%)]	Loss: -6.6482	Cost: 6.28s
Train Epoch: 2298 	Average Loss: -7.0195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6616

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2299 [0/90000 (0%)]	Loss: -6.5596	Cost: 23.51s
Train Epoch: 2299 [20480/90000 (23%)]	Loss: -6.5562	Cost: 6.06s
Train Epoch: 2299 [40960/90000 (45%)]	Loss: -6.3443	Cost: 8.06s
Train Epoch: 2299 [61440/90000 (68%)]	Loss: -6.8538	Cost: 5.86s
Train Epoch: 2299 [81920/90000 (91%)]	Loss: -6.6902	Cost: 6.14s
Train Epoch: 2299 	Average Loss: -7.0508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5338

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2300 [0/90000 (0%)]	Loss: -7.9864	Cost: 23.12s
Train Epoch: 2300 [20480/90000 (23%)]	Loss: -6.4448	Cost: 6.13s
Train Epoch: 2300 [40960/90000 (45%)]	Loss: -6.4467	Cost: 8.13s
Train Epoch: 2300 [61440/90000 (68%)]	Loss: -6.9407	Cost: 5.86s
Train Epoch: 2300 [81920/90000 (91%)]	Loss: -6.6043	Cost: 6.29s
Train Epoch: 2300 	Average Loss: -7.0848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5836

Saving model as model.pt_e2300 & waveforms_supplementary.hdf5_e2300
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2301 [0/90000 (0%)]	Loss: -7.0348	Cost: 23.46s
Train Epoch: 2301 [20480/90000 (23%)]	Loss: -6.4562	Cost: 6.11s
Train Epoch: 2301 [40960/90000 (45%)]	Loss: -6.4385	Cost: 8.03s
Train Epoch: 2301 [61440/90000 (68%)]	Loss: -6.9371	Cost: 5.93s
Train Epoch: 2301 [81920/90000 (91%)]	Loss: -6.6724	Cost: 6.28s
Train Epoch: 2301 	Average Loss: -7.0004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7799

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2302 [0/90000 (0%)]	Loss: -6.7162	Cost: 24.25s
Train Epoch: 2302 [20480/90000 (23%)]	Loss: -6.5718	Cost: 6.12s
Train Epoch: 2302 [40960/90000 (45%)]	Loss: -6.3726	Cost: 8.13s
Train Epoch: 2302 [61440/90000 (68%)]	Loss: -7.0011	Cost: 5.87s
Train Epoch: 2302 [81920/90000 (91%)]	Loss: -6.7211	Cost: 6.09s
Train Epoch: 2302 	Average Loss: -7.0256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6608

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2303 [0/90000 (0%)]	Loss: -7.1120	Cost: 23.53s
Train Epoch: 2303 [20480/90000 (23%)]	Loss: -6.6122	Cost: 6.13s
Train Epoch: 2303 [40960/90000 (45%)]	Loss: -6.3979	Cost: 8.13s
Train Epoch: 2303 [61440/90000 (68%)]	Loss: -6.9739	Cost: 5.93s
Train Epoch: 2303 [81920/90000 (91%)]	Loss: -6.7010	Cost: 6.06s
Train Epoch: 2303 	Average Loss: -7.0710
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6972

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2304 [0/90000 (0%)]	Loss: -8.0641	Cost: 23.69s
Train Epoch: 2304 [20480/90000 (23%)]	Loss: -6.4540	Cost: 6.25s
Train Epoch: 2304 [40960/90000 (45%)]	Loss: -6.3635	Cost: 8.21s
Train Epoch: 2304 [61440/90000 (68%)]	Loss: -7.0521	Cost: 5.88s
Train Epoch: 2304 [81920/90000 (91%)]	Loss: -6.7473	Cost: 6.05s
Train Epoch: 2304 	Average Loss: -7.0501
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6822

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2305 [0/90000 (0%)]	Loss: -6.9211	Cost: 23.91s
Train Epoch: 2305 [20480/90000 (23%)]	Loss: -6.5696	Cost: 6.13s
Train Epoch: 2305 [40960/90000 (45%)]	Loss: -6.2865	Cost: 7.92s
Train Epoch: 2305 [61440/90000 (68%)]	Loss: -7.0570	Cost: 5.85s
Train Epoch: 2305 [81920/90000 (91%)]	Loss: -6.6378	Cost: 6.13s
Train Epoch: 2305 	Average Loss: -7.0056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7604

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2306 [0/90000 (0%)]	Loss: -6.6294	Cost: 23.55s
Train Epoch: 2306 [20480/90000 (23%)]	Loss: -6.4315	Cost: 6.10s
Train Epoch: 2306 [40960/90000 (45%)]	Loss: -6.4212	Cost: 8.43s
Train Epoch: 2306 [61440/90000 (68%)]	Loss: -6.9777	Cost: 6.01s
Train Epoch: 2306 [81920/90000 (91%)]	Loss: -6.6977	Cost: 6.13s
Train Epoch: 2306 	Average Loss: -7.0232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6950

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2307 [0/90000 (0%)]	Loss: -6.5868	Cost: 23.62s
Train Epoch: 2307 [20480/90000 (23%)]	Loss: -6.4296	Cost: 6.06s
Train Epoch: 2307 [40960/90000 (45%)]	Loss: -6.2542	Cost: 8.01s
Train Epoch: 2307 [61440/90000 (68%)]	Loss: -7.0128	Cost: 5.82s
Train Epoch: 2307 [81920/90000 (91%)]	Loss: -6.7441	Cost: 6.18s
Train Epoch: 2307 	Average Loss: -6.9911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6783

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2308 [0/90000 (0%)]	Loss: -8.3182	Cost: 23.50s
Train Epoch: 2308 [20480/90000 (23%)]	Loss: -6.4016	Cost: 6.17s
Train Epoch: 2308 [40960/90000 (45%)]	Loss: -6.3192	Cost: 8.28s
Train Epoch: 2308 [61440/90000 (68%)]	Loss: -6.9169	Cost: 5.89s
Train Epoch: 2308 [81920/90000 (91%)]	Loss: -6.8733	Cost: 6.16s
Train Epoch: 2308 	Average Loss: -7.0701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6414

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2309 [0/90000 (0%)]	Loss: -8.2803	Cost: 23.66s
Train Epoch: 2309 [20480/90000 (23%)]	Loss: -6.4582	Cost: 6.12s
Train Epoch: 2309 [40960/90000 (45%)]	Loss: -6.3218	Cost: 8.01s
Train Epoch: 2309 [61440/90000 (68%)]	Loss: -7.1376	Cost: 5.85s
Train Epoch: 2309 [81920/90000 (91%)]	Loss: -6.6947	Cost: 6.11s
Train Epoch: 2309 	Average Loss: -7.0432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6767

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2310 [0/90000 (0%)]	Loss: -6.2765	Cost: 23.42s
Train Epoch: 2310 [20480/90000 (23%)]	Loss: -6.5839	Cost: 6.08s
Train Epoch: 2310 [40960/90000 (45%)]	Loss: -6.4452	Cost: 8.31s
Train Epoch: 2310 [61440/90000 (68%)]	Loss: -7.0071	Cost: 5.85s
Train Epoch: 2310 [81920/90000 (91%)]	Loss: -6.7202	Cost: 6.55s
Train Epoch: 2310 	Average Loss: -7.0757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6314

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2311 [0/90000 (0%)]	Loss: -7.3481	Cost: 23.71s
Train Epoch: 2311 [20480/90000 (23%)]	Loss: -6.4847	Cost: 6.07s
Train Epoch: 2311 [40960/90000 (45%)]	Loss: -6.4875	Cost: 7.83s
Train Epoch: 2311 [61440/90000 (68%)]	Loss: -7.1764	Cost: 5.94s
Train Epoch: 2311 [81920/90000 (91%)]	Loss: -6.6611	Cost: 6.04s
Train Epoch: 2311 	Average Loss: -7.0264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8194

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2312 [0/90000 (0%)]	Loss: -4.8903	Cost: 23.49s
Train Epoch: 2312 [20480/90000 (23%)]	Loss: -6.6194	Cost: 6.13s
Train Epoch: 2312 [40960/90000 (45%)]	Loss: -6.3211	Cost: 8.05s
Train Epoch: 2312 [61440/90000 (68%)]	Loss: -7.0539	Cost: 5.88s
Train Epoch: 2312 [81920/90000 (91%)]	Loss: -6.4601	Cost: 6.61s
Train Epoch: 2312 	Average Loss: -6.9235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6382

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2313 [0/90000 (0%)]	Loss: -7.8707	Cost: 24.41s
Train Epoch: 2313 [20480/90000 (23%)]	Loss: -6.5841	Cost: 6.08s
Train Epoch: 2313 [40960/90000 (45%)]	Loss: -6.3205	Cost: 7.79s
Train Epoch: 2313 [61440/90000 (68%)]	Loss: -6.9895	Cost: 5.84s
Train Epoch: 2313 [81920/90000 (91%)]	Loss: -6.7948	Cost: 6.05s
Train Epoch: 2313 	Average Loss: -7.0589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6895

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2314 [0/90000 (0%)]	Loss: -6.8820	Cost: 23.44s
Train Epoch: 2314 [20480/90000 (23%)]	Loss: -6.4772	Cost: 6.12s
Train Epoch: 2314 [40960/90000 (45%)]	Loss: -6.3548	Cost: 7.97s
Train Epoch: 2314 [61440/90000 (68%)]	Loss: -6.8424	Cost: 5.84s
Train Epoch: 2314 [81920/90000 (91%)]	Loss: -6.6858	Cost: 6.65s
Train Epoch: 2314 	Average Loss: -6.9888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5542

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2315 [0/90000 (0%)]	Loss: -5.1338	Cost: 23.18s
Train Epoch: 2315 [20480/90000 (23%)]	Loss: -6.5106	Cost: 6.00s
Train Epoch: 2315 [40960/90000 (45%)]	Loss: -6.2371	Cost: 8.09s
Train Epoch: 2315 [61440/90000 (68%)]	Loss: -7.0642	Cost: 5.86s
Train Epoch: 2315 [81920/90000 (91%)]	Loss: -6.6424	Cost: 6.58s
Train Epoch: 2315 	Average Loss: -6.9716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7452

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2316 [0/90000 (0%)]	Loss: -5.4027	Cost: 23.53s
Train Epoch: 2316 [20480/90000 (23%)]	Loss: -6.5735	Cost: 6.12s
Train Epoch: 2316 [40960/90000 (45%)]	Loss: -6.4431	Cost: 8.15s
Train Epoch: 2316 [61440/90000 (68%)]	Loss: -7.0991	Cost: 6.24s
Train Epoch: 2316 [81920/90000 (91%)]	Loss: -6.7103	Cost: 5.80s
Train Epoch: 2316 	Average Loss: -6.9962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7496

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2317 [0/90000 (0%)]	Loss: -6.6782	Cost: 23.99s
Train Epoch: 2317 [20480/90000 (23%)]	Loss: -6.5958	Cost: 6.08s
Train Epoch: 2317 [40960/90000 (45%)]	Loss: -6.3984	Cost: 8.21s
Train Epoch: 2317 [61440/90000 (68%)]	Loss: -6.9703	Cost: 5.85s
Train Epoch: 2317 [81920/90000 (91%)]	Loss: -6.5924	Cost: 6.46s
Train Epoch: 2317 	Average Loss: -7.0066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7420

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2318 [0/90000 (0%)]	Loss: -7.6604	Cost: 23.48s
Train Epoch: 2318 [20480/90000 (23%)]	Loss: -6.3865	Cost: 6.27s
Train Epoch: 2318 [40960/90000 (45%)]	Loss: -6.3618	Cost: 7.93s
Train Epoch: 2318 [61440/90000 (68%)]	Loss: -7.0642	Cost: 5.86s
Train Epoch: 2318 [81920/90000 (91%)]	Loss: -6.7622	Cost: 6.32s
Train Epoch: 2318 	Average Loss: -7.0183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7114

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2319 [0/90000 (0%)]	Loss: -8.0770	Cost: 23.13s
Train Epoch: 2319 [20480/90000 (23%)]	Loss: -6.6146	Cost: 6.12s
Train Epoch: 2319 [40960/90000 (45%)]	Loss: -6.4355	Cost: 8.07s
Train Epoch: 2319 [61440/90000 (68%)]	Loss: -6.9319	Cost: 5.86s
Train Epoch: 2319 [81920/90000 (91%)]	Loss: -6.7439	Cost: 6.14s
Train Epoch: 2319 	Average Loss: -7.0414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8888

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2320 [0/90000 (0%)]	Loss: -6.4544	Cost: 23.36s
Train Epoch: 2320 [20480/90000 (23%)]	Loss: -6.4672	Cost: 6.24s
Train Epoch: 2320 [40960/90000 (45%)]	Loss: -6.2259	Cost: 8.10s
Train Epoch: 2320 [61440/90000 (68%)]	Loss: -6.9778	Cost: 5.97s
Train Epoch: 2320 [81920/90000 (91%)]	Loss: -6.7985	Cost: 6.19s
Train Epoch: 2320 	Average Loss: -7.0590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7553

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2321 [0/90000 (0%)]	Loss: -7.5681	Cost: 23.20s
Train Epoch: 2321 [20480/90000 (23%)]	Loss: -6.5394	Cost: 6.14s
Train Epoch: 2321 [40960/90000 (45%)]	Loss: -6.2664	Cost: 8.24s
Train Epoch: 2321 [61440/90000 (68%)]	Loss: -7.0295	Cost: 5.91s
Train Epoch: 2321 [81920/90000 (91%)]	Loss: -6.7289	Cost: 6.02s
Train Epoch: 2321 	Average Loss: -7.0332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7383

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2322 [0/90000 (0%)]	Loss: -8.5159	Cost: 23.29s
Train Epoch: 2322 [20480/90000 (23%)]	Loss: -6.5622	Cost: 6.10s
Train Epoch: 2322 [40960/90000 (45%)]	Loss: -6.2448	Cost: 8.26s
Train Epoch: 2322 [61440/90000 (68%)]	Loss: -6.9146	Cost: 5.90s
Train Epoch: 2322 [81920/90000 (91%)]	Loss: -6.5560	Cost: 6.43s
Train Epoch: 2322 	Average Loss: -7.0365
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7952

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2323 [0/90000 (0%)]	Loss: -5.1004	Cost: 23.60s
Train Epoch: 2323 [20480/90000 (23%)]	Loss: -6.4171	Cost: 6.12s
Train Epoch: 2323 [40960/90000 (45%)]	Loss: -6.3864	Cost: 8.13s
Train Epoch: 2323 [61440/90000 (68%)]	Loss: -6.8926	Cost: 5.86s
Train Epoch: 2323 [81920/90000 (91%)]	Loss: -6.7704	Cost: 6.08s
Train Epoch: 2323 	Average Loss: -7.0009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7222

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2324 [0/90000 (0%)]	Loss: -6.6033	Cost: 23.87s
Train Epoch: 2324 [20480/90000 (23%)]	Loss: -6.5548	Cost: 6.11s
Train Epoch: 2324 [40960/90000 (45%)]	Loss: -6.4765	Cost: 8.02s
Train Epoch: 2324 [61440/90000 (68%)]	Loss: -7.0465	Cost: 5.86s
Train Epoch: 2324 [81920/90000 (91%)]	Loss: -6.4591	Cost: 6.30s
Train Epoch: 2324 	Average Loss: -7.0424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7440

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2325 [0/90000 (0%)]	Loss: -5.9669	Cost: 24.02s
Train Epoch: 2325 [20480/90000 (23%)]	Loss: -6.3427	Cost: 6.07s
Train Epoch: 2325 [40960/90000 (45%)]	Loss: -6.3934	Cost: 8.01s
Train Epoch: 2325 [61440/90000 (68%)]	Loss: -7.0079	Cost: 5.83s
Train Epoch: 2325 [81920/90000 (91%)]	Loss: -6.5123	Cost: 6.29s
Train Epoch: 2325 	Average Loss: -6.9971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8041

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2326 [0/90000 (0%)]	Loss: -7.0818	Cost: 23.89s
Train Epoch: 2326 [20480/90000 (23%)]	Loss: -6.3720	Cost: 6.19s
Train Epoch: 2326 [40960/90000 (45%)]	Loss: -6.3946	Cost: 7.97s
Train Epoch: 2326 [61440/90000 (68%)]	Loss: -7.1572	Cost: 5.95s
Train Epoch: 2326 [81920/90000 (91%)]	Loss: -6.5470	Cost: 6.38s
Train Epoch: 2326 	Average Loss: -7.0715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7742

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2327 [0/90000 (0%)]	Loss: -7.3098	Cost: 23.69s
Train Epoch: 2327 [20480/90000 (23%)]	Loss: -6.6354	Cost: 6.14s
Train Epoch: 2327 [40960/90000 (45%)]	Loss: -6.4935	Cost: 8.09s
Train Epoch: 2327 [61440/90000 (68%)]	Loss: -7.0567	Cost: 6.00s
Train Epoch: 2327 [81920/90000 (91%)]	Loss: -6.8334	Cost: 5.97s
Train Epoch: 2327 	Average Loss: -7.0212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7951

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2328 [0/90000 (0%)]	Loss: -8.1269	Cost: 23.54s
Train Epoch: 2328 [20480/90000 (23%)]	Loss: -6.4426	Cost: 6.06s
Train Epoch: 2328 [40960/90000 (45%)]	Loss: -6.2921	Cost: 8.06s
Train Epoch: 2328 [61440/90000 (68%)]	Loss: -7.1282	Cost: 5.88s
Train Epoch: 2328 [81920/90000 (91%)]	Loss: -6.6855	Cost: 6.38s
Train Epoch: 2328 	Average Loss: -6.9992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7763

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2329 [0/90000 (0%)]	Loss: -5.7613	Cost: 23.96s
Train Epoch: 2329 [20480/90000 (23%)]	Loss: -6.6380	Cost: 6.12s
Train Epoch: 2329 [40960/90000 (45%)]	Loss: -6.3138	Cost: 7.98s
Train Epoch: 2329 [61440/90000 (68%)]	Loss: -6.9997	Cost: 5.84s
Train Epoch: 2329 [81920/90000 (91%)]	Loss: -6.6179	Cost: 6.00s
Train Epoch: 2329 	Average Loss: -6.9915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6093

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2330 [0/90000 (0%)]	Loss: -8.1521	Cost: 23.66s
Train Epoch: 2330 [20480/90000 (23%)]	Loss: -6.5020	Cost: 6.09s
Train Epoch: 2330 [40960/90000 (45%)]	Loss: -6.3837	Cost: 8.01s
Train Epoch: 2330 [61440/90000 (68%)]	Loss: -6.9536	Cost: 5.93s
Train Epoch: 2330 [81920/90000 (91%)]	Loss: -6.8299	Cost: 6.47s
Train Epoch: 2330 	Average Loss: -7.0130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6878

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2331 [0/90000 (0%)]	Loss: -7.2173	Cost: 23.50s
Train Epoch: 2331 [20480/90000 (23%)]	Loss: -6.4856	Cost: 6.09s
Train Epoch: 2331 [40960/90000 (45%)]	Loss: -6.5155	Cost: 8.05s
Train Epoch: 2331 [61440/90000 (68%)]	Loss: -7.0808	Cost: 5.86s
Train Epoch: 2331 [81920/90000 (91%)]	Loss: -6.7345	Cost: 6.35s
Train Epoch: 2331 	Average Loss: -7.0295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6516

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2332 [0/90000 (0%)]	Loss: -7.1928	Cost: 23.97s
Train Epoch: 2332 [20480/90000 (23%)]	Loss: -6.4635	Cost: 6.16s
Train Epoch: 2332 [40960/90000 (45%)]	Loss: -6.2211	Cost: 8.06s
Train Epoch: 2332 [61440/90000 (68%)]	Loss: -7.0068	Cost: 5.91s
Train Epoch: 2332 [81920/90000 (91%)]	Loss: -6.8695	Cost: 6.34s
Train Epoch: 2332 	Average Loss: -7.0694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8561

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2333 [0/90000 (0%)]	Loss: -7.9578	Cost: 23.43s
Train Epoch: 2333 [20480/90000 (23%)]	Loss: -6.6855	Cost: 6.14s
Train Epoch: 2333 [40960/90000 (45%)]	Loss: -6.1938	Cost: 7.97s
Train Epoch: 2333 [61440/90000 (68%)]	Loss: -6.9942	Cost: 5.88s
Train Epoch: 2333 [81920/90000 (91%)]	Loss: -6.7861	Cost: 6.16s
Train Epoch: 2333 	Average Loss: -7.0399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7069

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2334 [0/90000 (0%)]	Loss: -6.7184	Cost: 23.52s
Train Epoch: 2334 [20480/90000 (23%)]	Loss: -6.5782	Cost: 6.12s
Train Epoch: 2334 [40960/90000 (45%)]	Loss: -6.4438	Cost: 8.10s
Train Epoch: 2334 [61440/90000 (68%)]	Loss: -6.9522	Cost: 5.88s
Train Epoch: 2334 [81920/90000 (91%)]	Loss: -6.8403	Cost: 6.36s
Train Epoch: 2334 	Average Loss: -7.0558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8099

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2335 [0/90000 (0%)]	Loss: -7.3114	Cost: 24.35s
Train Epoch: 2335 [20480/90000 (23%)]	Loss: -6.4718	Cost: 6.08s
Train Epoch: 2335 [40960/90000 (45%)]	Loss: -6.3026	Cost: 7.98s
Train Epoch: 2335 [61440/90000 (68%)]	Loss: -6.9855	Cost: 5.86s
Train Epoch: 2335 [81920/90000 (91%)]	Loss: -6.6107	Cost: 6.20s
Train Epoch: 2335 	Average Loss: -7.0540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6422

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2336 [0/90000 (0%)]	Loss: -6.2232	Cost: 23.44s
Train Epoch: 2336 [20480/90000 (23%)]	Loss: -6.3230	Cost: 6.19s
Train Epoch: 2336 [40960/90000 (45%)]	Loss: -6.5373	Cost: 7.89s
Train Epoch: 2336 [61440/90000 (68%)]	Loss: -7.0539	Cost: 5.90s
Train Epoch: 2336 [81920/90000 (91%)]	Loss: -6.6869	Cost: 6.43s
Train Epoch: 2336 	Average Loss: -7.0607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6813

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2337 [0/90000 (0%)]	Loss: -3.1122	Cost: 23.35s
Train Epoch: 2337 [20480/90000 (23%)]	Loss: -6.4496	Cost: 6.22s
Train Epoch: 2337 [40960/90000 (45%)]	Loss: -6.5438	Cost: 7.87s
Train Epoch: 2337 [61440/90000 (68%)]	Loss: -6.9141	Cost: 6.05s
Train Epoch: 2337 [81920/90000 (91%)]	Loss: -6.7289	Cost: 5.90s
Train Epoch: 2337 	Average Loss: -6.9487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5168

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2338 [0/90000 (0%)]	Loss: -7.3255	Cost: 24.50s
Train Epoch: 2338 [20480/90000 (23%)]	Loss: -6.4220	Cost: 6.11s
Train Epoch: 2338 [40960/90000 (45%)]	Loss: -6.3604	Cost: 8.04s
Train Epoch: 2338 [61440/90000 (68%)]	Loss: -7.0239	Cost: 5.88s
Train Epoch: 2338 [81920/90000 (91%)]	Loss: -6.5704	Cost: 6.43s
Train Epoch: 2338 	Average Loss: -7.0660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6899

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2339 [0/90000 (0%)]	Loss: -7.4395	Cost: 23.76s
Train Epoch: 2339 [20480/90000 (23%)]	Loss: -6.6556	Cost: 6.06s
Train Epoch: 2339 [40960/90000 (45%)]	Loss: -6.2269	Cost: 8.16s
Train Epoch: 2339 [61440/90000 (68%)]	Loss: -7.0878	Cost: 5.92s
Train Epoch: 2339 [81920/90000 (91%)]	Loss: -6.7025	Cost: 6.29s
Train Epoch: 2339 	Average Loss: -7.0765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6071

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2340 [0/90000 (0%)]	Loss: -7.8804	Cost: 23.80s
Train Epoch: 2340 [20480/90000 (23%)]	Loss: -6.4936	Cost: 6.19s
Train Epoch: 2340 [40960/90000 (45%)]	Loss: -6.5499	Cost: 7.90s
Train Epoch: 2340 [61440/90000 (68%)]	Loss: -7.0737	Cost: 5.91s
Train Epoch: 2340 [81920/90000 (91%)]	Loss: -6.7020	Cost: 6.36s
Train Epoch: 2340 	Average Loss: -7.1067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7394

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2341 [0/90000 (0%)]	Loss: -6.1390	Cost: 23.77s
Train Epoch: 2341 [20480/90000 (23%)]	Loss: -6.4715	Cost: 6.18s
Train Epoch: 2341 [40960/90000 (45%)]	Loss: -6.3678	Cost: 7.95s
Train Epoch: 2341 [61440/90000 (68%)]	Loss: -7.1412	Cost: 5.93s
Train Epoch: 2341 [81920/90000 (91%)]	Loss: -6.6445	Cost: 6.08s
Train Epoch: 2341 	Average Loss: -7.0727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7231

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2342 [0/90000 (0%)]	Loss: -7.3289	Cost: 23.63s
Train Epoch: 2342 [20480/90000 (23%)]	Loss: -6.3954	Cost: 6.13s
Train Epoch: 2342 [40960/90000 (45%)]	Loss: -6.2829	Cost: 8.19s
Train Epoch: 2342 [61440/90000 (68%)]	Loss: -6.9045	Cost: 5.94s
Train Epoch: 2342 [81920/90000 (91%)]	Loss: -6.7393	Cost: 6.30s
Train Epoch: 2342 	Average Loss: -7.0438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6609

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2343 [0/90000 (0%)]	Loss: -6.2940	Cost: 23.87s
Train Epoch: 2343 [20480/90000 (23%)]	Loss: -6.4302	Cost: 6.10s
Train Epoch: 2343 [40960/90000 (45%)]	Loss: -6.3375	Cost: 8.16s
Train Epoch: 2343 [61440/90000 (68%)]	Loss: -6.8750	Cost: 5.83s
Train Epoch: 2343 [81920/90000 (91%)]	Loss: -6.6917	Cost: 6.24s
Train Epoch: 2343 	Average Loss: -6.9965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6431

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2344 [0/90000 (0%)]	Loss: -5.7148	Cost: 23.24s
Train Epoch: 2344 [20480/90000 (23%)]	Loss: -6.5151	Cost: 6.18s
Train Epoch: 2344 [40960/90000 (45%)]	Loss: -6.4934	Cost: 8.13s
Train Epoch: 2344 [61440/90000 (68%)]	Loss: -6.9527	Cost: 5.94s
Train Epoch: 2344 [81920/90000 (91%)]	Loss: -6.4572	Cost: 6.29s
Train Epoch: 2344 	Average Loss: -7.0070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6644

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2345 [0/90000 (0%)]	Loss: -6.4555	Cost: 23.87s
Train Epoch: 2345 [20480/90000 (23%)]	Loss: -6.4428	Cost: 6.11s
Train Epoch: 2345 [40960/90000 (45%)]	Loss: -6.4676	Cost: 8.00s
Train Epoch: 2345 [61440/90000 (68%)]	Loss: -7.0267	Cost: 5.92s
Train Epoch: 2345 [81920/90000 (91%)]	Loss: -6.6331	Cost: 5.93s
Train Epoch: 2345 	Average Loss: -6.9694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8746

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2346 [0/90000 (0%)]	Loss: -7.5872	Cost: 23.52s
Train Epoch: 2346 [20480/90000 (23%)]	Loss: -6.6252	Cost: 6.15s
Train Epoch: 2346 [40960/90000 (45%)]	Loss: -6.1900	Cost: 8.09s
Train Epoch: 2346 [61440/90000 (68%)]	Loss: -6.9500	Cost: 5.93s
Train Epoch: 2346 [81920/90000 (91%)]	Loss: -6.6428	Cost: 6.36s
Train Epoch: 2346 	Average Loss: -7.0848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8030

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2347 [0/90000 (0%)]	Loss: -6.7172	Cost: 24.04s
Train Epoch: 2347 [20480/90000 (23%)]	Loss: -6.5697	Cost: 6.14s
Train Epoch: 2347 [40960/90000 (45%)]	Loss: -6.3748	Cost: 7.97s
Train Epoch: 2347 [61440/90000 (68%)]	Loss: -7.1339	Cost: 5.95s
Train Epoch: 2347 [81920/90000 (91%)]	Loss: -6.6820	Cost: 6.12s
Train Epoch: 2347 	Average Loss: -7.0233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7996

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2348 [0/90000 (0%)]	Loss: -5.5180	Cost: 23.46s
Train Epoch: 2348 [20480/90000 (23%)]	Loss: -6.4162	Cost: 6.14s
Train Epoch: 2348 [40960/90000 (45%)]	Loss: -6.2818	Cost: 8.15s
Train Epoch: 2348 [61440/90000 (68%)]	Loss: -7.3275	Cost: 5.94s
Train Epoch: 2348 [81920/90000 (91%)]	Loss: -6.6153	Cost: 6.54s
Train Epoch: 2348 	Average Loss: -6.9963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5966

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2349 [0/90000 (0%)]	Loss: -5.7980	Cost: 23.51s
Train Epoch: 2349 [20480/90000 (23%)]	Loss: -6.4362	Cost: 6.15s
Train Epoch: 2349 [40960/90000 (45%)]	Loss: -6.4138	Cost: 8.13s
Train Epoch: 2349 [61440/90000 (68%)]	Loss: -7.1565	Cost: 5.99s
Train Epoch: 2349 [81920/90000 (91%)]	Loss: -6.7334	Cost: 6.31s
Train Epoch: 2349 	Average Loss: -7.0062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7629

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2350 [0/90000 (0%)]	Loss: -5.6673	Cost: 23.73s
Train Epoch: 2350 [20480/90000 (23%)]	Loss: -6.5581	Cost: 6.18s
Train Epoch: 2350 [40960/90000 (45%)]	Loss: -6.2435	Cost: 8.09s
Train Epoch: 2350 [61440/90000 (68%)]	Loss: -7.0771	Cost: 5.84s
Train Epoch: 2350 [81920/90000 (91%)]	Loss: -6.7760	Cost: 6.38s
Train Epoch: 2350 	Average Loss: -6.9945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6956

Saving model as model.pt_e2350 & waveforms_supplementary.hdf5_e2350
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2351 [0/90000 (0%)]	Loss: -6.7882	Cost: 23.90s
Train Epoch: 2351 [20480/90000 (23%)]	Loss: -6.4898	Cost: 6.08s
Train Epoch: 2351 [40960/90000 (45%)]	Loss: -6.1906	Cost: 7.94s
Train Epoch: 2351 [61440/90000 (68%)]	Loss: -6.9134	Cost: 5.87s
Train Epoch: 2351 [81920/90000 (91%)]	Loss: -6.5738	Cost: 6.14s
Train Epoch: 2351 	Average Loss: -6.9929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6201

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2352 [0/90000 (0%)]	Loss: -4.9339	Cost: 23.91s
Train Epoch: 2352 [20480/90000 (23%)]	Loss: -6.6308	Cost: 6.16s
Train Epoch: 2352 [40960/90000 (45%)]	Loss: -6.3069	Cost: 8.08s
Train Epoch: 2352 [61440/90000 (68%)]	Loss: -6.9585	Cost: 5.93s
Train Epoch: 2352 [81920/90000 (91%)]	Loss: -6.5463	Cost: 6.45s
Train Epoch: 2352 	Average Loss: -6.9792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8213

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2353 [0/90000 (0%)]	Loss: -5.4522	Cost: 23.92s
Train Epoch: 2353 [20480/90000 (23%)]	Loss: -6.4614	Cost: 6.11s
Train Epoch: 2353 [40960/90000 (45%)]	Loss: -6.3036	Cost: 8.08s
Train Epoch: 2353 [61440/90000 (68%)]	Loss: -6.9656	Cost: 5.90s
Train Epoch: 2353 [81920/90000 (91%)]	Loss: -6.6868	Cost: 6.14s
Train Epoch: 2353 	Average Loss: -7.0150
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6350

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2354 [0/90000 (0%)]	Loss: -6.1086	Cost: 24.08s
Train Epoch: 2354 [20480/90000 (23%)]	Loss: -6.5588	Cost: 6.22s
Train Epoch: 2354 [40960/90000 (45%)]	Loss: -6.3220	Cost: 8.22s
Train Epoch: 2354 [61440/90000 (68%)]	Loss: -7.0392	Cost: 6.04s
Train Epoch: 2354 [81920/90000 (91%)]	Loss: -6.7777	Cost: 5.77s
Train Epoch: 2354 	Average Loss: -7.0644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6889

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2355 [0/90000 (0%)]	Loss: -8.0571	Cost: 23.82s
Train Epoch: 2355 [20480/90000 (23%)]	Loss: -6.4851	Cost: 6.13s
Train Epoch: 2355 [40960/90000 (45%)]	Loss: -6.3494	Cost: 7.84s
Train Epoch: 2355 [61440/90000 (68%)]	Loss: -7.0895	Cost: 5.91s
Train Epoch: 2355 [81920/90000 (91%)]	Loss: -6.7690	Cost: 6.48s
Train Epoch: 2355 	Average Loss: -7.0769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5916

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2356 [0/90000 (0%)]	Loss: -7.5033	Cost: 23.98s
Train Epoch: 2356 [20480/90000 (23%)]	Loss: -6.4475	Cost: 6.17s
Train Epoch: 2356 [40960/90000 (45%)]	Loss: -6.3651	Cost: 8.42s
Train Epoch: 2356 [61440/90000 (68%)]	Loss: -7.0431	Cost: 6.04s
Train Epoch: 2356 [81920/90000 (91%)]	Loss: -6.6202	Cost: 5.98s
Train Epoch: 2356 	Average Loss: -7.0046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7889

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2357 [0/90000 (0%)]	Loss: -7.5144	Cost: 23.78s
Train Epoch: 2357 [20480/90000 (23%)]	Loss: -6.5853	Cost: 6.13s
Train Epoch: 2357 [40960/90000 (45%)]	Loss: -6.4064	Cost: 8.08s
Train Epoch: 2357 [61440/90000 (68%)]	Loss: -7.0161	Cost: 6.02s
Train Epoch: 2357 [81920/90000 (91%)]	Loss: -6.7284	Cost: 6.06s
Train Epoch: 2357 	Average Loss: -7.0791
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7547

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2358 [0/90000 (0%)]	Loss: -7.5272	Cost: 23.58s
Train Epoch: 2358 [20480/90000 (23%)]	Loss: -6.5739	Cost: 6.47s
Train Epoch: 2358 [40960/90000 (45%)]	Loss: -6.2650	Cost: 8.18s
Train Epoch: 2358 [61440/90000 (68%)]	Loss: -6.9089	Cost: 6.09s
Train Epoch: 2358 [81920/90000 (91%)]	Loss: -6.7424	Cost: 6.16s
Train Epoch: 2358 	Average Loss: -6.9831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7268

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2359 [0/90000 (0%)]	Loss: -6.4347	Cost: 24.06s
Train Epoch: 2359 [20480/90000 (23%)]	Loss: -6.4666	Cost: 6.13s
Train Epoch: 2359 [40960/90000 (45%)]	Loss: -6.4730	Cost: 7.91s
Train Epoch: 2359 [61440/90000 (68%)]	Loss: -6.9913	Cost: 5.91s
Train Epoch: 2359 [81920/90000 (91%)]	Loss: -6.7503	Cost: 6.17s
Train Epoch: 2359 	Average Loss: -6.9628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6859

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2360 [0/90000 (0%)]	Loss: -7.5664	Cost: 23.54s
Train Epoch: 2360 [20480/90000 (23%)]	Loss: -6.5303	Cost: 6.07s
Train Epoch: 2360 [40960/90000 (45%)]	Loss: -6.4674	Cost: 8.15s
Train Epoch: 2360 [61440/90000 (68%)]	Loss: -7.0052	Cost: 5.84s
Train Epoch: 2360 [81920/90000 (91%)]	Loss: -6.6595	Cost: 6.36s
Train Epoch: 2360 	Average Loss: -6.9696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8482

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2361 [0/90000 (0%)]	Loss: -7.3411	Cost: 23.40s
Train Epoch: 2361 [20480/90000 (23%)]	Loss: -6.4045	Cost: 6.09s
Train Epoch: 2361 [40960/90000 (45%)]	Loss: -6.4615	Cost: 8.16s
Train Epoch: 2361 [61440/90000 (68%)]	Loss: -7.0456	Cost: 5.83s
Train Epoch: 2361 [81920/90000 (91%)]	Loss: -6.6964	Cost: 6.21s
Train Epoch: 2361 	Average Loss: -7.0517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6038

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2362 [0/90000 (0%)]	Loss: -6.2446	Cost: 24.09s
Train Epoch: 2362 [20480/90000 (23%)]	Loss: -6.5252	Cost: 6.16s
Train Epoch: 2362 [40960/90000 (45%)]	Loss: -6.5229	Cost: 7.97s
Train Epoch: 2362 [61440/90000 (68%)]	Loss: -6.9203	Cost: 5.87s
Train Epoch: 2362 [81920/90000 (91%)]	Loss: -6.7989	Cost: 6.27s
Train Epoch: 2362 	Average Loss: -7.0426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6950

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2363 [0/90000 (0%)]	Loss: -7.2568	Cost: 23.08s
Train Epoch: 2363 [20480/90000 (23%)]	Loss: -6.4617	Cost: 6.14s
Train Epoch: 2363 [40960/90000 (45%)]	Loss: -6.3045	Cost: 7.86s
Train Epoch: 2363 [61440/90000 (68%)]	Loss: -6.9069	Cost: 5.86s
Train Epoch: 2363 [81920/90000 (91%)]	Loss: -6.6699	Cost: 6.35s
Train Epoch: 2363 	Average Loss: -7.0421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7302

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2364 [0/90000 (0%)]	Loss: -7.3129	Cost: 23.26s
Train Epoch: 2364 [20480/90000 (23%)]	Loss: -6.4942	Cost: 6.13s
Train Epoch: 2364 [40960/90000 (45%)]	Loss: -6.4048	Cost: 8.23s
Train Epoch: 2364 [61440/90000 (68%)]	Loss: -7.0237	Cost: 6.04s
Train Epoch: 2364 [81920/90000 (91%)]	Loss: -6.7804	Cost: 6.50s
Train Epoch: 2364 	Average Loss: -7.0801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7000

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2365 [0/90000 (0%)]	Loss: -8.0785	Cost: 23.93s
Train Epoch: 2365 [20480/90000 (23%)]	Loss: -6.6955	Cost: 6.18s
Train Epoch: 2365 [40960/90000 (45%)]	Loss: -6.4260	Cost: 8.11s
Train Epoch: 2365 [61440/90000 (68%)]	Loss: -6.9394	Cost: 5.95s
Train Epoch: 2365 [81920/90000 (91%)]	Loss: -6.6566	Cost: 6.25s
Train Epoch: 2365 	Average Loss: -7.0852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7814

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2366 [0/90000 (0%)]	Loss: -7.5555	Cost: 23.70s
Train Epoch: 2366 [20480/90000 (23%)]	Loss: -6.2945	Cost: 6.30s
Train Epoch: 2366 [40960/90000 (45%)]	Loss: -6.4405	Cost: 7.93s
Train Epoch: 2366 [61440/90000 (68%)]	Loss: -7.0039	Cost: 5.89s
Train Epoch: 2366 [81920/90000 (91%)]	Loss: -6.7869	Cost: 6.44s
Train Epoch: 2366 	Average Loss: -7.0620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6923

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2367 [0/90000 (0%)]	Loss: -6.2400	Cost: 23.52s
Train Epoch: 2367 [20480/90000 (23%)]	Loss: -6.6086	Cost: 6.15s
Train Epoch: 2367 [40960/90000 (45%)]	Loss: -6.5366	Cost: 8.12s
Train Epoch: 2367 [61440/90000 (68%)]	Loss: -6.8949	Cost: 5.83s
Train Epoch: 2367 [81920/90000 (91%)]	Loss: -6.6796	Cost: 6.21s
Train Epoch: 2367 	Average Loss: -6.9992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7340

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2368 [0/90000 (0%)]	Loss: -6.8294	Cost: 23.79s
Train Epoch: 2368 [20480/90000 (23%)]	Loss: -6.5064	Cost: 6.02s
Train Epoch: 2368 [40960/90000 (45%)]	Loss: -6.3535	Cost: 8.17s
Train Epoch: 2368 [61440/90000 (68%)]	Loss: -7.0463	Cost: 5.83s
Train Epoch: 2368 [81920/90000 (91%)]	Loss: -6.7479	Cost: 6.47s
Train Epoch: 2368 	Average Loss: -6.9455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6921

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2369 [0/90000 (0%)]	Loss: -7.1439	Cost: 23.62s
Train Epoch: 2369 [20480/90000 (23%)]	Loss: -6.4772	Cost: 6.03s
Train Epoch: 2369 [40960/90000 (45%)]	Loss: -6.4505	Cost: 8.21s
Train Epoch: 2369 [61440/90000 (68%)]	Loss: -6.9876	Cost: 5.94s
Train Epoch: 2369 [81920/90000 (91%)]	Loss: -6.6363	Cost: 6.54s
Train Epoch: 2369 	Average Loss: -7.0613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6992

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2370 [0/90000 (0%)]	Loss: -7.7957	Cost: 23.73s
Train Epoch: 2370 [20480/90000 (23%)]	Loss: -6.5277	Cost: 5.99s
Train Epoch: 2370 [40960/90000 (45%)]	Loss: -6.4280	Cost: 8.15s
Train Epoch: 2370 [61440/90000 (68%)]	Loss: -6.9398	Cost: 5.88s
Train Epoch: 2370 [81920/90000 (91%)]	Loss: -6.7663	Cost: 6.28s
Train Epoch: 2370 	Average Loss: -7.1043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5858

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2371 [0/90000 (0%)]	Loss: -6.9980	Cost: 24.02s
Train Epoch: 2371 [20480/90000 (23%)]	Loss: -6.4220	Cost: 6.21s
Train Epoch: 2371 [40960/90000 (45%)]	Loss: -6.1916	Cost: 8.44s
Train Epoch: 2371 [61440/90000 (68%)]	Loss: -6.8688	Cost: 5.88s
Train Epoch: 2371 [81920/90000 (91%)]	Loss: -6.7888	Cost: 6.25s
Train Epoch: 2371 	Average Loss: -7.0360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8330

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2372 [0/90000 (0%)]	Loss: -6.0870	Cost: 23.68s
Train Epoch: 2372 [20480/90000 (23%)]	Loss: -6.5180	Cost: 6.13s
Train Epoch: 2372 [40960/90000 (45%)]	Loss: -6.3809	Cost: 7.94s
Train Epoch: 2372 [61440/90000 (68%)]	Loss: -7.0984	Cost: 5.93s
Train Epoch: 2372 [81920/90000 (91%)]	Loss: -6.9175	Cost: 6.27s
Train Epoch: 2372 	Average Loss: -7.0642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7337

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2373 [0/90000 (0%)]	Loss: -7.1249	Cost: 23.73s
Train Epoch: 2373 [20480/90000 (23%)]	Loss: -6.5706	Cost: 6.16s
Train Epoch: 2373 [40960/90000 (45%)]	Loss: -6.3467	Cost: 7.97s
Train Epoch: 2373 [61440/90000 (68%)]	Loss: -6.9590	Cost: 5.87s
Train Epoch: 2373 [81920/90000 (91%)]	Loss: -6.8293	Cost: 6.12s
Train Epoch: 2373 	Average Loss: -7.0258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7993

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2374 [0/90000 (0%)]	Loss: -6.6212	Cost: 23.42s
Train Epoch: 2374 [20480/90000 (23%)]	Loss: -6.5430	Cost: 6.16s
Train Epoch: 2374 [40960/90000 (45%)]	Loss: -6.4242	Cost: 8.13s
Train Epoch: 2374 [61440/90000 (68%)]	Loss: -7.1323	Cost: 5.82s
Train Epoch: 2374 [81920/90000 (91%)]	Loss: -6.6756	Cost: 6.30s
Train Epoch: 2374 	Average Loss: -7.0423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6078

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2375 [0/90000 (0%)]	Loss: -7.5445	Cost: 23.90s
Train Epoch: 2375 [20480/90000 (23%)]	Loss: -6.4924	Cost: 6.08s
Train Epoch: 2375 [40960/90000 (45%)]	Loss: -6.3805	Cost: 8.10s
Train Epoch: 2375 [61440/90000 (68%)]	Loss: -7.0255	Cost: 5.87s
Train Epoch: 2375 [81920/90000 (91%)]	Loss: -6.5851	Cost: 6.27s
Train Epoch: 2375 	Average Loss: -7.0623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7091

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2376 [0/90000 (0%)]	Loss: -6.3045	Cost: 23.77s
Train Epoch: 2376 [20480/90000 (23%)]	Loss: -6.4184	Cost: 6.02s
Train Epoch: 2376 [40960/90000 (45%)]	Loss: -6.3747	Cost: 8.17s
Train Epoch: 2376 [61440/90000 (68%)]	Loss: -6.9097	Cost: 5.91s
Train Epoch: 2376 [81920/90000 (91%)]	Loss: -6.6531	Cost: 6.07s
Train Epoch: 2376 	Average Loss: -7.0434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7574

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2377 [0/90000 (0%)]	Loss: -6.8286	Cost: 23.39s
Train Epoch: 2377 [20480/90000 (23%)]	Loss: -6.4977	Cost: 6.22s
Train Epoch: 2377 [40960/90000 (45%)]	Loss: -6.3048	Cost: 8.04s
Train Epoch: 2377 [61440/90000 (68%)]	Loss: -6.9322	Cost: 5.97s
Train Epoch: 2377 [81920/90000 (91%)]	Loss: -6.8385	Cost: 6.14s
Train Epoch: 2377 	Average Loss: -6.9742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7054

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2378 [0/90000 (0%)]	Loss: -5.6324	Cost: 23.96s
Train Epoch: 2378 [20480/90000 (23%)]	Loss: -6.6081	Cost: 6.16s
Train Epoch: 2378 [40960/90000 (45%)]	Loss: -6.3754	Cost: 7.79s
Train Epoch: 2378 [61440/90000 (68%)]	Loss: -7.0655	Cost: 5.92s
Train Epoch: 2378 [81920/90000 (91%)]	Loss: -6.6284	Cost: 6.03s
Train Epoch: 2378 	Average Loss: -6.9746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5463

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2379 [0/90000 (0%)]	Loss: -7.5844	Cost: 23.37s
Train Epoch: 2379 [20480/90000 (23%)]	Loss: -6.5771	Cost: 6.09s
Train Epoch: 2379 [40960/90000 (45%)]	Loss: -6.3749	Cost: 8.06s
Train Epoch: 2379 [61440/90000 (68%)]	Loss: -7.0427	Cost: 5.87s
Train Epoch: 2379 [81920/90000 (91%)]	Loss: -6.7448	Cost: 6.06s
Train Epoch: 2379 	Average Loss: -7.0918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6305

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2380 [0/90000 (0%)]	Loss: -8.1833	Cost: 23.94s
Train Epoch: 2380 [20480/90000 (23%)]	Loss: -6.4331	Cost: 6.05s
Train Epoch: 2380 [40960/90000 (45%)]	Loss: -6.5232	Cost: 8.11s
Train Epoch: 2380 [61440/90000 (68%)]	Loss: -7.0197	Cost: 5.84s
Train Epoch: 2380 [81920/90000 (91%)]	Loss: -6.7659	Cost: 6.66s
Train Epoch: 2380 	Average Loss: -7.1000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7330

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2381 [0/90000 (0%)]	Loss: -7.6105	Cost: 23.73s
Train Epoch: 2381 [20480/90000 (23%)]	Loss: -6.4789	Cost: 6.12s
Train Epoch: 2381 [40960/90000 (45%)]	Loss: -6.4383	Cost: 7.93s
Train Epoch: 2381 [61440/90000 (68%)]	Loss: -6.9266	Cost: 5.82s
Train Epoch: 2381 [81920/90000 (91%)]	Loss: -6.7420	Cost: 6.12s
Train Epoch: 2381 	Average Loss: -7.0605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7080

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2382 [0/90000 (0%)]	Loss: -8.0814	Cost: 23.42s
Train Epoch: 2382 [20480/90000 (23%)]	Loss: -6.6075	Cost: 6.08s
Train Epoch: 2382 [40960/90000 (45%)]	Loss: -6.5563	Cost: 8.16s
Train Epoch: 2382 [61440/90000 (68%)]	Loss: -7.0772	Cost: 5.80s
Train Epoch: 2382 [81920/90000 (91%)]	Loss: -6.7385	Cost: 6.31s
Train Epoch: 2382 	Average Loss: -7.0234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7680

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2383 [0/90000 (0%)]	Loss: -6.0642	Cost: 23.93s
Train Epoch: 2383 [20480/90000 (23%)]	Loss: -6.5912	Cost: 6.06s
Train Epoch: 2383 [40960/90000 (45%)]	Loss: -6.3398	Cost: 8.04s
Train Epoch: 2383 [61440/90000 (68%)]	Loss: -6.9719	Cost: 5.86s
Train Epoch: 2383 [81920/90000 (91%)]	Loss: -6.7428	Cost: 6.40s
Train Epoch: 2383 	Average Loss: -7.0452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7316

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2384 [0/90000 (0%)]	Loss: -6.5332	Cost: 23.51s
Train Epoch: 2384 [20480/90000 (23%)]	Loss: -6.4671	Cost: 6.14s
Train Epoch: 2384 [40960/90000 (45%)]	Loss: -6.4006	Cost: 8.07s
Train Epoch: 2384 [61440/90000 (68%)]	Loss: -6.8476	Cost: 5.92s
Train Epoch: 2384 [81920/90000 (91%)]	Loss: -6.6250	Cost: 6.30s
Train Epoch: 2384 	Average Loss: -7.0831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6148

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2385 [0/90000 (0%)]	Loss: -7.8963	Cost: 23.56s
Train Epoch: 2385 [20480/90000 (23%)]	Loss: -6.4646	Cost: 6.06s
Train Epoch: 2385 [40960/90000 (45%)]	Loss: -6.1735	Cost: 8.14s
Train Epoch: 2385 [61440/90000 (68%)]	Loss: -7.1897	Cost: 5.91s
Train Epoch: 2385 [81920/90000 (91%)]	Loss: -6.6104	Cost: 6.39s
Train Epoch: 2385 	Average Loss: -7.0739
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7155

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2386 [0/90000 (0%)]	Loss: -7.9449	Cost: 23.26s
Train Epoch: 2386 [20480/90000 (23%)]	Loss: -6.5352	Cost: 6.10s
Train Epoch: 2386 [40960/90000 (45%)]	Loss: -6.3979	Cost: 8.06s
Train Epoch: 2386 [61440/90000 (68%)]	Loss: -6.9856	Cost: 5.84s
Train Epoch: 2386 [81920/90000 (91%)]	Loss: -6.7463	Cost: 6.21s
Train Epoch: 2386 	Average Loss: -7.0760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7004

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2387 [0/90000 (0%)]	Loss: -6.9431	Cost: 23.58s
Train Epoch: 2387 [20480/90000 (23%)]	Loss: -6.4488	Cost: 6.08s
Train Epoch: 2387 [40960/90000 (45%)]	Loss: -6.3854	Cost: 7.92s
Train Epoch: 2387 [61440/90000 (68%)]	Loss: -7.0111	Cost: 5.88s
Train Epoch: 2387 [81920/90000 (91%)]	Loss: -6.7176	Cost: 6.04s
Train Epoch: 2387 	Average Loss: -7.0297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8060

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2388 [0/90000 (0%)]	Loss: -7.0952	Cost: 23.60s
Train Epoch: 2388 [20480/90000 (23%)]	Loss: -6.3825	Cost: 6.10s
Train Epoch: 2388 [40960/90000 (45%)]	Loss: -6.4345	Cost: 7.92s
Train Epoch: 2388 [61440/90000 (68%)]	Loss: -7.0963	Cost: 5.84s
Train Epoch: 2388 [81920/90000 (91%)]	Loss: -6.5918	Cost: 6.34s
Train Epoch: 2388 	Average Loss: -7.0084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6404

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2389 [0/90000 (0%)]	Loss: -6.5570	Cost: 23.29s
Train Epoch: 2389 [20480/90000 (23%)]	Loss: -6.6192	Cost: 6.14s
Train Epoch: 2389 [40960/90000 (45%)]	Loss: -6.3526	Cost: 8.00s
Train Epoch: 2389 [61440/90000 (68%)]	Loss: -7.0683	Cost: 5.90s
Train Epoch: 2389 [81920/90000 (91%)]	Loss: -6.7001	Cost: 6.04s
Train Epoch: 2389 	Average Loss: -7.0734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6920

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2390 [0/90000 (0%)]	Loss: -6.4454	Cost: 23.71s
Train Epoch: 2390 [20480/90000 (23%)]	Loss: -6.3185	Cost: 6.07s
Train Epoch: 2390 [40960/90000 (45%)]	Loss: -6.5010	Cost: 7.96s
Train Epoch: 2390 [61440/90000 (68%)]	Loss: -7.0417	Cost: 5.88s
Train Epoch: 2390 [81920/90000 (91%)]	Loss: -6.7419	Cost: 6.20s
Train Epoch: 2390 	Average Loss: -7.0325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5628

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2391 [0/90000 (0%)]	Loss: -7.0614	Cost: 23.45s
Train Epoch: 2391 [20480/90000 (23%)]	Loss: -6.3962	Cost: 6.14s
Train Epoch: 2391 [40960/90000 (45%)]	Loss: -6.4385	Cost: 8.10s
Train Epoch: 2391 [61440/90000 (68%)]	Loss: -6.9798	Cost: 6.00s
Train Epoch: 2391 [81920/90000 (91%)]	Loss: -6.7101	Cost: 6.22s
Train Epoch: 2391 	Average Loss: -7.0193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7303

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2392 [0/90000 (0%)]	Loss: -7.9865	Cost: 23.73s
Train Epoch: 2392 [20480/90000 (23%)]	Loss: -6.5111	Cost: 6.21s
Train Epoch: 2392 [40960/90000 (45%)]	Loss: -6.5713	Cost: 7.99s
Train Epoch: 2392 [61440/90000 (68%)]	Loss: -6.9727	Cost: 5.84s
Train Epoch: 2392 [81920/90000 (91%)]	Loss: -6.5963	Cost: 6.41s
Train Epoch: 2392 	Average Loss: -7.0549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7095

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2393 [0/90000 (0%)]	Loss: -6.4025	Cost: 23.41s
Train Epoch: 2393 [20480/90000 (23%)]	Loss: -6.5876	Cost: 6.07s
Train Epoch: 2393 [40960/90000 (45%)]	Loss: -6.3010	Cost: 8.05s
Train Epoch: 2393 [61440/90000 (68%)]	Loss: -7.1039	Cost: 5.87s
Train Epoch: 2393 [81920/90000 (91%)]	Loss: -6.7192	Cost: 6.01s
Train Epoch: 2393 	Average Loss: -7.0110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5393

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2394 [0/90000 (0%)]	Loss: -6.5195	Cost: 23.47s
Train Epoch: 2394 [20480/90000 (23%)]	Loss: -6.4137	Cost: 6.04s
Train Epoch: 2394 [40960/90000 (45%)]	Loss: -6.2781	Cost: 8.02s
Train Epoch: 2394 [61440/90000 (68%)]	Loss: -7.0752	Cost: 5.87s
Train Epoch: 2394 [81920/90000 (91%)]	Loss: -6.7416	Cost: 6.39s
Train Epoch: 2394 	Average Loss: -7.0310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6985

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2395 [0/90000 (0%)]	Loss: -8.3317	Cost: 23.65s
Train Epoch: 2395 [20480/90000 (23%)]	Loss: -6.3982	Cost: 6.17s
Train Epoch: 2395 [40960/90000 (45%)]	Loss: -6.2416	Cost: 7.92s
Train Epoch: 2395 [61440/90000 (68%)]	Loss: -6.9538	Cost: 5.88s
Train Epoch: 2395 [81920/90000 (91%)]	Loss: -6.7081	Cost: 6.12s
Train Epoch: 2395 	Average Loss: -7.0677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7686

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2396 [0/90000 (0%)]	Loss: -7.4087	Cost: 23.55s
Train Epoch: 2396 [20480/90000 (23%)]	Loss: -6.6316	Cost: 6.07s
Train Epoch: 2396 [40960/90000 (45%)]	Loss: -6.2464	Cost: 8.15s
Train Epoch: 2396 [61440/90000 (68%)]	Loss: -7.0023	Cost: 5.84s
Train Epoch: 2396 [81920/90000 (91%)]	Loss: -6.7831	Cost: 6.46s
Train Epoch: 2396 	Average Loss: -7.1229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5422

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2397 [0/90000 (0%)]	Loss: -7.1647	Cost: 23.47s
Train Epoch: 2397 [20480/90000 (23%)]	Loss: -6.5016	Cost: 6.14s
Train Epoch: 2397 [40960/90000 (45%)]	Loss: -6.4526	Cost: 8.14s
Train Epoch: 2397 [61440/90000 (68%)]	Loss: -6.9929	Cost: 5.88s
Train Epoch: 2397 [81920/90000 (91%)]	Loss: -6.6324	Cost: 6.31s
Train Epoch: 2397 	Average Loss: -7.0174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6063

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2398 [0/90000 (0%)]	Loss: -5.1037	Cost: 23.64s
Train Epoch: 2398 [20480/90000 (23%)]	Loss: -6.5472	Cost: 6.14s
Train Epoch: 2398 [40960/90000 (45%)]	Loss: -6.4779	Cost: 7.98s
Train Epoch: 2398 [61440/90000 (68%)]	Loss: -6.9779	Cost: 5.84s
Train Epoch: 2398 [81920/90000 (91%)]	Loss: -6.7138	Cost: 6.22s
Train Epoch: 2398 	Average Loss: -7.0150
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6881

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2399 [0/90000 (0%)]	Loss: -6.9902	Cost: 23.23s
Train Epoch: 2399 [20480/90000 (23%)]	Loss: -6.5890	Cost: 6.27s
Train Epoch: 2399 [40960/90000 (45%)]	Loss: -6.4601	Cost: 8.03s
Train Epoch: 2399 [61440/90000 (68%)]	Loss: -7.1298	Cost: 5.86s
Train Epoch: 2399 [81920/90000 (91%)]	Loss: -6.7961	Cost: 6.32s
Train Epoch: 2399 	Average Loss: -7.0616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8991

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2400 [0/90000 (0%)]	Loss: -7.3313	Cost: 23.79s
Train Epoch: 2400 [20480/90000 (23%)]	Loss: -6.2369	Cost: 6.15s
Train Epoch: 2400 [40960/90000 (45%)]	Loss: -6.4251	Cost: 8.11s
Train Epoch: 2400 [61440/90000 (68%)]	Loss: -7.0030	Cost: 5.92s
Train Epoch: 2400 [81920/90000 (91%)]	Loss: -6.7259	Cost: 6.14s
Train Epoch: 2400 	Average Loss: -7.0319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6886

Saving model as model.pt_e2400 & waveforms_supplementary.hdf5_e2400
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2401 [0/90000 (0%)]	Loss: -6.1956	Cost: 23.51s
Train Epoch: 2401 [20480/90000 (23%)]	Loss: -6.4865	Cost: 6.25s
Train Epoch: 2401 [40960/90000 (45%)]	Loss: -6.4188	Cost: 7.62s
Train Epoch: 2401 [61440/90000 (68%)]	Loss: -6.9123	Cost: 5.92s
Train Epoch: 2401 [81920/90000 (91%)]	Loss: -6.7875	Cost: 5.96s
Train Epoch: 2401 	Average Loss: -7.0534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6947

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2402 [0/90000 (0%)]	Loss: -7.7047	Cost: 23.85s
Train Epoch: 2402 [20480/90000 (23%)]	Loss: -6.3189	Cost: 6.21s
Train Epoch: 2402 [40960/90000 (45%)]	Loss: -6.2680	Cost: 8.22s
Train Epoch: 2402 [61440/90000 (68%)]	Loss: -6.9634	Cost: 5.90s
Train Epoch: 2402 [81920/90000 (91%)]	Loss: -6.6433	Cost: 6.11s
Train Epoch: 2402 	Average Loss: -7.0410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6922

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2403 [0/90000 (0%)]	Loss: -6.4943	Cost: 23.51s
Train Epoch: 2403 [20480/90000 (23%)]	Loss: -6.3543	Cost: 6.29s
Train Epoch: 2403 [40960/90000 (45%)]	Loss: -6.3796	Cost: 7.81s
Train Epoch: 2403 [61440/90000 (68%)]	Loss: -6.9187	Cost: 5.89s
Train Epoch: 2403 [81920/90000 (91%)]	Loss: -6.7833	Cost: 5.80s
Train Epoch: 2403 	Average Loss: -7.0679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7845

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2404 [0/90000 (0%)]	Loss: -7.6539	Cost: 24.00s
Train Epoch: 2404 [20480/90000 (23%)]	Loss: -6.5450	Cost: 6.46s
Train Epoch: 2404 [40960/90000 (45%)]	Loss: -6.2921	Cost: 7.91s
Train Epoch: 2404 [61440/90000 (68%)]	Loss: -7.0072	Cost: 5.89s
Train Epoch: 2404 [81920/90000 (91%)]	Loss: -6.7043	Cost: 6.00s
Train Epoch: 2404 	Average Loss: -7.0384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7584

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2405 [0/90000 (0%)]	Loss: -7.3478	Cost: 23.54s
Train Epoch: 2405 [20480/90000 (23%)]	Loss: -6.4583	Cost: 6.21s
Train Epoch: 2405 [40960/90000 (45%)]	Loss: -6.4756	Cost: 7.99s
Train Epoch: 2405 [61440/90000 (68%)]	Loss: -7.0235	Cost: 5.87s
Train Epoch: 2405 [81920/90000 (91%)]	Loss: -6.7606	Cost: 6.13s
Train Epoch: 2405 	Average Loss: -7.0922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7374

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2406 [0/90000 (0%)]	Loss: -7.7214	Cost: 23.82s
Train Epoch: 2406 [20480/90000 (23%)]	Loss: -6.7678	Cost: 6.17s
Train Epoch: 2406 [40960/90000 (45%)]	Loss: -6.3424	Cost: 8.39s
Train Epoch: 2406 [61440/90000 (68%)]	Loss: -7.0672	Cost: 6.17s
Train Epoch: 2406 [81920/90000 (91%)]	Loss: -6.7950	Cost: 6.17s
Train Epoch: 2406 	Average Loss: -7.1036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8830

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2407 [0/90000 (0%)]	Loss: -6.8402	Cost: 23.46s
Train Epoch: 2407 [20480/90000 (23%)]	Loss: -6.5137	Cost: 6.13s
Train Epoch: 2407 [40960/90000 (45%)]	Loss: -6.3627	Cost: 8.07s
Train Epoch: 2407 [61440/90000 (68%)]	Loss: -7.1869	Cost: 5.88s
Train Epoch: 2407 [81920/90000 (91%)]	Loss: -6.6260	Cost: 6.20s
Train Epoch: 2407 	Average Loss: -7.0417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8396

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2408 [0/90000 (0%)]	Loss: -7.7320	Cost: 23.52s
Train Epoch: 2408 [20480/90000 (23%)]	Loss: -6.4284	Cost: 6.13s
Train Epoch: 2408 [40960/90000 (45%)]	Loss: -6.3918	Cost: 8.14s
Train Epoch: 2408 [61440/90000 (68%)]	Loss: -7.0174	Cost: 5.89s
Train Epoch: 2408 [81920/90000 (91%)]	Loss: -6.6324	Cost: 6.72s
Train Epoch: 2408 	Average Loss: -7.0786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8294

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2409 [0/90000 (0%)]	Loss: -7.4603	Cost: 23.43s
Train Epoch: 2409 [20480/90000 (23%)]	Loss: -6.5618	Cost: 6.14s
Train Epoch: 2409 [40960/90000 (45%)]	Loss: -6.2808	Cost: 7.84s
Train Epoch: 2409 [61440/90000 (68%)]	Loss: -6.9471	Cost: 5.90s
Train Epoch: 2409 [81920/90000 (91%)]	Loss: -6.7248	Cost: 5.97s
Train Epoch: 2409 	Average Loss: -7.0490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8116

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2410 [0/90000 (0%)]	Loss: -6.8942	Cost: 23.49s
Train Epoch: 2410 [20480/90000 (23%)]	Loss: -6.4744	Cost: 6.04s
Train Epoch: 2410 [40960/90000 (45%)]	Loss: -6.3444	Cost: 8.27s
Train Epoch: 2410 [61440/90000 (68%)]	Loss: -7.0451	Cost: 6.04s
Train Epoch: 2410 [81920/90000 (91%)]	Loss: -6.6002	Cost: 6.02s
Train Epoch: 2410 	Average Loss: -7.0063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6918

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2411 [0/90000 (0%)]	Loss: -7.1175	Cost: 23.86s
Train Epoch: 2411 [20480/90000 (23%)]	Loss: -6.5725	Cost: 6.06s
Train Epoch: 2411 [40960/90000 (45%)]	Loss: -6.3156	Cost: 8.03s
Train Epoch: 2411 [61440/90000 (68%)]	Loss: -7.0116	Cost: 5.93s
Train Epoch: 2411 [81920/90000 (91%)]	Loss: -6.8398	Cost: 6.00s
Train Epoch: 2411 	Average Loss: -7.0556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6877

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2412 [0/90000 (0%)]	Loss: -8.0021	Cost: 23.80s
Train Epoch: 2412 [20480/90000 (23%)]	Loss: -6.6504	Cost: 6.01s
Train Epoch: 2412 [40960/90000 (45%)]	Loss: -6.4396	Cost: 8.30s
Train Epoch: 2412 [61440/90000 (68%)]	Loss: -7.0202	Cost: 5.82s
Train Epoch: 2412 [81920/90000 (91%)]	Loss: -6.6566	Cost: 6.40s
Train Epoch: 2412 	Average Loss: -7.0640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7550

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2413 [0/90000 (0%)]	Loss: -7.1141	Cost: 23.07s
Train Epoch: 2413 [20480/90000 (23%)]	Loss: -6.3762	Cost: 6.13s
Train Epoch: 2413 [40960/90000 (45%)]	Loss: -6.3666	Cost: 8.11s
Train Epoch: 2413 [61440/90000 (68%)]	Loss: -6.8868	Cost: 5.89s
Train Epoch: 2413 [81920/90000 (91%)]	Loss: -6.6008	Cost: 5.98s
Train Epoch: 2413 	Average Loss: -7.0804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7410

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2414 [0/90000 (0%)]	Loss: -6.6185	Cost: 23.55s
Train Epoch: 2414 [20480/90000 (23%)]	Loss: -6.4976	Cost: 6.03s
Train Epoch: 2414 [40960/90000 (45%)]	Loss: -6.3595	Cost: 8.16s
Train Epoch: 2414 [61440/90000 (68%)]	Loss: -7.0494	Cost: 5.89s
Train Epoch: 2414 [81920/90000 (91%)]	Loss: -6.7624	Cost: 5.79s
Train Epoch: 2414 	Average Loss: -7.0463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7126

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2415 [0/90000 (0%)]	Loss: -6.4432	Cost: 23.71s
Train Epoch: 2415 [20480/90000 (23%)]	Loss: -6.5479	Cost: 6.06s
Train Epoch: 2415 [40960/90000 (45%)]	Loss: -6.3707	Cost: 7.83s
Train Epoch: 2415 [61440/90000 (68%)]	Loss: -6.9604	Cost: 5.88s
Train Epoch: 2415 [81920/90000 (91%)]	Loss: -6.6949	Cost: 6.19s
Train Epoch: 2415 	Average Loss: -7.0610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8536

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2416 [0/90000 (0%)]	Loss: -8.3142	Cost: 23.61s
Train Epoch: 2416 [20480/90000 (23%)]	Loss: -6.5948	Cost: 6.10s
Train Epoch: 2416 [40960/90000 (45%)]	Loss: -6.3490	Cost: 7.95s
Train Epoch: 2416 [61440/90000 (68%)]	Loss: -7.0736	Cost: 5.96s
Train Epoch: 2416 [81920/90000 (91%)]	Loss: -6.8147	Cost: 6.04s
Train Epoch: 2416 	Average Loss: -7.0744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7473

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2417 [0/90000 (0%)]	Loss: -7.4970	Cost: 23.44s
Train Epoch: 2417 [20480/90000 (23%)]	Loss: -6.3562	Cost: 6.14s
Train Epoch: 2417 [40960/90000 (45%)]	Loss: -6.2435	Cost: 8.31s
Train Epoch: 2417 [61440/90000 (68%)]	Loss: -7.1470	Cost: 5.86s
Train Epoch: 2417 [81920/90000 (91%)]	Loss: -6.6096	Cost: 6.10s
Train Epoch: 2417 	Average Loss: -7.0614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7769

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2418 [0/90000 (0%)]	Loss: -7.7626	Cost: 23.65s
Train Epoch: 2418 [20480/90000 (23%)]	Loss: -6.3676	Cost: 6.28s
Train Epoch: 2418 [40960/90000 (45%)]	Loss: -6.4152	Cost: 7.65s
Train Epoch: 2418 [61440/90000 (68%)]	Loss: -6.9738	Cost: 5.91s
Train Epoch: 2418 [81920/90000 (91%)]	Loss: -6.7151	Cost: 6.16s
Train Epoch: 2418 	Average Loss: -7.1117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7893

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2419 [0/90000 (0%)]	Loss: -6.6650	Cost: 23.20s
Train Epoch: 2419 [20480/90000 (23%)]	Loss: -6.5304	Cost: 6.12s
Train Epoch: 2419 [40960/90000 (45%)]	Loss: -6.3547	Cost: 8.16s
Train Epoch: 2419 [61440/90000 (68%)]	Loss: -7.0132	Cost: 5.95s
Train Epoch: 2419 [81920/90000 (91%)]	Loss: -6.5972	Cost: 6.13s
Train Epoch: 2419 	Average Loss: -7.0269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7197

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2420 [0/90000 (0%)]	Loss: -5.7030	Cost: 23.44s
Train Epoch: 2420 [20480/90000 (23%)]	Loss: -6.4912	Cost: 6.19s
Train Epoch: 2420 [40960/90000 (45%)]	Loss: -6.4387	Cost: 8.18s
Train Epoch: 2420 [61440/90000 (68%)]	Loss: -6.8906	Cost: 5.89s
Train Epoch: 2420 [81920/90000 (91%)]	Loss: -6.6139	Cost: 6.33s
Train Epoch: 2420 	Average Loss: -7.0450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5859

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2421 [0/90000 (0%)]	Loss: -7.0999	Cost: 23.69s
Train Epoch: 2421 [20480/90000 (23%)]	Loss: -6.5866	Cost: 6.17s
Train Epoch: 2421 [40960/90000 (45%)]	Loss: -6.4296	Cost: 7.96s
Train Epoch: 2421 [61440/90000 (68%)]	Loss: -6.9090	Cost: 5.87s
Train Epoch: 2421 [81920/90000 (91%)]	Loss: -6.6360	Cost: 6.24s
Train Epoch: 2421 	Average Loss: -7.0464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7285

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2422 [0/90000 (0%)]	Loss: -5.9680	Cost: 23.48s
Train Epoch: 2422 [20480/90000 (23%)]	Loss: -6.3030	Cost: 6.09s
Train Epoch: 2422 [40960/90000 (45%)]	Loss: -6.5798	Cost: 8.01s
Train Epoch: 2422 [61440/90000 (68%)]	Loss: -6.9813	Cost: 5.92s
Train Epoch: 2422 [81920/90000 (91%)]	Loss: -6.7422	Cost: 6.33s
Train Epoch: 2422 	Average Loss: -7.0169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6408

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2423 [0/90000 (0%)]	Loss: -7.0396	Cost: 24.09s
Train Epoch: 2423 [20480/90000 (23%)]	Loss: -6.4964	Cost: 6.07s
Train Epoch: 2423 [40960/90000 (45%)]	Loss: -6.5193	Cost: 7.83s
Train Epoch: 2423 [61440/90000 (68%)]	Loss: -6.9693	Cost: 5.88s
Train Epoch: 2423 [81920/90000 (91%)]	Loss: -6.7748	Cost: 6.22s
Train Epoch: 2423 	Average Loss: -7.0271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7297

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2424 [0/90000 (0%)]	Loss: -8.0519	Cost: 23.40s
Train Epoch: 2424 [20480/90000 (23%)]	Loss: -6.4311	Cost: 6.11s
Train Epoch: 2424 [40960/90000 (45%)]	Loss: -6.2285	Cost: 7.77s
Train Epoch: 2424 [61440/90000 (68%)]	Loss: -6.9314	Cost: 5.85s
Train Epoch: 2424 [81920/90000 (91%)]	Loss: -6.7347	Cost: 6.61s
Train Epoch: 2424 	Average Loss: -7.0616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8334

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2425 [0/90000 (0%)]	Loss: -5.9389	Cost: 24.38s
Train Epoch: 2425 [20480/90000 (23%)]	Loss: -6.3632	Cost: 6.11s
Train Epoch: 2425 [40960/90000 (45%)]	Loss: -6.5029	Cost: 7.87s
Train Epoch: 2425 [61440/90000 (68%)]	Loss: -7.0783	Cost: 5.91s
Train Epoch: 2425 [81920/90000 (91%)]	Loss: -6.5908	Cost: 6.08s
Train Epoch: 2425 	Average Loss: -7.0448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7175

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2426 [0/90000 (0%)]	Loss: -8.3135	Cost: 23.63s
Train Epoch: 2426 [20480/90000 (23%)]	Loss: -6.5601	Cost: 6.05s
Train Epoch: 2426 [40960/90000 (45%)]	Loss: -6.3680	Cost: 8.08s
Train Epoch: 2426 [61440/90000 (68%)]	Loss: -6.9948	Cost: 5.89s
Train Epoch: 2426 [81920/90000 (91%)]	Loss: -6.8167	Cost: 6.16s
Train Epoch: 2426 	Average Loss: -7.0913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6316

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2427 [0/90000 (0%)]	Loss: -6.4624	Cost: 23.99s
Train Epoch: 2427 [20480/90000 (23%)]	Loss: -6.3481	Cost: 6.03s
Train Epoch: 2427 [40960/90000 (45%)]	Loss: -6.4803	Cost: 8.02s
Train Epoch: 2427 [61440/90000 (68%)]	Loss: -7.0349	Cost: 5.85s
Train Epoch: 2427 [81920/90000 (91%)]	Loss: -6.6898	Cost: 6.18s
Train Epoch: 2427 	Average Loss: -7.0168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7914

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2428 [0/90000 (0%)]	Loss: -7.5883	Cost: 23.62s
Train Epoch: 2428 [20480/90000 (23%)]	Loss: -6.5490	Cost: 6.07s
Train Epoch: 2428 [40960/90000 (45%)]	Loss: -6.2642	Cost: 8.01s
Train Epoch: 2428 [61440/90000 (68%)]	Loss: -6.9204	Cost: 5.88s
Train Epoch: 2428 [81920/90000 (91%)]	Loss: -6.6526	Cost: 6.60s
Train Epoch: 2428 	Average Loss: -7.1116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7092

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2429 [0/90000 (0%)]	Loss: -6.5893	Cost: 23.51s
Train Epoch: 2429 [20480/90000 (23%)]	Loss: -6.5667	Cost: 6.05s
Train Epoch: 2429 [40960/90000 (45%)]	Loss: -6.4257	Cost: 8.10s
Train Epoch: 2429 [61440/90000 (68%)]	Loss: -6.9112	Cost: 5.83s
Train Epoch: 2429 [81920/90000 (91%)]	Loss: -6.6483	Cost: 6.17s
Train Epoch: 2429 	Average Loss: -7.0474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6861

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2430 [0/90000 (0%)]	Loss: -7.8158	Cost: 23.85s
Train Epoch: 2430 [20480/90000 (23%)]	Loss: -6.4082	Cost: 6.13s
Train Epoch: 2430 [40960/90000 (45%)]	Loss: -6.3894	Cost: 8.16s
Train Epoch: 2430 [61440/90000 (68%)]	Loss: -7.0538	Cost: 5.88s
Train Epoch: 2430 [81920/90000 (91%)]	Loss: -6.6566	Cost: 6.47s
Train Epoch: 2430 	Average Loss: -7.0998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7244

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2431 [0/90000 (0%)]	Loss: -7.5496	Cost: 23.80s
Train Epoch: 2431 [20480/90000 (23%)]	Loss: -6.5516	Cost: 6.10s
Train Epoch: 2431 [40960/90000 (45%)]	Loss: -6.4490	Cost: 8.05s
Train Epoch: 2431 [61440/90000 (68%)]	Loss: -6.9422	Cost: 5.89s
Train Epoch: 2431 [81920/90000 (91%)]	Loss: -6.7877	Cost: 6.35s
Train Epoch: 2431 	Average Loss: -7.0209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6836

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2432 [0/90000 (0%)]	Loss: -7.1741	Cost: 23.39s
Train Epoch: 2432 [20480/90000 (23%)]	Loss: -6.6458	Cost: 6.12s
Train Epoch: 2432 [40960/90000 (45%)]	Loss: -6.4215	Cost: 8.18s
Train Epoch: 2432 [61440/90000 (68%)]	Loss: -6.8785	Cost: 5.83s
Train Epoch: 2432 [81920/90000 (91%)]	Loss: -6.7005	Cost: 6.50s
Train Epoch: 2432 	Average Loss: -6.9481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6490

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2433 [0/90000 (0%)]	Loss: -6.5857	Cost: 23.72s
Train Epoch: 2433 [20480/90000 (23%)]	Loss: -6.5243	Cost: 6.10s
Train Epoch: 2433 [40960/90000 (45%)]	Loss: -6.3568	Cost: 8.04s
Train Epoch: 2433 [61440/90000 (68%)]	Loss: -6.9290	Cost: 5.86s
Train Epoch: 2433 [81920/90000 (91%)]	Loss: -6.7262	Cost: 6.10s
Train Epoch: 2433 	Average Loss: -7.0494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8463

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2434 [0/90000 (0%)]	Loss: -7.0210	Cost: 23.57s
Train Epoch: 2434 [20480/90000 (23%)]	Loss: -6.4841	Cost: 6.09s
Train Epoch: 2434 [40960/90000 (45%)]	Loss: -6.3949	Cost: 8.06s
Train Epoch: 2434 [61440/90000 (68%)]	Loss: -7.0675	Cost: 5.85s
Train Epoch: 2434 [81920/90000 (91%)]	Loss: -6.6566	Cost: 6.32s
Train Epoch: 2434 	Average Loss: -7.0496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8864

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2435 [0/90000 (0%)]	Loss: -7.2474	Cost: 24.34s
Train Epoch: 2435 [20480/90000 (23%)]	Loss: -6.4130	Cost: 6.12s
Train Epoch: 2435 [40960/90000 (45%)]	Loss: -6.3302	Cost: 7.95s
Train Epoch: 2435 [61440/90000 (68%)]	Loss: -7.0582	Cost: 5.89s
Train Epoch: 2435 [81920/90000 (91%)]	Loss: -6.6726	Cost: 6.39s
Train Epoch: 2435 	Average Loss: -7.0482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6897

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2436 [0/90000 (0%)]	Loss: -5.7043	Cost: 23.73s
Train Epoch: 2436 [20480/90000 (23%)]	Loss: -6.4600	Cost: 6.15s
Train Epoch: 2436 [40960/90000 (45%)]	Loss: -6.2733	Cost: 8.18s
Train Epoch: 2436 [61440/90000 (68%)]	Loss: -7.0564	Cost: 5.88s
Train Epoch: 2436 [81920/90000 (91%)]	Loss: -6.6975	Cost: 6.50s
Train Epoch: 2436 	Average Loss: -7.0121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8093

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2437 [0/90000 (0%)]	Loss: -7.2895	Cost: 23.76s
Train Epoch: 2437 [20480/90000 (23%)]	Loss: -6.4450	Cost: 6.11s
Train Epoch: 2437 [40960/90000 (45%)]	Loss: -6.4823	Cost: 7.99s
Train Epoch: 2437 [61440/90000 (68%)]	Loss: -7.1454	Cost: 5.86s
Train Epoch: 2437 [81920/90000 (91%)]	Loss: -6.6733	Cost: 6.34s
Train Epoch: 2437 	Average Loss: -7.0511
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8044

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2438 [0/90000 (0%)]	Loss: -7.3796	Cost: 23.54s
Train Epoch: 2438 [20480/90000 (23%)]	Loss: -6.4701	Cost: 6.11s
Train Epoch: 2438 [40960/90000 (45%)]	Loss: -6.4794	Cost: 8.05s
Train Epoch: 2438 [61440/90000 (68%)]	Loss: -7.0810	Cost: 5.91s
Train Epoch: 2438 [81920/90000 (91%)]	Loss: -6.8408	Cost: 6.50s
Train Epoch: 2438 	Average Loss: -7.0460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6567

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2439 [0/90000 (0%)]	Loss: -6.9834	Cost: 23.49s
Train Epoch: 2439 [20480/90000 (23%)]	Loss: -6.3390	Cost: 6.05s
Train Epoch: 2439 [40960/90000 (45%)]	Loss: -6.3313	Cost: 8.10s
Train Epoch: 2439 [61440/90000 (68%)]	Loss: -7.0607	Cost: 5.83s
Train Epoch: 2439 [81920/90000 (91%)]	Loss: -6.7709	Cost: 6.23s
Train Epoch: 2439 	Average Loss: -7.0523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6574

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2440 [0/90000 (0%)]	Loss: -5.8304	Cost: 23.78s
Train Epoch: 2440 [20480/90000 (23%)]	Loss: -6.4667	Cost: 6.07s
Train Epoch: 2440 [40960/90000 (45%)]	Loss: -6.3199	Cost: 8.13s
Train Epoch: 2440 [61440/90000 (68%)]	Loss: -6.9800	Cost: 5.85s
Train Epoch: 2440 [81920/90000 (91%)]	Loss: -6.6183	Cost: 6.36s
Train Epoch: 2440 	Average Loss: -7.0190
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6743

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2441 [0/90000 (0%)]	Loss: -7.1055	Cost: 23.27s
Train Epoch: 2441 [20480/90000 (23%)]	Loss: -6.5462	Cost: 6.11s
Train Epoch: 2441 [40960/90000 (45%)]	Loss: -6.4564	Cost: 8.21s
Train Epoch: 2441 [61440/90000 (68%)]	Loss: -7.0228	Cost: 5.91s
Train Epoch: 2441 [81920/90000 (91%)]	Loss: -6.8270	Cost: 6.11s
Train Epoch: 2441 	Average Loss: -7.0335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7997

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2442 [0/90000 (0%)]	Loss: -5.8539	Cost: 23.87s
Train Epoch: 2442 [20480/90000 (23%)]	Loss: -6.4968	Cost: 6.07s
Train Epoch: 2442 [40960/90000 (45%)]	Loss: -6.4458	Cost: 8.02s
Train Epoch: 2442 [61440/90000 (68%)]	Loss: -6.9478	Cost: 5.84s
Train Epoch: 2442 [81920/90000 (91%)]	Loss: -6.9987	Cost: 6.43s
Train Epoch: 2442 	Average Loss: -7.0485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6938

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2443 [0/90000 (0%)]	Loss: -8.1033	Cost: 24.06s
Train Epoch: 2443 [20480/90000 (23%)]	Loss: -6.5081	Cost: 6.09s
Train Epoch: 2443 [40960/90000 (45%)]	Loss: -6.4209	Cost: 7.82s
Train Epoch: 2443 [61440/90000 (68%)]	Loss: -6.9172	Cost: 5.86s
Train Epoch: 2443 [81920/90000 (91%)]	Loss: -6.5976	Cost: 6.14s
Train Epoch: 2443 	Average Loss: -7.0721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7148

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2444 [0/90000 (0%)]	Loss: -6.7890	Cost: 24.23s
Train Epoch: 2444 [20480/90000 (23%)]	Loss: -6.5638	Cost: 6.08s
Train Epoch: 2444 [40960/90000 (45%)]	Loss: -6.3234	Cost: 7.70s
Train Epoch: 2444 [61440/90000 (68%)]	Loss: -6.9769	Cost: 5.87s
Train Epoch: 2444 [81920/90000 (91%)]	Loss: -6.7396	Cost: 6.31s
Train Epoch: 2444 	Average Loss: -6.9901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5166

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2445 [0/90000 (0%)]	Loss: -4.8880	Cost: 23.80s
Train Epoch: 2445 [20480/90000 (23%)]	Loss: -6.4049	Cost: 6.07s
Train Epoch: 2445 [40960/90000 (45%)]	Loss: -6.3650	Cost: 7.76s
Train Epoch: 2445 [61440/90000 (68%)]	Loss: -6.9326	Cost: 5.91s
Train Epoch: 2445 [81920/90000 (91%)]	Loss: -6.7861	Cost: 6.06s
Train Epoch: 2445 	Average Loss: -6.9244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6071

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2446 [0/90000 (0%)]	Loss: -6.9965	Cost: 24.15s
Train Epoch: 2446 [20480/90000 (23%)]	Loss: -6.4354	Cost: 6.08s
Train Epoch: 2446 [40960/90000 (45%)]	Loss: -6.3894	Cost: 7.76s
Train Epoch: 2446 [61440/90000 (68%)]	Loss: -7.0473	Cost: 5.86s
Train Epoch: 2446 [81920/90000 (91%)]	Loss: -6.6653	Cost: 6.28s
Train Epoch: 2446 	Average Loss: -7.0417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5506

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2447 [0/90000 (0%)]	Loss: -7.2710	Cost: 24.56s
Train Epoch: 2447 [20480/90000 (23%)]	Loss: -6.4994	Cost: 6.05s
Train Epoch: 2447 [40960/90000 (45%)]	Loss: -6.4495	Cost: 7.74s
Train Epoch: 2447 [61440/90000 (68%)]	Loss: -6.9417	Cost: 5.88s
Train Epoch: 2447 [81920/90000 (91%)]	Loss: -6.7670	Cost: 6.12s
Train Epoch: 2447 	Average Loss: -7.0285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5651

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2448 [0/90000 (0%)]	Loss: -7.4979	Cost: 24.09s
Train Epoch: 2448 [20480/90000 (23%)]	Loss: -6.4544	Cost: 6.12s
Train Epoch: 2448 [40960/90000 (45%)]	Loss: -6.2464	Cost: 8.13s
Train Epoch: 2448 [61440/90000 (68%)]	Loss: -7.0542	Cost: 5.87s
Train Epoch: 2448 [81920/90000 (91%)]	Loss: -6.6817	Cost: 6.10s
Train Epoch: 2448 	Average Loss: -7.0221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6738

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2449 [0/90000 (0%)]	Loss: -6.6747	Cost: 24.22s
Train Epoch: 2449 [20480/90000 (23%)]	Loss: -6.4446	Cost: 6.12s
Train Epoch: 2449 [40960/90000 (45%)]	Loss: -6.3398	Cost: 7.81s
Train Epoch: 2449 [61440/90000 (68%)]	Loss: -6.8512	Cost: 5.90s
Train Epoch: 2449 [81920/90000 (91%)]	Loss: -6.8177	Cost: 6.15s
Train Epoch: 2449 	Average Loss: -7.0322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7141

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2450 [0/90000 (0%)]	Loss: -5.8839	Cost: 23.29s
Train Epoch: 2450 [20480/90000 (23%)]	Loss: -6.5446	Cost: 6.11s
Train Epoch: 2450 [40960/90000 (45%)]	Loss: -6.3152	Cost: 8.21s
Train Epoch: 2450 [61440/90000 (68%)]	Loss: -7.0117	Cost: 5.87s
Train Epoch: 2450 [81920/90000 (91%)]	Loss: -6.6297	Cost: 6.73s
Train Epoch: 2450 	Average Loss: -6.9639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7368

Saving model as model.pt_e2450 & waveforms_supplementary.hdf5_e2450
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2451 [0/90000 (0%)]	Loss: -5.0926	Cost: 23.42s
Train Epoch: 2451 [20480/90000 (23%)]	Loss: -6.5207	Cost: 6.08s
Train Epoch: 2451 [40960/90000 (45%)]	Loss: -6.3814	Cost: 7.91s
Train Epoch: 2451 [61440/90000 (68%)]	Loss: -6.9861	Cost: 5.84s
Train Epoch: 2451 [81920/90000 (91%)]	Loss: -6.7879	Cost: 6.27s
Train Epoch: 2451 	Average Loss: -7.0485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7963

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2452 [0/90000 (0%)]	Loss: -6.9148	Cost: 23.84s
Train Epoch: 2452 [20480/90000 (23%)]	Loss: -6.3317	Cost: 6.14s
Train Epoch: 2452 [40960/90000 (45%)]	Loss: -6.3133	Cost: 8.20s
Train Epoch: 2452 [61440/90000 (68%)]	Loss: -6.9042	Cost: 5.86s
Train Epoch: 2452 [81920/90000 (91%)]	Loss: -6.7759	Cost: 6.42s
Train Epoch: 2452 	Average Loss: -7.0488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7698

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2453 [0/90000 (0%)]	Loss: -7.9269	Cost: 23.65s
Train Epoch: 2453 [20480/90000 (23%)]	Loss: -6.5286	Cost: 6.04s
Train Epoch: 2453 [40960/90000 (45%)]	Loss: -6.2850	Cost: 8.05s
Train Epoch: 2453 [61440/90000 (68%)]	Loss: -7.1196	Cost: 5.81s
Train Epoch: 2453 [81920/90000 (91%)]	Loss: -6.6471	Cost: 6.27s
Train Epoch: 2453 	Average Loss: -7.0223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6597

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2454 [0/90000 (0%)]	Loss: -7.5148	Cost: 23.81s
Train Epoch: 2454 [20480/90000 (23%)]	Loss: -6.5458	Cost: 6.12s
Train Epoch: 2454 [40960/90000 (45%)]	Loss: -6.2885	Cost: 8.06s
Train Epoch: 2454 [61440/90000 (68%)]	Loss: -6.9453	Cost: 5.92s
Train Epoch: 2454 [81920/90000 (91%)]	Loss: -6.5947	Cost: 6.36s
Train Epoch: 2454 	Average Loss: -7.0149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6547

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2455 [0/90000 (0%)]	Loss: -7.0357	Cost: 23.38s
Train Epoch: 2455 [20480/90000 (23%)]	Loss: -6.4993	Cost: 6.14s
Train Epoch: 2455 [40960/90000 (45%)]	Loss: -6.3293	Cost: 7.94s
Train Epoch: 2455 [61440/90000 (68%)]	Loss: -6.9009	Cost: 5.91s
Train Epoch: 2455 [81920/90000 (91%)]	Loss: -6.6965	Cost: 6.26s
Train Epoch: 2455 	Average Loss: -7.0045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6549

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2456 [0/90000 (0%)]	Loss: -6.8592	Cost: 23.46s
Train Epoch: 2456 [20480/90000 (23%)]	Loss: -6.5167	Cost: 6.06s
Train Epoch: 2456 [40960/90000 (45%)]	Loss: -6.3919	Cost: 8.30s
Train Epoch: 2456 [61440/90000 (68%)]	Loss: -6.9808	Cost: 6.01s
Train Epoch: 2456 [81920/90000 (91%)]	Loss: -6.6944	Cost: 5.82s
Train Epoch: 2456 	Average Loss: -7.0598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6790

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2457 [0/90000 (0%)]	Loss: -8.4194	Cost: 23.16s
Train Epoch: 2457 [20480/90000 (23%)]	Loss: -6.5327	Cost: 6.08s
Train Epoch: 2457 [40960/90000 (45%)]	Loss: -6.3635	Cost: 7.90s
Train Epoch: 2457 [61440/90000 (68%)]	Loss: -7.1074	Cost: 5.86s
Train Epoch: 2457 [81920/90000 (91%)]	Loss: -6.5791	Cost: 6.37s
Train Epoch: 2457 	Average Loss: -7.0438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7382

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2458 [0/90000 (0%)]	Loss: -6.1183	Cost: 23.33s
Train Epoch: 2458 [20480/90000 (23%)]	Loss: -6.3933	Cost: 6.12s
Train Epoch: 2458 [40960/90000 (45%)]	Loss: -6.6348	Cost: 8.23s
Train Epoch: 2458 [61440/90000 (68%)]	Loss: -7.1996	Cost: 6.06s
Train Epoch: 2458 [81920/90000 (91%)]	Loss: -6.7949	Cost: 5.96s
Train Epoch: 2458 	Average Loss: -7.0220
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7292

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2459 [0/90000 (0%)]	Loss: -6.4598	Cost: 23.49s
Train Epoch: 2459 [20480/90000 (23%)]	Loss: -6.6124	Cost: 6.10s
Train Epoch: 2459 [40960/90000 (45%)]	Loss: -6.3189	Cost: 7.99s
Train Epoch: 2459 [61440/90000 (68%)]	Loss: -6.8881	Cost: 5.86s
Train Epoch: 2459 [81920/90000 (91%)]	Loss: -6.7212	Cost: 6.09s
Train Epoch: 2459 	Average Loss: -7.0132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8663

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2460 [0/90000 (0%)]	Loss: -7.7936	Cost: 23.32s
Train Epoch: 2460 [20480/90000 (23%)]	Loss: -6.5715	Cost: 6.10s
Train Epoch: 2460 [40960/90000 (45%)]	Loss: -6.2792	Cost: 8.41s
Train Epoch: 2460 [61440/90000 (68%)]	Loss: -7.0747	Cost: 5.86s
Train Epoch: 2460 [81920/90000 (91%)]	Loss: -6.7076	Cost: 6.29s
Train Epoch: 2460 	Average Loss: -6.9917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7254

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2461 [0/90000 (0%)]	Loss: -7.5337	Cost: 23.56s
Train Epoch: 2461 [20480/90000 (23%)]	Loss: -6.4367	Cost: 6.06s
Train Epoch: 2461 [40960/90000 (45%)]	Loss: -6.3546	Cost: 7.96s
Train Epoch: 2461 [61440/90000 (68%)]	Loss: -6.9334	Cost: 5.84s
Train Epoch: 2461 [81920/90000 (91%)]	Loss: -6.7045	Cost: 6.26s
Train Epoch: 2461 	Average Loss: -7.0602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7454

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2462 [0/90000 (0%)]	Loss: -6.6876	Cost: 23.63s
Train Epoch: 2462 [20480/90000 (23%)]	Loss: -6.5431	Cost: 6.09s
Train Epoch: 2462 [40960/90000 (45%)]	Loss: -6.3974	Cost: 8.19s
Train Epoch: 2462 [61440/90000 (68%)]	Loss: -6.9980	Cost: 5.83s
Train Epoch: 2462 [81920/90000 (91%)]	Loss: -6.8867	Cost: 6.67s
Train Epoch: 2462 	Average Loss: -7.0503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7485

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2463 [0/90000 (0%)]	Loss: -6.3751	Cost: 23.29s
Train Epoch: 2463 [20480/90000 (23%)]	Loss: -6.4050	Cost: 6.08s
Train Epoch: 2463 [40960/90000 (45%)]	Loss: -6.3663	Cost: 7.79s
Train Epoch: 2463 [61440/90000 (68%)]	Loss: -7.0065	Cost: 5.93s
Train Epoch: 2463 [81920/90000 (91%)]	Loss: -6.8878	Cost: 6.44s
Train Epoch: 2463 	Average Loss: -6.9873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6714

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2464 [0/90000 (0%)]	Loss: -6.1599	Cost: 23.53s
Train Epoch: 2464 [20480/90000 (23%)]	Loss: -6.4615	Cost: 6.12s
Train Epoch: 2464 [40960/90000 (45%)]	Loss: -6.2620	Cost: 8.23s
Train Epoch: 2464 [61440/90000 (68%)]	Loss: -6.9824	Cost: 5.86s
Train Epoch: 2464 [81920/90000 (91%)]	Loss: -6.6565	Cost: 6.30s
Train Epoch: 2464 	Average Loss: -7.0850
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7527

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2465 [0/90000 (0%)]	Loss: -6.7309	Cost: 23.50s
Train Epoch: 2465 [20480/90000 (23%)]	Loss: -6.5214	Cost: 6.11s
Train Epoch: 2465 [40960/90000 (45%)]	Loss: -6.5372	Cost: 7.93s
Train Epoch: 2465 [61440/90000 (68%)]	Loss: -6.9940	Cost: 5.86s
Train Epoch: 2465 [81920/90000 (91%)]	Loss: -6.6484	Cost: 6.11s
Train Epoch: 2465 	Average Loss: -7.0269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6733

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2466 [0/90000 (0%)]	Loss: -6.2878	Cost: 23.77s
Train Epoch: 2466 [20480/90000 (23%)]	Loss: -6.5270	Cost: 6.19s
Train Epoch: 2466 [40960/90000 (45%)]	Loss: -6.4049	Cost: 8.02s
Train Epoch: 2466 [61440/90000 (68%)]	Loss: -6.9069	Cost: 5.89s
Train Epoch: 2466 [81920/90000 (91%)]	Loss: -6.7930	Cost: 6.13s
Train Epoch: 2466 	Average Loss: -7.0116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8116

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2467 [0/90000 (0%)]	Loss: -7.2850	Cost: 23.19s
Train Epoch: 2467 [20480/90000 (23%)]	Loss: -6.5651	Cost: 6.20s
Train Epoch: 2467 [40960/90000 (45%)]	Loss: -6.4142	Cost: 7.89s
Train Epoch: 2467 [61440/90000 (68%)]	Loss: -7.1147	Cost: 5.89s
Train Epoch: 2467 [81920/90000 (91%)]	Loss: -6.6758	Cost: 6.17s
Train Epoch: 2467 	Average Loss: -7.0550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8815

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2468 [0/90000 (0%)]	Loss: -6.8165	Cost: 23.19s
Train Epoch: 2468 [20480/90000 (23%)]	Loss: -6.5124	Cost: 6.23s
Train Epoch: 2468 [40960/90000 (45%)]	Loss: -6.3947	Cost: 8.26s
Train Epoch: 2468 [61440/90000 (68%)]	Loss: -7.0250	Cost: 5.87s
Train Epoch: 2468 [81920/90000 (91%)]	Loss: -6.5475	Cost: 6.17s
Train Epoch: 2468 	Average Loss: -7.0197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5755

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2469 [0/90000 (0%)]	Loss: -7.3886	Cost: 23.68s
Train Epoch: 2469 [20480/90000 (23%)]	Loss: -6.5509	Cost: 6.19s
Train Epoch: 2469 [40960/90000 (45%)]	Loss: -6.5049	Cost: 7.52s
Train Epoch: 2469 [61440/90000 (68%)]	Loss: -7.0555	Cost: 5.91s
Train Epoch: 2469 [81920/90000 (91%)]	Loss: -6.7297	Cost: 5.98s
Train Epoch: 2469 	Average Loss: -7.0636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7984

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2470 [0/90000 (0%)]	Loss: -6.8094	Cost: 23.58s
Train Epoch: 2470 [20480/90000 (23%)]	Loss: -6.5279	Cost: 6.17s
Train Epoch: 2470 [40960/90000 (45%)]	Loss: -6.3890	Cost: 8.10s
Train Epoch: 2470 [61440/90000 (68%)]	Loss: -7.0074	Cost: 5.91s
Train Epoch: 2470 [81920/90000 (91%)]	Loss: -6.6299	Cost: 6.29s
Train Epoch: 2470 	Average Loss: -6.9695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6388

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2471 [0/90000 (0%)]	Loss: -8.9066	Cost: 23.69s
Train Epoch: 2471 [20480/90000 (23%)]	Loss: -6.4450	Cost: 6.22s
Train Epoch: 2471 [40960/90000 (45%)]	Loss: -6.3507	Cost: 7.95s
Train Epoch: 2471 [61440/90000 (68%)]	Loss: -6.8374	Cost: 5.88s
Train Epoch: 2471 [81920/90000 (91%)]	Loss: -6.6664	Cost: 5.93s
Train Epoch: 2471 	Average Loss: -7.0849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7662

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2472 [0/90000 (0%)]	Loss: -7.2027	Cost: 23.70s
Train Epoch: 2472 [20480/90000 (23%)]	Loss: -6.4040	Cost: 6.18s
Train Epoch: 2472 [40960/90000 (45%)]	Loss: -6.3417	Cost: 8.14s
Train Epoch: 2472 [61440/90000 (68%)]	Loss: -6.9360	Cost: 5.87s
Train Epoch: 2472 [81920/90000 (91%)]	Loss: -6.7854	Cost: 6.37s
Train Epoch: 2472 	Average Loss: -7.0716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7054

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2473 [0/90000 (0%)]	Loss: -6.6739	Cost: 23.19s
Train Epoch: 2473 [20480/90000 (23%)]	Loss: -6.5248	Cost: 6.05s
Train Epoch: 2473 [40960/90000 (45%)]	Loss: -6.4385	Cost: 8.20s
Train Epoch: 2473 [61440/90000 (68%)]	Loss: -6.9854	Cost: 5.93s
Train Epoch: 2473 [81920/90000 (91%)]	Loss: -6.7385	Cost: 5.96s
Train Epoch: 2473 	Average Loss: -7.0534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7171

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2474 [0/90000 (0%)]	Loss: -5.7014	Cost: 23.53s
Train Epoch: 2474 [20480/90000 (23%)]	Loss: -6.4303	Cost: 6.03s
Train Epoch: 2474 [40960/90000 (45%)]	Loss: -6.3201	Cost: 8.28s
Train Epoch: 2474 [61440/90000 (68%)]	Loss: -6.9224	Cost: 5.87s
Train Epoch: 2474 [81920/90000 (91%)]	Loss: -6.6338	Cost: 6.39s
Train Epoch: 2474 	Average Loss: -6.9787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8025

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2475 [0/90000 (0%)]	Loss: -6.0039	Cost: 24.13s
Train Epoch: 2475 [20480/90000 (23%)]	Loss: -6.3719	Cost: 6.16s
Train Epoch: 2475 [40960/90000 (45%)]	Loss: -6.4560	Cost: 7.36s
Train Epoch: 2475 [61440/90000 (68%)]	Loss: -7.0228	Cost: 5.92s
Train Epoch: 2475 [81920/90000 (91%)]	Loss: -6.7618	Cost: 6.15s
Train Epoch: 2475 	Average Loss: -6.9771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7509

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2476 [0/90000 (0%)]	Loss: -6.0662	Cost: 24.07s
Train Epoch: 2476 [20480/90000 (23%)]	Loss: -6.4601	Cost: 6.11s
Train Epoch: 2476 [40960/90000 (45%)]	Loss: -6.3694	Cost: 7.97s
Train Epoch: 2476 [61440/90000 (68%)]	Loss: -6.9706	Cost: 5.84s
Train Epoch: 2476 [81920/90000 (91%)]	Loss: -6.8341	Cost: 6.37s
Train Epoch: 2476 	Average Loss: -7.0369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7110

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2477 [0/90000 (0%)]	Loss: -7.2360	Cost: 23.57s
Train Epoch: 2477 [20480/90000 (23%)]	Loss: -6.4474	Cost: 6.22s
Train Epoch: 2477 [40960/90000 (45%)]	Loss: -6.3225	Cost: 7.87s
Train Epoch: 2477 [61440/90000 (68%)]	Loss: -6.9334	Cost: 5.88s
Train Epoch: 2477 [81920/90000 (91%)]	Loss: -6.7811	Cost: 6.00s
Train Epoch: 2477 	Average Loss: -7.0463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5683

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2478 [0/90000 (0%)]	Loss: -6.9852	Cost: 23.40s
Train Epoch: 2478 [20480/90000 (23%)]	Loss: -6.3807	Cost: 6.22s
Train Epoch: 2478 [40960/90000 (45%)]	Loss: -6.3756	Cost: 8.06s
Train Epoch: 2478 [61440/90000 (68%)]	Loss: -7.0569	Cost: 5.92s
Train Epoch: 2478 [81920/90000 (91%)]	Loss: -6.7362	Cost: 6.46s
Train Epoch: 2478 	Average Loss: -7.0394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7585

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2479 [0/90000 (0%)]	Loss: -6.6126	Cost: 23.52s
Train Epoch: 2479 [20480/90000 (23%)]	Loss: -6.5554	Cost: 6.17s
Train Epoch: 2479 [40960/90000 (45%)]	Loss: -6.3249	Cost: 7.90s
Train Epoch: 2479 [61440/90000 (68%)]	Loss: -7.0231	Cost: 5.89s
Train Epoch: 2479 [81920/90000 (91%)]	Loss: -6.5828	Cost: 6.18s
Train Epoch: 2479 	Average Loss: -7.0754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9198

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2480 [0/90000 (0%)]	Loss: -7.0048	Cost: 23.20s
Train Epoch: 2480 [20480/90000 (23%)]	Loss: -6.6347	Cost: 6.04s
Train Epoch: 2480 [40960/90000 (45%)]	Loss: -6.4653	Cost: 8.14s
Train Epoch: 2480 [61440/90000 (68%)]	Loss: -7.0027	Cost: 5.95s
Train Epoch: 2480 [81920/90000 (91%)]	Loss: -6.7146	Cost: 6.17s
Train Epoch: 2480 	Average Loss: -7.0885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7463

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2481 [0/90000 (0%)]	Loss: -7.7556	Cost: 23.72s
Train Epoch: 2481 [20480/90000 (23%)]	Loss: -6.3422	Cost: 6.02s
Train Epoch: 2481 [40960/90000 (45%)]	Loss: -6.5421	Cost: 7.82s
Train Epoch: 2481 [61440/90000 (68%)]	Loss: -7.0455	Cost: 5.93s
Train Epoch: 2481 [81920/90000 (91%)]	Loss: -6.6484	Cost: 6.04s
Train Epoch: 2481 	Average Loss: -7.1035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7682

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2482 [0/90000 (0%)]	Loss: -8.5054	Cost: 23.09s
Train Epoch: 2482 [20480/90000 (23%)]	Loss: -6.4953	Cost: 6.24s
Train Epoch: 2482 [40960/90000 (45%)]	Loss: -6.3761	Cost: 7.95s
Train Epoch: 2482 [61440/90000 (68%)]	Loss: -7.0978	Cost: 5.87s
Train Epoch: 2482 [81920/90000 (91%)]	Loss: -6.7323	Cost: 6.49s
Train Epoch: 2482 	Average Loss: -7.1243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7057

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2483 [0/90000 (0%)]	Loss: -7.8380	Cost: 23.61s
Train Epoch: 2483 [20480/90000 (23%)]	Loss: -6.6611	Cost: 6.14s
Train Epoch: 2483 [40960/90000 (45%)]	Loss: -6.2806	Cost: 7.83s
Train Epoch: 2483 [61440/90000 (68%)]	Loss: -6.9011	Cost: 5.94s
Train Epoch: 2483 [81920/90000 (91%)]	Loss: -6.6882	Cost: 6.00s
Train Epoch: 2483 	Average Loss: -7.0720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7035

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2484 [0/90000 (0%)]	Loss: -6.8684	Cost: 23.25s
Train Epoch: 2484 [20480/90000 (23%)]	Loss: -6.6426	Cost: 6.26s
Train Epoch: 2484 [40960/90000 (45%)]	Loss: -6.3352	Cost: 8.19s
Train Epoch: 2484 [61440/90000 (68%)]	Loss: -6.9986	Cost: 5.86s
Train Epoch: 2484 [81920/90000 (91%)]	Loss: -6.7190	Cost: 6.15s
Train Epoch: 2484 	Average Loss: -7.0542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6960

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2485 [0/90000 (0%)]	Loss: -7.8338	Cost: 23.87s
Train Epoch: 2485 [20480/90000 (23%)]	Loss: -6.6744	Cost: 6.01s
Train Epoch: 2485 [40960/90000 (45%)]	Loss: -6.2650	Cost: 8.02s
Train Epoch: 2485 [61440/90000 (68%)]	Loss: -6.9385	Cost: 5.94s
Train Epoch: 2485 [81920/90000 (91%)]	Loss: -6.6336	Cost: 5.74s
Train Epoch: 2485 	Average Loss: -7.0674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7453

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2486 [0/90000 (0%)]	Loss: -6.7022	Cost: 22.96s
Train Epoch: 2486 [20480/90000 (23%)]	Loss: -6.3804	Cost: 6.30s
Train Epoch: 2486 [40960/90000 (45%)]	Loss: -6.4262	Cost: 8.00s
Train Epoch: 2486 [61440/90000 (68%)]	Loss: -7.0490	Cost: 5.98s
Train Epoch: 2486 [81920/90000 (91%)]	Loss: -6.7513	Cost: 6.44s
Train Epoch: 2486 	Average Loss: -7.0281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7046

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2487 [0/90000 (0%)]	Loss: -6.7173	Cost: 23.29s
Train Epoch: 2487 [20480/90000 (23%)]	Loss: -6.4307	Cost: 6.11s
Train Epoch: 2487 [40960/90000 (45%)]	Loss: -6.2435	Cost: 8.07s
Train Epoch: 2487 [61440/90000 (68%)]	Loss: -7.1075	Cost: 5.88s
Train Epoch: 2487 [81920/90000 (91%)]	Loss: -6.7308	Cost: 5.99s
Train Epoch: 2487 	Average Loss: -7.0312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7632

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2488 [0/90000 (0%)]	Loss: -7.6121	Cost: 23.72s
Train Epoch: 2488 [20480/90000 (23%)]	Loss: -6.2940	Cost: 6.21s
Train Epoch: 2488 [40960/90000 (45%)]	Loss: -6.4604	Cost: 8.07s
Train Epoch: 2488 [61440/90000 (68%)]	Loss: -7.1420	Cost: 5.85s
Train Epoch: 2488 [81920/90000 (91%)]	Loss: -6.5495	Cost: 6.22s
Train Epoch: 2488 	Average Loss: -7.0164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8620

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2489 [0/90000 (0%)]	Loss: -6.5825	Cost: 23.69s
Train Epoch: 2489 [20480/90000 (23%)]	Loss: -6.5985	Cost: 6.00s
Train Epoch: 2489 [40960/90000 (45%)]	Loss: -6.3611	Cost: 8.02s
Train Epoch: 2489 [61440/90000 (68%)]	Loss: -7.0480	Cost: 5.84s
Train Epoch: 2489 [81920/90000 (91%)]	Loss: -6.6148	Cost: 5.92s
Train Epoch: 2489 	Average Loss: -7.0900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8239

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2490 [0/90000 (0%)]	Loss: -7.8452	Cost: 23.49s
Train Epoch: 2490 [20480/90000 (23%)]	Loss: -6.4978	Cost: 6.15s
Train Epoch: 2490 [40960/90000 (45%)]	Loss: -6.1362	Cost: 7.96s
Train Epoch: 2490 [61440/90000 (68%)]	Loss: -7.2056	Cost: 5.84s
Train Epoch: 2490 [81920/90000 (91%)]	Loss: -6.7790	Cost: 6.24s
Train Epoch: 2490 	Average Loss: -7.0413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8034

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2491 [0/90000 (0%)]	Loss: -6.5813	Cost: 23.34s
Train Epoch: 2491 [20480/90000 (23%)]	Loss: -6.5336	Cost: 6.26s
Train Epoch: 2491 [40960/90000 (45%)]	Loss: -6.3993	Cost: 8.00s
Train Epoch: 2491 [61440/90000 (68%)]	Loss: -6.9828	Cost: 5.91s
Train Epoch: 2491 [81920/90000 (91%)]	Loss: -6.6800	Cost: 5.87s
Train Epoch: 2491 	Average Loss: -7.0436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8160

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2492 [0/90000 (0%)]	Loss: -7.1975	Cost: 23.85s
Train Epoch: 2492 [20480/90000 (23%)]	Loss: -6.4134	Cost: 6.10s
Train Epoch: 2492 [40960/90000 (45%)]	Loss: -6.3505	Cost: 7.96s
Train Epoch: 2492 [61440/90000 (68%)]	Loss: -7.0102	Cost: 5.92s
Train Epoch: 2492 [81920/90000 (91%)]	Loss: -6.8364	Cost: 6.43s
Train Epoch: 2492 	Average Loss: -7.0479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7352

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2493 [0/90000 (0%)]	Loss: -6.4173	Cost: 24.15s
Train Epoch: 2493 [20480/90000 (23%)]	Loss: -6.5823	Cost: 6.22s
Train Epoch: 2493 [40960/90000 (45%)]	Loss: -6.2692	Cost: 8.00s
Train Epoch: 2493 [61440/90000 (68%)]	Loss: -7.1260	Cost: 5.99s
Train Epoch: 2493 [81920/90000 (91%)]	Loss: -6.6782	Cost: 5.95s
Train Epoch: 2493 	Average Loss: -6.9736
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6761

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2494 [0/90000 (0%)]	Loss: -4.0059	Cost: 23.23s
Train Epoch: 2494 [20480/90000 (23%)]	Loss: -6.4619	Cost: 6.13s
Train Epoch: 2494 [40960/90000 (45%)]	Loss: -6.5023	Cost: 8.20s
Train Epoch: 2494 [61440/90000 (68%)]	Loss: -6.9738	Cost: 5.87s
Train Epoch: 2494 [81920/90000 (91%)]	Loss: -6.6875	Cost: 6.21s
Train Epoch: 2494 	Average Loss: -6.9609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7478

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2495 [0/90000 (0%)]	Loss: -5.4055	Cost: 23.70s
Train Epoch: 2495 [20480/90000 (23%)]	Loss: -6.5003	Cost: 6.13s
Train Epoch: 2495 [40960/90000 (45%)]	Loss: -6.4089	Cost: 7.90s
Train Epoch: 2495 [61440/90000 (68%)]	Loss: -7.1302	Cost: 5.91s
Train Epoch: 2495 [81920/90000 (91%)]	Loss: -6.6762	Cost: 6.08s
Train Epoch: 2495 	Average Loss: -6.8841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7026

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2496 [0/90000 (0%)]	Loss: -7.1997	Cost: 23.44s
Train Epoch: 2496 [20480/90000 (23%)]	Loss: -6.5390	Cost: 6.19s
Train Epoch: 2496 [40960/90000 (45%)]	Loss: -6.2756	Cost: 8.18s
Train Epoch: 2496 [61440/90000 (68%)]	Loss: -7.1797	Cost: 5.86s
Train Epoch: 2496 [81920/90000 (91%)]	Loss: -6.8331	Cost: 6.13s
Train Epoch: 2496 	Average Loss: -7.0961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6161

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2497 [0/90000 (0%)]	Loss: -6.8668	Cost: 23.52s
Train Epoch: 2497 [20480/90000 (23%)]	Loss: -6.4659	Cost: 6.25s
Train Epoch: 2497 [40960/90000 (45%)]	Loss: -6.5200	Cost: 7.78s
Train Epoch: 2497 [61440/90000 (68%)]	Loss: -6.9660	Cost: 5.90s
Train Epoch: 2497 [81920/90000 (91%)]	Loss: -6.6541	Cost: 6.20s
Train Epoch: 2497 	Average Loss: -7.0228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8590

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2498 [0/90000 (0%)]	Loss: -6.3663	Cost: 23.77s
Train Epoch: 2498 [20480/90000 (23%)]	Loss: -6.4752	Cost: 6.16s
Train Epoch: 2498 [40960/90000 (45%)]	Loss: -6.4668	Cost: 7.70s
Train Epoch: 2498 [61440/90000 (68%)]	Loss: -6.9253	Cost: 6.08s
Train Epoch: 2498 [81920/90000 (91%)]	Loss: -6.9193	Cost: 6.19s
Train Epoch: 2498 	Average Loss: -7.0053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5780

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2499 [0/90000 (0%)]	Loss: -7.5507	Cost: 23.12s
Train Epoch: 2499 [20480/90000 (23%)]	Loss: -6.4666	Cost: 6.11s
Train Epoch: 2499 [40960/90000 (45%)]	Loss: -6.3222	Cost: 8.08s
Train Epoch: 2499 [61440/90000 (68%)]	Loss: -6.8685	Cost: 5.87s
Train Epoch: 2499 [81920/90000 (91%)]	Loss: -6.8320	Cost: 6.06s
Train Epoch: 2499 	Average Loss: -6.9777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7163

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2500 [0/90000 (0%)]	Loss: -6.2547	Cost: 23.73s
Train Epoch: 2500 [20480/90000 (23%)]	Loss: -6.3687	Cost: 6.17s
Train Epoch: 2500 [40960/90000 (45%)]	Loss: -6.4578	Cost: 7.97s
Train Epoch: 2500 [61440/90000 (68%)]	Loss: -6.8877	Cost: 5.90s
Train Epoch: 2500 [81920/90000 (91%)]	Loss: -6.6954	Cost: 6.25s
Train Epoch: 2500 	Average Loss: -7.0139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5789

Saving model as model.pt_e2500 & waveforms_supplementary.hdf5_e2500
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2501 [0/90000 (0%)]	Loss: -5.7532	Cost: 24.12s
Train Epoch: 2501 [20480/90000 (23%)]	Loss: -6.4274	Cost: 6.13s
Train Epoch: 2501 [40960/90000 (45%)]	Loss: -6.4047	Cost: 7.95s
Train Epoch: 2501 [61440/90000 (68%)]	Loss: -7.0503	Cost: 5.83s
Train Epoch: 2501 [81920/90000 (91%)]	Loss: -6.5031	Cost: 6.08s
Train Epoch: 2501 	Average Loss: -6.9657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7941

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2502 [0/90000 (0%)]	Loss: -5.5590	Cost: 23.86s
Train Epoch: 2502 [20480/90000 (23%)]	Loss: -6.4878	Cost: 6.20s
Train Epoch: 2502 [40960/90000 (45%)]	Loss: -6.6157	Cost: 7.87s
Train Epoch: 2502 [61440/90000 (68%)]	Loss: -7.1684	Cost: 5.98s
Train Epoch: 2502 [81920/90000 (91%)]	Loss: -6.6660	Cost: 5.84s
Train Epoch: 2502 	Average Loss: -7.0108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6218

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2503 [0/90000 (0%)]	Loss: -7.0835	Cost: 23.53s
Train Epoch: 2503 [20480/90000 (23%)]	Loss: -6.5374	Cost: 6.14s
Train Epoch: 2503 [40960/90000 (45%)]	Loss: -6.5624	Cost: 7.97s
Train Epoch: 2503 [61440/90000 (68%)]	Loss: -6.9356	Cost: 5.93s
Train Epoch: 2503 [81920/90000 (91%)]	Loss: -6.5540	Cost: 5.82s
Train Epoch: 2503 	Average Loss: -6.9943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6888

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2504 [0/90000 (0%)]	Loss: -8.0779	Cost: 24.06s
Train Epoch: 2504 [20480/90000 (23%)]	Loss: -6.6202	Cost: 6.15s
Train Epoch: 2504 [40960/90000 (45%)]	Loss: -6.3402	Cost: 7.94s
Train Epoch: 2504 [61440/90000 (68%)]	Loss: -7.2055	Cost: 5.91s
Train Epoch: 2504 [81920/90000 (91%)]	Loss: -6.5844	Cost: 5.86s
Train Epoch: 2504 	Average Loss: -7.0497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7363

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2505 [0/90000 (0%)]	Loss: -8.1787	Cost: 24.12s
Train Epoch: 2505 [20480/90000 (23%)]	Loss: -6.3421	Cost: 6.10s
Train Epoch: 2505 [40960/90000 (45%)]	Loss: -6.4401	Cost: 7.97s
Train Epoch: 2505 [61440/90000 (68%)]	Loss: -7.1346	Cost: 5.88s
Train Epoch: 2505 [81920/90000 (91%)]	Loss: -6.5776	Cost: 6.02s
Train Epoch: 2505 	Average Loss: -7.0610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6326

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2506 [0/90000 (0%)]	Loss: -7.8248	Cost: 23.21s
Train Epoch: 2506 [20480/90000 (23%)]	Loss: -6.4268	Cost: 6.18s
Train Epoch: 2506 [40960/90000 (45%)]	Loss: -6.2279	Cost: 8.22s
Train Epoch: 2506 [61440/90000 (68%)]	Loss: -7.0495	Cost: 6.06s
Train Epoch: 2506 [81920/90000 (91%)]	Loss: -6.7585	Cost: 6.01s
Train Epoch: 2506 	Average Loss: -7.0279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8145

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2507 [0/90000 (0%)]	Loss: -7.3719	Cost: 23.64s
Train Epoch: 2507 [20480/90000 (23%)]	Loss: -6.4386	Cost: 6.03s
Train Epoch: 2507 [40960/90000 (45%)]	Loss: -6.4792	Cost: 8.06s
Train Epoch: 2507 [61440/90000 (68%)]	Loss: -6.9100	Cost: 5.86s
Train Epoch: 2507 [81920/90000 (91%)]	Loss: -6.7696	Cost: 6.14s
Train Epoch: 2507 	Average Loss: -7.0950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7612

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2508 [0/90000 (0%)]	Loss: -7.1204	Cost: 23.24s
Train Epoch: 2508 [20480/90000 (23%)]	Loss: -6.4898	Cost: 6.06s
Train Epoch: 2508 [40960/90000 (45%)]	Loss: -6.3176	Cost: 8.16s
Train Epoch: 2508 [61440/90000 (68%)]	Loss: -6.9806	Cost: 6.01s
Train Epoch: 2508 [81920/90000 (91%)]	Loss: -6.7054	Cost: 5.93s
Train Epoch: 2508 	Average Loss: -7.0208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7927

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2509 [0/90000 (0%)]	Loss: -4.6917	Cost: 23.46s
Train Epoch: 2509 [20480/90000 (23%)]	Loss: -6.5857	Cost: 6.16s
Train Epoch: 2509 [40960/90000 (45%)]	Loss: -6.3911	Cost: 7.94s
Train Epoch: 2509 [61440/90000 (68%)]	Loss: -6.9517	Cost: 5.88s
Train Epoch: 2509 [81920/90000 (91%)]	Loss: -6.6748	Cost: 5.85s
Train Epoch: 2509 	Average Loss: -6.9431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7524

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2510 [0/90000 (0%)]	Loss: -8.0873	Cost: 23.43s
Train Epoch: 2510 [20480/90000 (23%)]	Loss: -6.5044	Cost: 6.14s
Train Epoch: 2510 [40960/90000 (45%)]	Loss: -6.4433	Cost: 8.58s
Train Epoch: 2510 [61440/90000 (68%)]	Loss: -6.9361	Cost: 6.01s
Train Epoch: 2510 [81920/90000 (91%)]	Loss: -6.7603	Cost: 6.03s
Train Epoch: 2510 	Average Loss: -7.0783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6577

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2511 [0/90000 (0%)]	Loss: -7.0919	Cost: 23.63s
Train Epoch: 2511 [20480/90000 (23%)]	Loss: -6.5065	Cost: 6.16s
Train Epoch: 2511 [40960/90000 (45%)]	Loss: -6.4154	Cost: 7.80s
Train Epoch: 2511 [61440/90000 (68%)]	Loss: -6.9376	Cost: 5.96s
Train Epoch: 2511 [81920/90000 (91%)]	Loss: -6.6602	Cost: 6.18s
Train Epoch: 2511 	Average Loss: -7.0323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7640

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2512 [0/90000 (0%)]	Loss: -5.6439	Cost: 23.68s
Train Epoch: 2512 [20480/90000 (23%)]	Loss: -6.4692	Cost: 6.18s
Train Epoch: 2512 [40960/90000 (45%)]	Loss: -6.3974	Cost: 8.23s
Train Epoch: 2512 [61440/90000 (68%)]	Loss: -7.0954	Cost: 5.89s
Train Epoch: 2512 [81920/90000 (91%)]	Loss: -6.6285	Cost: 6.11s
Train Epoch: 2512 	Average Loss: -7.0338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6406

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2513 [0/90000 (0%)]	Loss: -5.7821	Cost: 23.69s
Train Epoch: 2513 [20480/90000 (23%)]	Loss: -6.5262	Cost: 6.21s
Train Epoch: 2513 [40960/90000 (45%)]	Loss: -6.3904	Cost: 7.97s
Train Epoch: 2513 [61440/90000 (68%)]	Loss: -6.8913	Cost: 6.45s
Train Epoch: 2513 [81920/90000 (91%)]	Loss: -6.6277	Cost: 5.59s
Train Epoch: 2513 	Average Loss: -6.9844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6804

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2514 [0/90000 (0%)]	Loss: -7.7679	Cost: 23.63s
Train Epoch: 2514 [20480/90000 (23%)]	Loss: -6.5130	Cost: 6.20s
Train Epoch: 2514 [40960/90000 (45%)]	Loss: -6.3641	Cost: 8.03s
Train Epoch: 2514 [61440/90000 (68%)]	Loss: -6.9491	Cost: 5.87s
Train Epoch: 2514 [81920/90000 (91%)]	Loss: -6.7414	Cost: 6.28s
Train Epoch: 2514 	Average Loss: -7.1203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8267

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2515 [0/90000 (0%)]	Loss: -7.7732	Cost: 23.63s
Train Epoch: 2515 [20480/90000 (23%)]	Loss: -6.4330	Cost: 6.14s
Train Epoch: 2515 [40960/90000 (45%)]	Loss: -6.5031	Cost: 7.92s
Train Epoch: 2515 [61440/90000 (68%)]	Loss: -6.9716	Cost: 5.96s
Train Epoch: 2515 [81920/90000 (91%)]	Loss: -6.5396	Cost: 6.00s
Train Epoch: 2515 	Average Loss: -7.0438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6948

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2516 [0/90000 (0%)]	Loss: -6.2240	Cost: 23.12s
Train Epoch: 2516 [20480/90000 (23%)]	Loss: -6.7430	Cost: 6.26s
Train Epoch: 2516 [40960/90000 (45%)]	Loss: -6.4978	Cost: 8.16s
Train Epoch: 2516 [61440/90000 (68%)]	Loss: -6.9248	Cost: 5.93s
Train Epoch: 2516 [81920/90000 (91%)]	Loss: -6.8196	Cost: 6.28s
Train Epoch: 2516 	Average Loss: -7.0080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7223

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2517 [0/90000 (0%)]	Loss: -5.6559	Cost: 23.30s
Train Epoch: 2517 [20480/90000 (23%)]	Loss: -6.6519	Cost: 6.15s
Train Epoch: 2517 [40960/90000 (45%)]	Loss: -6.3071	Cost: 7.67s
Train Epoch: 2517 [61440/90000 (68%)]	Loss: -6.7801	Cost: 6.01s
Train Epoch: 2517 [81920/90000 (91%)]	Loss: -6.5910	Cost: 5.85s
Train Epoch: 2517 	Average Loss: -7.0272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8277

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2518 [0/90000 (0%)]	Loss: -7.7391	Cost: 24.02s
Train Epoch: 2518 [20480/90000 (23%)]	Loss: -6.5578	Cost: 6.17s
Train Epoch: 2518 [40960/90000 (45%)]	Loss: -6.3508	Cost: 7.84s
Train Epoch: 2518 [61440/90000 (68%)]	Loss: -7.0123	Cost: 5.87s
Train Epoch: 2518 [81920/90000 (91%)]	Loss: -6.7696	Cost: 6.39s
Train Epoch: 2518 	Average Loss: -7.0816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7045

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2519 [0/90000 (0%)]	Loss: -7.7643	Cost: 24.12s
Train Epoch: 2519 [20480/90000 (23%)]	Loss: -6.7147	Cost: 6.22s
Train Epoch: 2519 [40960/90000 (45%)]	Loss: -6.3235	Cost: 7.75s
Train Epoch: 2519 [61440/90000 (68%)]	Loss: -6.9963	Cost: 5.98s
Train Epoch: 2519 [81920/90000 (91%)]	Loss: -6.7920	Cost: 6.19s
Train Epoch: 2519 	Average Loss: -7.0727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8292

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2520 [0/90000 (0%)]	Loss: -7.2601	Cost: 23.53s
Train Epoch: 2520 [20480/90000 (23%)]	Loss: -6.4447	Cost: 6.17s
Train Epoch: 2520 [40960/90000 (45%)]	Loss: -6.3169	Cost: 7.93s
Train Epoch: 2520 [61440/90000 (68%)]	Loss: -7.1482	Cost: 5.92s
Train Epoch: 2520 [81920/90000 (91%)]	Loss: -6.6061	Cost: 6.24s
Train Epoch: 2520 	Average Loss: -7.0660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7944

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2521 [0/90000 (0%)]	Loss: -7.7157	Cost: 23.68s
Train Epoch: 2521 [20480/90000 (23%)]	Loss: -6.5376	Cost: 6.42s
Train Epoch: 2521 [40960/90000 (45%)]	Loss: -6.3521	Cost: 7.64s
Train Epoch: 2521 [61440/90000 (68%)]	Loss: -6.9514	Cost: 5.87s
Train Epoch: 2521 [81920/90000 (91%)]	Loss: -6.8786	Cost: 6.15s
Train Epoch: 2521 	Average Loss: -7.0828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6817

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2522 [0/90000 (0%)]	Loss: -5.9326	Cost: 23.52s
Train Epoch: 2522 [20480/90000 (23%)]	Loss: -6.3603	Cost: 6.15s
Train Epoch: 2522 [40960/90000 (45%)]	Loss: -6.5593	Cost: 7.99s
Train Epoch: 2522 [61440/90000 (68%)]	Loss: -6.9352	Cost: 5.94s
Train Epoch: 2522 [81920/90000 (91%)]	Loss: -6.7885	Cost: 6.21s
Train Epoch: 2522 	Average Loss: -7.0015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7343

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2523 [0/90000 (0%)]	Loss: -6.7826	Cost: 23.38s
Train Epoch: 2523 [20480/90000 (23%)]	Loss: -6.6225	Cost: 6.18s
Train Epoch: 2523 [40960/90000 (45%)]	Loss: -6.4516	Cost: 7.90s
Train Epoch: 2523 [61440/90000 (68%)]	Loss: -7.0538	Cost: 5.84s
Train Epoch: 2523 [81920/90000 (91%)]	Loss: -6.7222	Cost: 6.16s
Train Epoch: 2523 	Average Loss: -7.0952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6940

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2524 [0/90000 (0%)]	Loss: -6.7760	Cost: 23.86s
Train Epoch: 2524 [20480/90000 (23%)]	Loss: -6.4661	Cost: 6.20s
Train Epoch: 2524 [40960/90000 (45%)]	Loss: -6.3321	Cost: 7.94s
Train Epoch: 2524 [61440/90000 (68%)]	Loss: -7.0201	Cost: 5.98s
Train Epoch: 2524 [81920/90000 (91%)]	Loss: -6.6022	Cost: 6.25s
Train Epoch: 2524 	Average Loss: -7.0304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7788

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2525 [0/90000 (0%)]	Loss: -7.4424	Cost: 23.71s
Train Epoch: 2525 [20480/90000 (23%)]	Loss: -6.6580	Cost: 6.12s
Train Epoch: 2525 [40960/90000 (45%)]	Loss: -6.4063	Cost: 8.00s
Train Epoch: 2525 [61440/90000 (68%)]	Loss: -7.0681	Cost: 5.85s
Train Epoch: 2525 [81920/90000 (91%)]	Loss: -6.6880	Cost: 6.12s
Train Epoch: 2525 	Average Loss: -7.0336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6932

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2526 [0/90000 (0%)]	Loss: -7.4425	Cost: 23.66s
Train Epoch: 2526 [20480/90000 (23%)]	Loss: -6.5916	Cost: 6.11s
Train Epoch: 2526 [40960/90000 (45%)]	Loss: -6.2829	Cost: 8.36s
Train Epoch: 2526 [61440/90000 (68%)]	Loss: -7.0480	Cost: 5.84s
Train Epoch: 2526 [81920/90000 (91%)]	Loss: -6.7436	Cost: 6.43s
Train Epoch: 2526 	Average Loss: -7.0761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7014

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2527 [0/90000 (0%)]	Loss: -6.0276	Cost: 23.89s
Train Epoch: 2527 [20480/90000 (23%)]	Loss: -6.4850	Cost: 6.13s
Train Epoch: 2527 [40960/90000 (45%)]	Loss: -6.4260	Cost: 7.98s
Train Epoch: 2527 [61440/90000 (68%)]	Loss: -6.9164	Cost: 5.92s
Train Epoch: 2527 [81920/90000 (91%)]	Loss: -6.6905	Cost: 6.02s
Train Epoch: 2527 	Average Loss: -7.0140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6092

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2528 [0/90000 (0%)]	Loss: -7.1163	Cost: 23.15s
Train Epoch: 2528 [20480/90000 (23%)]	Loss: -6.5135	Cost: 6.04s
Train Epoch: 2528 [40960/90000 (45%)]	Loss: -6.5140	Cost: 8.18s
Train Epoch: 2528 [61440/90000 (68%)]	Loss: -7.1634	Cost: 5.91s
Train Epoch: 2528 [81920/90000 (91%)]	Loss: -6.5787	Cost: 6.30s
Train Epoch: 2528 	Average Loss: -7.0911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7237

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2529 [0/90000 (0%)]	Loss: -7.1595	Cost: 23.71s
Train Epoch: 2529 [20480/90000 (23%)]	Loss: -6.5580	Cost: 6.26s
Train Epoch: 2529 [40960/90000 (45%)]	Loss: -6.3213	Cost: 8.27s
Train Epoch: 2529 [61440/90000 (68%)]	Loss: -7.0611	Cost: 6.30s
Train Epoch: 2529 [81920/90000 (91%)]	Loss: -6.4738	Cost: 5.66s
Train Epoch: 2529 	Average Loss: -7.0303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6139

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2530 [0/90000 (0%)]	Loss: -7.8934	Cost: 23.48s
Train Epoch: 2530 [20480/90000 (23%)]	Loss: -6.4436	Cost: 6.19s
Train Epoch: 2530 [40960/90000 (45%)]	Loss: -6.4479	Cost: 7.69s
Train Epoch: 2530 [61440/90000 (68%)]	Loss: -7.0358	Cost: 6.07s
Train Epoch: 2530 [81920/90000 (91%)]	Loss: -6.7487	Cost: 6.17s
Train Epoch: 2530 	Average Loss: -7.0974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8174

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2531 [0/90000 (0%)]	Loss: -7.7947	Cost: 23.72s
Train Epoch: 2531 [20480/90000 (23%)]	Loss: -6.4907	Cost: 6.17s
Train Epoch: 2531 [40960/90000 (45%)]	Loss: -6.4451	Cost: 7.74s
Train Epoch: 2531 [61440/90000 (68%)]	Loss: -6.9693	Cost: 5.88s
Train Epoch: 2531 [81920/90000 (91%)]	Loss: -6.6374	Cost: 6.11s
Train Epoch: 2531 	Average Loss: -7.0558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6043

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2532 [0/90000 (0%)]	Loss: -8.1823	Cost: 23.76s
Train Epoch: 2532 [20480/90000 (23%)]	Loss: -6.4309	Cost: 6.07s
Train Epoch: 2532 [40960/90000 (45%)]	Loss: -6.3821	Cost: 8.27s
Train Epoch: 2532 [61440/90000 (68%)]	Loss: -7.0451	Cost: 5.87s
Train Epoch: 2532 [81920/90000 (91%)]	Loss: -6.6882	Cost: 6.08s
Train Epoch: 2532 	Average Loss: -7.0670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6551

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2533 [0/90000 (0%)]	Loss: -6.5926	Cost: 24.03s
Train Epoch: 2533 [20480/90000 (23%)]	Loss: -6.4686	Cost: 6.10s
Train Epoch: 2533 [40960/90000 (45%)]	Loss: -6.3519	Cost: 7.82s
Train Epoch: 2533 [61440/90000 (68%)]	Loss: -6.8876	Cost: 5.90s
Train Epoch: 2533 [81920/90000 (91%)]	Loss: -6.7616	Cost: 6.05s
Train Epoch: 2533 	Average Loss: -7.0688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7250

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2534 [0/90000 (0%)]	Loss: -6.7507	Cost: 23.24s
Train Epoch: 2534 [20480/90000 (23%)]	Loss: -6.4068	Cost: 6.09s
Train Epoch: 2534 [40960/90000 (45%)]	Loss: -6.4776	Cost: 8.20s
Train Epoch: 2534 [61440/90000 (68%)]	Loss: -7.0735	Cost: 5.90s
Train Epoch: 2534 [81920/90000 (91%)]	Loss: -6.6846	Cost: 6.15s
Train Epoch: 2534 	Average Loss: -7.0708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7071

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2535 [0/90000 (0%)]	Loss: -7.6539	Cost: 23.74s
Train Epoch: 2535 [20480/90000 (23%)]	Loss: -6.5221	Cost: 6.13s
Train Epoch: 2535 [40960/90000 (45%)]	Loss: -6.4633	Cost: 7.90s
Train Epoch: 2535 [61440/90000 (68%)]	Loss: -6.9530	Cost: 5.84s
Train Epoch: 2535 [81920/90000 (91%)]	Loss: -6.6393	Cost: 6.17s
Train Epoch: 2535 	Average Loss: -7.0735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7414

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2536 [0/90000 (0%)]	Loss: -5.8429	Cost: 23.37s
Train Epoch: 2536 [20480/90000 (23%)]	Loss: -6.5736	Cost: 6.17s
Train Epoch: 2536 [40960/90000 (45%)]	Loss: -6.2441	Cost: 8.05s
Train Epoch: 2536 [61440/90000 (68%)]	Loss: -6.9382	Cost: 5.85s
Train Epoch: 2536 [81920/90000 (91%)]	Loss: -6.8047	Cost: 6.41s
Train Epoch: 2536 	Average Loss: -7.0425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6752

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2537 [0/90000 (0%)]	Loss: -7.2475	Cost: 23.97s
Train Epoch: 2537 [20480/90000 (23%)]	Loss: -6.6984	Cost: 6.07s
Train Epoch: 2537 [40960/90000 (45%)]	Loss: -6.2572	Cost: 7.81s
Train Epoch: 2537 [61440/90000 (68%)]	Loss: -7.0853	Cost: 5.94s
Train Epoch: 2537 [81920/90000 (91%)]	Loss: -6.8190	Cost: 6.03s
Train Epoch: 2537 	Average Loss: -7.0727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6984

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2538 [0/90000 (0%)]	Loss: -7.2226	Cost: 23.93s
Train Epoch: 2538 [20480/90000 (23%)]	Loss: -6.3611	Cost: 6.29s
Train Epoch: 2538 [40960/90000 (45%)]	Loss: -6.3665	Cost: 7.29s
Train Epoch: 2538 [61440/90000 (68%)]	Loss: -7.0176	Cost: 5.90s
Train Epoch: 2538 [81920/90000 (91%)]	Loss: -6.7587	Cost: 6.19s
Train Epoch: 2538 	Average Loss: -7.0280
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6387

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2539 [0/90000 (0%)]	Loss: -6.5148	Cost: 24.44s
Train Epoch: 2539 [20480/90000 (23%)]	Loss: -6.6376	Cost: 6.43s
Train Epoch: 2539 [40960/90000 (45%)]	Loss: -6.3233	Cost: 6.92s
Train Epoch: 2539 [61440/90000 (68%)]	Loss: -7.0334	Cost: 5.90s
Train Epoch: 2539 [81920/90000 (91%)]	Loss: -6.7626	Cost: 6.48s
Train Epoch: 2539 	Average Loss: -7.0499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6748

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2540 [0/90000 (0%)]	Loss: -7.0530	Cost: 23.05s
Train Epoch: 2540 [20480/90000 (23%)]	Loss: -6.4851	Cost: 6.08s
Train Epoch: 2540 [40960/90000 (45%)]	Loss: -6.3206	Cost: 8.12s
Train Epoch: 2540 [61440/90000 (68%)]	Loss: -6.9626	Cost: 5.87s
Train Epoch: 2540 [81920/90000 (91%)]	Loss: -6.8403	Cost: 6.29s
Train Epoch: 2540 	Average Loss: -7.0573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7536

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2541 [0/90000 (0%)]	Loss: -6.8415	Cost: 23.79s
Train Epoch: 2541 [20480/90000 (23%)]	Loss: -6.5627	Cost: 6.11s
Train Epoch: 2541 [40960/90000 (45%)]	Loss: -6.3109	Cost: 7.69s
Train Epoch: 2541 [61440/90000 (68%)]	Loss: -7.0709	Cost: 5.89s
Train Epoch: 2541 [81920/90000 (91%)]	Loss: -6.8031	Cost: 6.13s
Train Epoch: 2541 	Average Loss: -7.0566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7161

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2542 [0/90000 (0%)]	Loss: -6.4922	Cost: 23.41s
Train Epoch: 2542 [20480/90000 (23%)]	Loss: -6.5744	Cost: 6.05s
Train Epoch: 2542 [40960/90000 (45%)]	Loss: -6.3834	Cost: 8.03s
Train Epoch: 2542 [61440/90000 (68%)]	Loss: -6.8510	Cost: 5.82s
Train Epoch: 2542 [81920/90000 (91%)]	Loss: -6.8246	Cost: 6.38s
Train Epoch: 2542 	Average Loss: -7.0610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7948

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2543 [0/90000 (0%)]	Loss: -5.5654	Cost: 23.92s
Train Epoch: 2543 [20480/90000 (23%)]	Loss: -6.4987	Cost: 6.26s
Train Epoch: 2543 [40960/90000 (45%)]	Loss: -6.4925	Cost: 7.76s
Train Epoch: 2543 [61440/90000 (68%)]	Loss: -6.8533	Cost: 5.87s
Train Epoch: 2543 [81920/90000 (91%)]	Loss: -6.6793	Cost: 6.33s
Train Epoch: 2543 	Average Loss: -6.9753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7116

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2544 [0/90000 (0%)]	Loss: -5.9515	Cost: 24.23s
Train Epoch: 2544 [20480/90000 (23%)]	Loss: -6.6274	Cost: 6.08s
Train Epoch: 2544 [40960/90000 (45%)]	Loss: -6.4966	Cost: 7.74s
Train Epoch: 2544 [61440/90000 (68%)]	Loss: -7.3476	Cost: 5.87s
Train Epoch: 2544 [81920/90000 (91%)]	Loss: -6.6245	Cost: 6.28s
Train Epoch: 2544 	Average Loss: -7.0185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7477

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2545 [0/90000 (0%)]	Loss: -7.7460	Cost: 23.99s
Train Epoch: 2545 [20480/90000 (23%)]	Loss: -6.4662	Cost: 6.38s
Train Epoch: 2545 [40960/90000 (45%)]	Loss: -6.5353	Cost: 7.45s
Train Epoch: 2545 [61440/90000 (68%)]	Loss: -6.9980	Cost: 5.86s
Train Epoch: 2545 [81920/90000 (91%)]	Loss: -6.6375	Cost: 6.19s
Train Epoch: 2545 	Average Loss: -7.0335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6973

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2546 [0/90000 (0%)]	Loss: -6.1470	Cost: 23.23s
Train Epoch: 2546 [20480/90000 (23%)]	Loss: -6.4894	Cost: 6.11s
Train Epoch: 2546 [40960/90000 (45%)]	Loss: -6.3699	Cost: 8.06s
Train Epoch: 2546 [61440/90000 (68%)]	Loss: -7.0649	Cost: 6.02s
Train Epoch: 2546 [81920/90000 (91%)]	Loss: -6.7510	Cost: 6.64s
Train Epoch: 2546 	Average Loss: -7.0102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6520

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2547 [0/90000 (0%)]	Loss: -6.6280	Cost: 23.75s
Train Epoch: 2547 [20480/90000 (23%)]	Loss: -6.4449	Cost: 6.16s
Train Epoch: 2547 [40960/90000 (45%)]	Loss: -6.4425	Cost: 7.96s
Train Epoch: 2547 [61440/90000 (68%)]	Loss: -6.9924	Cost: 5.85s
Train Epoch: 2547 [81920/90000 (91%)]	Loss: -6.7960	Cost: 6.23s
Train Epoch: 2547 	Average Loss: -7.0397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6179

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2548 [0/90000 (0%)]	Loss: -7.2545	Cost: 23.56s
Train Epoch: 2548 [20480/90000 (23%)]	Loss: -6.4590	Cost: 6.11s
Train Epoch: 2548 [40960/90000 (45%)]	Loss: -6.4190	Cost: 8.11s
Train Epoch: 2548 [61440/90000 (68%)]	Loss: -6.9729	Cost: 5.91s
Train Epoch: 2548 [81920/90000 (91%)]	Loss: -6.6718	Cost: 6.16s
Train Epoch: 2548 	Average Loss: -7.0446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7623

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2549 [0/90000 (0%)]	Loss: -6.2372	Cost: 23.18s
Train Epoch: 2549 [20480/90000 (23%)]	Loss: -6.5993	Cost: 6.10s
Train Epoch: 2549 [40960/90000 (45%)]	Loss: -6.5097	Cost: 8.06s
Train Epoch: 2549 [61440/90000 (68%)]	Loss: -6.9275	Cost: 5.83s
Train Epoch: 2549 [81920/90000 (91%)]	Loss: -6.8100	Cost: 6.14s
Train Epoch: 2549 	Average Loss: -7.0121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5833

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2550 [0/90000 (0%)]	Loss: -6.7337	Cost: 23.88s
Train Epoch: 2550 [20480/90000 (23%)]	Loss: -6.2999	Cost: 6.19s
Train Epoch: 2550 [40960/90000 (45%)]	Loss: -6.4022	Cost: 7.87s
Train Epoch: 2550 [61440/90000 (68%)]	Loss: -6.9578	Cost: 5.87s
Train Epoch: 2550 [81920/90000 (91%)]	Loss: -6.6455	Cost: 6.11s
Train Epoch: 2550 	Average Loss: -7.0400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7518

Saving model as model.pt_e2550 & waveforms_supplementary.hdf5_e2550
Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2551 [0/90000 (0%)]	Loss: -7.6182	Cost: 24.08s
Train Epoch: 2551 [20480/90000 (23%)]	Loss: -6.3560	Cost: 6.08s
Train Epoch: 2551 [40960/90000 (45%)]	Loss: -6.4507	Cost: 7.90s
Train Epoch: 2551 [61440/90000 (68%)]	Loss: -6.9735	Cost: 5.85s
Train Epoch: 2551 [81920/90000 (91%)]	Loss: -6.5343	Cost: 6.01s
Train Epoch: 2551 	Average Loss: -7.0607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8986

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2552 [0/90000 (0%)]	Loss: -6.0996	Cost: 23.91s
Train Epoch: 2552 [20480/90000 (23%)]	Loss: -6.5379	Cost: 6.09s
Train Epoch: 2552 [40960/90000 (45%)]	Loss: -6.2593	Cost: 8.07s
Train Epoch: 2552 [61440/90000 (68%)]	Loss: -7.1281	Cost: 5.86s
Train Epoch: 2552 [81920/90000 (91%)]	Loss: -6.6689	Cost: 6.15s
Train Epoch: 2552 	Average Loss: -6.9908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7973

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2553 [0/90000 (0%)]	Loss: -7.0869	Cost: 24.18s
Train Epoch: 2553 [20480/90000 (23%)]	Loss: -6.2998	Cost: 6.15s
Train Epoch: 2553 [40960/90000 (45%)]	Loss: -6.4824	Cost: 7.97s
Train Epoch: 2553 [61440/90000 (68%)]	Loss: -6.8795	Cost: 5.90s
Train Epoch: 2553 [81920/90000 (91%)]	Loss: -6.5863	Cost: 6.02s
Train Epoch: 2553 	Average Loss: -7.0558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6032

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2554 [0/90000 (0%)]	Loss: -7.5772	Cost: 23.67s
Train Epoch: 2554 [20480/90000 (23%)]	Loss: -6.4753	Cost: 6.33s
Train Epoch: 2554 [40960/90000 (45%)]	Loss: -6.4309	Cost: 8.12s
Train Epoch: 2554 [61440/90000 (68%)]	Loss: -6.9932	Cost: 5.86s
Train Epoch: 2554 [81920/90000 (91%)]	Loss: -6.6911	Cost: 5.81s
Train Epoch: 2554 	Average Loss: -7.0389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7933

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2555 [0/90000 (0%)]	Loss: -6.8068	Cost: 23.83s
Train Epoch: 2555 [20480/90000 (23%)]	Loss: -6.5083	Cost: 6.00s
Train Epoch: 2555 [40960/90000 (45%)]	Loss: -6.3844	Cost: 7.86s
Train Epoch: 2555 [61440/90000 (68%)]	Loss: -6.9795	Cost: 5.85s
Train Epoch: 2555 [81920/90000 (91%)]	Loss: -6.6795	Cost: 6.09s
Train Epoch: 2555 	Average Loss: -7.0206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7193

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2556 [0/90000 (0%)]	Loss: -7.6178	Cost: 23.69s
Train Epoch: 2556 [20480/90000 (23%)]	Loss: -6.4911	Cost: 6.25s
Train Epoch: 2556 [40960/90000 (45%)]	Loss: -6.2765	Cost: 7.95s
Train Epoch: 2556 [61440/90000 (68%)]	Loss: -7.0710	Cost: 6.61s
Train Epoch: 2556 [81920/90000 (91%)]	Loss: -6.5089	Cost: 5.75s
Train Epoch: 2556 	Average Loss: -7.0661
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7317

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2557 [0/90000 (0%)]	Loss: -7.0959	Cost: 24.04s
Train Epoch: 2557 [20480/90000 (23%)]	Loss: -6.4572	Cost: 6.26s
Train Epoch: 2557 [40960/90000 (45%)]	Loss: -6.3773	Cost: 7.32s
Train Epoch: 2557 [61440/90000 (68%)]	Loss: -7.1303	Cost: 5.94s
Train Epoch: 2557 [81920/90000 (91%)]	Loss: -6.8337	Cost: 6.29s
Train Epoch: 2557 	Average Loss: -7.0613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6823

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2558 [0/90000 (0%)]	Loss: -7.5880	Cost: 23.33s
Train Epoch: 2558 [20480/90000 (23%)]	Loss: -6.4123	Cost: 6.21s
Train Epoch: 2558 [40960/90000 (45%)]	Loss: -6.5163	Cost: 8.11s
Train Epoch: 2558 [61440/90000 (68%)]	Loss: -7.0137	Cost: 5.86s
Train Epoch: 2558 [81920/90000 (91%)]	Loss: -6.7055	Cost: 6.21s
Train Epoch: 2558 	Average Loss: -7.0343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6542

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2559 [0/90000 (0%)]	Loss: -7.3028	Cost: 23.48s
Train Epoch: 2559 [20480/90000 (23%)]	Loss: -6.4153	Cost: 6.21s
Train Epoch: 2559 [40960/90000 (45%)]	Loss: -6.3159	Cost: 8.14s
Train Epoch: 2559 [61440/90000 (68%)]	Loss: -7.0620	Cost: 6.04s
Train Epoch: 2559 [81920/90000 (91%)]	Loss: -6.8404	Cost: 5.77s
Train Epoch: 2559 	Average Loss: -7.0433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6525

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2560 [0/90000 (0%)]	Loss: -4.3426	Cost: 23.63s
Train Epoch: 2560 [20480/90000 (23%)]	Loss: -6.5634	Cost: 6.20s
Train Epoch: 2560 [40960/90000 (45%)]	Loss: -6.3731	Cost: 8.48s
Train Epoch: 2560 [61440/90000 (68%)]	Loss: -6.9768	Cost: 5.86s
Train Epoch: 2560 [81920/90000 (91%)]	Loss: -6.6145	Cost: 6.33s
Train Epoch: 2560 	Average Loss: -6.9174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6932

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2561 [0/90000 (0%)]	Loss: -3.4352	Cost: 23.61s
Train Epoch: 2561 [20480/90000 (23%)]	Loss: -6.4459	Cost: 6.12s
Train Epoch: 2561 [40960/90000 (45%)]	Loss: -6.4101	Cost: 8.05s
Train Epoch: 2561 [61440/90000 (68%)]	Loss: -7.0307	Cost: 5.81s
Train Epoch: 2561 [81920/90000 (91%)]	Loss: -6.6687	Cost: 5.98s
Train Epoch: 2561 	Average Loss: -6.8868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8154

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2562 [0/90000 (0%)]	Loss: -7.0355	Cost: 23.43s
Train Epoch: 2562 [20480/90000 (23%)]	Loss: -6.5251	Cost: 5.91s
Train Epoch: 2562 [40960/90000 (45%)]	Loss: -6.3335	Cost: 8.09s
Train Epoch: 2562 [61440/90000 (68%)]	Loss: -6.9686	Cost: 5.94s
Train Epoch: 2562 [81920/90000 (91%)]	Loss: -6.6339	Cost: 6.55s
Train Epoch: 2562 	Average Loss: -7.0506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6759

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2563 [0/90000 (0%)]	Loss: -8.0481	Cost: 23.52s
Train Epoch: 2563 [20480/90000 (23%)]	Loss: -6.5807	Cost: 6.17s
Train Epoch: 2563 [40960/90000 (45%)]	Loss: -6.4185	Cost: 7.72s
Train Epoch: 2563 [61440/90000 (68%)]	Loss: -7.0791	Cost: 5.92s
Train Epoch: 2563 [81920/90000 (91%)]	Loss: -6.7805	Cost: 6.04s
Train Epoch: 2563 	Average Loss: -7.1146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5070

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2564 [0/90000 (0%)]	Loss: -7.9648	Cost: 23.46s
Train Epoch: 2564 [20480/90000 (23%)]	Loss: -6.5880	Cost: 6.13s
Train Epoch: 2564 [40960/90000 (45%)]	Loss: -6.4061	Cost: 8.46s
Train Epoch: 2564 [61440/90000 (68%)]	Loss: -6.8685	Cost: 5.88s
Train Epoch: 2564 [81920/90000 (91%)]	Loss: -6.7087	Cost: 5.98s
Train Epoch: 2564 	Average Loss: -7.0478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5420

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2565 [0/90000 (0%)]	Loss: -6.2894	Cost: 23.85s
Train Epoch: 2565 [20480/90000 (23%)]	Loss: -6.4522	Cost: 6.17s
Train Epoch: 2565 [40960/90000 (45%)]	Loss: -6.2611	Cost: 7.33s
Train Epoch: 2565 [61440/90000 (68%)]	Loss: -7.1064	Cost: 5.90s
Train Epoch: 2565 [81920/90000 (91%)]	Loss: -6.8341	Cost: 5.98s
Train Epoch: 2565 	Average Loss: -7.0245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6850

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2566 [0/90000 (0%)]	Loss: -7.5107	Cost: 23.25s
Train Epoch: 2566 [20480/90000 (23%)]	Loss: -6.4358	Cost: 6.25s
Train Epoch: 2566 [40960/90000 (45%)]	Loss: -6.3145	Cost: 7.67s
Train Epoch: 2566 [61440/90000 (68%)]	Loss: -6.9686	Cost: 5.86s
Train Epoch: 2566 [81920/90000 (91%)]	Loss: -6.7672	Cost: 6.52s
Train Epoch: 2566 	Average Loss: -7.0720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7831

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2567 [0/90000 (0%)]	Loss: -6.6380	Cost: 23.93s
Train Epoch: 2567 [20480/90000 (23%)]	Loss: -6.4202	Cost: 6.19s
Train Epoch: 2567 [40960/90000 (45%)]	Loss: -6.5354	Cost: 7.84s
Train Epoch: 2567 [61440/90000 (68%)]	Loss: -7.0885	Cost: 5.98s
Train Epoch: 2567 [81920/90000 (91%)]	Loss: -6.6641	Cost: 5.86s
Train Epoch: 2567 	Average Loss: -7.0308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6607

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2568 [0/90000 (0%)]	Loss: -6.4859	Cost: 23.20s
Train Epoch: 2568 [20480/90000 (23%)]	Loss: -6.3645	Cost: 6.20s
Train Epoch: 2568 [40960/90000 (45%)]	Loss: -6.2453	Cost: 8.45s
Train Epoch: 2568 [61440/90000 (68%)]	Loss: -7.0709	Cost: 5.94s
Train Epoch: 2568 [81920/90000 (91%)]	Loss: -6.5489	Cost: 6.10s
Train Epoch: 2568 	Average Loss: -7.0123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5810

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2569 [0/90000 (0%)]	Loss: -6.2399	Cost: 23.51s
Train Epoch: 2569 [20480/90000 (23%)]	Loss: -6.4715	Cost: 6.12s
Train Epoch: 2569 [40960/90000 (45%)]	Loss: -6.2816	Cost: 7.76s
Train Epoch: 2569 [61440/90000 (68%)]	Loss: -7.0185	Cost: 5.87s
Train Epoch: 2569 [81920/90000 (91%)]	Loss: -6.7912	Cost: 6.02s
Train Epoch: 2569 	Average Loss: -7.0693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7654

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2570 [0/90000 (0%)]	Loss: -6.5724	Cost: 23.86s
Train Epoch: 2570 [20480/90000 (23%)]	Loss: -6.4006	Cost: 6.12s
Train Epoch: 2570 [40960/90000 (45%)]	Loss: -6.5190	Cost: 8.16s
Train Epoch: 2570 [61440/90000 (68%)]	Loss: -6.9477	Cost: 5.81s
Train Epoch: 2570 [81920/90000 (91%)]	Loss: -6.8515	Cost: 6.30s
Train Epoch: 2570 	Average Loss: -7.0288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8178

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2571 [0/90000 (0%)]	Loss: -7.3942	Cost: 23.56s
Train Epoch: 2571 [20480/90000 (23%)]	Loss: -6.5011	Cost: 6.12s
Train Epoch: 2571 [40960/90000 (45%)]	Loss: -6.4139	Cost: 7.88s
Train Epoch: 2571 [61440/90000 (68%)]	Loss: -7.1036	Cost: 5.87s
Train Epoch: 2571 [81920/90000 (91%)]	Loss: -6.7844	Cost: 6.12s
Train Epoch: 2571 	Average Loss: -7.0310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7839

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2572 [0/90000 (0%)]	Loss: -7.6918	Cost: 24.13s
Train Epoch: 2572 [20480/90000 (23%)]	Loss: -6.3860	Cost: 6.09s
Train Epoch: 2572 [40960/90000 (45%)]	Loss: -6.3168	Cost: 8.23s
Train Epoch: 2572 [61440/90000 (68%)]	Loss: -7.0491	Cost: 5.84s
Train Epoch: 2572 [81920/90000 (91%)]	Loss: -6.6730	Cost: 6.17s
Train Epoch: 2572 	Average Loss: -7.0636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7995

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2573 [0/90000 (0%)]	Loss: -7.9566	Cost: 23.09s
Train Epoch: 2573 [20480/90000 (23%)]	Loss: -6.6564	Cost: 6.04s
Train Epoch: 2573 [40960/90000 (45%)]	Loss: -6.3977	Cost: 8.11s
Train Epoch: 2573 [61440/90000 (68%)]	Loss: -6.9997	Cost: 5.87s
Train Epoch: 2573 [81920/90000 (91%)]	Loss: -6.7341	Cost: 6.02s
Train Epoch: 2573 	Average Loss: -7.0912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7579

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2574 [0/90000 (0%)]	Loss: -5.7268	Cost: 23.28s
Train Epoch: 2574 [20480/90000 (23%)]	Loss: -6.5722	Cost: 6.24s
Train Epoch: 2574 [40960/90000 (45%)]	Loss: -6.3659	Cost: 8.10s
Train Epoch: 2574 [61440/90000 (68%)]	Loss: -6.9610	Cost: 5.86s
Train Epoch: 2574 [81920/90000 (91%)]	Loss: -6.7273	Cost: 6.18s
Train Epoch: 2574 	Average Loss: -6.9742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7247

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2575 [0/90000 (0%)]	Loss: -7.0083	Cost: 23.71s
Train Epoch: 2575 [20480/90000 (23%)]	Loss: -6.6323	Cost: 6.16s
Train Epoch: 2575 [40960/90000 (45%)]	Loss: -6.4323	Cost: 8.02s
Train Epoch: 2575 [61440/90000 (68%)]	Loss: -7.0496	Cost: 5.89s
Train Epoch: 2575 [81920/90000 (91%)]	Loss: -6.7735	Cost: 6.02s
Train Epoch: 2575 	Average Loss: -7.0231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7994

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2576 [0/90000 (0%)]	Loss: -5.9326	Cost: 23.58s
Train Epoch: 2576 [20480/90000 (23%)]	Loss: -6.5426	Cost: 6.32s
Train Epoch: 2576 [40960/90000 (45%)]	Loss: -6.3509	Cost: 7.89s
Train Epoch: 2576 [61440/90000 (68%)]	Loss: -7.0614	Cost: 5.85s
Train Epoch: 2576 [81920/90000 (91%)]	Loss: -6.6562	Cost: 6.16s
Train Epoch: 2576 	Average Loss: -6.9837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6377

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2577 [0/90000 (0%)]	Loss: -7.0811	Cost: 23.23s
Train Epoch: 2577 [20480/90000 (23%)]	Loss: -6.5989	Cost: 6.27s
Train Epoch: 2577 [40960/90000 (45%)]	Loss: -6.4404	Cost: 7.68s
Train Epoch: 2577 [61440/90000 (68%)]	Loss: -6.9612	Cost: 5.93s
Train Epoch: 2577 [81920/90000 (91%)]	Loss: -6.6214	Cost: 6.09s
Train Epoch: 2577 	Average Loss: -7.0370
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6804

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2578 [0/90000 (0%)]	Loss: -3.8937	Cost: 23.86s
Train Epoch: 2578 [20480/90000 (23%)]	Loss: -6.5320	Cost: 6.10s
Train Epoch: 2578 [40960/90000 (45%)]	Loss: -6.4031	Cost: 8.28s
Train Epoch: 2578 [61440/90000 (68%)]	Loss: -7.0388	Cost: 5.86s
Train Epoch: 2578 [81920/90000 (91%)]	Loss: -6.7906	Cost: 6.18s
Train Epoch: 2578 	Average Loss: -6.9274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6926

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2579 [0/90000 (0%)]	Loss: -6.1168	Cost: 23.21s
Train Epoch: 2579 [20480/90000 (23%)]	Loss: -6.5560	Cost: 6.05s
Train Epoch: 2579 [40960/90000 (45%)]	Loss: -6.4101	Cost: 8.21s
Train Epoch: 2579 [61440/90000 (68%)]	Loss: -6.7758	Cost: 5.91s
Train Epoch: 2579 [81920/90000 (91%)]	Loss: -6.6616	Cost: 5.99s
Train Epoch: 2579 	Average Loss: -7.0505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7799

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2580 [0/90000 (0%)]	Loss: -6.0574	Cost: 23.39s
Train Epoch: 2580 [20480/90000 (23%)]	Loss: -6.4383	Cost: 6.23s
Train Epoch: 2580 [40960/90000 (45%)]	Loss: -6.3082	Cost: 8.01s
Train Epoch: 2580 [61440/90000 (68%)]	Loss: -7.1923	Cost: 5.94s
Train Epoch: 2580 [81920/90000 (91%)]	Loss: -6.6289	Cost: 6.24s
Train Epoch: 2580 	Average Loss: -6.9964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6008

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2581 [0/90000 (0%)]	Loss: -7.6627	Cost: 24.03s
Train Epoch: 2581 [20480/90000 (23%)]	Loss: -6.5504	Cost: 6.20s
Train Epoch: 2581 [40960/90000 (45%)]	Loss: -6.3118	Cost: 7.51s
Train Epoch: 2581 [61440/90000 (68%)]	Loss: -7.1291	Cost: 5.89s
Train Epoch: 2581 [81920/90000 (91%)]	Loss: -6.7533	Cost: 6.23s
Train Epoch: 2581 	Average Loss: -7.0924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8725

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2582 [0/90000 (0%)]	Loss: -4.8387	Cost: 23.66s
Train Epoch: 2582 [20480/90000 (23%)]	Loss: -6.4746	Cost: 6.25s
Train Epoch: 2582 [40960/90000 (45%)]	Loss: -6.2647	Cost: 7.83s
Train Epoch: 2582 [61440/90000 (68%)]	Loss: -7.0863	Cost: 5.92s
Train Epoch: 2582 [81920/90000 (91%)]	Loss: -6.6403	Cost: 6.16s
Train Epoch: 2582 	Average Loss: -6.9931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6255

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2583 [0/90000 (0%)]	Loss: -5.7612	Cost: 23.93s
Train Epoch: 2583 [20480/90000 (23%)]	Loss: -6.3478	Cost: 6.18s
Train Epoch: 2583 [40960/90000 (45%)]	Loss: -6.3285	Cost: 7.79s
Train Epoch: 2583 [61440/90000 (68%)]	Loss: -7.0587	Cost: 5.97s
Train Epoch: 2583 [81920/90000 (91%)]	Loss: -6.6239	Cost: 5.91s
Train Epoch: 2583 	Average Loss: -7.0181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8288

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2584 [0/90000 (0%)]	Loss: -8.6885	Cost: 23.50s
Train Epoch: 2584 [20480/90000 (23%)]	Loss: -6.4370	Cost: 6.06s
Train Epoch: 2584 [40960/90000 (45%)]	Loss: -6.2464	Cost: 8.34s
Train Epoch: 2584 [61440/90000 (68%)]	Loss: -6.9649	Cost: 5.85s
Train Epoch: 2584 [81920/90000 (91%)]	Loss: -6.7921	Cost: 6.26s
Train Epoch: 2584 	Average Loss: -7.0697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7372

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2585 [0/90000 (0%)]	Loss: -6.8992	Cost: 23.56s
Train Epoch: 2585 [20480/90000 (23%)]	Loss: -6.4090	Cost: 6.17s
Train Epoch: 2585 [40960/90000 (45%)]	Loss: -6.2659	Cost: 8.05s
Train Epoch: 2585 [61440/90000 (68%)]	Loss: -6.8976	Cost: 5.92s
Train Epoch: 2585 [81920/90000 (91%)]	Loss: -6.6808	Cost: 6.12s
Train Epoch: 2585 	Average Loss: -7.0104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5782

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2586 [0/90000 (0%)]	Loss: -7.1214	Cost: 24.33s
Train Epoch: 2586 [20480/90000 (23%)]	Loss: -6.5179	Cost: 6.09s
Train Epoch: 2586 [40960/90000 (45%)]	Loss: -6.3209	Cost: 8.10s
Train Epoch: 2586 [61440/90000 (68%)]	Loss: -6.8850	Cost: 5.86s
Train Epoch: 2586 [81920/90000 (91%)]	Loss: -6.7413	Cost: 6.11s
Train Epoch: 2586 	Average Loss: -7.0670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8235

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2587 [0/90000 (0%)]	Loss: -6.2540	Cost: 23.28s
Train Epoch: 2587 [20480/90000 (23%)]	Loss: -6.4235	Cost: 6.09s
Train Epoch: 2587 [40960/90000 (45%)]	Loss: -6.3396	Cost: 7.70s
Train Epoch: 2587 [61440/90000 (68%)]	Loss: -6.9879	Cost: 5.87s
Train Epoch: 2587 [81920/90000 (91%)]	Loss: -6.7618	Cost: 6.24s
Train Epoch: 2587 	Average Loss: -7.0300
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7971

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2588 [0/90000 (0%)]	Loss: -6.4421	Cost: 24.50s
Train Epoch: 2588 [20480/90000 (23%)]	Loss: -6.3814	Cost: 6.10s
Train Epoch: 2588 [40960/90000 (45%)]	Loss: -6.2869	Cost: 7.84s
Train Epoch: 2588 [61440/90000 (68%)]	Loss: -6.9738	Cost: 5.87s
Train Epoch: 2588 [81920/90000 (91%)]	Loss: -6.7150	Cost: 6.16s
Train Epoch: 2588 	Average Loss: -7.0440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6938

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2589 [0/90000 (0%)]	Loss: -6.6294	Cost: 23.72s
Train Epoch: 2589 [20480/90000 (23%)]	Loss: -6.4823	Cost: 6.15s
Train Epoch: 2589 [40960/90000 (45%)]	Loss: -6.3753	Cost: 7.92s
Train Epoch: 2589 [61440/90000 (68%)]	Loss: -6.9776	Cost: 5.91s
Train Epoch: 2589 [81920/90000 (91%)]	Loss: -6.6363	Cost: 6.30s
Train Epoch: 2589 	Average Loss: -7.0163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6360

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2590 [0/90000 (0%)]	Loss: -5.9792	Cost: 23.26s
Train Epoch: 2590 [20480/90000 (23%)]	Loss: -6.5251	Cost: 6.18s
Train Epoch: 2590 [40960/90000 (45%)]	Loss: -6.3728	Cost: 8.17s
Train Epoch: 2590 [61440/90000 (68%)]	Loss: -6.9746	Cost: 5.89s
Train Epoch: 2590 [81920/90000 (91%)]	Loss: -6.6678	Cost: 6.36s
Train Epoch: 2590 	Average Loss: -7.0543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7992

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2591 [0/90000 (0%)]	Loss: -4.2155	Cost: 23.17s
Train Epoch: 2591 [20480/90000 (23%)]	Loss: -6.4975	Cost: 6.02s
Train Epoch: 2591 [40960/90000 (45%)]	Loss: -6.4087	Cost: 8.20s
Train Epoch: 2591 [61440/90000 (68%)]	Loss: -7.0961	Cost: 6.43s
Train Epoch: 2591 [81920/90000 (91%)]	Loss: -6.8170	Cost: 5.76s
Train Epoch: 2591 	Average Loss: -6.9637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6520

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2592 [0/90000 (0%)]	Loss: -8.4037	Cost: 23.63s
Train Epoch: 2592 [20480/90000 (23%)]	Loss: -6.3317	Cost: 6.13s
Train Epoch: 2592 [40960/90000 (45%)]	Loss: -6.3013	Cost: 8.14s
Train Epoch: 2592 [61440/90000 (68%)]	Loss: -6.9813	Cost: 5.92s
Train Epoch: 2592 [81920/90000 (91%)]	Loss: -6.6245	Cost: 6.31s
Train Epoch: 2592 	Average Loss: -7.0604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8023

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2593 [0/90000 (0%)]	Loss: -7.9144	Cost: 23.34s
Train Epoch: 2593 [20480/90000 (23%)]	Loss: -6.5678	Cost: 6.17s
Train Epoch: 2593 [40960/90000 (45%)]	Loss: -6.3483	Cost: 8.00s
Train Epoch: 2593 [61440/90000 (68%)]	Loss: -6.8911	Cost: 5.91s
Train Epoch: 2593 [81920/90000 (91%)]	Loss: -6.6530	Cost: 6.24s
Train Epoch: 2593 	Average Loss: -7.0218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7068

Learning rate: 0.0
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2594 [0/90000 (0%)]	Loss: -7.5435	Cost: 23.92s
Train Epoch: 2594 [20480/90000 (23%)]	Loss: -6.5274	Cost: 6.15s
Train Epoch: 2594 [40960/90000 (45%)]	Loss: -6.4507	Cost: 8.11s
Train Epoch: 2594 [61440/90000 (68%)]	Loss: -6.9361	Cost: 5.85s

Stopping timer.
Training time (including validation): 42614.139534235 seconds
Saving model
Program complete
