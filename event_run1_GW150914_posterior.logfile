Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=100000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.0, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_posterior_prior/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 100000 epochs
Starting timer
Learning rate: 0.0002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.8864	Cost: 44.90s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.7574	Cost: 9.37s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 20.8475	Cost: 11.69s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 20.4221	Cost: 7.27s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.1173	Cost: 7.74s
Train Epoch: 1 	Average Loss: 21.2663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9755

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999995065198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 19.8993	Cost: 27.07s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 19.7387	Cost: 7.17s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.3698	Cost: 12.51s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 18.8633	Cost: 6.25s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 18.5843	Cost: 6.42s
Train Epoch: 2 	Average Loss: 19.2490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5123

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.0001999999998026079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 18.3734	Cost: 32.91s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 18.2822	Cost: 7.46s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.0309	Cost: 12.30s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 17.8489	Cost: 11.99s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 17.5229	Cost: 9.52s
Train Epoch: 3 	Average Loss: 17.9578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8726

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.0001999999995558678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 17.3527	Cost: 32.46s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 17.2241	Cost: 12.09s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 17.0477	Cost: 12.11s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 16.9388	Cost: 12.08s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 16.8044	Cost: 12.30s
Train Epoch: 4 	Average Loss: 17.0781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8932

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019999999921043165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 16.7212	Cost: 52.22s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 16.5241	Cost: 11.26s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 16.4218	Cost: 12.61s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 16.2876	Cost: 12.41s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 16.1067	Cost: 12.18s
Train Epoch: 5 	Average Loss: 16.3878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1509

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019999999876629945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 15.8801	Cost: 45.14s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 15.9287	Cost: 13.28s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 15.9242	Cost: 16.30s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 15.7826	Cost: 11.44s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 15.6370	Cost: 11.95s
Train Epoch: 6 	Average Loss: 15.8390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8450

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019999999822347122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 15.6145	Cost: 63.03s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 15.4995	Cost: 13.20s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 15.3482	Cost: 12.89s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 15.2605	Cost: 11.99s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 15.3782	Cost: 11.96s
Train Epoch: 7 	Average Loss: 15.4008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3492

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019999999758194695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 15.4313	Cost: 54.10s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 15.0034	Cost: 12.37s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 15.0305	Cost: 12.31s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 15.0155	Cost: 11.69s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 14.9118	Cost: 11.63s
Train Epoch: 8 	Average Loss: 15.0376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9997

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019999999684172664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 14.9279	Cost: 39.07s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 14.8732	Cost: 13.40s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 14.8001	Cost: 12.21s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 14.5887	Cost: 11.85s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 14.7891	Cost: 10.44s
Train Epoch: 9 	Average Loss: 14.7347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5171

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019999999600281025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 14.4291	Cost: 30.05s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 14.4359	Cost: 8.36s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 14.2780	Cost: 12.61s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 14.2715	Cost: 12.05s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 14.1375	Cost: 10.81s
Train Epoch: 10 	Average Loss: 14.3877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1368

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 14.1700	Cost: 29.55s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 14.2843	Cost: 12.80s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 14.1703	Cost: 14.81s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 14.0133	Cost: 12.53s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 13.9358	Cost: 12.30s
Train Epoch: 11 	Average Loss: 14.0639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8536

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019999999402888941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 13.7798	Cost: 34.05s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 13.9095	Cost: 6.98s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 14.0029	Cost: 13.08s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 13.8354	Cost: 14.27s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 13.7411	Cost: 13.43s
Train Epoch: 12 	Average Loss: 13.8201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6857

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019999999289388494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 13.7704	Cost: 32.34s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 13.9031	Cost: 11.82s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 13.7530	Cost: 12.14s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 13.3868	Cost: 12.90s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 13.3481	Cost: 14.97s
Train Epoch: 13 	Average Loss: 13.5987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4855

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.0001999999916601844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 13.2826	Cost: 29.64s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 13.6073	Cost: 12.97s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 13.3759	Cost: 12.41s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 13.2845	Cost: 12.12s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 13.2160	Cost: 12.32s
Train Epoch: 14 	Average Loss: 13.3559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3285

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.00019999999032778784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 13.2774	Cost: 27.66s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 13.1410	Cost: 12.50s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 13.0846	Cost: 17.15s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 13.1212	Cost: 14.00s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 13.1302	Cost: 11.72s
Train Epoch: 15 	Average Loss: 13.1586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0566

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019999998889669524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 13.0613	Cost: 36.12s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 12.9043	Cost: 8.85s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 12.9677	Cost: 19.34s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 12.8648	Cost: 13.52s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 12.8069	Cost: 14.30s
Train Epoch: 16 	Average Loss: 12.9342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9378

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001999999873669066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 12.8912	Cost: 62.95s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 12.7529	Cost: 11.30s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 12.8490	Cost: 12.47s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 12.8507	Cost: 11.94s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 12.8395	Cost: 7.65s
Train Epoch: 17 	Average Loss: 12.7678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8788

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019999998573842195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 12.8092	Cost: 61.31s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 12.7929	Cost: 8.61s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 12.5091	Cost: 12.24s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 12.5394	Cost: 12.07s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 12.5260	Cost: 10.12s
Train Epoch: 18 	Average Loss: 12.6559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7755

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.00019999998401124124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 12.7245	Cost: 62.95s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 12.4601	Cost: 8.33s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 12.6497	Cost: 12.11s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 12.3195	Cost: 12.12s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 12.3465	Cost: 12.09s
Train Epoch: 19 	Average Loss: 12.5063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4002

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019999998218536453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 12.2977	Cost: 47.17s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 12.2839	Cost: 8.72s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 12.4655	Cost: 12.31s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 12.2929	Cost: 12.16s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 12.1895	Cost: 12.04s
Train Epoch: 20 	Average Loss: 12.3277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2974

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019999998026079178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 12.2420	Cost: 35.16s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 12.0932	Cost: 12.13s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 12.2931	Cost: 12.25s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 12.1628	Cost: 12.43s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 12.0996	Cost: 13.07s
Train Epoch: 21 	Average Loss: 12.2229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1751

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.000199999978237523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 12.0722	Cost: 52.81s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 12.1960	Cost: 9.08s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 11.8935	Cost: 12.59s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 12.1074	Cost: 12.21s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 11.9925	Cost: 11.39s
Train Epoch: 22 	Average Loss: 12.0766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0605

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.00019999997611555822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 12.0814	Cost: 66.00s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 12.0237	Cost: 13.59s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 12.2310	Cost: 12.21s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 12.1992	Cost: 11.99s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 12.0477	Cost: 9.49s
Train Epoch: 23 	Average Loss: 12.0328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0200

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.00019999997389489742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 11.9663	Cost: 64.12s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 12.0603	Cost: 12.22s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 11.9220	Cost: 12.01s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 11.7364	Cost: 12.04s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 11.8668	Cost: 10.04s
Train Epoch: 24 	Average Loss: 11.8709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7251

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.00019999997157554058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 11.8135	Cost: 49.05s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 11.8639	Cost: 8.29s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 11.8235	Cost: 12.48s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 11.6495	Cost: 12.09s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 11.6871	Cost: 10.11s
Train Epoch: 25 	Average Loss: 11.7523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7817

Learning rate: 0.00019999996915748774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 11.4975	Cost: 32.73s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 11.6827	Cost: 11.24s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 11.6169	Cost: 12.03s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 11.5494	Cost: 12.34s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 11.6195	Cost: 10.60s
Train Epoch: 26 	Average Loss: 11.6353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5335

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019999996664073888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 11.6155	Cost: 39.94s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 11.5514	Cost: 13.45s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 11.4425	Cost: 14.10s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 11.4203	Cost: 12.58s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 11.4085	Cost: 9.51s
Train Epoch: 27 	Average Loss: 11.4994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4779

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019999996402529402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 11.4063	Cost: 54.54s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 11.5147	Cost: 10.41s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 11.7058	Cost: 14.21s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 11.3794	Cost: 12.13s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 11.4418	Cost: 6.39s
Train Epoch: 28 	Average Loss: 11.4488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3416

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019999996131115315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 11.2627	Cost: 63.81s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 11.5073	Cost: 9.40s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 11.3564	Cost: 11.22s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 11.2031	Cost: 12.00s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 11.5675	Cost: 11.76s
Train Epoch: 29 	Average Loss: 11.3643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3010

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.00019999995849831625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 11.3254	Cost: 54.87s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 11.3940	Cost: 12.32s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 11.2398	Cost: 12.08s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 11.2291	Cost: 12.20s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 11.1309	Cost: 11.88s
Train Epoch: 30 	Average Loss: 11.2493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1253

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.00019999995558678336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 11.2592	Cost: 30.58s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 11.2232	Cost: 12.32s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 11.1386	Cost: 12.81s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 11.1882	Cost: 11.91s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 11.1462	Cost: 11.86s
Train Epoch: 31 	Average Loss: 11.1460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3051

Learning rate: 0.0001999999525765545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 11.1283	Cost: 26.67s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 11.0152	Cost: 12.76s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 11.0625	Cost: 12.38s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 10.9485	Cost: 12.01s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 10.9996	Cost: 11.75s
Train Epoch: 32 	Average Loss: 11.0486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9625

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.0001999999494676296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 10.9988	Cost: 33.98s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 11.0340	Cost: 12.31s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 11.1724	Cost: 12.38s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 10.8019	Cost: 11.91s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 11.0139	Cost: 11.93s
Train Epoch: 33 	Average Loss: 11.0213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0493

Learning rate: 0.00019999994626000874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 10.9324	Cost: 29.24s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 10.9052	Cost: 8.14s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 10.9658	Cost: 12.39s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 10.8893	Cost: 12.18s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 11.0044	Cost: 11.87s
Train Epoch: 34 	Average Loss: 10.9183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8635

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019999994295369188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 10.8088	Cost: 27.52s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 10.8293	Cost: 7.26s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 11.0051	Cost: 12.33s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 10.7902	Cost: 12.09s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 10.7418	Cost: 12.06s
Train Epoch: 35 	Average Loss: 10.8618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8418

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.000199999939548679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 10.7830	Cost: 32.79s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 10.6834	Cost: 6.81s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 10.7933	Cost: 13.13s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 10.6125	Cost: 12.36s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 10.8309	Cost: 12.40s
Train Epoch: 36 	Average Loss: 10.7503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6365

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.00019999993604497015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 10.7173	Cost: 29.38s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 10.8763	Cost: 12.05s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 10.7539	Cost: 12.57s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 10.4554	Cost: 12.79s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 10.6781	Cost: 12.43s
Train Epoch: 37 	Average Loss: 10.6792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7220

Learning rate: 0.00019999993244256535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 10.7859	Cost: 27.94s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 10.5628	Cost: 11.81s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 10.7104	Cost: 15.48s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 10.5667	Cost: 12.93s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 10.4945	Cost: 15.64s
Train Epoch: 38 	Average Loss: 10.6350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6346

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.00019999992874146456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 10.5944	Cost: 31.47s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 10.7356	Cost: 12.14s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 10.6608	Cost: 13.73s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 10.5469	Cost: 13.30s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 10.4714	Cost: 12.20s
Train Epoch: 39 	Average Loss: 10.5557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4248

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.0001999999249416678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 10.4680	Cost: 44.11s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 10.5291	Cost: 13.90s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 10.4162	Cost: 17.35s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 10.5195	Cost: 13.12s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 10.4039	Cost: 12.14s
Train Epoch: 40 	Average Loss: 10.4419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4676

Learning rate: 0.00019999992104317507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 10.3372	Cost: 70.36s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 10.3364	Cost: 13.85s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 10.4642	Cost: 12.85s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 10.3246	Cost: 11.93s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 10.3356	Cost: 11.84s
Train Epoch: 41 	Average Loss: 10.3977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3848

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019999991704598637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 10.3204	Cost: 64.66s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 10.2877	Cost: 14.76s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 10.5184	Cost: 12.41s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 10.4068	Cost: 11.91s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 10.2775	Cost: 12.05s
Train Epoch: 42 	Average Loss: 10.3340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2637

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.00019999991295010171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 10.1932	Cost: 65.06s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 10.2164	Cost: 13.84s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 10.3825	Cost: 11.96s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 10.2336	Cost: 11.93s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 10.4103	Cost: 12.03s
Train Epoch: 43 	Average Loss: 10.2830
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2938

Learning rate: 0.00019999990875552108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 10.4369	Cost: 62.86s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 10.2672	Cost: 13.14s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 10.2337	Cost: 12.28s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 10.3335	Cost: 11.92s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 10.3111	Cost: 11.96s
Train Epoch: 44 	Average Loss: 10.2658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2430

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 0.00019999990446224451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 10.2936	Cost: 46.73s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 10.2180	Cost: 11.94s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 10.2602	Cost: 11.92s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 10.1318	Cost: 12.09s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 10.1775	Cost: 12.23s
Train Epoch: 45 	Average Loss: 10.2049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2121

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.000199999900070272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 10.1835	Cost: 31.10s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 10.1568	Cost: 11.07s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 10.1998	Cost: 12.25s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 10.0183	Cost: 12.63s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 10.2369	Cost: 10.42s
Train Epoch: 46 	Average Loss: 10.1350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2698

Learning rate: 0.00019999989557960353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 10.1611	Cost: 29.92s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 10.1434	Cost: 9.86s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 10.1348	Cost: 13.62s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 10.0451	Cost: 12.95s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 10.1113	Cost: 10.96s
Train Epoch: 47 	Average Loss: 10.0677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3381

Learning rate: 0.0001999998909902391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 10.2552	Cost: 27.28s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 10.2063	Cost: 12.20s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 10.1895	Cost: 13.57s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 9.9857	Cost: 14.46s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 10.0759	Cost: 15.21s
Train Epoch: 48 	Average Loss: 10.0903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1190

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 0.00019999988630217875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 10.2246	Cost: 30.26s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 10.0745	Cost: 12.61s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 10.1067	Cost: 14.53s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 9.9880	Cost: 15.04s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 9.9854	Cost: 14.68s
Train Epoch: 49 	Average Loss: 10.0197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9330

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019999988151542247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 9.8232	Cost: 32.86s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 9.9611	Cost: 13.53s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 9.9953	Cost: 14.44s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 9.8844	Cost: 14.40s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 9.8497	Cost: 12.98s
Train Epoch: 50 	Average Loss: 9.9267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9216

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 0.00019999987662997027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 9.9612	Cost: 45.03s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 9.9540	Cost: 14.13s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 9.9011	Cost: 13.04s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 9.8752	Cost: 11.38s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 9.9044	Cost: 6.48s
Train Epoch: 51 	Average Loss: 9.9314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9278

Learning rate: 0.00019999987164582216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 9.8945	Cost: 30.49s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 9.7936	Cost: 13.08s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 9.8969	Cost: 12.80s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 9.8386	Cost: 12.83s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 9.9289	Cost: 12.11s
Train Epoch: 52 	Average Loss: 9.8601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8444

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 0.0001999998665629781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 9.7584	Cost: 30.68s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 9.8340	Cost: 14.53s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 9.8023	Cost: 14.54s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 9.7089	Cost: 12.18s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 9.7618	Cost: 12.94s
Train Epoch: 53 	Average Loss: 9.8037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7892

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 0.00019999986138143815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 9.8993	Cost: 35.65s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 9.9906	Cost: 13.54s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 9.8513	Cost: 15.47s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 9.7559	Cost: 15.38s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 9.7736	Cost: 15.26s
Train Epoch: 54 	Average Loss: 9.8454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8943

Learning rate: 0.00019999985610120227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 9.7946	Cost: 35.41s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 9.6079	Cost: 13.14s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 9.9546	Cost: 14.07s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 9.7020	Cost: 15.49s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 9.7603	Cost: 14.05s
Train Epoch: 55 	Average Loss: 9.7517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7343

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.0001999998507222705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 9.7689	Cost: 28.82s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 9.6853	Cost: 12.72s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 9.7385	Cost: 16.17s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 9.7290	Cost: 12.32s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 9.7246	Cost: 10.27s
Train Epoch: 56 	Average Loss: 9.6951
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7124

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019999984524464283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 9.7146	Cost: 27.09s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 9.6453	Cost: 12.54s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 9.7646	Cost: 14.38s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 9.6395	Cost: 12.75s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 9.7366	Cost: 11.00s
Train Epoch: 57 	Average Loss: 9.6809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7539

Learning rate: 0.0001999998396683193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 9.7366	Cost: 32.76s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 9.7315	Cost: 11.88s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 9.7054	Cost: 12.18s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 9.5327	Cost: 12.98s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 9.6621	Cost: 12.83s
Train Epoch: 58 	Average Loss: 9.6677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7235

Learning rate: 0.00019999983399329984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 9.6500	Cost: 45.15s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 9.7587	Cost: 10.11s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 9.5894	Cost: 11.74s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 9.6003	Cost: 12.39s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 9.7191	Cost: 11.60s
Train Epoch: 59 	Average Loss: 9.6355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5575

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00019999982821958452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 9.5592	Cost: 34.23s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 9.5109	Cost: 11.69s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 9.5656	Cost: 12.18s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 9.6413	Cost: 12.30s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 9.4200	Cost: 11.16s
Train Epoch: 60 	Average Loss: 9.5670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6646

Learning rate: 0.00019999982234717332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 9.5934	Cost: 30.43s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 9.6536	Cost: 12.18s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 9.6832	Cost: 12.31s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 9.6015	Cost: 12.88s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 9.5757	Cost: 13.77s
Train Epoch: 61 	Average Loss: 9.5793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5804

Learning rate: 0.00019999981637606627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 9.6643	Cost: 28.65s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 9.4865	Cost: 11.11s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 9.5831	Cost: 15.24s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 9.4879	Cost: 15.27s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 9.6195	Cost: 17.29s
Train Epoch: 62 	Average Loss: 9.5347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5682

Learning rate: 0.00019999981030626333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 9.6327	Cost: 27.80s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 9.4364	Cost: 9.11s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 9.5812	Cost: 16.69s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 9.5169	Cost: 13.91s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 9.4051	Cost: 15.38s
Train Epoch: 63 	Average Loss: 9.4995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6435

Learning rate: 0.00019999980413776456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 9.4765	Cost: 28.97s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 9.7373	Cost: 10.25s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 9.6631	Cost: 17.50s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 9.3790	Cost: 14.59s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 9.5090	Cost: 18.99s
Train Epoch: 64 	Average Loss: 9.4882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4466

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00019999979787056995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 9.4681	Cost: 26.82s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 9.5034	Cost: 12.86s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 9.4499	Cost: 18.54s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 9.4672	Cost: 15.21s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 9.4145	Cost: 17.59s
Train Epoch: 65 	Average Loss: 9.4269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4657

Learning rate: 0.00019999979150467947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 9.5822	Cost: 27.88s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 9.5748	Cost: 9.75s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 9.5898	Cost: 15.23s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 9.3932	Cost: 14.47s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 9.5161	Cost: 16.59s
Train Epoch: 66 	Average Loss: 9.4469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4176

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.00019999978504009312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 9.4527	Cost: 31.58s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 9.3939	Cost: 13.09s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 9.4869	Cost: 14.56s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 9.3512	Cost: 15.20s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 9.3873	Cost: 15.15s
Train Epoch: 67 	Average Loss: 9.3940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4165

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Learning rate: 0.00019999977847681098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 9.3420	Cost: 29.39s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 9.2713	Cost: 13.25s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 9.4785	Cost: 13.98s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 9.3540	Cost: 13.72s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 9.4113	Cost: 14.37s
Train Epoch: 68 	Average Loss: 9.3664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4024

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 0.00019999977181483299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 9.2740	Cost: 32.50s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 9.3996	Cost: 15.55s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 9.5096	Cost: 14.84s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 9.3508	Cost: 14.54s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 9.2901	Cost: 10.15s
Train Epoch: 69 	Average Loss: 9.3428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4910

Learning rate: 0.0001999997650541592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 9.4290	Cost: 31.35s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 9.2424	Cost: 15.91s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 9.5013	Cost: 22.43s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 9.2465	Cost: 13.92s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 9.3105	Cost: 15.82s
Train Epoch: 70 	Average Loss: 9.2967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2592

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Learning rate: 0.0001999997581947896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 9.3096	Cost: 32.45s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 9.1176	Cost: 11.84s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 9.3181	Cost: 22.11s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 9.0739	Cost: 13.07s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 9.3103	Cost: 15.01s
Train Epoch: 71 	Average Loss: 9.2672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3481

Learning rate: 0.0001999997512367242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 9.2471	Cost: 29.66s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 9.2066	Cost: 13.60s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 9.2407	Cost: 17.20s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 9.1611	Cost: 14.92s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 9.2276	Cost: 13.69s
Train Epoch: 72 	Average Loss: 9.2267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2192

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 0.000199999744179963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 9.3742	Cost: 35.92s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 9.3342	Cost: 11.11s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 9.4183	Cost: 13.60s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 9.2608	Cost: 14.22s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 9.2301	Cost: 13.70s
Train Epoch: 73 	Average Loss: 9.2809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3826

Learning rate: 0.000199999737024506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 9.1754	Cost: 31.82s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 9.3022	Cost: 11.80s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 9.3280	Cost: 12.39s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 9.2344	Cost: 14.76s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 9.1513	Cost: 15.86s
Train Epoch: 74 	Average Loss: 9.2205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2787

Learning rate: 0.00019999972977035322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 9.3576	Cost: 31.31s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 9.1795	Cost: 12.98s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 9.1899	Cost: 14.64s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 9.1310	Cost: 12.48s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 9.1119	Cost: 11.65s
Train Epoch: 75 	Average Loss: 9.1901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3564

Learning rate: 0.00019999972241750466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 9.2949	Cost: 30.20s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 9.1804	Cost: 11.09s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 9.2212	Cost: 14.60s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 9.0857	Cost: 13.90s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 9.0479	Cost: 14.69s
Train Epoch: 76 	Average Loss: 9.1453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1816

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.0001999997149659603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 9.1334	Cost: 33.88s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 9.0451	Cost: 14.97s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 9.2824	Cost: 13.96s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 9.2281	Cost: 13.31s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 9.1386	Cost: 10.52s
Train Epoch: 77 	Average Loss: 9.1049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0666

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Learning rate: 0.0001999997074157202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 9.0060	Cost: 27.49s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 9.0842	Cost: 13.66s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 9.2355	Cost: 15.21s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 9.0185	Cost: 13.42s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 9.0273	Cost: 11.97s
Train Epoch: 78 	Average Loss: 9.0893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1699

Learning rate: 0.00019999969976678433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 9.1954	Cost: 31.50s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 9.0177	Cost: 11.25s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 9.1305	Cost: 12.39s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 9.0246	Cost: 12.99s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 9.0084	Cost: 12.39s
Train Epoch: 79 	Average Loss: 9.0723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0886

Learning rate: 0.00019999969201915272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 9.1261	Cost: 35.27s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 9.1072	Cost: 6.20s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 9.0979	Cost: 12.35s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 9.0730	Cost: 12.15s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 8.9572	Cost: 11.96s
Train Epoch: 80 	Average Loss: 9.0734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1698

Learning rate: 0.00019999968417282538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 9.2280	Cost: 31.42s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 9.0720	Cost: 12.02s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 9.1339	Cost: 12.46s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 8.9517	Cost: 12.65s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 8.8714	Cost: 12.48s
Train Epoch: 81 	Average Loss: 9.0425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1857

Learning rate: 0.0001999996762278023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 9.0711	Cost: 27.92s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 9.0580	Cost: 12.11s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 9.1219	Cost: 14.31s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 8.9289	Cost: 14.27s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 9.0017	Cost: 15.03s
Train Epoch: 82 	Average Loss: 9.0002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2769

Learning rate: 0.0001999996681840835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 9.0679	Cost: 29.14s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 8.9696	Cost: 10.62s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 9.1010	Cost: 14.31s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 8.9187	Cost: 15.45s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 9.0694	Cost: 18.72s
Train Epoch: 83 	Average Loss: 9.0055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1060

Learning rate: 0.00019999966004166902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 9.1092	Cost: 29.93s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 8.9013	Cost: 12.10s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 9.0253	Cost: 16.61s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 8.9797	Cost: 13.88s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 8.9442	Cost: 16.57s
Train Epoch: 84 	Average Loss: 8.9640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0025

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 0.0001999996518005588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 9.0867	Cost: 34.75s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 8.9999	Cost: 13.30s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 8.9860	Cost: 13.39s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 8.9167	Cost: 15.69s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 8.8875	Cost: 13.37s
Train Epoch: 85 	Average Loss: 8.9762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0694

Learning rate: 0.00019999964346075288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 9.0899	Cost: 27.80s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 8.9094	Cost: 14.12s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 8.9894	Cost: 14.97s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 8.7944	Cost: 14.82s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 8.8450	Cost: 14.22s
Train Epoch: 86 	Average Loss: 8.9114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8719

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 0.00019999963502225128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 8.9445	Cost: 33.40s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 8.9491	Cost: 14.12s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 9.0761	Cost: 13.32s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 8.8503	Cost: 15.30s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 8.8237	Cost: 14.67s
Train Epoch: 87 	Average Loss: 8.9162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0170

Learning rate: 0.00019999962648505396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 8.9537	Cost: 29.61s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 8.8304	Cost: 11.98s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 8.9612	Cost: 14.37s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 8.7330	Cost: 14.68s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 8.8652	Cost: 14.68s
Train Epoch: 88 	Average Loss: 8.8598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0249

Learning rate: 0.000199999617849161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 8.9235	Cost: 27.96s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 8.7900	Cost: 10.03s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 8.7635	Cost: 15.74s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 8.7937	Cost: 13.51s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 8.8096	Cost: 14.18s
Train Epoch: 89 	Average Loss: 8.8426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9077

Learning rate: 0.00019999960911457236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 8.9021	Cost: 29.54s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 8.8281	Cost: 11.24s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 8.8387	Cost: 16.77s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 8.7174	Cost: 13.41s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 8.7500	Cost: 14.88s
Train Epoch: 90 	Average Loss: 8.8361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8477

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 0.00019999960028128805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 8.8325	Cost: 39.66s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 8.7652	Cost: 13.76s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 8.9343	Cost: 20.79s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 8.7465	Cost: 13.33s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 8.9012	Cost: 11.29s
Train Epoch: 91 	Average Loss: 8.7932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9366

Learning rate: 0.00019999959134930808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 8.9015	Cost: 29.97s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 8.7271	Cost: 14.44s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 8.7768	Cost: 16.51s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 8.7680	Cost: 14.01s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 8.7348	Cost: 14.22s
Train Epoch: 92 	Average Loss: 8.7727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8597

Learning rate: 0.0001999995823186325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 8.8919	Cost: 29.31s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 8.8007	Cost: 9.67s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 8.9433	Cost: 13.49s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 8.7512	Cost: 15.21s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 8.7263	Cost: 15.79s
Train Epoch: 93 	Average Loss: 8.7643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8928

Learning rate: 0.00019999957318926127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 8.9348	Cost: 29.11s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 8.7952	Cost: 11.19s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 8.8031	Cost: 14.35s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 8.6785	Cost: 13.18s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 8.6882	Cost: 12.33s
Train Epoch: 94 	Average Loss: 8.7523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8658

Learning rate: 0.00019999956396119442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 8.8513	Cost: 26.86s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 8.7234	Cost: 10.16s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 8.7460	Cost: 14.93s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 8.6053	Cost: 14.26s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 8.6177	Cost: 12.34s
Train Epoch: 95 	Average Loss: 8.7119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8241

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00019999955463443194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 8.8197	Cost: 29.40s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 8.7197	Cost: 7.05s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 8.6909	Cost: 16.75s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 8.5867	Cost: 13.98s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 8.7546	Cost: 14.17s
Train Epoch: 96 	Average Loss: 8.6733
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7936

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Learning rate: 0.00019999954520897388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 8.8616	Cost: 28.78s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 8.7150	Cost: 11.59s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 8.6988	Cost: 15.11s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 8.6529	Cost: 15.04s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 8.6563	Cost: 15.75s
Train Epoch: 97 	Average Loss: 8.6659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8134

Learning rate: 0.00019999953568482025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 8.8697	Cost: 32.51s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 8.6444	Cost: 14.16s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 8.7063	Cost: 14.97s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 8.5993	Cost: 12.82s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 8.7493	Cost: 16.26s
Train Epoch: 98 	Average Loss: 8.6477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9211

Learning rate: 0.000199999526061971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 8.7633	Cost: 33.61s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 8.6804	Cost: 14.74s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 8.6008	Cost: 16.50s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 8.5550	Cost: 14.72s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 8.5997	Cost: 15.72s
Train Epoch: 99 	Average Loss: 8.6054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6912

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Learning rate: 0.00019999951634042617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 8.8223	Cost: 31.08s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 8.7315	Cost: 16.55s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 8.6910	Cost: 15.98s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 8.5495	Cost: 15.35s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 8.4518	Cost: 18.62s
Train Epoch: 100 	Average Loss: 8.5920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7034

Learning rate: 0.00019999950652018581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 8.7620	Cost: 30.06s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 8.5165	Cost: 13.84s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 8.6454	Cost: 15.60s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 8.6739	Cost: 15.27s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 8.5548	Cost: 15.37s
Train Epoch: 101 	Average Loss: 8.5844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7043

Learning rate: 0.00019999949660124986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 8.6609	Cost: 33.47s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 8.4860	Cost: 14.84s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 8.7116	Cost: 18.02s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 8.4811	Cost: 14.10s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 8.4989	Cost: 17.87s
Train Epoch: 102 	Average Loss: 8.5686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6302

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00019999948658361836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 8.8016	Cost: 30.90s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 8.4865	Cost: 15.64s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 8.7215	Cost: 22.83s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 8.4749	Cost: 13.94s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 8.4789	Cost: 15.59s
Train Epoch: 103 	Average Loss: 8.5631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6244

Saving model as e103_model.pt & e103_waveforms_supplementary.hdf5
Learning rate: 0.00019999947646729134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 8.5660	Cost: 29.70s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 8.5714	Cost: 13.55s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 8.5016	Cost: 16.51s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 8.4502	Cost: 13.90s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 8.5745	Cost: 13.23s
Train Epoch: 104 	Average Loss: 8.5183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6134

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Learning rate: 0.00019999946625226878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 8.5283	Cost: 28.71s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 8.4125	Cost: 11.02s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 8.5061	Cost: 15.37s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 8.4233	Cost: 15.43s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 8.4950	Cost: 12.64s
Train Epoch: 105 	Average Loss: 8.4948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5689

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00019999945593855072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 8.5690	Cost: 30.86s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 8.5878	Cost: 12.25s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 8.5788	Cost: 14.38s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 8.3126	Cost: 13.69s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 8.3460	Cost: 15.54s
Train Epoch: 106 	Average Loss: 8.4917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6511

Learning rate: 0.00019999944552613714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 8.6955	Cost: 28.88s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 8.5389	Cost: 11.45s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 8.4799	Cost: 14.72s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 8.6085	Cost: 13.88s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 8.4128	Cost: 13.20s
Train Epoch: 107 	Average Loss: 8.5019
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4923

Saving model as e107_model.pt & e107_waveforms_supplementary.hdf5
Learning rate: 0.00019999943501502806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 8.5512	Cost: 28.18s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 8.2903	Cost: 11.62s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 8.4606	Cost: 16.55s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 8.3184	Cost: 13.87s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 8.4222	Cost: 18.54s
Train Epoch: 108 	Average Loss: 8.4202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4796

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Learning rate: 0.0001999994244052235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 8.6700	Cost: 32.14s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 8.4280	Cost: 15.50s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 8.4630	Cost: 15.53s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 8.3916	Cost: 15.16s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 8.3650	Cost: 15.29s
Train Epoch: 109 	Average Loss: 8.4411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6452

Learning rate: 0.00019999941369672346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 8.5757	Cost: 29.07s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 8.3381	Cost: 9.04s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 8.4887	Cost: 14.45s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 8.3130	Cost: 14.91s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 8.3811	Cost: 14.45s
Train Epoch: 110 	Average Loss: 8.4255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5533

Learning rate: 0.00019999940288952794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 8.5987	Cost: 29.45s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 8.3295	Cost: 9.58s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 8.4809	Cost: 15.15s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 8.3806	Cost: 13.63s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 8.4750	Cost: 14.51s
Train Epoch: 111 	Average Loss: 8.3812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5583

Learning rate: 0.000199999391983637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 8.6347	Cost: 27.88s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 8.1924	Cost: 9.84s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 8.3635	Cost: 13.65s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 8.2659	Cost: 14.13s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 8.2351	Cost: 15.21s
Train Epoch: 112 	Average Loss: 8.3591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5247

Learning rate: 0.0001999993809790506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 8.4817	Cost: 29.59s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 8.4481	Cost: 6.25s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 8.4608	Cost: 12.79s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 8.3958	Cost: 13.48s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 8.2271	Cost: 14.02s
Train Epoch: 113 	Average Loss: 8.3642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5488

Learning rate: 0.00019999936987576873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 8.5234	Cost: 38.19s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 8.2750	Cost: 9.96s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 8.2987	Cost: 13.92s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 8.1987	Cost: 13.35s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 8.3446	Cost: 13.54s
Train Epoch: 114 	Average Loss: 8.3165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5392

Learning rate: 0.00019999935867379148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 8.5001	Cost: 29.84s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 8.3494	Cost: 8.02s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 8.3507	Cost: 11.77s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 8.2699	Cost: 11.79s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 8.2164	Cost: 14.70s
Train Epoch: 115 	Average Loss: 8.3211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4497

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Learning rate: 0.00019999934737311882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 8.3813	Cost: 34.28s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 8.2787	Cost: 12.88s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 8.2478	Cost: 14.51s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 8.2174	Cost: 15.06s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 8.3609	Cost: 14.36s
Train Epoch: 116 	Average Loss: 8.2976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5615

Learning rate: 0.00019999933597375074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 8.4845	Cost: 31.23s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 8.3361	Cost: 13.64s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 8.4183	Cost: 15.71s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 8.1556	Cost: 14.27s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 8.2581	Cost: 16.99s
Train Epoch: 117 	Average Loss: 8.2944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4376

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 0.0001999993244756873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 8.3714	Cost: 28.40s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 8.2144	Cost: 15.02s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 8.3320	Cost: 15.55s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 8.1158	Cost: 15.20s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 8.2164	Cost: 17.74s
Train Epoch: 118 	Average Loss: 8.2562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3620

Saving model as e118_model.pt & e118_waveforms_supplementary.hdf5
Learning rate: 0.00019999931287892846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 8.4125	Cost: 30.21s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 8.0971	Cost: 13.16s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 8.2437	Cost: 17.77s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 8.1814	Cost: 15.45s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 8.1811	Cost: 18.20s
Train Epoch: 119 	Average Loss: 8.2304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4008

Learning rate: 0.00019999930118347426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 8.5261	Cost: 28.87s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 8.3162	Cost: 13.28s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 8.3602	Cost: 14.29s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 8.0816	Cost: 15.01s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 8.1132	Cost: 18.10s
Train Epoch: 120 	Average Loss: 8.2441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3340

Saving model as e120_model.pt & e120_waveforms_supplementary.hdf5
Learning rate: 0.0001999992893893247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 8.4239	Cost: 33.41s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 8.2191	Cost: 16.35s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 8.2820	Cost: 18.81s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 7.9923	Cost: 15.72s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 8.1573	Cost: 11.64s
Train Epoch: 121 	Average Loss: 8.2138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3230

Saving model as e121_model.pt & e121_waveforms_supplementary.hdf5
Learning rate: 0.0001999992774964798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 8.2689	Cost: 31.72s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 8.2060	Cost: 14.86s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 8.2286	Cost: 14.38s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 8.2089	Cost: 14.89s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 8.1533	Cost: 11.19s
Train Epoch: 122 	Average Loss: 8.1899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3185

Saving model as e122_model.pt & e122_waveforms_supplementary.hdf5
Learning rate: 0.00019999926550493962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 8.2419	Cost: 35.34s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 8.0119	Cost: 12.82s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 8.2822	Cost: 15.02s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 8.1791	Cost: 15.64s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 8.1462	Cost: 13.06s
Train Epoch: 123 	Average Loss: 8.1641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4759

Learning rate: 0.00019999925341470404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 8.2926	Cost: 36.45s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 8.1012	Cost: 12.38s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 8.2488	Cost: 18.51s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 8.0184	Cost: 14.34s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 8.2025	Cost: 12.40s
Train Epoch: 124 	Average Loss: 8.1662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3625

Learning rate: 0.0001999992412257732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 8.4622	Cost: 31.39s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 8.1087	Cost: 13.23s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 8.2394	Cost: 17.66s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 8.0322	Cost: 9.90s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 8.0613	Cost: 13.78s
Train Epoch: 125 	Average Loss: 8.1520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2728

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 0.00019999922893814705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 8.3259	Cost: 29.90s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 8.0874	Cost: 14.82s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 8.2358	Cost: 15.57s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 8.1000	Cost: 14.20s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 7.9819	Cost: 13.94s
Train Epoch: 126 	Average Loss: 8.1231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3786

Learning rate: 0.00019999921655182562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 8.2810	Cost: 38.87s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 8.0661	Cost: 15.20s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 8.1729	Cost: 15.00s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 8.1151	Cost: 15.25s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 8.0603	Cost: 11.86s
Train Epoch: 127 	Average Loss: 8.0758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2975

Learning rate: 0.0001999992040668089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 8.2687	Cost: 29.11s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 8.0014	Cost: 12.43s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 8.3209	Cost: 15.21s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 7.9353	Cost: 14.57s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 8.0937	Cost: 15.17s
Train Epoch: 128 	Average Loss: 8.0807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2540

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Learning rate: 0.00019999919148309698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 8.2356	Cost: 35.80s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 7.8789	Cost: 12.21s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 8.2891	Cost: 15.13s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 8.0079	Cost: 15.99s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 7.9188	Cost: 12.94s
Train Epoch: 129 	Average Loss: 8.0634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3076

Learning rate: 0.00019999917880068977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 8.2472	Cost: 33.21s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 7.9393	Cost: 13.28s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 8.1196	Cost: 14.22s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 7.9835	Cost: 12.69s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 7.9895	Cost: 12.53s
Train Epoch: 130 	Average Loss: 8.0347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2624

Learning rate: 0.00019999916601958734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 8.2205	Cost: 32.17s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 7.8483	Cost: 14.57s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 8.0808	Cost: 14.92s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 7.9005	Cost: 12.32s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 7.9200	Cost: 10.10s
Train Epoch: 131 	Average Loss: 8.0311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1755

Saving model as e131_model.pt & e131_waveforms_supplementary.hdf5
Learning rate: 0.00019999915313978966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 8.1991	Cost: 32.01s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 7.9555	Cost: 13.45s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 8.1187	Cost: 14.27s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 8.0160	Cost: 13.81s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 7.8726	Cost: 12.10s
Train Epoch: 132 	Average Loss: 7.9871
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2872

Learning rate: 0.00019999914016129682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 8.2010	Cost: 50.79s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 7.8985	Cost: 11.19s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 8.0525	Cost: 20.92s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 7.8684	Cost: 11.92s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 7.9878	Cost: 11.93s
Train Epoch: 133 	Average Loss: 7.9901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3622

Learning rate: 0.00019999912708410875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 8.2803	Cost: 55.42s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 7.9135	Cost: 8.72s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 8.1335	Cost: 16.49s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 7.9358	Cost: 12.26s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 7.9453	Cost: 11.93s
Train Epoch: 134 	Average Loss: 7.9884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2181

Learning rate: 0.00019999911390822548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 8.2036	Cost: 60.66s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 7.9294	Cost: 7.66s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 8.1671	Cost: 14.40s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 7.9745	Cost: 12.14s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 7.9145	Cost: 12.04s
Train Epoch: 135 	Average Loss: 7.9801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2422

Learning rate: 0.00019999910063364705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 8.2810	Cost: 41.72s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 7.8923	Cost: 6.28s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 8.0051	Cost: 13.29s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 7.9601	Cost: 12.18s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 7.8847	Cost: 11.93s
Train Epoch: 136 	Average Loss: 7.9641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0752

Saving model as e136_model.pt & e136_waveforms_supplementary.hdf5
Learning rate: 0.00019999908726037348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 8.1369	Cost: 34.76s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 7.8444	Cost: 7.59s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 7.9399	Cost: 12.38s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 7.7415	Cost: 12.13s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 7.8205	Cost: 12.17s
Train Epoch: 137 	Average Loss: 7.9215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1040

Learning rate: 0.00019999907378840477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 8.2744	Cost: 26.63s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 7.9345	Cost: 8.18s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 8.0023	Cost: 12.10s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 7.8456	Cost: 12.19s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 7.8272	Cost: 12.00s
Train Epoch: 138 	Average Loss: 7.9030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1712

Learning rate: 0.00019999906021774094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 8.2289	Cost: 26.72s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 7.7680	Cost: 6.88s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 7.8364	Cost: 13.32s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 7.9013	Cost: 12.69s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 7.7613	Cost: 12.07s
Train Epoch: 139 	Average Loss: 7.9070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1077

Learning rate: 0.00019999904654838195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 8.1551	Cost: 25.50s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 7.7840	Cost: 8.01s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 7.8713	Cost: 14.16s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 7.8167	Cost: 12.14s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 7.6976	Cost: 12.42s
Train Epoch: 140 	Average Loss: 7.8427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1500

Learning rate: 0.0001999990327803279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 8.2197	Cost: 31.11s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 7.8350	Cost: 12.65s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 7.9723	Cost: 12.79s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 7.7350	Cost: 12.34s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 7.7805	Cost: 12.34s
Train Epoch: 141 	Average Loss: 7.8589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1306

Learning rate: 0.00019999901891357876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 8.0894	Cost: 30.58s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 7.8064	Cost: 14.33s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 7.8986	Cost: 15.10s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 7.8272	Cost: 15.45s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 7.7961	Cost: 14.86s
Train Epoch: 142 	Average Loss: 7.8245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1078

Learning rate: 0.0001999990049481345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 8.1098	Cost: 28.49s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 7.7123	Cost: 8.95s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 7.8938	Cost: 13.50s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 7.7533	Cost: 15.34s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 7.7121	Cost: 14.72s
Train Epoch: 143 	Average Loss: 7.7868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0154

Saving model as e143_model.pt & e143_waveforms_supplementary.hdf5
Learning rate: 0.00019999899088399522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 8.0910	Cost: 33.27s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 7.8610	Cost: 12.53s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 7.8321	Cost: 14.49s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 7.7183	Cost: 13.46s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 7.6689	Cost: 13.89s
Train Epoch: 144 	Average Loss: 7.8050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0454

Learning rate: 0.0001999989767211609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 8.0269	Cost: 30.45s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 7.5560	Cost: 10.65s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 7.8750	Cost: 15.89s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 7.7226	Cost: 13.78s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 7.6613	Cost: 13.50s
Train Epoch: 145 	Average Loss: 7.7305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9828

Saving model as e145_model.pt & e145_waveforms_supplementary.hdf5
Learning rate: 0.00019999896245963153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 8.0705	Cost: 28.63s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 7.7338	Cost: 10.37s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 7.9241	Cost: 20.64s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 7.6485	Cost: 14.28s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 7.7734	Cost: 18.35s
Train Epoch: 146 	Average Loss: 7.7438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0159

Learning rate: 0.00019999894809940715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 8.0278	Cost: 31.08s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 7.4994	Cost: 14.03s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 7.7752	Cost: 17.71s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 7.6780	Cost: 15.04s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 7.5892	Cost: 15.32s
Train Epoch: 147 	Average Loss: 7.7126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0040

Learning rate: 0.00019999893364048776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 7.8887	Cost: 27.49s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 7.6518	Cost: 9.04s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 7.7807	Cost: 15.18s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 7.6664	Cost: 15.03s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 7.5553	Cost: 15.14s
Train Epoch: 148 	Average Loss: 7.6979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0389

Learning rate: 0.00019999891908287334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 7.9577	Cost: 31.58s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 7.6300	Cost: 10.33s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 7.7274	Cost: 14.59s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 7.6333	Cost: 15.02s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 7.5063	Cost: 14.60s
Train Epoch: 149 	Average Loss: 7.6719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9525

Saving model as e149_model.pt & e149_waveforms_supplementary.hdf5
Learning rate: 0.00019999890442656397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 7.9805	Cost: 34.00s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 7.5536	Cost: 12.53s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 7.7514	Cost: 13.53s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 7.5617	Cost: 12.99s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 7.5218	Cost: 11.53s
Train Epoch: 150 	Average Loss: 7.6264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0443

Learning rate: 0.00019999888967155965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 8.0308	Cost: 34.68s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 7.5586	Cost: 13.63s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 7.7552	Cost: 17.88s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 7.6262	Cost: 12.04s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 7.5684	Cost: 11.97s
Train Epoch: 151 	Average Loss: 7.6439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8867

Saving model as e151_model.pt & e151_waveforms_supplementary.hdf5
Learning rate: 0.00019999887481786036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 7.9180	Cost: 34.27s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 7.5301	Cost: 12.27s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 7.6644	Cost: 14.49s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 7.5574	Cost: 13.84s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 7.5541	Cost: 17.26s
Train Epoch: 152 	Average Loss: 7.6179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8953

Learning rate: 0.00019999885986546616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 7.9292	Cost: 26.71s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 7.5572	Cost: 11.49s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 7.6843	Cost: 15.13s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 7.5528	Cost: 14.30s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 7.5027	Cost: 20.51s
Train Epoch: 153 	Average Loss: 7.5751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9344

Learning rate: 0.00019999884481437704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 7.8810	Cost: 39.79s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 7.5550	Cost: 14.27s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 7.8051	Cost: 15.18s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 7.4918	Cost: 13.34s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 7.6144	Cost: 9.29s
Train Epoch: 154 	Average Loss: 7.5862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9268

Learning rate: 0.000199998829664593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 7.8833	Cost: 47.81s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 7.3983	Cost: 15.27s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 7.6150	Cost: 20.54s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 7.4498	Cost: 9.54s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 7.4990	Cost: 11.91s
Train Epoch: 155 	Average Loss: 7.5531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7981

Saving model as e155_model.pt & e155_waveforms_supplementary.hdf5
Learning rate: 0.00019999881441611406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 7.8767	Cost: 29.82s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 7.4356	Cost: 14.77s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 7.6208	Cost: 21.23s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 7.3888	Cost: 12.01s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 7.5683	Cost: 15.92s
Train Epoch: 156 	Average Loss: 7.5579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8566

Learning rate: 0.00019999879906894028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 7.8224	Cost: 34.83s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 7.4536	Cost: 9.09s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 7.5993	Cost: 14.59s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 7.4277	Cost: 14.90s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 7.3477	Cost: 12.08s
Train Epoch: 157 	Average Loss: 7.4913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7264

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Learning rate: 0.00019999878362307163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 7.7371	Cost: 32.71s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 7.4642	Cost: 10.79s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 7.5586	Cost: 14.09s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 7.3424	Cost: 14.95s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 7.4084	Cost: 13.36s
Train Epoch: 158 	Average Loss: 7.5118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7538

Learning rate: 0.0001999987680785081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 7.7240	Cost: 43.81s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 7.3380	Cost: 10.29s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 7.5266	Cost: 15.31s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 7.3605	Cost: 13.16s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 7.3561	Cost: 13.30s
Train Epoch: 159 	Average Loss: 7.4227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8272

Learning rate: 0.00019999875243524977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 7.7466	Cost: 33.69s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 7.2955	Cost: 14.50s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 7.4506	Cost: 14.42s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 7.3968	Cost: 15.46s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 7.3617	Cost: 14.46s
Train Epoch: 160 	Average Loss: 7.4479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7448

Learning rate: 0.00019999873669329665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 7.7602	Cost: 29.95s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 7.2268	Cost: 14.83s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 7.4330	Cost: 14.49s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 7.4209	Cost: 14.77s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 7.3654	Cost: 18.29s
Train Epoch: 161 	Average Loss: 7.4211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7625

Learning rate: 0.0001999987208526487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 7.7796	Cost: 28.95s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 7.3143	Cost: 14.43s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 7.5182	Cost: 17.17s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 7.4336	Cost: 15.01s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 7.2995	Cost: 16.07s
Train Epoch: 162 	Average Loss: 7.4012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7892

Learning rate: 0.000199998704913306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 7.7079	Cost: 27.57s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 7.3825	Cost: 11.18s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 7.4526	Cost: 16.51s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 7.3616	Cost: 14.97s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 7.3392	Cost: 18.27s
Train Epoch: 163 	Average Loss: 7.3887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7918

Learning rate: 0.00019999868887526852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 7.6980	Cost: 40.60s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 7.2653	Cost: 12.99s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 7.4092	Cost: 16.15s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 7.3057	Cost: 14.02s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 7.4142	Cost: 12.26s
Train Epoch: 164 	Average Loss: 7.3549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7246

Saving model as e164_model.pt & e164_waveforms_supplementary.hdf5
Learning rate: 0.0001999986727385363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 7.6513	Cost: 29.07s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 7.2013	Cost: 14.10s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 7.3947	Cost: 16.52s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 7.2588	Cost: 14.30s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 7.2701	Cost: 15.22s
Train Epoch: 165 	Average Loss: 7.3301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7793

Learning rate: 0.0001999986565031093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 7.8454	Cost: 33.62s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 7.2498	Cost: 13.92s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 7.4913	Cost: 15.39s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 7.2980	Cost: 14.98s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 7.2424	Cost: 15.72s
Train Epoch: 166 	Average Loss: 7.3305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7098

Saving model as e166_model.pt & e166_waveforms_supplementary.hdf5
Learning rate: 0.00019999864016898762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 7.5689	Cost: 35.76s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 7.1649	Cost: 14.25s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 7.3657	Cost: 18.43s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 7.2917	Cost: 13.50s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 7.1771	Cost: 14.46s
Train Epoch: 167 	Average Loss: 7.2559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7050

Saving model as e167_model.pt & e167_waveforms_supplementary.hdf5
Learning rate: 0.00019999862373617122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 7.5455	Cost: 30.98s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 7.2454	Cost: 14.64s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 7.3717	Cost: 14.17s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 7.2849	Cost: 14.39s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 7.1683	Cost: 14.80s
Train Epoch: 168 	Average Loss: 7.2480
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6182

Saving model as e168_model.pt & e168_waveforms_supplementary.hdf5
Learning rate: 0.00019999860720466015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 7.5934	Cost: 29.40s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 7.2012	Cost: 14.39s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 7.2382	Cost: 14.87s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 7.0955	Cost: 15.22s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 7.1022	Cost: 16.38s
Train Epoch: 169 	Average Loss: 7.2320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6270

Learning rate: 0.0001999985905744544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 7.6265	Cost: 28.97s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 7.1253	Cost: 14.47s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 7.3516	Cost: 14.73s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 7.1471	Cost: 12.61s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 7.2786	Cost: 14.26s
Train Epoch: 170 	Average Loss: 7.2422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7338

Learning rate: 0.000199998573845554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 7.6402	Cost: 28.99s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 7.0702	Cost: 13.92s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 7.3662	Cost: 17.18s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 7.1007	Cost: 14.89s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 7.1424	Cost: 17.61s
Train Epoch: 171 	Average Loss: 7.2145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6434

Learning rate: 0.00019999855701795897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 7.5624	Cost: 27.92s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 7.1189	Cost: 12.40s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 7.1410	Cost: 15.70s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 6.9456	Cost: 14.99s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 7.1261	Cost: 20.30s
Train Epoch: 172 	Average Loss: 7.1848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6551

Learning rate: 0.00019999854009166934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 7.5857	Cost: 28.34s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 7.0406	Cost: 12.98s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 7.2691	Cost: 15.11s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 7.0504	Cost: 15.92s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 7.1468	Cost: 16.23s
Train Epoch: 173 	Average Loss: 7.1796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5897

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 0.00019999852306668508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 7.5729	Cost: 28.71s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 7.0113	Cost: 13.70s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 7.2300	Cost: 15.51s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 7.1292	Cost: 15.22s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 7.1449	Cost: 17.19s
Train Epoch: 174 	Average Loss: 7.1019
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6229

Learning rate: 0.00019999850594300622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 7.6445	Cost: 31.70s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 7.0771	Cost: 13.69s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 7.2749	Cost: 14.30s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 7.1394	Cost: 15.10s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 7.1263	Cost: 17.39s
Train Epoch: 175 	Average Loss: 7.1897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6169

Learning rate: 0.00019999848872063282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 7.6667	Cost: 36.62s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 6.9952	Cost: 15.12s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 7.3097	Cost: 17.00s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 7.0720	Cost: 12.92s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 6.8846	Cost: 14.46s
Train Epoch: 176 	Average Loss: 7.1105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5235

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Learning rate: 0.00019999847139956484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 7.5547	Cost: 34.14s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 7.0575	Cost: 13.73s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 7.1548	Cost: 17.00s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 7.0643	Cost: 14.10s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 7.0095	Cost: 15.27s
Train Epoch: 177 	Average Loss: 7.0590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5590

Learning rate: 0.00019999845397980232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 7.7104	Cost: 32.69s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 6.8547	Cost: 13.97s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 7.0835	Cost: 14.28s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 6.9656	Cost: 13.03s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 6.8259	Cost: 17.37s
Train Epoch: 178 	Average Loss: 7.0434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5736

Learning rate: 0.00019999843646134532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 7.4963	Cost: 31.92s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 6.9900	Cost: 12.62s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 7.0497	Cost: 16.34s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 7.0048	Cost: 14.26s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 6.9404	Cost: 12.52s
Train Epoch: 179 	Average Loss: 7.0255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5978

Learning rate: 0.00019999841884419376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 7.3045	Cost: 30.82s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 6.8126	Cost: 13.12s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 7.1972	Cost: 24.16s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 7.0139	Cost: 15.28s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 6.8322	Cost: 14.94s
Train Epoch: 180 	Average Loss: 6.9881
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5283

Learning rate: 0.00019999840112834775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 7.4459	Cost: 28.68s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 6.8876	Cost: 15.46s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 7.1174	Cost: 13.41s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 6.8962	Cost: 15.13s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 6.7771	Cost: 20.46s
Train Epoch: 181 	Average Loss: 6.9718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5585

Learning rate: 0.00019999838331380727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 7.5525	Cost: 27.84s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 6.9039	Cost: 11.40s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 7.1341	Cost: 17.59s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 7.0284	Cost: 14.36s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 7.0018	Cost: 19.13s
Train Epoch: 182 	Average Loss: 6.9685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4589

Saving model as e182_model.pt & e182_waveforms_supplementary.hdf5
Learning rate: 0.00019999836540057235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 7.4712	Cost: 34.83s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 6.7788	Cost: 14.83s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 7.0943	Cost: 12.54s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 6.9063	Cost: 13.97s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 6.8909	Cost: 14.26s
Train Epoch: 183 	Average Loss: 6.9326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4873

Learning rate: 0.000199998347388643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 7.4424	Cost: 28.31s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 6.8940	Cost: 13.08s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 7.0608	Cost: 15.73s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 6.8470	Cost: 15.32s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 6.8666	Cost: 16.94s
Train Epoch: 184 	Average Loss: 6.8828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5128

Learning rate: 0.00019999832927801924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 7.3571	Cost: 30.70s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 6.7301	Cost: 11.55s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 7.0431	Cost: 14.87s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 6.8305	Cost: 14.21s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 6.8719	Cost: 15.29s
Train Epoch: 185 	Average Loss: 6.8813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4710

Learning rate: 0.00019999831106870108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 7.4957	Cost: 30.32s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 6.8346	Cost: 11.17s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 7.0139	Cost: 15.00s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 6.7050	Cost: 14.84s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 6.7153	Cost: 16.16s
Train Epoch: 186 	Average Loss: 6.8556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4660

Learning rate: 0.00019999829276068855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 7.3004	Cost: 29.79s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 6.6790	Cost: 10.71s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 6.9671	Cost: 15.87s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 6.7003	Cost: 14.96s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 6.8599	Cost: 20.71s
Train Epoch: 187 	Average Loss: 6.8525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4220

Saving model as e187_model.pt & e187_waveforms_supplementary.hdf5
Learning rate: 0.00019999827435398168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 7.4437	Cost: 37.47s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 6.6845	Cost: 11.61s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 6.9022	Cost: 22.32s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 6.6745	Cost: 13.77s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 6.7570	Cost: 11.62s
Train Epoch: 188 	Average Loss: 6.8166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3680

Saving model as e188_model.pt & e188_waveforms_supplementary.hdf5
Learning rate: 0.00019999825584858045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 7.3424	Cost: 29.64s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 6.7075	Cost: 13.64s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 6.8885	Cost: 14.56s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 6.6799	Cost: 14.02s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 6.7177	Cost: 14.69s
Train Epoch: 189 	Average Loss: 6.7607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3243

Saving model as e189_model.pt & e189_waveforms_supplementary.hdf5
Learning rate: 0.00019999823724448486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 7.4097	Cost: 28.58s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 6.6391	Cost: 14.02s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 6.9008	Cost: 15.56s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 6.5878	Cost: 16.29s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 6.6799	Cost: 14.87s
Train Epoch: 190 	Average Loss: 6.7527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2824

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 0.000199998218541695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 7.2440	Cost: 30.04s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 6.6229	Cost: 14.38s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 6.8848	Cost: 17.32s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 6.7279	Cost: 14.50s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 6.6622	Cost: 14.91s
Train Epoch: 191 	Average Loss: 6.7398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3286

Learning rate: 0.00019999819974021087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 7.1838	Cost: 38.97s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 6.5301	Cost: 13.47s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 6.8735	Cost: 15.00s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 6.6835	Cost: 13.50s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 6.6422	Cost: 10.70s
Train Epoch: 192 	Average Loss: 6.7001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3063

Learning rate: 0.00019999818084003246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 7.3547	Cost: 31.80s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 6.6200	Cost: 14.17s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 6.8309	Cost: 14.00s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 6.5652	Cost: 14.97s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 6.5510	Cost: 13.04s
Train Epoch: 193 	Average Loss: 6.6598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2632

Saving model as e193_model.pt & e193_waveforms_supplementary.hdf5
Learning rate: 0.00019999816184115978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 7.1563	Cost: 27.98s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 6.4758	Cost: 11.18s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 6.7880	Cost: 21.46s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 6.6135	Cost: 14.59s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 6.5823	Cost: 16.90s
Train Epoch: 194 	Average Loss: 6.6837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3080

Learning rate: 0.00019999814274359288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 7.1638	Cost: 34.62s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 6.4898	Cost: 14.49s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 6.7133	Cost: 24.43s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 6.5719	Cost: 15.04s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 6.5027	Cost: 11.08s
Train Epoch: 195 	Average Loss: 6.6312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3057

Learning rate: 0.00019999812354733177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 7.2328	Cost: 32.51s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 6.5339	Cost: 14.75s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 7.0602	Cost: 16.48s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 6.5710	Cost: 15.23s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 6.5821	Cost: 18.05s
Train Epoch: 196 	Average Loss: 6.6976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2624

Saving model as e196_model.pt & e196_waveforms_supplementary.hdf5
Learning rate: 0.00019999810425237646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 7.2388	Cost: 30.38s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 6.5097	Cost: 15.00s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 6.7835	Cost: 18.08s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 6.5219	Cost: 13.60s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 6.5009	Cost: 16.27s
Train Epoch: 197 	Average Loss: 6.6351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2809

Learning rate: 0.00019999808485872698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 7.1875	Cost: 32.46s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 6.5076	Cost: 14.44s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 6.6879	Cost: 18.18s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 6.5369	Cost: 14.87s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 6.5424	Cost: 13.80s
Train Epoch: 198 	Average Loss: 6.6009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2732

Learning rate: 0.00019999806536638337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 7.2507	Cost: 30.26s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 6.4743	Cost: 13.28s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 6.7136	Cost: 15.14s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 6.4195	Cost: 14.53s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 6.3711	Cost: 14.58s
Train Epoch: 199 	Average Loss: 6.5396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2212

Saving model as e199_model.pt & e199_waveforms_supplementary.hdf5
Learning rate: 0.00019999804577534562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 7.1101	Cost: 29.99s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 6.3905	Cost: 13.54s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 6.5816	Cost: 14.51s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 6.4758	Cost: 14.87s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 6.5841	Cost: 15.34s
Train Epoch: 200 	Average Loss: 6.5181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1978

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 0.00019999802608561374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 7.3127	Cost: 34.55s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 6.4270	Cost: 14.54s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 6.6742	Cost: 14.75s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 6.4579	Cost: 13.92s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 6.3890	Cost: 12.13s
Train Epoch: 201 	Average Loss: 6.5197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1354

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 0.00019999800629718777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 7.1968	Cost: 34.86s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 6.3624	Cost: 15.57s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 6.5571	Cost: 15.69s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 6.3523	Cost: 14.64s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 6.3456	Cost: 13.56s
Train Epoch: 202 	Average Loss: 6.4524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1197

Saving model as e202_model.pt & e202_waveforms_supplementary.hdf5
Learning rate: 0.00019999798641006774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 7.1040	Cost: 29.92s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 6.3209	Cost: 11.80s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 6.5032	Cost: 22.03s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 6.4425	Cost: 13.28s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 6.3023	Cost: 14.94s
Train Epoch: 203 	Average Loss: 6.4387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1619

Learning rate: 0.00019999796642425366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 7.0216	Cost: 29.54s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 6.2571	Cost: 11.33s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 6.4560	Cost: 14.71s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 6.3409	Cost: 14.73s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 6.2672	Cost: 13.98s
Train Epoch: 204 	Average Loss: 6.3922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0720

Saving model as e204_model.pt & e204_waveforms_supplementary.hdf5
Learning rate: 0.00019999794633974552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 6.9980	Cost: 30.84s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 6.3014	Cost: 13.46s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 6.4159	Cost: 15.40s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 6.3433	Cost: 14.98s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 6.2305	Cost: 14.60s
Train Epoch: 205 	Average Loss: 6.3690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1128

Learning rate: 0.00019999792615654335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 7.0099	Cost: 29.90s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 6.3683	Cost: 14.37s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 6.5831	Cost: 17.87s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 6.3224	Cost: 14.39s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 6.2548	Cost: 12.98s
Train Epoch: 206 	Average Loss: 6.4417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1101

Learning rate: 0.00019999790587464718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 7.0106	Cost: 30.64s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 6.2691	Cost: 12.74s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 6.3973	Cost: 15.36s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 6.3089	Cost: 13.31s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 6.2245	Cost: 15.96s
Train Epoch: 207 	Average Loss: 6.3351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9969

Saving model as e207_model.pt & e207_waveforms_supplementary.hdf5
Learning rate: 0.00019999788549405706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 7.0085	Cost: 29.93s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 6.3144	Cost: 13.20s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 6.4745	Cost: 23.16s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 6.1349	Cost: 14.77s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 6.2029	Cost: 16.40s
Train Epoch: 208 	Average Loss: 6.3024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9765

Saving model as e208_model.pt & e208_waveforms_supplementary.hdf5
Learning rate: 0.00019999786501477296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 7.0024	Cost: 31.38s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 6.2397	Cost: 13.75s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 6.3026	Cost: 13.59s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 6.2600	Cost: 15.46s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 6.1853	Cost: 15.38s
Train Epoch: 209 	Average Loss: 6.2674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9991

Learning rate: 0.00019999784443679492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 6.8740	Cost: 27.54s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 6.0463	Cost: 13.42s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 6.2808	Cost: 14.89s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 6.2204	Cost: 14.41s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 6.1694	Cost: 15.04s
Train Epoch: 210 	Average Loss: 6.2325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9987

Learning rate: 0.000199997823760123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 7.0030	Cost: 28.70s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 6.1386	Cost: 13.18s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 6.3361	Cost: 14.17s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 6.2204	Cost: 15.13s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 6.1491	Cost: 13.60s
Train Epoch: 211 	Average Loss: 6.2212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9258

Saving model as e211_model.pt & e211_waveforms_supplementary.hdf5
Learning rate: 0.00019999780298475715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 6.9102	Cost: 28.48s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 6.1609	Cost: 9.57s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 6.2193	Cost: 16.68s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 6.1359	Cost: 13.75s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 6.0915	Cost: 14.86s
Train Epoch: 212 	Average Loss: 6.1867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9213

Saving model as e212_model.pt & e212_waveforms_supplementary.hdf5
Learning rate: 0.00019999778211069746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 7.1001	Cost: 30.31s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 6.0216	Cost: 15.25s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 6.3139	Cost: 14.63s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 6.1639	Cost: 15.21s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 5.9799	Cost: 14.55s
Train Epoch: 213 	Average Loss: 6.1587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8793

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Learning rate: 0.0001999977611379439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 6.8700	Cost: 38.07s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 6.0328	Cost: 15.19s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 6.2452	Cost: 16.13s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 6.0307	Cost: 15.23s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 6.0597	Cost: 9.55s
Train Epoch: 214 	Average Loss: 6.1377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9569

Learning rate: 0.00019999774006649652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 6.9255	Cost: 28.82s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 6.0667	Cost: 14.46s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 6.1687	Cost: 11.69s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 6.0398	Cost: 13.45s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 5.9852	Cost: 13.34s
Train Epoch: 215 	Average Loss: 6.1267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8912

Learning rate: 0.00019999771889635528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 6.8344	Cost: 27.71s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 5.9994	Cost: 6.38s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 6.1629	Cost: 18.40s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 5.9593	Cost: 11.57s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 6.0610	Cost: 21.30s
Train Epoch: 216 	Average Loss: 6.0797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8938

Learning rate: 0.00019999769762752028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 6.7881	Cost: 31.23s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 5.8687	Cost: 6.42s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 6.1767	Cost: 12.25s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 6.0281	Cost: 12.94s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 5.8752	Cost: 14.32s
Train Epoch: 217 	Average Loss: 6.0342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8683

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 0.00019999767625999152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 6.9149	Cost: 35.90s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 5.8551	Cost: 11.12s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 6.1013	Cost: 15.33s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 6.0390	Cost: 13.31s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 6.0502	Cost: 9.93s
Train Epoch: 218 	Average Loss: 6.0427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8401

Saving model as e218_model.pt & e218_waveforms_supplementary.hdf5
Learning rate: 0.00019999765479376897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 6.8271	Cost: 27.77s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 5.8599	Cost: 13.31s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 6.1543	Cost: 11.95s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 6.1077	Cost: 14.84s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 5.9366	Cost: 15.66s
Train Epoch: 219 	Average Loss: 6.0316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8255

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 0.00019999763322885272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 6.7062	Cost: 36.98s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 5.8240	Cost: 14.09s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 6.1642	Cost: 14.54s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 5.7892	Cost: 15.88s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 5.9031	Cost: 12.51s
Train Epoch: 220 	Average Loss: 5.9837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8633

Learning rate: 0.00019999761156524275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 6.7968	Cost: 28.46s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 5.7833	Cost: 11.79s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 6.1527	Cost: 15.21s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 6.0062	Cost: 14.30s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 5.7839	Cost: 19.13s
Train Epoch: 221 	Average Loss: 5.9511
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7959

Saving model as e221_model.pt & e221_waveforms_supplementary.hdf5
Learning rate: 0.0001999975898029391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 6.8178	Cost: 30.36s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 5.8559	Cost: 14.83s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 5.9984	Cost: 20.57s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 5.9174	Cost: 15.53s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 5.7651	Cost: 14.88s
Train Epoch: 222 	Average Loss: 5.9184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7784

Saving model as e222_model.pt & e222_waveforms_supplementary.hdf5
Learning rate: 0.00019999756794194176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 6.8728	Cost: 28.29s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 5.7788	Cost: 11.90s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 6.0676	Cost: 18.73s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 5.7412	Cost: 14.61s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 5.7657	Cost: 16.60s
Train Epoch: 223 	Average Loss: 5.8804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7172

Saving model as e223_model.pt & e223_waveforms_supplementary.hdf5
Learning rate: 0.0001999975459822508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 6.7285	Cost: 29.18s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 5.8768	Cost: 12.18s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 6.0583	Cost: 19.80s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 5.9502	Cost: 12.73s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 5.9060	Cost: 19.68s
Train Epoch: 224 	Average Loss: 5.9320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7859

Learning rate: 0.0001999975239238662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 6.8371	Cost: 34.11s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 5.7533	Cost: 13.87s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 6.0550	Cost: 12.11s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 5.7917	Cost: 15.03s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 5.6582	Cost: 12.96s
Train Epoch: 225 	Average Loss: 5.8570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6565

Saving model as e225_model.pt & e225_waveforms_supplementary.hdf5
Learning rate: 0.000199997501766788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 6.6356	Cost: 28.17s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 5.4882	Cost: 11.16s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 5.9910	Cost: 14.33s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 5.6605	Cost: 13.48s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 5.6644	Cost: 14.81s
Train Epoch: 226 	Average Loss: 5.8211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6501

Saving model as e226_model.pt & e226_waveforms_supplementary.hdf5
Learning rate: 0.00019999747951101625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 6.6833	Cost: 32.68s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 5.8153	Cost: 13.50s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 5.9589	Cost: 15.51s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 5.7224	Cost: 15.24s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 5.7951	Cost: 14.69s
Train Epoch: 227 	Average Loss: 5.8247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7657

Learning rate: 0.0001999974571565509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 6.5659	Cost: 33.95s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 5.6145	Cost: 12.17s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 5.8274	Cost: 14.65s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 5.8325	Cost: 14.64s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 5.7491	Cost: 15.18s
Train Epoch: 228 	Average Loss: 5.7612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7488

Learning rate: 0.00019999743470339206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 6.7149	Cost: 35.89s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 5.6432	Cost: 12.53s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 5.9763	Cost: 15.29s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 5.7596	Cost: 14.54s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 5.6742	Cost: 10.64s
Train Epoch: 229 	Average Loss: 5.8286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7463

Learning rate: 0.0001999974121515397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 6.6411	Cost: 28.70s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 5.5718	Cost: 12.66s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 5.8701	Cost: 22.56s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 5.6729	Cost: 14.25s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 5.4405	Cost: 13.81s
Train Epoch: 230 	Average Loss: 5.7460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6521

Learning rate: 0.00019999738950099387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 6.6457	Cost: 28.53s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 5.4795	Cost: 13.96s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 5.8379	Cost: 14.80s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 5.6056	Cost: 15.53s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 5.6059	Cost: 14.19s
Train Epoch: 231 	Average Loss: 5.6798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6556

Learning rate: 0.00019999736675175452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 6.5376	Cost: 28.49s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 5.5245	Cost: 12.14s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 5.9184	Cost: 17.79s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 5.6833	Cost: 15.18s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 5.5594	Cost: 17.96s
Train Epoch: 232 	Average Loss: 5.6678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5748

Saving model as e232_model.pt & e232_waveforms_supplementary.hdf5
Learning rate: 0.00019999734390382178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 6.4891	Cost: 27.51s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 5.5657	Cost: 12.77s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 5.5972	Cost: 14.89s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 5.4588	Cost: 15.20s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 5.3716	Cost: 14.87s
Train Epoch: 233 	Average Loss: 5.5946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5005

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Learning rate: 0.00019999732095719557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 6.3088	Cost: 28.72s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 5.3949	Cost: 12.21s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 5.6622	Cost: 15.43s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 5.5340	Cost: 15.71s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 5.4616	Cost: 18.73s
Train Epoch: 234 	Average Loss: 5.5947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5976

Learning rate: 0.00019999729791187596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 6.4911	Cost: 30.63s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 5.5145	Cost: 14.14s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 5.7030	Cost: 16.60s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 5.5251	Cost: 15.58s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 5.5815	Cost: 15.27s
Train Epoch: 235 	Average Loss: 5.5993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5874

Learning rate: 0.000199997274767863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 6.4094	Cost: 33.69s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 5.3681	Cost: 13.99s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 5.6216	Cost: 15.20s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 5.3586	Cost: 13.33s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 5.4224	Cost: 13.89s
Train Epoch: 236 	Average Loss: 5.5454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4636

Saving model as e236_model.pt & e236_waveforms_supplementary.hdf5
Learning rate: 0.0001999972515251567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 6.4349	Cost: 34.22s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 5.4185	Cost: 14.43s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 5.6462	Cost: 21.87s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 5.4283	Cost: 12.48s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 5.3733	Cost: 14.92s
Train Epoch: 237 	Average Loss: 5.5151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4861

Learning rate: 0.00019999722818375706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 6.3269	Cost: 31.30s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 5.3764	Cost: 14.89s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 5.7261	Cost: 15.13s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 5.5136	Cost: 14.46s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 5.3596	Cost: 13.34s
Train Epoch: 238 	Average Loss: 5.5032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4771

Learning rate: 0.00019999720474366407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 6.5267	Cost: 27.30s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 5.4165	Cost: 12.35s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 5.4897	Cost: 15.67s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 5.3243	Cost: 13.73s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 5.3501	Cost: 16.53s
Train Epoch: 239 	Average Loss: 5.4743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4637

Learning rate: 0.00019999718120487783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 6.2659	Cost: 27.79s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 5.0944	Cost: 10.14s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 5.6218	Cost: 17.59s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 5.3306	Cost: 13.96s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 5.2069	Cost: 18.54s
Train Epoch: 240 	Average Loss: 5.4426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5215

Learning rate: 0.00019999715756739835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 6.5067	Cost: 35.51s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 5.1847	Cost: 14.14s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 5.4193	Cost: 14.96s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 5.3289	Cost: 15.40s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 5.3603	Cost: 15.25s
Train Epoch: 241 	Average Loss: 5.3943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3965

Saving model as e241_model.pt & e241_waveforms_supplementary.hdf5
Learning rate: 0.00019999713383122558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 6.3472	Cost: 30.02s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 5.1877	Cost: 13.27s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 5.6186	Cost: 15.77s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 5.2842	Cost: 13.89s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 5.2961	Cost: 15.15s
Train Epoch: 242 	Average Loss: 5.3725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4375

Learning rate: 0.0001999971099963596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 6.4116	Cost: 32.05s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 5.1981	Cost: 7.77s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 5.3940	Cost: 13.08s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 5.1850	Cost: 13.98s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 5.1031	Cost: 13.96s
Train Epoch: 243 	Average Loss: 5.3192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4188

Learning rate: 0.00019999708606280046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 6.3159	Cost: 30.87s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 5.0677	Cost: 10.96s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 5.3797	Cost: 14.05s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 5.1162	Cost: 13.28s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 5.0895	Cost: 14.86s
Train Epoch: 244 	Average Loss: 5.2697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3144

Saving model as e244_model.pt & e244_waveforms_supplementary.hdf5
Learning rate: 0.00019999706203054814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 6.2830	Cost: 27.97s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 5.0395	Cost: 13.50s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 5.4271	Cost: 15.86s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 5.2129	Cost: 13.76s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 5.2817	Cost: 14.55s
Train Epoch: 245 	Average Loss: 5.2979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4587

Learning rate: 0.00019999703789960266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 6.2874	Cost: 28.48s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 4.9889	Cost: 11.77s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 5.3336	Cost: 17.25s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 5.1993	Cost: 14.21s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 5.0605	Cost: 14.25s
Train Epoch: 246 	Average Loss: 5.2669
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3280

Learning rate: 0.00019999701366996408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 6.0484	Cost: 34.72s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 5.0358	Cost: 13.23s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 5.3269	Cost: 14.41s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 5.1988	Cost: 14.65s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 5.0512	Cost: 15.51s
Train Epoch: 247 	Average Loss: 5.2027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2993

Saving model as e247_model.pt & e247_waveforms_supplementary.hdf5
Learning rate: 0.0001999969893416324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 6.1303	Cost: 32.38s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 4.9727	Cost: 14.37s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 5.2526	Cost: 14.12s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 5.2137	Cost: 15.08s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 5.1698	Cost: 14.22s
Train Epoch: 248 	Average Loss: 5.2436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3550

Learning rate: 0.00019999696491460766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 6.2166	Cost: 28.66s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 4.9479	Cost: 12.11s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 5.4127	Cost: 18.40s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 5.1277	Cost: 14.47s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 5.1704	Cost: 17.15s
Train Epoch: 249 	Average Loss: 5.2327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3627

Learning rate: 0.00019999694038888986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 6.2939	Cost: 35.63s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 5.0500	Cost: 13.03s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 5.2742	Cost: 15.90s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 5.1674	Cost: 13.99s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 5.0368	Cost: 14.80s
Train Epoch: 250 	Average Loss: 5.1574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2487

Saving model as e250_model.pt & e250_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 5.9580	Cost: 31.24s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 4.9441	Cost: 13.79s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 5.3784	Cost: 14.24s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 5.0443	Cost: 13.52s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 5.0742	Cost: 11.49s
Train Epoch: 251 	Average Loss: 5.1290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3442

Learning rate: 0.0001999968910413752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 6.3440	Cost: 39.29s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 5.0269	Cost: 13.66s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 5.2213	Cost: 15.29s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 5.0234	Cost: 13.82s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 4.9858	Cost: 16.93s
Train Epoch: 252 	Average Loss: 5.1632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3096

Learning rate: 0.0001999968662195784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 6.1640	Cost: 30.47s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 4.9194	Cost: 14.28s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 5.2290	Cost: 18.53s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 5.0614	Cost: 15.54s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 5.1545	Cost: 17.81s
Train Epoch: 253 	Average Loss: 5.1264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2397

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 0.00019999684129908864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 6.2570	Cost: 36.36s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 5.0442	Cost: 13.85s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 5.1267	Cost: 16.44s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 4.9962	Cost: 15.33s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 4.8160	Cost: 13.93s
Train Epoch: 254 	Average Loss: 5.0425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1416

Saving model as e254_model.pt & e254_waveforms_supplementary.hdf5
Learning rate: 0.00019999681627990595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 6.0871	Cost: 30.92s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 4.7297	Cost: 14.53s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 5.1421	Cost: 16.42s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 4.9624	Cost: 15.24s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 4.9785	Cost: 16.85s
Train Epoch: 255 	Average Loss: 4.9901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1165

Saving model as e255_model.pt & e255_waveforms_supplementary.hdf5
Learning rate: 0.00019999679116203034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 6.0917	Cost: 26.58s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 4.8273	Cost: 11.88s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 5.1857	Cost: 15.71s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 5.0116	Cost: 14.12s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 4.8164	Cost: 17.39s
Train Epoch: 256 	Average Loss: 4.9942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1344

Learning rate: 0.0001999967659454619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 6.1594	Cost: 31.02s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 4.7686	Cost: 13.15s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 4.9493	Cost: 18.65s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 4.9055	Cost: 13.96s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 4.9800	Cost: 18.71s
Train Epoch: 257 	Average Loss: 5.0331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2679

Learning rate: 0.00019999674063020056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 6.2788	Cost: 32.02s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 4.8061	Cost: 13.59s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 5.0743	Cost: 17.78s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 4.9104	Cost: 14.63s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 4.8503	Cost: 15.87s
Train Epoch: 258 	Average Loss: 5.0006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1129

Saving model as e258_model.pt & e258_waveforms_supplementary.hdf5
Learning rate: 0.00019999671521624642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 6.0867	Cost: 32.98s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 4.6860	Cost: 14.90s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 4.9477	Cost: 18.66s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 4.8010	Cost: 14.37s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 4.8055	Cost: 15.95s
Train Epoch: 259 	Average Loss: 4.9230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1157

Learning rate: 0.0001999966897035995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 6.0062	Cost: 27.47s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 4.6660	Cost: 12.48s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 4.9979	Cost: 16.77s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 4.7491	Cost: 14.81s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 4.7402	Cost: 21.80s
Train Epoch: 260 	Average Loss: 4.8369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0485

Saving model as e260_model.pt & e260_waveforms_supplementary.hdf5
Learning rate: 0.00019999666409225978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 5.9916	Cost: 33.20s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 4.5676	Cost: 14.87s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 4.8352	Cost: 19.98s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 4.7260	Cost: 15.33s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 4.6407	Cost: 15.38s
Train Epoch: 261 	Average Loss: 4.8152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0895

Learning rate: 0.00019999663838222732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 6.1353	Cost: 30.94s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 4.5817	Cost: 14.88s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 5.0211	Cost: 16.14s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 4.6740	Cost: 15.15s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 4.7606	Cost: 16.84s
Train Epoch: 262 	Average Loss: 4.8340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0420

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 0.00019999661257350212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 6.0051	Cost: 28.33s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 4.5733	Cost: 14.49s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 4.8098	Cost: 14.27s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 4.7379	Cost: 15.14s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 4.6317	Cost: 14.30s
Train Epoch: 263 	Average Loss: 4.7691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9653

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Learning rate: 0.00019999658666608423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 5.9667	Cost: 34.33s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 4.5068	Cost: 15.13s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 4.9003	Cost: 18.49s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 4.6621	Cost: 14.46s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 4.5834	Cost: 13.97s
Train Epoch: 264 	Average Loss: 4.7271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9935

Learning rate: 0.00019999656065997363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 5.8391	Cost: 29.58s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 4.5743	Cost: 13.35s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 4.8553	Cost: 16.49s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 4.7250	Cost: 15.10s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 4.6640	Cost: 18.97s
Train Epoch: 265 	Average Loss: 4.7441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9985

Learning rate: 0.00019999653455517042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 6.0090	Cost: 28.58s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 4.5846	Cost: 12.02s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 5.0906	Cost: 14.91s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 5.0410	Cost: 14.39s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 4.9908	Cost: 19.22s
Train Epoch: 266 	Average Loss: 4.9379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2211

Learning rate: 0.00019999650835167456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 5.9733	Cost: 28.60s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 4.7054	Cost: 13.13s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 4.9653	Cost: 14.34s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 4.7348	Cost: 15.24s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 4.5624	Cost: 16.55s
Train Epoch: 267 	Average Loss: 4.7925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9955

Learning rate: 0.00019999648204948613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 5.9155	Cost: 35.58s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 4.4592	Cost: 15.71s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 4.8308	Cost: 21.64s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 4.5544	Cost: 14.23s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 4.4361	Cost: 16.25s
Train Epoch: 268 	Average Loss: 4.6414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8492

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Learning rate: 0.0001999964556486051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 5.8174	Cost: 32.01s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 4.5024	Cost: 11.53s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 4.7913	Cost: 22.11s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 4.5774	Cost: 12.06s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 4.4983	Cost: 15.40s
Train Epoch: 269 	Average Loss: 4.6523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9217

Learning rate: 0.00019999642914903155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 5.9041	Cost: 27.85s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 4.4375	Cost: 11.63s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 4.7778	Cost: 14.75s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 4.4357	Cost: 14.83s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 4.3451	Cost: 14.77s
Train Epoch: 270 	Average Loss: 4.5874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8106

Saving model as e270_model.pt & e270_waveforms_supplementary.hdf5
Learning rate: 0.00019999640255076545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 5.6593	Cost: 30.03s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 4.3350	Cost: 12.44s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 4.6422	Cost: 14.09s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 4.4530	Cost: 14.42s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 4.4097	Cost: 14.49s
Train Epoch: 271 	Average Loss: 4.5456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8276

Learning rate: 0.0001999963758538069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 5.6938	Cost: 28.46s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 4.2305	Cost: 12.28s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 4.5750	Cost: 14.36s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 4.4554	Cost: 13.74s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 4.6154	Cost: 12.86s
Train Epoch: 272 	Average Loss: 4.5373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8403

Learning rate: 0.00019999634905815583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 5.8487	Cost: 27.43s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 4.2801	Cost: 10.71s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 4.5221	Cost: 16.71s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 4.3489	Cost: 14.07s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 4.3584	Cost: 16.08s
Train Epoch: 273 	Average Loss: 4.4933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7816

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 0.00019999632216381234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 5.7066	Cost: 35.29s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 4.2355	Cost: 13.84s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 4.6646	Cost: 15.40s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 4.3036	Cost: 15.73s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 4.2955	Cost: 13.72s
Train Epoch: 274 	Average Loss: 4.4146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7325

Saving model as e274_model.pt & e274_waveforms_supplementary.hdf5
Learning rate: 0.00019999629517077644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 5.6024	Cost: 33.27s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 4.1285	Cost: 14.68s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 4.5741	Cost: 16.11s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 4.3014	Cost: 15.33s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 4.2791	Cost: 14.14s
Train Epoch: 275 	Average Loss: 4.3679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7614

Learning rate: 0.00019999626807904816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 5.6286	Cost: 32.45s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 4.3162	Cost: 15.94s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 4.5757	Cost: 17.93s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 4.3072	Cost: 15.27s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 4.3402	Cost: 14.04s
Train Epoch: 276 	Average Loss: 4.4045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7322

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Learning rate: 0.0001999962408886275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 5.6858	Cost: 28.02s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 4.1934	Cost: 13.04s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 4.6070	Cost: 16.02s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 4.1446	Cost: 15.24s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 4.2664	Cost: 14.96s
Train Epoch: 277 	Average Loss: 4.3764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6991

Saving model as e277_model.pt & e277_waveforms_supplementary.hdf5
Learning rate: 0.00019999621359951451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 5.6673	Cost: 31.85s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 4.2636	Cost: 14.49s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 4.3901	Cost: 13.89s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 4.2392	Cost: 15.55s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 4.2397	Cost: 14.55s
Train Epoch: 278 	Average Loss: 4.3325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7004

Learning rate: 0.00019999618621170925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 5.4933	Cost: 31.40s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 4.0270	Cost: 14.15s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 4.4052	Cost: 17.17s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 4.2166	Cost: 15.04s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 4.2753	Cost: 16.39s
Train Epoch: 279 	Average Loss: 4.3147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7005

Learning rate: 0.00019999615872521166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 5.5021	Cost: 30.59s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 4.0878	Cost: 13.17s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 4.4295	Cost: 16.89s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 4.1490	Cost: 15.21s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 4.1175	Cost: 14.27s
Train Epoch: 280 	Average Loss: 4.2547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6456

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Learning rate: 0.00019999613114002183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 5.6772	Cost: 27.18s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 4.0791	Cost: 13.01s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 4.3867	Cost: 16.75s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 4.0680	Cost: 14.81s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 4.1756	Cost: 16.59s
Train Epoch: 281 	Average Loss: 4.2712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6188

Saving model as e281_model.pt & e281_waveforms_supplementary.hdf5
Learning rate: 0.0001999961034561398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 5.5558	Cost: 32.93s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 4.0612	Cost: 12.37s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 4.3874	Cost: 14.09s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 4.0900	Cost: 15.24s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 4.0655	Cost: 14.78s
Train Epoch: 282 	Average Loss: 4.2165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7049

Learning rate: 0.0001999960756735655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 5.7436	Cost: 35.82s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 4.2117	Cost: 13.00s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 4.3513	Cost: 14.53s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 3.9894	Cost: 13.67s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 4.1217	Cost: 12.94s
Train Epoch: 283 	Average Loss: 4.2600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7490

Learning rate: 0.0001999960477922991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 5.6965	Cost: 28.16s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 4.1012	Cost: 14.00s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 4.2033	Cost: 14.67s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 3.9885	Cost: 14.82s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 3.9714	Cost: 13.91s
Train Epoch: 284 	Average Loss: 4.2015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5678

Saving model as e284_model.pt & e284_waveforms_supplementary.hdf5
Learning rate: 0.00019999601981234054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 5.4383	Cost: 31.74s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 3.9309	Cost: 15.18s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 4.2697	Cost: 15.65s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 3.9686	Cost: 15.71s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 3.9422	Cost: 11.58s
Train Epoch: 285 	Average Loss: 4.1504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5300

Saving model as e285_model.pt & e285_waveforms_supplementary.hdf5
Learning rate: 0.00019999599173368987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 5.2936	Cost: 28.50s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 3.7943	Cost: 13.56s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 4.1224	Cost: 15.46s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 3.9237	Cost: 13.96s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 4.2025	Cost: 17.56s
Train Epoch: 286 	Average Loss: 4.1098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7101

Learning rate: 0.00019999596355634708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 5.3228	Cost: 28.52s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 3.8568	Cost: 13.49s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 4.1451	Cost: 14.68s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 3.9860	Cost: 14.84s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 3.8560	Cost: 13.35s
Train Epoch: 287 	Average Loss: 4.1295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4999

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Learning rate: 0.00019999593528031228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 5.4748	Cost: 31.20s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 3.7528	Cost: 13.83s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 4.2803	Cost: 16.90s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 3.8806	Cost: 11.24s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 3.8916	Cost: 16.37s
Train Epoch: 288 	Average Loss: 4.0083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4809

Saving model as e288_model.pt & e288_waveforms_supplementary.hdf5
Learning rate: 0.0001999959069055854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 5.4063	Cost: 44.87s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 3.7111	Cost: 12.23s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 4.1316	Cost: 13.96s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 3.8298	Cost: 13.19s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 3.8576	Cost: 6.78s
Train Epoch: 289 	Average Loss: 3.9575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5182

Learning rate: 0.00019999587843216654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 5.7059	Cost: 38.41s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 3.7233	Cost: 9.91s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 4.1142	Cost: 14.78s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 3.7693	Cost: 14.15s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 3.8899	Cost: 15.15s
Train Epoch: 290 	Average Loss: 3.9948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5066

Learning rate: 0.00019999584986005571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 5.3823	Cost: 29.97s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 3.8319	Cost: 15.10s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 4.0609	Cost: 14.43s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 3.8881	Cost: 14.89s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 3.9767	Cost: 13.99s
Train Epoch: 291 	Average Loss: 3.9809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4459

Saving model as e291_model.pt & e291_waveforms_supplementary.hdf5
Learning rate: 0.00019999582118925292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 5.4410	Cost: 27.82s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 3.7502	Cost: 14.40s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 4.1240	Cost: 15.58s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 3.7427	Cost: 14.75s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 3.7119	Cost: 13.63s
Train Epoch: 292 	Average Loss: 3.9449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3930

Saving model as e292_model.pt & e292_waveforms_supplementary.hdf5
Learning rate: 0.00019999579241975824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 5.2294	Cost: 31.38s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 3.6956	Cost: 13.91s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 4.0638	Cost: 15.37s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 3.6507	Cost: 14.83s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 4.0051	Cost: 12.54s
Train Epoch: 293 	Average Loss: 3.9009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5637

Learning rate: 0.00019999576355157165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 5.6187	Cost: 29.37s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 3.7524	Cost: 14.11s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 4.0499	Cost: 14.62s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 3.8725	Cost: 14.42s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 3.6926	Cost: 13.34s
Train Epoch: 294 	Average Loss: 3.9454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3464

Saving model as e294_model.pt & e294_waveforms_supplementary.hdf5
Learning rate: 0.0001999957345846932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 5.3324	Cost: 32.59s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 3.4684	Cost: 12.38s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 3.9676	Cost: 16.83s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 3.5664	Cost: 14.79s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 3.5797	Cost: 15.78s
Train Epoch: 295 	Average Loss: 3.8082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3262

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 0.0001999957055191229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 5.1271	Cost: 32.10s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 3.5306	Cost: 13.66s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 3.9389	Cost: 12.82s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 3.6156	Cost: 15.06s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 3.6278	Cost: 11.24s
Train Epoch: 296 	Average Loss: 3.7652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3252

Saving model as e296_model.pt & e296_waveforms_supplementary.hdf5
Learning rate: 0.0001999956763548608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 5.3338	Cost: 30.12s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 3.5052	Cost: 13.15s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 3.9398	Cost: 14.81s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 3.6517	Cost: 14.64s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 3.6017	Cost: 14.75s
Train Epoch: 297 	Average Loss: 3.7844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2844

Saving model as e297_model.pt & e297_waveforms_supplementary.hdf5
Learning rate: 0.00019999564709190693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 5.2359	Cost: 28.77s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 3.5943	Cost: 14.41s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 3.9772	Cost: 17.68s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 3.6177	Cost: 14.86s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 3.7642	Cost: 19.14s
Train Epoch: 298 	Average Loss: 3.8011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2714

Saving model as e298_model.pt & e298_waveforms_supplementary.hdf5
Learning rate: 0.00019999561773026132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 5.1980	Cost: 34.71s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 3.5565	Cost: 14.64s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 4.2140	Cost: 14.81s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 3.7592	Cost: 15.45s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 3.5757	Cost: 11.25s
Train Epoch: 299 	Average Loss: 3.8581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3605

Learning rate: 0.00019999558826992397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 5.5840	Cost: 27.91s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 3.7088	Cost: 13.64s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 3.9165	Cost: 15.74s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 3.6857	Cost: 14.18s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 3.7629	Cost: 14.10s
Train Epoch: 300 	Average Loss: 3.8970
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2548

Saving model as e300_model.pt & e300_waveforms_supplementary.hdf5
Learning rate: 0.00019999555871089494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 5.1872	Cost: 29.25s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 3.4039	Cost: 12.89s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 3.7800	Cost: 14.44s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 3.5708	Cost: 15.06s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 3.5400	Cost: 14.71s
Train Epoch: 301 	Average Loss: 3.6820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3232

Learning rate: 0.00019999552905317427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 5.2933	Cost: 37.22s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 3.4858	Cost: 14.80s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 3.7855	Cost: 12.65s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 3.6148	Cost: 15.42s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 3.6026	Cost: 13.88s
Train Epoch: 302 	Average Loss: 3.7011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3038

Learning rate: 0.00019999549929676196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 5.1331	Cost: 27.75s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 3.5614	Cost: 10.26s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 3.6380	Cost: 19.81s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 3.4879	Cost: 11.09s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 3.4038	Cost: 20.29s
Train Epoch: 303 	Average Loss: 3.6141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0861

Saving model as e303_model.pt & e303_waveforms_supplementary.hdf5
Learning rate: 0.00019999546944165803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 5.0858	Cost: 27.37s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 3.3448	Cost: 8.34s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 3.7051	Cost: 19.17s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 3.4716	Cost: 13.46s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 3.4650	Cost: 20.34s
Train Epoch: 304 	Average Loss: 3.6228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1601

Learning rate: 0.00019999543948786254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 4.9522	Cost: 29.19s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 3.4160	Cost: 9.83s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 3.6870	Cost: 15.27s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 3.3791	Cost: 14.57s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 3.3719	Cost: 15.37s
Train Epoch: 305 	Average Loss: 3.5520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1438

Learning rate: 0.0001999954094353755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 4.9619	Cost: 28.20s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 3.2303	Cost: 6.97s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 3.7682	Cost: 14.92s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 3.4766	Cost: 15.05s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 3.6280	Cost: 14.73s
Train Epoch: 306 	Average Loss: 3.6024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1932

Learning rate: 0.00019999537928419694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 4.9749	Cost: 26.71s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 3.2022	Cost: 7.03s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 3.5980	Cost: 13.62s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 3.2406	Cost: 15.47s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 3.4057	Cost: 14.46s
Train Epoch: 307 	Average Loss: 3.4865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0535

Saving model as e307_model.pt & e307_waveforms_supplementary.hdf5
Learning rate: 0.00019999534903432692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 4.9771	Cost: 32.86s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 3.2993	Cost: 14.50s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 3.5256	Cost: 14.64s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 3.2963	Cost: 14.99s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 3.4868	Cost: 14.54s
Train Epoch: 308 	Average Loss: 3.4802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1016

Learning rate: 0.00019999531868576542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 5.0378	Cost: 30.31s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 3.1322	Cost: 9.92s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 3.5390	Cost: 14.49s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 3.2944	Cost: 13.28s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 3.2665	Cost: 19.09s
Train Epoch: 309 	Average Loss: 3.4102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9707

Saving model as e309_model.pt & e309_waveforms_supplementary.hdf5
Learning rate: 0.00019999528823851252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 5.0451	Cost: 30.17s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 3.1008	Cost: 14.14s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 3.4695	Cost: 18.84s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 3.2505	Cost: 13.91s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 3.3267	Cost: 21.15s
Train Epoch: 310 	Average Loss: 3.3513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0330

Learning rate: 0.00019999525769256822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 4.8515	Cost: 31.99s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 3.0049	Cost: 13.85s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 3.4987	Cost: 25.85s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 3.2224	Cost: 12.62s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 3.2892	Cost: 15.97s
Train Epoch: 311 	Average Loss: 3.3287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8635

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Learning rate: 0.00019999522704793255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 4.9592	Cost: 35.55s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 3.0075	Cost: 12.86s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 3.4228	Cost: 15.06s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 3.1005	Cost: 15.09s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 3.2265	Cost: 10.53s
Train Epoch: 312 	Average Loss: 3.3129
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0745

Learning rate: 0.00019999519630460553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 4.8294	Cost: 33.73s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 3.1079	Cost: 14.16s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 3.4845	Cost: 13.69s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 3.3257	Cost: 16.18s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 3.3204	Cost: 11.14s
Train Epoch: 313 	Average Loss: 3.3793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0547

Learning rate: 0.00019999516546258725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 5.0614	Cost: 28.62s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 3.0362	Cost: 14.66s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 3.4094	Cost: 14.71s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 3.2013	Cost: 15.17s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 3.2257	Cost: 18.21s
Train Epoch: 314 	Average Loss: 3.3089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9524

Learning rate: 0.00019999513452187764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 4.9481	Cost: 32.55s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 3.0395	Cost: 14.56s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 3.1999	Cost: 14.10s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 3.0137	Cost: 13.52s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 3.1548	Cost: 14.45s
Train Epoch: 315 	Average Loss: 3.2597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9352

Learning rate: 0.0001999951034824768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 4.5482	Cost: 29.34s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 3.2010	Cost: 10.74s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 3.3865	Cost: 19.14s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 3.1365	Cost: 14.21s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 3.0744	Cost: 20.77s
Train Epoch: 316 	Average Loss: 3.2174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8048

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 0.00019999507234438478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 4.8172	Cost: 33.88s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 2.8623	Cost: 15.01s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 3.2930	Cost: 23.48s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 3.0646	Cost: 13.20s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 2.9587	Cost: 12.80s
Train Epoch: 317 	Average Loss: 3.1517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7711

Saving model as e317_model.pt & e317_waveforms_supplementary.hdf5
Learning rate: 0.00019999504110760157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 4.6745	Cost: 37.30s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 2.8652	Cost: 13.66s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 3.2787	Cost: 20.44s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 2.8483	Cost: 12.58s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 3.0168	Cost: 15.98s
Train Epoch: 318 	Average Loss: 3.1313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8067

Learning rate: 0.0001999950097721272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 4.5625	Cost: 33.36s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 2.8699	Cost: 14.26s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 3.3343	Cost: 16.22s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 2.9648	Cost: 14.08s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 2.8811	Cost: 15.16s
Train Epoch: 319 	Average Loss: 3.0723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8541

Learning rate: 0.00019999497833796175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 4.6198	Cost: 27.20s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 2.7764	Cost: 8.83s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 3.1343	Cost: 15.06s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 2.8569	Cost: 14.51s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 2.9285	Cost: 15.30s
Train Epoch: 320 	Average Loss: 3.0477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7498

Saving model as e320_model.pt & e320_waveforms_supplementary.hdf5
Learning rate: 0.00019999494680510515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 4.6747	Cost: 30.55s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 2.7140	Cost: 12.80s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 3.3252	Cost: 14.95s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 2.9445	Cost: 14.92s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 3.0027	Cost: 14.40s
Train Epoch: 321 	Average Loss: 3.1053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7859

Learning rate: 0.00019999491517355754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 4.7058	Cost: 32.30s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 2.8857	Cost: 14.02s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 3.2832	Cost: 16.22s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 2.9080	Cost: 15.14s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 2.9342	Cost: 16.44s
Train Epoch: 322 	Average Loss: 3.0825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7879

Learning rate: 0.00019999488344331888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 4.7204	Cost: 30.02s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 2.7912	Cost: 13.58s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 3.2250	Cost: 14.94s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 2.9193	Cost: 15.41s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 2.7301	Cost: 19.75s
Train Epoch: 323 	Average Loss: 3.0005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7402

Saving model as e323_model.pt & e323_waveforms_supplementary.hdf5
Learning rate: 0.00019999485161438922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 4.5608	Cost: 37.30s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 2.5494	Cost: 14.74s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 3.0702	Cost: 15.27s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 2.6101	Cost: 14.87s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 2.8634	Cost: 12.98s
Train Epoch: 324 	Average Loss: 2.9111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6649

Saving model as e324_model.pt & e324_waveforms_supplementary.hdf5
Learning rate: 0.0001999948196867686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 4.7716	Cost: 34.52s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 2.7833	Cost: 13.73s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 3.0615	Cost: 16.07s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 2.8804	Cost: 13.48s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 2.6349	Cost: 16.40s
Train Epoch: 325 	Average Loss: 2.9480
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7208

Learning rate: 0.00019999478766045706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 4.7200	Cost: 41.48s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 2.5894	Cost: 11.63s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 2.9889	Cost: 19.62s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 2.6465	Cost: 11.03s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 2.7488	Cost: 14.70s
Train Epoch: 326 	Average Loss: 2.8741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6539

Saving model as e326_model.pt & e326_waveforms_supplementary.hdf5
Learning rate: 0.00019999475553545462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 4.7184	Cost: 30.44s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 2.5790	Cost: 13.99s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 3.0862	Cost: 15.86s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 2.6504	Cost: 14.85s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 2.6537	Cost: 17.13s
Train Epoch: 327 	Average Loss: 2.8581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5745

Saving model as e327_model.pt & e327_waveforms_supplementary.hdf5
Learning rate: 0.0001999947233117613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 4.4854	Cost: 31.09s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 2.4524	Cost: 14.69s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 2.9721	Cost: 15.35s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 2.8529	Cost: 14.95s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 2.9917	Cost: 15.82s
Train Epoch: 328 	Average Loss: 2.9468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7295

Learning rate: 0.00019999469098937715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 4.7936	Cost: 38.93s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 2.7260	Cost: 14.19s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 3.1808	Cost: 16.82s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 2.6278	Cost: 13.90s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 2.5738	Cost: 15.92s
Train Epoch: 329 	Average Loss: 2.9121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5387

Saving model as e329_model.pt & e329_waveforms_supplementary.hdf5
Learning rate: 0.00019999465856830218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 4.4481	Cost: 40.62s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 2.5965	Cost: 14.18s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 2.9697	Cost: 25.16s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 2.5239	Cost: 11.66s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 2.6264	Cost: 10.64s
Train Epoch: 330 	Average Loss: 2.8160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5901

Learning rate: 0.00019999462604853647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 4.4500	Cost: 32.75s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 2.4471	Cost: 15.80s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 3.0205	Cost: 18.07s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 2.8399	Cost: 14.37s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 2.6424	Cost: 12.40s
Train Epoch: 331 	Average Loss: 2.8159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6165

Learning rate: 0.00019999459343008003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 4.5158	Cost: 26.76s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 2.4759	Cost: 8.32s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 2.9367	Cost: 18.26s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 2.8036	Cost: 13.35s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 2.6739	Cost: 17.72s
Train Epoch: 332 	Average Loss: 2.7830
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6175

Learning rate: 0.00019999456071293284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 4.4867	Cost: 30.53s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 2.4359	Cost: 7.69s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 3.0091	Cost: 12.24s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 2.9993	Cost: 14.24s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 2.9448	Cost: 14.91s
Train Epoch: 333 	Average Loss: 2.9146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5852

Learning rate: 0.00019999452789709498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 4.8875	Cost: 29.05s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 2.5502	Cost: 10.30s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 2.7995	Cost: 12.13s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 2.5840	Cost: 12.04s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 2.4985	Cost: 13.71s
Train Epoch: 334 	Average Loss: 2.7142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4156

Saving model as e334_model.pt & e334_waveforms_supplementary.hdf5
Learning rate: 0.0001999944949825665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 4.0769	Cost: 31.24s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 2.2603	Cost: 10.78s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 2.7608	Cost: 12.17s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 2.4424	Cost: 12.01s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 2.4844	Cost: 13.80s
Train Epoch: 335 	Average Loss: 2.6022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4842

Learning rate: 0.0001999944619693474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 4.2604	Cost: 28.10s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 2.4123	Cost: 8.62s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 2.7574	Cost: 12.28s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 2.5066	Cost: 12.24s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 2.5396	Cost: 12.84s
Train Epoch: 336 	Average Loss: 2.6721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6063

Learning rate: 0.00019999442885743776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 4.5486	Cost: 30.45s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 2.3748	Cost: 7.02s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 2.7772	Cost: 12.69s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 2.6261	Cost: 12.09s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 2.6015	Cost: 12.75s
Train Epoch: 337 	Average Loss: 2.7176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4010

Saving model as e337_model.pt & e337_waveforms_supplementary.hdf5
Learning rate: 0.00019999439564683753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 4.2378	Cost: 30.49s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 2.2778	Cost: 11.99s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 2.7262	Cost: 13.24s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 2.4133	Cost: 13.61s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 2.3418	Cost: 13.06s
Train Epoch: 338 	Average Loss: 2.5579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4217

Learning rate: 0.0001999943623375468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 4.3530	Cost: 31.79s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 2.2503	Cost: 13.98s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 2.6334	Cost: 14.71s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 2.3154	Cost: 13.29s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 2.3827	Cost: 10.18s
Train Epoch: 339 	Average Loss: 2.5128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3712

Saving model as e339_model.pt & e339_waveforms_supplementary.hdf5
Learning rate: 0.0001999943289295656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 4.0768	Cost: 27.49s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 2.2168	Cost: 12.16s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 2.6586	Cost: 15.46s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 2.3802	Cost: 13.14s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 2.3788	Cost: 10.31s
Train Epoch: 340 	Average Loss: 2.4964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3682

Saving model as e340_model.pt & e340_waveforms_supplementary.hdf5
Learning rate: 0.00019999429542289394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 4.4667	Cost: 34.55s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 2.2435	Cost: 12.09s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 2.5575	Cost: 12.16s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 2.2660	Cost: 12.66s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 2.2296	Cost: 12.08s
Train Epoch: 341 	Average Loss: 2.4540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2911

Saving model as e341_model.pt & e341_waveforms_supplementary.hdf5
Learning rate: 0.00019999426181753187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 3.8746	Cost: 33.59s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 2.1647	Cost: 7.61s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 2.5464	Cost: 11.83s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 2.1487	Cost: 12.11s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 2.2149	Cost: 12.16s
Train Epoch: 342 	Average Loss: 2.3596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2524

Saving model as e342_model.pt & e342_waveforms_supplementary.hdf5
Learning rate: 0.0001999942281134794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 4.2161	Cost: 34.14s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 1.9728	Cost: 8.91s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 2.4872	Cost: 16.22s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 2.1491	Cost: 11.70s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 2.2503	Cost: 11.87s
Train Epoch: 343 	Average Loss: 2.3479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3090

Learning rate: 0.0001999941943107366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 4.2346	Cost: 25.78s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 2.0590	Cost: 7.74s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 2.6137	Cost: 14.32s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 2.3297	Cost: 12.32s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 2.3324	Cost: 12.03s
Train Epoch: 344 	Average Loss: 2.4419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4702

Learning rate: 0.00019999416040930349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 4.2884	Cost: 30.79s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 2.1817	Cost: 8.59s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 2.6564	Cost: 12.05s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 2.3208	Cost: 12.10s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 2.2889	Cost: 12.09s
Train Epoch: 345 	Average Loss: 2.4533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2458

Saving model as e345_model.pt & e345_waveforms_supplementary.hdf5
Learning rate: 0.0001999941264091801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 4.2242	Cost: 32.50s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 2.2520	Cost: 12.53s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 2.5718	Cost: 13.15s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 2.2732	Cost: 12.61s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 2.2493	Cost: 12.49s
Train Epoch: 346 	Average Loss: 2.4337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3281

Learning rate: 0.00019999409231036646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 4.1881	Cost: 29.05s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 2.1737	Cost: 11.38s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 2.3346	Cost: 13.94s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 2.1829	Cost: 14.35s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 2.1563	Cost: 15.60s
Train Epoch: 347 	Average Loss: 2.3439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3475

Learning rate: 0.0001999940581128626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 4.2010	Cost: 30.15s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 2.0901	Cost: 9.56s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 2.4620	Cost: 12.91s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 2.2158	Cost: 12.73s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 2.3011	Cost: 15.19s
Train Epoch: 348 	Average Loss: 2.3662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2264

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Learning rate: 0.00019999402381666855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 4.2013	Cost: 30.30s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 1.9305	Cost: 12.91s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 2.3495	Cost: 13.03s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 2.1623	Cost: 12.50s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 2.1643	Cost: 12.14s
Train Epoch: 349 	Average Loss: 2.2968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2508

Learning rate: 0.0001999939894217844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 3.8869	Cost: 29.10s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 2.1057	Cost: 13.92s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 2.3472	Cost: 16.90s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 2.1805	Cost: 13.35s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 2.0947	Cost: 12.22s
Train Epoch: 350 	Average Loss: 2.2746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1329

Saving model as e350_model.pt & e350_waveforms_supplementary.hdf5
Learning rate: 0.0001999939549282101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 4.4733	Cost: 28.74s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 2.0893	Cost: 15.19s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 2.4492	Cost: 14.37s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 2.0825	Cost: 13.95s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 2.1612	Cost: 12.19s
Train Epoch: 351 	Average Loss: 2.2506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1425

Learning rate: 0.00019999392033594573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 3.9809	Cost: 33.62s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 1.9049	Cost: 11.67s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 2.3123	Cost: 14.48s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 1.9544	Cost: 14.17s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 1.9608	Cost: 12.80s
Train Epoch: 352 	Average Loss: 2.1523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1247

Saving model as e352_model.pt & e352_waveforms_supplementary.hdf5
Learning rate: 0.0001999938856449913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 3.9270	Cost: 58.66s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 1.9167	Cost: 12.57s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 2.1971	Cost: 16.94s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 1.8704	Cost: 12.03s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 1.9090	Cost: 11.88s
Train Epoch: 353 	Average Loss: 2.1055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0192

Saving model as e353_model.pt & e353_waveforms_supplementary.hdf5
Learning rate: 0.00019999385085534688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 4.1098	Cost: 61.89s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 1.7037	Cost: 12.44s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 2.1819	Cost: 12.33s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 2.0580	Cost: 11.79s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 1.9153	Cost: 11.96s
Train Epoch: 354 	Average Loss: 2.0869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0855

Learning rate: 0.00019999381596701247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 3.5310	Cost: 40.06s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 1.6869	Cost: 10.16s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 2.1335	Cost: 12.24s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 1.7574	Cost: 11.97s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 1.8516	Cost: 10.11s
Train Epoch: 355 	Average Loss: 1.9972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0746

Learning rate: 0.00019999378097998813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 4.0708	Cost: 29.94s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 1.7171	Cost: 7.22s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 2.1275	Cost: 12.25s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 1.8686	Cost: 12.54s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 1.9093	Cost: 10.12s
Train Epoch: 356 	Average Loss: 2.0315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9248

Saving model as e356_model.pt & e356_waveforms_supplementary.hdf5
Learning rate: 0.00019999374589427387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 3.8251	Cost: 28.04s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 1.7370	Cost: 7.21s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 2.0303	Cost: 12.98s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 2.3181	Cost: 11.93s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 2.2678	Cost: 9.96s
Train Epoch: 357 	Average Loss: 2.1878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5700

Learning rate: 0.00019999371070986973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 4.4248	Cost: 27.35s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 2.2325	Cost: 10.30s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 2.4204	Cost: 12.16s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 1.9621	Cost: 12.12s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 2.0091	Cost: 11.24s
Train Epoch: 358 	Average Loss: 2.3276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1532

Learning rate: 0.00019999367542677577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 3.9345	Cost: 27.86s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 1.6917	Cost: 9.54s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 2.0182	Cost: 12.83s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 1.7615	Cost: 11.90s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 1.7027	Cost: 10.05s
Train Epoch: 359 	Average Loss: 1.9497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7971

Saving model as e359_model.pt & e359_waveforms_supplementary.hdf5
Learning rate: 0.00019999364004499203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 3.7917	Cost: 27.64s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 1.4669	Cost: 9.84s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 1.9641	Cost: 12.47s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 1.6573	Cost: 12.07s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 1.7629	Cost: 8.31s
Train Epoch: 360 	Average Loss: 1.8686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9837

Learning rate: 0.0001999936045645185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 3.9293	Cost: 27.25s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 1.5002	Cost: 11.66s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 2.2384	Cost: 12.63s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 1.8609	Cost: 12.00s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 1.7066	Cost: 9.52s
Train Epoch: 361 	Average Loss: 1.9290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9122

Learning rate: 0.00019999356898535523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 3.9341	Cost: 27.15s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 1.6065	Cost: 12.10s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 1.9121	Cost: 12.00s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 1.8344	Cost: 12.05s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 1.8593	Cost: 11.31s
Train Epoch: 362 	Average Loss: 1.9832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9081

Learning rate: 0.0001999935333075023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 3.9924	Cost: 31.45s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 1.6421	Cost: 11.33s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 2.1000	Cost: 12.87s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 1.7391	Cost: 12.31s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 1.7112	Cost: 12.09s
Train Epoch: 363 	Average Loss: 1.8808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7994

Learning rate: 0.0001999934975309597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 3.8793	Cost: 41.14s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 1.4555	Cost: 11.23s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 1.9535	Cost: 13.92s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 1.7854	Cost: 12.65s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 1.7119	Cost: 10.86s
Train Epoch: 364 	Average Loss: 1.8352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8916

Learning rate: 0.00019999346165572743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 3.8437	Cost: 30.24s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 1.6156	Cost: 12.98s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 1.9293	Cost: 15.15s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 1.8105	Cost: 15.98s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 1.7929	Cost: 15.14s
Train Epoch: 365 	Average Loss: 1.9047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9723

Learning rate: 0.00019999342568180562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 4.0294	Cost: 34.58s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 1.7815	Cost: 7.93s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 2.1499	Cost: 17.22s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 1.7610	Cost: 15.59s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 1.7649	Cost: 11.34s
Train Epoch: 366 	Average Loss: 1.9900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8958

Learning rate: 0.00019999338960919423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 3.7967	Cost: 31.84s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 1.5783	Cost: 11.42s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 1.9834	Cost: 14.57s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 1.6512	Cost: 15.45s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 1.4996	Cost: 13.85s
Train Epoch: 367 	Average Loss: 1.8090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7201

Saving model as e367_model.pt & e367_waveforms_supplementary.hdf5
Learning rate: 0.0001999933534378933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 3.6019	Cost: 29.73s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 1.5255	Cost: 11.30s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 2.0886	Cost: 12.29s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 1.7867	Cost: 14.20s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 1.9249	Cost: 14.15s
Train Epoch: 368 	Average Loss: 1.8904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0367

Learning rate: 0.00019999331716790292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 3.8502	Cost: 31.38s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 1.5333	Cost: 12.31s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 1.8909	Cost: 11.97s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 1.6947	Cost: 12.40s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 1.6661	Cost: 14.44s
Train Epoch: 369 	Average Loss: 1.8341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9074

Learning rate: 0.00019999328079922307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 3.5531	Cost: 34.50s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 1.7701	Cost: 11.90s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 2.2203	Cost: 11.43s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 1.6344	Cost: 12.94s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 1.5477	Cost: 12.88s
Train Epoch: 370 	Average Loss: 1.9454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8056

Learning rate: 0.00019999324433185383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 3.7400	Cost: 33.91s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 1.4069	Cost: 11.53s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 1.7235	Cost: 11.77s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 1.5921	Cost: 14.04s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 1.4999	Cost: 12.83s
Train Epoch: 371 	Average Loss: 1.6837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7481

Learning rate: 0.0001999932077657952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 3.5704	Cost: 30.77s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 1.3546	Cost: 8.74s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 1.7725	Cost: 13.21s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 1.5265	Cost: 14.23s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 1.5299	Cost: 12.92s
Train Epoch: 372 	Average Loss: 1.6541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7538

Learning rate: 0.00019999317110104724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 3.9439	Cost: 32.75s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 1.1852	Cost: 11.48s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 1.7682	Cost: 12.99s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 1.3193	Cost: 13.81s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 1.3837	Cost: 12.99s
Train Epoch: 373 	Average Loss: 1.5634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6257

Saving model as e373_model.pt & e373_waveforms_supplementary.hdf5
Learning rate: 0.00019999313433760997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 3.2779	Cost: 36.19s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 1.3338	Cost: 12.43s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 1.6617	Cost: 15.46s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 1.3461	Cost: 14.34s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 1.4256	Cost: 13.13s
Train Epoch: 374 	Average Loss: 1.5232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5896

Saving model as e374_model.pt & e374_waveforms_supplementary.hdf5
Learning rate: 0.00019999309747548342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 3.6787	Cost: 33.13s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 1.2271	Cost: 13.22s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 1.7237	Cost: 14.26s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 1.4582	Cost: 14.25s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 1.3478	Cost: 10.85s
Train Epoch: 375 	Average Loss: 1.5486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6442

Learning rate: 0.00019999306051466764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 3.4829	Cost: 33.73s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 1.1700	Cost: 13.96s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 1.5590	Cost: 14.99s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 1.3347	Cost: 16.51s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 1.2887	Cost: 11.18s
Train Epoch: 376 	Average Loss: 1.5305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5841

Saving model as e376_model.pt & e376_waveforms_supplementary.hdf5
Learning rate: 0.0001999930234551627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 3.6875	Cost: 29.05s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 1.1891	Cost: 12.98s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 1.5946	Cost: 16.10s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 1.2303	Cost: 16.11s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 1.2122	Cost: 15.32s
Train Epoch: 377 	Average Loss: 1.4551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5346

Saving model as e377_model.pt & e377_waveforms_supplementary.hdf5
Learning rate: 0.00019999298629696857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 3.3267	Cost: 29.41s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 1.0467	Cost: 12.73s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 1.5188	Cost: 14.76s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 1.3563	Cost: 15.22s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 1.2396	Cost: 14.74s
Train Epoch: 378 	Average Loss: 1.4108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5966

Learning rate: 0.00019999294904008533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 3.2667	Cost: 33.25s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 1.1489	Cost: 12.31s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 1.4295	Cost: 12.05s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 1.2918	Cost: 15.60s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 1.2519	Cost: 17.19s
Train Epoch: 379 	Average Loss: 1.4023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5953

Learning rate: 0.000199992911684513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 3.6123	Cost: 30.74s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 1.1947	Cost: 12.60s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 1.4132	Cost: 12.57s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 1.1495	Cost: 14.78s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 0.9842	Cost: 14.56s
Train Epoch: 380 	Average Loss: 1.3992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5510

Learning rate: 0.0001999928742302516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 3.2469	Cost: 40.02s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 0.9280	Cost: 11.79s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 1.3218	Cost: 14.20s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 1.0402	Cost: 13.90s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 1.2583	Cost: 12.28s
Train Epoch: 381 	Average Loss: 1.3166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7411

Learning rate: 0.00019999283667730122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 3.6753	Cost: 33.86s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 1.4296	Cost: 13.38s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 1.9481	Cost: 14.97s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 1.4666	Cost: 15.66s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 1.5611	Cost: 13.41s
Train Epoch: 382 	Average Loss: 1.6958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6239

Learning rate: 0.00019999279902566184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 3.5519	Cost: 40.13s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 1.3446	Cost: 11.23s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 1.7718	Cost: 15.43s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 1.4046	Cost: 15.46s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 1.2303	Cost: 11.97s
Train Epoch: 383 	Average Loss: 1.5507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4726

Saving model as e383_model.pt & e383_waveforms_supplementary.hdf5
Learning rate: 0.0001999927612753335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 3.3463	Cost: 38.56s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 1.0322	Cost: 11.26s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 1.4012	Cost: 15.17s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 1.1733	Cost: 13.12s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 1.1212	Cost: 14.93s
Train Epoch: 384 	Average Loss: 1.2857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4638

Saving model as e384_model.pt & e384_waveforms_supplementary.hdf5
Learning rate: 0.00019999272342631632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 3.4396	Cost: 28.93s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 1.0223	Cost: 13.49s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 1.3748	Cost: 16.44s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 0.9843	Cost: 15.52s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 0.8949	Cost: 13.70s
Train Epoch: 385 	Average Loss: 1.2430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3833

Saving model as e385_model.pt & e385_waveforms_supplementary.hdf5
Learning rate: 0.00019999268547861025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 3.2184	Cost: 29.32s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 0.8778	Cost: 6.18s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 1.2284	Cost: 14.37s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 0.9491	Cost: 14.76s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 0.9629	Cost: 15.54s
Train Epoch: 386 	Average Loss: 1.1409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3312

Saving model as e386_model.pt & e386_waveforms_supplementary.hdf5
Learning rate: 0.00019999264743221536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 3.3785	Cost: 30.17s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 0.7214	Cost: 11.34s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 2.4571	Cost: 12.80s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 1.9777	Cost: 12.48s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 1.6292	Cost: 14.13s
Train Epoch: 387 	Average Loss: 1.7155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8402

Learning rate: 0.00019999260928713167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 3.9498	Cost: 31.01s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 1.2613	Cost: 12.98s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 1.5803	Cost: 13.41s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 1.2617	Cost: 12.08s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 1.2288	Cost: 13.32s
Train Epoch: 388 	Average Loss: 1.5045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4753

Learning rate: 0.00019999257104335924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 3.3232	Cost: 41.53s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 0.9491	Cost: 11.41s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 1.3163	Cost: 20.57s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 1.0996	Cost: 14.03s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 1.0564	Cost: 8.00s
Train Epoch: 389 	Average Loss: 1.1901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3178

Saving model as e389_model.pt & e389_waveforms_supplementary.hdf5
Learning rate: 0.00019999253270089811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 3.1542	Cost: 31.52s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 0.8194	Cost: 11.03s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 1.1205	Cost: 16.04s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 0.8409	Cost: 14.08s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 0.9738	Cost: 17.55s
Train Epoch: 390 	Average Loss: 1.0730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3716

Learning rate: 0.0001999924942597483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 3.0739	Cost: 37.51s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 0.5978	Cost: 9.39s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 1.1648	Cost: 12.17s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 0.8262	Cost: 14.96s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 0.9850	Cost: 13.29s
Train Epoch: 391 	Average Loss: 1.0369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3884

Learning rate: 0.00019999245571990988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 3.5488	Cost: 36.34s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 0.8498	Cost: 12.13s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 1.2107	Cost: 12.63s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 0.9715	Cost: 12.68s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 0.9276	Cost: 12.29s
Train Epoch: 392 	Average Loss: 1.1560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2979

Saving model as e392_model.pt & e392_waveforms_supplementary.hdf5
Learning rate: 0.00019999241708138285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 3.1801	Cost: 34.39s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 1.6494	Cost: 11.33s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 1.8463	Cost: 14.74s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 1.6430	Cost: 15.27s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 1.4652	Cost: 11.18s
Train Epoch: 393 	Average Loss: 1.6821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6693

Learning rate: 0.00019999237834416724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 3.7121	Cost: 36.32s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 1.2996	Cost: 14.64s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 1.4950	Cost: 15.11s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 1.0346	Cost: 15.06s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 0.9435	Cost: 14.54s
Train Epoch: 394 	Average Loss: 1.3355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3468

Learning rate: 0.0001999923395082631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 3.4390	Cost: 34.15s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 0.8184	Cost: 15.47s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 1.2164	Cost: 20.23s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 0.9158	Cost: 12.77s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 0.9117	Cost: 14.34s
Train Epoch: 395 	Average Loss: 1.1156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2776

Saving model as e395_model.pt & e395_waveforms_supplementary.hdf5
Learning rate: 0.0001999923005736705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 3.3818	Cost: 28.93s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 0.8175	Cost: 10.27s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 1.1996	Cost: 12.26s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 0.8752	Cost: 14.75s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 0.8694	Cost: 15.62s
Train Epoch: 396 	Average Loss: 1.1084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2498

Saving model as e396_model.pt & e396_waveforms_supplementary.hdf5
Learning rate: 0.00019999226154038944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 2.9734	Cost: 40.34s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 0.5955	Cost: 7.12s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 1.0303	Cost: 12.08s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 0.6647	Cost: 11.81s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 0.8514	Cost: 12.53s
Train Epoch: 397 	Average Loss: 0.9552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2224

Saving model as e397_model.pt & e397_waveforms_supplementary.hdf5
Learning rate: 0.00019999222240841996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 3.2797	Cost: 26.91s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 0.6361	Cost: 12.85s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 1.0318	Cost: 12.11s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 0.8103	Cost: 11.83s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 0.8547	Cost: 11.85s
Train Epoch: 398 	Average Loss: 0.9816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2827

Learning rate: 0.00019999218317776212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 3.1257	Cost: 26.47s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 0.5651	Cost: 9.65s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 1.4004	Cost: 12.59s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 1.2073	Cost: 12.09s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 1.1471	Cost: 11.82s
Train Epoch: 399 	Average Loss: 1.1728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3882

Learning rate: 0.00019999214384841597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 3.3904	Cost: 29.14s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 0.8535	Cost: 7.20s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 1.1958	Cost: 13.22s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 0.7141	Cost: 11.93s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 0.8279	Cost: 12.03s
Train Epoch: 400 	Average Loss: 1.0464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2597

Learning rate: 0.00019999210442038154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 3.0116	Cost: 29.36s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 0.4667	Cost: 11.41s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 0.9950	Cost: 12.23s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 0.5373	Cost: 11.91s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 0.4402	Cost: 12.43s
Train Epoch: 401 	Average Loss: 0.7886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0838

Saving model as e401_model.pt & e401_waveforms_supplementary.hdf5
Learning rate: 0.00019999206489365883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 2.8947	Cost: 30.07s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 0.6148	Cost: 13.44s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 1.0085	Cost: 13.67s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 0.5768	Cost: 12.42s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 0.4800	Cost: 12.03s
Train Epoch: 402 	Average Loss: 0.7993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1356

Learning rate: 0.0001999920252682479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 2.8799	Cost: 29.67s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 0.6887	Cost: 14.10s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 1.1020	Cost: 14.73s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 0.7940	Cost: 13.19s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 0.5408	Cost: 17.80s
Train Epoch: 403 	Average Loss: 0.9152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0342

Saving model as e403_model.pt & e403_waveforms_supplementary.hdf5
Learning rate: 0.00019999198554414882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 2.9468	Cost: 28.62s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 0.4979	Cost: 14.07s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 0.8630	Cost: 14.13s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 0.5751	Cost: 14.67s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 0.5121	Cost: 13.72s
Train Epoch: 404 	Average Loss: 0.7289
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9605

Saving model as e404_model.pt & e404_waveforms_supplementary.hdf5
Learning rate: 0.0001999919457213616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 3.1710	Cost: 28.22s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 0.3785	Cost: 13.25s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 0.8660	Cost: 15.19s
Train Epoch: 405 [61440/90000 (68%)]	Loss: 0.3989	Cost: 14.05s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 0.4540	Cost: 17.83s
Train Epoch: 405 	Average Loss: 0.6768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9454

Saving model as e405_model.pt & e405_waveforms_supplementary.hdf5
Learning rate: 0.00019999190579988627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 2.8912	Cost: 29.38s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 0.1977	Cost: 14.41s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 0.7094	Cost: 14.82s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 0.4043	Cost: 13.67s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 0.3199	Cost: 15.39s
Train Epoch: 406 	Average Loss: 0.6134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8894

Saving model as e406_model.pt & e406_waveforms_supplementary.hdf5
Learning rate: 0.0001999918657797229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 2.7952	Cost: 34.24s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 0.2879	Cost: 14.55s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 0.7424	Cost: 16.03s
Train Epoch: 407 [61440/90000 (68%)]	Loss: 0.3324	Cost: 14.83s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 0.3030	Cost: 13.92s
Train Epoch: 407 	Average Loss: 0.6069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8162

Saving model as e407_model.pt & e407_waveforms_supplementary.hdf5
Learning rate: 0.00019999182566087152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 2.8677	Cost: 35.46s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 0.2999	Cost: 14.91s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 0.5982	Cost: 15.80s
Train Epoch: 408 [61440/90000 (68%)]	Loss: 0.4132	Cost: 14.35s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 0.6369	Cost: 13.70s
Train Epoch: 408 	Average Loss: 0.6010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0270

Learning rate: 0.00019999178544333215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 2.7431	Cost: 28.89s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 0.4791	Cost: 12.57s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 0.8478	Cost: 15.02s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 0.5394	Cost: 15.01s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 0.4394	Cost: 16.32s
Train Epoch: 409 	Average Loss: 0.6908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9962

Learning rate: 0.00019999174512710485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 2.5964	Cost: 30.15s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 0.3107	Cost: 8.78s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 0.5714	Cost: 13.71s
Train Epoch: 410 [61440/90000 (68%)]	Loss: 0.3229	Cost: 14.71s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 0.4149	Cost: 16.22s
Train Epoch: 410 	Average Loss: 0.5508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9149

Learning rate: 0.00019999170471218965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 2.9473	Cost: 28.62s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 0.3073	Cost: 13.08s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 1.0642	Cost: 17.33s
Train Epoch: 411 [61440/90000 (68%)]	Loss: 0.6817	Cost: 14.99s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 0.6912	Cost: 17.01s
Train Epoch: 411 	Average Loss: 0.7848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0061

Learning rate: 0.0001999916641985866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 2.9826	Cost: 28.17s
Train Epoch: 412 [20480/90000 (23%)]	Loss: 0.5228	Cost: 12.26s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 0.7518	Cost: 17.82s
Train Epoch: 412 [61440/90000 (68%)]	Loss: 0.5274	Cost: 14.30s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 0.4333	Cost: 15.69s
Train Epoch: 412 	Average Loss: 0.7042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9802

Learning rate: 0.00019999162358629572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 2.5990	Cost: 29.25s
Train Epoch: 413 [20480/90000 (23%)]	Loss: 0.5336	Cost: 12.93s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 0.8919	Cost: 20.53s
Train Epoch: 413 [61440/90000 (68%)]	Loss: 0.3932	Cost: 15.08s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 0.2022	Cost: 19.06s
Train Epoch: 413 	Average Loss: 0.7085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8959

Learning rate: 0.0001999915828753171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 2.8267	Cost: 31.66s
Train Epoch: 414 [20480/90000 (23%)]	Loss: 0.0082	Cost: 15.12s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 0.5786	Cost: 14.95s
Train Epoch: 414 [61440/90000 (68%)]	Loss: 0.3036	Cost: 16.14s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 0.3040	Cost: 18.00s
Train Epoch: 414 	Average Loss: 0.4770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9285

Learning rate: 0.0001999915420656507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 2.9692	Cost: 27.11s
Train Epoch: 415 [20480/90000 (23%)]	Loss: 0.2136	Cost: 9.86s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 0.5478	Cost: 18.73s
Train Epoch: 415 [61440/90000 (68%)]	Loss: 0.2934	Cost: 14.46s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 0.2043	Cost: 20.92s
Train Epoch: 415 	Average Loss: 0.4298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8329

Learning rate: 0.0001999915011572966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 2.7904	Cost: 28.75s
Train Epoch: 416 [20480/90000 (23%)]	Loss: 0.1290	Cost: 13.80s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 0.5243	Cost: 14.58s
Train Epoch: 416 [61440/90000 (68%)]	Loss: 0.3031	Cost: 14.45s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 0.4001	Cost: 16.60s
Train Epoch: 416 	Average Loss: 0.4901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9038

Learning rate: 0.0001999914601502549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 2.6630	Cost: 27.61s
Train Epoch: 417 [20480/90000 (23%)]	Loss: 0.2425	Cost: 8.65s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 0.6895	Cost: 18.12s
Train Epoch: 417 [61440/90000 (68%)]	Loss: 0.5682	Cost: 11.93s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 0.3101	Cost: 18.69s
Train Epoch: 417 	Average Loss: 0.5689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7937

Saving model as e417_model.pt & e417_waveforms_supplementary.hdf5
Learning rate: 0.00019999141904452554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 2.7064	Cost: 28.80s
Train Epoch: 418 [20480/90000 (23%)]	Loss: 0.2283	Cost: 10.22s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 0.6752	Cost: 14.72s
Train Epoch: 418 [61440/90000 (68%)]	Loss: 0.2365	Cost: 14.83s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 0.1044	Cost: 24.40s
Train Epoch: 418 	Average Loss: 0.4651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7320

Saving model as e418_model.pt & e418_waveforms_supplementary.hdf5
Learning rate: 0.0001999913778401086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 2.8556	Cost: 32.69s
Train Epoch: 419 [20480/90000 (23%)]	Loss: -0.0131	Cost: 13.17s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 0.4022	Cost: 14.87s
Train Epoch: 419 [61440/90000 (68%)]	Loss: 0.0928	Cost: 14.87s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 0.0725	Cost: 14.47s
Train Epoch: 419 	Average Loss: 0.3530
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6967

Saving model as e419_model.pt & e419_waveforms_supplementary.hdf5
Learning rate: 0.00019999133653700416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 2.6074	Cost: 31.19s
Train Epoch: 420 [20480/90000 (23%)]	Loss: -0.1837	Cost: 11.88s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 0.3968	Cost: 14.94s
Train Epoch: 420 [61440/90000 (68%)]	Loss: 0.1281	Cost: 14.33s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 0.0929	Cost: 16.62s
Train Epoch: 420 	Average Loss: 0.2984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7368

Learning rate: 0.0001999912951352122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 2.6045	Cost: 30.16s
Train Epoch: 421 [20480/90000 (23%)]	Loss: 0.1099	Cost: 15.63s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 0.4763	Cost: 14.81s
Train Epoch: 421 [61440/90000 (68%)]	Loss: 0.1823	Cost: 13.14s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 0.0049	Cost: 12.22s
Train Epoch: 421 	Average Loss: 0.3380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6978

Learning rate: 0.0001999912536347328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 2.9519	Cost: 30.36s
Train Epoch: 422 [20480/90000 (23%)]	Loss: -0.0220	Cost: 14.57s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 0.4674	Cost: 16.71s
Train Epoch: 422 [61440/90000 (68%)]	Loss: 0.3424	Cost: 13.03s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 0.2877	Cost: 12.85s
Train Epoch: 422 	Average Loss: 0.4204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7594

Learning rate: 0.00019999121203556597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 2.7354	Cost: 37.32s
Train Epoch: 423 [20480/90000 (23%)]	Loss: 0.3176	Cost: 12.09s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 0.8009	Cost: 12.78s
Train Epoch: 423 [61440/90000 (68%)]	Loss: 0.3251	Cost: 13.30s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 0.0243	Cost: 12.29s
Train Epoch: 423 	Average Loss: 0.5001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7696

Learning rate: 0.0001999911703377118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 2.5960	Cost: 33.35s
Train Epoch: 424 [20480/90000 (23%)]	Loss: -0.0993	Cost: 7.83s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 0.2714	Cost: 10.44s
Train Epoch: 424 [61440/90000 (68%)]	Loss: -0.1257	Cost: 13.31s
Train Epoch: 424 [81920/90000 (91%)]	Loss: -0.1415	Cost: 12.91s
Train Epoch: 424 	Average Loss: 0.1820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5873

Saving model as e424_model.pt & e424_waveforms_supplementary.hdf5
Learning rate: 0.00019999112854117028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 2.5034	Cost: 28.32s
Train Epoch: 425 [20480/90000 (23%)]	Loss: -0.1986	Cost: 12.90s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 0.3901	Cost: 17.96s
Train Epoch: 425 [61440/90000 (68%)]	Loss: -0.2016	Cost: 14.20s
Train Epoch: 425 [81920/90000 (91%)]	Loss: -0.1889	Cost: 16.43s
Train Epoch: 425 	Average Loss: 0.0971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4832

Saving model as e425_model.pt & e425_waveforms_supplementary.hdf5
Learning rate: 0.00019999108664594148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 2.4681	Cost: 27.71s
Train Epoch: 426 [20480/90000 (23%)]	Loss: -0.4909	Cost: 12.05s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 0.1043	Cost: 16.51s
Train Epoch: 426 [61440/90000 (68%)]	Loss: -0.1218	Cost: 16.34s
Train Epoch: 426 [81920/90000 (91%)]	Loss: -0.0806	Cost: 16.01s
Train Epoch: 426 	Average Loss: 0.0426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5082

Learning rate: 0.0001999910446520254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 2.3655	Cost: 32.55s
Train Epoch: 427 [20480/90000 (23%)]	Loss: -0.3323	Cost: 7.86s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 0.1549	Cost: 13.38s
Train Epoch: 427 [61440/90000 (68%)]	Loss: -0.1878	Cost: 12.23s
Train Epoch: 427 [81920/90000 (91%)]	Loss: -0.3922	Cost: 12.28s
Train Epoch: 427 	Average Loss: 0.0074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4153

Saving model as e427_model.pt & e427_waveforms_supplementary.hdf5
Learning rate: 0.00019999100255942216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 2.4238	Cost: 29.83s
Train Epoch: 428 [20480/90000 (23%)]	Loss: -0.3003	Cost: 11.45s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 0.2785	Cost: 13.67s
Train Epoch: 428 [61440/90000 (68%)]	Loss: -0.0634	Cost: 13.45s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 0.1558	Cost: 12.22s
Train Epoch: 428 	Average Loss: 0.1420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6313

Learning rate: 0.00019999096036813171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 2.6945	Cost: 27.03s
Train Epoch: 429 [20480/90000 (23%)]	Loss: -0.2087	Cost: 7.75s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 0.1919	Cost: 17.12s
Train Epoch: 429 [61440/90000 (68%)]	Loss: -0.1980	Cost: 14.14s
Train Epoch: 429 [81920/90000 (91%)]	Loss: -0.1590	Cost: 12.56s
Train Epoch: 429 	Average Loss: 0.1053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5135

Learning rate: 0.0001999909180781542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 2.4583	Cost: 30.59s
Train Epoch: 430 [20480/90000 (23%)]	Loss: -0.1687	Cost: 6.46s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 0.2706	Cost: 12.40s
Train Epoch: 430 [61440/90000 (68%)]	Loss: -0.1434	Cost: 13.19s
Train Epoch: 430 [81920/90000 (91%)]	Loss: -0.1743	Cost: 12.94s
Train Epoch: 430 	Average Loss: 0.0972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6080

Learning rate: 0.00019999087568948958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 2.6876	Cost: 41.60s
Train Epoch: 431 [20480/90000 (23%)]	Loss: -0.3562	Cost: 6.85s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 0.0471	Cost: 12.78s
Train Epoch: 431 [61440/90000 (68%)]	Loss: -0.1824	Cost: 12.10s
Train Epoch: 431 [81920/90000 (91%)]	Loss: -0.2304	Cost: 12.32s
Train Epoch: 431 	Average Loss: -0.0168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3981

Saving model as e431_model.pt & e431_waveforms_supplementary.hdf5
Learning rate: 0.0001999908332021379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 2.1243	Cost: 36.00s
Train Epoch: 432 [20480/90000 (23%)]	Loss: -0.2894	Cost: 13.04s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 0.0427	Cost: 13.37s
Train Epoch: 432 [61440/90000 (68%)]	Loss: -0.2912	Cost: 12.10s
Train Epoch: 432 [81920/90000 (91%)]	Loss: -0.1433	Cost: 11.80s
Train Epoch: 432 	Average Loss: 0.0219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4628

Learning rate: 0.00019999079061609924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 2.3136	Cost: 26.02s
Train Epoch: 433 [20480/90000 (23%)]	Loss: 0.9652	Cost: 12.73s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 1.3369	Cost: 13.90s
Train Epoch: 433 [61440/90000 (68%)]	Loss: 0.6233	Cost: 12.39s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 0.2798	Cost: 12.48s
Train Epoch: 433 	Average Loss: 0.9414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7948

Learning rate: 0.00019999074793137364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 2.9065	Cost: 29.99s
Train Epoch: 434 [20480/90000 (23%)]	Loss: -0.0150	Cost: 13.50s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 0.1869	Cost: 14.27s
Train Epoch: 434 [61440/90000 (68%)]	Loss: 0.9787	Cost: 13.50s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 0.8483	Cost: 12.65s
Train Epoch: 434 	Average Loss: 0.5233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1476

Learning rate: 0.00019999070514796111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 3.0733	Cost: 30.91s
Train Epoch: 435 [20480/90000 (23%)]	Loss: 0.2961	Cost: 12.63s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 0.5021	Cost: 14.58s
Train Epoch: 435 [61440/90000 (68%)]	Loss: 0.0022	Cost: 15.74s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 0.0956	Cost: 14.51s
Train Epoch: 435 	Average Loss: 0.4108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5959

Learning rate: 0.00019999066226586174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 2.7563	Cost: 40.02s
Train Epoch: 436 [20480/90000 (23%)]	Loss: -0.1518	Cost: 6.20s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 0.5886	Cost: 12.26s
Train Epoch: 436 [61440/90000 (68%)]	Loss: 0.0902	Cost: 11.71s
Train Epoch: 436 [81920/90000 (91%)]	Loss: -0.0471	Cost: 11.45s
Train Epoch: 436 	Average Loss: 0.2018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5696

Learning rate: 0.00019999061928507552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 2.2036	Cost: 32.08s
Train Epoch: 437 [20480/90000 (23%)]	Loss: -0.3530	Cost: 11.30s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 0.2148	Cost: 11.61s
Train Epoch: 437 [61440/90000 (68%)]	Loss: 0.0474	Cost: 7.75s
Train Epoch: 437 [81920/90000 (91%)]	Loss: -0.1203	Cost: 6.90s
Train Epoch: 437 	Average Loss: 0.0714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5868

Learning rate: 0.0001999905762056025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 2.3816	Cost: 28.99s
Train Epoch: 438 [20480/90000 (23%)]	Loss: -0.5178	Cost: 12.61s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 0.1395	Cost: 11.90s
Train Epoch: 438 [61440/90000 (68%)]	Loss: -0.2781	Cost: 8.94s
Train Epoch: 438 [81920/90000 (91%)]	Loss: -0.3856	Cost: 8.47s
Train Epoch: 438 	Average Loss: -0.0043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3717

Saving model as e438_model.pt & e438_waveforms_supplementary.hdf5
Learning rate: 0.00019999053302744273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 2.4630	Cost: 30.87s
Train Epoch: 439 [20480/90000 (23%)]	Loss: -0.4752	Cost: 12.50s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 0.1517	Cost: 12.15s
Train Epoch: 439 [61440/90000 (68%)]	Loss: -0.4068	Cost: 9.37s
Train Epoch: 439 [81920/90000 (91%)]	Loss: -0.3563	Cost: 10.01s
Train Epoch: 439 	Average Loss: -0.1305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2510

Saving model as e439_model.pt & e439_waveforms_supplementary.hdf5
Learning rate: 0.00019999048975059627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 2.3304	Cost: 31.40s
Train Epoch: 440 [20480/90000 (23%)]	Loss: -0.5454	Cost: 11.56s
Train Epoch: 440 [40960/90000 (45%)]	Loss: -0.3063	Cost: 12.64s
Train Epoch: 440 [61440/90000 (68%)]	Loss: -0.4609	Cost: 8.34s
Train Epoch: 440 [81920/90000 (91%)]	Loss: -0.4588	Cost: 8.96s
Train Epoch: 440 	Average Loss: -0.2782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3222

Learning rate: 0.00019999044637506315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 2.0752	Cost: 35.09s
Train Epoch: 441 [20480/90000 (23%)]	Loss: -0.3817	Cost: 9.03s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 0.0834	Cost: 11.97s
Train Epoch: 441 [61440/90000 (68%)]	Loss: -0.2892	Cost: 10.45s
Train Epoch: 441 [81920/90000 (91%)]	Loss: -0.4023	Cost: 8.84s
Train Epoch: 441 	Average Loss: -0.1139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4227

Learning rate: 0.0001999904029008434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 2.3325	Cost: 32.97s
Train Epoch: 442 [20480/90000 (23%)]	Loss: -0.5424	Cost: 7.70s
Train Epoch: 442 [40960/90000 (45%)]	Loss: -0.1884	Cost: 11.83s
Train Epoch: 442 [61440/90000 (68%)]	Loss: -0.3717	Cost: 8.37s
Train Epoch: 442 [81920/90000 (91%)]	Loss: -0.3749	Cost: 8.34s
Train Epoch: 442 	Average Loss: -0.2309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2018

Saving model as e442_model.pt & e442_waveforms_supplementary.hdf5
Learning rate: 0.0001999903593279371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 2.1129	Cost: 30.48s
Train Epoch: 443 [20480/90000 (23%)]	Loss: -0.6723	Cost: 12.45s
Train Epoch: 443 [40960/90000 (45%)]	Loss: -0.3012	Cost: 11.92s
Train Epoch: 443 [61440/90000 (68%)]	Loss: -0.6067	Cost: 10.65s
Train Epoch: 443 [81920/90000 (91%)]	Loss: -0.6314	Cost: 6.56s
Train Epoch: 443 	Average Loss: -0.3759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1580

Saving model as e443_model.pt & e443_waveforms_supplementary.hdf5
Learning rate: 0.00019999031565634426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 2.1145	Cost: 30.37s
Train Epoch: 444 [20480/90000 (23%)]	Loss: -0.7314	Cost: 12.11s
Train Epoch: 444 [40960/90000 (45%)]	Loss: -0.3085	Cost: 12.49s
Train Epoch: 444 [61440/90000 (68%)]	Loss: -0.5950	Cost: 10.98s
Train Epoch: 444 [81920/90000 (91%)]	Loss: -0.5553	Cost: 9.78s
Train Epoch: 444 	Average Loss: -0.3712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2664

Learning rate: 0.00019999027188606495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 2.3481	Cost: 30.23s
Train Epoch: 445 [20480/90000 (23%)]	Loss: -0.8875	Cost: 11.45s
Train Epoch: 445 [40960/90000 (45%)]	Loss: -0.4152	Cost: 13.82s
Train Epoch: 445 [61440/90000 (68%)]	Loss: -0.6883	Cost: 9.49s
Train Epoch: 445 [81920/90000 (91%)]	Loss: -0.7112	Cost: 7.23s
Train Epoch: 445 	Average Loss: -0.4577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1127

Saving model as e445_model.pt & e445_waveforms_supplementary.hdf5
Learning rate: 0.0001999902280170992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 1.9431	Cost: 29.43s
Train Epoch: 446 [20480/90000 (23%)]	Loss: -0.8407	Cost: 8.20s
Train Epoch: 446 [40960/90000 (45%)]	Loss: -0.3000	Cost: 14.78s
Train Epoch: 446 [61440/90000 (68%)]	Loss: -0.5395	Cost: 9.09s
Train Epoch: 446 [81920/90000 (91%)]	Loss: -0.7913	Cost: 8.91s
Train Epoch: 446 	Average Loss: -0.4546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1008

Saving model as e446_model.pt & e446_waveforms_supplementary.hdf5
Learning rate: 0.00019999018404944703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 2.0167	Cost: 29.86s
Train Epoch: 447 [20480/90000 (23%)]	Loss: -0.7537	Cost: 8.03s
Train Epoch: 447 [40960/90000 (45%)]	Loss: -0.3495	Cost: 14.34s
Train Epoch: 447 [61440/90000 (68%)]	Loss: -0.6341	Cost: 9.44s
Train Epoch: 447 [81920/90000 (91%)]	Loss: -0.6099	Cost: 10.43s
Train Epoch: 447 	Average Loss: -0.4520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0850

Saving model as e447_model.pt & e447_waveforms_supplementary.hdf5
Learning rate: 0.0001999901399831085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 1.8636	Cost: 31.85s
Train Epoch: 448 [20480/90000 (23%)]	Loss: -0.8349	Cost: 9.66s
Train Epoch: 448 [40960/90000 (45%)]	Loss: -0.1594	Cost: 13.69s
Train Epoch: 448 [61440/90000 (68%)]	Loss: -0.5803	Cost: 10.66s
Train Epoch: 448 [81920/90000 (91%)]	Loss: -0.4938	Cost: 12.06s
Train Epoch: 448 	Average Loss: -0.3845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2957

Learning rate: 0.00019999009581808368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 2.3652	Cost: 31.51s
Train Epoch: 449 [20480/90000 (23%)]	Loss: -0.5760	Cost: 7.26s
Train Epoch: 449 [40960/90000 (45%)]	Loss: -0.1918	Cost: 12.02s
Train Epoch: 449 [61440/90000 (68%)]	Loss: -0.5704	Cost: 7.44s
Train Epoch: 449 [81920/90000 (91%)]	Loss: -0.4783	Cost: 9.85s
Train Epoch: 449 	Average Loss: -0.2723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2384

Learning rate: 0.00019999005155437258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 2.3922	Cost: 31.04s
Train Epoch: 450 [20480/90000 (23%)]	Loss: -0.7462	Cost: 8.01s
Train Epoch: 450 [40960/90000 (45%)]	Loss: -0.2532	Cost: 11.98s
Train Epoch: 450 [61440/90000 (68%)]	Loss: -0.7447	Cost: 8.71s
Train Epoch: 450 [81920/90000 (91%)]	Loss: -0.6867	Cost: 9.82s
Train Epoch: 450 	Average Loss: -0.4460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0460

Saving model as e450_model.pt & e450_waveforms_supplementary.hdf5
Learning rate: 0.00019999000719197527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 1.8243	Cost: 30.71s
Train Epoch: 451 [20480/90000 (23%)]	Loss: -0.8698	Cost: 7.13s
Train Epoch: 451 [40960/90000 (45%)]	Loss: -0.4471	Cost: 12.66s
Train Epoch: 451 [61440/90000 (68%)]	Loss: -0.7959	Cost: 7.55s
Train Epoch: 451 [81920/90000 (91%)]	Loss: -0.7847	Cost: 15.31s
Train Epoch: 451 	Average Loss: -0.5266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9605

Saving model as e451_model.pt & e451_waveforms_supplementary.hdf5
Learning rate: 0.00019998996273089178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 1.9947	Cost: 28.01s
Train Epoch: 452 [20480/90000 (23%)]	Loss: -0.9523	Cost: 6.95s
Train Epoch: 452 [40960/90000 (45%)]	Loss: -0.3080	Cost: 13.05s
Train Epoch: 452 [61440/90000 (68%)]	Loss: -0.7916	Cost: 9.05s
Train Epoch: 452 [81920/90000 (91%)]	Loss: -0.7763	Cost: 10.65s
Train Epoch: 452 	Average Loss: -0.5293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0592

Learning rate: 0.00019998991817112214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 2.1651	Cost: 32.52s
Train Epoch: 453 [20480/90000 (23%)]	Loss: -0.9070	Cost: 11.27s
Train Epoch: 453 [40960/90000 (45%)]	Loss: -0.4927	Cost: 11.92s
Train Epoch: 453 [61440/90000 (68%)]	Loss: -0.6889	Cost: 12.12s
Train Epoch: 453 [81920/90000 (91%)]	Loss: -0.8907	Cost: 7.88s
Train Epoch: 453 	Average Loss: -0.5589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9046

Saving model as e453_model.pt & e453_waveforms_supplementary.hdf5
Learning rate: 0.00019998987351266641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 1.8289	Cost: 29.04s
Train Epoch: 454 [20480/90000 (23%)]	Loss: -1.0901	Cost: 10.61s
Train Epoch: 454 [40960/90000 (45%)]	Loss: -0.6247	Cost: 12.77s
Train Epoch: 454 [61440/90000 (68%)]	Loss: -0.5629	Cost: 8.03s
Train Epoch: 454 [81920/90000 (91%)]	Loss: -0.7068	Cost: 6.94s
Train Epoch: 454 	Average Loss: -0.5662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0807

Learning rate: 0.00019998982875552463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 2.0380	Cost: 31.18s
Train Epoch: 455 [20480/90000 (23%)]	Loss: -0.8346	Cost: 9.30s
Train Epoch: 455 [40960/90000 (45%)]	Loss: -0.4525	Cost: 12.55s
Train Epoch: 455 [61440/90000 (68%)]	Loss: -0.8355	Cost: 12.73s
Train Epoch: 455 [81920/90000 (91%)]	Loss: -0.8815	Cost: 8.32s
Train Epoch: 455 	Average Loss: -0.5792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9972

Learning rate: 0.00019998978389969684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 2.1032	Cost: 31.83s
Train Epoch: 456 [20480/90000 (23%)]	Loss: -0.8532	Cost: 7.57s
Train Epoch: 456 [40960/90000 (45%)]	Loss: -0.4063	Cost: 14.89s
Train Epoch: 456 [61440/90000 (68%)]	Loss: -0.7016	Cost: 12.89s
Train Epoch: 456 [81920/90000 (91%)]	Loss: -0.6703	Cost: 10.73s
Train Epoch: 456 	Average Loss: -0.5074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1757

Learning rate: 0.0001999897389451831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 2.1502	Cost: 30.97s
Train Epoch: 457 [20480/90000 (23%)]	Loss: -0.6895	Cost: 8.64s
Train Epoch: 457 [40960/90000 (45%)]	Loss: -0.4988	Cost: 14.29s
Train Epoch: 457 [61440/90000 (68%)]	Loss: -0.7319	Cost: 13.46s
Train Epoch: 457 [81920/90000 (91%)]	Loss: -0.8600	Cost: 11.60s
Train Epoch: 457 	Average Loss: -0.5674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9610

Learning rate: 0.00019998969389198342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 2.1107	Cost: 32.90s
Train Epoch: 458 [20480/90000 (23%)]	Loss: -0.7537	Cost: 13.40s
Train Epoch: 458 [40960/90000 (45%)]	Loss: -0.3540	Cost: 13.21s
Train Epoch: 458 [61440/90000 (68%)]	Loss: -0.7723	Cost: 12.76s
Train Epoch: 458 [81920/90000 (91%)]	Loss: -0.9493	Cost: 12.55s
Train Epoch: 458 	Average Loss: -0.5574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8776

Saving model as e458_model.pt & e458_waveforms_supplementary.hdf5
Learning rate: 0.00019998964874009788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 1.9305	Cost: 28.50s
Train Epoch: 459 [20480/90000 (23%)]	Loss: -1.1272	Cost: 14.42s
Train Epoch: 459 [40960/90000 (45%)]	Loss: -0.6958	Cost: 15.29s
Train Epoch: 459 [61440/90000 (68%)]	Loss: -1.0533	Cost: 13.09s
Train Epoch: 459 [81920/90000 (91%)]	Loss: -0.7749	Cost: 12.61s
Train Epoch: 459 	Average Loss: -0.7260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1465

Learning rate: 0.00019998960348952653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 2.0701	Cost: 27.60s
Train Epoch: 460 [20480/90000 (23%)]	Loss: -0.6471	Cost: 11.70s
Train Epoch: 460 [40960/90000 (45%)]	Loss: -0.3660	Cost: 14.03s
Train Epoch: 460 [61440/90000 (68%)]	Loss: -0.7298	Cost: 13.75s
Train Epoch: 460 [81920/90000 (91%)]	Loss: -0.8510	Cost: 18.28s
Train Epoch: 460 	Average Loss: -0.4783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0131

Learning rate: 0.00019998955814026938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 2.1459	Cost: 28.16s
Train Epoch: 461 [20480/90000 (23%)]	Loss: -1.1167	Cost: 10.96s
Train Epoch: 461 [40960/90000 (45%)]	Loss: -0.4343	Cost: 18.37s
Train Epoch: 461 [61440/90000 (68%)]	Loss: -0.7602	Cost: 13.41s
Train Epoch: 461 [81920/90000 (91%)]	Loss: -0.9560	Cost: 22.08s
Train Epoch: 461 	Average Loss: -0.6633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9609

Learning rate: 0.0001999895126923265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 1.5633	Cost: 33.01s
Train Epoch: 462 [20480/90000 (23%)]	Loss: -0.9596	Cost: 15.53s
Train Epoch: 462 [40960/90000 (45%)]	Loss: -0.6573	Cost: 13.02s
Train Epoch: 462 [61440/90000 (68%)]	Loss: -0.8860	Cost: 14.72s
Train Epoch: 462 [81920/90000 (91%)]	Loss: -1.0230	Cost: 16.93s
Train Epoch: 462 	Average Loss: -0.6456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8579

Saving model as e462_model.pt & e462_waveforms_supplementary.hdf5
Learning rate: 0.00019998946714569794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 1.6835	Cost: 31.13s
Train Epoch: 463 [20480/90000 (23%)]	Loss: -1.0781	Cost: 14.12s
Train Epoch: 463 [40960/90000 (45%)]	Loss: -0.6371	Cost: 17.09s
Train Epoch: 463 [61440/90000 (68%)]	Loss: -1.1736	Cost: 14.24s
Train Epoch: 463 [81920/90000 (91%)]	Loss: -1.0854	Cost: 19.80s
Train Epoch: 463 	Average Loss: -0.7970
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7551

Saving model as e463_model.pt & e463_waveforms_supplementary.hdf5
Learning rate: 0.0001999894215003837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 1.5373	Cost: 28.81s
Train Epoch: 464 [20480/90000 (23%)]	Loss: -1.2429	Cost: 15.02s
Train Epoch: 464 [40960/90000 (45%)]	Loss: -0.6852	Cost: 14.59s
Train Epoch: 464 [61440/90000 (68%)]	Loss: -1.0067	Cost: 16.71s
Train Epoch: 464 [81920/90000 (91%)]	Loss: -0.9909	Cost: 24.46s
Train Epoch: 464 	Average Loss: -0.9129
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7842

Learning rate: 0.00019998937575638385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 1.6753	Cost: 28.39s
Train Epoch: 465 [20480/90000 (23%)]	Loss: -1.2795	Cost: 12.78s
Train Epoch: 465 [40960/90000 (45%)]	Loss: -0.8337	Cost: 15.77s
Train Epoch: 465 [61440/90000 (68%)]	Loss: -1.2395	Cost: 13.54s
Train Epoch: 465 [81920/90000 (91%)]	Loss: -1.1624	Cost: 18.92s
Train Epoch: 465 	Average Loss: -0.9569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7525

Saving model as e465_model.pt & e465_waveforms_supplementary.hdf5
Learning rate: 0.0001999893299136985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 1.4257	Cost: 33.60s
Train Epoch: 466 [20480/90000 (23%)]	Loss: -1.2299	Cost: 14.73s
Train Epoch: 466 [40960/90000 (45%)]	Loss: -0.8231	Cost: 23.47s
Train Epoch: 466 [61440/90000 (68%)]	Loss: -0.6139	Cost: 14.77s
Train Epoch: 466 [81920/90000 (91%)]	Loss: -0.7994	Cost: 9.85s
Train Epoch: 466 	Average Loss: -0.7680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0286

Learning rate: 0.00019998928397232759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 1.7141	Cost: 34.37s
Train Epoch: 467 [20480/90000 (23%)]	Loss: -0.9948	Cost: 13.89s
Train Epoch: 467 [40960/90000 (45%)]	Loss: -0.5234	Cost: 17.60s
Train Epoch: 467 [61440/90000 (68%)]	Loss: -0.7640	Cost: 14.16s
Train Epoch: 467 [81920/90000 (91%)]	Loss: -0.9272	Cost: 19.40s
Train Epoch: 467 	Average Loss: -0.6187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9452

Learning rate: 0.00019998923793227122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 2.0373	Cost: 31.87s
Train Epoch: 468 [20480/90000 (23%)]	Loss: -1.1416	Cost: 14.45s
Train Epoch: 468 [40960/90000 (45%)]	Loss: -0.5994	Cost: 14.91s
Train Epoch: 468 [61440/90000 (68%)]	Loss: -1.1502	Cost: 15.04s
Train Epoch: 468 [81920/90000 (91%)]	Loss: -0.7197	Cost: 12.77s
Train Epoch: 468 	Average Loss: -0.7184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0412

Learning rate: 0.0001999891917935294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 2.2383	Cost: 31.02s
Train Epoch: 469 [20480/90000 (23%)]	Loss: -0.8405	Cost: 14.43s
Train Epoch: 469 [40960/90000 (45%)]	Loss: -0.6092	Cost: 13.52s
Train Epoch: 469 [61440/90000 (68%)]	Loss: -1.2059	Cost: 14.76s
Train Epoch: 469 [81920/90000 (91%)]	Loss: -1.2018	Cost: 14.00s
Train Epoch: 469 	Average Loss: -0.7715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7873

Learning rate: 0.00019998914555610225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 1.9949	Cost: 29.04s
Train Epoch: 470 [20480/90000 (23%)]	Loss: -1.3369	Cost: 12.30s
Train Epoch: 470 [40960/90000 (45%)]	Loss: -0.8164	Cost: 15.37s
Train Epoch: 470 [61440/90000 (68%)]	Loss: -1.2345	Cost: 15.27s
Train Epoch: 470 [81920/90000 (91%)]	Loss: -1.3986	Cost: 13.87s
Train Epoch: 470 	Average Loss: -0.9589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6872

Saving model as e470_model.pt & e470_waveforms_supplementary.hdf5
Learning rate: 0.00019998909921998975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 1.8006	Cost: 30.14s
Train Epoch: 471 [20480/90000 (23%)]	Loss: -1.1418	Cost: 12.47s
Train Epoch: 471 [40960/90000 (45%)]	Loss: -0.7718	Cost: 14.53s
Train Epoch: 471 [61440/90000 (68%)]	Loss: -0.8641	Cost: 14.45s
Train Epoch: 471 [81920/90000 (91%)]	Loss: -1.0029	Cost: 14.77s
Train Epoch: 471 	Average Loss: -0.8378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8897

Learning rate: 0.00019998905278519196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 2.1771	Cost: 29.58s
Train Epoch: 472 [20480/90000 (23%)]	Loss: -1.3098	Cost: 12.68s
Train Epoch: 472 [40960/90000 (45%)]	Loss: -0.8425	Cost: 16.40s
Train Epoch: 472 [61440/90000 (68%)]	Loss: -1.0305	Cost: 14.95s
Train Epoch: 472 [81920/90000 (91%)]	Loss: -1.2675	Cost: 15.72s
Train Epoch: 472 	Average Loss: -0.9222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7148

Learning rate: 0.00019998900625170892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 1.6655	Cost: 29.13s
Train Epoch: 473 [20480/90000 (23%)]	Loss: -1.4875	Cost: 11.95s
Train Epoch: 473 [40960/90000 (45%)]	Loss: -1.1140	Cost: 14.35s
Train Epoch: 473 [61440/90000 (68%)]	Loss: -1.4349	Cost: 14.56s
Train Epoch: 473 [81920/90000 (91%)]	Loss: -1.2276	Cost: 14.89s
Train Epoch: 473 	Average Loss: -1.1003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7816

Learning rate: 0.0001999889596195407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 1.9185	Cost: 34.95s
Train Epoch: 474 [20480/90000 (23%)]	Loss: -1.4899	Cost: 14.76s
Train Epoch: 474 [40960/90000 (45%)]	Loss: -0.8202	Cost: 16.59s
Train Epoch: 474 [61440/90000 (68%)]	Loss: -1.2513	Cost: 12.59s
Train Epoch: 474 [81920/90000 (91%)]	Loss: -1.2332	Cost: 10.79s
Train Epoch: 474 	Average Loss: -0.9905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6301

Saving model as e474_model.pt & e474_waveforms_supplementary.hdf5
Learning rate: 0.00019998891288868732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 1.5220	Cost: 33.82s
Train Epoch: 475 [20480/90000 (23%)]	Loss: -1.4724	Cost: 14.36s
Train Epoch: 475 [40960/90000 (45%)]	Loss: -0.8708	Cost: 15.41s
Train Epoch: 475 [61440/90000 (68%)]	Loss: -1.3069	Cost: 14.88s
Train Epoch: 475 [81920/90000 (91%)]	Loss: -1.1764	Cost: 10.33s
Train Epoch: 475 	Average Loss: -1.0239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5645

Saving model as e475_model.pt & e475_waveforms_supplementary.hdf5
Learning rate: 0.00019998886605914883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 1.4315	Cost: 28.86s
Train Epoch: 476 [20480/90000 (23%)]	Loss: -1.1906	Cost: 14.72s
Train Epoch: 476 [40960/90000 (45%)]	Loss: -0.7259	Cost: 12.86s
Train Epoch: 476 [61440/90000 (68%)]	Loss: -1.2961	Cost: 14.62s
Train Epoch: 476 [81920/90000 (91%)]	Loss: -1.2842	Cost: 14.45s
Train Epoch: 476 	Average Loss: -0.9727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6536

Learning rate: 0.00019998881913092532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 1.5872	Cost: 32.17s
Train Epoch: 477 [20480/90000 (23%)]	Loss: -1.4271	Cost: 14.90s
Train Epoch: 477 [40960/90000 (45%)]	Loss: -0.8683	Cost: 15.40s
Train Epoch: 477 [61440/90000 (68%)]	Loss: -1.2369	Cost: 15.30s
Train Epoch: 477 [81920/90000 (91%)]	Loss: -1.1501	Cost: 14.21s
Train Epoch: 477 	Average Loss: -1.0675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8308

Learning rate: 0.00019998877210401677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 1.8453	Cost: 40.23s
Train Epoch: 478 [20480/90000 (23%)]	Loss: -1.4815	Cost: 13.91s
Train Epoch: 478 [40960/90000 (45%)]	Loss: -1.1136	Cost: 13.95s
Train Epoch: 478 [61440/90000 (68%)]	Loss: -1.5662	Cost: 14.09s
Train Epoch: 478 [81920/90000 (91%)]	Loss: -1.2996	Cost: 12.68s
Train Epoch: 478 	Average Loss: -1.0902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6422

Learning rate: 0.00019998872497842328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 1.2982	Cost: 39.19s
Train Epoch: 479 [20480/90000 (23%)]	Loss: -1.4685	Cost: 15.09s
Train Epoch: 479 [40960/90000 (45%)]	Loss: -0.8876	Cost: 18.81s
Train Epoch: 479 [61440/90000 (68%)]	Loss: -1.1662	Cost: 14.05s
Train Epoch: 479 [81920/90000 (91%)]	Loss: -1.2240	Cost: 13.00s
Train Epoch: 479 	Average Loss: -1.0909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6109

Learning rate: 0.00019998867775414486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 1.4241	Cost: 40.54s
Train Epoch: 480 [20480/90000 (23%)]	Loss: -1.5159	Cost: 16.02s
Train Epoch: 480 [40960/90000 (45%)]	Loss: -0.9555	Cost: 19.43s
Train Epoch: 480 [61440/90000 (68%)]	Loss: -1.4039	Cost: 13.53s
Train Epoch: 480 [81920/90000 (91%)]	Loss: -1.3489	Cost: 13.47s
Train Epoch: 480 	Average Loss: -1.1017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6899

Learning rate: 0.00019998863043118158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 1.8535	Cost: 26.02s
Train Epoch: 481 [20480/90000 (23%)]	Loss: -1.4276	Cost: 11.61s
Train Epoch: 481 [40960/90000 (45%)]	Loss: -1.2281	Cost: 17.91s
Train Epoch: 481 [61440/90000 (68%)]	Loss: -1.5229	Cost: 16.17s
Train Epoch: 481 [81920/90000 (91%)]	Loss: -1.6264	Cost: 17.11s
Train Epoch: 481 	Average Loss: -1.2630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4030

Saving model as e481_model.pt & e481_waveforms_supplementary.hdf5
Learning rate: 0.00019998858300953348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 1.4271	Cost: 33.53s
Train Epoch: 482 [20480/90000 (23%)]	Loss: -1.7726	Cost: 11.85s
Train Epoch: 482 [40960/90000 (45%)]	Loss: -1.2340	Cost: 12.97s
Train Epoch: 482 [61440/90000 (68%)]	Loss: -1.5931	Cost: 14.35s
Train Epoch: 482 [81920/90000 (91%)]	Loss: -1.3841	Cost: 13.85s
Train Epoch: 482 	Average Loss: -1.3575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7000

Learning rate: 0.0001999885354892006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 1.4759	Cost: 36.31s
Train Epoch: 483 [20480/90000 (23%)]	Loss: -1.2939	Cost: 12.29s
Train Epoch: 483 [40960/90000 (45%)]	Loss: -0.9286	Cost: 11.88s
Train Epoch: 483 [61440/90000 (68%)]	Loss: -1.2774	Cost: 12.95s
Train Epoch: 483 [81920/90000 (91%)]	Loss: -1.2751	Cost: 12.50s
Train Epoch: 483 	Average Loss: -1.0764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5904

Learning rate: 0.000199988487870183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 1.6418	Cost: 34.74s
Train Epoch: 484 [20480/90000 (23%)]	Loss: -1.4614	Cost: 10.13s
Train Epoch: 484 [40960/90000 (45%)]	Loss: -1.3420	Cost: 12.27s
Train Epoch: 484 [61440/90000 (68%)]	Loss: -1.6937	Cost: 12.51s
Train Epoch: 484 [81920/90000 (91%)]	Loss: -1.8237	Cost: 16.19s
Train Epoch: 484 	Average Loss: -1.3283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3691

Saving model as e484_model.pt & e484_waveforms_supplementary.hdf5
Learning rate: 0.00019998844015248072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 1.3357	Cost: 29.04s
Train Epoch: 485 [20480/90000 (23%)]	Loss: -1.7837	Cost: 10.45s
Train Epoch: 485 [40960/90000 (45%)]	Loss: -1.3381	Cost: 13.54s
Train Epoch: 485 [61440/90000 (68%)]	Loss: -1.6087	Cost: 12.98s
Train Epoch: 485 [81920/90000 (91%)]	Loss: -1.8552	Cost: 12.23s
Train Epoch: 485 	Average Loss: -1.4484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3071

Saving model as e485_model.pt & e485_waveforms_supplementary.hdf5
Learning rate: 0.0001999883923360938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 1.1630	Cost: 27.43s
Train Epoch: 486 [20480/90000 (23%)]	Loss: -1.6898	Cost: 11.75s
Train Epoch: 486 [40960/90000 (45%)]	Loss: -1.3240	Cost: 15.09s
Train Epoch: 486 [61440/90000 (68%)]	Loss: -1.5793	Cost: 14.49s
Train Epoch: 486 [81920/90000 (91%)]	Loss: -1.3589	Cost: 12.25s
Train Epoch: 486 	Average Loss: -1.3938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4643

Learning rate: 0.00019998834442102228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 1.5393	Cost: 47.98s
Train Epoch: 487 [20480/90000 (23%)]	Loss: -1.7499	Cost: 15.18s
Train Epoch: 487 [40960/90000 (45%)]	Loss: -1.3454	Cost: 16.31s
Train Epoch: 487 [61440/90000 (68%)]	Loss: -1.8601	Cost: 12.65s
Train Epoch: 487 [81920/90000 (91%)]	Loss: -1.5678	Cost: 11.28s
Train Epoch: 487 	Average Loss: -1.4686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3396

Learning rate: 0.00019998829640726623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 1.0526	Cost: 64.68s
Train Epoch: 488 [20480/90000 (23%)]	Loss: -1.8328	Cost: 13.99s
Train Epoch: 488 [40960/90000 (45%)]	Loss: -1.3004	Cost: 14.11s
Train Epoch: 488 [61440/90000 (68%)]	Loss: -1.6846	Cost: 11.88s
Train Epoch: 488 [81920/90000 (91%)]	Loss: -1.2535	Cost: 11.93s
Train Epoch: 488 	Average Loss: -1.3507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9288

Learning rate: 0.00019998824829482568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 1.7274	Cost: 61.16s
Train Epoch: 489 [20480/90000 (23%)]	Loss: -0.9447	Cost: 11.56s
Train Epoch: 489 [40960/90000 (45%)]	Loss: -0.7783	Cost: 11.97s
Train Epoch: 489 [61440/90000 (68%)]	Loss: -1.3280	Cost: 12.05s
Train Epoch: 489 [81920/90000 (91%)]	Loss: -1.6078	Cost: 11.91s
Train Epoch: 489 	Average Loss: -0.9511
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3395

Learning rate: 0.0001999882000837007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 1.2916	Cost: 50.80s
Train Epoch: 490 [20480/90000 (23%)]	Loss: -1.7184	Cost: 6.25s
Train Epoch: 490 [40960/90000 (45%)]	Loss: -1.3166	Cost: 12.35s
Train Epoch: 490 [61440/90000 (68%)]	Loss: -1.7924	Cost: 12.36s
Train Epoch: 490 [81920/90000 (91%)]	Loss: -1.6902	Cost: 11.97s
Train Epoch: 490 	Average Loss: -1.4174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3285

Learning rate: 0.0001999881517738913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 1.3203	Cost: 31.22s
Train Epoch: 491 [20480/90000 (23%)]	Loss: -1.7814	Cost: 6.50s
Train Epoch: 491 [40960/90000 (45%)]	Loss: -1.3117	Cost: 13.12s
Train Epoch: 491 [61440/90000 (68%)]	Loss: -1.6872	Cost: 12.46s
Train Epoch: 491 [81920/90000 (91%)]	Loss: -1.7836	Cost: 12.23s
Train Epoch: 491 	Average Loss: -1.4236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3116

Learning rate: 0.00019998810336539752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 1.5850	Cost: 30.17s
Train Epoch: 492 [20480/90000 (23%)]	Loss: -1.9894	Cost: 10.01s
Train Epoch: 492 [40960/90000 (45%)]	Loss: -1.5122	Cost: 12.18s
Train Epoch: 492 [61440/90000 (68%)]	Loss: -1.9663	Cost: 12.18s
Train Epoch: 492 [81920/90000 (91%)]	Loss: -1.5626	Cost: 12.45s
Train Epoch: 492 	Average Loss: -1.5316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4092

Learning rate: 0.00019998805485821946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 1.4826	Cost: 27.16s
Train Epoch: 493 [20480/90000 (23%)]	Loss: -1.6975	Cost: 10.33s
Train Epoch: 493 [40960/90000 (45%)]	Loss: -1.2907	Cost: 13.38s
Train Epoch: 493 [61440/90000 (68%)]	Loss: -1.6808	Cost: 11.96s
Train Epoch: 493 [81920/90000 (91%)]	Loss: -1.5402	Cost: 12.17s
Train Epoch: 493 	Average Loss: -1.3861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5330

Learning rate: 0.00019998800625235718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 1.4597	Cost: 27.42s
Train Epoch: 494 [20480/90000 (23%)]	Loss: -1.5877	Cost: 8.74s
Train Epoch: 494 [40960/90000 (45%)]	Loss: -1.4067	Cost: 13.83s
Train Epoch: 494 [61440/90000 (68%)]	Loss: -1.6848	Cost: 11.98s
Train Epoch: 494 [81920/90000 (91%)]	Loss: -1.9922	Cost: 12.14s
Train Epoch: 494 	Average Loss: -1.3976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0937

Saving model as e494_model.pt & e494_waveforms_supplementary.hdf5
Learning rate: 0.00019998795754781068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 1.0632	Cost: 28.93s
Train Epoch: 495 [20480/90000 (23%)]	Loss: -2.0293	Cost: 12.02s
Train Epoch: 495 [40960/90000 (45%)]	Loss: -1.8179	Cost: 13.07s
Train Epoch: 495 [61440/90000 (68%)]	Loss: -2.0742	Cost: 12.17s
Train Epoch: 495 [81920/90000 (91%)]	Loss: -2.1487	Cost: 13.72s
Train Epoch: 495 	Average Loss: -1.7586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1230

Learning rate: 0.00019998790874458001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 0.9082	Cost: 34.74s
Train Epoch: 496 [20480/90000 (23%)]	Loss: -1.9329	Cost: 13.22s
Train Epoch: 496 [40960/90000 (45%)]	Loss: -1.3182	Cost: 12.53s
Train Epoch: 496 [61440/90000 (68%)]	Loss: -1.7251	Cost: 12.10s
Train Epoch: 496 [81920/90000 (91%)]	Loss: -1.7097	Cost: 11.57s
Train Epoch: 496 	Average Loss: -1.5681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2646

Learning rate: 0.00019998785984266522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 0.8888	Cost: 37.54s
Train Epoch: 497 [20480/90000 (23%)]	Loss: -1.8861	Cost: 13.77s
Train Epoch: 497 [40960/90000 (45%)]	Loss: -1.4174	Cost: 14.93s
Train Epoch: 497 [61440/90000 (68%)]	Loss: -1.7142	Cost: 15.92s
Train Epoch: 497 [81920/90000 (91%)]	Loss: -1.6103	Cost: 13.32s
Train Epoch: 497 	Average Loss: -1.5006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3328

Learning rate: 0.0001999878108420664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 1.3533	Cost: 30.60s
Train Epoch: 498 [20480/90000 (23%)]	Loss: -2.0271	Cost: 13.09s
Train Epoch: 498 [40960/90000 (45%)]	Loss: -1.6080	Cost: 15.75s
Train Epoch: 498 [61440/90000 (68%)]	Loss: -1.8466	Cost: 14.91s
Train Epoch: 498 [81920/90000 (91%)]	Loss: -2.0723	Cost: 16.32s
Train Epoch: 498 	Average Loss: -1.6709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0316

Saving model as e498_model.pt & e498_waveforms_supplementary.hdf5
Learning rate: 0.0001999877617427835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 1.2415	Cost: 36.46s
Train Epoch: 499 [20480/90000 (23%)]	Loss: -2.2771	Cost: 9.08s
Train Epoch: 499 [40960/90000 (45%)]	Loss: -1.7280	Cost: 13.96s
Train Epoch: 499 [61440/90000 (68%)]	Loss: -2.2262	Cost: 15.66s
Train Epoch: 499 [81920/90000 (91%)]	Loss: -2.1285	Cost: 12.43s
Train Epoch: 499 	Average Loss: -1.8524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1347

Learning rate: 0.00019998771254481668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 1.1319	Cost: 30.61s
Train Epoch: 500 [20480/90000 (23%)]	Loss: -2.0381	Cost: 12.51s
Train Epoch: 500 [40960/90000 (45%)]	Loss: -1.5459	Cost: 12.92s
Train Epoch: 500 [61440/90000 (68%)]	Loss: -1.8745	Cost: 12.39s
Train Epoch: 500 [81920/90000 (91%)]	Loss: -2.0858	Cost: 12.97s
Train Epoch: 500 	Average Loss: -1.7072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0582

Learning rate: 0.00019998766324816594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: 0.6864	Cost: 43.91s
Train Epoch: 501 [20480/90000 (23%)]	Loss: -2.3098	Cost: 12.35s
Train Epoch: 501 [40960/90000 (45%)]	Loss: -1.8560	Cost: 17.28s
Train Epoch: 501 [61440/90000 (68%)]	Loss: -2.2597	Cost: 12.11s
Train Epoch: 501 [81920/90000 (91%)]	Loss: -2.2327	Cost: 6.38s
Train Epoch: 501 	Average Loss: -1.9536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8805

Saving model as e501_model.pt & e501_waveforms_supplementary.hdf5
Learning rate: 0.00019998761385283135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: 0.8495	Cost: 39.81s
Train Epoch: 502 [20480/90000 (23%)]	Loss: -2.3748	Cost: 15.45s
Train Epoch: 502 [40960/90000 (45%)]	Loss: -1.8351	Cost: 14.03s
Train Epoch: 502 [61440/90000 (68%)]	Loss: -2.0466	Cost: 14.31s
Train Epoch: 502 [81920/90000 (91%)]	Loss: -2.2289	Cost: 9.75s
Train Epoch: 502 	Average Loss: -1.9373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0076

Learning rate: 0.00019998756435881293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: 1.0932	Cost: 28.50s
Train Epoch: 503 [20480/90000 (23%)]	Loss: -2.4021	Cost: 13.69s
Train Epoch: 503 [40960/90000 (45%)]	Loss: -1.8103	Cost: 14.37s
Train Epoch: 503 [61440/90000 (68%)]	Loss: -1.8209	Cost: 15.65s
Train Epoch: 503 [81920/90000 (91%)]	Loss: -1.8812	Cost: 18.09s
Train Epoch: 503 	Average Loss: -1.8163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1771

Learning rate: 0.00019998751476611075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: 1.3355	Cost: 29.63s
Train Epoch: 504 [20480/90000 (23%)]	Loss: -1.8453	Cost: 14.41s
Train Epoch: 504 [40960/90000 (45%)]	Loss: -1.4503	Cost: 16.42s
Train Epoch: 504 [61440/90000 (68%)]	Loss: -1.8114	Cost: 14.82s
Train Epoch: 504 [81920/90000 (91%)]	Loss: -1.8775	Cost: 14.52s
Train Epoch: 504 	Average Loss: -1.5665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1405

Learning rate: 0.00019998746507472485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: 1.3606	Cost: 30.08s
Train Epoch: 505 [20480/90000 (23%)]	Loss: -2.2599	Cost: 13.37s
Train Epoch: 505 [40960/90000 (45%)]	Loss: -1.6955	Cost: 15.20s
Train Epoch: 505 [61440/90000 (68%)]	Loss: -2.0950	Cost: 15.19s
Train Epoch: 505 [81920/90000 (91%)]	Loss: -2.0625	Cost: 19.43s
Train Epoch: 505 	Average Loss: -1.7988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0791

Learning rate: 0.00019998741528465526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: 1.3061	Cost: 30.45s
Train Epoch: 506 [20480/90000 (23%)]	Loss: -2.3600	Cost: 12.32s
Train Epoch: 506 [40960/90000 (45%)]	Loss: -1.7540	Cost: 17.34s
Train Epoch: 506 [61440/90000 (68%)]	Loss: -2.0926	Cost: 14.65s
Train Epoch: 506 [81920/90000 (91%)]	Loss: -1.9453	Cost: 15.85s
Train Epoch: 506 	Average Loss: -1.8567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1586

Learning rate: 0.00019998736539590206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: 1.4479	Cost: 27.32s
Train Epoch: 507 [20480/90000 (23%)]	Loss: -2.0046	Cost: 9.13s
Train Epoch: 507 [40960/90000 (45%)]	Loss: -1.7970	Cost: 17.67s
Train Epoch: 507 [61440/90000 (68%)]	Loss: -1.8714	Cost: 14.50s
Train Epoch: 507 [81920/90000 (91%)]	Loss: -2.0761	Cost: 14.84s
Train Epoch: 507 	Average Loss: -1.7720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9734

Learning rate: 0.00019998731540846526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: 0.7698	Cost: 28.48s
Train Epoch: 508 [20480/90000 (23%)]	Loss: -2.2234	Cost: 8.48s
Train Epoch: 508 [40960/90000 (45%)]	Loss: -1.7751	Cost: 17.95s
Train Epoch: 508 [61440/90000 (68%)]	Loss: -1.9323	Cost: 14.41s
Train Epoch: 508 [81920/90000 (91%)]	Loss: -2.1397	Cost: 16.77s
Train Epoch: 508 	Average Loss: -1.8482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0272

Learning rate: 0.00019998726532234495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: 0.9660	Cost: 35.69s
Train Epoch: 509 [20480/90000 (23%)]	Loss: -2.1126	Cost: 14.11s
Train Epoch: 509 [40960/90000 (45%)]	Loss: -1.8548	Cost: 17.74s
Train Epoch: 509 [61440/90000 (68%)]	Loss: -1.9206	Cost: 13.60s
Train Epoch: 509 [81920/90000 (91%)]	Loss: -1.9414	Cost: 17.14s
Train Epoch: 509 	Average Loss: -1.8611
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0807

Learning rate: 0.00019998721513754116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: 1.1613	Cost: 32.47s
Train Epoch: 510 [20480/90000 (23%)]	Loss: -2.2828	Cost: 14.04s
Train Epoch: 510 [40960/90000 (45%)]	Loss: -1.6175	Cost: 15.91s
Train Epoch: 510 [61440/90000 (68%)]	Loss: -1.1606	Cost: 13.87s
Train Epoch: 510 [81920/90000 (91%)]	Loss: -1.4397	Cost: 12.94s
Train Epoch: 510 	Average Loss: -1.5053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4138

Learning rate: 0.00019998716485405393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: 1.4027	Cost: 28.47s
Train Epoch: 511 [20480/90000 (23%)]	Loss: -1.8971	Cost: 14.81s
Train Epoch: 511 [40960/90000 (45%)]	Loss: -1.6337	Cost: 14.44s
Train Epoch: 511 [61440/90000 (68%)]	Loss: -1.9657	Cost: 13.48s
Train Epoch: 511 [81920/90000 (91%)]	Loss: -2.1172	Cost: 14.16s
Train Epoch: 511 	Average Loss: -1.6764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0827

Learning rate: 0.00019998711447188336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: 0.9232	Cost: 29.82s
Train Epoch: 512 [20480/90000 (23%)]	Loss: -2.3877	Cost: 12.64s
Train Epoch: 512 [40960/90000 (45%)]	Loss: -1.8107	Cost: 15.16s
Train Epoch: 512 [61440/90000 (68%)]	Loss: -2.3071	Cost: 13.28s
Train Epoch: 512 [81920/90000 (91%)]	Loss: -2.4911	Cost: 14.54s
Train Epoch: 512 	Average Loss: -2.0486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8180

Saving model as e512_model.pt & e512_waveforms_supplementary.hdf5
Learning rate: 0.00019998706399102943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: 0.8761	Cost: 32.94s
Train Epoch: 513 [20480/90000 (23%)]	Loss: -2.4265	Cost: 14.49s
Train Epoch: 513 [40960/90000 (45%)]	Loss: -2.1505	Cost: 14.23s
Train Epoch: 513 [61440/90000 (68%)]	Loss: -2.4575	Cost: 15.26s
Train Epoch: 513 [81920/90000 (91%)]	Loss: -2.3664	Cost: 15.69s
Train Epoch: 513 	Average Loss: -2.1519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8772

Learning rate: 0.00019998701341149226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: 0.8946	Cost: 30.45s
Train Epoch: 514 [20480/90000 (23%)]	Loss: -2.4822	Cost: 14.94s
Train Epoch: 514 [40960/90000 (45%)]	Loss: -2.1244	Cost: 16.73s
Train Epoch: 514 [61440/90000 (68%)]	Loss: -2.3450	Cost: 15.79s
Train Epoch: 514 [81920/90000 (91%)]	Loss: -2.5550	Cost: 16.59s
Train Epoch: 514 	Average Loss: -2.1969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6871

Saving model as e514_model.pt & e514_waveforms_supplementary.hdf5
Learning rate: 0.00019998696273327185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: 0.8441	Cost: 32.81s
Train Epoch: 515 [20480/90000 (23%)]	Loss: -2.5589	Cost: 14.73s
Train Epoch: 515 [40960/90000 (45%)]	Loss: -2.0004	Cost: 25.45s
Train Epoch: 515 [61440/90000 (68%)]	Loss: -2.3037	Cost: 12.27s
Train Epoch: 515 [81920/90000 (91%)]	Loss: -2.4308	Cost: 13.00s
Train Epoch: 515 	Average Loss: -2.1350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9078

Learning rate: 0.00019998691195636826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: 0.7649	Cost: 37.20s
Train Epoch: 516 [20480/90000 (23%)]	Loss: -2.5818	Cost: 12.79s
Train Epoch: 516 [40960/90000 (45%)]	Loss: -2.1082	Cost: 17.74s
Train Epoch: 516 [61440/90000 (68%)]	Loss: -2.4620	Cost: 14.79s
Train Epoch: 516 [81920/90000 (91%)]	Loss: -2.4192	Cost: 7.66s
Train Epoch: 516 	Average Loss: -2.1866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6421

Saving model as e516_model.pt & e516_waveforms_supplementary.hdf5
Learning rate: 0.00019998686108078153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: 0.8150	Cost: 36.47s
Train Epoch: 517 [20480/90000 (23%)]	Loss: -2.7561	Cost: 12.26s
Train Epoch: 517 [40960/90000 (45%)]	Loss: -2.2635	Cost: 18.45s
Train Epoch: 517 [61440/90000 (68%)]	Loss: -2.5419	Cost: 13.20s
Train Epoch: 517 [81920/90000 (91%)]	Loss: -2.6115	Cost: 8.57s
Train Epoch: 517 	Average Loss: -2.3149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7282

Learning rate: 0.00019998681010651175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: 0.5108	Cost: 28.29s
Train Epoch: 518 [20480/90000 (23%)]	Loss: -2.6846	Cost: 11.95s
Train Epoch: 518 [40960/90000 (45%)]	Loss: -1.8400	Cost: 15.75s
Train Epoch: 518 [61440/90000 (68%)]	Loss: -2.4785	Cost: 14.00s
Train Epoch: 518 [81920/90000 (91%)]	Loss: -2.4717	Cost: 14.52s
Train Epoch: 518 	Average Loss: -2.1680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6814

Learning rate: 0.0001999867590335589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: 0.5828	Cost: 28.61s
Train Epoch: 519 [20480/90000 (23%)]	Loss: -2.7999	Cost: 7.19s
Train Epoch: 519 [40960/90000 (45%)]	Loss: -2.3807	Cost: 18.59s
Train Epoch: 519 [61440/90000 (68%)]	Loss: -2.4920	Cost: 14.03s
Train Epoch: 519 [81920/90000 (91%)]	Loss: -2.6765	Cost: 14.43s
Train Epoch: 519 	Average Loss: -2.3554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4936

Saving model as e519_model.pt & e519_waveforms_supplementary.hdf5
Learning rate: 0.00019998670786192314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: 0.5816	Cost: 30.71s
Train Epoch: 520 [20480/90000 (23%)]	Loss: -2.8529	Cost: 13.89s
Train Epoch: 520 [40960/90000 (45%)]	Loss: -2.2422	Cost: 14.80s
Train Epoch: 520 [61440/90000 (68%)]	Loss: -2.3310	Cost: 13.90s
Train Epoch: 520 [81920/90000 (91%)]	Loss: -2.3173	Cost: 14.95s
Train Epoch: 520 	Average Loss: -2.3032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8599

Learning rate: 0.00019998665659160442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: 0.4763	Cost: 44.11s
Train Epoch: 521 [20480/90000 (23%)]	Loss: -2.5087	Cost: 14.21s
Train Epoch: 521 [40960/90000 (45%)]	Loss: -2.0300	Cost: 17.61s
Train Epoch: 521 [61440/90000 (68%)]	Loss: -2.3393	Cost: 13.39s
Train Epoch: 521 [81920/90000 (91%)]	Loss: -2.4253	Cost: 12.95s
Train Epoch: 521 	Average Loss: -2.0962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8020

Learning rate: 0.00019998660522260283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 0.8726	Cost: 35.86s
Train Epoch: 522 [20480/90000 (23%)]	Loss: -2.5730	Cost: 14.70s
Train Epoch: 522 [40960/90000 (45%)]	Loss: -2.1646	Cost: 16.65s
Train Epoch: 522 [61440/90000 (68%)]	Loss: -2.6302	Cost: 14.90s
Train Epoch: 522 [81920/90000 (91%)]	Loss: -2.7629	Cost: 17.76s
Train Epoch: 522 	Average Loss: -2.2596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4876

Saving model as e522_model.pt & e522_waveforms_supplementary.hdf5
Learning rate: 0.00019998655375491842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: 0.5002	Cost: 36.78s
Train Epoch: 523 [20480/90000 (23%)]	Loss: -2.6966	Cost: 12.83s
Train Epoch: 523 [40960/90000 (45%)]	Loss: -2.1927	Cost: 18.34s
Train Epoch: 523 [61440/90000 (68%)]	Loss: -2.5138	Cost: 13.85s
Train Epoch: 523 [81920/90000 (91%)]	Loss: -2.5612	Cost: 14.31s
Train Epoch: 523 	Average Loss: -2.3152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7561

Learning rate: 0.00019998650218855122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: 0.6891	Cost: 29.90s
Train Epoch: 524 [20480/90000 (23%)]	Loss: -2.8148	Cost: 12.86s
Train Epoch: 524 [40960/90000 (45%)]	Loss: -2.2901	Cost: 18.94s
Train Epoch: 524 [61440/90000 (68%)]	Loss: -2.7087	Cost: 15.58s
Train Epoch: 524 [81920/90000 (91%)]	Loss: -2.6254	Cost: 21.04s
Train Epoch: 524 	Average Loss: -2.3975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7746

Learning rate: 0.00019998645052350132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: 0.7477	Cost: 28.40s
Train Epoch: 525 [20480/90000 (23%)]	Loss: -2.5844	Cost: 13.96s
Train Epoch: 525 [40960/90000 (45%)]	Loss: -2.2485	Cost: 22.55s
Train Epoch: 525 [61440/90000 (68%)]	Loss: -2.6542	Cost: 13.85s
Train Epoch: 525 [81920/90000 (91%)]	Loss: -2.8213	Cost: 16.21s
Train Epoch: 525 	Average Loss: -2.3340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4423

Saving model as e525_model.pt & e525_waveforms_supplementary.hdf5
Learning rate: 0.00019998639875976873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: 0.5989	Cost: 29.45s
Train Epoch: 526 [20480/90000 (23%)]	Loss: -2.9197	Cost: 12.90s
Train Epoch: 526 [40960/90000 (45%)]	Loss: -2.3049	Cost: 15.79s
Train Epoch: 526 [61440/90000 (68%)]	Loss: -2.5495	Cost: 13.66s
Train Epoch: 526 [81920/90000 (91%)]	Loss: -2.6921	Cost: 19.71s
Train Epoch: 526 	Average Loss: -2.4141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4478

Learning rate: 0.0001999863468973535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: 0.3700	Cost: 42.47s
Train Epoch: 527 [20480/90000 (23%)]	Loss: -2.9954	Cost: 12.90s
Train Epoch: 527 [40960/90000 (45%)]	Loss: -2.5232	Cost: 17.72s
Train Epoch: 527 [61440/90000 (68%)]	Loss: -2.7071	Cost: 13.83s
Train Epoch: 527 [81920/90000 (91%)]	Loss: -2.4905	Cost: 9.84s
Train Epoch: 527 	Average Loss: -2.4799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8975

Learning rate: 0.00019998629493625576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: 0.6249	Cost: 38.47s
Train Epoch: 528 [20480/90000 (23%)]	Loss: -2.6050	Cost: 13.41s
Train Epoch: 528 [40960/90000 (45%)]	Loss: -1.9334	Cost: 28.12s
Train Epoch: 528 [61440/90000 (68%)]	Loss: -2.5406	Cost: 13.28s
Train Epoch: 528 [81920/90000 (91%)]	Loss: -2.7924	Cost: 9.54s
Train Epoch: 528 	Average Loss: -2.2910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5844

Learning rate: 0.00019998624287647545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: 0.6295	Cost: 30.16s
Train Epoch: 529 [20480/90000 (23%)]	Loss: -2.8669	Cost: 13.11s
Train Epoch: 529 [40960/90000 (45%)]	Loss: -2.4060	Cost: 17.58s
Train Epoch: 529 [61440/90000 (68%)]	Loss: -2.9799	Cost: 14.81s
Train Epoch: 529 [81920/90000 (91%)]	Loss: -2.7634	Cost: 16.47s
Train Epoch: 529 	Average Loss: -2.6267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3806

Saving model as e529_model.pt & e529_waveforms_supplementary.hdf5
Learning rate: 0.0001999861907180127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: 0.4454	Cost: 29.73s
Train Epoch: 530 [20480/90000 (23%)]	Loss: -2.9467	Cost: 12.82s
Train Epoch: 530 [40960/90000 (45%)]	Loss: -2.2439	Cost: 17.57s
Train Epoch: 530 [61440/90000 (68%)]	Loss: -2.8298	Cost: 14.60s
Train Epoch: 530 [81920/90000 (91%)]	Loss: -2.8288	Cost: 13.61s
Train Epoch: 530 	Average Loss: -2.5826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5442

Learning rate: 0.0001999861384608675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: 0.7758	Cost: 30.28s
Train Epoch: 531 [20480/90000 (23%)]	Loss: -2.9447	Cost: 6.70s
Train Epoch: 531 [40960/90000 (45%)]	Loss: -2.4469	Cost: 12.31s
Train Epoch: 531 [61440/90000 (68%)]	Loss: -2.9726	Cost: 13.89s
Train Epoch: 531 [81920/90000 (91%)]	Loss: -2.8704	Cost: 16.43s
Train Epoch: 531 	Average Loss: -2.5830
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4515

Learning rate: 0.00019998608610503996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: 0.5669	Cost: 32.18s
Train Epoch: 532 [20480/90000 (23%)]	Loss: -3.0757	Cost: 11.65s
Train Epoch: 532 [40960/90000 (45%)]	Loss: -2.6738	Cost: 14.41s
Train Epoch: 532 [61440/90000 (68%)]	Loss: -2.9311	Cost: 14.05s
Train Epoch: 532 [81920/90000 (91%)]	Loss: -2.8001	Cost: 12.64s
Train Epoch: 532 	Average Loss: -2.6130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2919

Saving model as e532_model.pt & e532_waveforms_supplementary.hdf5
Learning rate: 0.00019998603365053012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: 0.1004	Cost: 35.53s
Train Epoch: 533 [20480/90000 (23%)]	Loss: -3.0031	Cost: 13.89s
Train Epoch: 533 [40960/90000 (45%)]	Loss: -2.5496	Cost: 14.23s
Train Epoch: 533 [61440/90000 (68%)]	Loss: -2.8908	Cost: 13.06s
Train Epoch: 533 [81920/90000 (91%)]	Loss: -2.9640	Cost: 12.04s
Train Epoch: 533 	Average Loss: -2.6662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3534

Learning rate: 0.00019998598109733802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: 0.1240	Cost: 28.36s
Train Epoch: 534 [20480/90000 (23%)]	Loss: -2.6890	Cost: 13.07s
Train Epoch: 534 [40960/90000 (45%)]	Loss: -2.2760	Cost: 14.37s
Train Epoch: 534 [61440/90000 (68%)]	Loss: -2.6631	Cost: 14.32s
Train Epoch: 534 [81920/90000 (91%)]	Loss: -2.7628	Cost: 12.21s
Train Epoch: 534 	Average Loss: -2.4456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4504

Learning rate: 0.0001999859284454637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: 0.5421	Cost: 27.48s
Train Epoch: 535 [20480/90000 (23%)]	Loss: -2.9535	Cost: 8.31s
Train Epoch: 535 [40960/90000 (45%)]	Loss: -2.6156	Cost: 15.12s
Train Epoch: 535 [61440/90000 (68%)]	Loss: -3.0675	Cost: 13.70s
Train Epoch: 535 [81920/90000 (91%)]	Loss: -2.8130	Cost: 12.55s
Train Epoch: 535 	Average Loss: -2.6841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4278

Learning rate: 0.00019998587569490723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: 0.0262	Cost: 34.64s
Train Epoch: 536 [20480/90000 (23%)]	Loss: -3.1537	Cost: 8.36s
Train Epoch: 536 [40960/90000 (45%)]	Loss: -2.7418	Cost: 13.42s
Train Epoch: 536 [61440/90000 (68%)]	Loss: -2.9197	Cost: 12.04s
Train Epoch: 536 [81920/90000 (91%)]	Loss: -3.0065	Cost: 12.40s
Train Epoch: 536 	Average Loss: -2.7293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3750

Learning rate: 0.00019998582284566865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: 0.3696	Cost: 37.07s
Train Epoch: 537 [20480/90000 (23%)]	Loss: -3.2088	Cost: 12.73s
Train Epoch: 537 [40960/90000 (45%)]	Loss: -2.5929	Cost: 14.32s
Train Epoch: 537 [61440/90000 (68%)]	Loss: -2.8674	Cost: 12.48s
Train Epoch: 537 [81920/90000 (91%)]	Loss: -2.8991	Cost: 12.32s
Train Epoch: 537 	Average Loss: -2.6856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3881

Learning rate: 0.00019998576989774803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: 0.2512	Cost: 36.41s
Train Epoch: 538 [20480/90000 (23%)]	Loss: -2.9784	Cost: 14.22s
Train Epoch: 538 [40960/90000 (45%)]	Loss: -2.6777	Cost: 18.69s
Train Epoch: 538 [61440/90000 (68%)]	Loss: -2.6773	Cost: 15.22s
Train Epoch: 538 [81920/90000 (91%)]	Loss: -2.9430	Cost: 15.00s
Train Epoch: 538 	Average Loss: -2.6095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3771

Learning rate: 0.0001999857168511454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: -0.1508	Cost: 37.08s
Train Epoch: 539 [20480/90000 (23%)]	Loss: -3.1238	Cost: 15.57s
Train Epoch: 539 [40960/90000 (45%)]	Loss: -2.6149	Cost: 14.51s
Train Epoch: 539 [61440/90000 (68%)]	Loss: -2.9847	Cost: 14.59s
Train Epoch: 539 [81920/90000 (91%)]	Loss: -2.8634	Cost: 11.39s
Train Epoch: 539 	Average Loss: -2.7324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3331

Learning rate: 0.00019998566370586085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: 0.3268	Cost: 27.61s
Train Epoch: 540 [20480/90000 (23%)]	Loss: -3.1471	Cost: 9.49s
Train Epoch: 540 [40960/90000 (45%)]	Loss: -2.0804	Cost: 13.97s
Train Epoch: 540 [61440/90000 (68%)]	Loss: -2.1584	Cost: 16.32s
Train Epoch: 540 [81920/90000 (91%)]	Loss: -2.2695	Cost: 15.44s
Train Epoch: 540 	Average Loss: -2.2110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6775

Learning rate: 0.0001999856104618944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: 0.7951	Cost: 31.99s
Train Epoch: 541 [20480/90000 (23%)]	Loss: -2.8658	Cost: 10.21s
Train Epoch: 541 [40960/90000 (45%)]	Loss: -2.6009	Cost: 12.11s
Train Epoch: 541 [61440/90000 (68%)]	Loss: -3.0653	Cost: 12.05s
Train Epoch: 541 [81920/90000 (91%)]	Loss: -2.9671	Cost: 12.77s
Train Epoch: 541 	Average Loss: -2.5983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3795

Learning rate: 0.0001999855571192461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: 0.4820	Cost: 29.37s
Train Epoch: 542 [20480/90000 (23%)]	Loss: -2.5958	Cost: 11.63s
Train Epoch: 542 [40960/90000 (45%)]	Loss: -2.1738	Cost: 12.99s
Train Epoch: 542 [61440/90000 (68%)]	Loss: -2.8242	Cost: 12.56s
Train Epoch: 542 [81920/90000 (91%)]	Loss: -2.8062	Cost: 12.58s
Train Epoch: 542 	Average Loss: -2.3916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4563

Learning rate: 0.00019998550367791602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: 0.5811	Cost: 27.37s
Train Epoch: 543 [20480/90000 (23%)]	Loss: -2.4457	Cost: 10.63s
Train Epoch: 543 [40960/90000 (45%)]	Loss: -2.3566	Cost: 14.34s
Train Epoch: 543 [61440/90000 (68%)]	Loss: -2.9218	Cost: 14.39s
Train Epoch: 543 [81920/90000 (91%)]	Loss: -2.7037	Cost: 16.75s
Train Epoch: 543 	Average Loss: -2.4319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5309

Learning rate: 0.0001999854501379042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: 0.3655	Cost: 31.67s
Train Epoch: 544 [20480/90000 (23%)]	Loss: -3.1089	Cost: 13.50s
Train Epoch: 544 [40960/90000 (45%)]	Loss: -2.6266	Cost: 14.60s
Train Epoch: 544 [61440/90000 (68%)]	Loss: -2.8786	Cost: 12.44s
Train Epoch: 544 [81920/90000 (91%)]	Loss: -3.1049	Cost: 11.35s
Train Epoch: 544 	Average Loss: -2.7200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3415

Learning rate: 0.00019998539649921068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: 0.0668	Cost: 28.74s
Train Epoch: 545 [20480/90000 (23%)]	Loss: -2.8611	Cost: 7.66s
Train Epoch: 545 [40960/90000 (45%)]	Loss: -2.3554	Cost: 13.05s
Train Epoch: 545 [61440/90000 (68%)]	Loss: -2.8241	Cost: 13.49s
Train Epoch: 545 [81920/90000 (91%)]	Loss: -2.7588	Cost: 14.59s
Train Epoch: 545 	Average Loss: -2.4709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4797

Learning rate: 0.00019998534276183553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: 0.7349	Cost: 32.13s
Train Epoch: 546 [20480/90000 (23%)]	Loss: -2.6231	Cost: 8.38s
Train Epoch: 546 [40960/90000 (45%)]	Loss: -2.0387	Cost: 14.99s
Train Epoch: 546 [61440/90000 (68%)]	Loss: -2.7005	Cost: 15.42s
Train Epoch: 546 [81920/90000 (91%)]	Loss: -2.8525	Cost: 15.35s
Train Epoch: 546 	Average Loss: -2.3706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4161

Learning rate: 0.00019998528892577877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: 0.4365	Cost: 28.68s
Train Epoch: 547 [20480/90000 (23%)]	Loss: -3.1583	Cost: 11.71s
Train Epoch: 547 [40960/90000 (45%)]	Loss: -2.7747	Cost: 14.71s
Train Epoch: 547 [61440/90000 (68%)]	Loss: -3.1667	Cost: 13.89s
Train Epoch: 547 [81920/90000 (91%)]	Loss: -3.3592	Cost: 12.17s
Train Epoch: 547 	Average Loss: -2.8702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1716

Saving model as e547_model.pt & e547_waveforms_supplementary.hdf5
Learning rate: 0.00019998523499104056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: 0.4853	Cost: 28.47s
Train Epoch: 548 [20480/90000 (23%)]	Loss: -3.4234	Cost: 16.18s
Train Epoch: 548 [40960/90000 (45%)]	Loss: -2.8604	Cost: 15.15s
Train Epoch: 548 [61440/90000 (68%)]	Loss: -3.0199	Cost: 12.85s
Train Epoch: 548 [81920/90000 (91%)]	Loss: -3.1909	Cost: 11.85s
Train Epoch: 548 	Average Loss: -2.9256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1689

Saving model as e548_model.pt & e548_waveforms_supplementary.hdf5
Learning rate: 0.0001999851809576208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: 0.3592	Cost: 27.54s
Train Epoch: 549 [20480/90000 (23%)]	Loss: -3.3807	Cost: 12.58s
Train Epoch: 549 [40960/90000 (45%)]	Loss: -2.8667	Cost: 15.18s
Train Epoch: 549 [61440/90000 (68%)]	Loss: -3.2593	Cost: 13.27s
Train Epoch: 549 [81920/90000 (91%)]	Loss: -3.0297	Cost: 13.29s
Train Epoch: 549 	Average Loss: -2.9196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3962

Learning rate: 0.00019998512682551964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: 0.5459	Cost: 31.60s
Train Epoch: 550 [20480/90000 (23%)]	Loss: -2.9599	Cost: 12.47s
Train Epoch: 550 [40960/90000 (45%)]	Loss: -2.6747	Cost: 14.26s
Train Epoch: 550 [61440/90000 (68%)]	Loss: -3.1661	Cost: 15.45s
Train Epoch: 550 [81920/90000 (91%)]	Loss: -3.0422	Cost: 14.65s
Train Epoch: 550 	Average Loss: -2.7587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1281

Saving model as e550_model.pt & e550_waveforms_supplementary.hdf5
Learning rate: 0.00019998507259473715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: 0.1016	Cost: 29.48s
Train Epoch: 551 [20480/90000 (23%)]	Loss: -3.3799	Cost: 14.53s
Train Epoch: 551 [40960/90000 (45%)]	Loss: -2.6348	Cost: 14.71s
Train Epoch: 551 [61440/90000 (68%)]	Loss: -3.0200	Cost: 14.83s
Train Epoch: 551 [81920/90000 (91%)]	Loss: -3.0598	Cost: 15.58s
Train Epoch: 551 	Average Loss: -2.8940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2840

Learning rate: 0.00019998501826527334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: -0.3755	Cost: 31.69s
Train Epoch: 552 [20480/90000 (23%)]	Loss: -3.3296	Cost: 14.64s
Train Epoch: 552 [40960/90000 (45%)]	Loss: -2.9510	Cost: 14.30s
Train Epoch: 552 [61440/90000 (68%)]	Loss: -3.3080	Cost: 14.57s
Train Epoch: 552 [81920/90000 (91%)]	Loss: -3.1937	Cost: 13.46s
Train Epoch: 552 	Average Loss: -2.9865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2189

Learning rate: 0.00019998496383712825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: 0.1476	Cost: 29.44s
Train Epoch: 553 [20480/90000 (23%)]	Loss: -3.2835	Cost: 10.70s
Train Epoch: 553 [40960/90000 (45%)]	Loss: -2.9294	Cost: 16.26s
Train Epoch: 553 [61440/90000 (68%)]	Loss: -3.3295	Cost: 14.36s
Train Epoch: 553 [81920/90000 (91%)]	Loss: -3.4540	Cost: 16.14s
Train Epoch: 553 	Average Loss: -3.0252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1342

Learning rate: 0.000199984909310302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: 0.0049	Cost: 29.06s
Train Epoch: 554 [20480/90000 (23%)]	Loss: -3.2628	Cost: 12.51s
Train Epoch: 554 [40960/90000 (45%)]	Loss: -2.9257	Cost: 24.07s
Train Epoch: 554 [61440/90000 (68%)]	Loss: -3.3041	Cost: 14.98s
Train Epoch: 554 [81920/90000 (91%)]	Loss: -3.4402	Cost: 17.57s
Train Epoch: 554 	Average Loss: -3.0604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1135

Saving model as e554_model.pt & e554_waveforms_supplementary.hdf5
Learning rate: 0.00019998485468479454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: 0.0285	Cost: 34.68s
Train Epoch: 555 [20480/90000 (23%)]	Loss: -3.7101	Cost: 15.07s
Train Epoch: 555 [40960/90000 (45%)]	Loss: -3.2166	Cost: 17.65s
Train Epoch: 555 [61440/90000 (68%)]	Loss: -3.4314	Cost: 14.43s
Train Epoch: 555 [81920/90000 (91%)]	Loss: -3.6988	Cost: 12.53s
Train Epoch: 555 	Average Loss: -3.2798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0783

Learning rate: 0.000199984799960606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: -0.1130	Cost: 29.71s
Train Epoch: 556 [20480/90000 (23%)]	Loss: -3.6162	Cost: 11.37s
Train Epoch: 556 [40960/90000 (45%)]	Loss: -3.1556	Cost: 15.22s
Train Epoch: 556 [61440/90000 (68%)]	Loss: -3.4111	Cost: 13.80s
Train Epoch: 556 [81920/90000 (91%)]	Loss: -3.5504	Cost: 18.15s
Train Epoch: 556 	Average Loss: -3.2176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0479

Learning rate: 0.00019998474513773643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: -0.3098	Cost: 27.69s
Train Epoch: 557 [20480/90000 (23%)]	Loss: -3.5662	Cost: 11.58s
Train Epoch: 557 [40960/90000 (45%)]	Loss: -2.8884	Cost: 21.39s
Train Epoch: 557 [61440/90000 (68%)]	Loss: -3.1678	Cost: 14.48s
Train Epoch: 557 [81920/90000 (91%)]	Loss: -3.5851	Cost: 17.13s
Train Epoch: 557 	Average Loss: -3.0942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0667

Learning rate: 0.00019998469021618588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: -0.3015	Cost: 35.69s
Train Epoch: 558 [20480/90000 (23%)]	Loss: -3.5833	Cost: 14.65s
Train Epoch: 558 [40960/90000 (45%)]	Loss: -3.2319	Cost: 15.19s
Train Epoch: 558 [61440/90000 (68%)]	Loss: -1.6391	Cost: 14.95s
Train Epoch: 558 [81920/90000 (91%)]	Loss: -1.8080	Cost: 13.58s
Train Epoch: 558 	Average Loss: -2.5742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1816

Learning rate: 0.00019998463519595438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: 1.1615	Cost: 36.07s
Train Epoch: 559 [20480/90000 (23%)]	Loss: -2.6636	Cost: 14.28s
Train Epoch: 559 [40960/90000 (45%)]	Loss: -2.5068	Cost: 17.29s
Train Epoch: 559 [61440/90000 (68%)]	Loss: -2.9175	Cost: 15.22s
Train Epoch: 559 [81920/90000 (91%)]	Loss: -3.1662	Cost: 17.94s
Train Epoch: 559 	Average Loss: -2.4690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1697

Learning rate: 0.000199984580077042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: 0.0081	Cost: 28.77s
Train Epoch: 560 [20480/90000 (23%)]	Loss: -3.3074	Cost: 12.59s
Train Epoch: 560 [40960/90000 (45%)]	Loss: -3.0276	Cost: 18.81s
Train Epoch: 560 [61440/90000 (68%)]	Loss: -3.4528	Cost: 14.61s
Train Epoch: 560 [81920/90000 (91%)]	Loss: -3.5533	Cost: 21.67s
Train Epoch: 560 	Average Loss: -3.0988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1122

Learning rate: 0.00019998452485944882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: -0.2474	Cost: 28.18s
Train Epoch: 561 [20480/90000 (23%)]	Loss: -3.6224	Cost: 7.63s
Train Epoch: 561 [40960/90000 (45%)]	Loss: -3.0676	Cost: 14.80s
Train Epoch: 561 [61440/90000 (68%)]	Loss: -3.4309	Cost: 15.34s
Train Epoch: 561 [81920/90000 (91%)]	Loss: -3.5080	Cost: 14.78s
Train Epoch: 561 	Average Loss: -3.2121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0998

Learning rate: 0.00019998446954317485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: 0.0170	Cost: 30.15s
Train Epoch: 562 [20480/90000 (23%)]	Loss: -3.3406	Cost: 7.09s
Train Epoch: 562 [40960/90000 (45%)]	Loss: -3.0665	Cost: 12.88s
Train Epoch: 562 [61440/90000 (68%)]	Loss: -3.3263	Cost: 13.64s
Train Epoch: 562 [81920/90000 (91%)]	Loss: -3.5850	Cost: 14.79s
Train Epoch: 562 	Average Loss: -3.1076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1715

Saving model as e562_model.pt & e562_waveforms_supplementary.hdf5
Learning rate: 0.00019998441412822013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: -0.2286	Cost: 29.55s
Train Epoch: 563 [20480/90000 (23%)]	Loss: -3.7812	Cost: 13.02s
Train Epoch: 563 [40960/90000 (45%)]	Loss: -3.3801	Cost: 14.25s
Train Epoch: 563 [61440/90000 (68%)]	Loss: -3.5982	Cost: 13.46s
Train Epoch: 563 [81920/90000 (91%)]	Loss: -3.8276	Cost: 12.87s
Train Epoch: 563 	Average Loss: -3.3821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1862

Saving model as e563_model.pt & e563_waveforms_supplementary.hdf5
Learning rate: 0.0001999843586145848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: -0.0227	Cost: 30.08s
Train Epoch: 564 [20480/90000 (23%)]	Loss: -3.6689	Cost: 14.42s
Train Epoch: 564 [40960/90000 (45%)]	Loss: -3.1236	Cost: 14.33s
Train Epoch: 564 [61440/90000 (68%)]	Loss: -3.4475	Cost: 13.39s
Train Epoch: 564 [81920/90000 (91%)]	Loss: -3.6287	Cost: 12.12s
Train Epoch: 564 	Average Loss: -3.2059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1821

Learning rate: 0.00019998430300226887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: 0.0349	Cost: 27.87s
Train Epoch: 565 [20480/90000 (23%)]	Loss: -3.3138	Cost: 11.87s
Train Epoch: 565 [40960/90000 (45%)]	Loss: -2.9124	Cost: 15.85s
Train Epoch: 565 [61440/90000 (68%)]	Loss: -3.2613	Cost: 13.02s
Train Epoch: 565 [81920/90000 (91%)]	Loss: -3.2560	Cost: 18.41s
Train Epoch: 565 	Average Loss: -3.0278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3705

Learning rate: 0.0001999842472912724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: 0.5163	Cost: 29.11s
Train Epoch: 566 [20480/90000 (23%)]	Loss: -3.1699	Cost: 12.30s
Train Epoch: 566 [40960/90000 (45%)]	Loss: -2.8850	Cost: 14.57s
Train Epoch: 566 [61440/90000 (68%)]	Loss: -3.3521	Cost: 14.47s
Train Epoch: 566 [81920/90000 (91%)]	Loss: -3.6562	Cost: 15.76s
Train Epoch: 566 	Average Loss: -3.0482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2555

Saving model as e566_model.pt & e566_waveforms_supplementary.hdf5
Learning rate: 0.0001999841914815954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: 0.0274	Cost: 32.21s
Train Epoch: 567 [20480/90000 (23%)]	Loss: -3.7016	Cost: 14.85s
Train Epoch: 567 [40960/90000 (45%)]	Loss: -3.3989	Cost: 15.17s
Train Epoch: 567 [61440/90000 (68%)]	Loss: -3.5315	Cost: 15.87s
Train Epoch: 567 [81920/90000 (91%)]	Loss: -3.8774	Cost: 14.05s
Train Epoch: 567 	Average Loss: -3.4494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2447

Learning rate: 0.00019998413557323794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: -0.1915	Cost: 38.61s
Train Epoch: 568 [20480/90000 (23%)]	Loss: -3.9499	Cost: 14.76s
Train Epoch: 568 [40960/90000 (45%)]	Loss: -3.5136	Cost: 13.53s
Train Epoch: 568 [61440/90000 (68%)]	Loss: -3.7551	Cost: 16.06s
Train Epoch: 568 [81920/90000 (91%)]	Loss: -3.6917	Cost: 12.75s
Train Epoch: 568 	Average Loss: -3.5416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2458

Learning rate: 0.00019998407956620012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: -0.3414	Cost: 28.85s
Train Epoch: 569 [20480/90000 (23%)]	Loss: -4.0176	Cost: 12.15s
Train Epoch: 569 [40960/90000 (45%)]	Loss: -3.4047	Cost: 16.90s
Train Epoch: 569 [61440/90000 (68%)]	Loss: -3.8763	Cost: 15.51s
Train Epoch: 569 [81920/90000 (91%)]	Loss: -3.8578	Cost: 15.97s
Train Epoch: 569 	Average Loss: -3.5597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2815

Saving model as e569_model.pt & e569_waveforms_supplementary.hdf5
Learning rate: 0.00019998402346048196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: -0.1943	Cost: 32.52s
Train Epoch: 570 [20480/90000 (23%)]	Loss: -3.9835	Cost: 14.47s
Train Epoch: 570 [40960/90000 (45%)]	Loss: -3.5469	Cost: 16.47s
Train Epoch: 570 [61440/90000 (68%)]	Loss: -3.8280	Cost: 15.75s
Train Epoch: 570 [81920/90000 (91%)]	Loss: -3.8538	Cost: 12.91s
Train Epoch: 570 	Average Loss: -3.5735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3338

Saving model as e570_model.pt & e570_waveforms_supplementary.hdf5
Learning rate: 0.0001999839672560835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: -0.3818	Cost: 31.58s
Train Epoch: 571 [20480/90000 (23%)]	Loss: -3.9424	Cost: 15.14s
Train Epoch: 571 [40960/90000 (45%)]	Loss: -3.4898	Cost: 20.37s
Train Epoch: 571 [61440/90000 (68%)]	Loss: -3.6249	Cost: 12.59s
Train Epoch: 571 [81920/90000 (91%)]	Loss: -3.7480	Cost: 18.70s
Train Epoch: 571 	Average Loss: -3.6194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2147

Learning rate: 0.00019998391095300483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: -0.1050	Cost: 27.97s
Train Epoch: 572 [20480/90000 (23%)]	Loss: -3.9688	Cost: 15.00s
Train Epoch: 572 [40960/90000 (45%)]	Loss: -3.4171	Cost: 16.14s
Train Epoch: 572 [61440/90000 (68%)]	Loss: -3.8462	Cost: 15.27s
Train Epoch: 572 [81920/90000 (91%)]	Loss: -3.6778	Cost: 20.08s
Train Epoch: 572 	Average Loss: -3.5138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2913

Learning rate: 0.00019998385455124602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: -0.6365	Cost: 26.93s
Train Epoch: 573 [20480/90000 (23%)]	Loss: -3.9129	Cost: 10.32s
Train Epoch: 573 [40960/90000 (45%)]	Loss: -3.3950	Cost: 20.16s
Train Epoch: 573 [61440/90000 (68%)]	Loss: -3.4419	Cost: 15.91s
Train Epoch: 573 [81920/90000 (91%)]	Loss: -3.5408	Cost: 16.04s
Train Epoch: 573 	Average Loss: -3.3887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1909

Learning rate: 0.00019998379805080712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: -0.1930	Cost: 35.06s
Train Epoch: 574 [20480/90000 (23%)]	Loss: -3.3341	Cost: 11.74s
Train Epoch: 574 [40960/90000 (45%)]	Loss: -3.1499	Cost: 15.59s
Train Epoch: 574 [61440/90000 (68%)]	Loss: -3.5317	Cost: 13.31s
Train Epoch: 574 [81920/90000 (91%)]	Loss: -3.8103	Cost: 15.22s
Train Epoch: 574 	Average Loss: -3.2394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3713

Saving model as e574_model.pt & e574_waveforms_supplementary.hdf5
Learning rate: 0.00019998374145168815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: -0.2417	Cost: 32.48s
Train Epoch: 575 [20480/90000 (23%)]	Loss: -4.0989	Cost: 14.48s
Train Epoch: 575 [40960/90000 (45%)]	Loss: -3.4917	Cost: 16.02s
Train Epoch: 575 [61440/90000 (68%)]	Loss: -3.8844	Cost: 16.10s
Train Epoch: 575 [81920/90000 (91%)]	Loss: -3.9908	Cost: 16.31s
Train Epoch: 575 	Average Loss: -3.6203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5290

Saving model as e575_model.pt & e575_waveforms_supplementary.hdf5
Learning rate: 0.00019998368475388916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: 0.1678	Cost: 31.82s
Train Epoch: 576 [20480/90000 (23%)]	Loss: -4.0905	Cost: 15.04s
Train Epoch: 576 [40960/90000 (45%)]	Loss: -3.3659	Cost: 18.73s
Train Epoch: 576 [61440/90000 (68%)]	Loss: -3.6002	Cost: 14.92s
Train Epoch: 576 [81920/90000 (91%)]	Loss: -3.8518	Cost: 16.43s
Train Epoch: 576 	Average Loss: -3.5054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2437

Learning rate: 0.00019998362795741026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: -0.2390	Cost: 27.36s
Train Epoch: 577 [20480/90000 (23%)]	Loss: -3.9130	Cost: 10.68s
Train Epoch: 577 [40960/90000 (45%)]	Loss: -3.4656	Cost: 15.66s
Train Epoch: 577 [61440/90000 (68%)]	Loss: -3.4209	Cost: 13.12s
Train Epoch: 577 [81920/90000 (91%)]	Loss: -3.3866	Cost: 21.30s
Train Epoch: 577 	Average Loss: -3.3490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1444

Learning rate: 0.00019998357106225145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: 0.1551	Cost: 29.98s
Train Epoch: 578 [20480/90000 (23%)]	Loss: -3.6410	Cost: 11.25s
Train Epoch: 578 [40960/90000 (45%)]	Loss: -3.2965	Cost: 14.87s
Train Epoch: 578 [61440/90000 (68%)]	Loss: -3.6123	Cost: 13.69s
Train Epoch: 578 [81920/90000 (91%)]	Loss: -3.8048	Cost: 14.59s
Train Epoch: 578 	Average Loss: -3.3754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5061

Learning rate: 0.00019998351406841282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: -0.3726	Cost: 36.60s
Train Epoch: 579 [20480/90000 (23%)]	Loss: -3.9931	Cost: 14.74s
Train Epoch: 579 [40960/90000 (45%)]	Loss: -3.5818	Cost: 12.02s
Train Epoch: 579 [61440/90000 (68%)]	Loss: -3.8150	Cost: 14.68s
Train Epoch: 579 [81920/90000 (91%)]	Loss: -3.8802	Cost: 12.15s
Train Epoch: 579 	Average Loss: -3.6073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3730

Learning rate: 0.0001999834569758944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: -0.2723	Cost: 27.19s
Train Epoch: 580 [20480/90000 (23%)]	Loss: -4.1635	Cost: 9.81s
Train Epoch: 580 [40960/90000 (45%)]	Loss: -3.6774	Cost: 17.24s
Train Epoch: 580 [61440/90000 (68%)]	Loss: -3.8240	Cost: 12.83s
Train Epoch: 580 [81920/90000 (91%)]	Loss: -4.0291	Cost: 19.99s
Train Epoch: 580 	Average Loss: -3.7008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4252

Learning rate: 0.00019998339978469627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: -0.3179	Cost: 30.31s
Train Epoch: 581 [20480/90000 (23%)]	Loss: -3.7507	Cost: 8.44s
Train Epoch: 581 [40960/90000 (45%)]	Loss: -3.1536	Cost: 13.57s
Train Epoch: 581 [61440/90000 (68%)]	Loss: -3.4110	Cost: 14.69s
Train Epoch: 581 [81920/90000 (91%)]	Loss: -3.4023	Cost: 14.67s
Train Epoch: 581 	Average Loss: -3.2234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0787

Learning rate: 0.0001999833424948185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: -0.0553	Cost: 29.02s
Train Epoch: 582 [20480/90000 (23%)]	Loss: -3.6584	Cost: 9.41s
Train Epoch: 582 [40960/90000 (45%)]	Loss: -2.9856	Cost: 13.67s
Train Epoch: 582 [61440/90000 (68%)]	Loss: -3.7437	Cost: 13.61s
Train Epoch: 582 [81920/90000 (91%)]	Loss: -3.7913	Cost: 15.05s
Train Epoch: 582 	Average Loss: -3.3076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3347

Learning rate: 0.00019998328510626112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: -0.4900	Cost: 27.79s
Train Epoch: 583 [20480/90000 (23%)]	Loss: -3.9596	Cost: 6.98s
Train Epoch: 583 [40960/90000 (45%)]	Loss: -3.3592	Cost: 18.70s
Train Epoch: 583 [61440/90000 (68%)]	Loss: -3.7435	Cost: 14.16s
Train Epoch: 583 [81920/90000 (91%)]	Loss: -3.8433	Cost: 15.13s
Train Epoch: 583 	Average Loss: -3.5257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4032

Learning rate: 0.0001999832276190242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: -0.5401	Cost: 27.46s
Train Epoch: 584 [20480/90000 (23%)]	Loss: -4.1523	Cost: 8.01s
Train Epoch: 584 [40960/90000 (45%)]	Loss: -3.7737	Cost: 17.14s
Train Epoch: 584 [61440/90000 (68%)]	Loss: -3.9818	Cost: 12.27s
Train Epoch: 584 [81920/90000 (91%)]	Loss: -4.0967	Cost: 18.52s
Train Epoch: 584 	Average Loss: -3.7398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4492

Learning rate: 0.00019998317003310778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: -0.4305	Cost: 26.93s
Train Epoch: 585 [20480/90000 (23%)]	Loss: -4.2745	Cost: 9.20s
Train Epoch: 585 [40960/90000 (45%)]	Loss: -3.8209	Cost: 14.80s
Train Epoch: 585 [61440/90000 (68%)]	Loss: -4.0074	Cost: 14.12s
Train Epoch: 585 [81920/90000 (91%)]	Loss: -4.2031	Cost: 14.36s
Train Epoch: 585 	Average Loss: -3.8080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5797

Saving model as e585_model.pt & e585_waveforms_supplementary.hdf5
Learning rate: 0.0001999831123485119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: -0.7392	Cost: 33.11s
Train Epoch: 586 [20480/90000 (23%)]	Loss: -4.3510	Cost: 13.72s
Train Epoch: 586 [40960/90000 (45%)]	Loss: -3.9265	Cost: 15.15s
Train Epoch: 586 [61440/90000 (68%)]	Loss: -4.2718	Cost: 14.64s
Train Epoch: 586 [81920/90000 (91%)]	Loss: -4.0768	Cost: 13.79s
Train Epoch: 586 	Average Loss: -3.9703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7057

Saving model as e586_model.pt & e586_waveforms_supplementary.hdf5
Learning rate: 0.00019998305456523665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: -0.5932	Cost: 29.78s
Train Epoch: 587 [20480/90000 (23%)]	Loss: -4.2671	Cost: 13.91s
Train Epoch: 587 [40960/90000 (45%)]	Loss: -3.9049	Cost: 14.60s
Train Epoch: 587 [61440/90000 (68%)]	Loss: -3.9134	Cost: 14.06s
Train Epoch: 587 [81920/90000 (91%)]	Loss: -4.3033	Cost: 14.17s
Train Epoch: 587 	Average Loss: -3.9279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7215

Saving model as e587_model.pt & e587_waveforms_supplementary.hdf5
Learning rate: 0.0001999829966832821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: -1.0031	Cost: 30.10s
Train Epoch: 588 [20480/90000 (23%)]	Loss: -4.5651	Cost: 14.55s
Train Epoch: 588 [40960/90000 (45%)]	Loss: -3.6295	Cost: 21.24s
Train Epoch: 588 [61440/90000 (68%)]	Loss: -3.9539	Cost: 15.35s
Train Epoch: 588 [81920/90000 (91%)]	Loss: -4.2682	Cost: 15.98s
Train Epoch: 588 	Average Loss: -3.9573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7057

Learning rate: 0.00019998293870264827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: -0.6728	Cost: 27.93s
Train Epoch: 589 [20480/90000 (23%)]	Loss: -4.4854	Cost: 13.54s
Train Epoch: 589 [40960/90000 (45%)]	Loss: -4.0028	Cost: 14.84s
Train Epoch: 589 [61440/90000 (68%)]	Loss: -2.7032	Cost: 14.54s
Train Epoch: 589 [81920/90000 (91%)]	Loss: -2.6107	Cost: 16.28s
Train Epoch: 589 	Average Loss: -3.3781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7816

Learning rate: 0.00019998288062333524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: 0.9231	Cost: 38.96s
Train Epoch: 590 [20480/90000 (23%)]	Loss: -3.0009	Cost: 14.36s
Train Epoch: 590 [40960/90000 (45%)]	Loss: -3.0316	Cost: 25.86s
Train Epoch: 590 [61440/90000 (68%)]	Loss: -3.3367	Cost: 14.99s
Train Epoch: 590 [81920/90000 (91%)]	Loss: -3.7269	Cost: 10.70s
Train Epoch: 590 	Average Loss: -2.9798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2390

Learning rate: 0.00019998282244534305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: 0.0545	Cost: 31.60s
Train Epoch: 591 [20480/90000 (23%)]	Loss: -4.1088	Cost: 13.46s
Train Epoch: 591 [40960/90000 (45%)]	Loss: -3.8542	Cost: 16.35s
Train Epoch: 591 [61440/90000 (68%)]	Loss: -3.8705	Cost: 14.67s
Train Epoch: 591 [81920/90000 (91%)]	Loss: -4.1114	Cost: 14.07s
Train Epoch: 591 	Average Loss: -3.7629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5463

Learning rate: 0.0001999827641686718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: -0.3218	Cost: 35.15s
Train Epoch: 592 [20480/90000 (23%)]	Loss: -4.2710	Cost: 10.09s
Train Epoch: 592 [40960/90000 (45%)]	Loss: -4.0386	Cost: 18.89s
Train Epoch: 592 [61440/90000 (68%)]	Loss: -4.1845	Cost: 9.15s
Train Epoch: 592 [81920/90000 (91%)]	Loss: -4.2869	Cost: 11.39s
Train Epoch: 592 	Average Loss: -3.9691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6897

Learning rate: 0.0001999827057933215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: -0.5931	Cost: 31.92s
Train Epoch: 593 [20480/90000 (23%)]	Loss: -4.2115	Cost: 15.11s
Train Epoch: 593 [40960/90000 (45%)]	Loss: -3.8826	Cost: 13.08s
Train Epoch: 593 [61440/90000 (68%)]	Loss: -4.1001	Cost: 14.57s
Train Epoch: 593 [81920/90000 (91%)]	Loss: -4.3569	Cost: 12.66s
Train Epoch: 593 	Average Loss: -3.9899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6961

Learning rate: 0.0001999826473192922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: -1.0389	Cost: 27.50s
Train Epoch: 594 [20480/90000 (23%)]	Loss: -4.6251	Cost: 7.28s
Train Epoch: 594 [40960/90000 (45%)]	Loss: -4.2104	Cost: 18.36s
Train Epoch: 594 [61440/90000 (68%)]	Loss: -4.0491	Cost: 16.15s
Train Epoch: 594 [81920/90000 (91%)]	Loss: -4.0763	Cost: 18.67s
Train Epoch: 594 	Average Loss: -4.0920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6168

Learning rate: 0.00019998258874658403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: -0.7489	Cost: 28.55s
Train Epoch: 595 [20480/90000 (23%)]	Loss: -4.0690	Cost: 6.62s
Train Epoch: 595 [40960/90000 (45%)]	Loss: -3.5378	Cost: 16.49s
Train Epoch: 595 [61440/90000 (68%)]	Loss: -3.8703	Cost: 14.59s
Train Epoch: 595 [81920/90000 (91%)]	Loss: -4.1325	Cost: 14.64s
Train Epoch: 595 	Average Loss: -3.6955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6044

Learning rate: 0.00019998253007519698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: -0.2815	Cost: 29.79s
Train Epoch: 596 [20480/90000 (23%)]	Loss: -4.3662	Cost: 6.58s
Train Epoch: 596 [40960/90000 (45%)]	Loss: -3.7202	Cost: 13.63s
Train Epoch: 596 [61440/90000 (68%)]	Loss: -4.0537	Cost: 12.47s
Train Epoch: 596 [81920/90000 (91%)]	Loss: -4.3463	Cost: 14.79s
Train Epoch: 596 	Average Loss: -3.8645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6763

Learning rate: 0.00019998247130513115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: -0.7605	Cost: 28.05s
Train Epoch: 597 [20480/90000 (23%)]	Loss: -4.4202	Cost: 7.72s
Train Epoch: 597 [40960/90000 (45%)]	Loss: -3.8691	Cost: 14.02s
Train Epoch: 597 [61440/90000 (68%)]	Loss: -4.1204	Cost: 13.93s
Train Epoch: 597 [81920/90000 (91%)]	Loss: -4.2186	Cost: 12.61s
Train Epoch: 597 	Average Loss: -3.9228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6825

Learning rate: 0.00019998241243638655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: -0.7819	Cost: 26.59s
Train Epoch: 598 [20480/90000 (23%)]	Loss: -4.3954	Cost: 8.57s
Train Epoch: 598 [40960/90000 (45%)]	Loss: -3.9329	Cost: 14.46s
Train Epoch: 598 [61440/90000 (68%)]	Loss: -4.2419	Cost: 14.41s
Train Epoch: 598 [81920/90000 (91%)]	Loss: -4.5031	Cost: 14.76s
Train Epoch: 598 	Average Loss: -4.0609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8542

Saving model as e598_model.pt & e598_waveforms_supplementary.hdf5
Learning rate: 0.00019998235346896327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: -1.2130	Cost: 28.55s
Train Epoch: 599 [20480/90000 (23%)]	Loss: -4.5436	Cost: 10.07s
Train Epoch: 599 [40960/90000 (45%)]	Loss: -3.7483	Cost: 14.88s
Train Epoch: 599 [61440/90000 (68%)]	Loss: -4.1772	Cost: 13.89s
Train Epoch: 599 [81920/90000 (91%)]	Loss: -4.4050	Cost: 11.67s
Train Epoch: 599 	Average Loss: -4.0583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9374

Saving model as e599_model.pt & e599_waveforms_supplementary.hdf5
Learning rate: 0.0001999822944028614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: -0.3601	Cost: 31.03s
Train Epoch: 600 [20480/90000 (23%)]	Loss: -4.8525	Cost: 11.90s
Train Epoch: 600 [40960/90000 (45%)]	Loss: -4.2496	Cost: 15.70s
Train Epoch: 600 [61440/90000 (68%)]	Loss: -4.3227	Cost: 14.31s
Train Epoch: 600 [81920/90000 (91%)]	Loss: -4.5155	Cost: 13.34s
Train Epoch: 600 	Average Loss: -4.2641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7479

Learning rate: 0.0001999822352380809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: -0.9034	Cost: 30.97s
Train Epoch: 601 [20480/90000 (23%)]	Loss: -4.7196	Cost: 11.24s
Train Epoch: 601 [40960/90000 (45%)]	Loss: -4.1353	Cost: 14.32s
Train Epoch: 601 [61440/90000 (68%)]	Loss: -4.3870	Cost: 13.33s
Train Epoch: 601 [81920/90000 (91%)]	Loss: -4.5822	Cost: 12.28s
Train Epoch: 601 	Average Loss: -4.1594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8454

Learning rate: 0.00019998217597462192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: -0.7505	Cost: 31.15s
Train Epoch: 602 [20480/90000 (23%)]	Loss: -4.9154	Cost: 12.71s
Train Epoch: 602 [40960/90000 (45%)]	Loss: -4.3043	Cost: 11.93s
Train Epoch: 602 [61440/90000 (68%)]	Loss: -4.6285	Cost: 11.72s
Train Epoch: 602 [81920/90000 (91%)]	Loss: -4.6256	Cost: 14.04s
Train Epoch: 602 	Average Loss: -4.3538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9682

Saving model as e602_model.pt & e602_waveforms_supplementary.hdf5
Learning rate: 0.00019998211661248448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: -0.7428	Cost: 26.88s
Train Epoch: 603 [20480/90000 (23%)]	Loss: -4.8483	Cost: 11.98s
Train Epoch: 603 [40960/90000 (45%)]	Loss: -4.3593	Cost: 14.72s
Train Epoch: 603 [61440/90000 (68%)]	Loss: -4.6039	Cost: 13.58s
Train Epoch: 603 [81920/90000 (91%)]	Loss: -3.3639	Cost: 13.67s
Train Epoch: 603 	Average Loss: -4.2478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1240

Learning rate: 0.00019998205715166862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: 0.3486	Cost: 27.86s
Train Epoch: 604 [20480/90000 (23%)]	Loss: -3.8328	Cost: 12.36s
Train Epoch: 604 [40960/90000 (45%)]	Loss: -3.5904	Cost: 14.57s
Train Epoch: 604 [61440/90000 (68%)]	Loss: -4.0191	Cost: 13.32s
Train Epoch: 604 [81920/90000 (91%)]	Loss: -3.9501	Cost: 19.49s
Train Epoch: 604 	Average Loss: -3.4956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4496

Learning rate: 0.00019998199759217446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: -0.6838	Cost: 28.27s
Train Epoch: 605 [20480/90000 (23%)]	Loss: -4.5772	Cost: 13.08s
Train Epoch: 605 [40960/90000 (45%)]	Loss: -4.1051	Cost: 14.29s
Train Epoch: 605 [61440/90000 (68%)]	Loss: -4.4184	Cost: 14.00s
Train Epoch: 605 [81920/90000 (91%)]	Loss: -4.3797	Cost: 14.99s
Train Epoch: 605 	Average Loss: -4.1123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7842

Learning rate: 0.000199981937934002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: -0.8227	Cost: 28.53s
Train Epoch: 606 [20480/90000 (23%)]	Loss: -4.4819	Cost: 12.94s
Train Epoch: 606 [40960/90000 (45%)]	Loss: -3.9630	Cost: 22.79s
Train Epoch: 606 [61440/90000 (68%)]	Loss: -4.5212	Cost: 14.06s
Train Epoch: 606 [81920/90000 (91%)]	Loss: -4.6794	Cost: 18.10s
Train Epoch: 606 	Average Loss: -4.1603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9860

Saving model as e606_model.pt & e606_waveforms_supplementary.hdf5
Learning rate: 0.00019998187817715134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: -1.1080	Cost: 29.33s
Train Epoch: 607 [20480/90000 (23%)]	Loss: -4.6062	Cost: 15.08s
Train Epoch: 607 [40960/90000 (45%)]	Loss: -3.9259	Cost: 17.92s
Train Epoch: 607 [61440/90000 (68%)]	Loss: -4.3629	Cost: 14.39s
Train Epoch: 607 [81920/90000 (91%)]	Loss: -4.5685	Cost: 15.09s
Train Epoch: 607 	Average Loss: -4.1753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8155

Learning rate: 0.00019998181832162252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: -0.8649	Cost: 30.58s
Train Epoch: 608 [20480/90000 (23%)]	Loss: -4.8772	Cost: 15.40s
Train Epoch: 608 [40960/90000 (45%)]	Loss: -4.1217	Cost: 18.01s
Train Epoch: 608 [61440/90000 (68%)]	Loss: -4.2009	Cost: 14.34s
Train Epoch: 608 [81920/90000 (91%)]	Loss: -4.2463	Cost: 16.35s
Train Epoch: 608 	Average Loss: -4.1087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7172

Learning rate: 0.0001999817583674156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: -0.4387	Cost: 36.80s
Train Epoch: 609 [20480/90000 (23%)]	Loss: -4.6060	Cost: 14.51s
Train Epoch: 609 [40960/90000 (45%)]	Loss: -4.2384	Cost: 14.90s
Train Epoch: 609 [61440/90000 (68%)]	Loss: -4.6244	Cost: 14.91s
Train Epoch: 609 [81920/90000 (91%)]	Loss: -4.7716	Cost: 16.82s
Train Epoch: 609 	Average Loss: -4.3029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1100

Saving model as e609_model.pt & e609_waveforms_supplementary.hdf5
Learning rate: 0.00019998169831453064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: -1.3214	Cost: 33.66s
Train Epoch: 610 [20480/90000 (23%)]	Loss: -4.7901	Cost: 15.41s
Train Epoch: 610 [40960/90000 (45%)]	Loss: -4.2391	Cost: 15.96s
Train Epoch: 610 [61440/90000 (68%)]	Loss: -4.6599	Cost: 15.37s
Train Epoch: 610 [81920/90000 (91%)]	Loss: -4.7737	Cost: 13.77s
Train Epoch: 610 	Average Loss: -4.4553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2044

Saving model as e610_model.pt & e610_waveforms_supplementary.hdf5
Learning rate: 0.0001999816381629677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: -1.0899	Cost: 29.26s
Train Epoch: 611 [20480/90000 (23%)]	Loss: -5.0308	Cost: 15.90s
Train Epoch: 611 [40960/90000 (45%)]	Loss: -4.2759	Cost: 15.35s
Train Epoch: 611 [61440/90000 (68%)]	Loss: -4.6272	Cost: 15.38s
Train Epoch: 611 [81920/90000 (91%)]	Loss: -4.7388	Cost: 17.76s
Train Epoch: 611 	Average Loss: -4.5012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0561

Learning rate: 0.00019998157791272685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: -1.1090	Cost: 28.18s
Train Epoch: 612 [20480/90000 (23%)]	Loss: -5.0376	Cost: 13.01s
Train Epoch: 612 [40960/90000 (45%)]	Loss: -4.5863	Cost: 21.24s
Train Epoch: 612 [61440/90000 (68%)]	Loss: -4.8448	Cost: 14.22s
Train Epoch: 612 [81920/90000 (91%)]	Loss: -4.6676	Cost: 15.95s
Train Epoch: 612 	Average Loss: -4.4997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0759

Learning rate: 0.00019998151756380812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: -1.1274	Cost: 30.10s
Train Epoch: 613 [20480/90000 (23%)]	Loss: -4.9167	Cost: 9.42s
Train Epoch: 613 [40960/90000 (45%)]	Loss: -4.1184	Cost: 17.67s
Train Epoch: 613 [61440/90000 (68%)]	Loss: -4.2448	Cost: 13.51s
Train Epoch: 613 [81920/90000 (91%)]	Loss: -4.6020	Cost: 18.15s
Train Epoch: 613 	Average Loss: -4.2784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9323

Learning rate: 0.0001999814571162116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: -1.0527	Cost: 35.95s
Train Epoch: 614 [20480/90000 (23%)]	Loss: -4.0631	Cost: 15.36s
Train Epoch: 614 [40960/90000 (45%)]	Loss: -3.2673	Cost: 18.07s
Train Epoch: 614 [61440/90000 (68%)]	Loss: -3.8284	Cost: 15.25s
Train Epoch: 614 [81920/90000 (91%)]	Loss: -4.2724	Cost: 18.16s
Train Epoch: 614 	Average Loss: -3.7109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7513

Learning rate: 0.00019998139656993732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: -0.7816	Cost: 29.95s
Train Epoch: 615 [20480/90000 (23%)]	Loss: -4.8014	Cost: 14.69s
Train Epoch: 615 [40960/90000 (45%)]	Loss: -4.4918	Cost: 14.98s
Train Epoch: 615 [61440/90000 (68%)]	Loss: -4.6099	Cost: 14.03s
Train Epoch: 615 [81920/90000 (91%)]	Loss: -4.6693	Cost: 16.94s
Train Epoch: 615 	Average Loss: -4.3144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0666

Learning rate: 0.00019998133592498537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: -1.0119	Cost: 29.38s
Train Epoch: 616 [20480/90000 (23%)]	Loss: -4.8717	Cost: 13.16s
Train Epoch: 616 [40960/90000 (45%)]	Loss: -4.2942	Cost: 15.12s
Train Epoch: 616 [61440/90000 (68%)]	Loss: -4.5889	Cost: 15.91s
Train Epoch: 616 [81920/90000 (91%)]	Loss: -4.5618	Cost: 14.72s
Train Epoch: 616 	Average Loss: -4.3960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9859

Learning rate: 0.00019998127518135577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: -0.9587	Cost: 30.07s
Train Epoch: 617 [20480/90000 (23%)]	Loss: -5.0861	Cost: 12.74s
Train Epoch: 617 [40960/90000 (45%)]	Loss: -4.6298	Cost: 14.95s
Train Epoch: 617 [61440/90000 (68%)]	Loss: -4.7798	Cost: 13.67s
Train Epoch: 617 [81920/90000 (91%)]	Loss: -4.9450	Cost: 12.08s
Train Epoch: 617 	Average Loss: -4.5389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1983

Learning rate: 0.0001999812143390486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: -1.4520	Cost: 27.10s
Train Epoch: 618 [20480/90000 (23%)]	Loss: -5.1946	Cost: 11.63s
Train Epoch: 618 [40960/90000 (45%)]	Loss: -4.7111	Cost: 14.11s
Train Epoch: 618 [61440/90000 (68%)]	Loss: -4.8114	Cost: 13.47s
Train Epoch: 618 [81920/90000 (91%)]	Loss: -5.0825	Cost: 14.67s
Train Epoch: 618 	Average Loss: -4.6777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1928

Learning rate: 0.00019998115339806398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: -1.1016	Cost: 27.42s
Train Epoch: 619 [20480/90000 (23%)]	Loss: -5.0115	Cost: 10.45s
Train Epoch: 619 [40960/90000 (45%)]	Loss: -4.7334	Cost: 16.94s
Train Epoch: 619 [61440/90000 (68%)]	Loss: -4.9848	Cost: 14.75s
Train Epoch: 619 [81920/90000 (91%)]	Loss: -5.0310	Cost: 14.89s
Train Epoch: 619 	Average Loss: -4.7199
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2055

Saving model as e619_model.pt & e619_waveforms_supplementary.hdf5
Learning rate: 0.00019998109235840191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: -1.3451	Cost: 42.97s
Train Epoch: 620 [20480/90000 (23%)]	Loss: -5.0880	Cost: 13.61s
Train Epoch: 620 [40960/90000 (45%)]	Loss: -4.5638	Cost: 16.07s
Train Epoch: 620 [61440/90000 (68%)]	Loss: -5.0418	Cost: 15.15s
Train Epoch: 620 [81920/90000 (91%)]	Loss: -5.1171	Cost: 10.76s
Train Epoch: 620 	Average Loss: -4.7189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3245

Saving model as e620_model.pt & e620_waveforms_supplementary.hdf5
Learning rate: 0.00019998103122006243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: -1.4129	Cost: 34.29s
Train Epoch: 621 [20480/90000 (23%)]	Loss: -4.9789	Cost: 12.98s
Train Epoch: 621 [40960/90000 (45%)]	Loss: -4.4494	Cost: 14.71s
Train Epoch: 621 [61440/90000 (68%)]	Loss: -4.9275	Cost: 15.89s
Train Epoch: 621 [81920/90000 (91%)]	Loss: -4.8253	Cost: 12.27s
Train Epoch: 621 	Average Loss: -4.6258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0323

Learning rate: 0.00019998096998304565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: -0.7495	Cost: 30.01s
Train Epoch: 622 [20480/90000 (23%)]	Loss: -4.9294	Cost: 14.73s
Train Epoch: 622 [40960/90000 (45%)]	Loss: -4.6052	Cost: 16.04s
Train Epoch: 622 [61440/90000 (68%)]	Loss: -5.1799	Cost: 15.33s
Train Epoch: 622 [81920/90000 (91%)]	Loss: -5.1654	Cost: 14.99s
Train Epoch: 622 	Average Loss: -4.6609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3785

Saving model as e622_model.pt & e622_waveforms_supplementary.hdf5
Learning rate: 0.0001999809086473516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: -1.4046	Cost: 30.91s
Train Epoch: 623 [20480/90000 (23%)]	Loss: -5.3209	Cost: 13.67s
Train Epoch: 623 [40960/90000 (45%)]	Loss: -4.7286	Cost: 14.33s
Train Epoch: 623 [61440/90000 (68%)]	Loss: -4.9373	Cost: 14.45s
Train Epoch: 623 [81920/90000 (91%)]	Loss: -5.0858	Cost: 13.91s
Train Epoch: 623 	Average Loss: -4.8367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2850

Learning rate: 0.00019998084721298032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: -1.6013	Cost: 42.45s
Train Epoch: 624 [20480/90000 (23%)]	Loss: -5.2717	Cost: 14.23s
Train Epoch: 624 [40960/90000 (45%)]	Loss: -4.5409	Cost: 15.28s
Train Epoch: 624 [61440/90000 (68%)]	Loss: -5.0452	Cost: 14.68s
Train Epoch: 624 [81920/90000 (91%)]	Loss: -5.0625	Cost: 9.78s
Train Epoch: 624 	Average Loss: -4.7981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3686

Learning rate: 0.00019998078567993191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: -1.0385	Cost: 32.04s
Train Epoch: 625 [20480/90000 (23%)]	Loss: -5.2598	Cost: 14.10s
Train Epoch: 625 [40960/90000 (45%)]	Loss: -4.8330	Cost: 15.49s
Train Epoch: 625 [61440/90000 (68%)]	Loss: -5.1145	Cost: 14.98s
Train Epoch: 625 [81920/90000 (91%)]	Loss: -5.0624	Cost: 14.01s
Train Epoch: 625 	Average Loss: -4.8130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3276

Learning rate: 0.00019998072404820645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: -1.6017	Cost: 30.33s
Train Epoch: 626 [20480/90000 (23%)]	Loss: -5.5140	Cost: 13.85s
Train Epoch: 626 [40960/90000 (45%)]	Loss: -4.8917	Cost: 16.81s
Train Epoch: 626 [61440/90000 (68%)]	Loss: -5.2265	Cost: 15.29s
Train Epoch: 626 [81920/90000 (91%)]	Loss: -5.3133	Cost: 20.54s
Train Epoch: 626 	Average Loss: -4.9311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4019

Saving model as e626_model.pt & e626_waveforms_supplementary.hdf5
Learning rate: 0.00019998066231780395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: -1.4920	Cost: 31.24s
Train Epoch: 627 [20480/90000 (23%)]	Loss: -5.3033	Cost: 14.00s
Train Epoch: 627 [40960/90000 (45%)]	Loss: -4.8465	Cost: 15.64s
Train Epoch: 627 [61440/90000 (68%)]	Loss: -5.0232	Cost: 13.46s
Train Epoch: 627 [81920/90000 (91%)]	Loss: -4.8663	Cost: 19.73s
Train Epoch: 627 	Average Loss: -4.7595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2696

Learning rate: 0.0001999806004887245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: -1.0871	Cost: 30.72s
Train Epoch: 628 [20480/90000 (23%)]	Loss: -5.0604	Cost: 14.33s
Train Epoch: 628 [40960/90000 (45%)]	Loss: -4.5350	Cost: 14.00s
Train Epoch: 628 [61440/90000 (68%)]	Loss: -5.0469	Cost: 14.58s
Train Epoch: 628 [81920/90000 (91%)]	Loss: -4.9119	Cost: 13.42s
Train Epoch: 628 	Average Loss: -4.6708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3205

Learning rate: 0.00019998053856096817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: -1.4618	Cost: 34.42s
Train Epoch: 629 [20480/90000 (23%)]	Loss: -5.4574	Cost: 12.15s
Train Epoch: 629 [40960/90000 (45%)]	Loss: -4.8671	Cost: 15.76s
Train Epoch: 629 [61440/90000 (68%)]	Loss: -5.3470	Cost: 14.64s
Train Epoch: 629 [81920/90000 (91%)]	Loss: -5.4753	Cost: 14.28s
Train Epoch: 629 	Average Loss: -5.0480
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6765

Saving model as e629_model.pt & e629_waveforms_supplementary.hdf5
Learning rate: 0.00019998047653453497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: -1.5780	Cost: 31.77s
Train Epoch: 630 [20480/90000 (23%)]	Loss: -5.6210	Cost: 11.72s
Train Epoch: 630 [40960/90000 (45%)]	Loss: -4.7736	Cost: 19.68s
Train Epoch: 630 [61440/90000 (68%)]	Loss: -5.1494	Cost: 14.63s
Train Epoch: 630 [81920/90000 (91%)]	Loss: -5.3233	Cost: 16.84s
Train Epoch: 630 	Average Loss: -4.9858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5715

Learning rate: 0.000199980414409425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: -1.4224	Cost: 30.20s
Train Epoch: 631 [20480/90000 (23%)]	Loss: -5.3632	Cost: 13.77s
Train Epoch: 631 [40960/90000 (45%)]	Loss: -4.9663	Cost: 17.05s
Train Epoch: 631 [61440/90000 (68%)]	Loss: -5.1470	Cost: 14.94s
Train Epoch: 631 [81920/90000 (91%)]	Loss: -5.1347	Cost: 19.39s
Train Epoch: 631 	Average Loss: -4.9233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5809

Learning rate: 0.0001999803521856383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: -1.8218	Cost: 29.31s
Train Epoch: 632 [20480/90000 (23%)]	Loss: -5.4563	Cost: 12.11s
Train Epoch: 632 [40960/90000 (45%)]	Loss: -4.5294	Cost: 15.39s
Train Epoch: 632 [61440/90000 (68%)]	Loss: -5.0796	Cost: 14.61s
Train Epoch: 632 [81920/90000 (91%)]	Loss: -5.2961	Cost: 15.31s
Train Epoch: 632 	Average Loss: -4.9194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5428

Learning rate: 0.00019998028986317499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: -1.5159	Cost: 28.49s
Train Epoch: 633 [20480/90000 (23%)]	Loss: -5.4666	Cost: 10.60s
Train Epoch: 633 [40960/90000 (45%)]	Loss: -5.0461	Cost: 19.07s
Train Epoch: 633 [61440/90000 (68%)]	Loss: -5.4295	Cost: 13.48s
Train Epoch: 633 [81920/90000 (91%)]	Loss: -5.2042	Cost: 14.94s
Train Epoch: 633 	Average Loss: -5.0847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5401

Learning rate: 0.00019998022744203506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: -2.0179	Cost: 28.30s
Train Epoch: 634 [20480/90000 (23%)]	Loss: -5.4698	Cost: 13.62s
Train Epoch: 634 [40960/90000 (45%)]	Loss: -4.9386	Cost: 14.53s
Train Epoch: 634 [61440/90000 (68%)]	Loss: -5.4287	Cost: 14.72s
Train Epoch: 634 [81920/90000 (91%)]	Loss: -5.3471	Cost: 25.08s
Train Epoch: 634 	Average Loss: -5.1172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4188

Learning rate: 0.0001999801649222186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: -1.5032	Cost: 27.41s
Train Epoch: 635 [20480/90000 (23%)]	Loss: -4.4145	Cost: 12.51s
Train Epoch: 635 [40960/90000 (45%)]	Loss: -4.3513	Cost: 17.59s
Train Epoch: 635 [61440/90000 (68%)]	Loss: -4.8761	Cost: 14.85s
Train Epoch: 635 [81920/90000 (91%)]	Loss: -4.5931	Cost: 14.11s
Train Epoch: 635 	Average Loss: -4.4007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9998

Learning rate: 0.00019998010230372565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: -1.0501	Cost: 30.43s
Train Epoch: 636 [20480/90000 (23%)]	Loss: -4.9387	Cost: 11.75s
Train Epoch: 636 [40960/90000 (45%)]	Loss: -4.4475	Cost: 23.34s
Train Epoch: 636 [61440/90000 (68%)]	Loss: -5.1883	Cost: 15.62s
Train Epoch: 636 [81920/90000 (91%)]	Loss: -5.0312	Cost: 17.30s
Train Epoch: 636 	Average Loss: -4.6332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2633

Learning rate: 0.00019998003958655633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: -1.4916	Cost: 29.92s
Train Epoch: 637 [20480/90000 (23%)]	Loss: -5.3374	Cost: 15.36s
Train Epoch: 637 [40960/90000 (45%)]	Loss: -4.9298	Cost: 15.46s
Train Epoch: 637 [61440/90000 (68%)]	Loss: -5.3326	Cost: 15.38s
Train Epoch: 637 [81920/90000 (91%)]	Loss: -5.4518	Cost: 17.22s
Train Epoch: 637 	Average Loss: -5.0266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6365

Learning rate: 0.00019997997677071068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: -1.6382	Cost: 29.72s
Train Epoch: 638 [20480/90000 (23%)]	Loss: -5.5000	Cost: 14.83s
Train Epoch: 638 [40960/90000 (45%)]	Loss: -4.9649	Cost: 18.04s
Train Epoch: 638 [61440/90000 (68%)]	Loss: -5.3067	Cost: 14.81s
Train Epoch: 638 [81920/90000 (91%)]	Loss: -5.2458	Cost: 14.33s
Train Epoch: 638 	Average Loss: -5.0657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5921

Learning rate: 0.00019997991385618872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: -1.7721	Cost: 29.86s
Train Epoch: 639 [20480/90000 (23%)]	Loss: -5.5271	Cost: 11.47s
Train Epoch: 639 [40960/90000 (45%)]	Loss: -5.1464	Cost: 16.03s
Train Epoch: 639 [61440/90000 (68%)]	Loss: -5.3362	Cost: 14.55s
Train Epoch: 639 [81920/90000 (91%)]	Loss: -5.5641	Cost: 17.85s
Train Epoch: 639 	Average Loss: -5.1389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7571

Saving model as e639_model.pt & e639_waveforms_supplementary.hdf5
Learning rate: 0.00019997985084299058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: -1.8552	Cost: 31.98s
Train Epoch: 640 [20480/90000 (23%)]	Loss: -5.9124	Cost: 15.24s
Train Epoch: 640 [40960/90000 (45%)]	Loss: -5.2223	Cost: 14.55s
Train Epoch: 640 [61440/90000 (68%)]	Loss: -5.4535	Cost: 15.68s
Train Epoch: 640 [81920/90000 (91%)]	Loss: -5.5542	Cost: 19.58s
Train Epoch: 640 	Average Loss: -5.2923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4659

Learning rate: 0.00019997978773111623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: -1.5270	Cost: 29.03s
Train Epoch: 641 [20480/90000 (23%)]	Loss: -5.1924	Cost: 11.78s
Train Epoch: 641 [40960/90000 (45%)]	Loss: -4.4702	Cost: 17.19s
Train Epoch: 641 [61440/90000 (68%)]	Loss: -4.8456	Cost: 12.82s
Train Epoch: 641 [81920/90000 (91%)]	Loss: -5.1675	Cost: 14.59s
Train Epoch: 641 	Average Loss: -4.7101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3344

Learning rate: 0.00019997972452056583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: -1.3411	Cost: 29.09s
Train Epoch: 642 [20480/90000 (23%)]	Loss: -5.6041	Cost: 6.81s
Train Epoch: 642 [40960/90000 (45%)]	Loss: -5.1342	Cost: 16.21s
Train Epoch: 642 [61440/90000 (68%)]	Loss: -5.3612	Cost: 13.19s
Train Epoch: 642 [81920/90000 (91%)]	Loss: -5.4852	Cost: 16.19s
Train Epoch: 642 	Average Loss: -5.1212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4782

Learning rate: 0.00019997966121133937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: -1.2467	Cost: 28.41s
Train Epoch: 643 [20480/90000 (23%)]	Loss: -5.5392	Cost: 6.77s
Train Epoch: 643 [40960/90000 (45%)]	Loss: -4.9545	Cost: 14.22s
Train Epoch: 643 [61440/90000 (68%)]	Loss: -5.4065	Cost: 14.36s
Train Epoch: 643 [81920/90000 (91%)]	Loss: -5.3045	Cost: 14.07s
Train Epoch: 643 	Average Loss: -5.0898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5917

Learning rate: 0.00019997959780343694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: -1.5816	Cost: 26.48s
Train Epoch: 644 [20480/90000 (23%)]	Loss: -5.7888	Cost: 9.54s
Train Epoch: 644 [40960/90000 (45%)]	Loss: -5.2193	Cost: 14.67s
Train Epoch: 644 [61440/90000 (68%)]	Loss: -5.6274	Cost: 14.67s
Train Epoch: 644 [81920/90000 (91%)]	Loss: -5.5814	Cost: 12.55s
Train Epoch: 644 	Average Loss: -5.2697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8470

Saving model as e644_model.pt & e644_waveforms_supplementary.hdf5
Learning rate: 0.0001999795342968586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: -1.4807	Cost: 29.84s
Train Epoch: 645 [20480/90000 (23%)]	Loss: -5.8179	Cost: 14.42s
Train Epoch: 645 [40960/90000 (45%)]	Loss: -5.2263	Cost: 15.09s
Train Epoch: 645 [61440/90000 (68%)]	Loss: -5.5114	Cost: 14.86s
Train Epoch: 645 [81920/90000 (91%)]	Loss: -5.8882	Cost: 13.71s
Train Epoch: 645 	Average Loss: -5.4133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9298

Saving model as e645_model.pt & e645_waveforms_supplementary.hdf5
Learning rate: 0.00019997947069160443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: -1.3949	Cost: 27.95s
Train Epoch: 646 [20480/90000 (23%)]	Loss: -6.0508	Cost: 13.14s
Train Epoch: 646 [40960/90000 (45%)]	Loss: -5.4191	Cost: 16.42s
Train Epoch: 646 [61440/90000 (68%)]	Loss: -5.5306	Cost: 13.75s
Train Epoch: 646 [81920/90000 (91%)]	Loss: -5.5298	Cost: 22.30s
Train Epoch: 646 	Average Loss: -5.3810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7349

Learning rate: 0.00019997940698767447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: -1.6014	Cost: 28.51s
Train Epoch: 647 [20480/90000 (23%)]	Loss: -5.8782	Cost: 10.92s
Train Epoch: 647 [40960/90000 (45%)]	Loss: -5.1882	Cost: 14.53s
Train Epoch: 647 [61440/90000 (68%)]	Loss: -5.6519	Cost: 14.45s
Train Epoch: 647 [81920/90000 (91%)]	Loss: -5.8739	Cost: 14.25s
Train Epoch: 647 	Average Loss: -5.3781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8691

Learning rate: 0.0001999793431850688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: -1.0918	Cost: 33.92s
Train Epoch: 648 [20480/90000 (23%)]	Loss: -5.2646	Cost: 14.81s
Train Epoch: 648 [40960/90000 (45%)]	Loss: -4.8700	Cost: 13.86s
Train Epoch: 648 [61440/90000 (68%)]	Loss: -5.0816	Cost: 15.14s
Train Epoch: 648 [81920/90000 (91%)]	Loss: -5.3185	Cost: 12.57s
Train Epoch: 648 	Average Loss: -4.9278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5390

Learning rate: 0.00019997927928378745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: -1.9649	Cost: 32.54s
Train Epoch: 649 [20480/90000 (23%)]	Loss: -5.5439	Cost: 14.74s
Train Epoch: 649 [40960/90000 (45%)]	Loss: -5.1253	Cost: 18.42s
Train Epoch: 649 [61440/90000 (68%)]	Loss: -5.4371	Cost: 13.72s
Train Epoch: 649 [81920/90000 (91%)]	Loss: -5.5736	Cost: 12.51s
Train Epoch: 649 	Average Loss: -5.1754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7210

Learning rate: 0.0001999792152838305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: -1.7536	Cost: 36.94s
Train Epoch: 650 [20480/90000 (23%)]	Loss: -5.8635	Cost: 14.23s
Train Epoch: 650 [40960/90000 (45%)]	Loss: -5.4317	Cost: 20.96s
Train Epoch: 650 [61440/90000 (68%)]	Loss: -5.4224	Cost: 12.69s
Train Epoch: 650 [81920/90000 (91%)]	Loss: -5.3734	Cost: 10.09s
Train Epoch: 650 	Average Loss: -5.2562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6010

Learning rate: 0.00019997915118519805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: -1.6555	Cost: 32.51s
Train Epoch: 651 [20480/90000 (23%)]	Loss: -5.5776	Cost: 14.15s
Train Epoch: 651 [40960/90000 (45%)]	Loss: -5.1601	Cost: 15.75s
Train Epoch: 651 [61440/90000 (68%)]	Loss: -5.4857	Cost: 14.77s
Train Epoch: 651 [81920/90000 (91%)]	Loss: -5.8955	Cost: 12.68s
Train Epoch: 651 	Average Loss: -5.3362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0434

Saving model as e651_model.pt & e651_waveforms_supplementary.hdf5
Learning rate: 0.0001999790869878901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: -1.8606	Cost: 34.68s
Train Epoch: 652 [20480/90000 (23%)]	Loss: -6.0765	Cost: 13.34s
Train Epoch: 652 [40960/90000 (45%)]	Loss: -5.6412	Cost: 19.42s
Train Epoch: 652 [61440/90000 (68%)]	Loss: -5.8538	Cost: 13.59s
Train Epoch: 652 [81920/90000 (91%)]	Loss: -5.8902	Cost: 12.91s
Train Epoch: 652 	Average Loss: -5.5848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9540

Learning rate: 0.00019997902269190676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: -2.5005	Cost: 36.77s
Train Epoch: 653 [20480/90000 (23%)]	Loss: -6.0849	Cost: 15.43s
Train Epoch: 653 [40960/90000 (45%)]	Loss: -5.3690	Cost: 16.45s
Train Epoch: 653 [61440/90000 (68%)]	Loss: -5.6162	Cost: 15.54s
Train Epoch: 653 [81920/90000 (91%)]	Loss: -5.7031	Cost: 13.45s
Train Epoch: 653 	Average Loss: -5.5642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8836

Learning rate: 0.0001999789582972481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: -2.1445	Cost: 44.51s
Train Epoch: 654 [20480/90000 (23%)]	Loss: -5.8218	Cost: 12.78s
Train Epoch: 654 [40960/90000 (45%)]	Loss: -5.3562	Cost: 14.08s
Train Epoch: 654 [61440/90000 (68%)]	Loss: -4.6078	Cost: 13.95s
Train Epoch: 654 [81920/90000 (91%)]	Loss: -5.3724	Cost: 6.89s
Train Epoch: 654 	Average Loss: -5.1772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4981

Learning rate: 0.00019997889380391414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: -1.4935	Cost: 31.23s
Train Epoch: 655 [20480/90000 (23%)]	Loss: -5.7054	Cost: 15.29s
Train Epoch: 655 [40960/90000 (45%)]	Loss: -5.1688	Cost: 15.48s
Train Epoch: 655 [61440/90000 (68%)]	Loss: -5.6781	Cost: 15.51s
Train Epoch: 655 [81920/90000 (91%)]	Loss: -5.3667	Cost: 10.64s
Train Epoch: 655 	Average Loss: -5.1812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4001

Learning rate: 0.00019997882921190502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: -1.1271	Cost: 29.08s
Train Epoch: 656 [20480/90000 (23%)]	Loss: -5.6178	Cost: 14.37s
Train Epoch: 656 [40960/90000 (45%)]	Loss: -5.3103	Cost: 14.95s
Train Epoch: 656 [61440/90000 (68%)]	Loss: -5.7392	Cost: 14.06s
Train Epoch: 656 [81920/90000 (91%)]	Loss: -5.8341	Cost: 20.16s
Train Epoch: 656 	Average Loss: -5.3670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9449

Learning rate: 0.00019997876452122068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: -2.1841	Cost: 36.92s
Train Epoch: 657 [20480/90000 (23%)]	Loss: -6.1402	Cost: 14.78s
Train Epoch: 657 [40960/90000 (45%)]	Loss: -5.3927	Cost: 16.06s
Train Epoch: 657 [61440/90000 (68%)]	Loss: -5.7565	Cost: 14.96s
Train Epoch: 657 [81920/90000 (91%)]	Loss: -6.0052	Cost: 12.20s
Train Epoch: 657 	Average Loss: -5.5926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9409

Learning rate: 0.00019997869973186128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: -2.2365	Cost: 33.67s
Train Epoch: 658 [20480/90000 (23%)]	Loss: -6.1786	Cost: 14.69s
Train Epoch: 658 [40960/90000 (45%)]	Loss: -5.6462	Cost: 14.34s
Train Epoch: 658 [61440/90000 (68%)]	Loss: -5.8067	Cost: 15.34s
Train Epoch: 658 [81920/90000 (91%)]	Loss: -5.8242	Cost: 14.25s
Train Epoch: 658 	Average Loss: -5.6440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9405

Learning rate: 0.00019997863484382683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: -1.7524	Cost: 34.49s
Train Epoch: 659 [20480/90000 (23%)]	Loss: -5.9556	Cost: 14.20s
Train Epoch: 659 [40960/90000 (45%)]	Loss: -5.5024	Cost: 14.63s
Train Epoch: 659 [61440/90000 (68%)]	Loss: -6.0015	Cost: 15.51s
Train Epoch: 659 [81920/90000 (91%)]	Loss: -6.0781	Cost: 15.85s
Train Epoch: 659 	Average Loss: -5.5859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9826

Learning rate: 0.00019997856985711746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: -1.9234	Cost: 37.15s
Train Epoch: 660 [20480/90000 (23%)]	Loss: -6.2445	Cost: 14.54s
Train Epoch: 660 [40960/90000 (45%)]	Loss: -5.6469	Cost: 13.16s
Train Epoch: 660 [61440/90000 (68%)]	Loss: -5.7641	Cost: 15.25s
Train Epoch: 660 [81920/90000 (91%)]	Loss: -5.7366	Cost: 14.87s
Train Epoch: 660 	Average Loss: -5.5915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0193

Learning rate: 0.0001999785047717332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: -2.2181	Cost: 35.43s
Train Epoch: 661 [20480/90000 (23%)]	Loss: -6.1740	Cost: 14.04s
Train Epoch: 661 [40960/90000 (45%)]	Loss: -5.7091	Cost: 15.03s
Train Epoch: 661 [61440/90000 (68%)]	Loss: -6.1675	Cost: 14.64s
Train Epoch: 661 [81920/90000 (91%)]	Loss: -5.9175	Cost: 17.28s
Train Epoch: 661 	Average Loss: -5.6754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9730

Learning rate: 0.0001999784395876741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: -1.8967	Cost: 31.36s
Train Epoch: 662 [20480/90000 (23%)]	Loss: -6.0400	Cost: 14.77s
Train Epoch: 662 [40960/90000 (45%)]	Loss: -5.6769	Cost: 20.55s
Train Epoch: 662 [61440/90000 (68%)]	Loss: -6.1196	Cost: 15.64s
Train Epoch: 662 [81920/90000 (91%)]	Loss: -6.1160	Cost: 19.16s
Train Epoch: 662 	Average Loss: -5.6999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1550

Saving model as e662_model.pt & e662_waveforms_supplementary.hdf5
Learning rate: 0.00019997837430494025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: -2.3149	Cost: 26.88s
Train Epoch: 663 [20480/90000 (23%)]	Loss: -6.2816	Cost: 9.50s
Train Epoch: 663 [40960/90000 (45%)]	Loss: -5.6633	Cost: 16.32s
Train Epoch: 663 [61440/90000 (68%)]	Loss: -5.9702	Cost: 13.09s
Train Epoch: 663 [81920/90000 (91%)]	Loss: -5.9910	Cost: 20.40s
Train Epoch: 663 	Average Loss: -5.7584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7801

Learning rate: 0.00019997830892353166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: -1.3537	Cost: 28.54s
Train Epoch: 664 [20480/90000 (23%)]	Loss: -5.9421	Cost: 6.37s
Train Epoch: 664 [40960/90000 (45%)]	Loss: -5.3281	Cost: 18.98s
Train Epoch: 664 [61440/90000 (68%)]	Loss: -6.0302	Cost: 14.30s
Train Epoch: 664 [81920/90000 (91%)]	Loss: -5.9390	Cost: 14.92s
Train Epoch: 664 	Average Loss: -5.5867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1064

Learning rate: 0.0001999782434434485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: -1.9665	Cost: 27.33s
Train Epoch: 665 [20480/90000 (23%)]	Loss: -6.2878	Cost: 6.90s
Train Epoch: 665 [40960/90000 (45%)]	Loss: -5.6996	Cost: 14.12s
Train Epoch: 665 [61440/90000 (68%)]	Loss: -6.0556	Cost: 14.49s
Train Epoch: 665 [81920/90000 (91%)]	Loss: -6.0854	Cost: 18.32s
Train Epoch: 665 	Average Loss: -5.7982
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1665

Saving model as e665_model.pt & e665_waveforms_supplementary.hdf5
Learning rate: 0.0001999781778646907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: -1.9795	Cost: 36.15s
Train Epoch: 666 [20480/90000 (23%)]	Loss: -6.4423	Cost: 14.17s
Train Epoch: 666 [40960/90000 (45%)]	Loss: -5.8836	Cost: 14.77s
Train Epoch: 666 [61440/90000 (68%)]	Loss: -6.0856	Cost: 15.27s
Train Epoch: 666 [81920/90000 (91%)]	Loss: -6.2739	Cost: 14.26s
Train Epoch: 666 	Average Loss: -5.8270
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3465

Saving model as e666_model.pt & e666_waveforms_supplementary.hdf5
Learning rate: 0.00019997811218725844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: -1.7055	Cost: 30.04s
Train Epoch: 667 [20480/90000 (23%)]	Loss: -6.2024	Cost: 15.18s
Train Epoch: 667 [40960/90000 (45%)]	Loss: -5.5577	Cost: 13.81s
Train Epoch: 667 [61440/90000 (68%)]	Loss: -5.8848	Cost: 14.49s
Train Epoch: 667 [81920/90000 (91%)]	Loss: -5.6996	Cost: 21.57s
Train Epoch: 667 	Average Loss: -5.5745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8134

Learning rate: 0.0001999780464111517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: -2.0415	Cost: 30.06s
Train Epoch: 668 [20480/90000 (23%)]	Loss: -6.0559	Cost: 14.13s
Train Epoch: 668 [40960/90000 (45%)]	Loss: -5.5551	Cost: 14.26s
Train Epoch: 668 [61440/90000 (68%)]	Loss: -6.0769	Cost: 15.55s
Train Epoch: 668 [81920/90000 (91%)]	Loss: -6.1661	Cost: 11.77s
Train Epoch: 668 	Average Loss: -5.6504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1664

Learning rate: 0.00019997798053637063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: -1.7194	Cost: 29.12s
Train Epoch: 669 [20480/90000 (23%)]	Loss: -6.3621	Cost: 10.67s
Train Epoch: 669 [40960/90000 (45%)]	Loss: -5.8178	Cost: 17.07s
Train Epoch: 669 [61440/90000 (68%)]	Loss: -6.0748	Cost: 13.26s
Train Epoch: 669 [81920/90000 (91%)]	Loss: -6.2017	Cost: 16.49s
Train Epoch: 669 	Average Loss: -5.8298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1735

Learning rate: 0.00019997791456291523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: -2.0334	Cost: 28.33s
Train Epoch: 670 [20480/90000 (23%)]	Loss: -6.4323	Cost: 7.42s
Train Epoch: 670 [40960/90000 (45%)]	Loss: -5.5591	Cost: 22.81s
Train Epoch: 670 [61440/90000 (68%)]	Loss: -5.8724	Cost: 12.07s
Train Epoch: 670 [81920/90000 (91%)]	Loss: -6.1167	Cost: 12.98s
Train Epoch: 670 	Average Loss: -5.7639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1149

Learning rate: 0.00019997784849078558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: -1.8783	Cost: 26.37s
Train Epoch: 671 [20480/90000 (23%)]	Loss: -6.2839	Cost: 7.45s
Train Epoch: 671 [40960/90000 (45%)]	Loss: -5.6710	Cost: 17.55s
Train Epoch: 671 [61440/90000 (68%)]	Loss: -6.2455	Cost: 12.95s
Train Epoch: 671 [81920/90000 (91%)]	Loss: -6.1961	Cost: 13.90s
Train Epoch: 671 	Average Loss: -5.7890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2347

Learning rate: 0.00019997778231998174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: -1.5928	Cost: 27.55s
Train Epoch: 672 [20480/90000 (23%)]	Loss: -6.4227	Cost: 8.15s
Train Epoch: 672 [40960/90000 (45%)]	Loss: -5.8859	Cost: 14.83s
Train Epoch: 672 [61440/90000 (68%)]	Loss: -5.9201	Cost: 15.35s
Train Epoch: 672 [81920/90000 (91%)]	Loss: -5.9408	Cost: 14.69s
Train Epoch: 672 	Average Loss: -5.7992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9605

Learning rate: 0.0001999777160505038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: -1.5769	Cost: 31.39s
Train Epoch: 673 [20480/90000 (23%)]	Loss: -6.1922	Cost: 6.38s
Train Epoch: 673 [40960/90000 (45%)]	Loss: -5.6393	Cost: 12.34s
Train Epoch: 673 [61440/90000 (68%)]	Loss: -6.0175	Cost: 12.71s
Train Epoch: 673 [81920/90000 (91%)]	Loss: -6.0281	Cost: 13.91s
Train Epoch: 673 	Average Loss: -5.6833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0144

Learning rate: 0.0001999776496823518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: -1.9514	Cost: 32.14s
Train Epoch: 674 [20480/90000 (23%)]	Loss: -6.2190	Cost: 10.39s
Train Epoch: 674 [40960/90000 (45%)]	Loss: -5.7578	Cost: 14.74s
Train Epoch: 674 [61440/90000 (68%)]	Loss: -6.3460	Cost: 13.60s
Train Epoch: 674 [81920/90000 (91%)]	Loss: -6.3800	Cost: 9.20s
Train Epoch: 674 	Average Loss: -5.7991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2176

Learning rate: 0.00019997758321552579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: -2.0398	Cost: 27.95s
Train Epoch: 675 [20480/90000 (23%)]	Loss: -6.4220	Cost: 12.47s
Train Epoch: 675 [40960/90000 (45%)]	Loss: -6.0040	Cost: 14.90s
Train Epoch: 675 [61440/90000 (68%)]	Loss: -6.3584	Cost: 13.30s
Train Epoch: 675 [81920/90000 (91%)]	Loss: -6.4916	Cost: 12.07s
Train Epoch: 675 	Average Loss: -6.0347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3572

Saving model as e675_model.pt & e675_waveforms_supplementary.hdf5
Learning rate: 0.00019997751665002588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: -2.4834	Cost: 30.37s
Train Epoch: 676 [20480/90000 (23%)]	Loss: -6.4093	Cost: 14.30s
Train Epoch: 676 [40960/90000 (45%)]	Loss: -5.9029	Cost: 14.16s
Train Epoch: 676 [61440/90000 (68%)]	Loss: -6.3290	Cost: 14.75s
Train Epoch: 676 [81920/90000 (91%)]	Loss: -6.4077	Cost: 13.19s
Train Epoch: 676 	Average Loss: -6.0158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2936

Learning rate: 0.00019997744998585216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: -2.1009	Cost: 30.23s
Train Epoch: 677 [20480/90000 (23%)]	Loss: -6.3151	Cost: 11.75s
Train Epoch: 677 [40960/90000 (45%)]	Loss: -5.9169	Cost: 14.22s
Train Epoch: 677 [61440/90000 (68%)]	Loss: -6.0755	Cost: 14.56s
Train Epoch: 677 [81920/90000 (91%)]	Loss: -6.2689	Cost: 14.49s
Train Epoch: 677 	Average Loss: -5.9468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3870

Saving model as e677_model.pt & e677_waveforms_supplementary.hdf5
Learning rate: 0.0001999773832230046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: -2.4020	Cost: 31.49s
Train Epoch: 678 [20480/90000 (23%)]	Loss: -6.5975	Cost: 13.57s
Train Epoch: 678 [40960/90000 (45%)]	Loss: -6.1151	Cost: 15.24s
Train Epoch: 678 [61440/90000 (68%)]	Loss: -6.0982	Cost: 14.58s
Train Epoch: 678 [81920/90000 (91%)]	Loss: -6.3817	Cost: 11.65s
Train Epoch: 678 	Average Loss: -6.1234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3162

Learning rate: 0.00019997731636148334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: -2.1925	Cost: 29.22s
Train Epoch: 679 [20480/90000 (23%)]	Loss: -6.2984	Cost: 13.67s
Train Epoch: 679 [40960/90000 (45%)]	Loss: -5.6473	Cost: 14.93s
Train Epoch: 679 [61440/90000 (68%)]	Loss: -6.1473	Cost: 12.89s
Train Epoch: 679 [81920/90000 (91%)]	Loss: -6.2698	Cost: 12.52s
Train Epoch: 679 	Average Loss: -5.8958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3694

Learning rate: 0.00019997724940128839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: -1.7701	Cost: 37.26s
Train Epoch: 680 [20480/90000 (23%)]	Loss: -6.6776	Cost: 13.60s
Train Epoch: 680 [40960/90000 (45%)]	Loss: -5.9895	Cost: 15.60s
Train Epoch: 680 [61440/90000 (68%)]	Loss: -6.4252	Cost: 16.26s
Train Epoch: 680 [81920/90000 (91%)]	Loss: -6.5346	Cost: 12.77s
Train Epoch: 680 	Average Loss: -6.0989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3152

Learning rate: 0.0001999771823424199
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: -2.2359	Cost: 39.95s
Train Epoch: 681 [20480/90000 (23%)]	Loss: -6.6649	Cost: 13.09s
Train Epoch: 681 [40960/90000 (45%)]	Loss: -6.1703	Cost: 22.56s
Train Epoch: 681 [61440/90000 (68%)]	Loss: -6.3034	Cost: 14.44s
Train Epoch: 681 [81920/90000 (91%)]	Loss: -6.4927	Cost: 10.54s
Train Epoch: 681 	Average Loss: -6.0866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5108

Saving model as e681_model.pt & e681_waveforms_supplementary.hdf5
Learning rate: 0.00019997711518487783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: -2.0043	Cost: 32.64s
Train Epoch: 682 [20480/90000 (23%)]	Loss: -6.7989	Cost: 13.67s
Train Epoch: 682 [40960/90000 (45%)]	Loss: -6.0541	Cost: 15.28s
Train Epoch: 682 [61440/90000 (68%)]	Loss: -6.2488	Cost: 14.91s
Train Epoch: 682 [81920/90000 (91%)]	Loss: -6.3694	Cost: 15.15s
Train Epoch: 682 	Average Loss: -6.0266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2488

Learning rate: 0.00019997704792866234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: -2.1070	Cost: 29.03s
Train Epoch: 683 [20480/90000 (23%)]	Loss: -6.4587	Cost: 13.03s
Train Epoch: 683 [40960/90000 (45%)]	Loss: -6.0199	Cost: 14.24s
Train Epoch: 683 [61440/90000 (68%)]	Loss: -6.3094	Cost: 14.94s
Train Epoch: 683 [81920/90000 (91%)]	Loss: -6.6508	Cost: 13.89s
Train Epoch: 683 	Average Loss: -6.0642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5357

Saving model as e683_model.pt & e683_waveforms_supplementary.hdf5
Learning rate: 0.00019997698057377345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: -2.6192	Cost: 31.80s
Train Epoch: 684 [20480/90000 (23%)]	Loss: -6.7086	Cost: 12.22s
Train Epoch: 684 [40960/90000 (45%)]	Loss: -6.2130	Cost: 14.20s
Train Epoch: 684 [61440/90000 (68%)]	Loss: -6.5483	Cost: 15.00s
Train Epoch: 684 [81920/90000 (91%)]	Loss: -6.6986	Cost: 13.19s
Train Epoch: 684 	Average Loss: -6.2774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5197

Learning rate: 0.0001999769131202112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: -1.8261	Cost: 30.60s
Train Epoch: 685 [20480/90000 (23%)]	Loss: -6.2158	Cost: 13.23s
Train Epoch: 685 [40960/90000 (45%)]	Loss: -5.8611	Cost: 13.90s
Train Epoch: 685 [61440/90000 (68%)]	Loss: -6.2369	Cost: 13.56s
Train Epoch: 685 [81920/90000 (91%)]	Loss: -6.2768	Cost: 13.66s
Train Epoch: 685 	Average Loss: -5.8564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3479

Learning rate: 0.00019997684556797576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: -1.9998	Cost: 28.18s
Train Epoch: 686 [20480/90000 (23%)]	Loss: -6.6296	Cost: 11.02s
Train Epoch: 686 [40960/90000 (45%)]	Loss: -5.9196	Cost: 16.86s
Train Epoch: 686 [61440/90000 (68%)]	Loss: -6.3674	Cost: 13.85s
Train Epoch: 686 [81920/90000 (91%)]	Loss: -6.6131	Cost: 13.94s
Train Epoch: 686 	Average Loss: -6.0744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5784

Saving model as e686_model.pt & e686_waveforms_supplementary.hdf5
Learning rate: 0.0001999767779170671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: -2.2616	Cost: 28.65s
Train Epoch: 687 [20480/90000 (23%)]	Loss: -6.9423	Cost: 14.18s
Train Epoch: 687 [40960/90000 (45%)]	Loss: -6.2668	Cost: 14.65s
Train Epoch: 687 [61440/90000 (68%)]	Loss: -6.7219	Cost: 13.50s
Train Epoch: 687 [81920/90000 (91%)]	Loss: -6.4713	Cost: 14.76s
Train Epoch: 687 	Average Loss: -6.2835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4688

Learning rate: 0.00019997671016748527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: -2.5830	Cost: 34.56s
Train Epoch: 688 [20480/90000 (23%)]	Loss: -6.9254	Cost: 15.47s
Train Epoch: 688 [40960/90000 (45%)]	Loss: -6.1030	Cost: 15.25s
Train Epoch: 688 [61440/90000 (68%)]	Loss: -6.5254	Cost: 14.24s
Train Epoch: 688 [81920/90000 (91%)]	Loss: -6.7182	Cost: 13.30s
Train Epoch: 688 	Average Loss: -6.2903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5426

Learning rate: 0.00019997664231923042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: -2.3054	Cost: 30.79s
Train Epoch: 689 [20480/90000 (23%)]	Loss: -6.7248	Cost: 10.78s
Train Epoch: 689 [40960/90000 (45%)]	Loss: -6.1766	Cost: 19.46s
Train Epoch: 689 [61440/90000 (68%)]	Loss: -6.5678	Cost: 14.64s
Train Epoch: 689 [81920/90000 (91%)]	Loss: -6.6651	Cost: 15.80s
Train Epoch: 689 	Average Loss: -6.2473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6388

Saving model as e689_model.pt & e689_waveforms_supplementary.hdf5
Learning rate: 0.00019997657437230258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: -2.6842	Cost: 32.28s
Train Epoch: 690 [20480/90000 (23%)]	Loss: -6.9392	Cost: 14.58s
Train Epoch: 690 [40960/90000 (45%)]	Loss: -6.3042	Cost: 15.29s
Train Epoch: 690 [61440/90000 (68%)]	Loss: -6.4484	Cost: 15.16s
Train Epoch: 690 [81920/90000 (91%)]	Loss: -6.6288	Cost: 13.30s
Train Epoch: 690 	Average Loss: -6.2475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4938

Learning rate: 0.00019997650632670182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: -2.8320	Cost: 31.14s
Train Epoch: 691 [20480/90000 (23%)]	Loss: -6.7139	Cost: 13.36s
Train Epoch: 691 [40960/90000 (45%)]	Loss: -6.0846	Cost: 14.53s
Train Epoch: 691 [61440/90000 (68%)]	Loss: -6.5840	Cost: 14.61s
Train Epoch: 691 [81920/90000 (91%)]	Loss: -6.7674	Cost: 17.35s
Train Epoch: 691 	Average Loss: -6.2886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6624

Saving model as e691_model.pt & e691_waveforms_supplementary.hdf5
Learning rate: 0.0001999764381824282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: -2.4071	Cost: 35.17s
Train Epoch: 692 [20480/90000 (23%)]	Loss: -6.7548	Cost: 14.28s
Train Epoch: 692 [40960/90000 (45%)]	Loss: -6.1479	Cost: 14.45s
Train Epoch: 692 [61440/90000 (68%)]	Loss: -6.5034	Cost: 15.00s
Train Epoch: 692 [81920/90000 (91%)]	Loss: -6.6069	Cost: 13.96s
Train Epoch: 692 	Average Loss: -6.2313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3376

Learning rate: 0.0001999763699394818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: -2.3480	Cost: 35.33s
Train Epoch: 693 [20480/90000 (23%)]	Loss: -6.6876	Cost: 13.73s
Train Epoch: 693 [40960/90000 (45%)]	Loss: -5.9886	Cost: 16.61s
Train Epoch: 693 [61440/90000 (68%)]	Loss: -6.5784	Cost: 14.39s
Train Epoch: 693 [81920/90000 (91%)]	Loss: -6.5786	Cost: 12.30s
Train Epoch: 693 	Average Loss: -6.1761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5715

Learning rate: 0.0001999763015978627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: -2.5128	Cost: 28.01s
Train Epoch: 694 [20480/90000 (23%)]	Loss: -6.9815	Cost: 6.52s
Train Epoch: 694 [40960/90000 (45%)]	Loss: -6.3633	Cost: 15.90s
Train Epoch: 694 [61440/90000 (68%)]	Loss: -6.5173	Cost: 15.11s
Train Epoch: 694 [81920/90000 (91%)]	Loss: -6.6540	Cost: 14.64s
Train Epoch: 694 	Average Loss: -6.3525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5700

Learning rate: 0.0001999762331575709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: -2.5365	Cost: 27.44s
Train Epoch: 695 [20480/90000 (23%)]	Loss: -7.0389	Cost: 6.92s
Train Epoch: 695 [40960/90000 (45%)]	Loss: -6.0484	Cost: 17.95s
Train Epoch: 695 [61440/90000 (68%)]	Loss: -6.5517	Cost: 12.17s
Train Epoch: 695 [81920/90000 (91%)]	Loss: -6.8071	Cost: 12.35s
Train Epoch: 695 	Average Loss: -6.2753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6197

Learning rate: 0.00019997616461860652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: -2.7496	Cost: 28.94s
Train Epoch: 696 [20480/90000 (23%)]	Loss: -6.3152	Cost: 8.18s
Train Epoch: 696 [40960/90000 (45%)]	Loss: -5.5710	Cost: 16.00s
Train Epoch: 696 [61440/90000 (68%)]	Loss: -6.1242	Cost: 13.56s
Train Epoch: 696 [81920/90000 (91%)]	Loss: -6.1825	Cost: 13.80s
Train Epoch: 696 	Average Loss: -5.8884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2208

Learning rate: 0.00019997609598096963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: -1.9805	Cost: 33.93s
Train Epoch: 697 [20480/90000 (23%)]	Loss: -6.3755	Cost: 9.47s
Train Epoch: 697 [40960/90000 (45%)]	Loss: -5.6822	Cost: 18.38s
Train Epoch: 697 [61440/90000 (68%)]	Loss: -5.8751	Cost: 13.81s
Train Epoch: 697 [81920/90000 (91%)]	Loss: -6.0352	Cost: 12.39s
Train Epoch: 697 	Average Loss: -5.7821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8624

Learning rate: 0.0001999760272446603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: -1.9370	Cost: 30.45s
Train Epoch: 698 [20480/90000 (23%)]	Loss: -6.0013	Cost: 10.66s
Train Epoch: 698 [40960/90000 (45%)]	Loss: -5.6938	Cost: 26.65s
Train Epoch: 698 [61440/90000 (68%)]	Loss: -5.7675	Cost: 14.08s
Train Epoch: 698 [81920/90000 (91%)]	Loss: -5.7606	Cost: 18.27s
Train Epoch: 698 	Average Loss: -5.5882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0661

Learning rate: 0.00019997595840967857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: -1.9575	Cost: 26.01s
Train Epoch: 699 [20480/90000 (23%)]	Loss: -6.3880	Cost: 6.47s
Train Epoch: 699 [40960/90000 (45%)]	Loss: -6.0953	Cost: 16.53s
Train Epoch: 699 [61440/90000 (68%)]	Loss: -6.5779	Cost: 14.19s
Train Epoch: 699 [81920/90000 (91%)]	Loss: -6.8386	Cost: 20.62s
Train Epoch: 699 	Average Loss: -6.1498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6836

Saving model as e699_model.pt & e699_waveforms_supplementary.hdf5
Learning rate: 0.00019997588947602451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: -2.4060	Cost: 37.13s
Train Epoch: 700 [20480/90000 (23%)]	Loss: -6.8104	Cost: 11.88s
Train Epoch: 700 [40960/90000 (45%)]	Loss: -6.1838	Cost: 13.91s
Train Epoch: 700 [61440/90000 (68%)]	Loss: -6.5825	Cost: 14.62s
Train Epoch: 700 [81920/90000 (91%)]	Loss: -6.7139	Cost: 13.45s
Train Epoch: 700 	Average Loss: -6.2968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5771

Learning rate: 0.00019997582044369825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: -3.1452	Cost: 34.17s
Train Epoch: 701 [20480/90000 (23%)]	Loss: -6.8329	Cost: 12.28s
Train Epoch: 701 [40960/90000 (45%)]	Loss: -6.2992	Cost: 13.79s
Train Epoch: 701 [61440/90000 (68%)]	Loss: -6.4756	Cost: 12.78s
Train Epoch: 701 [81920/90000 (91%)]	Loss: -5.4933	Cost: 10.81s
Train Epoch: 701 	Average Loss: -6.2114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2094

Learning rate: 0.00019997575131269977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: -0.8759	Cost: 40.04s
Train Epoch: 702 [20480/90000 (23%)]	Loss: -5.5809	Cost: 11.76s
Train Epoch: 702 [40960/90000 (45%)]	Loss: -5.6121	Cost: 17.14s
Train Epoch: 702 [61440/90000 (68%)]	Loss: -5.8922	Cost: 12.03s
Train Epoch: 702 [81920/90000 (91%)]	Loss: -6.3556	Cost: 10.30s
Train Epoch: 702 	Average Loss: -5.4265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4778

Learning rate: 0.00019997568208302919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: -2.0693	Cost: 43.16s
Train Epoch: 703 [20480/90000 (23%)]	Loss: -6.4459	Cost: 13.73s
Train Epoch: 703 [40960/90000 (45%)]	Loss: -6.2518	Cost: 17.44s
Train Epoch: 703 [61440/90000 (68%)]	Loss: -6.8062	Cost: 12.12s
Train Epoch: 703 [81920/90000 (91%)]	Loss: -6.9336	Cost: 6.10s
Train Epoch: 703 	Average Loss: -6.3355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8695

Saving model as e703_model.pt & e703_waveforms_supplementary.hdf5
Learning rate: 0.00019997561275468656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: -2.9580	Cost: 58.94s
Train Epoch: 704 [20480/90000 (23%)]	Loss: -7.0789	Cost: 12.92s
Train Epoch: 704 [40960/90000 (45%)]	Loss: -6.6241	Cost: 12.22s
Train Epoch: 704 [61440/90000 (68%)]	Loss: -6.9211	Cost: 11.81s
Train Epoch: 704 [81920/90000 (91%)]	Loss: -7.0023	Cost: 7.53s
Train Epoch: 704 	Average Loss: -6.6754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9219

Saving model as e704_model.pt & e704_waveforms_supplementary.hdf5
Learning rate: 0.00019997554332767197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: -2.6579	Cost: 53.95s
Train Epoch: 705 [20480/90000 (23%)]	Loss: -7.2762	Cost: 7.47s
Train Epoch: 705 [40960/90000 (45%)]	Loss: -6.7092	Cost: 12.18s
Train Epoch: 705 [61440/90000 (68%)]	Loss: -6.8774	Cost: 11.89s
Train Epoch: 705 [81920/90000 (91%)]	Loss: -6.8669	Cost: 10.32s
Train Epoch: 705 	Average Loss: -6.6815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9708

Saving model as e705_model.pt & e705_waveforms_supplementary.hdf5
Learning rate: 0.0001999754738019855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: -2.8024	Cost: 45.29s
Train Epoch: 706 [20480/90000 (23%)]	Loss: -7.2436	Cost: 11.89s
Train Epoch: 706 [40960/90000 (45%)]	Loss: -6.6417	Cost: 12.28s
Train Epoch: 706 [61440/90000 (68%)]	Loss: -7.0387	Cost: 11.96s
Train Epoch: 706 [81920/90000 (91%)]	Loss: -6.9782	Cost: 11.28s
Train Epoch: 706 	Average Loss: -6.7134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7300

Learning rate: 0.00019997540417762715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: -3.0574	Cost: 29.67s
Train Epoch: 707 [20480/90000 (23%)]	Loss: -7.1494	Cost: 12.08s
Train Epoch: 707 [40960/90000 (45%)]	Loss: -6.4800	Cost: 12.18s
Train Epoch: 707 [61440/90000 (68%)]	Loss: -7.1134	Cost: 12.10s
Train Epoch: 707 [81920/90000 (91%)]	Loss: -7.0378	Cost: 12.44s
Train Epoch: 707 	Average Loss: -6.6760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0315

Saving model as e707_model.pt & e707_waveforms_supplementary.hdf5
Learning rate: 0.00019997533445459704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: -2.7739	Cost: 27.02s
Train Epoch: 708 [20480/90000 (23%)]	Loss: -7.1940	Cost: 12.38s
Train Epoch: 708 [40960/90000 (45%)]	Loss: -6.4540	Cost: 14.17s
Train Epoch: 708 [61440/90000 (68%)]	Loss: -7.0111	Cost: 12.29s
Train Epoch: 708 [81920/90000 (91%)]	Loss: -6.9953	Cost: 12.30s
Train Epoch: 708 	Average Loss: -6.6606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5765

Learning rate: 0.00019997526463289524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: -3.1502	Cost: 28.50s
Train Epoch: 709 [20480/90000 (23%)]	Loss: -7.2078	Cost: 9.55s
Train Epoch: 709 [40960/90000 (45%)]	Loss: -6.5695	Cost: 13.75s
Train Epoch: 709 [61440/90000 (68%)]	Loss: -6.4894	Cost: 13.12s
Train Epoch: 709 [81920/90000 (91%)]	Loss: -6.8309	Cost: 13.22s
Train Epoch: 709 	Average Loss: -6.5083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7846

Learning rate: 0.0001999751947125218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: -2.6341	Cost: 30.11s
Train Epoch: 710 [20480/90000 (23%)]	Loss: -6.9431	Cost: 13.31s
Train Epoch: 710 [40960/90000 (45%)]	Loss: -6.0900	Cost: 15.80s
Train Epoch: 710 [61440/90000 (68%)]	Loss: -6.7285	Cost: 12.99s
Train Epoch: 710 [81920/90000 (91%)]	Loss: -6.8194	Cost: 13.09s
Train Epoch: 710 	Average Loss: -6.4319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8135

Learning rate: 0.00019997512469347679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: -2.5997	Cost: 36.98s
Train Epoch: 711 [20480/90000 (23%)]	Loss: -7.2312	Cost: 13.43s
Train Epoch: 711 [40960/90000 (45%)]	Loss: -6.6168	Cost: 12.36s
Train Epoch: 711 [61440/90000 (68%)]	Loss: -6.8689	Cost: 12.94s
Train Epoch: 711 [81920/90000 (91%)]	Loss: -7.0777	Cost: 12.04s
Train Epoch: 711 	Average Loss: -6.6920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9185

Learning rate: 0.00019997505457576027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: -2.7515	Cost: 30.28s
Train Epoch: 712 [20480/90000 (23%)]	Loss: -7.0952	Cost: 13.86s
Train Epoch: 712 [40960/90000 (45%)]	Loss: -6.6821	Cost: 14.87s
Train Epoch: 712 [61440/90000 (68%)]	Loss: -6.9554	Cost: 13.61s
Train Epoch: 712 [81920/90000 (91%)]	Loss: -7.0649	Cost: 12.18s
Train Epoch: 712 	Average Loss: -6.7080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9451

Learning rate: 0.00019997498435937237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: -2.5668	Cost: 33.35s
Train Epoch: 713 [20480/90000 (23%)]	Loss: -7.1951	Cost: 9.10s
Train Epoch: 713 [40960/90000 (45%)]	Loss: -6.6215	Cost: 13.73s
Train Epoch: 713 [61440/90000 (68%)]	Loss: -6.9997	Cost: 13.88s
Train Epoch: 713 [81920/90000 (91%)]	Loss: -7.0041	Cost: 12.53s
Train Epoch: 713 	Average Loss: -6.6682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7258

Learning rate: 0.00019997491404431306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: -2.8603	Cost: 43.33s
Train Epoch: 714 [20480/90000 (23%)]	Loss: -7.2025	Cost: 10.59s
Train Epoch: 714 [40960/90000 (45%)]	Loss: -6.8240	Cost: 13.37s
Train Epoch: 714 [61440/90000 (68%)]	Loss: -7.0365	Cost: 12.39s
Train Epoch: 714 [81920/90000 (91%)]	Loss: -7.2499	Cost: 12.42s
Train Epoch: 714 	Average Loss: -6.7939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0422

Saving model as e714_model.pt & e714_waveforms_supplementary.hdf5
Learning rate: 0.00019997484363058253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: -3.1261	Cost: 38.36s
Train Epoch: 715 [20480/90000 (23%)]	Loss: -7.4344	Cost: 14.52s
Train Epoch: 715 [40960/90000 (45%)]	Loss: -7.0787	Cost: 15.47s
Train Epoch: 715 [61440/90000 (68%)]	Loss: -7.3058	Cost: 15.13s
Train Epoch: 715 [81920/90000 (91%)]	Loss: -6.7714	Cost: 11.44s
Train Epoch: 715 	Average Loss: -6.8580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7004

Learning rate: 0.00019997477311818073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: -3.0975	Cost: 29.13s
Train Epoch: 716 [20480/90000 (23%)]	Loss: -6.9753	Cost: 12.15s
Train Epoch: 716 [40960/90000 (45%)]	Loss: -6.2279	Cost: 20.14s
Train Epoch: 716 [61440/90000 (68%)]	Loss: -5.6222	Cost: 15.81s
Train Epoch: 716 [81920/90000 (91%)]	Loss: -6.1471	Cost: 16.24s
Train Epoch: 716 	Average Loss: -6.0378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3771

Learning rate: 0.0001999747025071078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: -2.3379	Cost: 29.32s
Train Epoch: 717 [20480/90000 (23%)]	Loss: -6.6874	Cost: 8.73s
Train Epoch: 717 [40960/90000 (45%)]	Loss: -6.3704	Cost: 14.25s
Train Epoch: 717 [61440/90000 (68%)]	Loss: -6.7483	Cost: 13.48s
Train Epoch: 717 [81920/90000 (91%)]	Loss: -6.9522	Cost: 13.11s
Train Epoch: 717 	Average Loss: -6.4088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7551

Learning rate: 0.0001999746317973638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: -2.9769	Cost: 26.72s
Train Epoch: 718 [20480/90000 (23%)]	Loss: -7.1943	Cost: 9.39s
Train Epoch: 718 [40960/90000 (45%)]	Loss: -6.8202	Cost: 14.07s
Train Epoch: 718 [61440/90000 (68%)]	Loss: -7.1051	Cost: 14.01s
Train Epoch: 718 [81920/90000 (91%)]	Loss: -7.3264	Cost: 12.43s
Train Epoch: 718 	Average Loss: -6.8458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1151

Saving model as e718_model.pt & e718_waveforms_supplementary.hdf5
Learning rate: 0.00019997456098894882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: -3.0511	Cost: 27.24s
Train Epoch: 719 [20480/90000 (23%)]	Loss: -7.3862	Cost: 8.88s
Train Epoch: 719 [40960/90000 (45%)]	Loss: -6.8426	Cost: 15.31s
Train Epoch: 719 [61440/90000 (68%)]	Loss: -7.1824	Cost: 13.09s
Train Epoch: 719 [81920/90000 (91%)]	Loss: -7.2961	Cost: 12.44s
Train Epoch: 719 	Average Loss: -6.9589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0115

Learning rate: 0.00019997449008186285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: -2.7876	Cost: 35.53s
Train Epoch: 720 [20480/90000 (23%)]	Loss: -7.6402	Cost: 6.23s
Train Epoch: 720 [40960/90000 (45%)]	Loss: -7.0096	Cost: 12.25s
Train Epoch: 720 [61440/90000 (68%)]	Loss: -7.4315	Cost: 12.35s
Train Epoch: 720 [81920/90000 (91%)]	Loss: -7.4960	Cost: 13.12s
Train Epoch: 720 	Average Loss: -7.0418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2320

Saving model as e720_model.pt & e720_waveforms_supplementary.hdf5
Learning rate: 0.00019997441907610605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: -3.0827	Cost: 49.49s
Train Epoch: 721 [20480/90000 (23%)]	Loss: -7.7444	Cost: 7.41s
Train Epoch: 721 [40960/90000 (45%)]	Loss: -6.9239	Cost: 12.11s
Train Epoch: 721 [61440/90000 (68%)]	Loss: -7.2955	Cost: 12.13s
Train Epoch: 721 [81920/90000 (91%)]	Loss: -7.2884	Cost: 13.04s
Train Epoch: 721 	Average Loss: -7.0698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1119

Learning rate: 0.00019997434797167847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: -2.5618	Cost: 34.82s
Train Epoch: 722 [20480/90000 (23%)]	Loss: -7.5194	Cost: 8.86s
Train Epoch: 722 [40960/90000 (45%)]	Loss: -6.7838	Cost: 8.23s
Train Epoch: 722 [61440/90000 (68%)]	Loss: -6.9752	Cost: 11.75s
Train Epoch: 722 [81920/90000 (91%)]	Loss: -6.9281	Cost: 12.18s
Train Epoch: 722 	Average Loss: -6.8419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7165

Learning rate: 0.00019997427676858012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: -2.7634	Cost: 27.66s
Train Epoch: 723 [20480/90000 (23%)]	Loss: -7.4452	Cost: 9.13s
Train Epoch: 723 [40960/90000 (45%)]	Loss: -6.8901	Cost: 18.83s
Train Epoch: 723 [61440/90000 (68%)]	Loss: -7.0592	Cost: 11.96s
Train Epoch: 723 [81920/90000 (91%)]	Loss: -7.5097	Cost: 12.06s
Train Epoch: 723 	Average Loss: -6.8676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1165

Learning rate: 0.00019997420546681116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: -2.9539	Cost: 35.88s
Train Epoch: 724 [20480/90000 (23%)]	Loss: -7.5886	Cost: 8.64s
Train Epoch: 724 [40960/90000 (45%)]	Loss: -6.9138	Cost: 10.50s
Train Epoch: 724 [61440/90000 (68%)]	Loss: -7.3328	Cost: 10.90s
Train Epoch: 724 [81920/90000 (91%)]	Loss: -7.2390	Cost: 15.52s
Train Epoch: 724 	Average Loss: -7.0610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3273

Saving model as e724_model.pt & e724_waveforms_supplementary.hdf5
Learning rate: 0.0001999741340663716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: -3.2463	Cost: 59.02s
Train Epoch: 725 [20480/90000 (23%)]	Loss: -7.6174	Cost: 7.37s
Train Epoch: 725 [40960/90000 (45%)]	Loss: -7.1943	Cost: 13.30s
Train Epoch: 725 [61440/90000 (68%)]	Loss: -7.2250	Cost: 12.36s
Train Epoch: 725 [81920/90000 (91%)]	Loss: -7.5034	Cost: 11.80s
Train Epoch: 725 	Average Loss: -7.0631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1864

Learning rate: 0.0001999740625672615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: -2.6635	Cost: 34.28s
Train Epoch: 726 [20480/90000 (23%)]	Loss: -7.4635	Cost: 8.36s
Train Epoch: 726 [40960/90000 (45%)]	Loss: -7.0033	Cost: 11.48s
Train Epoch: 726 [61440/90000 (68%)]	Loss: -7.3672	Cost: 12.24s
Train Epoch: 726 [81920/90000 (91%)]	Loss: -7.4621	Cost: 12.14s
Train Epoch: 726 	Average Loss: -7.1171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1898

Learning rate: 0.00019997399096948094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: -3.2478	Cost: 43.51s
Train Epoch: 727 [20480/90000 (23%)]	Loss: -7.5294	Cost: 8.63s
Train Epoch: 727 [40960/90000 (45%)]	Loss: -7.0402	Cost: 10.21s
Train Epoch: 727 [61440/90000 (68%)]	Loss: -7.3294	Cost: 6.20s
Train Epoch: 727 [81920/90000 (91%)]	Loss: -7.3715	Cost: 15.45s
Train Epoch: 727 	Average Loss: -7.0469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0388

Learning rate: 0.00019997391927303003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: -3.0617	Cost: 62.63s
Train Epoch: 728 [20480/90000 (23%)]	Loss: -6.6373	Cost: 6.45s
Train Epoch: 728 [40960/90000 (45%)]	Loss: -6.2840	Cost: 10.41s
Train Epoch: 728 [61440/90000 (68%)]	Loss: -7.1196	Cost: 11.96s
Train Epoch: 728 [81920/90000 (91%)]	Loss: -7.2151	Cost: 12.00s
Train Epoch: 728 	Average Loss: -6.5022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9615

Learning rate: 0.00019997384747790883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: -2.8805	Cost: 41.86s
Train Epoch: 729 [20480/90000 (23%)]	Loss: -7.4903	Cost: 6.33s
Train Epoch: 729 [40960/90000 (45%)]	Loss: -6.9606	Cost: 12.54s
Train Epoch: 729 [61440/90000 (68%)]	Loss: -7.2797	Cost: 12.07s
Train Epoch: 729 [81920/90000 (91%)]	Loss: -7.3096	Cost: 12.18s
Train Epoch: 729 	Average Loss: -7.0144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2584

Learning rate: 0.00019997377558411737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: -3.2211	Cost: 32.19s
Train Epoch: 730 [20480/90000 (23%)]	Loss: -7.6277	Cost: 11.98s
Train Epoch: 730 [40960/90000 (45%)]	Loss: -7.1949	Cost: 13.14s
Train Epoch: 730 [61440/90000 (68%)]	Loss: -7.2031	Cost: 12.73s
Train Epoch: 730 [81920/90000 (91%)]	Loss: -7.0706	Cost: 12.34s
Train Epoch: 730 	Average Loss: -7.0457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9572

Learning rate: 0.00019997370359165574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: -2.6861	Cost: 30.57s
Train Epoch: 731 [20480/90000 (23%)]	Loss: -7.7063	Cost: 13.37s
Train Epoch: 731 [40960/90000 (45%)]	Loss: -7.0492	Cost: 14.66s
Train Epoch: 731 [61440/90000 (68%)]	Loss: -7.1477	Cost: 13.20s
Train Epoch: 731 [81920/90000 (91%)]	Loss: -6.9523	Cost: 12.17s
Train Epoch: 731 	Average Loss: -6.9857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7620

Learning rate: 0.00019997363150052406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: -2.8027	Cost: 27.32s
Train Epoch: 732 [20480/90000 (23%)]	Loss: -7.3031	Cost: 12.12s
Train Epoch: 732 [40960/90000 (45%)]	Loss: -6.9395	Cost: 14.58s
Train Epoch: 732 [61440/90000 (68%)]	Loss: -7.4355	Cost: 13.89s
Train Epoch: 732 [81920/90000 (91%)]	Loss: -7.5739	Cost: 12.26s
Train Epoch: 732 	Average Loss: -6.9980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2701

Learning rate: 0.00019997355931072235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: -2.8818	Cost: 27.62s
Train Epoch: 733 [20480/90000 (23%)]	Loss: -7.6839	Cost: 9.07s
Train Epoch: 733 [40960/90000 (45%)]	Loss: -7.1699	Cost: 14.18s
Train Epoch: 733 [61440/90000 (68%)]	Loss: -6.7758	Cost: 13.58s
Train Epoch: 733 [81920/90000 (91%)]	Loss: -6.7931	Cost: 12.85s
Train Epoch: 733 	Average Loss: -6.9157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8517

Learning rate: 0.0001999734870222507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: -3.0558	Cost: 28.75s
Train Epoch: 734 [20480/90000 (23%)]	Loss: -7.1473	Cost: 6.65s
Train Epoch: 734 [40960/90000 (45%)]	Loss: -6.9159	Cost: 19.49s
Train Epoch: 734 [61440/90000 (68%)]	Loss: -7.0915	Cost: 13.92s
Train Epoch: 734 [81920/90000 (91%)]	Loss: -7.2085	Cost: 14.10s
Train Epoch: 734 	Average Loss: -6.7556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0882

Learning rate: 0.00019997341463510914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: -3.2258	Cost: 30.07s
Train Epoch: 735 [20480/90000 (23%)]	Loss: -7.6273	Cost: 12.17s
Train Epoch: 735 [40960/90000 (45%)]	Loss: -6.8196	Cost: 14.45s
Train Epoch: 735 [61440/90000 (68%)]	Loss: -7.2522	Cost: 13.21s
Train Epoch: 735 [81920/90000 (91%)]	Loss: -7.4701	Cost: 18.49s
Train Epoch: 735 	Average Loss: -7.0012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3202

Learning rate: 0.00019997334214929782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: -3.1940	Cost: 29.09s
Train Epoch: 736 [20480/90000 (23%)]	Loss: -7.7672	Cost: 13.03s
Train Epoch: 736 [40960/90000 (45%)]	Loss: -7.2397	Cost: 12.76s
Train Epoch: 736 [61440/90000 (68%)]	Loss: -7.5735	Cost: 13.56s
Train Epoch: 736 [81920/90000 (91%)]	Loss: -7.7290	Cost: 15.70s
Train Epoch: 736 	Average Loss: -7.2957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3982

Saving model as e736_model.pt & e736_waveforms_supplementary.hdf5
Learning rate: 0.00019997326956481675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: -3.1302	Cost: 27.66s
Train Epoch: 737 [20480/90000 (23%)]	Loss: -7.8401	Cost: 11.48s
Train Epoch: 737 [40960/90000 (45%)]	Loss: -7.1990	Cost: 18.32s
Train Epoch: 737 [61440/90000 (68%)]	Loss: -7.5976	Cost: 13.14s
Train Epoch: 737 [81920/90000 (91%)]	Loss: -7.6031	Cost: 13.60s
Train Epoch: 737 	Average Loss: -7.3133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4275

Saving model as e737_model.pt & e737_waveforms_supplementary.hdf5
Learning rate: 0.000199973196881666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: -3.7693	Cost: 28.43s
Train Epoch: 738 [20480/90000 (23%)]	Loss: -8.0470	Cost: 12.23s
Train Epoch: 738 [40960/90000 (45%)]	Loss: -7.3047	Cost: 14.07s
Train Epoch: 738 [61440/90000 (68%)]	Loss: -7.6710	Cost: 14.49s
Train Epoch: 738 [81920/90000 (91%)]	Loss: -7.8358	Cost: 15.51s
Train Epoch: 738 	Average Loss: -7.4386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4055

Learning rate: 0.00019997312409984565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: -2.9295	Cost: 29.58s
Train Epoch: 739 [20480/90000 (23%)]	Loss: -8.0261	Cost: 11.52s
Train Epoch: 739 [40960/90000 (45%)]	Loss: -7.4201	Cost: 19.76s
Train Epoch: 739 [61440/90000 (68%)]	Loss: -7.5493	Cost: 14.86s
Train Epoch: 739 [81920/90000 (91%)]	Loss: -7.7220	Cost: 16.82s
Train Epoch: 739 	Average Loss: -7.4031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4616

Saving model as e739_model.pt & e739_waveforms_supplementary.hdf5
Learning rate: 0.00019997305121935581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: -3.0169	Cost: 31.52s
Train Epoch: 740 [20480/90000 (23%)]	Loss: -7.7536	Cost: 14.80s
Train Epoch: 740 [40960/90000 (45%)]	Loss: -7.3218	Cost: 15.48s
Train Epoch: 740 [61440/90000 (68%)]	Loss: -7.7391	Cost: 15.57s
Train Epoch: 740 [81920/90000 (91%)]	Loss: -7.8495	Cost: 16.18s
Train Epoch: 740 	Average Loss: -7.3718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5760

Saving model as e740_model.pt & e740_waveforms_supplementary.hdf5
Learning rate: 0.00019997297824019653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: -3.5196	Cost: 30.12s
Train Epoch: 741 [20480/90000 (23%)]	Loss: -8.0988	Cost: 14.26s
Train Epoch: 741 [40960/90000 (45%)]	Loss: -7.5042	Cost: 17.08s
Train Epoch: 741 [61440/90000 (68%)]	Loss: -7.6790	Cost: 13.95s
Train Epoch: 741 [81920/90000 (91%)]	Loss: -7.8106	Cost: 19.43s
Train Epoch: 741 	Average Loss: -7.4944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3762

Learning rate: 0.00019997290516236789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: -3.0221	Cost: 29.82s
Train Epoch: 742 [20480/90000 (23%)]	Loss: -7.8402	Cost: 14.31s
Train Epoch: 742 [40960/90000 (45%)]	Loss: -7.2773	Cost: 15.44s
Train Epoch: 742 [61440/90000 (68%)]	Loss: -7.7017	Cost: 14.01s
Train Epoch: 742 [81920/90000 (91%)]	Loss: -7.8600	Cost: 14.38s
Train Epoch: 742 	Average Loss: -7.4087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4239

Learning rate: 0.0001999728319858699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: -3.2410	Cost: 42.83s
Train Epoch: 743 [20480/90000 (23%)]	Loss: -7.9382	Cost: 12.89s
Train Epoch: 743 [40960/90000 (45%)]	Loss: -7.1144	Cost: 15.08s
Train Epoch: 743 [61440/90000 (68%)]	Loss: -7.5539	Cost: 12.98s
Train Epoch: 743 [81920/90000 (91%)]	Loss: -7.7419	Cost: 7.30s
Train Epoch: 743 	Average Loss: -7.3236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3985

Learning rate: 0.00019997275871070266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: -3.1656	Cost: 31.42s
Train Epoch: 744 [20480/90000 (23%)]	Loss: -7.9372	Cost: 13.46s
Train Epoch: 744 [40960/90000 (45%)]	Loss: -7.6356	Cost: 15.12s
Train Epoch: 744 [61440/90000 (68%)]	Loss: -7.7743	Cost: 15.92s
Train Epoch: 744 [81920/90000 (91%)]	Loss: -7.8319	Cost: 12.68s
Train Epoch: 744 	Average Loss: -7.4765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5843

Saving model as e744_model.pt & e744_waveforms_supplementary.hdf5
Learning rate: 0.00019997268533686628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: -3.5017	Cost: 27.90s
Train Epoch: 745 [20480/90000 (23%)]	Loss: -8.1063	Cost: 15.21s
Train Epoch: 745 [40960/90000 (45%)]	Loss: -7.6263	Cost: 18.28s
Train Epoch: 745 [61440/90000 (68%)]	Loss: -7.8803	Cost: 13.93s
Train Epoch: 745 [81920/90000 (91%)]	Loss: -7.6097	Cost: 15.96s
Train Epoch: 745 	Average Loss: -7.5239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4118

Learning rate: 0.00019997261186436086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: -2.5413	Cost: 34.24s
Train Epoch: 746 [20480/90000 (23%)]	Loss: -7.8229	Cost: 11.48s
Train Epoch: 746 [40960/90000 (45%)]	Loss: -7.4514	Cost: 13.81s
Train Epoch: 746 [61440/90000 (68%)]	Loss: -7.8530	Cost: 12.61s
Train Epoch: 746 [81920/90000 (91%)]	Loss: -7.8954	Cost: 18.77s
Train Epoch: 746 	Average Loss: -7.4410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5923

Saving model as e746_model.pt & e746_waveforms_supplementary.hdf5
Learning rate: 0.0001999725382931864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: -3.3903	Cost: 32.24s
Train Epoch: 747 [20480/90000 (23%)]	Loss: -8.2780	Cost: 12.99s
Train Epoch: 747 [40960/90000 (45%)]	Loss: -7.6985	Cost: 15.90s
Train Epoch: 747 [61440/90000 (68%)]	Loss: -7.8668	Cost: 15.18s
Train Epoch: 747 [81920/90000 (91%)]	Loss: -8.1120	Cost: 12.92s
Train Epoch: 747 	Average Loss: -7.6668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6809

Saving model as e747_model.pt & e747_waveforms_supplementary.hdf5
Learning rate: 0.000199972464623343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: -3.3738	Cost: 28.94s
Train Epoch: 748 [20480/90000 (23%)]	Loss: -8.2288	Cost: 12.53s
Train Epoch: 748 [40960/90000 (45%)]	Loss: -7.4323	Cost: 18.69s
Train Epoch: 748 [61440/90000 (68%)]	Loss: -7.5730	Cost: 9.61s
Train Epoch: 748 [81920/90000 (91%)]	Loss: -7.8864	Cost: 12.24s
Train Epoch: 748 	Average Loss: -7.4663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4389

Learning rate: 0.00019997239085483074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: -3.4343	Cost: 27.96s
Train Epoch: 749 [20480/90000 (23%)]	Loss: -7.9927	Cost: 10.26s
Train Epoch: 749 [40960/90000 (45%)]	Loss: -7.3654	Cost: 16.93s
Train Epoch: 749 [61440/90000 (68%)]	Loss: -7.3367	Cost: 12.13s
Train Epoch: 749 [81920/90000 (91%)]	Loss: -7.3759	Cost: 14.45s
Train Epoch: 749 	Average Loss: -7.2728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0774

Learning rate: 0.0001999723169876497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: -2.5154	Cost: 28.35s
Train Epoch: 750 [20480/90000 (23%)]	Loss: -7.6417	Cost: 7.78s
Train Epoch: 750 [40960/90000 (45%)]	Loss: -7.1186	Cost: 19.42s
Train Epoch: 750 [61440/90000 (68%)]	Loss: -7.6980	Cost: 14.76s
Train Epoch: 750 [81920/90000 (91%)]	Loss: -7.8015	Cost: 15.59s
Train Epoch: 750 	Average Loss: -7.2445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6660

Learning rate: 0.0001999722430217999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: -3.3953	Cost: 28.10s
Train Epoch: 751 [20480/90000 (23%)]	Loss: -8.1338	Cost: 9.47s
Train Epoch: 751 [40960/90000 (45%)]	Loss: -7.4169	Cost: 16.22s
Train Epoch: 751 [61440/90000 (68%)]	Loss: -7.7740	Cost: 15.49s
Train Epoch: 751 [81920/90000 (91%)]	Loss: -7.8685	Cost: 18.18s
Train Epoch: 751 	Average Loss: -7.5298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4284

Learning rate: 0.00019997216895728146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: -3.4819	Cost: 31.32s
Train Epoch: 752 [20480/90000 (23%)]	Loss: -8.2725	Cost: 12.31s
Train Epoch: 752 [40960/90000 (45%)]	Loss: -7.6509	Cost: 14.53s
Train Epoch: 752 [61440/90000 (68%)]	Loss: -7.7979	Cost: 14.43s
Train Epoch: 752 [81920/90000 (91%)]	Loss: -7.9104	Cost: 15.65s
Train Epoch: 752 	Average Loss: -7.5654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5651

Learning rate: 0.00019997209479409445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: -3.0774	Cost: 35.35s
Train Epoch: 753 [20480/90000 (23%)]	Loss: -8.1552	Cost: 14.15s
Train Epoch: 753 [40960/90000 (45%)]	Loss: -7.6105	Cost: 14.91s
Train Epoch: 753 [61440/90000 (68%)]	Loss: -7.7592	Cost: 15.26s
Train Epoch: 753 [81920/90000 (91%)]	Loss: -7.9062	Cost: 14.44s
Train Epoch: 753 	Average Loss: -7.6124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5643

Learning rate: 0.00019997202053223894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: -3.4700	Cost: 39.94s
Train Epoch: 754 [20480/90000 (23%)]	Loss: -8.0153	Cost: 14.21s
Train Epoch: 754 [40960/90000 (45%)]	Loss: -7.5043	Cost: 14.87s
Train Epoch: 754 [61440/90000 (68%)]	Loss: -7.9823	Cost: 15.50s
Train Epoch: 754 [81920/90000 (91%)]	Loss: -7.9551	Cost: 13.17s
Train Epoch: 754 	Average Loss: -7.6230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5974

Learning rate: 0.00019997194617171497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: -3.9583	Cost: 38.30s
Train Epoch: 755 [20480/90000 (23%)]	Loss: -8.0683	Cost: 13.20s
Train Epoch: 755 [40960/90000 (45%)]	Loss: -7.5117	Cost: 16.92s
Train Epoch: 755 [61440/90000 (68%)]	Loss: -7.9994	Cost: 14.26s
Train Epoch: 755 [81920/90000 (91%)]	Loss: -8.1680	Cost: 12.13s
Train Epoch: 755 	Average Loss: -7.7142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7148

Saving model as e755_model.pt & e755_waveforms_supplementary.hdf5
Learning rate: 0.00019997187171252268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: -3.2950	Cost: 35.50s
Train Epoch: 756 [20480/90000 (23%)]	Loss: -8.2395	Cost: 13.91s
Train Epoch: 756 [40960/90000 (45%)]	Loss: -7.7161	Cost: 27.22s
Train Epoch: 756 [61440/90000 (68%)]	Loss: -7.7935	Cost: 14.33s
Train Epoch: 756 [81920/90000 (91%)]	Loss: -7.6235	Cost: 14.38s
Train Epoch: 756 	Average Loss: -7.5991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4548

Learning rate: 0.0001999717971546621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: -3.4120	Cost: 29.46s
Train Epoch: 757 [20480/90000 (23%)]	Loss: -7.9996	Cost: 14.82s
Train Epoch: 757 [40960/90000 (45%)]	Loss: -7.7631	Cost: 15.54s
Train Epoch: 757 [61440/90000 (68%)]	Loss: -7.8524	Cost: 14.78s
Train Epoch: 757 [81920/90000 (91%)]	Loss: -7.9679	Cost: 16.14s
Train Epoch: 757 	Average Loss: -7.6159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7112

Learning rate: 0.00019997172249813333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: -3.5820	Cost: 29.42s
Train Epoch: 758 [20480/90000 (23%)]	Loss: -8.0346	Cost: 11.99s
Train Epoch: 758 [40960/90000 (45%)]	Loss: -7.5006	Cost: 20.83s
Train Epoch: 758 [61440/90000 (68%)]	Loss: -7.9036	Cost: 14.81s
Train Epoch: 758 [81920/90000 (91%)]	Loss: -8.0008	Cost: 17.98s
Train Epoch: 758 	Average Loss: -7.5378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5820

Learning rate: 0.0001999716477429364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: -3.3228	Cost: 37.63s
Train Epoch: 759 [20480/90000 (23%)]	Loss: -8.0771	Cost: 13.89s
Train Epoch: 759 [40960/90000 (45%)]	Loss: -7.0802	Cost: 17.09s
Train Epoch: 759 [61440/90000 (68%)]	Loss: -7.6980	Cost: 12.87s
Train Epoch: 759 [81920/90000 (91%)]	Loss: -7.8190	Cost: 16.86s
Train Epoch: 759 	Average Loss: -7.4156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6434

Learning rate: 0.00019997157288907143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: -4.0109	Cost: 30.68s
Train Epoch: 760 [20480/90000 (23%)]	Loss: -8.0644	Cost: 14.04s
Train Epoch: 760 [40960/90000 (45%)]	Loss: -7.7131	Cost: 15.95s
Train Epoch: 760 [61440/90000 (68%)]	Loss: -7.9247	Cost: 15.06s
Train Epoch: 760 [81920/90000 (91%)]	Loss: -7.8442	Cost: 21.36s
Train Epoch: 760 	Average Loss: -7.6596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3454

Learning rate: 0.00019997149793653845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: -3.2310	Cost: 27.63s
Train Epoch: 761 [20480/90000 (23%)]	Loss: -7.9350	Cost: 9.61s
Train Epoch: 761 [40960/90000 (45%)]	Loss: -7.4800	Cost: 15.47s
Train Epoch: 761 [61440/90000 (68%)]	Loss: -7.8275	Cost: 14.07s
Train Epoch: 761 [81920/90000 (91%)]	Loss: -8.3467	Cost: 15.17s
Train Epoch: 761 	Average Loss: -7.6049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8179

Saving model as e761_model.pt & e761_waveforms_supplementary.hdf5
Learning rate: 0.00019997142288533755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: -3.6398	Cost: 30.02s
Train Epoch: 762 [20480/90000 (23%)]	Loss: -8.4336	Cost: 6.38s
Train Epoch: 762 [40960/90000 (45%)]	Loss: -7.6539	Cost: 12.77s
Train Epoch: 762 [61440/90000 (68%)]	Loss: -7.9251	Cost: 12.86s
Train Epoch: 762 [81920/90000 (91%)]	Loss: -8.0757	Cost: 15.37s
Train Epoch: 762 	Average Loss: -7.7608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5644

Learning rate: 0.00019997134773546882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: -3.4555	Cost: 28.62s
Train Epoch: 763 [20480/90000 (23%)]	Loss: -8.3934	Cost: 9.48s
Train Epoch: 763 [40960/90000 (45%)]	Loss: -7.7686	Cost: 15.60s
Train Epoch: 763 [61440/90000 (68%)]	Loss: -8.0848	Cost: 13.96s
Train Epoch: 763 [81920/90000 (91%)]	Loss: -8.0255	Cost: 12.28s
Train Epoch: 763 	Average Loss: -7.7915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6906

Learning rate: 0.00019997127248693236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: -3.3968	Cost: 28.71s
Train Epoch: 764 [20480/90000 (23%)]	Loss: -8.2272	Cost: 8.92s
Train Epoch: 764 [40960/90000 (45%)]	Loss: -7.6878	Cost: 15.69s
Train Epoch: 764 [61440/90000 (68%)]	Loss: -8.0722	Cost: 13.94s
Train Epoch: 764 [81920/90000 (91%)]	Loss: -7.9431	Cost: 12.52s
Train Epoch: 764 	Average Loss: -7.6840
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6186

Learning rate: 0.00019997119713972814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: -3.5197	Cost: 37.44s
Train Epoch: 765 [20480/90000 (23%)]	Loss: -8.1893	Cost: 11.17s
Train Epoch: 765 [40960/90000 (45%)]	Loss: -7.7890	Cost: 12.21s
Train Epoch: 765 [61440/90000 (68%)]	Loss: -7.9870	Cost: 12.17s
Train Epoch: 765 [81920/90000 (91%)]	Loss: -8.0731	Cost: 12.45s
Train Epoch: 765 	Average Loss: -7.7766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7656

Learning rate: 0.00019997112169385637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: -3.7490	Cost: 30.43s
Train Epoch: 766 [20480/90000 (23%)]	Loss: -8.3185	Cost: 8.56s
Train Epoch: 766 [40960/90000 (45%)]	Loss: -7.8980	Cost: 12.50s
Train Epoch: 766 [61440/90000 (68%)]	Loss: -8.2945	Cost: 12.24s
Train Epoch: 766 [81920/90000 (91%)]	Loss: -8.4574	Cost: 11.99s
Train Epoch: 766 	Average Loss: -7.8805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9334

Saving model as e766_model.pt & e766_waveforms_supplementary.hdf5
Learning rate: 0.00019997104614931702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: -4.0372	Cost: 31.21s
Train Epoch: 767 [20480/90000 (23%)]	Loss: -8.5710	Cost: 8.92s
Train Epoch: 767 [40960/90000 (45%)]	Loss: -7.9875	Cost: 17.28s
Train Epoch: 767 [61440/90000 (68%)]	Loss: -7.5424	Cost: 8.90s
Train Epoch: 767 [81920/90000 (91%)]	Loss: -7.9526	Cost: 12.39s
Train Epoch: 767 	Average Loss: -7.7681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5612

Learning rate: 0.0001999709705061102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: -3.2823	Cost: 25.98s
Train Epoch: 768 [20480/90000 (23%)]	Loss: -7.8724	Cost: 8.33s
Train Epoch: 768 [40960/90000 (45%)]	Loss: -7.7123	Cost: 13.02s
Train Epoch: 768 [61440/90000 (68%)]	Loss: -8.1660	Cost: 12.21s
Train Epoch: 768 [81920/90000 (91%)]	Loss: -8.2875	Cost: 11.90s
Train Epoch: 768 	Average Loss: -7.6645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8519

Learning rate: 0.00019997089476423598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: -3.8142	Cost: 30.64s
Train Epoch: 769 [20480/90000 (23%)]	Loss: -8.7050	Cost: 12.09s
Train Epoch: 769 [40960/90000 (45%)]	Loss: -8.1920	Cost: 14.55s
Train Epoch: 769 [61440/90000 (68%)]	Loss: -8.4142	Cost: 12.09s
Train Epoch: 769 [81920/90000 (91%)]	Loss: -8.2774	Cost: 13.95s
Train Epoch: 769 	Average Loss: -8.0107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8691

Learning rate: 0.00019997081892369448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: -3.6264	Cost: 28.68s
Train Epoch: 770 [20480/90000 (23%)]	Loss: -8.4913	Cost: 12.23s
Train Epoch: 770 [40960/90000 (45%)]	Loss: -8.1807	Cost: 12.95s
Train Epoch: 770 [61440/90000 (68%)]	Loss: -8.5975	Cost: 12.07s
Train Epoch: 770 [81920/90000 (91%)]	Loss: -8.5319	Cost: 12.76s
Train Epoch: 770 	Average Loss: -8.1188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0412

Saving model as e770_model.pt & e770_waveforms_supplementary.hdf5
Learning rate: 0.0001999707429844857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: -3.8113	Cost: 37.39s
Train Epoch: 771 [20480/90000 (23%)]	Loss: -8.1993	Cost: 11.48s
Train Epoch: 771 [40960/90000 (45%)]	Loss: -7.7150	Cost: 12.22s
Train Epoch: 771 [61440/90000 (68%)]	Loss: -8.0941	Cost: 12.00s
Train Epoch: 771 [81920/90000 (91%)]	Loss: -8.2284	Cost: 9.83s
Train Epoch: 771 	Average Loss: -7.8788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8628

Learning rate: 0.00019997066694660978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: -3.4790	Cost: 33.72s
Train Epoch: 772 [20480/90000 (23%)]	Loss: -8.3873	Cost: 13.78s
Train Epoch: 772 [40960/90000 (45%)]	Loss: -7.8795	Cost: 12.08s
Train Epoch: 772 [61440/90000 (68%)]	Loss: -8.1507	Cost: 13.44s
Train Epoch: 772 [81920/90000 (91%)]	Loss: -8.1706	Cost: 12.47s
Train Epoch: 772 	Average Loss: -7.9241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9023

Learning rate: 0.00019997059081006675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: -3.9431	Cost: 32.00s
Train Epoch: 773 [20480/90000 (23%)]	Loss: -8.6225	Cost: 7.35s
Train Epoch: 773 [40960/90000 (45%)]	Loss: -7.9215	Cost: 13.17s
Train Epoch: 773 [61440/90000 (68%)]	Loss: -8.5036	Cost: 13.95s
Train Epoch: 773 [81920/90000 (91%)]	Loss: -8.5501	Cost: 17.66s
Train Epoch: 773 	Average Loss: -8.1049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9913

Learning rate: 0.0001999705145748567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: -4.0056	Cost: 33.36s
Train Epoch: 774 [20480/90000 (23%)]	Loss: -8.6251	Cost: 12.55s
Train Epoch: 774 [40960/90000 (45%)]	Loss: -8.0823	Cost: 12.80s
Train Epoch: 774 [61440/90000 (68%)]	Loss: -8.2250	Cost: 13.16s
Train Epoch: 774 [81920/90000 (91%)]	Loss: -8.3802	Cost: 12.94s
Train Epoch: 774 	Average Loss: -8.0868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1706

Saving model as e774_model.pt & e774_waveforms_supplementary.hdf5
Learning rate: 0.0001999704382409797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: -3.7330	Cost: 39.90s
Train Epoch: 775 [20480/90000 (23%)]	Loss: -8.4242	Cost: 10.60s
Train Epoch: 775 [40960/90000 (45%)]	Loss: -7.7958	Cost: 14.05s
Train Epoch: 775 [61440/90000 (68%)]	Loss: -8.4008	Cost: 13.39s
Train Epoch: 775 [81920/90000 (91%)]	Loss: -8.5300	Cost: 11.60s
Train Epoch: 775 	Average Loss: -7.9941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1797

Saving model as e775_model.pt & e775_waveforms_supplementary.hdf5
Learning rate: 0.00019997036180843583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: -4.1816	Cost: 36.27s
Train Epoch: 776 [20480/90000 (23%)]	Loss: -8.3744	Cost: 12.55s
Train Epoch: 776 [40960/90000 (45%)]	Loss: -8.0474	Cost: 15.78s
Train Epoch: 776 [61440/90000 (68%)]	Loss: -8.2620	Cost: 14.98s
Train Epoch: 776 [81920/90000 (91%)]	Loss: -8.4182	Cost: 11.69s
Train Epoch: 776 	Average Loss: -8.0246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0441

Learning rate: 0.00019997028527722518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: -3.3185	Cost: 40.03s
Train Epoch: 777 [20480/90000 (23%)]	Loss: -8.8290	Cost: 11.44s
Train Epoch: 777 [40960/90000 (45%)]	Loss: -8.3101	Cost: 15.24s
Train Epoch: 777 [61440/90000 (68%)]	Loss: -8.5088	Cost: 14.73s
Train Epoch: 777 [81920/90000 (91%)]	Loss: -8.6890	Cost: 11.15s
Train Epoch: 777 	Average Loss: -8.2833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1161

Learning rate: 0.00019997020864734782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: -4.1414	Cost: 33.68s
Train Epoch: 778 [20480/90000 (23%)]	Loss: -8.2618	Cost: 12.67s
Train Epoch: 778 [40960/90000 (45%)]	Loss: -8.0696	Cost: 12.97s
Train Epoch: 778 [61440/90000 (68%)]	Loss: -8.5105	Cost: 15.61s
Train Epoch: 778 [81920/90000 (91%)]	Loss: -8.4088	Cost: 13.16s
Train Epoch: 778 	Average Loss: -8.0783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8740

Learning rate: 0.00019997013191880381
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: -3.7922	Cost: 40.88s
Train Epoch: 779 [20480/90000 (23%)]	Loss: -8.4902	Cost: 10.88s
Train Epoch: 779 [40960/90000 (45%)]	Loss: -8.0644	Cost: 12.26s
Train Epoch: 779 [61440/90000 (68%)]	Loss: -8.4943	Cost: 12.34s
Train Epoch: 779 [81920/90000 (91%)]	Loss: -8.7433	Cost: 10.38s
Train Epoch: 779 	Average Loss: -8.1334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2113

Saving model as e779_model.pt & e779_waveforms_supplementary.hdf5
Learning rate: 0.00019997005509159326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: -3.3618	Cost: 35.95s
Train Epoch: 780 [20480/90000 (23%)]	Loss: -8.7348	Cost: 9.79s
Train Epoch: 780 [40960/90000 (45%)]	Loss: -8.0190	Cost: 12.95s
Train Epoch: 780 [61440/90000 (68%)]	Loss: -8.3580	Cost: 12.05s
Train Epoch: 780 [81920/90000 (91%)]	Loss: -8.3999	Cost: 7.95s
Train Epoch: 780 	Average Loss: -8.1431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0823

Learning rate: 0.0001999699781657162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: -3.6021	Cost: 33.98s
Train Epoch: 781 [20480/90000 (23%)]	Loss: -8.8750	Cost: 11.25s
Train Epoch: 781 [40960/90000 (45%)]	Loss: -8.1462	Cost: 12.18s
Train Epoch: 781 [61440/90000 (68%)]	Loss: -8.3989	Cost: 12.26s
Train Epoch: 781 [81920/90000 (91%)]	Loss: -8.3096	Cost: 7.16s
Train Epoch: 781 	Average Loss: -8.1340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5718

Learning rate: 0.00019996990114117273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: -3.5904	Cost: 30.03s
Train Epoch: 782 [20480/90000 (23%)]	Loss: -8.2335	Cost: 10.70s
Train Epoch: 782 [40960/90000 (45%)]	Loss: -7.8312	Cost: 14.41s
Train Epoch: 782 [61440/90000 (68%)]	Loss: -8.3685	Cost: 14.63s
Train Epoch: 782 [81920/90000 (91%)]	Loss: -8.5135	Cost: 13.62s
Train Epoch: 782 	Average Loss: -7.9327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0815

Learning rate: 0.0001999698240179629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: -3.7484	Cost: 29.11s
Train Epoch: 783 [20480/90000 (23%)]	Loss: -8.7875	Cost: 9.97s
Train Epoch: 783 [40960/90000 (45%)]	Loss: -8.1262	Cost: 13.46s
Train Epoch: 783 [61440/90000 (68%)]	Loss: -8.3980	Cost: 14.76s
Train Epoch: 783 [81920/90000 (91%)]	Loss: -8.4349	Cost: 14.48s
Train Epoch: 783 	Average Loss: -8.1746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0664

Learning rate: 0.00019996974679608684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: -3.4439	Cost: 29.87s
Train Epoch: 784 [20480/90000 (23%)]	Loss: -8.7291	Cost: 7.21s
Train Epoch: 784 [40960/90000 (45%)]	Loss: -8.3766	Cost: 14.13s
Train Epoch: 784 [61440/90000 (68%)]	Loss: -8.6351	Cost: 12.29s
Train Epoch: 784 [81920/90000 (91%)]	Loss: -8.1542	Cost: 13.99s
Train Epoch: 784 	Average Loss: -8.1518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6762

Learning rate: 0.00019996966947554456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: -3.5967	Cost: 29.63s
Train Epoch: 785 [20480/90000 (23%)]	Loss: -8.1571	Cost: 12.37s
Train Epoch: 785 [40960/90000 (45%)]	Loss: -7.6456	Cost: 12.55s
Train Epoch: 785 [61440/90000 (68%)]	Loss: -8.2178	Cost: 11.88s
Train Epoch: 785 [81920/90000 (91%)]	Loss: -8.5787	Cost: 12.51s
Train Epoch: 785 	Average Loss: -7.8133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1859

Learning rate: 0.0001999695920563362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: -4.3774	Cost: 34.94s
Train Epoch: 786 [20480/90000 (23%)]	Loss: -8.8389	Cost: 12.45s
Train Epoch: 786 [40960/90000 (45%)]	Loss: -8.1875	Cost: 12.40s
Train Epoch: 786 [61440/90000 (68%)]	Loss: -8.4694	Cost: 12.01s
Train Epoch: 786 [81920/90000 (91%)]	Loss: -8.6836	Cost: 12.32s
Train Epoch: 786 	Average Loss: -8.2358
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0916

Learning rate: 0.0001999695145384618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: -4.3747	Cost: 30.01s
Train Epoch: 787 [20480/90000 (23%)]	Loss: -8.8035	Cost: 10.08s
Train Epoch: 787 [40960/90000 (45%)]	Loss: -8.2004	Cost: 12.82s
Train Epoch: 787 [61440/90000 (68%)]	Loss: -8.4635	Cost: 12.09s
Train Epoch: 787 [81920/90000 (91%)]	Loss: -8.4193	Cost: 12.80s
Train Epoch: 787 	Average Loss: -8.2572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8615

Learning rate: 0.00019996943692192142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: -3.8550	Cost: 34.39s
Train Epoch: 788 [20480/90000 (23%)]	Loss: -8.3053	Cost: 12.93s
Train Epoch: 788 [40960/90000 (45%)]	Loss: -7.7620	Cost: 12.27s
Train Epoch: 788 [61440/90000 (68%)]	Loss: -8.2559	Cost: 12.26s
Train Epoch: 788 [81920/90000 (91%)]	Loss: -8.4517	Cost: 12.31s
Train Epoch: 788 	Average Loss: -7.9688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0417

Learning rate: 0.0001999693592067152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: -3.8041	Cost: 36.41s
Train Epoch: 789 [20480/90000 (23%)]	Loss: -8.0851	Cost: 7.44s
Train Epoch: 789 [40960/90000 (45%)]	Loss: -7.6202	Cost: 15.80s
Train Epoch: 789 [61440/90000 (68%)]	Loss: -8.2826	Cost: 14.85s
Train Epoch: 789 [81920/90000 (91%)]	Loss: -8.1935	Cost: 12.88s
Train Epoch: 789 	Average Loss: -7.9584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8219

Learning rate: 0.00019996928139284315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: -3.7994	Cost: 27.46s
Train Epoch: 790 [20480/90000 (23%)]	Loss: -8.4333	Cost: 9.22s
Train Epoch: 790 [40960/90000 (45%)]	Loss: -8.2325	Cost: 22.47s
Train Epoch: 790 [61440/90000 (68%)]	Loss: -8.4147	Cost: 13.55s
Train Epoch: 790 [81920/90000 (91%)]	Loss: -8.7069	Cost: 18.64s
Train Epoch: 790 	Average Loss: -8.1929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3479

Saving model as e790_model.pt & e790_waveforms_supplementary.hdf5
Learning rate: 0.00019996920348030537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: -3.8468	Cost: 31.70s
Train Epoch: 791 [20480/90000 (23%)]	Loss: -8.7307	Cost: 9.98s
Train Epoch: 791 [40960/90000 (45%)]	Loss: -8.1822	Cost: 12.43s
Train Epoch: 791 [61440/90000 (68%)]	Loss: -8.7194	Cost: 13.02s
Train Epoch: 791 [81920/90000 (91%)]	Loss: -8.6995	Cost: 16.89s
Train Epoch: 791 	Average Loss: -8.3000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1606

Learning rate: 0.00019996912546910197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: -4.0626	Cost: 30.45s
Train Epoch: 792 [20480/90000 (23%)]	Loss: -8.7978	Cost: 12.46s
Train Epoch: 792 [40960/90000 (45%)]	Loss: -8.3968	Cost: 12.04s
Train Epoch: 792 [61440/90000 (68%)]	Loss: -8.9090	Cost: 11.89s
Train Epoch: 792 [81920/90000 (91%)]	Loss: -8.9331	Cost: 15.40s
Train Epoch: 792 	Average Loss: -8.4318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3507

Saving model as e792_model.pt & e792_waveforms_supplementary.hdf5
Learning rate: 0.000199969047359233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: -4.1943	Cost: 32.71s
Train Epoch: 793 [20480/90000 (23%)]	Loss: -9.0031	Cost: 8.65s
Train Epoch: 793 [40960/90000 (45%)]	Loss: -8.3511	Cost: 11.12s
Train Epoch: 793 [61440/90000 (68%)]	Loss: -8.8338	Cost: 11.92s
Train Epoch: 793 [81920/90000 (91%)]	Loss: -8.8504	Cost: 11.88s
Train Epoch: 793 	Average Loss: -8.4912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2760

Learning rate: 0.00019996896915069852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: -3.9274	Cost: 26.53s
Train Epoch: 794 [20480/90000 (23%)]	Loss: -9.0040	Cost: 10.29s
Train Epoch: 794 [40960/90000 (45%)]	Loss: -8.3300	Cost: 12.43s
Train Epoch: 794 [61440/90000 (68%)]	Loss: -9.0328	Cost: 12.04s
Train Epoch: 794 [81920/90000 (91%)]	Loss: -9.1857	Cost: 12.05s
Train Epoch: 794 	Average Loss: -8.6067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4588

Saving model as e794_model.pt & e794_waveforms_supplementary.hdf5
Learning rate: 0.0001999688908434986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 795 [0/90000 (0%)]	Loss: -4.2906	Cost: 29.95s
Train Epoch: 795 [20480/90000 (23%)]	Loss: -8.8447	Cost: 9.02s
Train Epoch: 795 [40960/90000 (45%)]	Loss: -8.4028	Cost: 12.17s
Train Epoch: 795 [61440/90000 (68%)]	Loss: -8.9446	Cost: 12.01s
Train Epoch: 795 [81920/90000 (91%)]	Loss: -8.9316	Cost: 10.26s
Train Epoch: 795 	Average Loss: -8.4954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4177

Learning rate: 0.00019996881243763336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 796 [0/90000 (0%)]	Loss: -4.3694	Cost: 27.34s
Train Epoch: 796 [20480/90000 (23%)]	Loss: -9.0039	Cost: 11.34s
Train Epoch: 796 [40960/90000 (45%)]	Loss: -8.3447	Cost: 13.56s
Train Epoch: 796 [61440/90000 (68%)]	Loss: -8.8419	Cost: 13.25s
Train Epoch: 796 [81920/90000 (91%)]	Loss: -8.2937	Cost: 12.69s
Train Epoch: 796 	Average Loss: -8.3741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7021

Learning rate: 0.00019996873393310284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 797 [0/90000 (0%)]	Loss: -3.2583	Cost: 27.91s
Train Epoch: 797 [20480/90000 (23%)]	Loss: -8.3205	Cost: 12.28s
Train Epoch: 797 [40960/90000 (45%)]	Loss: -8.0394	Cost: 14.34s
Train Epoch: 797 [61440/90000 (68%)]	Loss: -8.5971	Cost: 14.30s
Train Epoch: 797 [81920/90000 (91%)]	Loss: -8.8970	Cost: 14.12s
Train Epoch: 797 	Average Loss: -8.1426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2480

Learning rate: 0.00019996865532990714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 798 [0/90000 (0%)]	Loss: -4.5551	Cost: 28.70s
Train Epoch: 798 [20480/90000 (23%)]	Loss: -8.9531	Cost: 6.70s
Train Epoch: 798 [40960/90000 (45%)]	Loss: -8.4690	Cost: 13.82s
Train Epoch: 798 [61440/90000 (68%)]	Loss: -8.9960	Cost: 14.53s
Train Epoch: 798 [81920/90000 (91%)]	Loss: -9.1547	Cost: 14.16s
Train Epoch: 798 	Average Loss: -8.5664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5923

Saving model as e798_model.pt & e798_waveforms_supplementary.hdf5
Learning rate: 0.00019996857662804636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 799 [0/90000 (0%)]	Loss: -4.1477	Cost: 32.83s
Train Epoch: 799 [20480/90000 (23%)]	Loss: -8.9636	Cost: 7.02s
Train Epoch: 799 [40960/90000 (45%)]	Loss: -8.3124	Cost: 12.50s
Train Epoch: 799 [61440/90000 (68%)]	Loss: -8.4318	Cost: 15.21s
Train Epoch: 799 [81920/90000 (91%)]	Loss: -8.3581	Cost: 15.04s
Train Epoch: 799 	Average Loss: -8.3436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9856

Learning rate: 0.00019996849782752052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 800 [0/90000 (0%)]	Loss: -4.0770	Cost: 35.05s
Train Epoch: 800 [20480/90000 (23%)]	Loss: -8.6449	Cost: 12.04s
Train Epoch: 800 [40960/90000 (45%)]	Loss: -8.5011	Cost: 13.83s
Train Epoch: 800 [61440/90000 (68%)]	Loss: -8.8860	Cost: 14.74s
Train Epoch: 800 [81920/90000 (91%)]	Loss: -9.1811	Cost: 14.42s
Train Epoch: 800 	Average Loss: -8.4745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5113

Learning rate: 0.00019996841892832974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 801 [0/90000 (0%)]	Loss: -4.7358	Cost: 30.43s
Train Epoch: 801 [20480/90000 (23%)]	Loss: -9.3418	Cost: 7.77s
Train Epoch: 801 [40960/90000 (45%)]	Loss: -8.7498	Cost: 14.48s
Train Epoch: 801 [61440/90000 (68%)]	Loss: -8.9550	Cost: 14.10s
Train Epoch: 801 [81920/90000 (91%)]	Loss: -9.1069	Cost: 15.23s
Train Epoch: 801 	Average Loss: -8.7750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5687

Learning rate: 0.00019996833993047412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 802 [0/90000 (0%)]	Loss: -4.2102	Cost: 27.52s
Train Epoch: 802 [20480/90000 (23%)]	Loss: -9.2462	Cost: 7.00s
Train Epoch: 802 [40960/90000 (45%)]	Loss: -8.5765	Cost: 14.80s
Train Epoch: 802 [61440/90000 (68%)]	Loss: -8.8576	Cost: 14.56s
Train Epoch: 802 [81920/90000 (91%)]	Loss: -8.8113	Cost: 13.91s
Train Epoch: 802 	Average Loss: -8.6488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3494

Learning rate: 0.00019996826083395366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 803 [0/90000 (0%)]	Loss: -4.0558	Cost: 26.50s
Train Epoch: 803 [20480/90000 (23%)]	Loss: -9.2733	Cost: 7.16s
Train Epoch: 803 [40960/90000 (45%)]	Loss: -8.6673	Cost: 14.85s
Train Epoch: 803 [61440/90000 (68%)]	Loss: -8.5277	Cost: 13.08s
Train Epoch: 803 [81920/90000 (91%)]	Loss: -5.7910	Cost: 20.65s
Train Epoch: 803 	Average Loss: -8.0584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4974

Learning rate: 0.0001999681816387685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 804 [0/90000 (0%)]	Loss: -1.5968	Cost: 29.94s
Train Epoch: 804 [20480/90000 (23%)]	Loss: -5.9458	Cost: 6.54s
Train Epoch: 804 [40960/90000 (45%)]	Loss: -6.2271	Cost: 13.51s
Train Epoch: 804 [61440/90000 (68%)]	Loss: -7.1634	Cost: 12.87s
Train Epoch: 804 [81920/90000 (91%)]	Loss: -7.5633	Cost: 15.69s
Train Epoch: 804 	Average Loss: -6.2106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2301

Learning rate: 0.00019996810234491867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 805 [0/90000 (0%)]	Loss: -2.9955	Cost: 30.39s
Train Epoch: 805 [20480/90000 (23%)]	Loss: -8.1566	Cost: 12.72s
Train Epoch: 805 [40960/90000 (45%)]	Loss: -7.7736	Cost: 14.05s
Train Epoch: 805 [61440/90000 (68%)]	Loss: -8.4615	Cost: 13.48s
Train Epoch: 805 [81920/90000 (91%)]	Loss: -8.4384	Cost: 14.86s
Train Epoch: 805 	Average Loss: -7.8620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1785

Learning rate: 0.0001999680229524043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 806 [0/90000 (0%)]	Loss: -3.7398	Cost: 32.01s
Train Epoch: 806 [20480/90000 (23%)]	Loss: -8.9353	Cost: 14.24s
Train Epoch: 806 [40960/90000 (45%)]	Loss: -8.2636	Cost: 17.12s
Train Epoch: 806 [61440/90000 (68%)]	Loss: -8.7205	Cost: 15.46s
Train Epoch: 806 [81920/90000 (91%)]	Loss: -8.6361	Cost: 17.03s
Train Epoch: 806 	Average Loss: -8.2798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0856

Learning rate: 0.00019996794346122544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 807 [0/90000 (0%)]	Loss: -3.7134	Cost: 29.16s
Train Epoch: 807 [20480/90000 (23%)]	Loss: -8.9769	Cost: 14.09s
Train Epoch: 807 [40960/90000 (45%)]	Loss: -8.4872	Cost: 15.26s
Train Epoch: 807 [61440/90000 (68%)]	Loss: -9.1644	Cost: 14.42s
Train Epoch: 807 [81920/90000 (91%)]	Loss: -9.0921	Cost: 17.56s
Train Epoch: 807 	Average Loss: -8.5641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5688

Learning rate: 0.00019996786387138218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 808 [0/90000 (0%)]	Loss: -4.4978	Cost: 30.62s
Train Epoch: 808 [20480/90000 (23%)]	Loss: -9.3045	Cost: 14.56s
Train Epoch: 808 [40960/90000 (45%)]	Loss: -8.9168	Cost: 14.57s
Train Epoch: 808 [61440/90000 (68%)]	Loss: -9.2103	Cost: 14.59s
Train Epoch: 808 [81920/90000 (91%)]	Loss: -9.2159	Cost: 13.17s
Train Epoch: 808 	Average Loss: -8.8230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6265

Saving model as e808_model.pt & e808_waveforms_supplementary.hdf5
Learning rate: 0.00019996778418287457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 809 [0/90000 (0%)]	Loss: -4.3349	Cost: 27.74s
Train Epoch: 809 [20480/90000 (23%)]	Loss: -9.4697	Cost: 13.88s
Train Epoch: 809 [40960/90000 (45%)]	Loss: -8.7428	Cost: 14.22s
Train Epoch: 809 [61440/90000 (68%)]	Loss: -9.2206	Cost: 12.76s
Train Epoch: 809 [81920/90000 (91%)]	Loss: -8.9348	Cost: 11.54s
Train Epoch: 809 	Average Loss: -8.7932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2491

Learning rate: 0.00019996770439570274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 810 [0/90000 (0%)]	Loss: -3.9312	Cost: 28.86s
Train Epoch: 810 [20480/90000 (23%)]	Loss: -8.8648	Cost: 7.50s
Train Epoch: 810 [40960/90000 (45%)]	Loss: -8.4953	Cost: 15.89s
Train Epoch: 810 [61440/90000 (68%)]	Loss: -8.7296	Cost: 13.65s
Train Epoch: 810 [81920/90000 (91%)]	Loss: -9.1064	Cost: 15.30s
Train Epoch: 810 	Average Loss: -8.4833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4575

Learning rate: 0.00019996762450986673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 811 [0/90000 (0%)]	Loss: -4.4862	Cost: 26.40s
Train Epoch: 811 [20480/90000 (23%)]	Loss: -9.2903	Cost: 7.03s
Train Epoch: 811 [40960/90000 (45%)]	Loss: -8.9242	Cost: 14.54s
Train Epoch: 811 [61440/90000 (68%)]	Loss: -9.3205	Cost: 13.24s
Train Epoch: 811 [81920/90000 (91%)]	Loss: -9.3383	Cost: 13.78s
Train Epoch: 811 	Average Loss: -8.8426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8206

Saving model as e811_model.pt & e811_waveforms_supplementary.hdf5
Learning rate: 0.00019996754452536662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 812 [0/90000 (0%)]	Loss: -4.4461	Cost: 27.34s
Train Epoch: 812 [20480/90000 (23%)]	Loss: -9.5822	Cost: 8.24s
Train Epoch: 812 [40960/90000 (45%)]	Loss: -8.8758	Cost: 14.22s
Train Epoch: 812 [61440/90000 (68%)]	Loss: -9.1837	Cost: 13.99s
Train Epoch: 812 [81920/90000 (91%)]	Loss: -8.9666	Cost: 20.80s
Train Epoch: 812 	Average Loss: -8.8304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3800

Learning rate: 0.0001999674644422025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 813 [0/90000 (0%)]	Loss: -4.0768	Cost: 28.13s
Train Epoch: 813 [20480/90000 (23%)]	Loss: -9.1468	Cost: 9.70s
Train Epoch: 813 [40960/90000 (45%)]	Loss: -8.7338	Cost: 16.26s
Train Epoch: 813 [61440/90000 (68%)]	Loss: -9.1793	Cost: 13.29s
Train Epoch: 813 [81920/90000 (91%)]	Loss: -9.0618	Cost: 16.00s
Train Epoch: 813 	Average Loss: -8.6794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7021

Learning rate: 0.00019996738426037447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 814 [0/90000 (0%)]	Loss: -4.5436	Cost: 31.52s
Train Epoch: 814 [20480/90000 (23%)]	Loss: -9.2783	Cost: 13.38s
Train Epoch: 814 [40960/90000 (45%)]	Loss: -8.7532	Cost: 15.62s
Train Epoch: 814 [61440/90000 (68%)]	Loss: -9.0666	Cost: 14.87s
Train Epoch: 814 [81920/90000 (91%)]	Loss: -9.2661	Cost: 18.03s
Train Epoch: 814 	Average Loss: -8.8005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6287

Learning rate: 0.00019996730397988258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 815 [0/90000 (0%)]	Loss: -4.2243	Cost: 28.18s
Train Epoch: 815 [20480/90000 (23%)]	Loss: -9.3708	Cost: 12.20s
Train Epoch: 815 [40960/90000 (45%)]	Loss: -8.7967	Cost: 15.68s
Train Epoch: 815 [61440/90000 (68%)]	Loss: -9.2087	Cost: 13.32s
Train Epoch: 815 [81920/90000 (91%)]	Loss: -9.4253	Cost: 14.43s
Train Epoch: 815 	Average Loss: -8.8841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6667

Learning rate: 0.00019996722360072691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 816 [0/90000 (0%)]	Loss: -3.8318	Cost: 28.94s
Train Epoch: 816 [20480/90000 (23%)]	Loss: -9.4637	Cost: 11.30s
Train Epoch: 816 [40960/90000 (45%)]	Loss: -8.8630	Cost: 14.20s
Train Epoch: 816 [61440/90000 (68%)]	Loss: -9.2078	Cost: 13.89s
Train Epoch: 816 [81920/90000 (91%)]	Loss: -9.2340	Cost: 15.47s
Train Epoch: 816 	Average Loss: -8.9195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6029

Learning rate: 0.00019996714312290757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 817 [0/90000 (0%)]	Loss: -3.8884	Cost: 28.28s
Train Epoch: 817 [20480/90000 (23%)]	Loss: -9.5418	Cost: 7.54s
Train Epoch: 817 [40960/90000 (45%)]	Loss: -8.8241	Cost: 20.73s
Train Epoch: 817 [61440/90000 (68%)]	Loss: -9.0606	Cost: 12.17s
Train Epoch: 817 [81920/90000 (91%)]	Loss: -9.0910	Cost: 21.31s
Train Epoch: 817 	Average Loss: -8.8146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6130

Learning rate: 0.0001999670625464246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 818 [0/90000 (0%)]	Loss: -4.3810	Cost: 28.46s
Train Epoch: 818 [20480/90000 (23%)]	Loss: -9.1966	Cost: 6.63s
Train Epoch: 818 [40960/90000 (45%)]	Loss: -8.8615	Cost: 17.87s
Train Epoch: 818 [61440/90000 (68%)]	Loss: -9.3102	Cost: 13.82s
Train Epoch: 818 [81920/90000 (91%)]	Loss: -9.4402	Cost: 13.65s
Train Epoch: 818 	Average Loss: -8.9431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9055

Saving model as e818_model.pt & e818_waveforms_supplementary.hdf5
Learning rate: 0.00019996698187127807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 819 [0/90000 (0%)]	Loss: -4.6866	Cost: 30.28s
Train Epoch: 819 [20480/90000 (23%)]	Loss: -9.7020	Cost: 11.25s
Train Epoch: 819 [40960/90000 (45%)]	Loss: -9.0532	Cost: 18.81s
Train Epoch: 819 [61440/90000 (68%)]	Loss: -9.4393	Cost: 13.58s
Train Epoch: 819 [81920/90000 (91%)]	Loss: -9.3890	Cost: 12.11s
Train Epoch: 819 	Average Loss: -9.1618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9191

Saving model as e819_model.pt & e819_waveforms_supplementary.hdf5
Learning rate: 0.00019996690109746812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 820 [0/90000 (0%)]	Loss: -4.4771	Cost: 28.19s
Train Epoch: 820 [20480/90000 (23%)]	Loss: -8.6528	Cost: 13.90s
Train Epoch: 820 [40960/90000 (45%)]	Loss: -7.9420	Cost: 14.18s
Train Epoch: 820 [61440/90000 (68%)]	Loss: -8.3846	Cost: 13.13s
Train Epoch: 820 [81920/90000 (91%)]	Loss: -8.8384	Cost: 12.27s
Train Epoch: 820 	Average Loss: -8.3273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3011

Learning rate: 0.00019996682022499477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 821 [0/90000 (0%)]	Loss: -4.1853	Cost: 29.26s
Train Epoch: 821 [20480/90000 (23%)]	Loss: -9.0824	Cost: 6.53s
Train Epoch: 821 [40960/90000 (45%)]	Loss: -8.8701	Cost: 12.33s
Train Epoch: 821 [61440/90000 (68%)]	Loss: -9.1903	Cost: 14.05s
Train Epoch: 821 [81920/90000 (91%)]	Loss: -9.1860	Cost: 12.50s
Train Epoch: 821 	Average Loss: -8.7896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6983

Learning rate: 0.00019996673925385812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 822 [0/90000 (0%)]	Loss: -4.0346	Cost: 41.83s
Train Epoch: 822 [20480/90000 (23%)]	Loss: -9.5062	Cost: 9.44s
Train Epoch: 822 [40960/90000 (45%)]	Loss: -9.1307	Cost: 11.97s
Train Epoch: 822 [61440/90000 (68%)]	Loss: -8.6842	Cost: 12.16s
Train Epoch: 822 [81920/90000 (91%)]	Loss: -8.8608	Cost: 13.12s
Train Epoch: 822 	Average Loss: -8.6543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3603

Learning rate: 0.00019996665818405824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 823 [0/90000 (0%)]	Loss: -3.7498	Cost: 35.59s
Train Epoch: 823 [20480/90000 (23%)]	Loss: -9.3344	Cost: 13.73s
Train Epoch: 823 [40960/90000 (45%)]	Loss: -8.7699	Cost: 15.33s
Train Epoch: 823 [61440/90000 (68%)]	Loss: -9.1714	Cost: 13.62s
Train Epoch: 823 [81920/90000 (91%)]	Loss: -9.2365	Cost: 12.47s
Train Epoch: 823 	Average Loss: -8.7601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6790

Learning rate: 0.00019996657701559526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 824 [0/90000 (0%)]	Loss: -4.5514	Cost: 29.75s
Train Epoch: 824 [20480/90000 (23%)]	Loss: -9.5559	Cost: 12.03s
Train Epoch: 824 [40960/90000 (45%)]	Loss: -8.9673	Cost: 18.70s
Train Epoch: 824 [61440/90000 (68%)]	Loss: -9.4663	Cost: 15.34s
Train Epoch: 824 [81920/90000 (91%)]	Loss: -9.6042	Cost: 14.32s
Train Epoch: 824 	Average Loss: -9.0743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8209

Learning rate: 0.0001999664957484692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 825 [0/90000 (0%)]	Loss: -4.8875	Cost: 28.89s
Train Epoch: 825 [20480/90000 (23%)]	Loss: -9.9070	Cost: 6.20s
Train Epoch: 825 [40960/90000 (45%)]	Loss: -9.2737	Cost: 12.89s
Train Epoch: 825 [61440/90000 (68%)]	Loss: -9.4006	Cost: 13.96s
Train Epoch: 825 [81920/90000 (91%)]	Loss: -9.5730	Cost: 14.26s
Train Epoch: 825 	Average Loss: -9.2698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6962

Learning rate: 0.00019996641438268018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 826 [0/90000 (0%)]	Loss: -5.0281	Cost: 33.51s
Train Epoch: 826 [20480/90000 (23%)]	Loss: -9.3197	Cost: 8.24s
Train Epoch: 826 [40960/90000 (45%)]	Loss: -8.7044	Cost: 12.40s
Train Epoch: 826 [61440/90000 (68%)]	Loss: -9.0724	Cost: 13.03s
Train Epoch: 826 [81920/90000 (91%)]	Loss: -9.4304	Cost: 15.01s
Train Epoch: 826 	Average Loss: -8.8544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7023

Learning rate: 0.00019996633291822824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 827 [0/90000 (0%)]	Loss: -4.5146	Cost: 32.07s
Train Epoch: 827 [20480/90000 (23%)]	Loss: -9.6386	Cost: 12.08s
Train Epoch: 827 [40960/90000 (45%)]	Loss: -8.9657	Cost: 13.18s
Train Epoch: 827 [61440/90000 (68%)]	Loss: -9.4925	Cost: 11.95s
Train Epoch: 827 [81920/90000 (91%)]	Loss: -9.1412	Cost: 12.12s
Train Epoch: 827 	Average Loss: -8.9800
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7069

Learning rate: 0.00019996625135511347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 828 [0/90000 (0%)]	Loss: -4.4777	Cost: 28.32s
Train Epoch: 828 [20480/90000 (23%)]	Loss: -9.7498	Cost: 10.74s
Train Epoch: 828 [40960/90000 (45%)]	Loss: -9.0282	Cost: 18.99s
Train Epoch: 828 [61440/90000 (68%)]	Loss: -9.5016	Cost: 13.54s
Train Epoch: 828 [81920/90000 (91%)]	Loss: -9.2831	Cost: 12.16s
Train Epoch: 828 	Average Loss: -9.0764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5506

Learning rate: 0.000199966169693336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 829 [0/90000 (0%)]	Loss: -4.8274	Cost: 53.90s
Train Epoch: 829 [20480/90000 (23%)]	Loss: -9.3281	Cost: 11.52s
Train Epoch: 829 [40960/90000 (45%)]	Loss: -8.9873	Cost: 14.63s
Train Epoch: 829 [61440/90000 (68%)]	Loss: -9.4474	Cost: 12.29s
Train Epoch: 829 [81920/90000 (91%)]	Loss: -9.6793	Cost: 11.95s
Train Epoch: 829 	Average Loss: -9.0492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7808

Learning rate: 0.00019996608793289584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 830 [0/90000 (0%)]	Loss: -4.6682	Cost: 55.97s
Train Epoch: 830 [20480/90000 (23%)]	Loss: -9.4132	Cost: 10.18s
Train Epoch: 830 [40960/90000 (45%)]	Loss: -9.1268	Cost: 20.26s
Train Epoch: 830 [61440/90000 (68%)]	Loss: -9.6696	Cost: 11.19s
Train Epoch: 830 [81920/90000 (91%)]	Loss: -9.6633	Cost: 11.83s
Train Epoch: 830 	Average Loss: -9.1797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9344

Saving model as e830_model.pt & e830_waveforms_supplementary.hdf5
Learning rate: 0.00019996600607379315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 831 [0/90000 (0%)]	Loss: -4.6177	Cost: 56.24s
Train Epoch: 831 [20480/90000 (23%)]	Loss: -9.6923	Cost: 10.30s
Train Epoch: 831 [40960/90000 (45%)]	Loss: -9.1035	Cost: 18.24s
Train Epoch: 831 [61440/90000 (68%)]	Loss: -9.3859	Cost: 9.35s
Train Epoch: 831 [81920/90000 (91%)]	Loss: -9.6562	Cost: 12.00s
Train Epoch: 831 	Average Loss: -9.2408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9075

Learning rate: 0.00019996592411602795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 832 [0/90000 (0%)]	Loss: -4.4829	Cost: 54.10s
Train Epoch: 832 [20480/90000 (23%)]	Loss: -9.7273	Cost: 12.57s
Train Epoch: 832 [40960/90000 (45%)]	Loss: -9.0538	Cost: 13.23s
Train Epoch: 832 [61440/90000 (68%)]	Loss: -9.2491	Cost: 12.11s
Train Epoch: 832 [81920/90000 (91%)]	Loss: -9.4947	Cost: 11.85s
Train Epoch: 832 	Average Loss: -9.1191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8579

Learning rate: 0.00019996584205960035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 833 [0/90000 (0%)]	Loss: -4.7552	Cost: 40.60s
Train Epoch: 833 [20480/90000 (23%)]	Loss: -9.6492	Cost: 12.98s
Train Epoch: 833 [40960/90000 (45%)]	Loss: -9.2030	Cost: 14.44s
Train Epoch: 833 [61440/90000 (68%)]	Loss: -9.7252	Cost: 11.85s
Train Epoch: 833 [81920/90000 (91%)]	Loss: -9.4904	Cost: 12.14s
Train Epoch: 833 	Average Loss: -9.2032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7649

Learning rate: 0.00019996575990451038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 834 [0/90000 (0%)]	Loss: -4.3885	Cost: 33.04s
Train Epoch: 834 [20480/90000 (23%)]	Loss: -9.7296	Cost: 7.92s
Train Epoch: 834 [40960/90000 (45%)]	Loss: -9.1514	Cost: 14.47s
Train Epoch: 834 [61440/90000 (68%)]	Loss: -9.6709	Cost: 12.97s
Train Epoch: 834 [81920/90000 (91%)]	Loss: -9.0556	Cost: 12.06s
Train Epoch: 834 	Average Loss: -9.1547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4118

Learning rate: 0.00019996567765075823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 835 [0/90000 (0%)]	Loss: -4.5977	Cost: 39.24s
Train Epoch: 835 [20480/90000 (23%)]	Loss: -8.9642	Cost: 8.92s
Train Epoch: 835 [40960/90000 (45%)]	Loss: -8.6489	Cost: 13.76s
Train Epoch: 835 [61440/90000 (68%)]	Loss: -9.2294	Cost: 6.52s
Train Epoch: 835 [81920/90000 (91%)]	Loss: -9.3790	Cost: 16.78s
Train Epoch: 835 	Average Loss: -8.6938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7142

Learning rate: 0.00019996559529834385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 836 [0/90000 (0%)]	Loss: -4.5692	Cost: 32.66s
Train Epoch: 836 [20480/90000 (23%)]	Loss: -9.6464	Cost: 10.73s
Train Epoch: 836 [40960/90000 (45%)]	Loss: -8.0854	Cost: 12.95s
Train Epoch: 836 [61440/90000 (68%)]	Loss: -8.7721	Cost: 8.80s
Train Epoch: 836 [81920/90000 (91%)]	Loss: -8.8409	Cost: 19.35s
Train Epoch: 836 	Average Loss: -8.5029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3793

Learning rate: 0.0001999655128472674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 837 [0/90000 (0%)]	Loss: -4.2827	Cost: 23.13s
Train Epoch: 837 [20480/90000 (23%)]	Loss: -9.3658	Cost: 7.02s
Train Epoch: 837 [40960/90000 (45%)]	Loss: -8.9911	Cost: 15.11s
Train Epoch: 837 [61440/90000 (68%)]	Loss: -9.2816	Cost: 10.10s
Train Epoch: 837 [81920/90000 (91%)]	Loss: -8.9353	Cost: 20.97s
Train Epoch: 837 	Average Loss: -8.8310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3124

Learning rate: 0.00019996543029752892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 838 [0/90000 (0%)]	Loss: -3.8065	Cost: 27.88s
Train Epoch: 838 [20480/90000 (23%)]	Loss: -9.4006	Cost: 6.14s
Train Epoch: 838 [40960/90000 (45%)]	Loss: -9.0565	Cost: 9.18s
Train Epoch: 838 [61440/90000 (68%)]	Loss: -9.2839	Cost: 6.20s
Train Epoch: 838 [81920/90000 (91%)]	Loss: -9.3245	Cost: 10.22s
Train Epoch: 838 	Average Loss: -8.8909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6602

Learning rate: 0.00019996534764912853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 839 [0/90000 (0%)]	Loss: -4.5316	Cost: 30.06s
Train Epoch: 839 [20480/90000 (23%)]	Loss: -8.7460	Cost: 10.52s
Train Epoch: 839 [40960/90000 (45%)]	Loss: -8.6043	Cost: 9.81s
Train Epoch: 839 [61440/90000 (68%)]	Loss: -9.4465	Cost: 6.36s
Train Epoch: 839 [81920/90000 (91%)]	Loss: -9.4064	Cost: 10.16s
Train Epoch: 839 	Average Loss: -8.7859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8711

Learning rate: 0.00019996526490206627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 840 [0/90000 (0%)]	Loss: -3.9796	Cost: 30.07s
Train Epoch: 840 [20480/90000 (23%)]	Loss: -9.7878	Cost: 6.66s
Train Epoch: 840 [40960/90000 (45%)]	Loss: -9.3976	Cost: 18.70s
Train Epoch: 840 [61440/90000 (68%)]	Loss: -9.8843	Cost: 8.79s
Train Epoch: 840 [81920/90000 (91%)]	Loss: -9.8736	Cost: 17.46s
Train Epoch: 840 	Average Loss: -9.3147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9555

Saving model as e840_model.pt & e840_waveforms_supplementary.hdf5
Learning rate: 0.00019996518205634228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 841 [0/90000 (0%)]	Loss: -4.6501	Cost: 40.62s
Train Epoch: 841 [20480/90000 (23%)]	Loss: -9.6225	Cost: 8.65s
Train Epoch: 841 [40960/90000 (45%)]	Loss: -9.1631	Cost: 13.70s
Train Epoch: 841 [61440/90000 (68%)]	Loss: -9.6056	Cost: 7.36s
Train Epoch: 841 [81920/90000 (91%)]	Loss: -9.6130	Cost: 16.50s
Train Epoch: 841 	Average Loss: -9.2445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9675

Saving model as e841_model.pt & e841_waveforms_supplementary.hdf5
Learning rate: 0.00019996509911195663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 842 [0/90000 (0%)]	Loss: -4.4458	Cost: 46.19s
Train Epoch: 842 [20480/90000 (23%)]	Loss: -9.8920	Cost: 8.80s
Train Epoch: 842 [40960/90000 (45%)]	Loss: -9.0814	Cost: 12.53s
Train Epoch: 842 [61440/90000 (68%)]	Loss: -9.7348	Cost: 6.59s
Train Epoch: 842 [81920/90000 (91%)]	Loss: -9.6224	Cost: 15.96s
Train Epoch: 842 	Average Loss: -9.2718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0897

Saving model as e842_model.pt & e842_waveforms_supplementary.hdf5
Learning rate: 0.00019996501606890936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 843 [0/90000 (0%)]	Loss: -4.9708	Cost: 56.18s
Train Epoch: 843 [20480/90000 (23%)]	Loss: -10.0058	Cost: 6.18s
Train Epoch: 843 [40960/90000 (45%)]	Loss: -9.3437	Cost: 9.39s
Train Epoch: 843 [61440/90000 (68%)]	Loss: -9.7413	Cost: 10.63s
Train Epoch: 843 [81920/90000 (91%)]	Loss: -9.7865	Cost: 12.05s
Train Epoch: 843 	Average Loss: -9.5150
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1415

Saving model as e843_model.pt & e843_waveforms_supplementary.hdf5
Learning rate: 0.0001999649329272006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 844 [0/90000 (0%)]	Loss: -5.2922	Cost: 62.08s
Train Epoch: 844 [20480/90000 (23%)]	Loss: -9.8159	Cost: 6.27s
Train Epoch: 844 [40960/90000 (45%)]	Loss: -9.3738	Cost: 10.55s
Train Epoch: 844 [61440/90000 (68%)]	Loss: -9.8988	Cost: 11.79s
Train Epoch: 844 [81920/90000 (91%)]	Loss: -9.8333	Cost: 12.17s
Train Epoch: 844 	Average Loss: -9.4482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2369

Saving model as e844_model.pt & e844_waveforms_supplementary.hdf5
Learning rate: 0.00019996484968683035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 845 [0/90000 (0%)]	Loss: -4.9435	Cost: 44.92s
Train Epoch: 845 [20480/90000 (23%)]	Loss: -10.1309	Cost: 6.73s
Train Epoch: 845 [40960/90000 (45%)]	Loss: -9.4587	Cost: 12.53s
Train Epoch: 845 [61440/90000 (68%)]	Loss: -9.9376	Cost: 12.10s
Train Epoch: 845 [81920/90000 (91%)]	Loss: -10.1018	Cost: 11.80s
Train Epoch: 845 	Average Loss: -9.5349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1712

Learning rate: 0.0001999647663477988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 846 [0/90000 (0%)]	Loss: -5.2935	Cost: 31.47s
Train Epoch: 846 [20480/90000 (23%)]	Loss: -10.2155	Cost: 12.23s
Train Epoch: 846 [40960/90000 (45%)]	Loss: -9.4975	Cost: 12.51s
Train Epoch: 846 [61440/90000 (68%)]	Loss: -9.8685	Cost: 12.16s
Train Epoch: 846 [81920/90000 (91%)]	Loss: -9.9259	Cost: 13.03s
Train Epoch: 846 	Average Loss: -9.6428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2260

Learning rate: 0.00019996468291010595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 847 [0/90000 (0%)]	Loss: -5.0790	Cost: 30.89s
Train Epoch: 847 [20480/90000 (23%)]	Loss: -10.0077	Cost: 8.40s
Train Epoch: 847 [40960/90000 (45%)]	Loss: -9.2338	Cost: 12.53s
Train Epoch: 847 [61440/90000 (68%)]	Loss: -9.5392	Cost: 13.60s
Train Epoch: 847 [81920/90000 (91%)]	Loss: -9.5886	Cost: 14.47s
Train Epoch: 847 	Average Loss: -9.3785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0128

Learning rate: 0.00019996459937375192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 848 [0/90000 (0%)]	Loss: -4.7620	Cost: 27.93s
Train Epoch: 848 [20480/90000 (23%)]	Loss: -9.9595	Cost: 8.83s
Train Epoch: 848 [40960/90000 (45%)]	Loss: -9.3408	Cost: 16.49s
Train Epoch: 848 [61440/90000 (68%)]	Loss: -9.2175	Cost: 12.04s
Train Epoch: 848 [81920/90000 (91%)]	Loss: -9.3456	Cost: 16.26s
Train Epoch: 848 	Average Loss: -9.2518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7584

Learning rate: 0.00019996451573873678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 849 [0/90000 (0%)]	Loss: -4.6589	Cost: 27.25s
Train Epoch: 849 [20480/90000 (23%)]	Loss: -9.3941	Cost: 12.62s
Train Epoch: 849 [40960/90000 (45%)]	Loss: -8.9334	Cost: 18.26s
Train Epoch: 849 [61440/90000 (68%)]	Loss: -9.4955	Cost: 15.96s
Train Epoch: 849 [81920/90000 (91%)]	Loss: -9.7122	Cost: 15.49s
Train Epoch: 849 	Average Loss: -9.0762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0949

Learning rate: 0.00019996443200506062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 850 [0/90000 (0%)]	Loss: -5.3785	Cost: 32.58s
Train Epoch: 850 [20480/90000 (23%)]	Loss: -10.1891	Cost: 10.58s
Train Epoch: 850 [40960/90000 (45%)]	Loss: -9.4343	Cost: 18.06s
Train Epoch: 850 [61440/90000 (68%)]	Loss: -9.8789	Cost: 13.34s
Train Epoch: 850 [81920/90000 (91%)]	Loss: -10.1374	Cost: 11.96s
Train Epoch: 850 	Average Loss: -9.5953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2760

Saving model as e850_model.pt & e850_waveforms_supplementary.hdf5
Learning rate: 0.00019996434817272352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 851 [0/90000 (0%)]	Loss: -5.0307	Cost: 30.38s
Train Epoch: 851 [20480/90000 (23%)]	Loss: -10.2370	Cost: 13.97s
Train Epoch: 851 [40960/90000 (45%)]	Loss: -9.7857	Cost: 13.88s
Train Epoch: 851 [61440/90000 (68%)]	Loss: -10.1439	Cost: 14.78s
Train Epoch: 851 [81920/90000 (91%)]	Loss: -10.0644	Cost: 18.88s
Train Epoch: 851 	Average Loss: -9.7020
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3765

Saving model as e851_model.pt & e851_waveforms_supplementary.hdf5
Learning rate: 0.00019996426424172557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 852 [0/90000 (0%)]	Loss: -5.7178	Cost: 29.96s
Train Epoch: 852 [20480/90000 (23%)]	Loss: -10.1671	Cost: 14.81s
Train Epoch: 852 [40960/90000 (45%)]	Loss: -9.7393	Cost: 17.13s
Train Epoch: 852 [61440/90000 (68%)]	Loss: -10.0908	Cost: 15.46s
Train Epoch: 852 [81920/90000 (91%)]	Loss: -10.0703	Cost: 14.49s
Train Epoch: 852 	Average Loss: -9.7200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1476

Learning rate: 0.00019996418021206683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 853 [0/90000 (0%)]	Loss: -4.9082	Cost: 35.98s
Train Epoch: 853 [20480/90000 (23%)]	Loss: -10.2302	Cost: 11.10s
Train Epoch: 853 [40960/90000 (45%)]	Loss: -9.5805	Cost: 15.07s
Train Epoch: 853 [61440/90000 (68%)]	Loss: -10.0567	Cost: 13.97s
Train Epoch: 853 [81920/90000 (91%)]	Loss: -10.0721	Cost: 19.75s
Train Epoch: 853 	Average Loss: -9.7184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3066

Learning rate: 0.00019996409608374742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 854 [0/90000 (0%)]	Loss: -5.3941	Cost: 32.24s
Train Epoch: 854 [20480/90000 (23%)]	Loss: -10.3173	Cost: 14.10s
Train Epoch: 854 [40960/90000 (45%)]	Loss: -9.4193	Cost: 15.61s
Train Epoch: 854 [61440/90000 (68%)]	Loss: -10.0898	Cost: 13.93s
Train Epoch: 854 [81920/90000 (91%)]	Loss: -10.0564	Cost: 16.55s
Train Epoch: 854 	Average Loss: -9.7378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3278

Learning rate: 0.0001999640118567674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 855 [0/90000 (0%)]	Loss: -5.2178	Cost: 28.98s
Train Epoch: 855 [20480/90000 (23%)]	Loss: -10.2294	Cost: 14.71s
Train Epoch: 855 [40960/90000 (45%)]	Loss: -9.3902	Cost: 15.57s
Train Epoch: 855 [61440/90000 (68%)]	Loss: -9.8516	Cost: 15.48s
Train Epoch: 855 [81920/90000 (91%)]	Loss: -9.8540	Cost: 13.83s
Train Epoch: 855 	Average Loss: -9.5941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3576

Learning rate: 0.00019996392753112682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 856 [0/90000 (0%)]	Loss: -4.8859	Cost: 27.96s
Train Epoch: 856 [20480/90000 (23%)]	Loss: -10.2852	Cost: 9.57s
Train Epoch: 856 [40960/90000 (45%)]	Loss: -9.6683	Cost: 14.24s
Train Epoch: 856 [61440/90000 (68%)]	Loss: -10.1444	Cost: 14.10s
Train Epoch: 856 [81920/90000 (91%)]	Loss: -10.0017	Cost: 17.47s
Train Epoch: 856 	Average Loss: -9.6869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2638

Learning rate: 0.00019996384310682583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 857 [0/90000 (0%)]	Loss: -4.8629	Cost: 29.76s
Train Epoch: 857 [20480/90000 (23%)]	Loss: -10.0912	Cost: 7.31s
Train Epoch: 857 [40960/90000 (45%)]	Loss: -9.5421	Cost: 18.17s
Train Epoch: 857 [61440/90000 (68%)]	Loss: -10.0510	Cost: 13.75s
Train Epoch: 857 [81920/90000 (91%)]	Loss: -10.0289	Cost: 18.22s
Train Epoch: 857 	Average Loss: -9.7005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2594

Learning rate: 0.00019996375858386448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 858 [0/90000 (0%)]	Loss: -5.0063	Cost: 29.28s
Train Epoch: 858 [20480/90000 (23%)]	Loss: -10.2612	Cost: 12.63s
Train Epoch: 858 [40960/90000 (45%)]	Loss: -9.5747	Cost: 14.37s
Train Epoch: 858 [61440/90000 (68%)]	Loss: -10.1375	Cost: 14.38s
Train Epoch: 858 [81920/90000 (91%)]	Loss: -10.3802	Cost: 14.61s
Train Epoch: 858 	Average Loss: -9.7598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5674

Saving model as e858_model.pt & e858_waveforms_supplementary.hdf5
Learning rate: 0.00019996367396224286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 859 [0/90000 (0%)]	Loss: -5.2115	Cost: 28.26s
Train Epoch: 859 [20480/90000 (23%)]	Loss: -10.4780	Cost: 10.00s
Train Epoch: 859 [40960/90000 (45%)]	Loss: -9.6345	Cost: 17.36s
Train Epoch: 859 [61440/90000 (68%)]	Loss: -10.1515	Cost: 13.80s
Train Epoch: 859 [81920/90000 (91%)]	Loss: -10.1608	Cost: 19.21s
Train Epoch: 859 	Average Loss: -9.8118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4612

Learning rate: 0.00019996358924196105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 860 [0/90000 (0%)]	Loss: -4.8444	Cost: 28.41s
Train Epoch: 860 [20480/90000 (23%)]	Loss: -10.5130	Cost: 13.16s
Train Epoch: 860 [40960/90000 (45%)]	Loss: -9.7285	Cost: 17.72s
Train Epoch: 860 [61440/90000 (68%)]	Loss: -10.1759	Cost: 16.17s
Train Epoch: 860 [81920/90000 (91%)]	Loss: -9.9791	Cost: 15.03s
Train Epoch: 860 	Average Loss: -9.7285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2515

Learning rate: 0.0001999635044230191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 861 [0/90000 (0%)]	Loss: -5.3379	Cost: 33.30s
Train Epoch: 861 [20480/90000 (23%)]	Loss: -9.9005	Cost: 14.18s
Train Epoch: 861 [40960/90000 (45%)]	Loss: -9.2248	Cost: 15.01s
Train Epoch: 861 [61440/90000 (68%)]	Loss: -9.8539	Cost: 15.78s
Train Epoch: 861 [81920/90000 (91%)]	Loss: -9.7776	Cost: 14.30s
Train Epoch: 861 	Average Loss: -9.4074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1805

Learning rate: 0.00019996341950541716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 862 [0/90000 (0%)]	Loss: -4.7859	Cost: 32.26s
Train Epoch: 862 [20480/90000 (23%)]	Loss: -9.9009	Cost: 13.82s
Train Epoch: 862 [40960/90000 (45%)]	Loss: -9.5580	Cost: 14.32s
Train Epoch: 862 [61440/90000 (68%)]	Loss: -10.1205	Cost: 14.46s
Train Epoch: 862 [81920/90000 (91%)]	Loss: -10.1075	Cost: 11.84s
Train Epoch: 862 	Average Loss: -9.5635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5175

Learning rate: 0.00019996333448915526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 863 [0/90000 (0%)]	Loss: -5.2399	Cost: 30.44s
Train Epoch: 863 [20480/90000 (23%)]	Loss: -10.3496	Cost: 15.09s
Train Epoch: 863 [40960/90000 (45%)]	Loss: -9.8980	Cost: 21.56s
Train Epoch: 863 [61440/90000 (68%)]	Loss: -10.3471	Cost: 15.18s
Train Epoch: 863 [81920/90000 (91%)]	Loss: -10.4782	Cost: 16.07s
Train Epoch: 863 	Average Loss: -9.9905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5623

Learning rate: 0.0001999632493742335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 864 [0/90000 (0%)]	Loss: -6.1857	Cost: 30.20s
Train Epoch: 864 [20480/90000 (23%)]	Loss: -10.1685	Cost: 13.06s
Train Epoch: 864 [40960/90000 (45%)]	Loss: -9.8176	Cost: 14.80s
Train Epoch: 864 [61440/90000 (68%)]	Loss: -10.2471	Cost: 14.40s
Train Epoch: 864 [81920/90000 (91%)]	Loss: -10.3757	Cost: 14.67s
Train Epoch: 864 	Average Loss: -9.8788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4098

Learning rate: 0.00019996316416065197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 865 [0/90000 (0%)]	Loss: -5.4750	Cost: 40.73s
Train Epoch: 865 [20480/90000 (23%)]	Loss: -10.3303	Cost: 11.70s
Train Epoch: 865 [40960/90000 (45%)]	Loss: -9.4122	Cost: 17.05s
Train Epoch: 865 [61440/90000 (68%)]	Loss: -10.0346	Cost: 14.18s
Train Epoch: 865 [81920/90000 (91%)]	Loss: -10.1342	Cost: 10.40s
Train Epoch: 865 	Average Loss: -9.6997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3436

Learning rate: 0.00019996307884841076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 866 [0/90000 (0%)]	Loss: -4.6344	Cost: 28.73s
Train Epoch: 866 [20480/90000 (23%)]	Loss: -10.3292	Cost: 13.61s
Train Epoch: 866 [40960/90000 (45%)]	Loss: -9.8654	Cost: 16.59s
Train Epoch: 866 [61440/90000 (68%)]	Loss: -10.2061	Cost: 15.35s
Train Epoch: 866 [81920/90000 (91%)]	Loss: -10.3361	Cost: 18.31s
Train Epoch: 866 	Average Loss: -9.8492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5089

Learning rate: 0.00019996299343750997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 867 [0/90000 (0%)]	Loss: -4.6990	Cost: 28.11s
Train Epoch: 867 [20480/90000 (23%)]	Loss: -10.3022	Cost: 11.87s
Train Epoch: 867 [40960/90000 (45%)]	Loss: -10.0131	Cost: 15.74s
Train Epoch: 867 [61440/90000 (68%)]	Loss: -10.2544	Cost: 14.61s
Train Epoch: 867 [81920/90000 (91%)]	Loss: -10.2130	Cost: 16.99s
Train Epoch: 867 	Average Loss: -9.9260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5110

Learning rate: 0.00019996290792794963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 868 [0/90000 (0%)]	Loss: -4.9794	Cost: 36.59s
Train Epoch: 868 [20480/90000 (23%)]	Loss: -10.4714	Cost: 14.74s
Train Epoch: 868 [40960/90000 (45%)]	Loss: -9.3964	Cost: 14.46s
Train Epoch: 868 [61440/90000 (68%)]	Loss: -9.6330	Cost: 14.95s
Train Epoch: 868 [81920/90000 (91%)]	Loss: -10.0417	Cost: 13.57s
Train Epoch: 868 	Average Loss: -9.6158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3876

Learning rate: 0.00019996282231972984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 869 [0/90000 (0%)]	Loss: -5.8613	Cost: 28.66s
Train Epoch: 869 [20480/90000 (23%)]	Loss: -10.3669	Cost: 13.52s
Train Epoch: 869 [40960/90000 (45%)]	Loss: -10.0319	Cost: 16.08s
Train Epoch: 869 [61440/90000 (68%)]	Loss: -10.3922	Cost: 14.45s
Train Epoch: 869 [81920/90000 (91%)]	Loss: -10.4269	Cost: 20.45s
Train Epoch: 869 	Average Loss: -10.0119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6927

Saving model as e869_model.pt & e869_waveforms_supplementary.hdf5
Learning rate: 0.00019996273661285075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 870 [0/90000 (0%)]	Loss: -4.9723	Cost: 29.22s
Train Epoch: 870 [20480/90000 (23%)]	Loss: -10.4865	Cost: 12.45s
Train Epoch: 870 [40960/90000 (45%)]	Loss: -9.8267	Cost: 15.21s
Train Epoch: 870 [61440/90000 (68%)]	Loss: -10.3336	Cost: 14.29s
Train Epoch: 870 [81920/90000 (91%)]	Loss: -10.2521	Cost: 14.80s
Train Epoch: 870 	Average Loss: -9.9515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7953

Saving model as e870_model.pt & e870_waveforms_supplementary.hdf5
Learning rate: 0.00019996265080731235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 871 [0/90000 (0%)]	Loss: -4.9554	Cost: 38.25s
Train Epoch: 871 [20480/90000 (23%)]	Loss: -10.6028	Cost: 12.33s
Train Epoch: 871 [40960/90000 (45%)]	Loss: -10.0975	Cost: 16.83s
Train Epoch: 871 [61440/90000 (68%)]	Loss: -10.3737	Cost: 12.44s
Train Epoch: 871 [81920/90000 (91%)]	Loss: -10.3850	Cost: 9.49s
Train Epoch: 871 	Average Loss: -10.0562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6409

Learning rate: 0.00019996256490311477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 872 [0/90000 (0%)]	Loss: -5.2443	Cost: 31.25s
Train Epoch: 872 [20480/90000 (23%)]	Loss: -10.3269	Cost: 14.51s
Train Epoch: 872 [40960/90000 (45%)]	Loss: -9.4290	Cost: 14.86s
Train Epoch: 872 [61440/90000 (68%)]	Loss: -10.0299	Cost: 12.53s
Train Epoch: 872 [81920/90000 (91%)]	Loss: -10.3540	Cost: 11.66s
Train Epoch: 872 	Average Loss: -9.7930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6832

Learning rate: 0.00019996247890025813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 873 [0/90000 (0%)]	Loss: -5.6836	Cost: 29.71s
Train Epoch: 873 [20480/90000 (23%)]	Loss: -10.6328	Cost: 14.30s
Train Epoch: 873 [40960/90000 (45%)]	Loss: -9.5285	Cost: 14.24s
Train Epoch: 873 [61440/90000 (68%)]	Loss: -9.8876	Cost: 12.90s
Train Epoch: 873 [81920/90000 (91%)]	Loss: -9.8672	Cost: 14.50s
Train Epoch: 873 	Average Loss: -9.7711
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3058

Learning rate: 0.00019996239279874246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 874 [0/90000 (0%)]	Loss: -5.4104	Cost: 28.72s
Train Epoch: 874 [20480/90000 (23%)]	Loss: -10.4180	Cost: 12.11s
Train Epoch: 874 [40960/90000 (45%)]	Loss: -9.9055	Cost: 16.72s
Train Epoch: 874 [61440/90000 (68%)]	Loss: -10.2739	Cost: 12.45s
Train Epoch: 874 [81920/90000 (91%)]	Loss: -10.2042	Cost: 14.78s
Train Epoch: 874 	Average Loss: -9.8652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4213

Learning rate: 0.00019996230659856786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 875 [0/90000 (0%)]	Loss: -5.4174	Cost: 28.99s
Train Epoch: 875 [20480/90000 (23%)]	Loss: -10.6351	Cost: 9.21s
Train Epoch: 875 [40960/90000 (45%)]	Loss: -10.0314	Cost: 19.60s
Train Epoch: 875 [61440/90000 (68%)]	Loss: -10.0989	Cost: 11.91s
Train Epoch: 875 [81920/90000 (91%)]	Loss: -9.7886	Cost: 12.58s
Train Epoch: 875 	Average Loss: -9.8490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0464

Learning rate: 0.0001999622202997344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 876 [0/90000 (0%)]	Loss: -3.8839	Cost: 27.14s
Train Epoch: 876 [20480/90000 (23%)]	Loss: -10.1576	Cost: 10.19s
Train Epoch: 876 [40960/90000 (45%)]	Loss: -9.3655	Cost: 18.98s
Train Epoch: 876 [61440/90000 (68%)]	Loss: -9.6324	Cost: 14.47s
Train Epoch: 876 [81920/90000 (91%)]	Loss: -10.1145	Cost: 17.11s
Train Epoch: 876 	Average Loss: -9.4734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4106

Learning rate: 0.0001999621339022422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 877 [0/90000 (0%)]	Loss: -5.5899	Cost: 30.95s
Train Epoch: 877 [20480/90000 (23%)]	Loss: -10.4463	Cost: 14.82s
Train Epoch: 877 [40960/90000 (45%)]	Loss: -9.9608	Cost: 14.45s
Train Epoch: 877 [61440/90000 (68%)]	Loss: -10.2063	Cost: 14.66s
Train Epoch: 877 [81920/90000 (91%)]	Loss: -10.4312	Cost: 18.61s
Train Epoch: 877 	Average Loss: -9.9717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5116

Learning rate: 0.00019996204740609135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 878 [0/90000 (0%)]	Loss: -5.4283	Cost: 30.87s
Train Epoch: 878 [20480/90000 (23%)]	Loss: -10.2549	Cost: 14.91s
Train Epoch: 878 [40960/90000 (45%)]	Loss: -9.4959	Cost: 18.22s
Train Epoch: 878 [61440/90000 (68%)]	Loss: -10.1535	Cost: 13.98s
Train Epoch: 878 [81920/90000 (91%)]	Loss: -10.5476	Cost: 17.87s
Train Epoch: 878 	Average Loss: -9.8622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8411

Saving model as e878_model.pt & e878_waveforms_supplementary.hdf5
Learning rate: 0.0001999619608112819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 879 [0/90000 (0%)]	Loss: -5.5999	Cost: 27.05s
Train Epoch: 879 [20480/90000 (23%)]	Loss: -10.6013	Cost: 10.29s
Train Epoch: 879 [40960/90000 (45%)]	Loss: -10.0502	Cost: 20.07s
Train Epoch: 879 [61440/90000 (68%)]	Loss: -10.6334	Cost: 14.45s
Train Epoch: 879 [81920/90000 (91%)]	Loss: -10.7204	Cost: 18.68s
Train Epoch: 879 	Average Loss: -10.1866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8002

Learning rate: 0.00019996187411781396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 880 [0/90000 (0%)]	Loss: -5.6618	Cost: 31.90s
Train Epoch: 880 [20480/90000 (23%)]	Loss: -10.8247	Cost: 15.10s
Train Epoch: 880 [40960/90000 (45%)]	Loss: -10.2580	Cost: 14.83s
Train Epoch: 880 [61440/90000 (68%)]	Loss: -10.8102	Cost: 15.81s
Train Epoch: 880 [81920/90000 (91%)]	Loss: -10.7033	Cost: 13.96s
Train Epoch: 880 	Average Loss: -10.3375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7537

Learning rate: 0.00019996178732568757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 881 [0/90000 (0%)]	Loss: -5.8245	Cost: 29.18s
Train Epoch: 881 [20480/90000 (23%)]	Loss: -10.6641	Cost: 14.51s
Train Epoch: 881 [40960/90000 (45%)]	Loss: -10.2499	Cost: 14.93s
Train Epoch: 881 [61440/90000 (68%)]	Loss: -10.7942	Cost: 14.52s
Train Epoch: 881 [81920/90000 (91%)]	Loss: -10.9803	Cost: 13.82s
Train Epoch: 881 	Average Loss: -10.3445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7825

Learning rate: 0.00019996170043490283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 882 [0/90000 (0%)]	Loss: -5.0542	Cost: 29.57s
Train Epoch: 882 [20480/90000 (23%)]	Loss: -10.8220	Cost: 11.93s
Train Epoch: 882 [40960/90000 (45%)]	Loss: -10.2936	Cost: 17.29s
Train Epoch: 882 [61440/90000 (68%)]	Loss: -10.6022	Cost: 13.81s
Train Epoch: 882 [81920/90000 (91%)]	Loss: -10.6718	Cost: 16.60s
Train Epoch: 882 	Average Loss: -10.2626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8365

Learning rate: 0.00019996161344545987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 883 [0/90000 (0%)]	Loss: -5.1622	Cost: 29.37s
Train Epoch: 883 [20480/90000 (23%)]	Loss: -10.7305	Cost: 15.54s
Train Epoch: 883 [40960/90000 (45%)]	Loss: -10.2661	Cost: 17.94s
Train Epoch: 883 [61440/90000 (68%)]	Loss: -10.6426	Cost: 15.21s
Train Epoch: 883 [81920/90000 (91%)]	Loss: -10.5503	Cost: 15.89s
Train Epoch: 883 	Average Loss: -10.2684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6693

Learning rate: 0.0001999615263573588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 884 [0/90000 (0%)]	Loss: -5.9486	Cost: 37.53s
Train Epoch: 884 [20480/90000 (23%)]	Loss: -10.7018	Cost: 12.10s
Train Epoch: 884 [40960/90000 (45%)]	Loss: -10.4271	Cost: 15.54s
Train Epoch: 884 [61440/90000 (68%)]	Loss: -10.8678	Cost: 14.96s
Train Epoch: 884 [81920/90000 (91%)]	Loss: -10.7506	Cost: 11.60s
Train Epoch: 884 	Average Loss: -10.3700
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9030

Saving model as e884_model.pt & e884_waveforms_supplementary.hdf5
Learning rate: 0.0001999614391705996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 885 [0/90000 (0%)]	Loss: -5.3815	Cost: 39.02s
Train Epoch: 885 [20480/90000 (23%)]	Loss: -10.8059	Cost: 14.08s
Train Epoch: 885 [40960/90000 (45%)]	Loss: -10.2836	Cost: 15.88s
Train Epoch: 885 [61440/90000 (68%)]	Loss: -10.6602	Cost: 13.88s
Train Epoch: 885 [81920/90000 (91%)]	Loss: -10.8371	Cost: 11.15s
Train Epoch: 885 	Average Loss: -10.3483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9163

Saving model as e885_model.pt & e885_waveforms_supplementary.hdf5
Learning rate: 0.00019996135188518242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 886 [0/90000 (0%)]	Loss: -5.3271	Cost: 32.96s
Train Epoch: 886 [20480/90000 (23%)]	Loss: -10.6718	Cost: 13.19s
Train Epoch: 886 [40960/90000 (45%)]	Loss: -10.1967	Cost: 17.10s
Train Epoch: 886 [61440/90000 (68%)]	Loss: -10.7843	Cost: 12.54s
Train Epoch: 886 [81920/90000 (91%)]	Loss: -10.6232	Cost: 12.68s
Train Epoch: 886 	Average Loss: -10.2725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7029

Learning rate: 0.00019996126450110731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 887 [0/90000 (0%)]	Loss: -5.9419	Cost: 32.02s
Train Epoch: 887 [20480/90000 (23%)]	Loss: -10.5489	Cost: 13.60s
Train Epoch: 887 [40960/90000 (45%)]	Loss: -9.8821	Cost: 14.60s
Train Epoch: 887 [61440/90000 (68%)]	Loss: -10.5383	Cost: 14.69s
Train Epoch: 887 [81920/90000 (91%)]	Loss: -10.4588	Cost: 14.46s
Train Epoch: 887 	Average Loss: -10.0940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7688

Learning rate: 0.00019996117701837445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 888 [0/90000 (0%)]	Loss: -5.6513	Cost: 27.81s
Train Epoch: 888 [20480/90000 (23%)]	Loss: -10.7146	Cost: 13.27s
Train Epoch: 888 [40960/90000 (45%)]	Loss: -10.4268	Cost: 18.08s
Train Epoch: 888 [61440/90000 (68%)]	Loss: -10.8785	Cost: 15.33s
Train Epoch: 888 [81920/90000 (91%)]	Loss: -10.7914	Cost: 15.78s
Train Epoch: 888 	Average Loss: -10.4040
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0822

Saving model as e888_model.pt & e888_waveforms_supplementary.hdf5
Learning rate: 0.00019996108943698385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 889 [0/90000 (0%)]	Loss: -5.2490	Cost: 27.12s
Train Epoch: 889 [20480/90000 (23%)]	Loss: -11.1171	Cost: 12.09s
Train Epoch: 889 [40960/90000 (45%)]	Loss: -10.4559	Cost: 16.20s
Train Epoch: 889 [61440/90000 (68%)]	Loss: -10.8280	Cost: 15.09s
Train Epoch: 889 [81920/90000 (91%)]	Loss: -11.0247	Cost: 23.01s
Train Epoch: 889 	Average Loss: -10.5018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9155

Learning rate: 0.0001999610017569356
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 890 [0/90000 (0%)]	Loss: -5.3808	Cost: 34.84s
Train Epoch: 890 [20480/90000 (23%)]	Loss: -10.8714	Cost: 14.75s
Train Epoch: 890 [40960/90000 (45%)]	Loss: -8.6801	Cost: 15.42s
Train Epoch: 890 [61440/90000 (68%)]	Loss: -9.2434	Cost: 14.90s
Train Epoch: 890 [81920/90000 (91%)]	Loss: -9.9481	Cost: 15.64s
Train Epoch: 890 	Average Loss: -9.6159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4031

Learning rate: 0.0001999609139782298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 891 [0/90000 (0%)]	Loss: -5.0949	Cost: 28.19s
Train Epoch: 891 [20480/90000 (23%)]	Loss: -10.3415	Cost: 13.88s
Train Epoch: 891 [40960/90000 (45%)]	Loss: -9.9942	Cost: 15.92s
Train Epoch: 891 [61440/90000 (68%)]	Loss: -10.5498	Cost: 14.70s
Train Epoch: 891 [81920/90000 (91%)]	Loss: -10.6336	Cost: 12.72s
Train Epoch: 891 	Average Loss: -10.0008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8600

Learning rate: 0.0001999608261008665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 892 [0/90000 (0%)]	Loss: -6.1876	Cost: 29.18s
Train Epoch: 892 [20480/90000 (23%)]	Loss: -10.4906	Cost: 11.19s
Train Epoch: 892 [40960/90000 (45%)]	Loss: -9.7027	Cost: 15.21s
Train Epoch: 892 [61440/90000 (68%)]	Loss: -9.7554	Cost: 14.81s
Train Epoch: 892 [81920/90000 (91%)]	Loss: -10.0810	Cost: 15.13s
Train Epoch: 892 	Average Loss: -9.8508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5472

Learning rate: 0.00019996073812484586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 893 [0/90000 (0%)]	Loss: -5.1391	Cost: 31.00s
Train Epoch: 893 [20480/90000 (23%)]	Loss: -10.5543	Cost: 6.41s
Train Epoch: 893 [40960/90000 (45%)]	Loss: -10.2716	Cost: 14.31s
Train Epoch: 893 [61440/90000 (68%)]	Loss: -10.7507	Cost: 14.66s
Train Epoch: 893 [81920/90000 (91%)]	Loss: -10.7381	Cost: 14.75s
Train Epoch: 893 	Average Loss: -10.1914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8295

Learning rate: 0.0001999606500501679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 894 [0/90000 (0%)]	Loss: -6.0017	Cost: 28.53s
Train Epoch: 894 [20480/90000 (23%)]	Loss: -10.6491	Cost: 6.73s
Train Epoch: 894 [40960/90000 (45%)]	Loss: -10.2350	Cost: 14.61s
Train Epoch: 894 [61440/90000 (68%)]	Loss: -10.5474	Cost: 14.19s
Train Epoch: 894 [81920/90000 (91%)]	Loss: -10.9480	Cost: 12.37s
Train Epoch: 894 	Average Loss: -10.3560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8989

Learning rate: 0.00019996056187683277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 895 [0/90000 (0%)]	Loss: -6.1504	Cost: 25.79s
Train Epoch: 895 [20480/90000 (23%)]	Loss: -9.6489	Cost: 7.22s
Train Epoch: 895 [40960/90000 (45%)]	Loss: -9.2657	Cost: 14.36s
Train Epoch: 895 [61440/90000 (68%)]	Loss: -9.9445	Cost: 14.25s
Train Epoch: 895 [81920/90000 (91%)]	Loss: -10.2922	Cost: 12.46s
Train Epoch: 895 	Average Loss: -9.4452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4470

Learning rate: 0.0001999604736048405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 896 [0/90000 (0%)]	Loss: -5.4128	Cost: 28.58s
Train Epoch: 896 [20480/90000 (23%)]	Loss: -10.6874	Cost: 6.33s
Train Epoch: 896 [40960/90000 (45%)]	Loss: -10.0728	Cost: 13.83s
Train Epoch: 896 [61440/90000 (68%)]	Loss: -10.7721	Cost: 13.28s
Train Epoch: 896 [81920/90000 (91%)]	Loss: -10.8230	Cost: 12.37s
Train Epoch: 896 	Average Loss: -10.2746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0490

Learning rate: 0.00019996038523419118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 897 [0/90000 (0%)]	Loss: -5.5915	Cost: 28.03s
Train Epoch: 897 [20480/90000 (23%)]	Loss: -11.0054	Cost: 6.17s
Train Epoch: 897 [40960/90000 (45%)]	Loss: -10.3704	Cost: 14.18s
Train Epoch: 897 [61440/90000 (68%)]	Loss: -10.8713	Cost: 12.77s
Train Epoch: 897 [81920/90000 (91%)]	Loss: -10.8272	Cost: 12.48s
Train Epoch: 897 	Average Loss: -10.4663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1036

Saving model as e897_model.pt & e897_waveforms_supplementary.hdf5
Learning rate: 0.0001999602967648849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 898 [0/90000 (0%)]	Loss: -5.0520	Cost: 30.00s
Train Epoch: 898 [20480/90000 (23%)]	Loss: -10.9731	Cost: 12.42s
Train Epoch: 898 [40960/90000 (45%)]	Loss: -10.5977	Cost: 14.23s
Train Epoch: 898 [61440/90000 (68%)]	Loss: -11.1960	Cost: 12.91s
Train Epoch: 898 [81920/90000 (91%)]	Loss: -10.9330	Cost: 12.54s
Train Epoch: 898 	Average Loss: -10.6054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9779

Learning rate: 0.0001999602081969218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 899 [0/90000 (0%)]	Loss: -5.8177	Cost: 29.04s
Train Epoch: 899 [20480/90000 (23%)]	Loss: -11.1899	Cost: 12.15s
Train Epoch: 899 [40960/90000 (45%)]	Loss: -10.5442	Cost: 14.98s
Train Epoch: 899 [61440/90000 (68%)]	Loss: -9.6884	Cost: 14.25s
Train Epoch: 899 [81920/90000 (91%)]	Loss: -9.9678	Cost: 14.96s
Train Epoch: 899 	Average Loss: -9.9777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3009

Learning rate: 0.00019996011953030192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 900 [0/90000 (0%)]	Loss: -5.7356	Cost: 28.26s
Train Epoch: 900 [20480/90000 (23%)]	Loss: -10.3696	Cost: 7.66s
Train Epoch: 900 [40960/90000 (45%)]	Loss: -10.1957	Cost: 15.43s
Train Epoch: 900 [61440/90000 (68%)]	Loss: -10.7325	Cost: 14.14s
Train Epoch: 900 [81920/90000 (91%)]	Loss: -10.7935	Cost: 14.83s
Train Epoch: 900 	Average Loss: -10.1558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1094

Saving model as e900_model.pt & e900_waveforms_supplementary.hdf5
Learning rate: 0.00019996003076502535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 901 [0/90000 (0%)]	Loss: -6.0672	Cost: 31.12s
Train Epoch: 901 [20480/90000 (23%)]	Loss: -11.1276	Cost: 10.65s
Train Epoch: 901 [40960/90000 (45%)]	Loss: -10.7559	Cost: 14.33s
Train Epoch: 901 [61440/90000 (68%)]	Loss: -11.1540	Cost: 14.57s
Train Epoch: 901 [81920/90000 (91%)]	Loss: -11.0755	Cost: 15.16s
Train Epoch: 901 	Average Loss: -10.6533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1887

Saving model as e901_model.pt & e901_waveforms_supplementary.hdf5
Learning rate: 0.0001999599419010922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 902 [0/90000 (0%)]	Loss: -5.7090	Cost: 31.38s
Train Epoch: 902 [20480/90000 (23%)]	Loss: -11.3238	Cost: 13.71s
Train Epoch: 902 [40960/90000 (45%)]	Loss: -10.4680	Cost: 13.00s
Train Epoch: 902 [61440/90000 (68%)]	Loss: -10.7560	Cost: 15.06s
Train Epoch: 902 [81920/90000 (91%)]	Loss: -10.8869	Cost: 13.39s
Train Epoch: 902 	Average Loss: -10.5328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0068

Learning rate: 0.00019995985293850256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 903 [0/90000 (0%)]	Loss: -5.6192	Cost: 28.25s
Train Epoch: 903 [20480/90000 (23%)]	Loss: -11.0164	Cost: 12.25s
Train Epoch: 903 [40960/90000 (45%)]	Loss: -10.6375	Cost: 14.49s
Train Epoch: 903 [61440/90000 (68%)]	Loss: -10.9230	Cost: 14.01s
Train Epoch: 903 [81920/90000 (91%)]	Loss: -10.8901	Cost: 13.37s
Train Epoch: 903 	Average Loss: -10.5608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9970

Learning rate: 0.00019995976387725647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 904 [0/90000 (0%)]	Loss: -5.5850	Cost: 30.50s
Train Epoch: 904 [20480/90000 (23%)]	Loss: -11.0085	Cost: 11.34s
Train Epoch: 904 [40960/90000 (45%)]	Loss: -10.5323	Cost: 15.87s
Train Epoch: 904 [61440/90000 (68%)]	Loss: -11.1214	Cost: 14.11s
Train Epoch: 904 [81920/90000 (91%)]	Loss: -11.1610	Cost: 12.13s
Train Epoch: 904 	Average Loss: -10.5525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2615

Saving model as e904_model.pt & e904_waveforms_supplementary.hdf5
Learning rate: 0.00019995967471735402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 905 [0/90000 (0%)]	Loss: -6.1231	Cost: 28.35s
Train Epoch: 905 [20480/90000 (23%)]	Loss: -11.3215	Cost: 13.14s
Train Epoch: 905 [40960/90000 (45%)]	Loss: -10.6467	Cost: 17.45s
Train Epoch: 905 [61440/90000 (68%)]	Loss: -11.1671	Cost: 13.80s
Train Epoch: 905 [81920/90000 (91%)]	Loss: -11.0517	Cost: 16.15s
Train Epoch: 905 	Average Loss: -10.7212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0538

Learning rate: 0.00019995958545879536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 906 [0/90000 (0%)]	Loss: -6.2696	Cost: 29.21s
Train Epoch: 906 [20480/90000 (23%)]	Loss: -10.9807	Cost: 12.85s
Train Epoch: 906 [40960/90000 (45%)]	Loss: -10.4049	Cost: 17.61s
Train Epoch: 906 [61440/90000 (68%)]	Loss: -10.9332	Cost: 14.67s
Train Epoch: 906 [81920/90000 (91%)]	Loss: -10.9614	Cost: 16.71s
Train Epoch: 906 	Average Loss: -10.4873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0766

Learning rate: 0.00019995949610158054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 907 [0/90000 (0%)]	Loss: -5.8693	Cost: 27.96s
Train Epoch: 907 [20480/90000 (23%)]	Loss: -11.1345	Cost: 10.74s
Train Epoch: 907 [40960/90000 (45%)]	Loss: -10.5231	Cost: 18.61s
Train Epoch: 907 [61440/90000 (68%)]	Loss: -11.1512	Cost: 15.29s
Train Epoch: 907 [81920/90000 (91%)]	Loss: -11.0886	Cost: 20.14s
Train Epoch: 907 	Average Loss: -10.7178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2469

Learning rate: 0.00019995940664570966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 908 [0/90000 (0%)]	Loss: -6.3247	Cost: 28.51s
Train Epoch: 908 [20480/90000 (23%)]	Loss: -11.3311	Cost: 13.15s
Train Epoch: 908 [40960/90000 (45%)]	Loss: -10.8759	Cost: 15.09s
Train Epoch: 908 [61440/90000 (68%)]	Loss: -11.1948	Cost: 14.64s
Train Epoch: 908 [81920/90000 (91%)]	Loss: -11.3555	Cost: 17.67s
Train Epoch: 908 	Average Loss: -10.8134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3549

Saving model as e908_model.pt & e908_waveforms_supplementary.hdf5
Learning rate: 0.00019995931709118278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 909 [0/90000 (0%)]	Loss: -5.7643	Cost: 28.97s
Train Epoch: 909 [20480/90000 (23%)]	Loss: -11.3805	Cost: 12.95s
Train Epoch: 909 [40960/90000 (45%)]	Loss: -10.9610	Cost: 14.47s
Train Epoch: 909 [61440/90000 (68%)]	Loss: -11.3431	Cost: 14.70s
Train Epoch: 909 [81920/90000 (91%)]	Loss: -11.2988	Cost: 17.69s
Train Epoch: 909 	Average Loss: -10.8447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2275

Learning rate: 0.00019995922743800003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 910 [0/90000 (0%)]	Loss: -6.0279	Cost: 28.18s
Train Epoch: 910 [20480/90000 (23%)]	Loss: -11.4896	Cost: 11.14s
Train Epoch: 910 [40960/90000 (45%)]	Loss: -10.6422	Cost: 14.38s
Train Epoch: 910 [61440/90000 (68%)]	Loss: -8.8391	Cost: 14.30s
Train Epoch: 910 [81920/90000 (91%)]	Loss: -9.3480	Cost: 15.66s
Train Epoch: 910 	Average Loss: -9.9618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9153

Learning rate: 0.00019995913768616145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 911 [0/90000 (0%)]	Loss: -4.2961	Cost: 35.75s
Train Epoch: 911 [20480/90000 (23%)]	Loss: -10.2017	Cost: 14.42s
Train Epoch: 911 [40960/90000 (45%)]	Loss: -9.4433	Cost: 13.81s
Train Epoch: 911 [61440/90000 (68%)]	Loss: -10.3712	Cost: 14.17s
Train Epoch: 911 [81920/90000 (91%)]	Loss: -10.3304	Cost: 13.02s
Train Epoch: 911 	Average Loss: -9.6740
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6552

Learning rate: 0.00019995904783566716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 912 [0/90000 (0%)]	Loss: -5.2795	Cost: 34.42s
Train Epoch: 912 [20480/90000 (23%)]	Loss: -10.8354	Cost: 14.36s
Train Epoch: 912 [40960/90000 (45%)]	Loss: -10.3175	Cost: 21.62s
Train Epoch: 912 [61440/90000 (68%)]	Loss: -10.7460	Cost: 12.30s
Train Epoch: 912 [81920/90000 (91%)]	Loss: -10.6330	Cost: 10.18s
Train Epoch: 912 	Average Loss: -10.3947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7649

Learning rate: 0.00019995895788651726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 913 [0/90000 (0%)]	Loss: -4.9303	Cost: 33.16s
Train Epoch: 913 [20480/90000 (23%)]	Loss: -10.8758	Cost: 14.88s
Train Epoch: 913 [40960/90000 (45%)]	Loss: -10.3635	Cost: 14.63s
Train Epoch: 913 [61440/90000 (68%)]	Loss: -10.8284	Cost: 14.47s
Train Epoch: 913 [81920/90000 (91%)]	Loss: -10.7311	Cost: 14.81s
Train Epoch: 913 	Average Loss: -10.3976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9102

Learning rate: 0.00019995886783871183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 914 [0/90000 (0%)]	Loss: -5.4432	Cost: 30.64s
Train Epoch: 914 [20480/90000 (23%)]	Loss: -11.1430	Cost: 15.28s
Train Epoch: 914 [40960/90000 (45%)]	Loss: -10.5089	Cost: 13.53s
Train Epoch: 914 [61440/90000 (68%)]	Loss: -10.9933	Cost: 15.16s
Train Epoch: 914 [81920/90000 (91%)]	Loss: -11.1193	Cost: 20.51s
Train Epoch: 914 	Average Loss: -10.6184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2760

Learning rate: 0.00019995877769225096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 915 [0/90000 (0%)]	Loss: -5.4807	Cost: 27.22s
Train Epoch: 915 [20480/90000 (23%)]	Loss: -10.9446	Cost: 9.57s
Train Epoch: 915 [40960/90000 (45%)]	Loss: -9.7510	Cost: 17.98s
Train Epoch: 915 [61440/90000 (68%)]	Loss: -10.1489	Cost: 14.57s
Train Epoch: 915 [81920/90000 (91%)]	Loss: -10.3609	Cost: 15.01s
Train Epoch: 915 	Average Loss: -10.1152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7780

Learning rate: 0.0001999586874471347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 916 [0/90000 (0%)]	Loss: -5.3780	Cost: 29.21s
Train Epoch: 916 [20480/90000 (23%)]	Loss: -11.1733	Cost: 11.71s
Train Epoch: 916 [40960/90000 (45%)]	Loss: -10.1171	Cost: 17.87s
Train Epoch: 916 [61440/90000 (68%)]	Loss: -10.6018	Cost: 14.05s
Train Epoch: 916 [81920/90000 (91%)]	Loss: -11.0427	Cost: 20.98s
Train Epoch: 916 	Average Loss: -10.3590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9844

Learning rate: 0.00019995859710336317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 917 [0/90000 (0%)]	Loss: -6.0081	Cost: 28.16s
Train Epoch: 917 [20480/90000 (23%)]	Loss: -11.2410	Cost: 10.69s
Train Epoch: 917 [40960/90000 (45%)]	Loss: -10.8425	Cost: 17.31s
Train Epoch: 917 [61440/90000 (68%)]	Loss: -11.1784	Cost: 13.15s
Train Epoch: 917 [81920/90000 (91%)]	Loss: -11.3196	Cost: 15.94s
Train Epoch: 917 	Average Loss: -10.8099
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3381

Learning rate: 0.00019995850666093646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 918 [0/90000 (0%)]	Loss: -6.0255	Cost: 27.71s
Train Epoch: 918 [20480/90000 (23%)]	Loss: -11.3743	Cost: 8.33s
Train Epoch: 918 [40960/90000 (45%)]	Loss: -10.8411	Cost: 17.23s
Train Epoch: 918 [61440/90000 (68%)]	Loss: -11.2621	Cost: 14.50s
Train Epoch: 918 [81920/90000 (91%)]	Loss: -11.2871	Cost: 12.70s
Train Epoch: 918 	Average Loss: -10.8720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2828

Learning rate: 0.0001999584161198547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 919 [0/90000 (0%)]	Loss: -5.0016	Cost: 29.79s
Train Epoch: 919 [20480/90000 (23%)]	Loss: -9.9475	Cost: 6.58s
Train Epoch: 919 [40960/90000 (45%)]	Loss: -9.8563	Cost: 12.52s
Train Epoch: 919 [61440/90000 (68%)]	Loss: -10.5411	Cost: 13.16s
Train Epoch: 919 [81920/90000 (91%)]	Loss: -11.0838	Cost: 13.64s
Train Epoch: 919 	Average Loss: -10.0325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1795

Learning rate: 0.0001999583254801179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 920 [0/90000 (0%)]	Loss: -5.6896	Cost: 33.56s
Train Epoch: 920 [20480/90000 (23%)]	Loss: -11.4235	Cost: 12.33s
Train Epoch: 920 [40960/90000 (45%)]	Loss: -11.0500	Cost: 14.33s
Train Epoch: 920 [61440/90000 (68%)]	Loss: -10.5874	Cost: 13.12s
Train Epoch: 920 [81920/90000 (91%)]	Loss: -10.8792	Cost: 15.06s
Train Epoch: 920 	Average Loss: -10.6299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0226

Learning rate: 0.0001999582347417262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 921 [0/90000 (0%)]	Loss: -6.4369	Cost: 27.39s
Train Epoch: 921 [20480/90000 (23%)]	Loss: -11.2699	Cost: 10.13s
Train Epoch: 921 [40960/90000 (45%)]	Loss: -10.7001	Cost: 13.93s
Train Epoch: 921 [61440/90000 (68%)]	Loss: -10.6178	Cost: 13.68s
Train Epoch: 921 [81920/90000 (91%)]	Loss: -10.9952	Cost: 15.40s
Train Epoch: 921 	Average Loss: -10.6319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9412

Learning rate: 0.00019995814390467965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 922 [0/90000 (0%)]	Loss: -5.2909	Cost: 27.19s
Train Epoch: 922 [20480/90000 (23%)]	Loss: -11.0926	Cost: 8.42s
Train Epoch: 922 [40960/90000 (45%)]	Loss: -10.5548	Cost: 17.05s
Train Epoch: 922 [61440/90000 (68%)]	Loss: -10.9040	Cost: 12.55s
Train Epoch: 922 [81920/90000 (91%)]	Loss: -11.0652	Cost: 12.82s
Train Epoch: 922 	Average Loss: -10.5015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2148

Learning rate: 0.00019995805296897838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 923 [0/90000 (0%)]	Loss: -6.4237	Cost: 26.98s
Train Epoch: 923 [20480/90000 (23%)]	Loss: -11.4019	Cost: 7.68s
Train Epoch: 923 [40960/90000 (45%)]	Loss: -10.9702	Cost: 15.56s
Train Epoch: 923 [61440/90000 (68%)]	Loss: -11.2967	Cost: 13.96s
Train Epoch: 923 [81920/90000 (91%)]	Loss: -11.3751	Cost: 14.45s
Train Epoch: 923 	Average Loss: -10.9302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2989

Learning rate: 0.00019995796193462246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 924 [0/90000 (0%)]	Loss: -6.3144	Cost: 31.15s
Train Epoch: 924 [20480/90000 (23%)]	Loss: -11.2242	Cost: 9.82s
Train Epoch: 924 [40960/90000 (45%)]	Loss: -10.5715	Cost: 15.48s
Train Epoch: 924 [61440/90000 (68%)]	Loss: -11.1283	Cost: 15.99s
Train Epoch: 924 [81920/90000 (91%)]	Loss: -11.2769	Cost: 15.18s
Train Epoch: 924 	Average Loss: -10.8249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4764

Saving model as e924_model.pt & e924_waveforms_supplementary.hdf5
Learning rate: 0.000199957870801612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 925 [0/90000 (0%)]	Loss: -6.7197	Cost: 28.17s
Train Epoch: 925 [20480/90000 (23%)]	Loss: -11.6666	Cost: 14.12s
Train Epoch: 925 [40960/90000 (45%)]	Loss: -10.9742	Cost: 17.32s
Train Epoch: 925 [61440/90000 (68%)]	Loss: -11.7406	Cost: 14.66s
Train Epoch: 925 [81920/90000 (91%)]	Loss: -11.4684	Cost: 17.30s
Train Epoch: 925 	Average Loss: -11.1761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4215

Learning rate: 0.00019995777956994707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 926 [0/90000 (0%)]	Loss: -6.2854	Cost: 30.83s
Train Epoch: 926 [20480/90000 (23%)]	Loss: -11.5251	Cost: 14.78s
Train Epoch: 926 [40960/90000 (45%)]	Loss: -10.8485	Cost: 15.11s
Train Epoch: 926 [61440/90000 (68%)]	Loss: -11.2307	Cost: 14.31s
Train Epoch: 926 [81920/90000 (91%)]	Loss: -11.4568	Cost: 15.25s
Train Epoch: 926 	Average Loss: -10.9771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5407

Saving model as e926_model.pt & e926_waveforms_supplementary.hdf5
Learning rate: 0.0001999576882396278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 927 [0/90000 (0%)]	Loss: -6.2943	Cost: 34.01s
Train Epoch: 927 [20480/90000 (23%)]	Loss: -11.7133	Cost: 14.55s
Train Epoch: 927 [40960/90000 (45%)]	Loss: -11.0557	Cost: 14.91s
Train Epoch: 927 [61440/90000 (68%)]	Loss: -11.6643	Cost: 13.15s
Train Epoch: 927 [81920/90000 (91%)]	Loss: -11.6631	Cost: 17.58s
Train Epoch: 927 	Average Loss: -11.2282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6405

Saving model as e927_model.pt & e927_waveforms_supplementary.hdf5
Learning rate: 0.00019995759681065418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 928 [0/90000 (0%)]	Loss: -6.2834	Cost: 39.43s
Train Epoch: 928 [20480/90000 (23%)]	Loss: -11.7166	Cost: 14.38s
Train Epoch: 928 [40960/90000 (45%)]	Loss: -11.1812	Cost: 27.52s
Train Epoch: 928 [61440/90000 (68%)]	Loss: -11.6653	Cost: 10.89s
Train Epoch: 928 [81920/90000 (91%)]	Loss: -11.8388	Cost: 11.59s
Train Epoch: 928 	Average Loss: -11.2539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6738

Saving model as e928_model.pt & e928_waveforms_supplementary.hdf5
Learning rate: 0.0001999575052830264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 929 [0/90000 (0%)]	Loss: -6.1781	Cost: 30.19s
Train Epoch: 929 [20480/90000 (23%)]	Loss: -11.8370	Cost: 10.70s
Train Epoch: 929 [40960/90000 (45%)]	Loss: -11.2890	Cost: 15.18s
Train Epoch: 929 [61440/90000 (68%)]	Loss: -11.0049	Cost: 15.46s
Train Epoch: 929 [81920/90000 (91%)]	Loss: -11.1874	Cost: 11.64s
Train Epoch: 929 	Average Loss: -11.0815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4895

Learning rate: 0.0001999574136567445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 930 [0/90000 (0%)]	Loss: -6.3165	Cost: 34.98s
Train Epoch: 930 [20480/90000 (23%)]	Loss: -11.4529	Cost: 12.04s
Train Epoch: 930 [40960/90000 (45%)]	Loss: -10.9638	Cost: 14.57s
Train Epoch: 930 [61440/90000 (68%)]	Loss: -11.3826	Cost: 15.73s
Train Epoch: 930 [81920/90000 (91%)]	Loss: -11.6663	Cost: 12.14s
Train Epoch: 930 	Average Loss: -11.0405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5994

Learning rate: 0.00019995732193180861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 931 [0/90000 (0%)]	Loss: -6.0471	Cost: 33.08s
Train Epoch: 931 [20480/90000 (23%)]	Loss: -11.8613	Cost: 13.15s
Train Epoch: 931 [40960/90000 (45%)]	Loss: -11.2861	Cost: 15.51s
Train Epoch: 931 [61440/90000 (68%)]	Loss: -11.7042	Cost: 15.43s
Train Epoch: 931 [81920/90000 (91%)]	Loss: -11.7552	Cost: 12.11s
Train Epoch: 931 	Average Loss: -11.3355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7552

Saving model as e931_model.pt & e931_waveforms_supplementary.hdf5
Learning rate: 0.00019995723010821879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 932 [0/90000 (0%)]	Loss: -6.4781	Cost: 30.32s
Train Epoch: 932 [20480/90000 (23%)]	Loss: -11.8972	Cost: 13.16s
Train Epoch: 932 [40960/90000 (45%)]	Loss: -11.3130	Cost: 14.46s
Train Epoch: 932 [61440/90000 (68%)]	Loss: -11.6265	Cost: 14.60s
Train Epoch: 932 [81920/90000 (91%)]	Loss: -11.6800	Cost: 18.73s
Train Epoch: 932 	Average Loss: -11.3029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6253

Learning rate: 0.00019995713818597515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 933 [0/90000 (0%)]	Loss: -6.3210	Cost: 33.46s
Train Epoch: 933 [20480/90000 (23%)]	Loss: -11.7096	Cost: 14.20s
Train Epoch: 933 [40960/90000 (45%)]	Loss: -11.2675	Cost: 13.94s
Train Epoch: 933 [61440/90000 (68%)]	Loss: -11.5691	Cost: 14.43s
Train Epoch: 933 [81920/90000 (91%)]	Loss: -11.8512	Cost: 14.35s
Train Epoch: 933 	Average Loss: -11.2777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7545

Learning rate: 0.00019995704616507777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 934 [0/90000 (0%)]	Loss: -6.0499	Cost: 30.21s
Train Epoch: 934 [20480/90000 (23%)]	Loss: -12.0876	Cost: 14.16s
Train Epoch: 934 [40960/90000 (45%)]	Loss: -11.2763	Cost: 14.34s
Train Epoch: 934 [61440/90000 (68%)]	Loss: -11.8667	Cost: 14.10s
Train Epoch: 934 [81920/90000 (91%)]	Loss: -11.8382	Cost: 13.99s
Train Epoch: 934 	Average Loss: -11.4256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8935

Saving model as e934_model.pt & e934_waveforms_supplementary.hdf5
Learning rate: 0.0001999569540455267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 935 [0/90000 (0%)]	Loss: -6.4897	Cost: 36.24s
Train Epoch: 935 [20480/90000 (23%)]	Loss: -11.9025	Cost: 13.28s
Train Epoch: 935 [40960/90000 (45%)]	Loss: -11.2529	Cost: 12.75s
Train Epoch: 935 [61440/90000 (68%)]	Loss: -11.6063	Cost: 16.23s
Train Epoch: 935 [81920/90000 (91%)]	Loss: -11.8031	Cost: 15.59s
Train Epoch: 935 	Average Loss: -11.3614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7639

Learning rate: 0.0001999568618273221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 936 [0/90000 (0%)]	Loss: -6.4494	Cost: 33.58s
Train Epoch: 936 [20480/90000 (23%)]	Loss: -11.9616	Cost: 14.29s
Train Epoch: 936 [40960/90000 (45%)]	Loss: -11.3031	Cost: 15.52s
Train Epoch: 936 [61440/90000 (68%)]	Loss: -11.5622	Cost: 14.32s
Train Epoch: 936 [81920/90000 (91%)]	Loss: -11.7603	Cost: 17.00s
Train Epoch: 936 	Average Loss: -11.3010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7191

Learning rate: 0.00019995676951046402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 937 [0/90000 (0%)]	Loss: -6.5020	Cost: 35.38s
Train Epoch: 937 [20480/90000 (23%)]	Loss: -11.9041	Cost: 15.00s
Train Epoch: 937 [40960/90000 (45%)]	Loss: -11.3756	Cost: 17.86s
Train Epoch: 937 [61440/90000 (68%)]	Loss: -11.8968	Cost: 15.25s
Train Epoch: 937 [81920/90000 (91%)]	Loss: -11.8632	Cost: 11.28s
Train Epoch: 937 	Average Loss: -11.3885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7498

Learning rate: 0.00019995667709495258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 938 [0/90000 (0%)]	Loss: -5.9755	Cost: 33.54s
Train Epoch: 938 [20480/90000 (23%)]	Loss: -11.8124	Cost: 14.02s
Train Epoch: 938 [40960/90000 (45%)]	Loss: -11.3060	Cost: 15.49s
Train Epoch: 938 [61440/90000 (68%)]	Loss: -11.7554	Cost: 13.18s
Train Epoch: 938 [81920/90000 (91%)]	Loss: -11.7128	Cost: 13.45s
Train Epoch: 938 	Average Loss: -11.3518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4095

Learning rate: 0.00019995658458078785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 939 [0/90000 (0%)]	Loss: -6.5664	Cost: 31.13s
Train Epoch: 939 [20480/90000 (23%)]	Loss: -11.4403	Cost: 13.04s
Train Epoch: 939 [40960/90000 (45%)]	Loss: -10.9963	Cost: 14.66s
Train Epoch: 939 [61440/90000 (68%)]	Loss: -11.8057	Cost: 13.99s
Train Epoch: 939 [81920/90000 (91%)]	Loss: -11.7420	Cost: 17.82s
Train Epoch: 939 	Average Loss: -11.1495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6354

Learning rate: 0.0001999564919679699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 940 [0/90000 (0%)]	Loss: -6.6844	Cost: 33.92s
Train Epoch: 940 [20480/90000 (23%)]	Loss: -11.8849	Cost: 14.07s
Train Epoch: 940 [40960/90000 (45%)]	Loss: -11.3121	Cost: 14.13s
Train Epoch: 940 [61440/90000 (68%)]	Loss: -11.8162	Cost: 14.32s
Train Epoch: 940 [81920/90000 (91%)]	Loss: -11.9057	Cost: 12.86s
Train Epoch: 940 	Average Loss: -11.4528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8512

Learning rate: 0.00019995639925649887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 941 [0/90000 (0%)]	Loss: -7.0219	Cost: 35.84s
Train Epoch: 941 [20480/90000 (23%)]	Loss: -12.0757	Cost: 14.08s
Train Epoch: 941 [40960/90000 (45%)]	Loss: -11.4033	Cost: 21.54s
Train Epoch: 941 [61440/90000 (68%)]	Loss: -11.2604	Cost: 14.96s
Train Epoch: 941 [81920/90000 (91%)]	Loss: -9.2020	Cost: 10.63s
Train Epoch: 941 	Average Loss: -10.9835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5106

Learning rate: 0.00019995630644637483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 942 [0/90000 (0%)]	Loss: -4.1740	Cost: 30.43s
Train Epoch: 942 [20480/90000 (23%)]	Loss: -9.7882	Cost: 14.64s
Train Epoch: 942 [40960/90000 (45%)]	Loss: -9.6147	Cost: 14.80s
Train Epoch: 942 [61440/90000 (68%)]	Loss: -10.5161	Cost: 14.68s
Train Epoch: 942 [81920/90000 (91%)]	Loss: -10.5044	Cost: 14.44s
Train Epoch: 942 	Average Loss: -9.5815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8725

Learning rate: 0.0001999562135375979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 943 [0/90000 (0%)]	Loss: -3.9747	Cost: 29.77s
Train Epoch: 943 [20480/90000 (23%)]	Loss: -9.2716	Cost: 14.01s
Train Epoch: 943 [40960/90000 (45%)]	Loss: -9.4795	Cost: 15.20s
Train Epoch: 943 [61440/90000 (68%)]	Loss: -10.3956	Cost: 14.17s
Train Epoch: 943 [81920/90000 (91%)]	Loss: -10.8809	Cost: 17.16s
Train Epoch: 943 	Average Loss: -9.5476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1304

Learning rate: 0.00019995612053016812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 944 [0/90000 (0%)]	Loss: -5.4454	Cost: 27.95s
Train Epoch: 944 [20480/90000 (23%)]	Loss: -11.3828	Cost: 14.00s
Train Epoch: 944 [40960/90000 (45%)]	Loss: -11.3332	Cost: 16.84s
Train Epoch: 944 [61440/90000 (68%)]	Loss: -11.7391	Cost: 14.73s
Train Epoch: 944 [81920/90000 (91%)]	Loss: -11.8352	Cost: 17.85s
Train Epoch: 944 	Average Loss: -11.1069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7532

Learning rate: 0.0001999560274240856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 945 [0/90000 (0%)]	Loss: -6.4030	Cost: 30.32s
Train Epoch: 945 [20480/90000 (23%)]	Loss: -11.8749	Cost: 14.53s
Train Epoch: 945 [40960/90000 (45%)]	Loss: -11.3677	Cost: 16.12s
Train Epoch: 945 [61440/90000 (68%)]	Loss: -11.7933	Cost: 15.81s
Train Epoch: 945 [81920/90000 (91%)]	Loss: -11.8084	Cost: 18.44s
Train Epoch: 945 	Average Loss: -11.3975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7702

Learning rate: 0.00019995593421935043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 946 [0/90000 (0%)]	Loss: -6.8270	Cost: 33.52s
Train Epoch: 946 [20480/90000 (23%)]	Loss: -11.7109	Cost: 14.76s
Train Epoch: 946 [40960/90000 (45%)]	Loss: -11.2339	Cost: 14.83s
Train Epoch: 946 [61440/90000 (68%)]	Loss: -11.7561	Cost: 14.78s
Train Epoch: 946 [81920/90000 (91%)]	Loss: -11.8889	Cost: 17.42s
Train Epoch: 946 	Average Loss: -11.3576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7258

Learning rate: 0.00019995584091596268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 947 [0/90000 (0%)]	Loss: -6.5095	Cost: 30.50s
Train Epoch: 947 [20480/90000 (23%)]	Loss: -11.8410	Cost: 14.07s
Train Epoch: 947 [40960/90000 (45%)]	Loss: -11.5767	Cost: 14.73s
Train Epoch: 947 [61440/90000 (68%)]	Loss: -11.8673	Cost: 13.52s
Train Epoch: 947 [81920/90000 (91%)]	Loss: -12.0555	Cost: 16.85s
Train Epoch: 947 	Average Loss: -11.5041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9219

Saving model as e947_model.pt & e947_waveforms_supplementary.hdf5
Learning rate: 0.00019995574751392248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 948 [0/90000 (0%)]	Loss: -7.1124	Cost: 28.22s
Train Epoch: 948 [20480/90000 (23%)]	Loss: -12.1561	Cost: 11.80s
Train Epoch: 948 [40960/90000 (45%)]	Loss: -11.4091	Cost: 15.40s
Train Epoch: 948 [61440/90000 (68%)]	Loss: -11.7384	Cost: 14.06s
Train Epoch: 948 [81920/90000 (91%)]	Loss: -11.8861	Cost: 16.94s
Train Epoch: 948 	Average Loss: -11.4790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8777

Learning rate: 0.00019995565401322992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 949 [0/90000 (0%)]	Loss: -6.9894	Cost: 28.04s
Train Epoch: 949 [20480/90000 (23%)]	Loss: -12.0503	Cost: 11.25s
Train Epoch: 949 [40960/90000 (45%)]	Loss: -11.4151	Cost: 17.32s
Train Epoch: 949 [61440/90000 (68%)]	Loss: -11.6924	Cost: 15.36s
Train Epoch: 949 [81920/90000 (91%)]	Loss: -11.9348	Cost: 20.92s
Train Epoch: 949 	Average Loss: -11.4746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8978

Learning rate: 0.00019995556041388512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 950 [0/90000 (0%)]	Loss: -7.0179	Cost: 28.00s
Train Epoch: 950 [20480/90000 (23%)]	Loss: -10.8700	Cost: 11.16s
Train Epoch: 950 [40960/90000 (45%)]	Loss: -10.3722	Cost: 14.37s
Train Epoch: 950 [61440/90000 (68%)]	Loss: -10.8605	Cost: 14.31s
Train Epoch: 950 [81920/90000 (91%)]	Loss: -11.2939	Cost: 14.73s
Train Epoch: 950 	Average Loss: -10.6713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3690

Learning rate: 0.0001999554667158881
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 951 [0/90000 (0%)]	Loss: -6.1663	Cost: 29.33s
Train Epoch: 951 [20480/90000 (23%)]	Loss: -11.7880	Cost: 9.77s
Train Epoch: 951 [40960/90000 (45%)]	Loss: -11.1320	Cost: 14.91s
Train Epoch: 951 [61440/90000 (68%)]	Loss: -11.5511	Cost: 13.93s
Train Epoch: 951 [81920/90000 (91%)]	Loss: -11.6865	Cost: 13.86s
Train Epoch: 951 	Average Loss: -11.2262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4205

Learning rate: 0.00019995537291923898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 952 [0/90000 (0%)]	Loss: -6.2347	Cost: 31.47s
Train Epoch: 952 [20480/90000 (23%)]	Loss: -11.9555	Cost: 10.17s
Train Epoch: 952 [40960/90000 (45%)]	Loss: -11.4154	Cost: 14.17s
Train Epoch: 952 [61440/90000 (68%)]	Loss: -12.0500	Cost: 13.86s
Train Epoch: 952 [81920/90000 (91%)]	Loss: -11.9488	Cost: 14.32s
Train Epoch: 952 	Average Loss: -11.4364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8556

Learning rate: 0.00019995527902393789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 953 [0/90000 (0%)]	Loss: -5.6692	Cost: 29.03s
Train Epoch: 953 [20480/90000 (23%)]	Loss: -12.0042	Cost: 10.67s
Train Epoch: 953 [40960/90000 (45%)]	Loss: -11.5522	Cost: 14.41s
Train Epoch: 953 [61440/90000 (68%)]	Loss: -11.9418	Cost: 14.21s
Train Epoch: 953 [81920/90000 (91%)]	Loss: -12.1219	Cost: 15.33s
Train Epoch: 953 	Average Loss: -11.5862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1267

Saving model as e953_model.pt & e953_waveforms_supplementary.hdf5
Learning rate: 0.00019995518502998488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 954 [0/90000 (0%)]	Loss: -6.2886	Cost: 30.77s
Train Epoch: 954 [20480/90000 (23%)]	Loss: -12.1009	Cost: 13.92s
Train Epoch: 954 [40960/90000 (45%)]	Loss: -11.6690	Cost: 15.25s
Train Epoch: 954 [61440/90000 (68%)]	Loss: -11.9523	Cost: 13.08s
Train Epoch: 954 [81920/90000 (91%)]	Loss: -12.1000	Cost: 13.97s
Train Epoch: 954 	Average Loss: -11.5966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8806

Learning rate: 0.00019995509093738005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 955 [0/90000 (0%)]	Loss: -6.4338	Cost: 31.86s
Train Epoch: 955 [20480/90000 (23%)]	Loss: -12.2560	Cost: 14.47s
Train Epoch: 955 [40960/90000 (45%)]	Loss: -11.7998	Cost: 14.09s
Train Epoch: 955 [61440/90000 (68%)]	Loss: -12.1051	Cost: 13.40s
Train Epoch: 955 [81920/90000 (91%)]	Loss: -11.9995	Cost: 12.09s
Train Epoch: 955 	Average Loss: -11.7148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0952

Learning rate: 0.00019995499674612354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 956 [0/90000 (0%)]	Loss: -6.5826	Cost: 35.65s
Train Epoch: 956 [20480/90000 (23%)]	Loss: -12.2378	Cost: 14.37s
Train Epoch: 956 [40960/90000 (45%)]	Loss: -11.5792	Cost: 14.09s
Train Epoch: 956 [61440/90000 (68%)]	Loss: -11.8822	Cost: 13.20s
Train Epoch: 956 [81920/90000 (91%)]	Loss: -12.2404	Cost: 12.68s
Train Epoch: 956 	Average Loss: -11.7498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0313

Learning rate: 0.00019995490245621535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 957 [0/90000 (0%)]	Loss: -7.0197	Cost: 37.40s
Train Epoch: 957 [20480/90000 (23%)]	Loss: -12.3204	Cost: 13.02s
Train Epoch: 957 [40960/90000 (45%)]	Loss: -11.4388	Cost: 15.05s
Train Epoch: 957 [61440/90000 (68%)]	Loss: -11.9886	Cost: 12.98s
Train Epoch: 957 [81920/90000 (91%)]	Loss: -12.0525	Cost: 12.89s
Train Epoch: 957 	Average Loss: -11.6311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9116

Learning rate: 0.00019995480806765564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 958 [0/90000 (0%)]	Loss: -6.5430	Cost: 41.39s
Train Epoch: 958 [20480/90000 (23%)]	Loss: -11.6986	Cost: 12.76s
Train Epoch: 958 [40960/90000 (45%)]	Loss: -11.0417	Cost: 18.79s
Train Epoch: 958 [61440/90000 (68%)]	Loss: -11.7214	Cost: 13.46s
Train Epoch: 958 [81920/90000 (91%)]	Loss: -12.0170	Cost: 9.99s
Train Epoch: 958 	Average Loss: -11.3542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9115

Learning rate: 0.0001999547135804445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 959 [0/90000 (0%)]	Loss: -6.7866	Cost: 48.30s
Train Epoch: 959 [20480/90000 (23%)]	Loss: -12.4211	Cost: 12.50s
Train Epoch: 959 [40960/90000 (45%)]	Loss: -11.6062	Cost: 22.52s
Train Epoch: 959 [61440/90000 (68%)]	Loss: -12.2227	Cost: 12.81s
Train Epoch: 959 [81920/90000 (91%)]	Loss: -12.0701	Cost: 7.65s
Train Epoch: 959 	Average Loss: -11.6910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8821

Learning rate: 0.000199954618994582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 960 [0/90000 (0%)]	Loss: -6.3751	Cost: 39.80s
Train Epoch: 960 [20480/90000 (23%)]	Loss: -12.2885	Cost: 13.57s
Train Epoch: 960 [40960/90000 (45%)]	Loss: -11.6651	Cost: 23.88s
Train Epoch: 960 [61440/90000 (68%)]	Loss: -12.1021	Cost: 12.82s
Train Epoch: 960 [81920/90000 (91%)]	Loss: -12.2787	Cost: 12.01s
Train Epoch: 960 	Average Loss: -11.7725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1552

Saving model as e960_model.pt & e960_waveforms_supplementary.hdf5
Learning rate: 0.00019995452431006823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 961 [0/90000 (0%)]	Loss: -7.1596	Cost: 27.42s
Train Epoch: 961 [20480/90000 (23%)]	Loss: -12.2011	Cost: 14.34s
Train Epoch: 961 [40960/90000 (45%)]	Loss: -11.5090	Cost: 14.92s
Train Epoch: 961 [61440/90000 (68%)]	Loss: -11.6929	Cost: 15.59s
Train Epoch: 961 [81920/90000 (91%)]	Loss: -11.9120	Cost: 20.19s
Train Epoch: 961 	Average Loss: -11.5213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8383

Learning rate: 0.0001999544295269033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 962 [0/90000 (0%)]	Loss: -6.2336	Cost: 33.96s
Train Epoch: 962 [20480/90000 (23%)]	Loss: -11.9355	Cost: 14.25s
Train Epoch: 962 [40960/90000 (45%)]	Loss: -11.5851	Cost: 15.67s
Train Epoch: 962 [61440/90000 (68%)]	Loss: -11.9085	Cost: 15.28s
Train Epoch: 962 [81920/90000 (91%)]	Loss: -11.7768	Cost: 15.52s
Train Epoch: 962 	Average Loss: -11.4640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3811

Learning rate: 0.00019995433464508735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 963 [0/90000 (0%)]	Loss: -6.2025	Cost: 37.59s
Train Epoch: 963 [20480/90000 (23%)]	Loss: -11.7305	Cost: 14.57s
Train Epoch: 963 [40960/90000 (45%)]	Loss: -11.2926	Cost: 14.20s
Train Epoch: 963 [61440/90000 (68%)]	Loss: -12.1704	Cost: 15.70s
Train Epoch: 963 [81920/90000 (91%)]	Loss: -11.9657	Cost: 10.92s
Train Epoch: 963 	Average Loss: -11.4522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0749

Learning rate: 0.0001999542396646204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 964 [0/90000 (0%)]	Loss: -6.2274	Cost: 29.71s
Train Epoch: 964 [20480/90000 (23%)]	Loss: -11.9978	Cost: 14.93s
Train Epoch: 964 [40960/90000 (45%)]	Loss: -11.4672	Cost: 13.72s
Train Epoch: 964 [61440/90000 (68%)]	Loss: -12.0984	Cost: 15.61s
Train Epoch: 964 [81920/90000 (91%)]	Loss: -11.8689	Cost: 19.48s
Train Epoch: 964 	Average Loss: -11.5644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8347

Learning rate: 0.00019995414458550255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 965 [0/90000 (0%)]	Loss: -5.9759	Cost: 28.76s
Train Epoch: 965 [20480/90000 (23%)]	Loss: -12.1878	Cost: 8.71s
Train Epoch: 965 [40960/90000 (45%)]	Loss: -11.6883	Cost: 14.83s
Train Epoch: 965 [61440/90000 (68%)]	Loss: -12.1859	Cost: 12.75s
Train Epoch: 965 [81920/90000 (91%)]	Loss: -12.2222	Cost: 17.68s
Train Epoch: 965 	Average Loss: -11.6420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0656

Learning rate: 0.00019995404940773392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 966 [0/90000 (0%)]	Loss: -6.1071	Cost: 30.29s
Train Epoch: 966 [20480/90000 (23%)]	Loss: -12.0951	Cost: 10.71s
Train Epoch: 966 [40960/90000 (45%)]	Loss: -11.5911	Cost: 11.90s
Train Epoch: 966 [61440/90000 (68%)]	Loss: -12.1986	Cost: 12.05s
Train Epoch: 966 [81920/90000 (91%)]	Loss: -12.0765	Cost: 8.62s
Train Epoch: 966 	Average Loss: -11.6647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9453

Learning rate: 0.00019995395413131462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 967 [0/90000 (0%)]	Loss: -6.6477	Cost: 27.08s
Train Epoch: 967 [20480/90000 (23%)]	Loss: -12.1533	Cost: 10.07s
Train Epoch: 967 [40960/90000 (45%)]	Loss: -11.6195	Cost: 12.42s
Train Epoch: 967 [61440/90000 (68%)]	Loss: -12.2009	Cost: 11.79s
Train Epoch: 967 [81920/90000 (91%)]	Loss: -12.3159	Cost: 8.33s
Train Epoch: 967 	Average Loss: -11.7527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1489

Learning rate: 0.00019995385875624472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 968 [0/90000 (0%)]	Loss: -6.5512	Cost: 31.32s
Train Epoch: 968 [20480/90000 (23%)]	Loss: -12.5053	Cost: 12.04s
Train Epoch: 968 [40960/90000 (45%)]	Loss: -11.9463	Cost: 12.21s
Train Epoch: 968 [61440/90000 (68%)]	Loss: -12.3206	Cost: 9.78s
Train Epoch: 968 [81920/90000 (91%)]	Loss: -12.1819	Cost: 9.64s
Train Epoch: 968 	Average Loss: -11.9118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0540

Learning rate: 0.00019995376328252426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 969 [0/90000 (0%)]	Loss: -6.5792	Cost: 32.47s
Train Epoch: 969 [20480/90000 (23%)]	Loss: -12.4420	Cost: 11.28s
Train Epoch: 969 [40960/90000 (45%)]	Loss: -11.9195	Cost: 12.50s
Train Epoch: 969 [61440/90000 (68%)]	Loss: -12.2795	Cost: 9.83s
Train Epoch: 969 [81920/90000 (91%)]	Loss: -12.3540	Cost: 8.62s
Train Epoch: 969 	Average Loss: -11.8910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2113

Saving model as e969_model.pt & e969_waveforms_supplementary.hdf5
Learning rate: 0.00019995366771015345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 970 [0/90000 (0%)]	Loss: -7.3674	Cost: 32.54s
Train Epoch: 970 [20480/90000 (23%)]	Loss: -12.5815	Cost: 12.29s
Train Epoch: 970 [40960/90000 (45%)]	Loss: -12.1041	Cost: 12.38s
Train Epoch: 970 [61440/90000 (68%)]	Loss: -12.3820	Cost: 9.69s
Train Epoch: 970 [81920/90000 (91%)]	Loss: -12.4465	Cost: 8.66s
Train Epoch: 970 	Average Loss: -12.0660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3052

Saving model as e970_model.pt & e970_waveforms_supplementary.hdf5
Learning rate: 0.0001999535720391323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 971 [0/90000 (0%)]	Loss: -6.5945	Cost: 30.97s
Train Epoch: 971 [20480/90000 (23%)]	Loss: -12.6163	Cost: 12.27s
Train Epoch: 971 [40960/90000 (45%)]	Loss: -12.0187	Cost: 12.26s
Train Epoch: 971 [61440/90000 (68%)]	Loss: -11.1767	Cost: 10.84s
Train Epoch: 971 [81920/90000 (91%)]	Loss: -11.3236	Cost: 8.38s
Train Epoch: 971 	Average Loss: -11.5722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5031

Learning rate: 0.00019995347626946094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 972 [0/90000 (0%)]	Loss: -6.4762	Cost: 34.17s
Train Epoch: 972 [20480/90000 (23%)]	Loss: -11.6705	Cost: 9.49s
Train Epoch: 972 [40960/90000 (45%)]	Loss: -11.5429	Cost: 12.03s
Train Epoch: 972 [61440/90000 (68%)]	Loss: -12.0914	Cost: 12.74s
Train Epoch: 972 [81920/90000 (91%)]	Loss: -12.1662	Cost: 9.74s
Train Epoch: 972 	Average Loss: -11.4643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2532

Learning rate: 0.00019995338040113944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 973 [0/90000 (0%)]	Loss: -7.1489	Cost: 36.01s
Train Epoch: 973 [20480/90000 (23%)]	Loss: -12.4941	Cost: 11.46s
Train Epoch: 973 [40960/90000 (45%)]	Loss: -12.0266	Cost: 12.67s
Train Epoch: 973 [61440/90000 (68%)]	Loss: -12.5189	Cost: 12.89s
Train Epoch: 973 [81920/90000 (91%)]	Loss: -12.4063	Cost: 13.58s
Train Epoch: 973 	Average Loss: -12.0993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3107

Saving model as e973_model.pt & e973_waveforms_supplementary.hdf5
Learning rate: 0.0001999532844341679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 974 [0/90000 (0%)]	Loss: -7.4076	Cost: 38.98s
Train Epoch: 974 [20480/90000 (23%)]	Loss: -12.5268	Cost: 14.43s
Train Epoch: 974 [40960/90000 (45%)]	Loss: -12.0940	Cost: 15.68s
Train Epoch: 974 [61440/90000 (68%)]	Loss: -12.5088	Cost: 15.09s
Train Epoch: 974 [81920/90000 (91%)]	Loss: -12.5514	Cost: 9.89s
Train Epoch: 974 	Average Loss: -12.1331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2581

Learning rate: 0.00019995318836854643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 975 [0/90000 (0%)]	Loss: -6.7054	Cost: 30.86s
Train Epoch: 975 [20480/90000 (23%)]	Loss: -11.9048	Cost: 13.95s
Train Epoch: 975 [40960/90000 (45%)]	Loss: -11.5680	Cost: 15.83s
Train Epoch: 975 [61440/90000 (68%)]	Loss: -11.9956	Cost: 15.02s
Train Epoch: 975 [81920/90000 (91%)]	Loss: -11.7505	Cost: 17.03s
Train Epoch: 975 	Average Loss: -11.5799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9174

Learning rate: 0.00019995309220427514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 976 [0/90000 (0%)]	Loss: -6.7332	Cost: 37.41s
Train Epoch: 976 [20480/90000 (23%)]	Loss: -12.1540	Cost: 13.77s
Train Epoch: 976 [40960/90000 (45%)]	Loss: -11.5546	Cost: 16.09s
Train Epoch: 976 [61440/90000 (68%)]	Loss: -12.1991	Cost: 15.25s
Train Epoch: 976 [81920/90000 (91%)]	Loss: -12.3100	Cost: 10.25s
Train Epoch: 976 	Average Loss: -11.7701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2758

Learning rate: 0.00019995299594135409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 977 [0/90000 (0%)]	Loss: -6.4526	Cost: 32.64s
Train Epoch: 977 [20480/90000 (23%)]	Loss: -12.5525	Cost: 14.14s
Train Epoch: 977 [40960/90000 (45%)]	Loss: -12.0652	Cost: 18.26s
Train Epoch: 977 [61440/90000 (68%)]	Loss: -12.3598	Cost: 14.17s
Train Epoch: 977 [81920/90000 (91%)]	Loss: -12.0463	Cost: 13.90s
Train Epoch: 977 	Average Loss: -11.9873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1829

Learning rate: 0.00019995289957978334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 978 [0/90000 (0%)]	Loss: -5.7443	Cost: 28.94s
Train Epoch: 978 [20480/90000 (23%)]	Loss: -12.3196	Cost: 12.71s
Train Epoch: 978 [40960/90000 (45%)]	Loss: -11.5645	Cost: 15.83s
Train Epoch: 978 [61440/90000 (68%)]	Loss: -12.1262	Cost: 14.67s
Train Epoch: 978 [81920/90000 (91%)]	Loss: -12.3237	Cost: 15.17s
Train Epoch: 978 	Average Loss: -11.7094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1841

Learning rate: 0.00019995280311956308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 979 [0/90000 (0%)]	Loss: -6.4181	Cost: 29.09s
Train Epoch: 979 [20480/90000 (23%)]	Loss: -12.5182	Cost: 12.96s
Train Epoch: 979 [40960/90000 (45%)]	Loss: -11.9010	Cost: 16.47s
Train Epoch: 979 [61440/90000 (68%)]	Loss: -12.5195	Cost: 15.05s
Train Epoch: 979 [81920/90000 (91%)]	Loss: -12.4841	Cost: 19.05s
Train Epoch: 979 	Average Loss: -11.9632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3386

Saving model as e979_model.pt & e979_waveforms_supplementary.hdf5
Learning rate: 0.00019995270656069335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 980 [0/90000 (0%)]	Loss: -7.1142	Cost: 34.23s
Train Epoch: 980 [20480/90000 (23%)]	Loss: -12.7126	Cost: 15.02s
Train Epoch: 980 [40960/90000 (45%)]	Loss: -11.6693	Cost: 18.84s
Train Epoch: 980 [61440/90000 (68%)]	Loss: -12.0163	Cost: 14.52s
Train Epoch: 980 [81920/90000 (91%)]	Loss: -11.9356	Cost: 11.66s
Train Epoch: 980 	Average Loss: -11.7953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9951

Learning rate: 0.00019995260990317428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 981 [0/90000 (0%)]	Loss: -6.7960	Cost: 29.26s
Train Epoch: 981 [20480/90000 (23%)]	Loss: -12.4441	Cost: 12.64s
Train Epoch: 981 [40960/90000 (45%)]	Loss: -11.8602	Cost: 14.61s
Train Epoch: 981 [61440/90000 (68%)]	Loss: -12.2592	Cost: 13.99s
Train Epoch: 981 [81920/90000 (91%)]	Loss: -12.3263	Cost: 13.84s
Train Epoch: 981 	Average Loss: -11.8496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1956

Learning rate: 0.0001999525131470059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 982 [0/90000 (0%)]	Loss: -6.7930	Cost: 29.77s
Train Epoch: 982 [20480/90000 (23%)]	Loss: -12.6700	Cost: 12.53s
Train Epoch: 982 [40960/90000 (45%)]	Loss: -12.0931	Cost: 14.49s
Train Epoch: 982 [61440/90000 (68%)]	Loss: -12.5787	Cost: 12.45s
Train Epoch: 982 [81920/90000 (91%)]	Loss: -12.7425	Cost: 16.22s
Train Epoch: 982 	Average Loss: -12.1159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4867

Saving model as e982_model.pt & e982_waveforms_supplementary.hdf5
Learning rate: 0.00019995241629218837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 983 [0/90000 (0%)]	Loss: -6.9266	Cost: 28.76s
Train Epoch: 983 [20480/90000 (23%)]	Loss: -12.7761	Cost: 12.91s
Train Epoch: 983 [40960/90000 (45%)]	Loss: -12.1142	Cost: 14.19s
Train Epoch: 983 [61440/90000 (68%)]	Loss: -12.6734	Cost: 13.70s
Train Epoch: 983 [81920/90000 (91%)]	Loss: -12.4918	Cost: 14.83s
Train Epoch: 983 	Average Loss: -12.1905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9936

Learning rate: 0.00019995231933872174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 984 [0/90000 (0%)]	Loss: -6.5815	Cost: 26.95s
Train Epoch: 984 [20480/90000 (23%)]	Loss: -11.3758	Cost: 7.47s
Train Epoch: 984 [40960/90000 (45%)]	Loss: -11.3969	Cost: 19.50s
Train Epoch: 984 [61440/90000 (68%)]	Loss: -12.1445	Cost: 14.01s
Train Epoch: 984 [81920/90000 (91%)]	Loss: -12.3516	Cost: 14.48s
Train Epoch: 984 	Average Loss: -11.4370
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3103

Learning rate: 0.00019995222228660613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 985 [0/90000 (0%)]	Loss: -7.2477	Cost: 28.40s
Train Epoch: 985 [20480/90000 (23%)]	Loss: -12.7121	Cost: 7.70s
Train Epoch: 985 [40960/90000 (45%)]	Loss: -12.1509	Cost: 13.46s
Train Epoch: 985 [61440/90000 (68%)]	Loss: -12.5877	Cost: 15.30s
Train Epoch: 985 [81920/90000 (91%)]	Loss: -12.7443	Cost: 15.45s
Train Epoch: 985 	Average Loss: -12.2119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5422

Saving model as e985_model.pt & e985_waveforms_supplementary.hdf5
Learning rate: 0.00019995212513584164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 986 [0/90000 (0%)]	Loss: -7.3209	Cost: 35.39s
Train Epoch: 986 [20480/90000 (23%)]	Loss: -12.9658	Cost: 14.98s
Train Epoch: 986 [40960/90000 (45%)]	Loss: -12.3252	Cost: 14.30s
Train Epoch: 986 [61440/90000 (68%)]	Loss: -12.7316	Cost: 12.91s
Train Epoch: 986 [81920/90000 (91%)]	Loss: -12.6698	Cost: 12.70s
Train Epoch: 986 	Average Loss: -12.3759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5503

Saving model as e986_model.pt & e986_waveforms_supplementary.hdf5
Learning rate: 0.00019995202788642834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 987 [0/90000 (0%)]	Loss: -6.7048	Cost: 35.21s
Train Epoch: 987 [20480/90000 (23%)]	Loss: -11.1220	Cost: 14.94s
Train Epoch: 987 [40960/90000 (45%)]	Loss: -10.6282	Cost: 15.38s
Train Epoch: 987 [61440/90000 (68%)]	Loss: -11.5722	Cost: 14.56s
Train Epoch: 987 [81920/90000 (91%)]	Loss: -11.8091	Cost: 12.81s
Train Epoch: 987 	Average Loss: -11.1312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0057

Learning rate: 0.00019995193053836638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 988 [0/90000 (0%)]	Loss: -6.8463	Cost: 36.95s
Train Epoch: 988 [20480/90000 (23%)]	Loss: -12.4139	Cost: 14.31s
Train Epoch: 988 [40960/90000 (45%)]	Loss: -11.9037	Cost: 21.87s
Train Epoch: 988 [61440/90000 (68%)]	Loss: -12.5454	Cost: 14.63s
Train Epoch: 988 [81920/90000 (91%)]	Loss: -12.5978	Cost: 9.32s
Train Epoch: 988 	Average Loss: -11.9389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3419

Learning rate: 0.0001999518330916558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 989 [0/90000 (0%)]	Loss: -7.1809	Cost: 31.26s
Train Epoch: 989 [20480/90000 (23%)]	Loss: -12.3724	Cost: 16.19s
Train Epoch: 989 [40960/90000 (45%)]	Loss: -11.6396	Cost: 16.60s
Train Epoch: 989 [61440/90000 (68%)]	Loss: -12.1762	Cost: 14.65s
Train Epoch: 989 [81920/90000 (91%)]	Loss: -12.5207	Cost: 15.28s
Train Epoch: 989 	Average Loss: -11.8699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3242

Learning rate: 0.0001999517355462967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 990 [0/90000 (0%)]	Loss: -6.9493	Cost: 30.01s
Train Epoch: 990 [20480/90000 (23%)]	Loss: -12.7062	Cost: 14.90s
Train Epoch: 990 [40960/90000 (45%)]	Loss: -12.2777	Cost: 18.54s
Train Epoch: 990 [61440/90000 (68%)]	Loss: -12.8141	Cost: 15.14s
Train Epoch: 990 [81920/90000 (91%)]	Loss: -12.8892	Cost: 15.65s
Train Epoch: 990 	Average Loss: -12.3033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5921

Saving model as e990_model.pt & e990_waveforms_supplementary.hdf5
Learning rate: 0.00019995163790228918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 991 [0/90000 (0%)]	Loss: -6.5690	Cost: 29.68s
Train Epoch: 991 [20480/90000 (23%)]	Loss: -12.8481	Cost: 12.81s
Train Epoch: 991 [40960/90000 (45%)]	Loss: -12.2096	Cost: 15.06s
Train Epoch: 991 [61440/90000 (68%)]	Loss: -12.5610	Cost: 14.37s
Train Epoch: 991 [81920/90000 (91%)]	Loss: -12.7650	Cost: 13.76s
Train Epoch: 991 	Average Loss: -12.2703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6114

Saving model as e991_model.pt & e991_waveforms_supplementary.hdf5
Learning rate: 0.00019995154015963335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 992 [0/90000 (0%)]	Loss: -7.3825	Cost: 28.91s
Train Epoch: 992 [20480/90000 (23%)]	Loss: -12.8450	Cost: 13.96s
Train Epoch: 992 [40960/90000 (45%)]	Loss: -12.1760	Cost: 19.71s
Train Epoch: 992 [61440/90000 (68%)]	Loss: -12.8132	Cost: 13.63s
Train Epoch: 992 [81920/90000 (91%)]	Loss: -12.7089	Cost: 12.02s
Train Epoch: 992 	Average Loss: -12.3500
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6925

Saving model as e992_model.pt & e992_waveforms_supplementary.hdf5
Learning rate: 0.0001999514423183293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 993 [0/90000 (0%)]	Loss: -6.9763	Cost: 38.71s
Train Epoch: 993 [20480/90000 (23%)]	Loss: -12.8666	Cost: 13.45s
Train Epoch: 993 [40960/90000 (45%)]	Loss: -12.5111	Cost: 20.69s
Train Epoch: 993 [61440/90000 (68%)]	Loss: -12.9751	Cost: 12.58s
Train Epoch: 993 [81920/90000 (91%)]	Loss: -12.8946	Cost: 10.59s
Train Epoch: 993 	Average Loss: -12.4530
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5770

Learning rate: 0.00019995134437837716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 994 [0/90000 (0%)]	Loss: -7.4013	Cost: 29.49s
Train Epoch: 994 [20480/90000 (23%)]	Loss: -13.1423	Cost: 13.66s
Train Epoch: 994 [40960/90000 (45%)]	Loss: -12.4072	Cost: 17.15s
Train Epoch: 994 [61440/90000 (68%)]	Loss: -12.7611	Cost: 12.74s
Train Epoch: 994 [81920/90000 (91%)]	Loss: -12.3144	Cost: 13.55s
Train Epoch: 994 	Average Loss: -12.3452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2878

Learning rate: 0.000199951246339777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 995 [0/90000 (0%)]	Loss: -7.1193	Cost: 29.56s
Train Epoch: 995 [20480/90000 (23%)]	Loss: -12.7346	Cost: 15.46s
Train Epoch: 995 [40960/90000 (45%)]	Loss: -12.3038	Cost: 14.96s
Train Epoch: 995 [61440/90000 (68%)]	Loss: -12.8154	Cost: 14.58s
Train Epoch: 995 [81920/90000 (91%)]	Loss: -12.7882	Cost: 14.92s
Train Epoch: 995 	Average Loss: -12.3568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7618

Saving model as e995_model.pt & e995_waveforms_supplementary.hdf5
Learning rate: 0.00019995114820252889
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 996 [0/90000 (0%)]	Loss: -7.4325	Cost: 34.44s
Train Epoch: 996 [20480/90000 (23%)]	Loss: -13.1071	Cost: 15.47s
Train Epoch: 996 [40960/90000 (45%)]	Loss: -12.3776	Cost: 14.80s
Train Epoch: 996 [61440/90000 (68%)]	Loss: -13.1131	Cost: 15.48s
Train Epoch: 996 [81920/90000 (91%)]	Loss: -12.7136	Cost: 19.28s
Train Epoch: 996 	Average Loss: -12.4851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5931

Learning rate: 0.00019995104996663296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 997 [0/90000 (0%)]	Loss: -7.2593	Cost: 34.98s
Train Epoch: 997 [20480/90000 (23%)]	Loss: -13.1366	Cost: 15.60s
Train Epoch: 997 [40960/90000 (45%)]	Loss: -12.5903	Cost: 19.78s
Train Epoch: 997 [61440/90000 (68%)]	Loss: -13.0152	Cost: 13.55s
Train Epoch: 997 [81920/90000 (91%)]	Loss: -12.8698	Cost: 12.40s
Train Epoch: 997 	Average Loss: -12.5493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6933

Learning rate: 0.00019995095163208927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 998 [0/90000 (0%)]	Loss: -7.1960	Cost: 27.51s
Train Epoch: 998 [20480/90000 (23%)]	Loss: -12.8528	Cost: 10.76s
Train Epoch: 998 [40960/90000 (45%)]	Loss: -12.4618	Cost: 14.71s
Train Epoch: 998 [61440/90000 (68%)]	Loss: -13.0233	Cost: 14.35s
Train Epoch: 998 [81920/90000 (91%)]	Loss: -12.9315	Cost: 17.29s
Train Epoch: 998 	Average Loss: -12.5457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8279

Saving model as e998_model.pt & e998_waveforms_supplementary.hdf5
Learning rate: 0.000199950853198898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 999 [0/90000 (0%)]	Loss: -7.5845	Cost: 29.14s
Train Epoch: 999 [20480/90000 (23%)]	Loss: -13.2708	Cost: 11.60s
Train Epoch: 999 [40960/90000 (45%)]	Loss: -12.3716	Cost: 14.64s
Train Epoch: 999 [61440/90000 (68%)]	Loss: -12.9462	Cost: 13.81s
Train Epoch: 999 [81920/90000 (91%)]	Loss: -12.9122	Cost: 12.27s
Train Epoch: 999 	Average Loss: -12.5781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5925

Learning rate: 0.00019995075466705913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1000 [0/90000 (0%)]	Loss: -6.7705	Cost: 28.56s
Train Epoch: 1000 [20480/90000 (23%)]	Loss: -12.8917	Cost: 11.22s
Train Epoch: 1000 [40960/90000 (45%)]	Loss: -12.3322	Cost: 14.61s
Train Epoch: 1000 [61440/90000 (68%)]	Loss: -12.8950	Cost: 13.32s
Train Epoch: 1000 [81920/90000 (91%)]	Loss: -12.8361	Cost: 13.74s
Train Epoch: 1000 	Average Loss: -12.3755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6113

Learning rate: 0.00019995065603657287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1001 [0/90000 (0%)]	Loss: -7.2229	Cost: 27.23s
Train Epoch: 1001 [20480/90000 (23%)]	Loss: -12.8619	Cost: 6.75s
Train Epoch: 1001 [40960/90000 (45%)]	Loss: -12.2101	Cost: 16.48s
Train Epoch: 1001 [61440/90000 (68%)]	Loss: -12.9063	Cost: 13.99s
Train Epoch: 1001 [81920/90000 (91%)]	Loss: -13.0967	Cost: 13.32s
Train Epoch: 1001 	Average Loss: -12.4470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6940

Learning rate: 0.00019995055730743925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1002 [0/90000 (0%)]	Loss: -7.5671	Cost: 26.21s
Train Epoch: 1002 [20480/90000 (23%)]	Loss: -13.1855	Cost: 6.98s
Train Epoch: 1002 [40960/90000 (45%)]	Loss: -12.4185	Cost: 13.62s
Train Epoch: 1002 [61440/90000 (68%)]	Loss: -13.0533	Cost: 14.13s
Train Epoch: 1002 [81920/90000 (91%)]	Loss: -13.1096	Cost: 13.19s
Train Epoch: 1002 	Average Loss: -12.6571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6162

Learning rate: 0.00019995045847965838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1003 [0/90000 (0%)]	Loss: -6.8665	Cost: 28.22s
Train Epoch: 1003 [20480/90000 (23%)]	Loss: -13.0015	Cost: 6.76s
Train Epoch: 1003 [40960/90000 (45%)]	Loss: -12.5894	Cost: 12.58s
Train Epoch: 1003 [61440/90000 (68%)]	Loss: -13.1557	Cost: 11.63s
Train Epoch: 1003 [81920/90000 (91%)]	Loss: -12.7319	Cost: 13.77s
Train Epoch: 1003 	Average Loss: -12.5476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5360

Learning rate: 0.00019995035955323038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1004 [0/90000 (0%)]	Loss: -6.3923	Cost: 29.25s
Train Epoch: 1004 [20480/90000 (23%)]	Loss: -13.0383	Cost: 6.61s
Train Epoch: 1004 [40960/90000 (45%)]	Loss: -12.5231	Cost: 15.04s
Train Epoch: 1004 [61440/90000 (68%)]	Loss: -12.9593	Cost: 13.56s
Train Epoch: 1004 [81920/90000 (91%)]	Loss: -13.1465	Cost: 12.97s
Train Epoch: 1004 	Average Loss: -12.4994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9412

Saving model as e1004_model.pt & e1004_waveforms_supplementary.hdf5
Learning rate: 0.00019995026052815532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1005 [0/90000 (0%)]	Loss: -7.5233	Cost: 27.09s
Train Epoch: 1005 [20480/90000 (23%)]	Loss: -13.1676	Cost: 10.93s
Train Epoch: 1005 [40960/90000 (45%)]	Loss: -12.2657	Cost: 16.39s
Train Epoch: 1005 [61440/90000 (68%)]	Loss: -12.6278	Cost: 13.89s
Train Epoch: 1005 [81920/90000 (91%)]	Loss: -12.9757	Cost: 12.88s
Train Epoch: 1005 	Average Loss: -12.5701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8037

Learning rate: 0.00019995016140443328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1006 [0/90000 (0%)]	Loss: -7.6647	Cost: 28.03s
Train Epoch: 1006 [20480/90000 (23%)]	Loss: -13.0840	Cost: 10.84s
Train Epoch: 1006 [40960/90000 (45%)]	Loss: -12.4938	Cost: 15.20s
Train Epoch: 1006 [61440/90000 (68%)]	Loss: -12.9176	Cost: 15.05s
Train Epoch: 1006 [81920/90000 (91%)]	Loss: -13.2348	Cost: 15.03s
Train Epoch: 1006 	Average Loss: -12.5777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8890

Learning rate: 0.0001999500621820644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1007 [0/90000 (0%)]	Loss: -7.0210	Cost: 28.59s
Train Epoch: 1007 [20480/90000 (23%)]	Loss: -13.3341	Cost: 10.28s
Train Epoch: 1007 [40960/90000 (45%)]	Loss: -12.5972	Cost: 14.96s
Train Epoch: 1007 [61440/90000 (68%)]	Loss: -12.8495	Cost: 14.17s
Train Epoch: 1007 [81920/90000 (91%)]	Loss: -12.9552	Cost: 14.09s
Train Epoch: 1007 	Average Loss: -12.6002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5814

Learning rate: 0.00019994996286104878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1008 [0/90000 (0%)]	Loss: -7.0238	Cost: 27.74s
Train Epoch: 1008 [20480/90000 (23%)]	Loss: -13.0865	Cost: 8.36s
Train Epoch: 1008 [40960/90000 (45%)]	Loss: -12.6815	Cost: 15.68s
Train Epoch: 1008 [61440/90000 (68%)]	Loss: -13.1594	Cost: 14.44s
Train Epoch: 1008 [81920/90000 (91%)]	Loss: -13.0503	Cost: 15.76s
Train Epoch: 1008 	Average Loss: -12.6480
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7771

Learning rate: 0.0001999498634413865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1009 [0/90000 (0%)]	Loss: -7.7379	Cost: 28.86s
Train Epoch: 1009 [20480/90000 (23%)]	Loss: -13.1611	Cost: 6.71s
Train Epoch: 1009 [40960/90000 (45%)]	Loss: -12.5392	Cost: 12.76s
Train Epoch: 1009 [61440/90000 (68%)]	Loss: -13.0219	Cost: 11.98s
Train Epoch: 1009 [81920/90000 (91%)]	Loss: -13.1680	Cost: 14.06s
Train Epoch: 1009 	Average Loss: -12.6626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8842

Learning rate: 0.00019994976392307765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1010 [0/90000 (0%)]	Loss: -7.3422	Cost: 40.90s
Train Epoch: 1010 [20480/90000 (23%)]	Loss: -13.3272	Cost: 11.17s
Train Epoch: 1010 [40960/90000 (45%)]	Loss: -12.6593	Cost: 12.22s
Train Epoch: 1010 [61440/90000 (68%)]	Loss: -11.9457	Cost: 13.86s
Train Epoch: 1010 [81920/90000 (91%)]	Loss: -6.8296	Cost: 12.83s
Train Epoch: 1010 	Average Loss: -11.3009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5396

Learning rate: 0.00019994966430612234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1011 [0/90000 (0%)]	Loss: -2.5309	Cost: 36.88s
Train Epoch: 1011 [20480/90000 (23%)]	Loss: -7.8555	Cost: 8.72s
Train Epoch: 1011 [40960/90000 (45%)]	Loss: -8.1854	Cost: 12.39s
Train Epoch: 1011 [61440/90000 (68%)]	Loss: -9.7670	Cost: 13.96s
Train Epoch: 1011 [81920/90000 (91%)]	Loss: -10.7136	Cost: 15.05s
Train Epoch: 1011 	Average Loss: -8.5235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3034

Learning rate: 0.00019994956459052065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1012 [0/90000 (0%)]	Loss: -6.0500	Cost: 30.29s
Train Epoch: 1012 [20480/90000 (23%)]	Loss: -11.5092	Cost: 12.66s
Train Epoch: 1012 [40960/90000 (45%)]	Loss: -11.4160	Cost: 14.36s
Train Epoch: 1012 [61440/90000 (68%)]	Loss: -12.1993	Cost: 13.18s
Train Epoch: 1012 [81920/90000 (91%)]	Loss: -12.5331	Cost: 13.30s
Train Epoch: 1012 	Average Loss: -11.5007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0830

Learning rate: 0.00019994946477627272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1013 [0/90000 (0%)]	Loss: -6.7520	Cost: 29.12s
Train Epoch: 1013 [20480/90000 (23%)]	Loss: -12.6197	Cost: 11.04s
Train Epoch: 1013 [40960/90000 (45%)]	Loss: -12.1313	Cost: 15.05s
Train Epoch: 1013 [61440/90000 (68%)]	Loss: -12.8464	Cost: 14.17s
Train Epoch: 1013 [81920/90000 (91%)]	Loss: -13.1047	Cost: 13.74s
Train Epoch: 1013 	Average Loss: -12.2545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7664

Learning rate: 0.0001999493648633786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1014 [0/90000 (0%)]	Loss: -7.2853	Cost: 38.49s
Train Epoch: 1014 [20480/90000 (23%)]	Loss: -13.2102	Cost: 14.77s
Train Epoch: 1014 [40960/90000 (45%)]	Loss: -12.6896	Cost: 14.77s
Train Epoch: 1014 [61440/90000 (68%)]	Loss: -12.8864	Cost: 15.10s
Train Epoch: 1014 [81920/90000 (91%)]	Loss: -12.9180	Cost: 10.36s
Train Epoch: 1014 	Average Loss: -12.5760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7299

Learning rate: 0.00019994926485183842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1015 [0/90000 (0%)]	Loss: -7.4748	Cost: 27.07s
Train Epoch: 1015 [20480/90000 (23%)]	Loss: -13.0697	Cost: 14.28s
Train Epoch: 1015 [40960/90000 (45%)]	Loss: -12.4496	Cost: 16.28s
Train Epoch: 1015 [61440/90000 (68%)]	Loss: -12.8494	Cost: 15.58s
Train Epoch: 1015 [81920/90000 (91%)]	Loss: -13.0777	Cost: 18.72s
Train Epoch: 1015 	Average Loss: -12.6130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9265

Learning rate: 0.00019994916474165228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1016 [0/90000 (0%)]	Loss: -7.2011	Cost: 29.05s
Train Epoch: 1016 [20480/90000 (23%)]	Loss: -13.3850	Cost: 14.22s
Train Epoch: 1016 [40960/90000 (45%)]	Loss: -12.6294	Cost: 15.93s
Train Epoch: 1016 [61440/90000 (68%)]	Loss: -13.2064	Cost: 15.20s
Train Epoch: 1016 [81920/90000 (91%)]	Loss: -13.2680	Cost: 16.04s
Train Epoch: 1016 	Average Loss: -12.7534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9183

Learning rate: 0.00019994906453282024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1017 [0/90000 (0%)]	Loss: -7.3607	Cost: 33.22s
Train Epoch: 1017 [20480/90000 (23%)]	Loss: -13.3064	Cost: 15.43s
Train Epoch: 1017 [40960/90000 (45%)]	Loss: -12.6496	Cost: 15.67s
Train Epoch: 1017 [61440/90000 (68%)]	Loss: -13.1757	Cost: 15.76s
Train Epoch: 1017 [81920/90000 (91%)]	Loss: -13.1301	Cost: 15.04s
Train Epoch: 1017 	Average Loss: -12.7522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8811

Learning rate: 0.00019994896422534245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1018 [0/90000 (0%)]	Loss: -7.6542	Cost: 29.46s
Train Epoch: 1018 [20480/90000 (23%)]	Loss: -13.3116	Cost: 14.70s
Train Epoch: 1018 [40960/90000 (45%)]	Loss: -12.6856	Cost: 16.97s
Train Epoch: 1018 [61440/90000 (68%)]	Loss: -13.0320	Cost: 15.76s
Train Epoch: 1018 [81920/90000 (91%)]	Loss: -12.7498	Cost: 17.74s
Train Epoch: 1018 	Average Loss: -12.6249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5803

Learning rate: 0.00019994886381921899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1019 [0/90000 (0%)]	Loss: -7.1263	Cost: 28.32s
Train Epoch: 1019 [20480/90000 (23%)]	Loss: -13.1821	Cost: 13.28s
Train Epoch: 1019 [40960/90000 (45%)]	Loss: -12.3993	Cost: 16.44s
Train Epoch: 1019 [61440/90000 (68%)]	Loss: -13.0348	Cost: 15.70s
Train Epoch: 1019 [81920/90000 (91%)]	Loss: -13.2919	Cost: 19.48s
Train Epoch: 1019 	Average Loss: -12.5928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9718

Saving model as e1019_model.pt & e1019_waveforms_supplementary.hdf5
Learning rate: 0.00019994876331444993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1020 [0/90000 (0%)]	Loss: -7.6859	Cost: 32.57s
Train Epoch: 1020 [20480/90000 (23%)]	Loss: -13.5440	Cost: 14.93s
Train Epoch: 1020 [40960/90000 (45%)]	Loss: -12.6837	Cost: 15.43s
Train Epoch: 1020 [61440/90000 (68%)]	Loss: -13.0972	Cost: 15.35s
Train Epoch: 1020 [81920/90000 (91%)]	Loss: -13.0673	Cost: 13.99s
Train Epoch: 1020 	Average Loss: -12.8471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8095

Learning rate: 0.0001999486627110354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1021 [0/90000 (0%)]	Loss: -7.8049	Cost: 32.26s
Train Epoch: 1021 [20480/90000 (23%)]	Loss: -13.3381	Cost: 14.57s
Train Epoch: 1021 [40960/90000 (45%)]	Loss: -12.8039	Cost: 13.98s
Train Epoch: 1021 [61440/90000 (68%)]	Loss: -13.1441	Cost: 15.04s
Train Epoch: 1021 [81920/90000 (91%)]	Loss: -13.1702	Cost: 14.95s
Train Epoch: 1021 	Average Loss: -12.7317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8882

Learning rate: 0.00019994856200897552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1022 [0/90000 (0%)]	Loss: -6.7448	Cost: 28.89s
Train Epoch: 1022 [20480/90000 (23%)]	Loss: -13.2919	Cost: 13.64s
Train Epoch: 1022 [40960/90000 (45%)]	Loss: -12.7294	Cost: 16.51s
Train Epoch: 1022 [61440/90000 (68%)]	Loss: -13.2793	Cost: 14.98s
Train Epoch: 1022 [81920/90000 (91%)]	Loss: -13.2863	Cost: 21.71s
Train Epoch: 1022 	Average Loss: -12.7800
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0533

Saving model as e1022_model.pt & e1022_waveforms_supplementary.hdf5
Learning rate: 0.00019994846120827034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1023 [0/90000 (0%)]	Loss: -7.9255	Cost: 36.09s
Train Epoch: 1023 [20480/90000 (23%)]	Loss: -13.4820	Cost: 13.98s
Train Epoch: 1023 [40960/90000 (45%)]	Loss: -12.6964	Cost: 15.23s
Train Epoch: 1023 [61440/90000 (68%)]	Loss: -11.8512	Cost: 14.20s
Train Epoch: 1023 [81920/90000 (91%)]	Loss: -11.7089	Cost: 12.09s
Train Epoch: 1023 	Average Loss: -12.3230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8432

Learning rate: 0.00019994836030891997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1024 [0/90000 (0%)]	Loss: -6.8226	Cost: 45.19s
Train Epoch: 1024 [20480/90000 (23%)]	Loss: -12.6705	Cost: 12.39s
Train Epoch: 1024 [40960/90000 (45%)]	Loss: -12.2214	Cost: 17.91s
Train Epoch: 1024 [61440/90000 (68%)]	Loss: -12.8335	Cost: 12.24s
Train Epoch: 1024 [81920/90000 (91%)]	Loss: -13.1213	Cost: 12.00s
Train Epoch: 1024 	Average Loss: -12.3403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9709

Learning rate: 0.00019994825931092452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1025 [0/90000 (0%)]	Loss: -7.6407	Cost: 31.74s
Train Epoch: 1025 [20480/90000 (23%)]	Loss: -13.4127	Cost: 14.00s
Train Epoch: 1025 [40960/90000 (45%)]	Loss: -12.9177	Cost: 15.25s
Train Epoch: 1025 [61440/90000 (68%)]	Loss: -13.3475	Cost: 14.79s
Train Epoch: 1025 [81920/90000 (91%)]	Loss: -13.3739	Cost: 15.44s
Train Epoch: 1025 	Average Loss: -12.9113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1326

Saving model as e1025_model.pt & e1025_waveforms_supplementary.hdf5
Learning rate: 0.00019994815821428413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1026 [0/90000 (0%)]	Loss: -8.2654	Cost: 29.34s
Train Epoch: 1026 [20480/90000 (23%)]	Loss: -13.1670	Cost: 14.20s
Train Epoch: 1026 [40960/90000 (45%)]	Loss: -12.4046	Cost: 18.38s
Train Epoch: 1026 [61440/90000 (68%)]	Loss: -12.8872	Cost: 15.37s
Train Epoch: 1026 [81920/90000 (91%)]	Loss: -12.9804	Cost: 15.64s
Train Epoch: 1026 	Average Loss: -12.6025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8307

Learning rate: 0.00019994805701899885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1027 [0/90000 (0%)]	Loss: -7.3900	Cost: 27.99s
Train Epoch: 1027 [20480/90000 (23%)]	Loss: -13.4366	Cost: 11.84s
Train Epoch: 1027 [40960/90000 (45%)]	Loss: -12.8047	Cost: 17.19s
Train Epoch: 1027 [61440/90000 (68%)]	Loss: -13.2193	Cost: 14.29s
Train Epoch: 1027 [81920/90000 (91%)]	Loss: -13.3796	Cost: 17.29s
Train Epoch: 1027 	Average Loss: -12.8524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1714

Saving model as e1027_model.pt & e1027_waveforms_supplementary.hdf5
Learning rate: 0.0001999479557250688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1028 [0/90000 (0%)]	Loss: -8.0313	Cost: 35.79s
Train Epoch: 1028 [20480/90000 (23%)]	Loss: -13.6031	Cost: 14.68s
Train Epoch: 1028 [40960/90000 (45%)]	Loss: -12.6545	Cost: 14.45s
Train Epoch: 1028 [61440/90000 (68%)]	Loss: -13.3408	Cost: 14.18s
Train Epoch: 1028 [81920/90000 (91%)]	Loss: -13.2211	Cost: 10.74s
Train Epoch: 1028 	Average Loss: -12.9137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0932

Learning rate: 0.00019994785433249406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1029 [0/90000 (0%)]	Loss: -7.7925	Cost: 34.56s
Train Epoch: 1029 [20480/90000 (23%)]	Loss: -13.3668	Cost: 15.28s
Train Epoch: 1029 [40960/90000 (45%)]	Loss: -12.8212	Cost: 14.47s
Train Epoch: 1029 [61440/90000 (68%)]	Loss: -13.3755	Cost: 15.41s
Train Epoch: 1029 [81920/90000 (91%)]	Loss: -13.4173	Cost: 12.65s
Train Epoch: 1029 	Average Loss: -12.9097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1528

Learning rate: 0.00019994775284127474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1030 [0/90000 (0%)]	Loss: -7.9377	Cost: 37.89s
Train Epoch: 1030 [20480/90000 (23%)]	Loss: -13.4553	Cost: 13.54s
Train Epoch: 1030 [40960/90000 (45%)]	Loss: -12.8965	Cost: 16.08s
Train Epoch: 1030 [61440/90000 (68%)]	Loss: -13.1714	Cost: 15.33s
Train Epoch: 1030 [81920/90000 (91%)]	Loss: -13.1539	Cost: 13.17s
Train Epoch: 1030 	Average Loss: -12.9018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0659

Learning rate: 0.00019994765125141094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1031 [0/90000 (0%)]	Loss: -8.2687	Cost: 35.75s
Train Epoch: 1031 [20480/90000 (23%)]	Loss: -13.4819	Cost: 14.70s
Train Epoch: 1031 [40960/90000 (45%)]	Loss: -12.8516	Cost: 16.03s
Train Epoch: 1031 [61440/90000 (68%)]	Loss: -13.3703	Cost: 15.30s
Train Epoch: 1031 [81920/90000 (91%)]	Loss: -13.0316	Cost: 14.66s
Train Epoch: 1031 	Average Loss: -12.9434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7314

Learning rate: 0.00019994754956290274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1032 [0/90000 (0%)]	Loss: -8.3029	Cost: 37.34s
Train Epoch: 1032 [20480/90000 (23%)]	Loss: -13.2547	Cost: 14.74s
Train Epoch: 1032 [40960/90000 (45%)]	Loss: -12.6039	Cost: 23.43s
Train Epoch: 1032 [61440/90000 (68%)]	Loss: -13.1770	Cost: 14.22s
Train Epoch: 1032 [81920/90000 (91%)]	Loss: -13.3939	Cost: 10.66s
Train Epoch: 1032 	Average Loss: -12.8044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1500

Learning rate: 0.0001999474477757503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1033 [0/90000 (0%)]	Loss: -7.6471	Cost: 33.49s
Train Epoch: 1033 [20480/90000 (23%)]	Loss: -13.7269	Cost: 14.56s
Train Epoch: 1033 [40960/90000 (45%)]	Loss: -12.9996	Cost: 16.44s
Train Epoch: 1033 [61440/90000 (68%)]	Loss: -13.5928	Cost: 15.44s
Train Epoch: 1033 [81920/90000 (91%)]	Loss: -13.5235	Cost: 12.72s
Train Epoch: 1033 	Average Loss: -13.1584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2686

Saving model as e1033_model.pt & e1033_waveforms_supplementary.hdf5
Learning rate: 0.00019994734588995366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1034 [0/90000 (0%)]	Loss: -7.8806	Cost: 30.10s
Train Epoch: 1034 [20480/90000 (23%)]	Loss: -13.7193	Cost: 14.02s
Train Epoch: 1034 [40960/90000 (45%)]	Loss: -13.2008	Cost: 14.75s
Train Epoch: 1034 [61440/90000 (68%)]	Loss: -13.5556	Cost: 14.32s
Train Epoch: 1034 [81920/90000 (91%)]	Loss: -13.5501	Cost: 17.00s
Train Epoch: 1034 	Average Loss: -13.1630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1954

Learning rate: 0.00019994724390551296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1035 [0/90000 (0%)]	Loss: -8.1181	Cost: 28.34s
Train Epoch: 1035 [20480/90000 (23%)]	Loss: -13.4899	Cost: 13.93s
Train Epoch: 1035 [40960/90000 (45%)]	Loss: -13.0173	Cost: 17.17s
Train Epoch: 1035 [61440/90000 (68%)]	Loss: -13.6146	Cost: 15.03s
Train Epoch: 1035 [81920/90000 (91%)]	Loss: -13.6697	Cost: 19.05s
Train Epoch: 1035 	Average Loss: -13.1285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2894

Saving model as e1035_model.pt & e1035_waveforms_supplementary.hdf5
Learning rate: 0.00019994714182242827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1036 [0/90000 (0%)]	Loss: -7.6489	Cost: 29.04s
Train Epoch: 1036 [20480/90000 (23%)]	Loss: -13.6273	Cost: 14.57s
Train Epoch: 1036 [40960/90000 (45%)]	Loss: -13.1413	Cost: 17.65s
Train Epoch: 1036 [61440/90000 (68%)]	Loss: -13.7660	Cost: 14.72s
Train Epoch: 1036 [81920/90000 (91%)]	Loss: -13.3617	Cost: 14.24s
Train Epoch: 1036 	Average Loss: -13.2009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1894

Learning rate: 0.0001999470396406997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1037 [0/90000 (0%)]	Loss: -7.7256	Cost: 28.94s
Train Epoch: 1037 [20480/90000 (23%)]	Loss: -13.6706	Cost: 10.69s
Train Epoch: 1037 [40960/90000 (45%)]	Loss: -13.1344	Cost: 15.64s
Train Epoch: 1037 [61440/90000 (68%)]	Loss: -13.7388	Cost: 14.46s
Train Epoch: 1037 [81920/90000 (91%)]	Loss: -13.7654	Cost: 16.22s
Train Epoch: 1037 	Average Loss: -13.2304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2201

Learning rate: 0.00019994693736032738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1038 [0/90000 (0%)]	Loss: -8.1762	Cost: 28.45s
Train Epoch: 1038 [20480/90000 (23%)]	Loss: -13.6369	Cost: 11.54s
Train Epoch: 1038 [40960/90000 (45%)]	Loss: -12.5509	Cost: 14.73s
Train Epoch: 1038 [61440/90000 (68%)]	Loss: -13.2170	Cost: 14.04s
Train Epoch: 1038 [81920/90000 (91%)]	Loss: -13.1961	Cost: 14.53s
Train Epoch: 1038 	Average Loss: -12.8494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0239

Learning rate: 0.00019994683498131136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1039 [0/90000 (0%)]	Loss: -7.1506	Cost: 32.85s
Train Epoch: 1039 [20480/90000 (23%)]	Loss: -13.3677	Cost: 9.45s
Train Epoch: 1039 [40960/90000 (45%)]	Loss: -13.0310	Cost: 14.51s
Train Epoch: 1039 [61440/90000 (68%)]	Loss: -13.5146	Cost: 14.68s
Train Epoch: 1039 [81920/90000 (91%)]	Loss: -13.5490	Cost: 14.79s
Train Epoch: 1039 	Average Loss: -13.0408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1275

Learning rate: 0.0001999467325036518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1040 [0/90000 (0%)]	Loss: -7.5952	Cost: 30.33s
Train Epoch: 1040 [20480/90000 (23%)]	Loss: -13.6566	Cost: 9.31s
Train Epoch: 1040 [40960/90000 (45%)]	Loss: -12.7898	Cost: 14.95s
Train Epoch: 1040 [61440/90000 (68%)]	Loss: -13.4067	Cost: 14.46s
Train Epoch: 1040 [81920/90000 (91%)]	Loss: -13.4994	Cost: 14.55s
Train Epoch: 1040 	Average Loss: -13.0087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2508

Learning rate: 0.00019994662992734875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1041 [0/90000 (0%)]	Loss: -8.1488	Cost: 31.20s
Train Epoch: 1041 [20480/90000 (23%)]	Loss: -13.8824	Cost: 10.99s
Train Epoch: 1041 [40960/90000 (45%)]	Loss: -13.2799	Cost: 14.64s
Train Epoch: 1041 [61440/90000 (68%)]	Loss: -13.8923	Cost: 14.27s
Train Epoch: 1041 [81920/90000 (91%)]	Loss: -13.4047	Cost: 15.06s
Train Epoch: 1041 	Average Loss: -13.2303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2452

Learning rate: 0.00019994652725240233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1042 [0/90000 (0%)]	Loss: -8.1121	Cost: 28.18s
Train Epoch: 1042 [20480/90000 (23%)]	Loss: -13.8025	Cost: 9.48s
Train Epoch: 1042 [40960/90000 (45%)]	Loss: -13.0078	Cost: 13.68s
Train Epoch: 1042 [61440/90000 (68%)]	Loss: -13.6030	Cost: 13.38s
Train Epoch: 1042 [81920/90000 (91%)]	Loss: -13.3097	Cost: 12.30s
Train Epoch: 1042 	Average Loss: -13.1094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0724

Learning rate: 0.00019994642447881264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1043 [0/90000 (0%)]	Loss: -6.5952	Cost: 35.32s
Train Epoch: 1043 [20480/90000 (23%)]	Loss: -13.5279	Cost: 9.73s
Train Epoch: 1043 [40960/90000 (45%)]	Loss: -13.0884	Cost: 12.86s
Train Epoch: 1043 [61440/90000 (68%)]	Loss: -13.6284	Cost: 12.07s
Train Epoch: 1043 [81920/90000 (91%)]	Loss: -13.7374	Cost: 11.98s
Train Epoch: 1043 	Average Loss: -13.0320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2779

Learning rate: 0.00019994632160657977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1044 [0/90000 (0%)]	Loss: -7.9145	Cost: 32.08s
Train Epoch: 1044 [20480/90000 (23%)]	Loss: -13.8015	Cost: 8.61s
Train Epoch: 1044 [40960/90000 (45%)]	Loss: -13.3670	Cost: 14.00s
Train Epoch: 1044 [61440/90000 (68%)]	Loss: -13.7475	Cost: 10.53s
Train Epoch: 1044 [81920/90000 (91%)]	Loss: -13.6930	Cost: 12.23s
Train Epoch: 1044 	Average Loss: -13.3343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3148

Saving model as e1044_model.pt & e1044_waveforms_supplementary.hdf5
Learning rate: 0.00019994621863570386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1045 [0/90000 (0%)]	Loss: -8.3752	Cost: 26.53s
Train Epoch: 1045 [20480/90000 (23%)]	Loss: -13.9935	Cost: 9.05s
Train Epoch: 1045 [40960/90000 (45%)]	Loss: -13.2013	Cost: 17.55s
Train Epoch: 1045 [61440/90000 (68%)]	Loss: -13.6366	Cost: 9.61s
Train Epoch: 1045 [81920/90000 (91%)]	Loss: -13.8199	Cost: 12.88s
Train Epoch: 1045 	Average Loss: -13.3102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5909

Learning rate: 0.00019994611556618498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1046 [0/90000 (0%)]	Loss: -7.6843	Cost: 24.86s
Train Epoch: 1046 [20480/90000 (23%)]	Loss: -12.7290	Cost: 8.79s
Train Epoch: 1046 [40960/90000 (45%)]	Loss: -12.4851	Cost: 14.39s
Train Epoch: 1046 [61440/90000 (68%)]	Loss: -13.1941	Cost: 12.71s
Train Epoch: 1046 [81920/90000 (91%)]	Loss: -13.4710	Cost: 13.52s
Train Epoch: 1046 	Average Loss: -12.4897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2185

Learning rate: 0.00019994601239802325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1047 [0/90000 (0%)]	Loss: -8.4581	Cost: 27.09s
Train Epoch: 1047 [20480/90000 (23%)]	Loss: -13.5905	Cost: 10.28s
Train Epoch: 1047 [40960/90000 (45%)]	Loss: -12.9756	Cost: 17.22s
Train Epoch: 1047 [61440/90000 (68%)]	Loss: -13.3039	Cost: 8.54s
Train Epoch: 1047 [81920/90000 (91%)]	Loss: -13.7070	Cost: 14.36s
Train Epoch: 1047 	Average Loss: -13.1010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4359

Saving model as e1047_model.pt & e1047_waveforms_supplementary.hdf5
Learning rate: 0.00019994590913121875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1048 [0/90000 (0%)]	Loss: -8.4558	Cost: 29.81s
Train Epoch: 1048 [20480/90000 (23%)]	Loss: -13.7298	Cost: 10.25s
Train Epoch: 1048 [40960/90000 (45%)]	Loss: -13.0333	Cost: 17.25s
Train Epoch: 1048 [61440/90000 (68%)]	Loss: -13.5868	Cost: 8.04s
Train Epoch: 1048 [81920/90000 (91%)]	Loss: -13.6784	Cost: 16.36s
Train Epoch: 1048 	Average Loss: -13.2434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4322

Learning rate: 0.0001999458057657716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1049 [0/90000 (0%)]	Loss: -7.5219	Cost: 31.49s
Train Epoch: 1049 [20480/90000 (23%)]	Loss: -14.0707	Cost: 10.29s
Train Epoch: 1049 [40960/90000 (45%)]	Loss: -13.4009	Cost: 14.71s
Train Epoch: 1049 [61440/90000 (68%)]	Loss: -13.7323	Cost: 8.17s
Train Epoch: 1049 [81920/90000 (91%)]	Loss: -13.8067	Cost: 15.01s
Train Epoch: 1049 	Average Loss: -13.4083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2954

Learning rate: 0.00019994570230168185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1050 [0/90000 (0%)]	Loss: -7.4352	Cost: 36.09s
Train Epoch: 1050 [20480/90000 (23%)]	Loss: -14.0524	Cost: 8.86s
Train Epoch: 1050 [40960/90000 (45%)]	Loss: -13.3121	Cost: 16.33s
Train Epoch: 1050 [61440/90000 (68%)]	Loss: -13.8723	Cost: 10.00s
Train Epoch: 1050 [81920/90000 (91%)]	Loss: -13.8801	Cost: 12.16s
Train Epoch: 1050 	Average Loss: -13.3825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5105

Saving model as e1050_model.pt & e1050_waveforms_supplementary.hdf5
Learning rate: 0.00019994559873894968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1051 [0/90000 (0%)]	Loss: -7.8657	Cost: 30.37s
Train Epoch: 1051 [20480/90000 (23%)]	Loss: -14.1480	Cost: 6.48s
Train Epoch: 1051 [40960/90000 (45%)]	Loss: -13.5191	Cost: 11.29s
Train Epoch: 1051 [61440/90000 (68%)]	Loss: -13.7777	Cost: 12.35s
Train Epoch: 1051 [81920/90000 (91%)]	Loss: -13.9314	Cost: 11.96s
Train Epoch: 1051 	Average Loss: -13.4755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4664

Learning rate: 0.00019994549507757517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1052 [0/90000 (0%)]	Loss: -7.8187	Cost: 30.41s
Train Epoch: 1052 [20480/90000 (23%)]	Loss: -13.9523	Cost: 7.99s
Train Epoch: 1052 [40960/90000 (45%)]	Loss: -13.3000	Cost: 11.65s
Train Epoch: 1052 [61440/90000 (68%)]	Loss: -13.6613	Cost: 9.12s
Train Epoch: 1052 [81920/90000 (91%)]	Loss: -13.9399	Cost: 13.24s
Train Epoch: 1052 	Average Loss: -13.3642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5952

Saving model as e1052_model.pt & e1052_waveforms_supplementary.hdf5
Learning rate: 0.0001999453913175584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1053 [0/90000 (0%)]	Loss: -8.8197	Cost: 37.74s
Train Epoch: 1053 [20480/90000 (23%)]	Loss: -14.0284	Cost: 8.14s
Train Epoch: 1053 [40960/90000 (45%)]	Loss: -13.5336	Cost: 12.12s
Train Epoch: 1053 [61440/90000 (68%)]	Loss: -14.0777	Cost: 8.58s
Train Epoch: 1053 [81920/90000 (91%)]	Loss: -13.8520	Cost: 13.93s
Train Epoch: 1053 	Average Loss: -13.5673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4957

Learning rate: 0.00019994528745889947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1054 [0/90000 (0%)]	Loss: -8.3910	Cost: 33.68s
Train Epoch: 1054 [20480/90000 (23%)]	Loss: -13.8828	Cost: 6.58s
Train Epoch: 1054 [40960/90000 (45%)]	Loss: -13.2325	Cost: 9.74s
Train Epoch: 1054 [61440/90000 (68%)]	Loss: -13.6087	Cost: 6.10s
Train Epoch: 1054 [81920/90000 (91%)]	Loss: -13.5447	Cost: 16.27s
Train Epoch: 1054 	Average Loss: -13.3727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2305

Learning rate: 0.0001999451835015985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1055 [0/90000 (0%)]	Loss: -7.5842	Cost: 26.12s
Train Epoch: 1055 [20480/90000 (23%)]	Loss: -13.7108	Cost: 6.87s
Train Epoch: 1055 [40960/90000 (45%)]	Loss: -13.3405	Cost: 10.28s
Train Epoch: 1055 [61440/90000 (68%)]	Loss: -13.8584	Cost: 6.60s
Train Epoch: 1055 [81920/90000 (91%)]	Loss: -13.6859	Cost: 16.24s
Train Epoch: 1055 	Average Loss: -13.3416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3733

Learning rate: 0.0001999450794456556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1056 [0/90000 (0%)]	Loss: -8.2441	Cost: 23.48s
Train Epoch: 1056 [20480/90000 (23%)]	Loss: -14.1288	Cost: 8.66s
Train Epoch: 1056 [40960/90000 (45%)]	Loss: -13.1370	Cost: 16.09s
Train Epoch: 1056 [61440/90000 (68%)]	Loss: -13.6675	Cost: 9.70s
Train Epoch: 1056 [81920/90000 (91%)]	Loss: -13.6629	Cost: 14.17s
Train Epoch: 1056 	Average Loss: -13.2997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4120

Learning rate: 0.00019994497529107083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1057 [0/90000 (0%)]	Loss: -7.7565	Cost: 24.31s
Train Epoch: 1057 [20480/90000 (23%)]	Loss: -14.0245	Cost: 8.81s
Train Epoch: 1057 [40960/90000 (45%)]	Loss: -13.5489	Cost: 17.91s
Train Epoch: 1057 [61440/90000 (68%)]	Loss: -14.0093	Cost: 12.34s
Train Epoch: 1057 [81920/90000 (91%)]	Loss: -13.7416	Cost: 12.10s
Train Epoch: 1057 	Average Loss: -13.5075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4802

Learning rate: 0.00019994487103784436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1058 [0/90000 (0%)]	Loss: -8.1765	Cost: 33.91s
Train Epoch: 1058 [20480/90000 (23%)]	Loss: -13.5688	Cost: 8.93s
Train Epoch: 1058 [40960/90000 (45%)]	Loss: -13.0448	Cost: 11.23s
Train Epoch: 1058 [61440/90000 (68%)]	Loss: -13.8199	Cost: 9.31s
Train Epoch: 1058 [81920/90000 (91%)]	Loss: -13.5741	Cost: 12.17s
Train Epoch: 1058 	Average Loss: -13.1857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3420

Learning rate: 0.00019994476668597623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1059 [0/90000 (0%)]	Loss: -7.8704	Cost: 26.31s
Train Epoch: 1059 [20480/90000 (23%)]	Loss: -13.9138	Cost: 7.35s
Train Epoch: 1059 [40960/90000 (45%)]	Loss: -13.4557	Cost: 12.13s
Train Epoch: 1059 [61440/90000 (68%)]	Loss: -13.9737	Cost: 11.98s
Train Epoch: 1059 [81920/90000 (91%)]	Loss: -13.9451	Cost: 11.95s
Train Epoch: 1059 	Average Loss: -13.4539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5032

Learning rate: 0.00019994466223546657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1060 [0/90000 (0%)]	Loss: -8.0283	Cost: 24.61s
Train Epoch: 1060 [20480/90000 (23%)]	Loss: -13.7460	Cost: 7.79s
Train Epoch: 1060 [40960/90000 (45%)]	Loss: -13.1475	Cost: 11.72s
Train Epoch: 1060 [61440/90000 (68%)]	Loss: -13.7270	Cost: 11.69s
Train Epoch: 1060 [81920/90000 (91%)]	Loss: -13.5212	Cost: 12.46s
Train Epoch: 1060 	Average Loss: -13.2852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2017

Learning rate: 0.0001999445576863155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1061 [0/90000 (0%)]	Loss: -7.9612	Cost: 27.02s
Train Epoch: 1061 [20480/90000 (23%)]	Loss: -13.8379	Cost: 8.04s
Train Epoch: 1061 [40960/90000 (45%)]	Loss: -13.3203	Cost: 13.08s
Train Epoch: 1061 [61440/90000 (68%)]	Loss: -13.8815	Cost: 12.19s
Train Epoch: 1061 [81920/90000 (91%)]	Loss: -14.0957	Cost: 12.07s
Train Epoch: 1061 	Average Loss: -13.4506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7646

Saving model as e1061_model.pt & e1061_waveforms_supplementary.hdf5
Learning rate: 0.0001999444530385231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1062 [0/90000 (0%)]	Loss: -8.0066	Cost: 29.73s
Train Epoch: 1062 [20480/90000 (23%)]	Loss: -14.1409	Cost: 8.75s
Train Epoch: 1062 [40960/90000 (45%)]	Loss: -13.5547	Cost: 13.55s
Train Epoch: 1062 [61440/90000 (68%)]	Loss: -13.7665	Cost: 12.14s
Train Epoch: 1062 [81920/90000 (91%)]	Loss: -13.4110	Cost: 11.92s
Train Epoch: 1062 	Average Loss: -13.5271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1631

Learning rate: 0.00019994434829208945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1063 [0/90000 (0%)]	Loss: -7.5836	Cost: 30.31s
Train Epoch: 1063 [20480/90000 (23%)]	Loss: -13.4562	Cost: 7.96s
Train Epoch: 1063 [40960/90000 (45%)]	Loss: -12.8749	Cost: 13.59s
Train Epoch: 1063 [61440/90000 (68%)]	Loss: -13.2939	Cost: 12.14s
Train Epoch: 1063 [81920/90000 (91%)]	Loss: -13.7199	Cost: 12.40s
Train Epoch: 1063 	Average Loss: -13.0871
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5062

Learning rate: 0.0001999442434470147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1064 [0/90000 (0%)]	Loss: -8.2157	Cost: 29.54s
Train Epoch: 1064 [20480/90000 (23%)]	Loss: -14.0377	Cost: 6.18s
Train Epoch: 1064 [40960/90000 (45%)]	Loss: -13.7771	Cost: 11.90s
Train Epoch: 1064 [61440/90000 (68%)]	Loss: -14.0782	Cost: 13.75s
Train Epoch: 1064 [81920/90000 (91%)]	Loss: -13.9695	Cost: 13.50s
Train Epoch: 1064 	Average Loss: -13.5624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5949

Learning rate: 0.00019994413850329894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1065 [0/90000 (0%)]	Loss: -8.3556	Cost: 30.13s
Train Epoch: 1065 [20480/90000 (23%)]	Loss: -13.6742	Cost: 11.27s
Train Epoch: 1065 [40960/90000 (45%)]	Loss: -13.2697	Cost: 15.61s
Train Epoch: 1065 [61440/90000 (68%)]	Loss: -13.8008	Cost: 13.23s
Train Epoch: 1065 [81920/90000 (91%)]	Loss: -13.9552	Cost: 12.20s
Train Epoch: 1065 	Average Loss: -13.3714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8089

Saving model as e1065_model.pt & e1065_waveforms_supplementary.hdf5
Learning rate: 0.0001999440334609423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1066 [0/90000 (0%)]	Loss: -8.7579	Cost: 46.37s
Train Epoch: 1066 [20480/90000 (23%)]	Loss: -14.2800	Cost: 12.02s
Train Epoch: 1066 [40960/90000 (45%)]	Loss: -13.7793	Cost: 12.29s
Train Epoch: 1066 [61440/90000 (68%)]	Loss: -13.7854	Cost: 11.94s
Train Epoch: 1066 [81920/90000 (91%)]	Loss: -13.9603	Cost: 11.91s
Train Epoch: 1066 	Average Loss: -13.6115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5174

Learning rate: 0.0001999439283199448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1067 [0/90000 (0%)]	Loss: -8.2458	Cost: 33.61s
Train Epoch: 1067 [20480/90000 (23%)]	Loss: -13.9765	Cost: 8.68s
Train Epoch: 1067 [40960/90000 (45%)]	Loss: -13.3958	Cost: 13.15s
Train Epoch: 1067 [61440/90000 (68%)]	Loss: -13.9666	Cost: 12.10s
Train Epoch: 1067 [81920/90000 (91%)]	Loss: -13.8413	Cost: 12.05s
Train Epoch: 1067 	Average Loss: -13.5061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5445

Learning rate: 0.0001999438230803066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1068 [0/90000 (0%)]	Loss: -8.2096	Cost: 37.17s
Train Epoch: 1068 [20480/90000 (23%)]	Loss: -14.0917	Cost: 13.16s
Train Epoch: 1068 [40960/90000 (45%)]	Loss: -13.5571	Cost: 12.40s
Train Epoch: 1068 [61440/90000 (68%)]	Loss: -14.0582	Cost: 11.88s
Train Epoch: 1068 [81920/90000 (91%)]	Loss: -14.0886	Cost: 12.11s
Train Epoch: 1068 	Average Loss: -13.6234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7359

Learning rate: 0.00019994371774202785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1069 [0/90000 (0%)]	Loss: -8.2782	Cost: 29.77s
Train Epoch: 1069 [20480/90000 (23%)]	Loss: -14.1382	Cost: 10.66s
Train Epoch: 1069 [40960/90000 (45%)]	Loss: -13.6220	Cost: 13.26s
Train Epoch: 1069 [61440/90000 (68%)]	Loss: -14.1396	Cost: 12.89s
Train Epoch: 1069 [81920/90000 (91%)]	Loss: -14.1078	Cost: 12.31s
Train Epoch: 1069 	Average Loss: -13.6583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6200

Learning rate: 0.00019994361230510856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1070 [0/90000 (0%)]	Loss: -8.4006	Cost: 26.84s
Train Epoch: 1070 [20480/90000 (23%)]	Loss: -14.2690	Cost: 9.09s
Train Epoch: 1070 [40960/90000 (45%)]	Loss: -13.5319	Cost: 18.63s
Train Epoch: 1070 [61440/90000 (68%)]	Loss: -14.1196	Cost: 12.95s
Train Epoch: 1070 [81920/90000 (91%)]	Loss: -14.2099	Cost: 12.37s
Train Epoch: 1070 	Average Loss: -13.6928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8399

Saving model as e1070_model.pt & e1070_waveforms_supplementary.hdf5
Learning rate: 0.00019994350676954888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1071 [0/90000 (0%)]	Loss: -8.0123	Cost: 31.93s
Train Epoch: 1071 [20480/90000 (23%)]	Loss: -14.1813	Cost: 15.04s
Train Epoch: 1071 [40960/90000 (45%)]	Loss: -13.3948	Cost: 14.77s
Train Epoch: 1071 [61440/90000 (68%)]	Loss: -14.0078	Cost: 12.95s
Train Epoch: 1071 [81920/90000 (91%)]	Loss: -14.0445	Cost: 12.00s
Train Epoch: 1071 	Average Loss: -13.6145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7920

Learning rate: 0.0001999434011353489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1072 [0/90000 (0%)]	Loss: -8.4330	Cost: 51.06s
Train Epoch: 1072 [20480/90000 (23%)]	Loss: -14.3799	Cost: 8.18s
Train Epoch: 1072 [40960/90000 (45%)]	Loss: -13.7675	Cost: 11.97s
Train Epoch: 1072 [61440/90000 (68%)]	Loss: -13.9796	Cost: 12.15s
Train Epoch: 1072 [81920/90000 (91%)]	Loss: -13.9606	Cost: 11.97s
Train Epoch: 1072 	Average Loss: -13.6654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6669

Learning rate: 0.00019994329540250878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1073 [0/90000 (0%)]	Loss: -8.2625	Cost: 31.37s
Train Epoch: 1073 [20480/90000 (23%)]	Loss: -14.0730	Cost: 6.29s
Train Epoch: 1073 [40960/90000 (45%)]	Loss: -13.6688	Cost: 13.38s
Train Epoch: 1073 [61440/90000 (68%)]	Loss: -14.0068	Cost: 12.06s
Train Epoch: 1073 [81920/90000 (91%)]	Loss: -14.0146	Cost: 12.12s
Train Epoch: 1073 	Average Loss: -13.6626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6465

Learning rate: 0.00019994318957102856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1074 [0/90000 (0%)]	Loss: -8.4262	Cost: 27.21s
Train Epoch: 1074 [20480/90000 (23%)]	Loss: -14.1627	Cost: 8.55s
Train Epoch: 1074 [40960/90000 (45%)]	Loss: -13.5629	Cost: 16.25s
Train Epoch: 1074 [61440/90000 (68%)]	Loss: -14.1204	Cost: 12.38s
Train Epoch: 1074 [81920/90000 (91%)]	Loss: -14.1909	Cost: 12.18s
Train Epoch: 1074 	Average Loss: -13.7174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6840

Learning rate: 0.00019994308364090836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1075 [0/90000 (0%)]	Loss: -8.7039	Cost: 42.58s
Train Epoch: 1075 [20480/90000 (23%)]	Loss: -14.3875	Cost: 10.62s
Train Epoch: 1075 [40960/90000 (45%)]	Loss: -13.6259	Cost: 12.16s
Train Epoch: 1075 [61440/90000 (68%)]	Loss: -14.2821	Cost: 12.15s
Train Epoch: 1075 [81920/90000 (91%)]	Loss: -14.3363	Cost: 12.27s
Train Epoch: 1075 	Average Loss: -13.8023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9732

Saving model as e1075_model.pt & e1075_waveforms_supplementary.hdf5
Learning rate: 0.0001999429776121483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1076 [0/90000 (0%)]	Loss: -8.2275	Cost: 28.79s
Train Epoch: 1076 [20480/90000 (23%)]	Loss: -14.3270	Cost: 15.64s
Train Epoch: 1076 [40960/90000 (45%)]	Loss: -13.9434	Cost: 15.17s
Train Epoch: 1076 [61440/90000 (68%)]	Loss: -14.3890	Cost: 12.72s
Train Epoch: 1076 [81920/90000 (91%)]	Loss: -14.3612	Cost: 12.10s
Train Epoch: 1076 	Average Loss: -13.9539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9144

Learning rate: 0.0001999428714847485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1077 [0/90000 (0%)]	Loss: -8.4505	Cost: 31.96s
Train Epoch: 1077 [20480/90000 (23%)]	Loss: -14.6113	Cost: 13.39s
Train Epoch: 1077 [40960/90000 (45%)]	Loss: -13.7395	Cost: 18.75s
Train Epoch: 1077 [61440/90000 (68%)]	Loss: -14.2329	Cost: 12.33s
Train Epoch: 1077 [81920/90000 (91%)]	Loss: -14.0942	Cost: 11.94s
Train Epoch: 1077 	Average Loss: -13.8439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9200

Learning rate: 0.000199942765258709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1078 [0/90000 (0%)]	Loss: -8.7239	Cost: 53.24s
Train Epoch: 1078 [20480/90000 (23%)]	Loss: -14.4740	Cost: 11.27s
Train Epoch: 1078 [40960/90000 (45%)]	Loss: -13.6654	Cost: 12.18s
Train Epoch: 1078 [61440/90000 (68%)]	Loss: -14.3942	Cost: 12.04s
Train Epoch: 1078 [81920/90000 (91%)]	Loss: -14.2467	Cost: 12.06s
Train Epoch: 1078 	Average Loss: -13.8930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7130

Learning rate: 0.00019994265893402997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1079 [0/90000 (0%)]	Loss: -7.7937	Cost: 30.23s
Train Epoch: 1079 [20480/90000 (23%)]	Loss: -12.9089	Cost: 10.29s
Train Epoch: 1079 [40960/90000 (45%)]	Loss: -11.6661	Cost: 13.21s
Train Epoch: 1079 [61440/90000 (68%)]	Loss: -11.5915	Cost: 12.78s
Train Epoch: 1079 [81920/90000 (91%)]	Loss: -12.1159	Cost: 12.27s
Train Epoch: 1079 	Average Loss: -12.0190
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3853

Learning rate: 0.00019994255251071146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1080 [0/90000 (0%)]	Loss: -7.5658	Cost: 33.10s
Train Epoch: 1080 [20480/90000 (23%)]	Loss: -13.2666	Cost: 10.90s
Train Epoch: 1080 [40960/90000 (45%)]	Loss: -13.1592	Cost: 17.47s
Train Epoch: 1080 [61440/90000 (68%)]	Loss: -13.7748	Cost: 12.39s
Train Epoch: 1080 [81920/90000 (91%)]	Loss: -13.8254	Cost: 11.92s
Train Epoch: 1080 	Average Loss: -13.0626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5507

Learning rate: 0.00019994244598875362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1081 [0/90000 (0%)]	Loss: -8.1153	Cost: 49.45s
Train Epoch: 1081 [20480/90000 (23%)]	Loss: -14.1305	Cost: 9.25s
Train Epoch: 1081 [40960/90000 (45%)]	Loss: -12.6990	Cost: 12.13s
Train Epoch: 1081 [61440/90000 (68%)]	Loss: -13.4560	Cost: 12.18s
Train Epoch: 1081 [81920/90000 (91%)]	Loss: -13.7657	Cost: 12.23s
Train Epoch: 1081 	Average Loss: -13.2569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4374

Learning rate: 0.00019994233936815656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1082 [0/90000 (0%)]	Loss: -8.2221	Cost: 28.23s
Train Epoch: 1082 [20480/90000 (23%)]	Loss: -14.1329	Cost: 7.42s
Train Epoch: 1082 [40960/90000 (45%)]	Loss: -13.6700	Cost: 14.44s
Train Epoch: 1082 [61440/90000 (68%)]	Loss: -14.1187	Cost: 12.21s
Train Epoch: 1082 [81920/90000 (91%)]	Loss: -14.2394	Cost: 12.05s
Train Epoch: 1082 	Average Loss: -13.6512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7980

Learning rate: 0.00019994223264892036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1083 [0/90000 (0%)]	Loss: -8.2681	Cost: 45.31s
Train Epoch: 1083 [20480/90000 (23%)]	Loss: -14.4404	Cost: 12.37s
Train Epoch: 1083 [40960/90000 (45%)]	Loss: -13.6511	Cost: 12.11s
Train Epoch: 1083 [61440/90000 (68%)]	Loss: -14.3186	Cost: 11.95s
Train Epoch: 1083 [81920/90000 (91%)]	Loss: -14.2246	Cost: 11.87s
Train Epoch: 1083 	Average Loss: -13.8947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0015

Saving model as e1083_model.pt & e1083_waveforms_supplementary.hdf5
Learning rate: 0.0001999421258310451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1084 [0/90000 (0%)]	Loss: -8.8376	Cost: 28.20s
Train Epoch: 1084 [20480/90000 (23%)]	Loss: -14.5949	Cost: 12.05s
Train Epoch: 1084 [40960/90000 (45%)]	Loss: -13.8201	Cost: 12.45s
Train Epoch: 1084 [61440/90000 (68%)]	Loss: -14.2599	Cost: 12.17s
Train Epoch: 1084 [81920/90000 (91%)]	Loss: -14.3268	Cost: 12.08s
Train Epoch: 1084 	Average Loss: -13.8966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6799

Learning rate: 0.00019994201891453093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1085 [0/90000 (0%)]	Loss: -8.5715	Cost: 39.83s
Train Epoch: 1085 [20480/90000 (23%)]	Loss: -14.6704	Cost: 12.32s
Train Epoch: 1085 [40960/90000 (45%)]	Loss: -13.9305	Cost: 11.95s
Train Epoch: 1085 [61440/90000 (68%)]	Loss: -14.3389	Cost: 12.10s
Train Epoch: 1085 [81920/90000 (91%)]	Loss: -14.2503	Cost: 11.33s
Train Epoch: 1085 	Average Loss: -13.9200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9835

Learning rate: 0.00019994191189937795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1086 [0/90000 (0%)]	Loss: -8.2254	Cost: 35.96s
Train Epoch: 1086 [20480/90000 (23%)]	Loss: -14.6534	Cost: 7.80s
Train Epoch: 1086 [40960/90000 (45%)]	Loss: -13.7998	Cost: 12.19s
Train Epoch: 1086 [61440/90000 (68%)]	Loss: -14.4241	Cost: 12.13s
Train Epoch: 1086 [81920/90000 (91%)]	Loss: -14.4437	Cost: 11.83s
Train Epoch: 1086 	Average Loss: -13.9925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0977

Saving model as e1086_model.pt & e1086_waveforms_supplementary.hdf5
Learning rate: 0.00019994180478558626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1087 [0/90000 (0%)]	Loss: -8.8700	Cost: 28.02s
Train Epoch: 1087 [20480/90000 (23%)]	Loss: -14.6041	Cost: 14.42s
Train Epoch: 1087 [40960/90000 (45%)]	Loss: -13.8175	Cost: 14.99s
Train Epoch: 1087 [61440/90000 (68%)]	Loss: -14.4237	Cost: 12.00s
Train Epoch: 1087 [81920/90000 (91%)]	Loss: -14.5005	Cost: 11.90s
Train Epoch: 1087 	Average Loss: -14.0291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8336

Learning rate: 0.00019994169757315598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1088 [0/90000 (0%)]	Loss: -8.0511	Cost: 27.70s
Train Epoch: 1088 [20480/90000 (23%)]	Loss: -14.5133	Cost: 7.24s
Train Epoch: 1088 [40960/90000 (45%)]	Loss: -13.7873	Cost: 12.31s
Train Epoch: 1088 [61440/90000 (68%)]	Loss: -14.3230	Cost: 12.27s
Train Epoch: 1088 [81920/90000 (91%)]	Loss: -14.4536	Cost: 12.19s
Train Epoch: 1088 	Average Loss: -13.9098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9746

Learning rate: 0.00019994159026208715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1089 [0/90000 (0%)]	Loss: -8.5092	Cost: 28.98s
Train Epoch: 1089 [20480/90000 (23%)]	Loss: -14.6571	Cost: 8.76s
Train Epoch: 1089 [40960/90000 (45%)]	Loss: -13.9411	Cost: 8.89s
Train Epoch: 1089 [61440/90000 (68%)]	Loss: -14.4961	Cost: 8.16s
Train Epoch: 1089 [81920/90000 (91%)]	Loss: -14.2993	Cost: 12.17s
Train Epoch: 1089 	Average Loss: -14.0142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9216

Learning rate: 0.00019994148285237993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1090 [0/90000 (0%)]	Loss: -8.7286	Cost: 24.22s
Train Epoch: 1090 [20480/90000 (23%)]	Loss: -14.5690	Cost: 6.84s
Train Epoch: 1090 [40960/90000 (45%)]	Loss: -14.0079	Cost: 9.66s
Train Epoch: 1090 [61440/90000 (68%)]	Loss: -14.3956	Cost: 6.61s
Train Epoch: 1090 [81920/90000 (91%)]	Loss: -14.1663	Cost: 15.50s
Train Epoch: 1090 	Average Loss: -13.9831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8442

Learning rate: 0.00019994137534403445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1091 [0/90000 (0%)]	Loss: -8.4424	Cost: 24.30s
Train Epoch: 1091 [20480/90000 (23%)]	Loss: -14.6616	Cost: 7.48s
Train Epoch: 1091 [40960/90000 (45%)]	Loss: -13.6136	Cost: 12.42s
Train Epoch: 1091 [61440/90000 (68%)]	Loss: -13.9860	Cost: 7.88s
Train Epoch: 1091 [81920/90000 (91%)]	Loss: -14.0610	Cost: 12.19s
Train Epoch: 1091 	Average Loss: -13.7764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8779

Learning rate: 0.00019994126773705077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1092 [0/90000 (0%)]	Loss: -8.0961	Cost: 27.07s
Train Epoch: 1092 [20480/90000 (23%)]	Loss: -14.4568	Cost: 7.46s
Train Epoch: 1092 [40960/90000 (45%)]	Loss: -14.1095	Cost: 6.34s
Train Epoch: 1092 [61440/90000 (68%)]	Loss: -14.3314	Cost: 6.22s
Train Epoch: 1092 [81920/90000 (91%)]	Loss: -14.3860	Cost: 9.96s
Train Epoch: 1092 	Average Loss: -13.9676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1040

Saving model as e1092_model.pt & e1092_waveforms_supplementary.hdf5
Learning rate: 0.000199941160031429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1093 [0/90000 (0%)]	Loss: -8.4319	Cost: 24.05s
Train Epoch: 1093 [20480/90000 (23%)]	Loss: -14.7349	Cost: 9.44s
Train Epoch: 1093 [40960/90000 (45%)]	Loss: -12.8899	Cost: 9.28s
Train Epoch: 1093 [61440/90000 (68%)]	Loss: -13.8201	Cost: 7.82s
Train Epoch: 1093 [81920/90000 (91%)]	Loss: -14.1486	Cost: 11.18s
Train Epoch: 1093 	Average Loss: -13.5732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7135

Learning rate: 0.00019994105222716926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1094 [0/90000 (0%)]	Loss: -8.4591	Cost: 27.81s
Train Epoch: 1094 [20480/90000 (23%)]	Loss: -14.3325	Cost: 8.42s
Train Epoch: 1094 [40960/90000 (45%)]	Loss: -13.8923	Cost: 6.12s
Train Epoch: 1094 [61440/90000 (68%)]	Loss: -14.5136	Cost: 6.61s
Train Epoch: 1094 [81920/90000 (91%)]	Loss: -14.6256	Cost: 8.34s
Train Epoch: 1094 	Average Loss: -13.9641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0336

Learning rate: 0.00019994094432427168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1095 [0/90000 (0%)]	Loss: -8.9090	Cost: 25.20s
Train Epoch: 1095 [20480/90000 (23%)]	Loss: -14.4881	Cost: 9.14s
Train Epoch: 1095 [40960/90000 (45%)]	Loss: -13.9587	Cost: 9.46s
Train Epoch: 1095 [61440/90000 (68%)]	Loss: -14.0336	Cost: 6.33s
Train Epoch: 1095 [81920/90000 (91%)]	Loss: -14.1117	Cost: 11.01s
Train Epoch: 1095 	Average Loss: -13.8658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8546

Learning rate: 0.00019994083632273634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1096 [0/90000 (0%)]	Loss: -8.3159	Cost: 26.87s
Train Epoch: 1096 [20480/90000 (23%)]	Loss: -14.5143	Cost: 8.74s
Train Epoch: 1096 [40960/90000 (45%)]	Loss: -13.8028	Cost: 8.60s
Train Epoch: 1096 [61440/90000 (68%)]	Loss: -14.2279	Cost: 7.59s
Train Epoch: 1096 [81920/90000 (91%)]	Loss: -14.4202	Cost: 6.20s
Train Epoch: 1096 	Average Loss: -13.8428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0368

Learning rate: 0.00019994072822256335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1097 [0/90000 (0%)]	Loss: -8.7176	Cost: 28.71s
Train Epoch: 1097 [20480/90000 (23%)]	Loss: -14.6275	Cost: 8.76s
Train Epoch: 1097 [40960/90000 (45%)]	Loss: -13.9705	Cost: 8.66s
Train Epoch: 1097 [61440/90000 (68%)]	Loss: -13.6274	Cost: 8.60s
Train Epoch: 1097 [81920/90000 (91%)]	Loss: -13.5071	Cost: 8.38s
Train Epoch: 1097 	Average Loss: -13.6352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4424

Learning rate: 0.0001999406200237528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1098 [0/90000 (0%)]	Loss: -8.0416	Cost: 26.03s
Train Epoch: 1098 [20480/90000 (23%)]	Loss: -14.0937	Cost: 6.39s
Train Epoch: 1098 [40960/90000 (45%)]	Loss: -13.6682	Cost: 9.28s
Train Epoch: 1098 [61440/90000 (68%)]	Loss: -14.2825	Cost: 6.23s
Train Epoch: 1098 [81920/90000 (91%)]	Loss: -14.5087	Cost: 14.36s
Train Epoch: 1098 	Average Loss: -13.7698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1574

Saving model as e1098_model.pt & e1098_waveforms_supplementary.hdf5
Learning rate: 0.00019994051172630482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1099 [0/90000 (0%)]	Loss: -8.5729	Cost: 34.05s
Train Epoch: 1099 [20480/90000 (23%)]	Loss: -14.7023	Cost: 11.87s
Train Epoch: 1099 [40960/90000 (45%)]	Loss: -14.3213	Cost: 8.04s
Train Epoch: 1099 [61440/90000 (68%)]	Loss: -14.5409	Cost: 6.02s
Train Epoch: 1099 [81920/90000 (91%)]	Loss: -14.5567	Cost: 6.00s
Train Epoch: 1099 	Average Loss: -14.2100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2076

Saving model as e1099_model.pt & e1099_waveforms_supplementary.hdf5
Learning rate: 0.0001999404033302195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1100 [0/90000 (0%)]	Loss: -9.3178	Cost: 32.97s
Train Epoch: 1100 [20480/90000 (23%)]	Loss: -14.9424	Cost: 11.01s
Train Epoch: 1100 [40960/90000 (45%)]	Loss: -14.1268	Cost: 12.11s
Train Epoch: 1100 [61440/90000 (68%)]	Loss: -14.8261	Cost: 7.01s
Train Epoch: 1100 [81920/90000 (91%)]	Loss: -14.5531	Cost: 6.28s
Train Epoch: 1100 	Average Loss: -14.2686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9132

Learning rate: 0.00019994029483549696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1101 [0/90000 (0%)]	Loss: -8.7461	Cost: 34.73s
Train Epoch: 1101 [20480/90000 (23%)]	Loss: -14.7944	Cost: 7.21s
Train Epoch: 1101 [40960/90000 (45%)]	Loss: -14.3087	Cost: 14.11s
Train Epoch: 1101 [61440/90000 (68%)]	Loss: -13.9389	Cost: 12.11s
Train Epoch: 1101 [81920/90000 (91%)]	Loss: -14.0722	Cost: 8.44s
Train Epoch: 1101 	Average Loss: -14.0224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7889

Learning rate: 0.0001999401862421373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1102 [0/90000 (0%)]	Loss: -8.2399	Cost: 28.47s
Train Epoch: 1102 [20480/90000 (23%)]	Loss: -14.6160	Cost: 12.53s
Train Epoch: 1102 [40960/90000 (45%)]	Loss: -13.9431	Cost: 12.46s
Train Epoch: 1102 [61440/90000 (68%)]	Loss: -14.3834	Cost: 12.14s
Train Epoch: 1102 [81920/90000 (91%)]	Loss: -14.7595	Cost: 12.11s
Train Epoch: 1102 	Average Loss: -14.0090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2216

Saving model as e1102_model.pt & e1102_waveforms_supplementary.hdf5
Learning rate: 0.00019994007755014064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1103 [0/90000 (0%)]	Loss: -9.2614	Cost: 40.39s
Train Epoch: 1103 [20480/90000 (23%)]	Loss: -14.4007	Cost: 7.02s
Train Epoch: 1103 [40960/90000 (45%)]	Loss: -13.0411	Cost: 12.70s
Train Epoch: 1103 [61440/90000 (68%)]	Loss: -13.8177	Cost: 11.99s
Train Epoch: 1103 [81920/90000 (91%)]	Loss: -14.1043	Cost: 9.60s
Train Epoch: 1103 	Average Loss: -13.5769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7561

Learning rate: 0.00019993996875950707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1104 [0/90000 (0%)]	Loss: -9.2133	Cost: 33.72s
Train Epoch: 1104 [20480/90000 (23%)]	Loss: -14.5086	Cost: 11.18s
Train Epoch: 1104 [40960/90000 (45%)]	Loss: -14.0284	Cost: 12.52s
Train Epoch: 1104 [61440/90000 (68%)]	Loss: -14.5956	Cost: 12.10s
Train Epoch: 1104 [81920/90000 (91%)]	Loss: -14.8377	Cost: 11.93s
Train Epoch: 1104 	Average Loss: -14.0868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2759

Saving model as e1104_model.pt & e1104_waveforms_supplementary.hdf5
Learning rate: 0.0001999398598702367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1105 [0/90000 (0%)]	Loss: -9.2637	Cost: 27.76s
Train Epoch: 1105 [20480/90000 (23%)]	Loss: -15.0447	Cost: 10.62s
Train Epoch: 1105 [40960/90000 (45%)]	Loss: -14.3272	Cost: 13.02s
Train Epoch: 1105 [61440/90000 (68%)]	Loss: -14.6983	Cost: 12.10s
Train Epoch: 1105 [81920/90000 (91%)]	Loss: -14.9865	Cost: 11.93s
Train Epoch: 1105 	Average Loss: -14.4211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2717

Learning rate: 0.00019993975088232965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1106 [0/90000 (0%)]	Loss: -8.2668	Cost: 29.38s
Train Epoch: 1106 [20480/90000 (23%)]	Loss: -14.9608	Cost: 6.49s
Train Epoch: 1106 [40960/90000 (45%)]	Loss: -14.1891	Cost: 13.81s
Train Epoch: 1106 [61440/90000 (68%)]	Loss: -14.5932	Cost: 11.48s
Train Epoch: 1106 [81920/90000 (91%)]	Loss: -14.7008	Cost: 12.28s
Train Epoch: 1106 	Average Loss: -14.2794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1575

Learning rate: 0.00019993964179578603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1107 [0/90000 (0%)]	Loss: -8.8002	Cost: 30.99s
Train Epoch: 1107 [20480/90000 (23%)]	Loss: -15.0972	Cost: 11.97s
Train Epoch: 1107 [40960/90000 (45%)]	Loss: -14.2837	Cost: 12.52s
Train Epoch: 1107 [61440/90000 (68%)]	Loss: -14.6632	Cost: 12.13s
Train Epoch: 1107 [81920/90000 (91%)]	Loss: -14.8180	Cost: 11.95s
Train Epoch: 1107 	Average Loss: -14.3479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2482

Learning rate: 0.0001999395326106059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1108 [0/90000 (0%)]	Loss: -8.6791	Cost: 26.89s
Train Epoch: 1108 [20480/90000 (23%)]	Loss: -14.8814	Cost: 6.99s
Train Epoch: 1108 [40960/90000 (45%)]	Loss: -14.2231	Cost: 13.17s
Train Epoch: 1108 [61440/90000 (68%)]	Loss: -14.8405	Cost: 12.18s
Train Epoch: 1108 [81920/90000 (91%)]	Loss: -14.7778	Cost: 12.10s
Train Epoch: 1108 	Average Loss: -14.3033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2298

Learning rate: 0.00019993942332678945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1109 [0/90000 (0%)]	Loss: -9.0624	Cost: 37.30s
Train Epoch: 1109 [20480/90000 (23%)]	Loss: -14.8963	Cost: 11.22s
Train Epoch: 1109 [40960/90000 (45%)]	Loss: -14.4392	Cost: 12.22s
Train Epoch: 1109 [61440/90000 (68%)]	Loss: -14.6588	Cost: 11.85s
Train Epoch: 1109 [81920/90000 (91%)]	Loss: -14.7992	Cost: 12.12s
Train Epoch: 1109 	Average Loss: -14.2727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3096

Saving model as e1109_model.pt & e1109_waveforms_supplementary.hdf5
Learning rate: 0.00019993931394433673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1110 [0/90000 (0%)]	Loss: -9.1232	Cost: 40.10s
Train Epoch: 1110 [20480/90000 (23%)]	Loss: -14.8078	Cost: 11.08s
Train Epoch: 1110 [40960/90000 (45%)]	Loss: -14.2988	Cost: 12.15s
Train Epoch: 1110 [61440/90000 (68%)]	Loss: -14.6927	Cost: 11.93s
Train Epoch: 1110 [81920/90000 (91%)]	Loss: -14.7102	Cost: 8.07s
Train Epoch: 1110 	Average Loss: -14.2896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1856

Learning rate: 0.00019993920446324782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1111 [0/90000 (0%)]	Loss: -8.3612	Cost: 27.99s
Train Epoch: 1111 [20480/90000 (23%)]	Loss: -14.9557	Cost: 12.66s
Train Epoch: 1111 [40960/90000 (45%)]	Loss: -14.1440	Cost: 12.56s
Train Epoch: 1111 [61440/90000 (68%)]	Loss: -14.7139	Cost: 11.98s
Train Epoch: 1111 [81920/90000 (91%)]	Loss: -14.7218	Cost: 11.06s
Train Epoch: 1111 	Average Loss: -14.2914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1914

Learning rate: 0.0001999390948835229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1112 [0/90000 (0%)]	Loss: -9.2883	Cost: 36.55s
Train Epoch: 1112 [20480/90000 (23%)]	Loss: -14.9881	Cost: 12.33s
Train Epoch: 1112 [40960/90000 (45%)]	Loss: -13.9863	Cost: 12.15s
Train Epoch: 1112 [61440/90000 (68%)]	Loss: -14.6576	Cost: 12.20s
Train Epoch: 1112 [81920/90000 (91%)]	Loss: -14.5776	Cost: 12.17s
Train Epoch: 1112 	Average Loss: -14.2603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1102

Learning rate: 0.00019993898520516204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1113 [0/90000 (0%)]	Loss: -8.7314	Cost: 41.13s
Train Epoch: 1113 [20480/90000 (23%)]	Loss: -15.0832	Cost: 12.21s
Train Epoch: 1113 [40960/90000 (45%)]	Loss: -14.2965	Cost: 12.16s
Train Epoch: 1113 [61440/90000 (68%)]	Loss: -14.6467	Cost: 11.98s
Train Epoch: 1113 [81920/90000 (91%)]	Loss: -14.7307	Cost: 9.86s
Train Epoch: 1113 	Average Loss: -14.2886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2207

Learning rate: 0.00019993887542816538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1114 [0/90000 (0%)]	Loss: -8.8899	Cost: 31.80s
Train Epoch: 1114 [20480/90000 (23%)]	Loss: -14.7105	Cost: 12.29s
Train Epoch: 1114 [40960/90000 (45%)]	Loss: -14.0205	Cost: 12.35s
Train Epoch: 1114 [61440/90000 (68%)]	Loss: -14.6514	Cost: 11.95s
Train Epoch: 1114 [81920/90000 (91%)]	Loss: -14.4414	Cost: 12.00s
Train Epoch: 1114 	Average Loss: -14.1445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9767

Learning rate: 0.000199938765552533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1115 [0/90000 (0%)]	Loss: -8.3344	Cost: 27.66s
Train Epoch: 1115 [20480/90000 (23%)]	Loss: -14.4151	Cost: 7.57s
Train Epoch: 1115 [40960/90000 (45%)]	Loss: -14.1499	Cost: 12.30s
Train Epoch: 1115 [61440/90000 (68%)]	Loss: -14.5249	Cost: 12.28s
Train Epoch: 1115 [81920/90000 (91%)]	Loss: -14.5038	Cost: 12.17s
Train Epoch: 1115 	Average Loss: -14.0928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9608

Learning rate: 0.00019993865557826497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1116 [0/90000 (0%)]	Loss: -8.6321	Cost: 31.97s
Train Epoch: 1116 [20480/90000 (23%)]	Loss: -14.7195	Cost: 7.40s
Train Epoch: 1116 [40960/90000 (45%)]	Loss: -14.4429	Cost: 9.77s
Train Epoch: 1116 [61440/90000 (68%)]	Loss: -14.8528	Cost: 11.16s
Train Epoch: 1116 [81920/90000 (91%)]	Loss: -14.5804	Cost: 12.14s
Train Epoch: 1116 	Average Loss: -14.2045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2876

Learning rate: 0.00019993854550536149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1117 [0/90000 (0%)]	Loss: -8.6907	Cost: 25.99s
Train Epoch: 1117 [20480/90000 (23%)]	Loss: -14.9256	Cost: 6.34s
Train Epoch: 1117 [40960/90000 (45%)]	Loss: -14.2808	Cost: 9.18s
Train Epoch: 1117 [61440/90000 (68%)]	Loss: -14.7783	Cost: 11.09s
Train Epoch: 1117 [81920/90000 (91%)]	Loss: -14.6707	Cost: 12.40s
Train Epoch: 1117 	Average Loss: -14.3376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2487

Learning rate: 0.00019993843533382257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1118 [0/90000 (0%)]	Loss: -8.9261	Cost: 30.46s
Train Epoch: 1118 [20480/90000 (23%)]	Loss: -14.9452	Cost: 10.11s
Train Epoch: 1118 [40960/90000 (45%)]	Loss: -14.4200	Cost: 10.35s
Train Epoch: 1118 [61440/90000 (68%)]	Loss: -14.9280	Cost: 11.83s
Train Epoch: 1118 [81920/90000 (91%)]	Loss: -14.4498	Cost: 12.10s
Train Epoch: 1118 	Average Loss: -14.3256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0141

Learning rate: 0.00019993832506364843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1119 [0/90000 (0%)]	Loss: -9.0428	Cost: 24.27s
Train Epoch: 1119 [20480/90000 (23%)]	Loss: -14.5150	Cost: 7.10s
Train Epoch: 1119 [40960/90000 (45%)]	Loss: -13.8600	Cost: 9.08s
Train Epoch: 1119 [61440/90000 (68%)]	Loss: -14.6031	Cost: 6.74s
Train Epoch: 1119 [81920/90000 (91%)]	Loss: -14.6656	Cost: 15.52s
Train Epoch: 1119 	Average Loss: -14.1339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2620

Learning rate: 0.00019993821469483904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1120 [0/90000 (0%)]	Loss: -8.7548	Cost: 25.06s
Train Epoch: 1120 [20480/90000 (23%)]	Loss: -15.0831	Cost: 9.57s
Train Epoch: 1120 [40960/90000 (45%)]	Loss: -14.4085	Cost: 11.37s
Train Epoch: 1120 [61440/90000 (68%)]	Loss: -14.8803	Cost: 8.95s
Train Epoch: 1120 [81920/90000 (91%)]	Loss: -14.9857	Cost: 12.95s
Train Epoch: 1120 	Average Loss: -14.5135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3729

Saving model as e1120_model.pt & e1120_waveforms_supplementary.hdf5
Learning rate: 0.00019993810422739465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1121 [0/90000 (0%)]	Loss: -9.3210	Cost: 26.81s
Train Epoch: 1121 [20480/90000 (23%)]	Loss: -15.0240	Cost: 6.39s
Train Epoch: 1121 [40960/90000 (45%)]	Loss: -14.4768	Cost: 10.54s
Train Epoch: 1121 [61440/90000 (68%)]	Loss: -14.9658	Cost: 6.39s
Train Epoch: 1121 [81920/90000 (91%)]	Loss: -14.5060	Cost: 15.77s
Train Epoch: 1121 	Average Loss: -14.4190
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9234

Learning rate: 0.00019993799366131528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1122 [0/90000 (0%)]	Loss: -8.5190	Cost: 23.93s
Train Epoch: 1122 [20480/90000 (23%)]	Loss: -14.6465	Cost: 6.26s
Train Epoch: 1122 [40960/90000 (45%)]	Loss: -14.1796	Cost: 14.67s
Train Epoch: 1122 [61440/90000 (68%)]	Loss: -14.8054	Cost: 12.05s
Train Epoch: 1122 [81920/90000 (91%)]	Loss: -14.4911	Cost: 12.15s
Train Epoch: 1122 	Average Loss: -14.1940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0121

Learning rate: 0.00019993788299660107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1123 [0/90000 (0%)]	Loss: -8.5742	Cost: 31.87s
Train Epoch: 1123 [20480/90000 (23%)]	Loss: -14.9211	Cost: 6.81s
Train Epoch: 1123 [40960/90000 (45%)]	Loss: -14.4041	Cost: 10.20s
Train Epoch: 1123 [61440/90000 (68%)]	Loss: -14.6614	Cost: 10.49s
Train Epoch: 1123 [81920/90000 (91%)]	Loss: -14.8614	Cost: 12.13s
Train Epoch: 1123 	Average Loss: -14.3182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2819

Learning rate: 0.00019993777223325214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1124 [0/90000 (0%)]	Loss: -8.9832	Cost: 25.49s
Train Epoch: 1124 [20480/90000 (23%)]	Loss: -15.0137	Cost: 6.91s
Train Epoch: 1124 [40960/90000 (45%)]	Loss: -14.5141	Cost: 13.88s
Train Epoch: 1124 [61440/90000 (68%)]	Loss: -14.7100	Cost: 12.22s
Train Epoch: 1124 [81920/90000 (91%)]	Loss: -14.7911	Cost: 12.16s
Train Epoch: 1124 	Average Loss: -14.4217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4772

Saving model as e1124_model.pt & e1124_waveforms_supplementary.hdf5
Learning rate: 0.00019993766137126854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1125 [0/90000 (0%)]	Loss: -9.1903	Cost: 37.85s
Train Epoch: 1125 [20480/90000 (23%)]	Loss: -15.2190	Cost: 6.37s
Train Epoch: 1125 [40960/90000 (45%)]	Loss: -14.6927	Cost: 13.04s
Train Epoch: 1125 [61440/90000 (68%)]	Loss: -15.2133	Cost: 11.96s
Train Epoch: 1125 [81920/90000 (91%)]	Loss: -14.5438	Cost: 11.94s
Train Epoch: 1125 	Average Loss: -14.5461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1795

Learning rate: 0.00019993755041065043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1126 [0/90000 (0%)]	Loss: -9.0093	Cost: 25.64s
Train Epoch: 1126 [20480/90000 (23%)]	Loss: -15.0021	Cost: 9.46s
Train Epoch: 1126 [40960/90000 (45%)]	Loss: -14.3495	Cost: 15.67s
Train Epoch: 1126 [61440/90000 (68%)]	Loss: -14.9007	Cost: 12.21s
Train Epoch: 1126 [81920/90000 (91%)]	Loss: -15.0765	Cost: 12.00s
Train Epoch: 1126 	Average Loss: -14.4663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3346

Learning rate: 0.00019993743935139792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1127 [0/90000 (0%)]	Loss: -9.0580	Cost: 29.54s
Train Epoch: 1127 [20480/90000 (23%)]	Loss: -15.0147	Cost: 6.59s
Train Epoch: 1127 [40960/90000 (45%)]	Loss: -14.3173	Cost: 11.66s
Train Epoch: 1127 [61440/90000 (68%)]	Loss: -14.9659	Cost: 12.14s
Train Epoch: 1127 [81920/90000 (91%)]	Loss: -14.9184	Cost: 12.15s
Train Epoch: 1127 	Average Loss: -14.4802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3983

Learning rate: 0.00019993732819351113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1128 [0/90000 (0%)]	Loss: -8.8677	Cost: 26.09s
Train Epoch: 1128 [20480/90000 (23%)]	Loss: -15.2529	Cost: 8.48s
Train Epoch: 1128 [40960/90000 (45%)]	Loss: -14.6219	Cost: 13.89s
Train Epoch: 1128 [61440/90000 (68%)]	Loss: -15.0917	Cost: 12.63s
Train Epoch: 1128 [81920/90000 (91%)]	Loss: -14.8222	Cost: 11.99s
Train Epoch: 1128 	Average Loss: -14.6221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5678

Saving model as e1128_model.pt & e1128_waveforms_supplementary.hdf5
Learning rate: 0.00019993721693699015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1129 [0/90000 (0%)]	Loss: -9.0210	Cost: 29.40s
Train Epoch: 1129 [20480/90000 (23%)]	Loss: -15.1397	Cost: 6.36s
Train Epoch: 1129 [40960/90000 (45%)]	Loss: -14.4260	Cost: 13.82s
Train Epoch: 1129 [61440/90000 (68%)]	Loss: -14.8014	Cost: 12.02s
Train Epoch: 1129 [81920/90000 (91%)]	Loss: -15.0760	Cost: 12.43s
Train Epoch: 1129 	Average Loss: -14.5163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2626

Learning rate: 0.00019993710558183504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1130 [0/90000 (0%)]	Loss: -9.0819	Cost: 30.06s
Train Epoch: 1130 [20480/90000 (23%)]	Loss: -15.0886	Cost: 9.16s
Train Epoch: 1130 [40960/90000 (45%)]	Loss: -14.5655	Cost: 12.64s
Train Epoch: 1130 [61440/90000 (68%)]	Loss: -15.1197	Cost: 12.46s
Train Epoch: 1130 [81920/90000 (91%)]	Loss: -15.0284	Cost: 12.00s
Train Epoch: 1130 	Average Loss: -14.6049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6550

Saving model as e1130_model.pt & e1130_waveforms_supplementary.hdf5
Learning rate: 0.000199936994128046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1131 [0/90000 (0%)]	Loss: -8.9013	Cost: 27.40s
Train Epoch: 1131 [20480/90000 (23%)]	Loss: -15.3006	Cost: 7.05s
Train Epoch: 1131 [40960/90000 (45%)]	Loss: -14.4882	Cost: 12.43s
Train Epoch: 1131 [61440/90000 (68%)]	Loss: -14.8643	Cost: 12.13s
Train Epoch: 1131 [81920/90000 (91%)]	Loss: -15.0646	Cost: 12.26s
Train Epoch: 1131 	Average Loss: -14.6115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4380

Learning rate: 0.0001999368825756231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1132 [0/90000 (0%)]	Loss: -8.6728	Cost: 27.23s
Train Epoch: 1132 [20480/90000 (23%)]	Loss: -15.1480	Cost: 9.21s
Train Epoch: 1132 [40960/90000 (45%)]	Loss: -14.5512	Cost: 13.52s
Train Epoch: 1132 [61440/90000 (68%)]	Loss: -15.2784	Cost: 12.13s
Train Epoch: 1132 [81920/90000 (91%)]	Loss: -15.1549	Cost: 12.11s
Train Epoch: 1132 	Average Loss: -14.6577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5656

Learning rate: 0.00019993677092456643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1133 [0/90000 (0%)]	Loss: -8.9989	Cost: 27.25s
Train Epoch: 1133 [20480/90000 (23%)]	Loss: -15.2982	Cost: 6.58s
Train Epoch: 1133 [40960/90000 (45%)]	Loss: -14.4625	Cost: 13.23s
Train Epoch: 1133 [61440/90000 (68%)]	Loss: -15.0165	Cost: 12.45s
Train Epoch: 1133 [81920/90000 (91%)]	Loss: -15.1325	Cost: 12.25s
Train Epoch: 1133 	Average Loss: -14.6492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7079

Saving model as e1133_model.pt & e1133_waveforms_supplementary.hdf5
Learning rate: 0.00019993665917487612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1134 [0/90000 (0%)]	Loss: -8.9188	Cost: 40.08s
Train Epoch: 1134 [20480/90000 (23%)]	Loss: -14.9784	Cost: 12.46s
Train Epoch: 1134 [40960/90000 (45%)]	Loss: -14.7384	Cost: 12.08s
Train Epoch: 1134 [61440/90000 (68%)]	Loss: -14.8601	Cost: 12.03s
Train Epoch: 1134 [81920/90000 (91%)]	Loss: -14.9389	Cost: 11.83s
Train Epoch: 1134 	Average Loss: -14.4876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5912

Learning rate: 0.0001999365473265523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1135 [0/90000 (0%)]	Loss: -8.8917	Cost: 26.90s
Train Epoch: 1135 [20480/90000 (23%)]	Loss: -14.4637	Cost: 10.04s
Train Epoch: 1135 [40960/90000 (45%)]	Loss: -13.5722	Cost: 13.44s
Train Epoch: 1135 [61440/90000 (68%)]	Loss: -14.3387	Cost: 12.11s
Train Epoch: 1135 [81920/90000 (91%)]	Loss: -14.7178	Cost: 11.95s
Train Epoch: 1135 	Average Loss: -14.0821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2896

Learning rate: 0.00019993643537959504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1136 [0/90000 (0%)]	Loss: -8.5127	Cost: 28.74s
Train Epoch: 1136 [20480/90000 (23%)]	Loss: -13.7488	Cost: 6.80s
Train Epoch: 1136 [40960/90000 (45%)]	Loss: -13.4194	Cost: 12.58s
Train Epoch: 1136 [61440/90000 (68%)]	Loss: -14.3412	Cost: 12.20s
Train Epoch: 1136 [81920/90000 (91%)]	Loss: -14.5118	Cost: 12.37s
Train Epoch: 1136 	Average Loss: -13.7100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1810

Learning rate: 0.0001999363233340045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1137 [0/90000 (0%)]	Loss: -8.8635	Cost: 35.63s
Train Epoch: 1137 [20480/90000 (23%)]	Loss: -15.1557	Cost: 10.01s
Train Epoch: 1137 [40960/90000 (45%)]	Loss: -14.5007	Cost: 12.29s
Train Epoch: 1137 [61440/90000 (68%)]	Loss: -14.9188	Cost: 12.34s
Train Epoch: 1137 [81920/90000 (91%)]	Loss: -15.1189	Cost: 11.72s
Train Epoch: 1137 	Average Loss: -14.5222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3902

Learning rate: 0.00019993621118978076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1138 [0/90000 (0%)]	Loss: -9.1775	Cost: 26.92s
Train Epoch: 1138 [20480/90000 (23%)]	Loss: -15.1448	Cost: 10.48s
Train Epoch: 1138 [40960/90000 (45%)]	Loss: -14.6965	Cost: 12.83s
Train Epoch: 1138 [61440/90000 (68%)]	Loss: -15.1039	Cost: 12.17s
Train Epoch: 1138 [81920/90000 (91%)]	Loss: -15.1202	Cost: 11.99s
Train Epoch: 1138 	Average Loss: -14.6893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3983

Learning rate: 0.00019993609894692393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1139 [0/90000 (0%)]	Loss: -8.7768	Cost: 32.48s
Train Epoch: 1139 [20480/90000 (23%)]	Loss: -15.0102	Cost: 6.46s
Train Epoch: 1139 [40960/90000 (45%)]	Loss: -14.0297	Cost: 12.69s
Train Epoch: 1139 [61440/90000 (68%)]	Loss: -14.8422	Cost: 12.06s
Train Epoch: 1139 [81920/90000 (91%)]	Loss: -15.0554	Cost: 11.92s
Train Epoch: 1139 	Average Loss: -14.4347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5506

Learning rate: 0.0001999359866054341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1140 [0/90000 (0%)]	Loss: -9.3739	Cost: 28.53s
Train Epoch: 1140 [20480/90000 (23%)]	Loss: -15.1836	Cost: 8.92s
Train Epoch: 1140 [40960/90000 (45%)]	Loss: -14.5999	Cost: 13.42s
Train Epoch: 1140 [61440/90000 (68%)]	Loss: -15.0010	Cost: 12.13s
Train Epoch: 1140 [81920/90000 (91%)]	Loss: -14.9939	Cost: 11.96s
Train Epoch: 1140 	Average Loss: -14.6723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6590

Learning rate: 0.00019993587416531144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1141 [0/90000 (0%)]	Loss: -9.2776	Cost: 27.17s
Train Epoch: 1141 [20480/90000 (23%)]	Loss: -15.5173	Cost: 6.99s
Train Epoch: 1141 [40960/90000 (45%)]	Loss: -14.7490	Cost: 13.22s
Train Epoch: 1141 [61440/90000 (68%)]	Loss: -15.1925	Cost: 12.11s
Train Epoch: 1141 [81920/90000 (91%)]	Loss: -15.2558	Cost: 12.74s
Train Epoch: 1141 	Average Loss: -14.8727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5326

Learning rate: 0.00019993576162655603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1142 [0/90000 (0%)]	Loss: -9.0793	Cost: 31.53s
Train Epoch: 1142 [20480/90000 (23%)]	Loss: -15.1195	Cost: 8.93s
Train Epoch: 1142 [40960/90000 (45%)]	Loss: -14.7866	Cost: 14.73s
Train Epoch: 1142 [61440/90000 (68%)]	Loss: -15.0086	Cost: 12.08s
Train Epoch: 1142 [81920/90000 (91%)]	Loss: -14.9854	Cost: 12.15s
Train Epoch: 1142 	Average Loss: -14.6456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3606

Learning rate: 0.00019993564898916795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1143 [0/90000 (0%)]	Loss: -8.7482	Cost: 26.30s
Train Epoch: 1143 [20480/90000 (23%)]	Loss: -15.0515	Cost: 6.29s
Train Epoch: 1143 [40960/90000 (45%)]	Loss: -14.6858	Cost: 12.34s
Train Epoch: 1143 [61440/90000 (68%)]	Loss: -14.9362	Cost: 12.69s
Train Epoch: 1143 [81920/90000 (91%)]	Loss: -15.1100	Cost: 12.06s
Train Epoch: 1143 	Average Loss: -14.5873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5229

Learning rate: 0.00019993553625314737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1144 [0/90000 (0%)]	Loss: -8.5639	Cost: 29.14s
Train Epoch: 1144 [20480/90000 (23%)]	Loss: -15.2288	Cost: 8.70s
Train Epoch: 1144 [40960/90000 (45%)]	Loss: -14.3318	Cost: 12.01s
Train Epoch: 1144 [61440/90000 (68%)]	Loss: -14.7276	Cost: 12.16s
Train Epoch: 1144 [81920/90000 (91%)]	Loss: -15.0772	Cost: 11.92s
Train Epoch: 1144 	Average Loss: -14.4672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5885

Learning rate: 0.00019993542341849435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1145 [0/90000 (0%)]	Loss: -8.9332	Cost: 26.36s
Train Epoch: 1145 [20480/90000 (23%)]	Loss: -15.2179	Cost: 6.15s
Train Epoch: 1145 [40960/90000 (45%)]	Loss: -14.5935	Cost: 16.30s
Train Epoch: 1145 [61440/90000 (68%)]	Loss: -15.0323	Cost: 12.35s
Train Epoch: 1145 [81920/90000 (91%)]	Loss: -15.1121	Cost: 12.03s
Train Epoch: 1145 	Average Loss: -14.5811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7091

Saving model as e1145_model.pt & e1145_waveforms_supplementary.hdf5
Learning rate: 0.000199935310485209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1146 [0/90000 (0%)]	Loss: -8.7194	Cost: 32.66s
Train Epoch: 1146 [20480/90000 (23%)]	Loss: -15.3185	Cost: 10.14s
Train Epoch: 1146 [40960/90000 (45%)]	Loss: -14.9193	Cost: 12.14s
Train Epoch: 1146 [61440/90000 (68%)]	Loss: -15.2607	Cost: 11.98s
Train Epoch: 1146 [81920/90000 (91%)]	Loss: -15.2313	Cost: 12.22s
Train Epoch: 1146 	Average Loss: -14.8652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6815

Learning rate: 0.00019993519745329147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1147 [0/90000 (0%)]	Loss: -8.8135	Cost: 33.49s
Train Epoch: 1147 [20480/90000 (23%)]	Loss: -15.5002	Cost: 11.58s
Train Epoch: 1147 [40960/90000 (45%)]	Loss: -14.7696	Cost: 12.51s
Train Epoch: 1147 [61440/90000 (68%)]	Loss: -15.1918	Cost: 11.96s
Train Epoch: 1147 [81920/90000 (91%)]	Loss: -15.1143	Cost: 11.86s
Train Epoch: 1147 	Average Loss: -14.8188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8489

Saving model as e1147_model.pt & e1147_waveforms_supplementary.hdf5
Learning rate: 0.00019993508432274184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1148 [0/90000 (0%)]	Loss: -9.1272	Cost: 27.42s
Train Epoch: 1148 [20480/90000 (23%)]	Loss: -15.4076	Cost: 11.36s
Train Epoch: 1148 [40960/90000 (45%)]	Loss: -14.7749	Cost: 12.69s
Train Epoch: 1148 [61440/90000 (68%)]	Loss: -15.1940	Cost: 12.14s
Train Epoch: 1148 [81920/90000 (91%)]	Loss: -15.2370	Cost: 11.85s
Train Epoch: 1148 	Average Loss: -14.8188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6612

Learning rate: 0.00019993497109356025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1149 [0/90000 (0%)]	Loss: -8.9163	Cost: 28.92s
Train Epoch: 1149 [20480/90000 (23%)]	Loss: -15.3063	Cost: 6.46s
Train Epoch: 1149 [40960/90000 (45%)]	Loss: -14.8388	Cost: 13.80s
Train Epoch: 1149 [61440/90000 (68%)]	Loss: -15.1893	Cost: 11.89s
Train Epoch: 1149 [81920/90000 (91%)]	Loss: -15.3442	Cost: 12.20s
Train Epoch: 1149 	Average Loss: -14.8236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7655

Learning rate: 0.00019993485776574678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1150 [0/90000 (0%)]	Loss: -9.4420	Cost: 28.57s
Train Epoch: 1150 [20480/90000 (23%)]	Loss: -15.5954	Cost: 11.42s
Train Epoch: 1150 [40960/90000 (45%)]	Loss: -14.8807	Cost: 12.45s
Train Epoch: 1150 [61440/90000 (68%)]	Loss: -15.2458	Cost: 12.00s
Train Epoch: 1150 [81920/90000 (91%)]	Loss: -15.3930	Cost: 11.88s
Train Epoch: 1150 	Average Loss: -14.9766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6148

Learning rate: 0.00019993474433930157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1151 [0/90000 (0%)]	Loss: -9.5910	Cost: 28.18s
Train Epoch: 1151 [20480/90000 (23%)]	Loss: -14.8308	Cost: 6.46s
Train Epoch: 1151 [40960/90000 (45%)]	Loss: -14.4372	Cost: 12.44s
Train Epoch: 1151 [61440/90000 (68%)]	Loss: -15.2246	Cost: 12.34s
Train Epoch: 1151 [81920/90000 (91%)]	Loss: -15.1807	Cost: 12.25s
Train Epoch: 1151 	Average Loss: -14.6153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7023

Learning rate: 0.00019993463081422472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1152 [0/90000 (0%)]	Loss: -9.9865	Cost: 31.44s
Train Epoch: 1152 [20480/90000 (23%)]	Loss: -15.4393	Cost: 10.17s
Train Epoch: 1152 [40960/90000 (45%)]	Loss: -14.7878	Cost: 12.83s
Train Epoch: 1152 [61440/90000 (68%)]	Loss: -15.3200	Cost: 12.02s
Train Epoch: 1152 [81920/90000 (91%)]	Loss: -15.3199	Cost: 11.92s
Train Epoch: 1152 	Average Loss: -14.8676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7086

Learning rate: 0.00019993451719051635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1153 [0/90000 (0%)]	Loss: -9.4153	Cost: 26.15s
Train Epoch: 1153 [20480/90000 (23%)]	Loss: -15.4088	Cost: 6.32s
Train Epoch: 1153 [40960/90000 (45%)]	Loss: -15.0091	Cost: 14.03s
Train Epoch: 1153 [61440/90000 (68%)]	Loss: -15.3038	Cost: 12.59s
Train Epoch: 1153 [81920/90000 (91%)]	Loss: -15.5759	Cost: 12.21s
Train Epoch: 1153 	Average Loss: -14.9716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8010

Learning rate: 0.00019993440346817654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1154 [0/90000 (0%)]	Loss: -9.3615	Cost: 34.13s
Train Epoch: 1154 [20480/90000 (23%)]	Loss: -15.3278	Cost: 6.24s
Train Epoch: 1154 [40960/90000 (45%)]	Loss: -14.9455	Cost: 12.73s
Train Epoch: 1154 [61440/90000 (68%)]	Loss: -15.4431	Cost: 11.98s
Train Epoch: 1154 [81920/90000 (91%)]	Loss: -15.4928	Cost: 12.06s
Train Epoch: 1154 	Average Loss: -14.9098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6750

Learning rate: 0.00019993428964720544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1155 [0/90000 (0%)]	Loss: -8.4822	Cost: 26.02s
Train Epoch: 1155 [20480/90000 (23%)]	Loss: -15.2109	Cost: 8.44s
Train Epoch: 1155 [40960/90000 (45%)]	Loss: -14.5309	Cost: 18.38s
Train Epoch: 1155 [61440/90000 (68%)]	Loss: -15.3020	Cost: 12.12s
Train Epoch: 1155 [81920/90000 (91%)]	Loss: -15.4012	Cost: 11.86s
Train Epoch: 1155 	Average Loss: -14.7534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7994

Learning rate: 0.00019993417572760315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1156 [0/90000 (0%)]	Loss: -9.3447	Cost: 28.88s
Train Epoch: 1156 [20480/90000 (23%)]	Loss: -15.1891	Cost: 6.59s
Train Epoch: 1156 [40960/90000 (45%)]	Loss: -14.7293	Cost: 13.09s
Train Epoch: 1156 [61440/90000 (68%)]	Loss: -15.0501	Cost: 11.94s
Train Epoch: 1156 [81920/90000 (91%)]	Loss: -15.0889	Cost: 12.26s
Train Epoch: 1156 	Average Loss: -14.7326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5619

Learning rate: 0.0001999340617093698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1157 [0/90000 (0%)]	Loss: -9.6347	Cost: 28.79s
Train Epoch: 1157 [20480/90000 (23%)]	Loss: -15.4557	Cost: 9.53s
Train Epoch: 1157 [40960/90000 (45%)]	Loss: -14.8874	Cost: 13.88s
Train Epoch: 1157 [61440/90000 (68%)]	Loss: -15.0752	Cost: 11.85s
Train Epoch: 1157 [81920/90000 (91%)]	Loss: -14.7406	Cost: 12.11s
Train Epoch: 1157 	Average Loss: -14.7281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2395

Learning rate: 0.00019993394759250545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1158 [0/90000 (0%)]	Loss: -9.1164	Cost: 25.66s
Train Epoch: 1158 [20480/90000 (23%)]	Loss: -15.0818	Cost: 6.85s
Train Epoch: 1158 [40960/90000 (45%)]	Loss: -14.6102	Cost: 11.57s
Train Epoch: 1158 [61440/90000 (68%)]	Loss: -15.2149	Cost: 12.17s
Train Epoch: 1158 [81920/90000 (91%)]	Loss: -15.2241	Cost: 12.33s
Train Epoch: 1158 	Average Loss: -14.6072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7205

Learning rate: 0.0001999338333770103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1159 [0/90000 (0%)]	Loss: -9.5033	Cost: 30.52s
Train Epoch: 1159 [20480/90000 (23%)]	Loss: -15.5047	Cost: 8.59s
Train Epoch: 1159 [40960/90000 (45%)]	Loss: -14.9407	Cost: 15.44s
Train Epoch: 1159 [61440/90000 (68%)]	Loss: -15.5627	Cost: 12.13s
Train Epoch: 1159 [81920/90000 (91%)]	Loss: -15.2827	Cost: 12.06s
Train Epoch: 1159 	Average Loss: -14.9030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6862

Learning rate: 0.00019993371906288436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1160 [0/90000 (0%)]	Loss: -8.9498	Cost: 25.33s
Train Epoch: 1160 [20480/90000 (23%)]	Loss: -15.5297	Cost: 7.07s
Train Epoch: 1160 [40960/90000 (45%)]	Loss: -14.9719	Cost: 10.16s
Train Epoch: 1160 [61440/90000 (68%)]	Loss: -15.5098	Cost: 12.22s
Train Epoch: 1160 [81920/90000 (91%)]	Loss: -15.4511	Cost: 12.35s
Train Epoch: 1160 	Average Loss: -14.9751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9663

Saving model as e1160_model.pt & e1160_waveforms_supplementary.hdf5
Learning rate: 0.0001999336046501278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1161 [0/90000 (0%)]	Loss: -9.2646	Cost: 26.87s
Train Epoch: 1161 [20480/90000 (23%)]	Loss: -15.5650	Cost: 8.92s
Train Epoch: 1161 [40960/90000 (45%)]	Loss: -14.9247	Cost: 14.58s
Train Epoch: 1161 [61440/90000 (68%)]	Loss: -14.9689	Cost: 12.21s
Train Epoch: 1161 [81920/90000 (91%)]	Loss: -15.5495	Cost: 12.14s
Train Epoch: 1161 	Average Loss: -14.8815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7276

Learning rate: 0.00019993349013874075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1162 [0/90000 (0%)]	Loss: -9.1260	Cost: 26.92s
Train Epoch: 1162 [20480/90000 (23%)]	Loss: -15.6022	Cost: 6.89s
Train Epoch: 1162 [40960/90000 (45%)]	Loss: -14.9945	Cost: 12.66s
Train Epoch: 1162 [61440/90000 (68%)]	Loss: -15.3997	Cost: 12.21s
Train Epoch: 1162 [81920/90000 (91%)]	Loss: -15.2391	Cost: 12.22s
Train Epoch: 1162 	Average Loss: -14.9155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7020

Learning rate: 0.00019993337552872326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1163 [0/90000 (0%)]	Loss: -9.3838	Cost: 29.85s
Train Epoch: 1163 [20480/90000 (23%)]	Loss: -15.5430	Cost: 8.55s
Train Epoch: 1163 [40960/90000 (45%)]	Loss: -14.8966	Cost: 14.27s
Train Epoch: 1163 [61440/90000 (68%)]	Loss: -15.4493	Cost: 12.22s
Train Epoch: 1163 [81920/90000 (91%)]	Loss: -15.5914	Cost: 11.97s
Train Epoch: 1163 	Average Loss: -14.9808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0197

Saving model as e1163_model.pt & e1163_waveforms_supplementary.hdf5
Learning rate: 0.0001999332608200755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1164 [0/90000 (0%)]	Loss: -9.5872	Cost: 30.16s
Train Epoch: 1164 [20480/90000 (23%)]	Loss: -15.7937	Cost: 6.40s
Train Epoch: 1164 [40960/90000 (45%)]	Loss: -14.9488	Cost: 13.21s
Train Epoch: 1164 [61440/90000 (68%)]	Loss: -15.2936	Cost: 12.38s
Train Epoch: 1164 [81920/90000 (91%)]	Loss: -15.1423	Cost: 12.22s
Train Epoch: 1164 	Average Loss: -14.9369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8572

Learning rate: 0.00019993314601279757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1165 [0/90000 (0%)]	Loss: -9.2671	Cost: 35.34s
Train Epoch: 1165 [20480/90000 (23%)]	Loss: -15.6621	Cost: 6.55s
Train Epoch: 1165 [40960/90000 (45%)]	Loss: -15.1334	Cost: 14.57s
Train Epoch: 1165 [61440/90000 (68%)]	Loss: -15.5490	Cost: 11.85s
Train Epoch: 1165 [81920/90000 (91%)]	Loss: -15.5552	Cost: 11.93s
Train Epoch: 1165 	Average Loss: -15.1256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9699

Learning rate: 0.00019993303110688956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1166 [0/90000 (0%)]	Loss: -9.8014	Cost: 26.92s
Train Epoch: 1166 [20480/90000 (23%)]	Loss: -15.6202	Cost: 6.23s
Train Epoch: 1166 [40960/90000 (45%)]	Loss: -15.0135	Cost: 12.25s
Train Epoch: 1166 [61440/90000 (68%)]	Loss: -15.6752	Cost: 12.27s
Train Epoch: 1166 [81920/90000 (91%)]	Loss: -15.4854	Cost: 12.07s
Train Epoch: 1166 	Average Loss: -15.0763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9915

Learning rate: 0.0001999329161023516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1167 [0/90000 (0%)]	Loss: -9.7915	Cost: 28.95s
Train Epoch: 1167 [20480/90000 (23%)]	Loss: -15.6688	Cost: 8.87s
Train Epoch: 1167 [40960/90000 (45%)]	Loss: -15.0810	Cost: 14.05s
Train Epoch: 1167 [61440/90000 (68%)]	Loss: -15.6510	Cost: 12.30s
Train Epoch: 1167 [81920/90000 (91%)]	Loss: -15.5298	Cost: 12.15s
Train Epoch: 1167 	Average Loss: -15.0981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8487

Learning rate: 0.00019993280099918386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1168 [0/90000 (0%)]	Loss: -10.1099	Cost: 25.96s
Train Epoch: 1168 [20480/90000 (23%)]	Loss: -15.7939	Cost: 7.21s
Train Epoch: 1168 [40960/90000 (45%)]	Loss: -15.1194	Cost: 13.91s
Train Epoch: 1168 [61440/90000 (68%)]	Loss: -15.2778	Cost: 12.23s
Train Epoch: 1168 [81920/90000 (91%)]	Loss: -15.3576	Cost: 12.11s
Train Epoch: 1168 	Average Loss: -14.9364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7675

Learning rate: 0.00019993268579738635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1169 [0/90000 (0%)]	Loss: -9.4819	Cost: 28.55s
Train Epoch: 1169 [20480/90000 (23%)]	Loss: -15.6144	Cost: 7.14s
Train Epoch: 1169 [40960/90000 (45%)]	Loss: -15.0726	Cost: 13.71s
Train Epoch: 1169 [61440/90000 (68%)]	Loss: -15.6347	Cost: 12.38s
Train Epoch: 1169 [81920/90000 (91%)]	Loss: -15.7201	Cost: 11.75s
Train Epoch: 1169 	Average Loss: -15.1126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0489

Saving model as e1169_model.pt & e1169_waveforms_supplementary.hdf5
Learning rate: 0.00019993257049695927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1170 [0/90000 (0%)]	Loss: -9.6430	Cost: 27.20s
Train Epoch: 1170 [20480/90000 (23%)]	Loss: -15.7143	Cost: 9.15s
Train Epoch: 1170 [40960/90000 (45%)]	Loss: -15.1408	Cost: 13.60s
Train Epoch: 1170 [61440/90000 (68%)]	Loss: -15.4812	Cost: 12.01s
Train Epoch: 1170 [81920/90000 (91%)]	Loss: -15.2945	Cost: 12.03s
Train Epoch: 1170 	Average Loss: -15.0560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8427

Learning rate: 0.00019993245509790266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1171 [0/90000 (0%)]	Loss: -9.0657	Cost: 28.06s
Train Epoch: 1171 [20480/90000 (23%)]	Loss: -15.6448	Cost: 6.87s
Train Epoch: 1171 [40960/90000 (45%)]	Loss: -14.2609	Cost: 13.10s
Train Epoch: 1171 [61440/90000 (68%)]	Loss: -15.0386	Cost: 12.19s
Train Epoch: 1171 [81920/90000 (91%)]	Loss: -15.1580	Cost: 12.30s
Train Epoch: 1171 	Average Loss: -14.6836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5741

Learning rate: 0.00019993233960021668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1172 [0/90000 (0%)]	Loss: -9.1978	Cost: 32.19s
Train Epoch: 1172 [20480/90000 (23%)]	Loss: -15.4728	Cost: 8.51s
Train Epoch: 1172 [40960/90000 (45%)]	Loss: -15.0569	Cost: 14.40s
Train Epoch: 1172 [61440/90000 (68%)]	Loss: -15.3585	Cost: 12.17s
Train Epoch: 1172 [81920/90000 (91%)]	Loss: -15.4227	Cost: 12.05s
Train Epoch: 1172 	Average Loss: -14.9571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9885

Learning rate: 0.00019993222400390142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1173 [0/90000 (0%)]	Loss: -9.8716	Cost: 27.13s
Train Epoch: 1173 [20480/90000 (23%)]	Loss: -15.8982	Cost: 6.48s
Train Epoch: 1173 [40960/90000 (45%)]	Loss: -15.0745	Cost: 12.71s
Train Epoch: 1173 [61440/90000 (68%)]	Loss: -15.6326	Cost: 12.28s
Train Epoch: 1173 [81920/90000 (91%)]	Loss: -15.2343	Cost: 12.12s
Train Epoch: 1173 	Average Loss: -15.1415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0727

Saving model as e1173_model.pt & e1173_waveforms_supplementary.hdf5
Learning rate: 0.00019993210830895701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1174 [0/90000 (0%)]	Loss: -9.4150	Cost: 29.74s
Train Epoch: 1174 [20480/90000 (23%)]	Loss: -15.7862	Cost: 7.57s
Train Epoch: 1174 [40960/90000 (45%)]	Loss: -15.2132	Cost: 11.11s
Train Epoch: 1174 [61440/90000 (68%)]	Loss: -15.7795	Cost: 12.24s
Train Epoch: 1174 [81920/90000 (91%)]	Loss: -15.7922	Cost: 12.01s
Train Epoch: 1174 	Average Loss: -15.2030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0830

Saving model as e1174_model.pt & e1174_waveforms_supplementary.hdf5
Learning rate: 0.00019993199251538358
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1175 [0/90000 (0%)]	Loss: -9.4443	Cost: 26.17s
Train Epoch: 1175 [20480/90000 (23%)]	Loss: -15.8617	Cost: 8.75s
Train Epoch: 1175 [40960/90000 (45%)]	Loss: -15.2353	Cost: 13.42s
Train Epoch: 1175 [61440/90000 (68%)]	Loss: -15.5313	Cost: 12.19s
Train Epoch: 1175 [81920/90000 (91%)]	Loss: -15.6656	Cost: 12.16s
Train Epoch: 1175 	Average Loss: -15.2579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0792

Learning rate: 0.00019993187662318122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1176 [0/90000 (0%)]	Loss: -9.5011	Cost: 28.23s
Train Epoch: 1176 [20480/90000 (23%)]	Loss: -15.7285	Cost: 6.24s
Train Epoch: 1176 [40960/90000 (45%)]	Loss: -15.1094	Cost: 14.27s
Train Epoch: 1176 [61440/90000 (68%)]	Loss: -15.8102	Cost: 11.55s
Train Epoch: 1176 [81920/90000 (91%)]	Loss: -15.6413	Cost: 12.18s
Train Epoch: 1176 	Average Loss: -15.2426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0436

Learning rate: 0.00019993176063235005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1177 [0/90000 (0%)]	Loss: -9.5466	Cost: 31.76s
Train Epoch: 1177 [20480/90000 (23%)]	Loss: -16.0433	Cost: 10.80s
Train Epoch: 1177 [40960/90000 (45%)]	Loss: -15.2212	Cost: 12.54s
Train Epoch: 1177 [61440/90000 (68%)]	Loss: -15.5227	Cost: 12.11s
Train Epoch: 1177 [81920/90000 (91%)]	Loss: -15.4925	Cost: 11.97s
Train Epoch: 1177 	Average Loss: -15.1837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9548

Learning rate: 0.00019993164454289018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1178 [0/90000 (0%)]	Loss: -10.1053	Cost: 28.50s
Train Epoch: 1178 [20480/90000 (23%)]	Loss: -15.6002	Cost: 8.92s
Train Epoch: 1178 [40960/90000 (45%)]	Loss: -15.0505	Cost: 13.69s
Train Epoch: 1178 [61440/90000 (68%)]	Loss: -15.7123	Cost: 12.18s
Train Epoch: 1178 [81920/90000 (91%)]	Loss: -15.8354	Cost: 12.02s
Train Epoch: 1178 	Average Loss: -15.0852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1134

Saving model as e1178_model.pt & e1178_waveforms_supplementary.hdf5
Learning rate: 0.00019993152835480173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1179 [0/90000 (0%)]	Loss: -10.3263	Cost: 30.50s
Train Epoch: 1179 [20480/90000 (23%)]	Loss: -15.9688	Cost: 6.28s
Train Epoch: 1179 [40960/90000 (45%)]	Loss: -14.4460	Cost: 12.20s
Train Epoch: 1179 [61440/90000 (68%)]	Loss: -15.0096	Cost: 12.12s
Train Epoch: 1179 [81920/90000 (91%)]	Loss: -15.3823	Cost: 12.21s
Train Epoch: 1179 	Average Loss: -14.9717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0639

Learning rate: 0.00019993141206808485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1180 [0/90000 (0%)]	Loss: -9.8477	Cost: 29.16s
Train Epoch: 1180 [20480/90000 (23%)]	Loss: -16.0041	Cost: 9.27s
Train Epoch: 1180 [40960/90000 (45%)]	Loss: -15.1757	Cost: 15.48s
Train Epoch: 1180 [61440/90000 (68%)]	Loss: -15.6791	Cost: 12.05s
Train Epoch: 1180 [81920/90000 (91%)]	Loss: -15.7780	Cost: 11.97s
Train Epoch: 1180 	Average Loss: -15.2810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1243

Saving model as e1180_model.pt & e1180_waveforms_supplementary.hdf5
Learning rate: 0.0001999312956827396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1181 [0/90000 (0%)]	Loss: -9.8755	Cost: 27.81s
Train Epoch: 1181 [20480/90000 (23%)]	Loss: -15.8274	Cost: 7.40s
Train Epoch: 1181 [40960/90000 (45%)]	Loss: -15.1997	Cost: 12.02s
Train Epoch: 1181 [61440/90000 (68%)]	Loss: -15.8379	Cost: 12.33s
Train Epoch: 1181 [81920/90000 (91%)]	Loss: -14.8819	Cost: 12.13s
Train Epoch: 1181 	Average Loss: -15.2067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2066

Learning rate: 0.00019993117919876613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1182 [0/90000 (0%)]	Loss: -9.1686	Cost: 28.04s
Train Epoch: 1182 [20480/90000 (23%)]	Loss: -15.0521	Cost: 8.69s
Train Epoch: 1182 [40960/90000 (45%)]	Loss: -14.4717	Cost: 12.14s
Train Epoch: 1182 [61440/90000 (68%)]	Loss: -14.6887	Cost: 11.21s
Train Epoch: 1182 [81920/90000 (91%)]	Loss: -14.9146	Cost: 12.14s
Train Epoch: 1182 	Average Loss: -14.4146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5970

Learning rate: 0.0001999310626161645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1183 [0/90000 (0%)]	Loss: -8.4729	Cost: 24.72s
Train Epoch: 1183 [20480/90000 (23%)]	Loss: -15.3529	Cost: 7.34s
Train Epoch: 1183 [40960/90000 (45%)]	Loss: -14.9259	Cost: 9.98s
Train Epoch: 1183 [61440/90000 (68%)]	Loss: -15.6363	Cost: 6.33s
Train Epoch: 1183 [81920/90000 (91%)]	Loss: -15.7627	Cost: 15.48s
Train Epoch: 1183 	Average Loss: -14.9974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1916

Saving model as e1183_model.pt & e1183_waveforms_supplementary.hdf5
Learning rate: 0.00019993094593493492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1184 [0/90000 (0%)]	Loss: -10.1930	Cost: 24.29s
Train Epoch: 1184 [20480/90000 (23%)]	Loss: -15.5382	Cost: 8.45s
Train Epoch: 1184 [40960/90000 (45%)]	Loss: -15.0534	Cost: 12.61s
Train Epoch: 1184 [61440/90000 (68%)]	Loss: -15.7465	Cost: 11.33s
Train Epoch: 1184 [81920/90000 (91%)]	Loss: -15.5950	Cost: 12.22s
Train Epoch: 1184 	Average Loss: -15.1917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1451

Learning rate: 0.0001999308291550774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1185 [0/90000 (0%)]	Loss: -9.2478	Cost: 27.53s
Train Epoch: 1185 [20480/90000 (23%)]	Loss: -15.8838	Cost: 6.91s
Train Epoch: 1185 [40960/90000 (45%)]	Loss: -15.3105	Cost: 9.27s
Train Epoch: 1185 [61440/90000 (68%)]	Loss: -15.5864	Cost: 6.22s
Train Epoch: 1185 [81920/90000 (91%)]	Loss: -15.4645	Cost: 15.11s
Train Epoch: 1185 	Average Loss: -15.1598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9049

Learning rate: 0.00019993071227659214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1186 [0/90000 (0%)]	Loss: -9.2483	Cost: 24.09s
Train Epoch: 1186 [20480/90000 (23%)]	Loss: -15.7479	Cost: 6.05s
Train Epoch: 1186 [40960/90000 (45%)]	Loss: -15.3502	Cost: 13.93s
Train Epoch: 1186 [61440/90000 (68%)]	Loss: -15.8336	Cost: 10.93s
Train Epoch: 1186 [81920/90000 (91%)]	Loss: -15.7679	Cost: 13.25s
Train Epoch: 1186 	Average Loss: -15.2926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1527

Learning rate: 0.0001999305952994792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1187 [0/90000 (0%)]	Loss: -9.6297	Cost: 27.77s
Train Epoch: 1187 [20480/90000 (23%)]	Loss: -16.0927	Cost: 9.41s
Train Epoch: 1187 [40960/90000 (45%)]	Loss: -15.3061	Cost: 12.51s
Train Epoch: 1187 [61440/90000 (68%)]	Loss: -15.6802	Cost: 7.44s
Train Epoch: 1187 [81920/90000 (91%)]	Loss: -15.7727	Cost: 12.64s
Train Epoch: 1187 	Average Loss: -15.3173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1663

Learning rate: 0.0001999304782237387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1188 [0/90000 (0%)]	Loss: -10.0323	Cost: 24.11s
Train Epoch: 1188 [20480/90000 (23%)]	Loss: -16.1930	Cost: 6.32s
Train Epoch: 1188 [40960/90000 (45%)]	Loss: -15.4310	Cost: 10.12s
Train Epoch: 1188 [61440/90000 (68%)]	Loss: -15.7869	Cost: 7.77s
Train Epoch: 1188 [81920/90000 (91%)]	Loss: -15.3168	Cost: 14.97s
Train Epoch: 1188 	Average Loss: -15.3584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6873

Learning rate: 0.0001999303610493708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1189 [0/90000 (0%)]	Loss: -8.9364	Cost: 24.83s
Train Epoch: 1189 [20480/90000 (23%)]	Loss: -15.2664	Cost: 8.85s
Train Epoch: 1189 [40960/90000 (45%)]	Loss: -15.1266	Cost: 14.59s
Train Epoch: 1189 [61440/90000 (68%)]	Loss: -15.7242	Cost: 6.97s
Train Epoch: 1189 [81920/90000 (91%)]	Loss: -15.6787	Cost: 9.55s
Train Epoch: 1189 	Average Loss: -14.9595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1629

Learning rate: 0.0001999302437763756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1190 [0/90000 (0%)]	Loss: -10.5988	Cost: 25.72s
Train Epoch: 1190 [20480/90000 (23%)]	Loss: -16.1648	Cost: 6.37s
Train Epoch: 1190 [40960/90000 (45%)]	Loss: -15.5529	Cost: 8.73s
Train Epoch: 1190 [61440/90000 (68%)]	Loss: -15.9311	Cost: 6.46s
Train Epoch: 1190 [81920/90000 (91%)]	Loss: -14.9520	Cost: 9.93s
Train Epoch: 1190 	Average Loss: -15.3788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4119

Learning rate: 0.00019993012640475317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1191 [0/90000 (0%)]	Loss: -8.7031	Cost: 24.94s
Train Epoch: 1191 [20480/90000 (23%)]	Loss: -15.2799	Cost: 6.61s
Train Epoch: 1191 [40960/90000 (45%)]	Loss: -14.8894	Cost: 13.06s
Train Epoch: 1191 [61440/90000 (68%)]	Loss: -15.6145	Cost: 6.88s
Train Epoch: 1191 [81920/90000 (91%)]	Loss: -15.5826	Cost: 9.88s
Train Epoch: 1191 	Average Loss: -14.9984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2763

Saving model as e1191_model.pt & e1191_waveforms_supplementary.hdf5
Learning rate: 0.00019993000893450363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1192 [0/90000 (0%)]	Loss: -9.9064	Cost: 26.92s
Train Epoch: 1192 [20480/90000 (23%)]	Loss: -15.8979	Cost: 6.54s
Train Epoch: 1192 [40960/90000 (45%)]	Loss: -14.9453	Cost: 7.96s
Train Epoch: 1192 [61440/90000 (68%)]	Loss: -15.7131	Cost: 6.51s
Train Epoch: 1192 [81920/90000 (91%)]	Loss: -15.7806	Cost: 9.64s
Train Epoch: 1192 	Average Loss: -15.2343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3577

Saving model as e1192_model.pt & e1192_waveforms_supplementary.hdf5
Learning rate: 0.00019992989136562717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1193 [0/90000 (0%)]	Loss: -9.5090	Cost: 25.68s
Train Epoch: 1193 [20480/90000 (23%)]	Loss: -15.9643	Cost: 6.84s
Train Epoch: 1193 [40960/90000 (45%)]	Loss: -15.3805	Cost: 12.65s
Train Epoch: 1193 [61440/90000 (68%)]	Loss: -15.8822	Cost: 6.87s
Train Epoch: 1193 [81920/90000 (91%)]	Loss: -15.7252	Cost: 9.42s
Train Epoch: 1193 	Average Loss: -15.3626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1857

Learning rate: 0.00019992977369812385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1194 [0/90000 (0%)]	Loss: -10.1223	Cost: 25.60s
Train Epoch: 1194 [20480/90000 (23%)]	Loss: -15.9304	Cost: 8.97s
Train Epoch: 1194 [40960/90000 (45%)]	Loss: -15.4653	Cost: 7.48s
Train Epoch: 1194 [61440/90000 (68%)]	Loss: -15.5502	Cost: 6.05s
Train Epoch: 1194 [81920/90000 (91%)]	Loss: -15.6627	Cost: 6.19s
Train Epoch: 1194 	Average Loss: -15.3339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9250

Learning rate: 0.00019992965593199378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1195 [0/90000 (0%)]	Loss: -9.6060	Cost: 30.48s
Train Epoch: 1195 [20480/90000 (23%)]	Loss: -15.9825	Cost: 8.36s
Train Epoch: 1195 [40960/90000 (45%)]	Loss: -15.0575	Cost: 9.39s
Train Epoch: 1195 [61440/90000 (68%)]	Loss: -15.7224	Cost: 6.33s
Train Epoch: 1195 [81920/90000 (91%)]	Loss: -15.8395	Cost: 9.14s
Train Epoch: 1195 	Average Loss: -15.2770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3870

Saving model as e1195_model.pt & e1195_waveforms_supplementary.hdf5
Learning rate: 0.00019992953806723712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1196 [0/90000 (0%)]	Loss: -9.2432	Cost: 24.63s
Train Epoch: 1196 [20480/90000 (23%)]	Loss: -16.1028	Cost: 8.61s
Train Epoch: 1196 [40960/90000 (45%)]	Loss: -15.7060	Cost: 6.18s
Train Epoch: 1196 [61440/90000 (68%)]	Loss: -16.0195	Cost: 7.12s
Train Epoch: 1196 [81920/90000 (91%)]	Loss: -16.0426	Cost: 7.66s
Train Epoch: 1196 	Average Loss: -15.5661
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4677

Saving model as e1196_model.pt & e1196_waveforms_supplementary.hdf5
Learning rate: 0.00019992942010385397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1197 [0/90000 (0%)]	Loss: -10.7249	Cost: 28.70s
Train Epoch: 1197 [20480/90000 (23%)]	Loss: -16.1627	Cost: 8.75s
Train Epoch: 1197 [40960/90000 (45%)]	Loss: -15.7446	Cost: 6.59s
Train Epoch: 1197 [61440/90000 (68%)]	Loss: -15.8605	Cost: 6.45s
Train Epoch: 1197 [81920/90000 (91%)]	Loss: -16.0234	Cost: 6.70s
Train Epoch: 1197 	Average Loss: -15.6254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4295

Learning rate: 0.0001999293020418444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1198 [0/90000 (0%)]	Loss: -10.4906	Cost: 26.53s
Train Epoch: 1198 [20480/90000 (23%)]	Loss: -16.2602	Cost: 8.85s
Train Epoch: 1198 [40960/90000 (45%)]	Loss: -15.3259	Cost: 9.24s
Train Epoch: 1198 [61440/90000 (68%)]	Loss: -15.7187	Cost: 8.90s
Train Epoch: 1198 [81920/90000 (91%)]	Loss: -16.0334	Cost: 7.43s
Train Epoch: 1198 	Average Loss: -15.5757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4453

Learning rate: 0.00019992918388120855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1199 [0/90000 (0%)]	Loss: -9.5404	Cost: 27.66s
Train Epoch: 1199 [20480/90000 (23%)]	Loss: -15.9324	Cost: 6.64s
Train Epoch: 1199 [40960/90000 (45%)]	Loss: -15.5195	Cost: 9.43s
Train Epoch: 1199 [61440/90000 (68%)]	Loss: -16.1727	Cost: 8.43s
Train Epoch: 1199 [81920/90000 (91%)]	Loss: -15.8032	Cost: 8.52s
Train Epoch: 1199 	Average Loss: -15.4549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2520

Learning rate: 0.00019992906562194657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1200 [0/90000 (0%)]	Loss: -10.2681	Cost: 25.36s
Train Epoch: 1200 [20480/90000 (23%)]	Loss: -16.0124	Cost: 7.81s
Train Epoch: 1200 [40960/90000 (45%)]	Loss: -15.4158	Cost: 10.79s
Train Epoch: 1200 [61440/90000 (68%)]	Loss: -16.0172	Cost: 6.63s
Train Epoch: 1200 [81920/90000 (91%)]	Loss: -15.9291	Cost: 11.90s
Train Epoch: 1200 	Average Loss: -15.5174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3461

Learning rate: 0.00019992894726405855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1201 [0/90000 (0%)]	Loss: -10.1811	Cost: 36.82s
Train Epoch: 1201 [20480/90000 (23%)]	Loss: -16.1398	Cost: 6.87s
Train Epoch: 1201 [40960/90000 (45%)]	Loss: -15.2617	Cost: 6.56s
Train Epoch: 1201 [61440/90000 (68%)]	Loss: -15.8595	Cost: 6.22s
Train Epoch: 1201 [81920/90000 (91%)]	Loss: -15.9839	Cost: 8.37s
Train Epoch: 1201 	Average Loss: -15.4949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4030

Learning rate: 0.00019992882880754464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1202 [0/90000 (0%)]	Loss: -10.0173	Cost: 27.85s
Train Epoch: 1202 [20480/90000 (23%)]	Loss: -16.1854	Cost: 7.44s
Train Epoch: 1202 [40960/90000 (45%)]	Loss: -15.6376	Cost: 12.82s
Train Epoch: 1202 [61440/90000 (68%)]	Loss: -16.2098	Cost: 7.30s
Train Epoch: 1202 [81920/90000 (91%)]	Loss: -15.7537	Cost: 6.43s
Train Epoch: 1202 	Average Loss: -15.5708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2183

Learning rate: 0.0001999287102524049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1203 [0/90000 (0%)]	Loss: -9.2817	Cost: 35.23s
Train Epoch: 1203 [20480/90000 (23%)]	Loss: -15.5969	Cost: 8.45s
Train Epoch: 1203 [40960/90000 (45%)]	Loss: -15.1115	Cost: 12.27s
Train Epoch: 1203 [61440/90000 (68%)]	Loss: -15.7949	Cost: 11.99s
Train Epoch: 1203 [81920/90000 (91%)]	Loss: -15.8200	Cost: 9.87s
Train Epoch: 1203 	Average Loss: -15.2419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2551

Learning rate: 0.0001999285915986395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1204 [0/90000 (0%)]	Loss: -9.4282	Cost: 29.28s
Train Epoch: 1204 [20480/90000 (23%)]	Loss: -16.3205	Cost: 12.12s
Train Epoch: 1204 [40960/90000 (45%)]	Loss: -15.5400	Cost: 13.95s
Train Epoch: 1204 [61440/90000 (68%)]	Loss: -16.2175	Cost: 12.15s
Train Epoch: 1204 [81920/90000 (91%)]	Loss: -16.0442	Cost: 11.96s
Train Epoch: 1204 	Average Loss: -15.5894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4641

Learning rate: 0.00019992847284624853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1205 [0/90000 (0%)]	Loss: -9.7199	Cost: 36.20s
Train Epoch: 1205 [20480/90000 (23%)]	Loss: -16.1108	Cost: 6.35s
Train Epoch: 1205 [40960/90000 (45%)]	Loss: -15.5414	Cost: 13.02s
Train Epoch: 1205 [61440/90000 (68%)]	Loss: -15.8514	Cost: 11.99s
Train Epoch: 1205 [81920/90000 (91%)]	Loss: -15.6868	Cost: 12.38s
Train Epoch: 1205 	Average Loss: -15.4242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2583

Learning rate: 0.00019992835399523207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1206 [0/90000 (0%)]	Loss: -9.5637	Cost: 32.73s
Train Epoch: 1206 [20480/90000 (23%)]	Loss: -16.0592	Cost: 8.98s
Train Epoch: 1206 [40960/90000 (45%)]	Loss: -15.5906	Cost: 11.76s
Train Epoch: 1206 [61440/90000 (68%)]	Loss: -15.9319	Cost: 12.32s
Train Epoch: 1206 [81920/90000 (91%)]	Loss: -16.0990	Cost: 12.16s
Train Epoch: 1206 	Average Loss: -15.5212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3313

Learning rate: 0.00019992823504559032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1207 [0/90000 (0%)]	Loss: -10.0219	Cost: 25.27s
Train Epoch: 1207 [20480/90000 (23%)]	Loss: -15.8184	Cost: 6.29s
Train Epoch: 1207 [40960/90000 (45%)]	Loss: -15.0902	Cost: 9.73s
Train Epoch: 1207 [61440/90000 (68%)]	Loss: -15.8529	Cost: 11.51s
Train Epoch: 1207 [81920/90000 (91%)]	Loss: -16.0110	Cost: 12.19s
Train Epoch: 1207 	Average Loss: -15.3474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3004

Learning rate: 0.00019992811599732333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1208 [0/90000 (0%)]	Loss: -9.9406	Cost: 27.22s
Train Epoch: 1208 [20480/90000 (23%)]	Loss: -16.3222	Cost: 8.82s
Train Epoch: 1208 [40960/90000 (45%)]	Loss: -15.5196	Cost: 12.69s
Train Epoch: 1208 [61440/90000 (68%)]	Loss: -16.2453	Cost: 11.04s
Train Epoch: 1208 [81920/90000 (91%)]	Loss: -16.1115	Cost: 11.98s
Train Epoch: 1208 	Average Loss: -15.6190
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4216

Learning rate: 0.00019992799685043125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1209 [0/90000 (0%)]	Loss: -10.2937	Cost: 26.66s
Train Epoch: 1209 [20480/90000 (23%)]	Loss: -16.4181	Cost: 6.25s
Train Epoch: 1209 [40960/90000 (45%)]	Loss: -15.6869	Cost: 10.84s
Train Epoch: 1209 [61440/90000 (68%)]	Loss: -15.9817	Cost: 6.36s
Train Epoch: 1209 [81920/90000 (91%)]	Loss: -15.9346	Cost: 15.54s
Train Epoch: 1209 	Average Loss: -15.6250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1260

Learning rate: 0.00019992787760491417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1210 [0/90000 (0%)]	Loss: -9.2624	Cost: 23.88s
Train Epoch: 1210 [20480/90000 (23%)]	Loss: -16.3034	Cost: 8.70s
Train Epoch: 1210 [40960/90000 (45%)]	Loss: -15.7256	Cost: 12.09s
Train Epoch: 1210 [61440/90000 (68%)]	Loss: -15.8699	Cost: 11.81s
Train Epoch: 1210 [81920/90000 (91%)]	Loss: -16.0312	Cost: 12.13s
Train Epoch: 1210 	Average Loss: -15.5610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4080

Learning rate: 0.00019992775826077226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1211 [0/90000 (0%)]	Loss: -10.3447	Cost: 31.83s
Train Epoch: 1211 [20480/90000 (23%)]	Loss: -16.3843	Cost: 6.86s
Train Epoch: 1211 [40960/90000 (45%)]	Loss: -15.7886	Cost: 9.85s
Train Epoch: 1211 [61440/90000 (68%)]	Loss: -16.1889	Cost: 11.81s
Train Epoch: 1211 [81920/90000 (91%)]	Loss: -16.2629	Cost: 12.09s
Train Epoch: 1211 	Average Loss: -15.7821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5467

Saving model as e1211_model.pt & e1211_waveforms_supplementary.hdf5
Learning rate: 0.0001999276388180056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1212 [0/90000 (0%)]	Loss: -9.8611	Cost: 25.42s
Train Epoch: 1212 [20480/90000 (23%)]	Loss: -16.4383	Cost: 6.77s
Train Epoch: 1212 [40960/90000 (45%)]	Loss: -15.6644	Cost: 17.33s
Train Epoch: 1212 [61440/90000 (68%)]	Loss: -16.1670	Cost: 12.15s
Train Epoch: 1212 [81920/90000 (91%)]	Loss: -15.8979	Cost: 11.87s
Train Epoch: 1212 	Average Loss: -15.7142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3829

Learning rate: 0.00019992751927661433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1213 [0/90000 (0%)]	Loss: -9.2110	Cost: 27.91s
Train Epoch: 1213 [20480/90000 (23%)]	Loss: -16.2975	Cost: 7.89s
Train Epoch: 1213 [40960/90000 (45%)]	Loss: -15.5547	Cost: 12.33s
Train Epoch: 1213 [61440/90000 (68%)]	Loss: -16.0155	Cost: 12.15s
Train Epoch: 1213 [81920/90000 (91%)]	Loss: -15.9109	Cost: 11.98s
Train Epoch: 1213 	Average Loss: -15.4889
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4225

Learning rate: 0.00019992739963659852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1214 [0/90000 (0%)]	Loss: -10.2186	Cost: 26.14s
Train Epoch: 1214 [20480/90000 (23%)]	Loss: -16.2204	Cost: 8.58s
Train Epoch: 1214 [40960/90000 (45%)]	Loss: -15.7149	Cost: 17.02s
Train Epoch: 1214 [61440/90000 (68%)]	Loss: -15.7258	Cost: 11.91s
Train Epoch: 1214 [81920/90000 (91%)]	Loss: -15.6912	Cost: 12.26s
Train Epoch: 1214 	Average Loss: -15.4934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2765

Learning rate: 0.00019992727989795832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1215 [0/90000 (0%)]	Loss: -9.6188	Cost: 35.32s
Train Epoch: 1215 [20480/90000 (23%)]	Loss: -15.5267	Cost: 10.82s
Train Epoch: 1215 [40960/90000 (45%)]	Loss: -14.9913	Cost: 12.18s
Train Epoch: 1215 [61440/90000 (68%)]	Loss: -15.6518	Cost: 11.89s
Train Epoch: 1215 [81920/90000 (91%)]	Loss: -15.5601	Cost: 12.30s
Train Epoch: 1215 	Average Loss: -15.1713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0729

Learning rate: 0.0001999271600606939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1216 [0/90000 (0%)]	Loss: -9.9383	Cost: 35.26s
Train Epoch: 1216 [20480/90000 (23%)]	Loss: -15.8914	Cost: 11.14s
Train Epoch: 1216 [40960/90000 (45%)]	Loss: -15.2199	Cost: 12.25s
Train Epoch: 1216 [61440/90000 (68%)]	Loss: -15.8120	Cost: 12.11s
Train Epoch: 1216 [81920/90000 (91%)]	Loss: -16.0886	Cost: 11.91s
Train Epoch: 1216 	Average Loss: -15.3635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5942

Saving model as e1216_model.pt & e1216_waveforms_supplementary.hdf5
Learning rate: 0.00019992704012480525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1217 [0/90000 (0%)]	Loss: -9.5330	Cost: 27.94s
Train Epoch: 1217 [20480/90000 (23%)]	Loss: -16.1686	Cost: 10.72s
Train Epoch: 1217 [40960/90000 (45%)]	Loss: -15.4824	Cost: 13.26s
Train Epoch: 1217 [61440/90000 (68%)]	Loss: -16.2320	Cost: 12.42s
Train Epoch: 1217 [81920/90000 (91%)]	Loss: -16.0169	Cost: 11.94s
Train Epoch: 1217 	Average Loss: -15.6286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3475

Learning rate: 0.00019992692009029262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1218 [0/90000 (0%)]	Loss: -9.4890	Cost: 33.71s
Train Epoch: 1218 [20480/90000 (23%)]	Loss: -15.8268	Cost: 8.29s
Train Epoch: 1218 [40960/90000 (45%)]	Loss: -15.5505	Cost: 12.18s
Train Epoch: 1218 [61440/90000 (68%)]	Loss: -15.8312	Cost: 12.12s
Train Epoch: 1218 [81920/90000 (91%)]	Loss: -16.0801	Cost: 12.19s
Train Epoch: 1218 	Average Loss: -15.4869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5107

Learning rate: 0.00019992679995715608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1219 [0/90000 (0%)]	Loss: -10.6214	Cost: 30.84s
Train Epoch: 1219 [20480/90000 (23%)]	Loss: -16.4811	Cost: 8.84s
Train Epoch: 1219 [40960/90000 (45%)]	Loss: -16.0298	Cost: 12.59s
Train Epoch: 1219 [61440/90000 (68%)]	Loss: -16.2835	Cost: 11.76s
Train Epoch: 1219 [81920/90000 (91%)]	Loss: -16.2979	Cost: 12.17s
Train Epoch: 1219 	Average Loss: -15.8405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4814

Learning rate: 0.00019992667972539572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1220 [0/90000 (0%)]	Loss: -9.9947	Cost: 25.97s
Train Epoch: 1220 [20480/90000 (23%)]	Loss: -16.5162	Cost: 6.87s
Train Epoch: 1220 [40960/90000 (45%)]	Loss: -15.7252	Cost: 9.98s
Train Epoch: 1220 [61440/90000 (68%)]	Loss: -16.0926	Cost: 8.17s
Train Epoch: 1220 [81920/90000 (91%)]	Loss: -16.2658	Cost: 13.88s
Train Epoch: 1220 	Average Loss: -15.7986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5309

Learning rate: 0.00019992655939501169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1221 [0/90000 (0%)]	Loss: -10.0637	Cost: 24.33s
Train Epoch: 1221 [20480/90000 (23%)]	Loss: -16.6656	Cost: 8.69s
Train Epoch: 1221 [40960/90000 (45%)]	Loss: -15.5363	Cost: 17.57s
Train Epoch: 1221 [61440/90000 (68%)]	Loss: -15.9712	Cost: 9.07s
Train Epoch: 1221 [81920/90000 (91%)]	Loss: -15.7294	Cost: 13.36s
Train Epoch: 1221 	Average Loss: -15.6006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3344

Learning rate: 0.0001999264389660041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1222 [0/90000 (0%)]	Loss: -9.9401	Cost: 27.02s
Train Epoch: 1222 [20480/90000 (23%)]	Loss: -15.0340	Cost: 6.27s
Train Epoch: 1222 [40960/90000 (45%)]	Loss: -14.6529	Cost: 10.43s
Train Epoch: 1222 [61440/90000 (68%)]	Loss: -15.1496	Cost: 6.20s
Train Epoch: 1222 [81920/90000 (91%)]	Loss: -15.6491	Cost: 15.62s
Train Epoch: 1222 	Average Loss: -14.7961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1778

Learning rate: 0.00019992631843837304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1223 [0/90000 (0%)]	Loss: -9.2246	Cost: 24.24s
Train Epoch: 1223 [20480/90000 (23%)]	Loss: -16.0017	Cost: 6.15s
Train Epoch: 1223 [40960/90000 (45%)]	Loss: -15.4290	Cost: 14.58s
Train Epoch: 1223 [61440/90000 (68%)]	Loss: -15.9723	Cost: 11.94s
Train Epoch: 1223 [81920/90000 (91%)]	Loss: -15.9748	Cost: 12.09s
Train Epoch: 1223 	Average Loss: -15.4629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4510

Learning rate: 0.00019992619781211864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1224 [0/90000 (0%)]	Loss: -9.5461	Cost: 28.89s
Train Epoch: 1224 [20480/90000 (23%)]	Loss: -16.3180	Cost: 8.53s
Train Epoch: 1224 [40960/90000 (45%)]	Loss: -15.6888	Cost: 8.85s
Train Epoch: 1224 [61440/90000 (68%)]	Loss: -15.9562	Cost: 6.23s
Train Epoch: 1224 [81920/90000 (91%)]	Loss: -15.8968	Cost: 14.78s
Train Epoch: 1224 	Average Loss: -15.6571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4450

Learning rate: 0.0001999260770872411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1225 [0/90000 (0%)]	Loss: -9.9410	Cost: 24.68s
Train Epoch: 1225 [20480/90000 (23%)]	Loss: -16.2167	Cost: 6.37s
Train Epoch: 1225 [40960/90000 (45%)]	Loss: -15.0231	Cost: 10.03s
Train Epoch: 1225 [61440/90000 (68%)]	Loss: -15.5662	Cost: 6.60s
Train Epoch: 1225 [81920/90000 (91%)]	Loss: -15.6814	Cost: 16.05s
Train Epoch: 1225 	Average Loss: -15.3639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1321

Learning rate: 0.00019992595626374044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1226 [0/90000 (0%)]	Loss: -9.7080	Cost: 24.69s
Train Epoch: 1226 [20480/90000 (23%)]	Loss: -16.1448	Cost: 8.77s
Train Epoch: 1226 [40960/90000 (45%)]	Loss: -15.3945	Cost: 12.06s
Train Epoch: 1226 [61440/90000 (68%)]	Loss: -15.8072	Cost: 7.36s
Train Epoch: 1226 [81920/90000 (91%)]	Loss: -15.9392	Cost: 15.46s
Train Epoch: 1226 	Average Loss: -15.4910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5527

Learning rate: 0.00019992583534161684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1227 [0/90000 (0%)]	Loss: -9.5782	Cost: 28.21s
Train Epoch: 1227 [20480/90000 (23%)]	Loss: -16.5026	Cost: 6.44s
Train Epoch: 1227 [40960/90000 (45%)]	Loss: -15.7573	Cost: 9.70s
Train Epoch: 1227 [61440/90000 (68%)]	Loss: -16.1756	Cost: 6.31s
Train Epoch: 1227 [81920/90000 (91%)]	Loss: -16.1759	Cost: 12.95s
Train Epoch: 1227 	Average Loss: -15.7377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5862

Learning rate: 0.00019992571432087038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1228 [0/90000 (0%)]	Loss: -9.4885	Cost: 23.65s
Train Epoch: 1228 [20480/90000 (23%)]	Loss: -16.3569	Cost: 6.40s
Train Epoch: 1228 [40960/90000 (45%)]	Loss: -15.9285	Cost: 15.94s
Train Epoch: 1228 [61440/90000 (68%)]	Loss: -16.4195	Cost: 6.74s
Train Epoch: 1228 [81920/90000 (91%)]	Loss: -16.2312	Cost: 17.53s
Train Epoch: 1228 	Average Loss: -15.8449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4486

Learning rate: 0.00019992559320150118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1229 [0/90000 (0%)]	Loss: -9.9106	Cost: 27.40s
Train Epoch: 1229 [20480/90000 (23%)]	Loss: -16.5867	Cost: 6.80s
Train Epoch: 1229 [40960/90000 (45%)]	Loss: -16.0031	Cost: 9.59s
Train Epoch: 1229 [61440/90000 (68%)]	Loss: -16.3879	Cost: 6.20s
Train Epoch: 1229 [81920/90000 (91%)]	Loss: -16.3545	Cost: 15.87s
Train Epoch: 1229 	Average Loss: -15.9264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7440

Saving model as e1229_model.pt & e1229_waveforms_supplementary.hdf5
Learning rate: 0.00019992547198350937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1230 [0/90000 (0%)]	Loss: -10.5114	Cost: 24.20s
Train Epoch: 1230 [20480/90000 (23%)]	Loss: -16.5752	Cost: 8.85s
Train Epoch: 1230 [40960/90000 (45%)]	Loss: -16.1335	Cost: 13.49s
Train Epoch: 1230 [61440/90000 (68%)]	Loss: -16.3135	Cost: 9.53s
Train Epoch: 1230 [81920/90000 (91%)]	Loss: -16.2149	Cost: 14.57s
Train Epoch: 1230 	Average Loss: -15.9098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3513

Learning rate: 0.00019992535066689507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1231 [0/90000 (0%)]	Loss: -9.9680	Cost: 27.75s
Train Epoch: 1231 [20480/90000 (23%)]	Loss: -16.0041	Cost: 7.61s
Train Epoch: 1231 [40960/90000 (45%)]	Loss: -15.5408	Cost: 9.02s
Train Epoch: 1231 [61440/90000 (68%)]	Loss: -16.1246	Cost: 6.39s
Train Epoch: 1231 [81920/90000 (91%)]	Loss: -16.3075	Cost: 15.63s
Train Epoch: 1231 	Average Loss: -15.5843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5362

Learning rate: 0.0001999252292516584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1232 [0/90000 (0%)]	Loss: -10.0237	Cost: 24.74s
Train Epoch: 1232 [20480/90000 (23%)]	Loss: -16.2346	Cost: 6.50s
Train Epoch: 1232 [40960/90000 (45%)]	Loss: -15.6314	Cost: 13.05s
Train Epoch: 1232 [61440/90000 (68%)]	Loss: -15.8817	Cost: 12.95s
Train Epoch: 1232 [81920/90000 (91%)]	Loss: -15.6993	Cost: 12.16s
Train Epoch: 1232 	Average Loss: -15.6496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3368

Learning rate: 0.0001999251077377995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1233 [0/90000 (0%)]	Loss: -9.4274	Cost: 33.83s
Train Epoch: 1233 [20480/90000 (23%)]	Loss: -16.2212	Cost: 7.06s
Train Epoch: 1233 [40960/90000 (45%)]	Loss: -15.6222	Cost: 12.47s
Train Epoch: 1233 [61440/90000 (68%)]	Loss: -16.4002	Cost: 11.48s
Train Epoch: 1233 [81920/90000 (91%)]	Loss: -16.4698	Cost: 11.93s
Train Epoch: 1233 	Average Loss: -15.7351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8726

Saving model as e1233_model.pt & e1233_waveforms_supplementary.hdf5
Learning rate: 0.00019992498612531848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1234 [0/90000 (0%)]	Loss: -10.0110	Cost: 25.76s
Train Epoch: 1234 [20480/90000 (23%)]	Loss: -16.5074	Cost: 8.48s
Train Epoch: 1234 [40960/90000 (45%)]	Loss: -15.7551	Cost: 13.56s
Train Epoch: 1234 [61440/90000 (68%)]	Loss: -16.5201	Cost: 12.02s
Train Epoch: 1234 [81920/90000 (91%)]	Loss: -16.1174	Cost: 11.82s
Train Epoch: 1234 	Average Loss: -15.9160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6654

Learning rate: 0.00019992486441421542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1235 [0/90000 (0%)]	Loss: -9.8851	Cost: 34.39s
Train Epoch: 1235 [20480/90000 (23%)]	Loss: -16.6362	Cost: 8.33s
Train Epoch: 1235 [40960/90000 (45%)]	Loss: -15.9117	Cost: 12.21s
Train Epoch: 1235 [61440/90000 (68%)]	Loss: -16.4721	Cost: 12.03s
Train Epoch: 1235 [81920/90000 (91%)]	Loss: -16.3689	Cost: 12.25s
Train Epoch: 1235 	Average Loss: -15.8940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7734

Learning rate: 0.0001999247426044905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1236 [0/90000 (0%)]	Loss: -10.6399	Cost: 27.63s
Train Epoch: 1236 [20480/90000 (23%)]	Loss: -16.3781	Cost: 8.63s
Train Epoch: 1236 [40960/90000 (45%)]	Loss: -15.7680	Cost: 9.49s
Train Epoch: 1236 [61440/90000 (68%)]	Loss: -15.9043	Cost: 10.74s
Train Epoch: 1236 [81920/90000 (91%)]	Loss: -16.0206	Cost: 12.12s
Train Epoch: 1236 	Average Loss: -15.6837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4210

Learning rate: 0.0001999246206961438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1237 [0/90000 (0%)]	Loss: -9.6455	Cost: 26.26s
Train Epoch: 1237 [20480/90000 (23%)]	Loss: -16.1724	Cost: 6.35s
Train Epoch: 1237 [40960/90000 (45%)]	Loss: -15.3059	Cost: 10.71s
Train Epoch: 1237 [61440/90000 (68%)]	Loss: -15.9878	Cost: 6.34s
Train Epoch: 1237 [81920/90000 (91%)]	Loss: -16.2470	Cost: 15.43s
Train Epoch: 1237 	Average Loss: -15.5394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7074

Learning rate: 0.00019992449868917544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1238 [0/90000 (0%)]	Loss: -9.6317	Cost: 23.78s
Train Epoch: 1238 [20480/90000 (23%)]	Loss: -16.3823	Cost: 8.51s
Train Epoch: 1238 [40960/90000 (45%)]	Loss: -15.9889	Cost: 13.99s
Train Epoch: 1238 [61440/90000 (68%)]	Loss: -16.3573	Cost: 11.28s
Train Epoch: 1238 [81920/90000 (91%)]	Loss: -16.6524	Cost: 12.87s
Train Epoch: 1238 	Average Loss: -15.9634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9495

Saving model as e1238_model.pt & e1238_waveforms_supplementary.hdf5
Learning rate: 0.00019992437658358558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1239 [0/90000 (0%)]	Loss: -10.2069	Cost: 27.82s
Train Epoch: 1239 [20480/90000 (23%)]	Loss: -16.7358	Cost: 6.46s
Train Epoch: 1239 [40960/90000 (45%)]	Loss: -16.2390	Cost: 10.56s
Train Epoch: 1239 [61440/90000 (68%)]	Loss: -16.4473	Cost: 9.05s
Train Epoch: 1239 [81920/90000 (91%)]	Loss: -16.4915	Cost: 13.34s
Train Epoch: 1239 	Average Loss: -16.1061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8832

Learning rate: 0.0001999242543793743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1240 [0/90000 (0%)]	Loss: -10.1247	Cost: 26.67s
Train Epoch: 1240 [20480/90000 (23%)]	Loss: -16.6587	Cost: 6.03s
Train Epoch: 1240 [40960/90000 (45%)]	Loss: -15.9668	Cost: 17.38s
Train Epoch: 1240 [61440/90000 (68%)]	Loss: -16.5917	Cost: 11.91s
Train Epoch: 1240 [81920/90000 (91%)]	Loss: -16.5015	Cost: 11.89s
Train Epoch: 1240 	Average Loss: -16.0715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6747

Learning rate: 0.0001999241320765417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1241 [0/90000 (0%)]	Loss: -10.3630	Cost: 28.68s
Train Epoch: 1241 [20480/90000 (23%)]	Loss: -16.5516	Cost: 7.02s
Train Epoch: 1241 [40960/90000 (45%)]	Loss: -15.8567	Cost: 12.77s
Train Epoch: 1241 [61440/90000 (68%)]	Loss: -16.0726	Cost: 12.04s
Train Epoch: 1241 [81920/90000 (91%)]	Loss: -16.2774	Cost: 12.22s
Train Epoch: 1241 	Average Loss: -15.8767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6941

Learning rate: 0.000199924009675088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1242 [0/90000 (0%)]	Loss: -9.6396	Cost: 25.37s
Train Epoch: 1242 [20480/90000 (23%)]	Loss: -16.6540	Cost: 8.75s
Train Epoch: 1242 [40960/90000 (45%)]	Loss: -16.0562	Cost: 12.26s
Train Epoch: 1242 [61440/90000 (68%)]	Loss: -16.6046	Cost: 12.53s
Train Epoch: 1242 [81920/90000 (91%)]	Loss: -16.4944	Cost: 12.04s
Train Epoch: 1242 	Average Loss: -16.0176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9214

Learning rate: 0.0001999238871750132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1243 [0/90000 (0%)]	Loss: -10.5760	Cost: 27.73s
Train Epoch: 1243 [20480/90000 (23%)]	Loss: -16.6907	Cost: 7.62s
Train Epoch: 1243 [40960/90000 (45%)]	Loss: -16.3439	Cost: 9.11s
Train Epoch: 1243 [61440/90000 (68%)]	Loss: -16.7876	Cost: 11.71s
Train Epoch: 1243 [81920/90000 (91%)]	Loss: -16.3962	Cost: 12.11s
Train Epoch: 1243 	Average Loss: -16.1269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7735

Learning rate: 0.0001999237645763175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1244 [0/90000 (0%)]	Loss: -10.2068	Cost: 25.53s
Train Epoch: 1244 [20480/90000 (23%)]	Loss: -16.5513	Cost: 8.81s
Train Epoch: 1244 [40960/90000 (45%)]	Loss: -15.8788	Cost: 13.26s
Train Epoch: 1244 [61440/90000 (68%)]	Loss: -16.5788	Cost: 12.47s
Train Epoch: 1244 [81920/90000 (91%)]	Loss: -16.3161	Cost: 11.98s
Train Epoch: 1244 	Average Loss: -15.9779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5525

Learning rate: 0.000199923641879001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1245 [0/90000 (0%)]	Loss: -10.3889	Cost: 29.96s
Train Epoch: 1245 [20480/90000 (23%)]	Loss: -16.7151	Cost: 6.82s
Train Epoch: 1245 [40960/90000 (45%)]	Loss: -15.8593	Cost: 10.10s
Train Epoch: 1245 [61440/90000 (68%)]	Loss: -16.4624	Cost: 12.25s
Train Epoch: 1245 [81920/90000 (91%)]	Loss: -16.3544	Cost: 12.10s
Train Epoch: 1245 	Average Loss: -15.9181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5149

Learning rate: 0.00019992351908306382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1246 [0/90000 (0%)]	Loss: -9.9243	Cost: 25.82s
Train Epoch: 1246 [20480/90000 (23%)]	Loss: -16.3756	Cost: 6.37s
Train Epoch: 1246 [40960/90000 (45%)]	Loss: -15.9968	Cost: 15.79s
Train Epoch: 1246 [61440/90000 (68%)]	Loss: -14.6868	Cost: 11.97s
Train Epoch: 1246 [81920/90000 (91%)]	Loss: -13.6559	Cost: 12.12s
Train Epoch: 1246 	Average Loss: -15.0712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2556

Learning rate: 0.00019992339618850606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1247 [0/90000 (0%)]	Loss: -7.4623	Cost: 33.12s
Train Epoch: 1247 [20480/90000 (23%)]	Loss: -14.5343	Cost: 6.39s
Train Epoch: 1247 [40960/90000 (45%)]	Loss: -14.0267	Cost: 12.44s
Train Epoch: 1247 [61440/90000 (68%)]	Loss: -14.7310	Cost: 12.07s
Train Epoch: 1247 [81920/90000 (91%)]	Loss: -15.2536	Cost: 11.92s
Train Epoch: 1247 	Average Loss: -14.1240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8924

Learning rate: 0.00019992327319532787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1248 [0/90000 (0%)]	Loss: -10.1761	Cost: 27.99s
Train Epoch: 1248 [20480/90000 (23%)]	Loss: -16.0035	Cost: 8.58s
Train Epoch: 1248 [40960/90000 (45%)]	Loss: -15.5493	Cost: 14.11s
Train Epoch: 1248 [61440/90000 (68%)]	Loss: -16.0943	Cost: 12.01s
Train Epoch: 1248 [81920/90000 (91%)]	Loss: -16.2290	Cost: 12.01s
Train Epoch: 1248 	Average Loss: -15.5985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7035

Learning rate: 0.0001999231501035294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1249 [0/90000 (0%)]	Loss: -10.5765	Cost: 27.87s
Train Epoch: 1249 [20480/90000 (23%)]	Loss: -16.3521	Cost: 6.92s
Train Epoch: 1249 [40960/90000 (45%)]	Loss: -15.9079	Cost: 13.59s
Train Epoch: 1249 [61440/90000 (68%)]	Loss: -16.4776	Cost: 11.86s
Train Epoch: 1249 [81920/90000 (91%)]	Loss: -16.5867	Cost: 12.27s
Train Epoch: 1249 	Average Loss: -15.9793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9033

Learning rate: 0.00019992302691311067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1250 [0/90000 (0%)]	Loss: -9.6539	Cost: 27.25s
Train Epoch: 1250 [20480/90000 (23%)]	Loss: -16.7270	Cost: 9.50s
Train Epoch: 1250 [40960/90000 (45%)]	Loss: -16.2000	Cost: 14.48s
Train Epoch: 1250 [61440/90000 (68%)]	Loss: -16.3517	Cost: 11.93s
Train Epoch: 1250 [81920/90000 (91%)]	Loss: -16.5592	Cost: 11.98s
Train Epoch: 1250 	Average Loss: -16.1000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0243

Saving model as e1250_model.pt & e1250_waveforms_supplementary.hdf5
Learning rate: 0.00019992290362407192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1251 [0/90000 (0%)]	Loss: -10.3034	Cost: 28.22s
Train Epoch: 1251 [20480/90000 (23%)]	Loss: -16.8288	Cost: 6.91s
Train Epoch: 1251 [40960/90000 (45%)]	Loss: -15.3592	Cost: 12.41s
Train Epoch: 1251 [61440/90000 (68%)]	Loss: -15.9726	Cost: 12.41s
Train Epoch: 1251 [81920/90000 (91%)]	Loss: -16.0618	Cost: 12.07s
Train Epoch: 1251 	Average Loss: -15.7917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4549

Learning rate: 0.00019992278023641319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1252 [0/90000 (0%)]	Loss: -8.8898	Cost: 32.97s
Train Epoch: 1252 [20480/90000 (23%)]	Loss: -16.4932	Cost: 8.92s
Train Epoch: 1252 [40960/90000 (45%)]	Loss: -16.0013	Cost: 15.55s
Train Epoch: 1252 [61440/90000 (68%)]	Loss: -16.5009	Cost: 11.89s
Train Epoch: 1252 [81920/90000 (91%)]	Loss: -16.2226	Cost: 11.96s
Train Epoch: 1252 	Average Loss: -15.8628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5147

Learning rate: 0.00019992265675013464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1253 [0/90000 (0%)]	Loss: -10.3958	Cost: 26.61s
Train Epoch: 1253 [20480/90000 (23%)]	Loss: -16.4963	Cost: 6.26s
Train Epoch: 1253 [40960/90000 (45%)]	Loss: -15.6667	Cost: 13.68s
Train Epoch: 1253 [61440/90000 (68%)]	Loss: -16.3079	Cost: 11.44s
Train Epoch: 1253 [81920/90000 (91%)]	Loss: -16.1012	Cost: 12.30s
Train Epoch: 1253 	Average Loss: -15.7763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6973

Learning rate: 0.00019992253316523635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1254 [0/90000 (0%)]	Loss: -9.2040	Cost: 37.31s
Train Epoch: 1254 [20480/90000 (23%)]	Loss: -16.5825	Cost: 10.80s
Train Epoch: 1254 [40960/90000 (45%)]	Loss: -15.9019	Cost: 12.21s
Train Epoch: 1254 [61440/90000 (68%)]	Loss: -16.4555	Cost: 12.11s
Train Epoch: 1254 [81920/90000 (91%)]	Loss: -16.6997	Cost: 12.10s
Train Epoch: 1254 	Average Loss: -16.0807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0593

Saving model as e1254_model.pt & e1254_waveforms_supplementary.hdf5
Learning rate: 0.0001999224094817185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1255 [0/90000 (0%)]	Loss: -11.0748	Cost: 33.62s
Train Epoch: 1255 [20480/90000 (23%)]	Loss: -17.0082	Cost: 12.73s
Train Epoch: 1255 [40960/90000 (45%)]	Loss: -16.4113	Cost: 12.14s
Train Epoch: 1255 [61440/90000 (68%)]	Loss: -16.7173	Cost: 12.03s
Train Epoch: 1255 [81920/90000 (91%)]	Loss: -16.6844	Cost: 11.70s
Train Epoch: 1255 	Average Loss: -16.3227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0015

Learning rate: 0.00019992228569958118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1256 [0/90000 (0%)]	Loss: -10.7567	Cost: 27.40s
Train Epoch: 1256 [20480/90000 (23%)]	Loss: -16.8321	Cost: 10.88s
Train Epoch: 1256 [40960/90000 (45%)]	Loss: -16.0241	Cost: 12.91s
Train Epoch: 1256 [61440/90000 (68%)]	Loss: -16.4470	Cost: 12.22s
Train Epoch: 1256 [81920/90000 (91%)]	Loss: -16.0543	Cost: 11.93s
Train Epoch: 1256 	Average Loss: -16.0532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4645

Learning rate: 0.0001999221618188245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1257 [0/90000 (0%)]	Loss: -10.0887	Cost: 40.59s
Train Epoch: 1257 [20480/90000 (23%)]	Loss: -16.3852	Cost: 11.95s
Train Epoch: 1257 [40960/90000 (45%)]	Loss: -15.9685	Cost: 12.08s
Train Epoch: 1257 [61440/90000 (68%)]	Loss: -16.5425	Cost: 12.10s
Train Epoch: 1257 [81920/90000 (91%)]	Loss: -16.4396	Cost: 12.14s
Train Epoch: 1257 	Average Loss: -15.9301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6896

Learning rate: 0.00019992203783944864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1258 [0/90000 (0%)]	Loss: -10.0854	Cost: 31.49s
Train Epoch: 1258 [20480/90000 (23%)]	Loss: -16.5137	Cost: 9.16s
Train Epoch: 1258 [40960/90000 (45%)]	Loss: -16.2000	Cost: 11.19s
Train Epoch: 1258 [61440/90000 (68%)]	Loss: -16.6175	Cost: 12.33s
Train Epoch: 1258 [81920/90000 (91%)]	Loss: -16.5034	Cost: 12.12s
Train Epoch: 1258 	Average Loss: -16.0374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7186

Learning rate: 0.00019992191376145364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1259 [0/90000 (0%)]	Loss: -10.3510	Cost: 25.98s
Train Epoch: 1259 [20480/90000 (23%)]	Loss: -16.5926	Cost: 6.49s
Train Epoch: 1259 [40960/90000 (45%)]	Loss: -16.1443	Cost: 13.16s
Train Epoch: 1259 [61440/90000 (68%)]	Loss: -16.6544	Cost: 12.21s
Train Epoch: 1259 [81920/90000 (91%)]	Loss: -16.3871	Cost: 12.03s
Train Epoch: 1259 	Average Loss: -16.0504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5660

Learning rate: 0.0001999217895848397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1260 [0/90000 (0%)]	Loss: -10.7059	Cost: 33.48s
Train Epoch: 1260 [20480/90000 (23%)]	Loss: -16.8115	Cost: 7.01s
Train Epoch: 1260 [40960/90000 (45%)]	Loss: -15.9826	Cost: 10.15s
Train Epoch: 1260 [61440/90000 (68%)]	Loss: -16.4280	Cost: 12.10s
Train Epoch: 1260 [81920/90000 (91%)]	Loss: -16.5257	Cost: 12.01s
Train Epoch: 1260 	Average Loss: -16.0559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7980

Learning rate: 0.0001999216653096069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1261 [0/90000 (0%)]	Loss: -10.2941	Cost: 26.20s
Train Epoch: 1261 [20480/90000 (23%)]	Loss: -16.6335	Cost: 6.23s
Train Epoch: 1261 [40960/90000 (45%)]	Loss: -15.9337	Cost: 15.20s
Train Epoch: 1261 [61440/90000 (68%)]	Loss: -16.2639	Cost: 12.21s
Train Epoch: 1261 [81920/90000 (91%)]	Loss: -16.5741	Cost: 12.00s
Train Epoch: 1261 	Average Loss: -15.9349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7705

Learning rate: 0.00019992154093575535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1262 [0/90000 (0%)]	Loss: -10.2028	Cost: 28.41s
Train Epoch: 1262 [20480/90000 (23%)]	Loss: -16.5098	Cost: 8.18s
Train Epoch: 1262 [40960/90000 (45%)]	Loss: -16.1272	Cost: 9.77s
Train Epoch: 1262 [61440/90000 (68%)]	Loss: -16.3737	Cost: 12.10s
Train Epoch: 1262 [81920/90000 (91%)]	Loss: -16.1381	Cost: 12.11s
Train Epoch: 1262 	Average Loss: -15.8992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5616

Learning rate: 0.0001999214164632852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1263 [0/90000 (0%)]	Loss: -10.4045	Cost: 26.11s
Train Epoch: 1263 [20480/90000 (23%)]	Loss: -16.4371	Cost: 8.45s
Train Epoch: 1263 [40960/90000 (45%)]	Loss: -16.0241	Cost: 15.91s
Train Epoch: 1263 [61440/90000 (68%)]	Loss: -16.5528	Cost: 11.60s
Train Epoch: 1263 [81920/90000 (91%)]	Loss: -16.8247	Cost: 11.90s
Train Epoch: 1263 	Average Loss: -16.0947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0535

Learning rate: 0.00019992129189219657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1264 [0/90000 (0%)]	Loss: -10.6950	Cost: 33.88s
Train Epoch: 1264 [20480/90000 (23%)]	Loss: -16.9437	Cost: 8.86s
Train Epoch: 1264 [40960/90000 (45%)]	Loss: -16.2134	Cost: 12.41s
Train Epoch: 1264 [61440/90000 (68%)]	Loss: -16.8126	Cost: 12.02s
Train Epoch: 1264 [81920/90000 (91%)]	Loss: -16.9270	Cost: 12.24s
Train Epoch: 1264 	Average Loss: -16.3931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1716

Saving model as e1264_model.pt & e1264_waveforms_supplementary.hdf5
Learning rate: 0.00019992116722248958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1265 [0/90000 (0%)]	Loss: -10.5934	Cost: 40.35s
Train Epoch: 1265 [20480/90000 (23%)]	Loss: -16.8023	Cost: 12.08s
Train Epoch: 1265 [40960/90000 (45%)]	Loss: -16.2025	Cost: 12.20s
Train Epoch: 1265 [61440/90000 (68%)]	Loss: -16.7259	Cost: 11.98s
Train Epoch: 1265 [81920/90000 (91%)]	Loss: -16.7090	Cost: 11.58s
Train Epoch: 1265 	Average Loss: -16.2527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0720

Learning rate: 0.00019992104245416436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1266 [0/90000 (0%)]	Loss: -10.7866	Cost: 33.60s
Train Epoch: 1266 [20480/90000 (23%)]	Loss: -16.9002	Cost: 12.59s
Train Epoch: 1266 [40960/90000 (45%)]	Loss: -16.3773	Cost: 12.51s
Train Epoch: 1266 [61440/90000 (68%)]	Loss: -16.7815	Cost: 11.92s
Train Epoch: 1266 [81920/90000 (91%)]	Loss: -16.7958	Cost: 11.86s
Train Epoch: 1266 	Average Loss: -16.3235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0084

Learning rate: 0.000199920917587221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1267 [0/90000 (0%)]	Loss: -9.9020	Cost: 29.07s
Train Epoch: 1267 [20480/90000 (23%)]	Loss: -17.0423	Cost: 12.36s
Train Epoch: 1267 [40960/90000 (45%)]	Loss: -16.1980	Cost: 12.03s
Train Epoch: 1267 [61440/90000 (68%)]	Loss: -16.5208	Cost: 12.07s
Train Epoch: 1267 [81920/90000 (91%)]	Loss: -16.6567	Cost: 11.72s
Train Epoch: 1267 	Average Loss: -16.2333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0605

Learning rate: 0.00019992079262165963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1268 [0/90000 (0%)]	Loss: -10.9800	Cost: 29.87s
Train Epoch: 1268 [20480/90000 (23%)]	Loss: -16.9352	Cost: 8.45s
Train Epoch: 1268 [40960/90000 (45%)]	Loss: -16.0479	Cost: 12.35s
Train Epoch: 1268 [61440/90000 (68%)]	Loss: -16.3715	Cost: 12.30s
Train Epoch: 1268 [81920/90000 (91%)]	Loss: -16.3631	Cost: 12.08s
Train Epoch: 1268 	Average Loss: -16.1226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5999

Learning rate: 0.00019992066755748043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1269 [0/90000 (0%)]	Loss: -10.2106	Cost: 28.72s
Train Epoch: 1269 [20480/90000 (23%)]	Loss: -16.8935	Cost: 8.89s
Train Epoch: 1269 [40960/90000 (45%)]	Loss: -16.2600	Cost: 14.20s
Train Epoch: 1269 [61440/90000 (68%)]	Loss: -16.6673	Cost: 12.22s
Train Epoch: 1269 [81920/90000 (91%)]	Loss: -16.7566	Cost: 12.19s
Train Epoch: 1269 	Average Loss: -16.2730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0014

Learning rate: 0.00019992054239468347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1270 [0/90000 (0%)]	Loss: -10.0784	Cost: 26.02s
Train Epoch: 1270 [20480/90000 (23%)]	Loss: -17.0903	Cost: 6.61s
Train Epoch: 1270 [40960/90000 (45%)]	Loss: -16.3081	Cost: 12.56s
Train Epoch: 1270 [61440/90000 (68%)]	Loss: -16.6539	Cost: 12.87s
Train Epoch: 1270 [81920/90000 (91%)]	Loss: -16.9364	Cost: 12.21s
Train Epoch: 1270 	Average Loss: -16.3926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1339

Learning rate: 0.0001999204171332689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1271 [0/90000 (0%)]	Loss: -9.7562	Cost: 27.14s
Train Epoch: 1271 [20480/90000 (23%)]	Loss: -16.9430	Cost: 9.16s
Train Epoch: 1271 [40960/90000 (45%)]	Loss: -16.3358	Cost: 9.68s
Train Epoch: 1271 [61440/90000 (68%)]	Loss: -16.5478	Cost: 7.47s
Train Epoch: 1271 [81920/90000 (91%)]	Loss: -16.7704	Cost: 14.36s
Train Epoch: 1271 	Average Loss: -16.2849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1676

Learning rate: 0.0001999202917732368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1272 [0/90000 (0%)]	Loss: -11.1410	Cost: 27.00s
Train Epoch: 1272 [20480/90000 (23%)]	Loss: -17.0591	Cost: 6.53s
Train Epoch: 1272 [40960/90000 (45%)]	Loss: -16.5976	Cost: 10.84s
Train Epoch: 1272 [61440/90000 (68%)]	Loss: -16.9572	Cost: 6.50s
Train Epoch: 1272 [81920/90000 (91%)]	Loss: -16.9325	Cost: 15.37s
Train Epoch: 1272 	Average Loss: -16.5508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2746

Saving model as e1272_model.pt & e1272_waveforms_supplementary.hdf5
Learning rate: 0.00019992016631458734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1273 [0/90000 (0%)]	Loss: -9.8872	Cost: 23.11s
Train Epoch: 1273 [20480/90000 (23%)]	Loss: -16.9972	Cost: 8.40s
Train Epoch: 1273 [40960/90000 (45%)]	Loss: -16.5020	Cost: 11.99s
Train Epoch: 1273 [61440/90000 (68%)]	Loss: -16.6752	Cost: 7.66s
Train Epoch: 1273 [81920/90000 (91%)]	Loss: -16.8731	Cost: 14.85s
Train Epoch: 1273 	Average Loss: -16.3800
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1833

Learning rate: 0.00019992004075732064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1274 [0/90000 (0%)]	Loss: -10.1803	Cost: 28.45s
Train Epoch: 1274 [20480/90000 (23%)]	Loss: -16.9435	Cost: 8.09s
Train Epoch: 1274 [40960/90000 (45%)]	Loss: -16.6696	Cost: 9.73s
Train Epoch: 1274 [61440/90000 (68%)]	Loss: -17.0961	Cost: 6.12s
Train Epoch: 1274 [81920/90000 (91%)]	Loss: -16.9281	Cost: 15.65s
Train Epoch: 1274 	Average Loss: -16.4660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1080

Learning rate: 0.0001999199151014368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1275 [0/90000 (0%)]	Loss: -10.4163	Cost: 24.07s
Train Epoch: 1275 [20480/90000 (23%)]	Loss: -17.1978	Cost: 6.11s
Train Epoch: 1275 [40960/90000 (45%)]	Loss: -16.4255	Cost: 12.69s
Train Epoch: 1275 [61440/90000 (68%)]	Loss: -14.8881	Cost: 12.00s
Train Epoch: 1275 [81920/90000 (91%)]	Loss: -14.6851	Cost: 12.31s
Train Epoch: 1275 	Average Loss: -15.5113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3615

Learning rate: 0.00019991978934693597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1276 [0/90000 (0%)]	Loss: -9.1121	Cost: 31.42s
Train Epoch: 1276 [20480/90000 (23%)]	Loss: -15.4503	Cost: 8.04s
Train Epoch: 1276 [40960/90000 (45%)]	Loss: -15.0358	Cost: 9.46s
Train Epoch: 1276 [61440/90000 (68%)]	Loss: -16.1239	Cost: 6.74s
Train Epoch: 1276 [81920/90000 (91%)]	Loss: -16.1520	Cost: 14.65s
Train Epoch: 1276 	Average Loss: -15.1938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4830

Learning rate: 0.00019991966349381824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1277 [0/90000 (0%)]	Loss: -10.1034	Cost: 25.89s
Train Epoch: 1277 [20480/90000 (23%)]	Loss: -16.4151	Cost: 6.08s
Train Epoch: 1277 [40960/90000 (45%)]	Loss: -15.8724	Cost: 15.14s
Train Epoch: 1277 [61440/90000 (68%)]	Loss: -16.5814	Cost: 12.42s
Train Epoch: 1277 [81920/90000 (91%)]	Loss: -16.4541	Cost: 12.17s
Train Epoch: 1277 	Average Loss: -15.9396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5605

Learning rate: 0.00019991953754208377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1278 [0/90000 (0%)]	Loss: -9.4674	Cost: 28.66s
Train Epoch: 1278 [20480/90000 (23%)]	Loss: -16.5809	Cost: 9.61s
Train Epoch: 1278 [40960/90000 (45%)]	Loss: -16.0475	Cost: 9.08s
Train Epoch: 1278 [61440/90000 (68%)]	Loss: -16.6629	Cost: 12.01s
Train Epoch: 1278 [81920/90000 (91%)]	Loss: -16.3339	Cost: 12.01s
Train Epoch: 1278 	Average Loss: -16.0133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8976

Learning rate: 0.00019991941149173268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1279 [0/90000 (0%)]	Loss: -10.5898	Cost: 25.59s
Train Epoch: 1279 [20480/90000 (23%)]	Loss: -16.9018	Cost: 6.15s
Train Epoch: 1279 [40960/90000 (45%)]	Loss: -16.4056	Cost: 10.31s
Train Epoch: 1279 [61440/90000 (68%)]	Loss: -16.8801	Cost: 12.73s
Train Epoch: 1279 [81920/90000 (91%)]	Loss: -16.9834	Cost: 12.20s
Train Epoch: 1279 	Average Loss: -16.3425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2115

Learning rate: 0.00019991928534276505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1280 [0/90000 (0%)]	Loss: -10.6081	Cost: 30.81s
Train Epoch: 1280 [20480/90000 (23%)]	Loss: -16.6109	Cost: 8.43s
Train Epoch: 1280 [40960/90000 (45%)]	Loss: -15.9646	Cost: 12.69s
Train Epoch: 1280 [61440/90000 (68%)]	Loss: -16.4309	Cost: 12.22s
Train Epoch: 1280 [81920/90000 (91%)]	Loss: -16.6513	Cost: 12.21s
Train Epoch: 1280 	Average Loss: -16.1429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0436

Learning rate: 0.00019991915909518107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1281 [0/90000 (0%)]	Loss: -10.5340	Cost: 25.22s
Train Epoch: 1281 [20480/90000 (23%)]	Loss: -17.0387	Cost: 6.07s
Train Epoch: 1281 [40960/90000 (45%)]	Loss: -16.3376	Cost: 7.52s
Train Epoch: 1281 [61440/90000 (68%)]	Loss: -16.8119	Cost: 5.88s
Train Epoch: 1281 [81920/90000 (91%)]	Loss: -16.8324	Cost: 6.26s
Train Epoch: 1281 	Average Loss: -16.3877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0126

Learning rate: 0.00019991903274898084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1282 [0/90000 (0%)]	Loss: -10.7764	Cost: 22.33s
Train Epoch: 1282 [20480/90000 (23%)]	Loss: -17.1068	Cost: 6.09s
Train Epoch: 1282 [40960/90000 (45%)]	Loss: -16.5397	Cost: 10.75s
Train Epoch: 1282 [61440/90000 (68%)]	Loss: -17.0709	Cost: 6.30s
Train Epoch: 1282 [81920/90000 (91%)]	Loss: -16.9645	Cost: 11.46s
Train Epoch: 1282 	Average Loss: -16.5895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2912

Saving model as e1282_model.pt & e1282_waveforms_supplementary.hdf5
Learning rate: 0.00019991890630416447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1283 [0/90000 (0%)]	Loss: -11.0186	Cost: 26.49s
Train Epoch: 1283 [20480/90000 (23%)]	Loss: -16.5900	Cost: 6.29s
Train Epoch: 1283 [40960/90000 (45%)]	Loss: -16.1393	Cost: 8.52s
Train Epoch: 1283 [61440/90000 (68%)]	Loss: -16.6064	Cost: 5.97s
Train Epoch: 1283 [81920/90000 (91%)]	Loss: -16.5366	Cost: 7.17s
Train Epoch: 1283 	Average Loss: -16.1200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9388

Learning rate: 0.00019991877976073208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1284 [0/90000 (0%)]	Loss: -10.3843	Cost: 23.76s
Train Epoch: 1284 [20480/90000 (23%)]	Loss: -16.9313	Cost: 6.10s
Train Epoch: 1284 [40960/90000 (45%)]	Loss: -16.4337	Cost: 8.67s
Train Epoch: 1284 [61440/90000 (68%)]	Loss: -16.9034	Cost: 5.81s
Train Epoch: 1284 [81920/90000 (91%)]	Loss: -17.0954	Cost: 6.48s
Train Epoch: 1284 	Average Loss: -16.4399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1687

Learning rate: 0.0001999186531186838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1285 [0/90000 (0%)]	Loss: -10.8794	Cost: 22.81s
Train Epoch: 1285 [20480/90000 (23%)]	Loss: -17.1121	Cost: 6.02s
Train Epoch: 1285 [40960/90000 (45%)]	Loss: -16.6490	Cost: 8.81s
Train Epoch: 1285 [61440/90000 (68%)]	Loss: -17.0624	Cost: 6.21s
Train Epoch: 1285 [81920/90000 (91%)]	Loss: -17.0681	Cost: 11.41s
Train Epoch: 1285 	Average Loss: -16.6025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2098

Learning rate: 0.00019991852637801978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1286 [0/90000 (0%)]	Loss: -10.9140	Cost: 25.99s
Train Epoch: 1286 [20480/90000 (23%)]	Loss: -16.9349	Cost: 6.37s
Train Epoch: 1286 [40960/90000 (45%)]	Loss: -15.4912	Cost: 10.93s
Train Epoch: 1286 [61440/90000 (68%)]	Loss: -16.0634	Cost: 5.83s
Train Epoch: 1286 [81920/90000 (91%)]	Loss: -16.5091	Cost: 7.46s
Train Epoch: 1286 	Average Loss: -15.9877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7931

Learning rate: 0.00019991839953874008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1287 [0/90000 (0%)]	Loss: -9.8516	Cost: 25.44s
Train Epoch: 1287 [20480/90000 (23%)]	Loss: -16.5446	Cost: 6.26s
Train Epoch: 1287 [40960/90000 (45%)]	Loss: -16.2923	Cost: 7.89s
Train Epoch: 1287 [61440/90000 (68%)]	Loss: -16.6649	Cost: 6.08s
Train Epoch: 1287 [81920/90000 (91%)]	Loss: -17.0987	Cost: 6.42s
Train Epoch: 1287 	Average Loss: -16.2976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3145

Saving model as e1287_model.pt & e1287_waveforms_supplementary.hdf5
Learning rate: 0.0001999182726008449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1288 [0/90000 (0%)]	Loss: -10.5620	Cost: 23.19s
Train Epoch: 1288 [20480/90000 (23%)]	Loss: -17.2904	Cost: 6.11s
Train Epoch: 1288 [40960/90000 (45%)]	Loss: -16.6373	Cost: 6.99s
Train Epoch: 1288 [61440/90000 (68%)]	Loss: -16.7303	Cost: 6.17s
Train Epoch: 1288 [81920/90000 (91%)]	Loss: -16.8069	Cost: 11.55s
Train Epoch: 1288 	Average Loss: -16.4324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9252

Learning rate: 0.0001999181455643344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1289 [0/90000 (0%)]	Loss: -10.9350	Cost: 24.79s
Train Epoch: 1289 [20480/90000 (23%)]	Loss: -17.0018	Cost: 6.24s
Train Epoch: 1289 [40960/90000 (45%)]	Loss: -16.3104	Cost: 11.28s
Train Epoch: 1289 [61440/90000 (68%)]	Loss: -17.1697	Cost: 6.21s
Train Epoch: 1289 [81920/90000 (91%)]	Loss: -17.1053	Cost: 8.95s
Train Epoch: 1289 	Average Loss: -16.5198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3251

Saving model as e1289_model.pt & e1289_waveforms_supplementary.hdf5
Learning rate: 0.00019991801842920856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1290 [0/90000 (0%)]	Loss: -10.6337	Cost: 27.12s
Train Epoch: 1290 [20480/90000 (23%)]	Loss: -17.3257	Cost: 6.13s
Train Epoch: 1290 [40960/90000 (45%)]	Loss: -16.2245	Cost: 8.20s
Train Epoch: 1290 [61440/90000 (68%)]	Loss: -16.8395	Cost: 5.92s
Train Epoch: 1290 [81920/90000 (91%)]	Loss: -16.8439	Cost: 7.96s
Train Epoch: 1290 	Average Loss: -16.4983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1214

Learning rate: 0.00019991789119546766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1291 [0/90000 (0%)]	Loss: -10.8395	Cost: 24.05s
Train Epoch: 1291 [20480/90000 (23%)]	Loss: -16.6827	Cost: 6.08s
Train Epoch: 1291 [40960/90000 (45%)]	Loss: -16.2554	Cost: 8.71s
Train Epoch: 1291 [61440/90000 (68%)]	Loss: -16.6684	Cost: 5.78s
Train Epoch: 1291 [81920/90000 (91%)]	Loss: -16.9865	Cost: 5.83s
Train Epoch: 1291 	Average Loss: -16.3025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2559

Learning rate: 0.0001999177638631117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1292 [0/90000 (0%)]	Loss: -11.1191	Cost: 23.11s
Train Epoch: 1292 [20480/90000 (23%)]	Loss: -17.2309	Cost: 6.04s
Train Epoch: 1292 [40960/90000 (45%)]	Loss: -16.4247	Cost: 8.40s
Train Epoch: 1292 [61440/90000 (68%)]	Loss: -16.9709	Cost: 6.16s
Train Epoch: 1292 [81920/90000 (91%)]	Loss: -16.8594	Cost: 11.31s
Train Epoch: 1292 	Average Loss: -16.5632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1777

Learning rate: 0.00019991763643214085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1293 [0/90000 (0%)]	Loss: -9.8108	Cost: 25.30s
Train Epoch: 1293 [20480/90000 (23%)]	Loss: -16.9823	Cost: 6.64s
Train Epoch: 1293 [40960/90000 (45%)]	Loss: -16.4333	Cost: 10.93s
Train Epoch: 1293 [61440/90000 (68%)]	Loss: -17.0589	Cost: 6.08s
Train Epoch: 1293 [81920/90000 (91%)]	Loss: -17.0176	Cost: 8.04s
Train Epoch: 1293 	Average Loss: -16.5295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1304

Learning rate: 0.00019991750890255527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1294 [0/90000 (0%)]	Loss: -10.1574	Cost: 26.38s
Train Epoch: 1294 [20480/90000 (23%)]	Loss: -17.0262	Cost: 6.13s
Train Epoch: 1294 [40960/90000 (45%)]	Loss: -16.3683	Cost: 8.51s
Train Epoch: 1294 [61440/90000 (68%)]	Loss: -17.0530	Cost: 6.20s
Train Epoch: 1294 [81920/90000 (91%)]	Loss: -16.8032	Cost: 7.69s
Train Epoch: 1294 	Average Loss: -16.4368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2608

Learning rate: 0.00019991738127435506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1295 [0/90000 (0%)]	Loss: -11.3598	Cost: 23.89s
Train Epoch: 1295 [20480/90000 (23%)]	Loss: -16.9591	Cost: 6.21s
Train Epoch: 1295 [40960/90000 (45%)]	Loss: -16.2380	Cost: 7.27s
Train Epoch: 1295 [61440/90000 (68%)]	Loss: -16.7903	Cost: 6.22s
Train Epoch: 1295 [81920/90000 (91%)]	Loss: -17.0249	Cost: 11.47s
Train Epoch: 1295 	Average Loss: -16.4518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1602

Learning rate: 0.00019991725354754033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1296 [0/90000 (0%)]	Loss: -10.9232	Cost: 26.41s
Train Epoch: 1296 [20480/90000 (23%)]	Loss: -17.2393	Cost: 6.50s
Train Epoch: 1296 [40960/90000 (45%)]	Loss: -16.7468	Cost: 11.43s
Train Epoch: 1296 [61440/90000 (68%)]	Loss: -17.1426	Cost: 6.33s
Train Epoch: 1296 [81920/90000 (91%)]	Loss: -16.7223	Cost: 8.16s
Train Epoch: 1296 	Average Loss: -16.6274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1197

Learning rate: 0.00019991712572211125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1297 [0/90000 (0%)]	Loss: -10.1666	Cost: 26.66s
Train Epoch: 1297 [20480/90000 (23%)]	Loss: -17.1191	Cost: 6.26s
Train Epoch: 1297 [40960/90000 (45%)]	Loss: -16.1280	Cost: 7.26s
Train Epoch: 1297 [61440/90000 (68%)]	Loss: -16.8289	Cost: 6.09s
Train Epoch: 1297 [81920/90000 (91%)]	Loss: -16.9689	Cost: 8.89s
Train Epoch: 1297 	Average Loss: -16.3735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1697

Learning rate: 0.00019991699779806793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1298 [0/90000 (0%)]	Loss: -10.7006	Cost: 23.47s
Train Epoch: 1298 [20480/90000 (23%)]	Loss: -17.1334	Cost: 6.12s
Train Epoch: 1298 [40960/90000 (45%)]	Loss: -16.5398	Cost: 7.51s
Train Epoch: 1298 [61440/90000 (68%)]	Loss: -16.8268	Cost: 6.32s
Train Epoch: 1298 [81920/90000 (91%)]	Loss: -17.0290	Cost: 9.39s
Train Epoch: 1298 	Average Loss: -16.5043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1998

Learning rate: 0.00019991686977541043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1299 [0/90000 (0%)]	Loss: -10.5124	Cost: 24.68s
Train Epoch: 1299 [20480/90000 (23%)]	Loss: -17.2935	Cost: 6.38s
Train Epoch: 1299 [40960/90000 (45%)]	Loss: -16.6039	Cost: 11.45s
Train Epoch: 1299 [61440/90000 (68%)]	Loss: -17.1355	Cost: 6.30s
Train Epoch: 1299 [81920/90000 (91%)]	Loss: -17.0439	Cost: 9.23s
Train Epoch: 1299 	Average Loss: -16.6616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2446

Learning rate: 0.00019991674165413894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1300 [0/90000 (0%)]	Loss: -10.8706	Cost: 27.20s
Train Epoch: 1300 [20480/90000 (23%)]	Loss: -17.3230	Cost: 6.30s
Train Epoch: 1300 [40960/90000 (45%)]	Loss: -16.6784	Cost: 7.79s
Train Epoch: 1300 [61440/90000 (68%)]	Loss: -16.9777	Cost: 6.16s
Train Epoch: 1300 [81920/90000 (91%)]	Loss: -16.7318	Cost: 8.26s
Train Epoch: 1300 	Average Loss: -16.5268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6129

Learning rate: 0.0001999166134342536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1301 [0/90000 (0%)]	Loss: -9.7906	Cost: 23.80s
Train Epoch: 1301 [20480/90000 (23%)]	Loss: -16.4479	Cost: 6.07s
Train Epoch: 1301 [40960/90000 (45%)]	Loss: -15.7469	Cost: 7.28s
Train Epoch: 1301 [61440/90000 (68%)]	Loss: -16.4885	Cost: 5.83s
Train Epoch: 1301 [81920/90000 (91%)]	Loss: -17.0230	Cost: 6.52s
Train Epoch: 1301 	Average Loss: -15.9673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3423

Saving model as e1301_model.pt & e1301_waveforms_supplementary.hdf5
Learning rate: 0.00019991648511575452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1302 [0/90000 (0%)]	Loss: -10.6492	Cost: 24.42s
Train Epoch: 1302 [20480/90000 (23%)]	Loss: -17.4060	Cost: 6.33s
Train Epoch: 1302 [40960/90000 (45%)]	Loss: -16.7814	Cost: 11.47s
Train Epoch: 1302 [61440/90000 (68%)]	Loss: -17.2207	Cost: 6.26s
Train Epoch: 1302 [81920/90000 (91%)]	Loss: -17.4990	Cost: 10.89s
Train Epoch: 1302 	Average Loss: -16.7410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6549

Saving model as e1302_model.pt & e1302_waveforms_supplementary.hdf5
Learning rate: 0.00019991635669864183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1303 [0/90000 (0%)]	Loss: -11.3966	Cost: 26.76s
Train Epoch: 1303 [20480/90000 (23%)]	Loss: -17.5887	Cost: 6.36s
Train Epoch: 1303 [40960/90000 (45%)]	Loss: -16.9247	Cost: 8.27s
Train Epoch: 1303 [61440/90000 (68%)]	Loss: -17.3480	Cost: 6.04s
Train Epoch: 1303 [81920/90000 (91%)]	Loss: -17.3175	Cost: 9.15s
Train Epoch: 1303 	Average Loss: -16.9345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4729

Learning rate: 0.00019991622818291564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1304 [0/90000 (0%)]	Loss: -10.4242	Cost: 23.67s
Train Epoch: 1304 [20480/90000 (23%)]	Loss: -17.3750	Cost: 6.13s
Train Epoch: 1304 [40960/90000 (45%)]	Loss: -16.6894	Cost: 7.37s
Train Epoch: 1304 [61440/90000 (68%)]	Loss: -17.2863	Cost: 6.32s
Train Epoch: 1304 [81920/90000 (91%)]	Loss: -17.2850	Cost: 11.10s
Train Epoch: 1304 	Average Loss: -16.7706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6323

Learning rate: 0.00019991609956857608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1305 [0/90000 (0%)]	Loss: -10.9885	Cost: 25.71s
Train Epoch: 1305 [20480/90000 (23%)]	Loss: -17.3700	Cost: 6.41s
Train Epoch: 1305 [40960/90000 (45%)]	Loss: -16.8836	Cost: 11.50s
Train Epoch: 1305 [61440/90000 (68%)]	Loss: -17.1739	Cost: 6.19s
Train Epoch: 1305 [81920/90000 (91%)]	Loss: -17.2376	Cost: 8.22s
Train Epoch: 1305 	Average Loss: -16.7929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3796

Learning rate: 0.0001999159708556233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1306 [0/90000 (0%)]	Loss: -11.7067	Cost: 26.78s
Train Epoch: 1306 [20480/90000 (23%)]	Loss: -17.1751	Cost: 6.27s
Train Epoch: 1306 [40960/90000 (45%)]	Loss: -16.6737	Cost: 7.90s
Train Epoch: 1306 [61440/90000 (68%)]	Loss: -17.0883	Cost: 6.08s
Train Epoch: 1306 [81920/90000 (91%)]	Loss: -17.0693	Cost: 8.55s
Train Epoch: 1306 	Average Loss: -16.7074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4698

Learning rate: 0.0001999158420440574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1307 [0/90000 (0%)]	Loss: -10.7267	Cost: 23.78s
Train Epoch: 1307 [20480/90000 (23%)]	Loss: -16.6902	Cost: 6.17s
Train Epoch: 1307 [40960/90000 (45%)]	Loss: -16.1521	Cost: 7.05s
Train Epoch: 1307 [61440/90000 (68%)]	Loss: -16.9629	Cost: 6.33s
Train Epoch: 1307 [81920/90000 (91%)]	Loss: -17.0274	Cost: 9.02s
Train Epoch: 1307 	Average Loss: -16.4177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2997

Learning rate: 0.0001999157131338785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1308 [0/90000 (0%)]	Loss: -10.5195	Cost: 23.46s
Train Epoch: 1308 [20480/90000 (23%)]	Loss: -17.1004	Cost: 6.27s
Train Epoch: 1308 [40960/90000 (45%)]	Loss: -16.6748	Cost: 11.23s
Train Epoch: 1308 [61440/90000 (68%)]	Loss: -16.8420	Cost: 6.22s
Train Epoch: 1308 [81920/90000 (91%)]	Loss: -17.2741	Cost: 10.32s
Train Epoch: 1308 	Average Loss: -16.7258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4650

Learning rate: 0.00019991558412508676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1309 [0/90000 (0%)]	Loss: -11.2589	Cost: 26.90s
Train Epoch: 1309 [20480/90000 (23%)]	Loss: -17.5826	Cost: 6.18s
Train Epoch: 1309 [40960/90000 (45%)]	Loss: -17.0982	Cost: 8.52s
Train Epoch: 1309 [61440/90000 (68%)]	Loss: -17.4100	Cost: 5.99s
Train Epoch: 1309 [81920/90000 (91%)]	Loss: -17.3117	Cost: 9.00s
Train Epoch: 1309 	Average Loss: -16.8932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5204

Learning rate: 0.00019991545501768228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1310 [0/90000 (0%)]	Loss: -10.8664	Cost: 24.27s
Train Epoch: 1310 [20480/90000 (23%)]	Loss: -17.4552	Cost: 6.15s
Train Epoch: 1310 [40960/90000 (45%)]	Loss: -16.9840	Cost: 7.87s
Train Epoch: 1310 [61440/90000 (68%)]	Loss: -17.2736	Cost: 5.87s
Train Epoch: 1310 [81920/90000 (91%)]	Loss: -17.3792	Cost: 7.22s
Train Epoch: 1310 	Average Loss: -16.8858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5554

Learning rate: 0.00019991532581166522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1311 [0/90000 (0%)]	Loss: -11.4075	Cost: 22.07s
Train Epoch: 1311 [20480/90000 (23%)]	Loss: -17.5313	Cost: 6.46s
Train Epoch: 1311 [40960/90000 (45%)]	Loss: -16.8204	Cost: 10.73s
Train Epoch: 1311 [61440/90000 (68%)]	Loss: -17.2319	Cost: 6.38s
Train Epoch: 1311 [81920/90000 (91%)]	Loss: -17.0064	Cost: 11.20s
Train Epoch: 1311 	Average Loss: -16.7957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5004

Learning rate: 0.00019991519650703569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1312 [0/90000 (0%)]	Loss: -11.3599	Cost: 26.89s
Train Epoch: 1312 [20480/90000 (23%)]	Loss: -17.2768	Cost: 6.36s
Train Epoch: 1312 [40960/90000 (45%)]	Loss: -16.5658	Cost: 9.57s
Train Epoch: 1312 [61440/90000 (68%)]	Loss: -17.0588	Cost: 5.80s
Train Epoch: 1312 [81920/90000 (91%)]	Loss: -17.2938	Cost: 6.76s
Train Epoch: 1312 	Average Loss: -16.7635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3676

Learning rate: 0.0001999150671037938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1313 [0/90000 (0%)]	Loss: -11.4697	Cost: 23.92s
Train Epoch: 1313 [20480/90000 (23%)]	Loss: -17.1832	Cost: 6.11s
Train Epoch: 1313 [40960/90000 (45%)]	Loss: -16.1216	Cost: 8.61s
Train Epoch: 1313 [61440/90000 (68%)]	Loss: -16.9306	Cost: 5.79s
Train Epoch: 1313 [81920/90000 (91%)]	Loss: -17.0275	Cost: 5.91s
Train Epoch: 1313 	Average Loss: -16.5133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4972

Learning rate: 0.00019991493760193965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1314 [0/90000 (0%)]	Loss: -11.0761	Cost: 22.87s
Train Epoch: 1314 [20480/90000 (23%)]	Loss: -17.4011	Cost: 6.07s
Train Epoch: 1314 [40960/90000 (45%)]	Loss: -16.6567	Cost: 8.44s
Train Epoch: 1314 [61440/90000 (68%)]	Loss: -17.1654	Cost: 6.21s
Train Epoch: 1314 [81920/90000 (91%)]	Loss: -17.2049	Cost: 12.05s
Train Epoch: 1314 	Average Loss: -16.6888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4165

Learning rate: 0.00019991480800147347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1315 [0/90000 (0%)]	Loss: -9.6648	Cost: 26.07s
Train Epoch: 1315 [20480/90000 (23%)]	Loss: -17.2801	Cost: 6.56s
Train Epoch: 1315 [40960/90000 (45%)]	Loss: -16.4626	Cost: 10.33s
Train Epoch: 1315 [61440/90000 (68%)]	Loss: -16.8123	Cost: 5.85s
Train Epoch: 1315 [81920/90000 (91%)]	Loss: -16.7884	Cost: 7.09s
Train Epoch: 1315 	Average Loss: -16.4766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8108

Learning rate: 0.00019991467830239527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1316 [0/90000 (0%)]	Loss: -10.6940	Cost: 26.29s
Train Epoch: 1316 [20480/90000 (23%)]	Loss: -16.4578	Cost: 6.10s
Train Epoch: 1316 [40960/90000 (45%)]	Loss: -16.2253	Cost: 7.82s
Train Epoch: 1316 [61440/90000 (68%)]	Loss: -16.7799	Cost: 6.01s
Train Epoch: 1316 [81920/90000 (91%)]	Loss: -17.0628	Cost: 6.82s
Train Epoch: 1316 	Average Loss: -16.2250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1937

Learning rate: 0.00019991454850470532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1317 [0/90000 (0%)]	Loss: -10.6252	Cost: 23.44s
Train Epoch: 1317 [20480/90000 (23%)]	Loss: -17.4365	Cost: 6.10s
Train Epoch: 1317 [40960/90000 (45%)]	Loss: -16.6709	Cost: 7.41s
Train Epoch: 1317 [61440/90000 (68%)]	Loss: -17.3723	Cost: 6.06s
Train Epoch: 1317 [81920/90000 (91%)]	Loss: -17.5518	Cost: 8.92s
Train Epoch: 1317 	Average Loss: -16.8318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7057

Saving model as e1317_model.pt & e1317_waveforms_supplementary.hdf5
Learning rate: 0.0001999144186084036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1318 [0/90000 (0%)]	Loss: -11.7381	Cost: 25.01s
Train Epoch: 1318 [20480/90000 (23%)]	Loss: -17.6389	Cost: 6.29s
Train Epoch: 1318 [40960/90000 (45%)]	Loss: -16.7561	Cost: 10.71s
Train Epoch: 1318 [61440/90000 (68%)]	Loss: -17.0516	Cost: 6.18s
Train Epoch: 1318 [81920/90000 (91%)]	Loss: -17.1734	Cost: 8.78s
Train Epoch: 1318 	Average Loss: -16.7818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0529

Learning rate: 0.0001999142886134903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1319 [0/90000 (0%)]	Loss: -10.1777	Cost: 26.82s
Train Epoch: 1319 [20480/90000 (23%)]	Loss: -16.9711	Cost: 6.12s
Train Epoch: 1319 [40960/90000 (45%)]	Loss: -16.6201	Cost: 7.37s
Train Epoch: 1319 [61440/90000 (68%)]	Loss: -16.7767	Cost: 6.02s
Train Epoch: 1319 [81920/90000 (91%)]	Loss: -16.9410	Cost: 8.60s
Train Epoch: 1319 	Average Loss: -16.4020
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1937

Learning rate: 0.00019991415851996556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1320 [0/90000 (0%)]	Loss: -10.6400	Cost: 24.39s
Train Epoch: 1320 [20480/90000 (23%)]	Loss: -17.3412	Cost: 6.03s
Train Epoch: 1320 [40960/90000 (45%)]	Loss: -16.8644	Cost: 6.89s
Train Epoch: 1320 [61440/90000 (68%)]	Loss: -17.4384	Cost: 5.97s
Train Epoch: 1320 [81920/90000 (91%)]	Loss: -17.2614	Cost: 7.60s
Train Epoch: 1320 	Average Loss: -16.8519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4614

Learning rate: 0.0001999140283278295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1321 [0/90000 (0%)]	Loss: -10.5710	Cost: 22.99s
Train Epoch: 1321 [20480/90000 (23%)]	Loss: -17.4303	Cost: 6.21s
Train Epoch: 1321 [40960/90000 (45%)]	Loss: -16.7402	Cost: 11.18s
Train Epoch: 1321 [61440/90000 (68%)]	Loss: -17.4475	Cost: 6.23s
Train Epoch: 1321 [81920/90000 (91%)]	Loss: -17.1389	Cost: 11.18s
Train Epoch: 1321 	Average Loss: -16.8901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5199

Learning rate: 0.00019991389803708227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1322 [0/90000 (0%)]	Loss: -11.2311	Cost: 26.88s
Train Epoch: 1322 [20480/90000 (23%)]	Loss: -17.4359	Cost: 6.33s
Train Epoch: 1322 [40960/90000 (45%)]	Loss: -16.7389	Cost: 8.61s
Train Epoch: 1322 [61440/90000 (68%)]	Loss: -17.3659	Cost: 6.02s
Train Epoch: 1322 [81920/90000 (91%)]	Loss: -17.2889	Cost: 8.29s
Train Epoch: 1322 	Average Loss: -16.8398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3480

Learning rate: 0.00019991376764772397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1323 [0/90000 (0%)]	Loss: -10.4437	Cost: 24.73s
Train Epoch: 1323 [20480/90000 (23%)]	Loss: -17.3535	Cost: 6.06s
Train Epoch: 1323 [40960/90000 (45%)]	Loss: -16.9027	Cost: 7.83s
Train Epoch: 1323 [61440/90000 (68%)]	Loss: -17.3154	Cost: 5.90s
Train Epoch: 1323 [81920/90000 (91%)]	Loss: -17.4408	Cost: 5.68s
Train Epoch: 1323 	Average Loss: -16.8348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5626

Learning rate: 0.00019991363715975472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1324 [0/90000 (0%)]	Loss: -10.4189	Cost: 22.48s
Train Epoch: 1324 [20480/90000 (23%)]	Loss: -17.5868	Cost: 6.04s
Train Epoch: 1324 [40960/90000 (45%)]	Loss: -17.0304	Cost: 8.34s
Train Epoch: 1324 [61440/90000 (68%)]	Loss: -17.4108	Cost: 6.16s
Train Epoch: 1324 [81920/90000 (91%)]	Loss: -17.2409	Cost: 11.80s
Train Epoch: 1324 	Average Loss: -16.9598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1572

Learning rate: 0.00019991350657317465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1325 [0/90000 (0%)]	Loss: -11.0625	Cost: 26.74s
Train Epoch: 1325 [20480/90000 (23%)]	Loss: -17.2097	Cost: 6.33s
Train Epoch: 1325 [40960/90000 (45%)]	Loss: -16.6478	Cost: 10.99s
Train Epoch: 1325 [61440/90000 (68%)]	Loss: -16.9451	Cost: 5.96s
Train Epoch: 1325 [81920/90000 (91%)]	Loss: -17.0866	Cost: 6.03s
Train Epoch: 1325 	Average Loss: -16.6461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3461

Learning rate: 0.0001999133758879839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1326 [0/90000 (0%)]	Loss: -11.8144	Cost: 25.60s
Train Epoch: 1326 [20480/90000 (23%)]	Loss: -17.6237	Cost: 6.08s
Train Epoch: 1326 [40960/90000 (45%)]	Loss: -16.9938	Cost: 7.49s
Train Epoch: 1326 [61440/90000 (68%)]	Loss: -17.7350	Cost: 5.99s
Train Epoch: 1326 [81920/90000 (91%)]	Loss: -17.4377	Cost: 7.12s
Train Epoch: 1326 	Average Loss: -17.0965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5673

Learning rate: 0.00019991324510418263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1327 [0/90000 (0%)]	Loss: -11.2133	Cost: 23.01s
Train Epoch: 1327 [20480/90000 (23%)]	Loss: -17.2599	Cost: 6.13s
Train Epoch: 1327 [40960/90000 (45%)]	Loss: -16.7584	Cost: 7.89s
Train Epoch: 1327 [61440/90000 (68%)]	Loss: -17.3673	Cost: 6.07s
Train Epoch: 1327 [81920/90000 (91%)]	Loss: -17.3671	Cost: 9.86s
Train Epoch: 1327 	Average Loss: -16.7905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5982

Learning rate: 0.00019991311422177093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1328 [0/90000 (0%)]	Loss: -11.2466	Cost: 24.48s
Train Epoch: 1328 [20480/90000 (23%)]	Loss: -17.5924	Cost: 6.20s
Train Epoch: 1328 [40960/90000 (45%)]	Loss: -17.1480	Cost: 11.39s
Train Epoch: 1328 [61440/90000 (68%)]	Loss: -17.4163	Cost: 6.18s
Train Epoch: 1328 [81920/90000 (91%)]	Loss: -17.5266	Cost: 10.11s
Train Epoch: 1328 	Average Loss: -17.0514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6298

Learning rate: 0.00019991298324074894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1329 [0/90000 (0%)]	Loss: -11.9004	Cost: 27.02s
Train Epoch: 1329 [20480/90000 (23%)]	Loss: -17.7076	Cost: 6.40s
Train Epoch: 1329 [40960/90000 (45%)]	Loss: -17.1556	Cost: 8.38s
Train Epoch: 1329 [61440/90000 (68%)]	Loss: -17.6033	Cost: 5.99s
Train Epoch: 1329 [81920/90000 (91%)]	Loss: -17.5496	Cost: 8.10s
Train Epoch: 1329 	Average Loss: -17.0880
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7172

Saving model as e1329_model.pt & e1329_waveforms_supplementary.hdf5
Learning rate: 0.00019991285216111677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1330 [0/90000 (0%)]	Loss: -10.9936	Cost: 23.40s
Train Epoch: 1330 [20480/90000 (23%)]	Loss: -17.6778	Cost: 6.11s
Train Epoch: 1330 [40960/90000 (45%)]	Loss: -17.0801	Cost: 7.16s
Train Epoch: 1330 [61440/90000 (68%)]	Loss: -17.3893	Cost: 5.91s
Train Epoch: 1330 [81920/90000 (91%)]	Loss: -17.3272	Cost: 6.92s
Train Epoch: 1330 	Average Loss: -16.9992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4633

Learning rate: 0.0001999127209828746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1331 [0/90000 (0%)]	Loss: -11.0712	Cost: 22.72s
Train Epoch: 1331 [20480/90000 (23%)]	Loss: -17.4197	Cost: 6.37s
Train Epoch: 1331 [40960/90000 (45%)]	Loss: -16.9563	Cost: 10.84s
Train Epoch: 1331 [61440/90000 (68%)]	Loss: -17.4626	Cost: 6.34s
Train Epoch: 1331 [81920/90000 (91%)]	Loss: -17.3065	Cost: 11.46s
Train Epoch: 1331 	Average Loss: -16.9244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4247

Learning rate: 0.0001999125897060225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1332 [0/90000 (0%)]	Loss: -10.9812	Cost: 26.83s
Train Epoch: 1332 [20480/90000 (23%)]	Loss: -17.3567	Cost: 6.35s
Train Epoch: 1332 [40960/90000 (45%)]	Loss: -16.8753	Cost: 8.86s
Train Epoch: 1332 [61440/90000 (68%)]	Loss: -17.3687	Cost: 6.03s
Train Epoch: 1332 [81920/90000 (91%)]	Loss: -17.4845	Cost: 7.93s
Train Epoch: 1332 	Average Loss: -16.8303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6939

Learning rate: 0.00019991245833056063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1333 [0/90000 (0%)]	Loss: -11.4877	Cost: 24.06s
Train Epoch: 1333 [20480/90000 (23%)]	Loss: -17.7148	Cost: 6.08s
Train Epoch: 1333 [40960/90000 (45%)]	Loss: -17.0585	Cost: 7.52s
Train Epoch: 1333 [61440/90000 (68%)]	Loss: -17.6596	Cost: 5.77s
Train Epoch: 1333 [81920/90000 (91%)]	Loss: -17.3557	Cost: 6.04s
Train Epoch: 1333 	Average Loss: -16.9787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6792

Learning rate: 0.00019991232685648912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1334 [0/90000 (0%)]	Loss: -11.2651	Cost: 22.53s
Train Epoch: 1334 [20480/90000 (23%)]	Loss: -17.6376	Cost: 6.49s
Train Epoch: 1334 [40960/90000 (45%)]	Loss: -17.0699	Cost: 10.70s
Train Epoch: 1334 [61440/90000 (68%)]	Loss: -17.2902	Cost: 6.34s
Train Epoch: 1334 [81920/90000 (91%)]	Loss: -17.2630	Cost: 11.24s
Train Epoch: 1334 	Average Loss: -16.9331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3947

Learning rate: 0.00019991219528380812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1335 [0/90000 (0%)]	Loss: -10.5082	Cost: 26.90s
Train Epoch: 1335 [20480/90000 (23%)]	Loss: -17.3950	Cost: 6.30s
Train Epoch: 1335 [40960/90000 (45%)]	Loss: -16.8901	Cost: 8.25s
Train Epoch: 1335 [61440/90000 (68%)]	Loss: -17.3327	Cost: 6.03s
Train Epoch: 1335 [81920/90000 (91%)]	Loss: -17.2803	Cost: 8.74s
Train Epoch: 1335 	Average Loss: -16.7909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4646

Learning rate: 0.0001999120636125177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1336 [0/90000 (0%)]	Loss: -11.2745	Cost: 24.17s
Train Epoch: 1336 [20480/90000 (23%)]	Loss: -17.5324	Cost: 6.10s
Train Epoch: 1336 [40960/90000 (45%)]	Loss: -16.8730	Cost: 7.21s
Train Epoch: 1336 [61440/90000 (68%)]	Loss: -17.4752	Cost: 5.81s
Train Epoch: 1336 [81920/90000 (91%)]	Loss: -17.5371	Cost: 6.55s
Train Epoch: 1336 	Average Loss: -16.9567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6142

Learning rate: 0.00019991193184261806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1337 [0/90000 (0%)]	Loss: -10.8052	Cost: 22.41s
Train Epoch: 1337 [20480/90000 (23%)]	Loss: -17.4821	Cost: 6.16s
Train Epoch: 1337 [40960/90000 (45%)]	Loss: -17.0277	Cost: 10.66s
Train Epoch: 1337 [61440/90000 (68%)]	Loss: -17.4707	Cost: 6.33s
Train Epoch: 1337 [81920/90000 (91%)]	Loss: -17.2155	Cost: 11.30s
Train Epoch: 1337 	Average Loss: -16.9363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8052

Saving model as e1337_model.pt & e1337_waveforms_supplementary.hdf5
Learning rate: 0.00019991179997410924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1338 [0/90000 (0%)]	Loss: -11.6955	Cost: 27.72s
Train Epoch: 1338 [20480/90000 (23%)]	Loss: -17.2786	Cost: 6.28s
Train Epoch: 1338 [40960/90000 (45%)]	Loss: -16.7234	Cost: 8.95s
Train Epoch: 1338 [61440/90000 (68%)]	Loss: -17.1521	Cost: 5.93s
Train Epoch: 1338 [81920/90000 (91%)]	Loss: -17.4658	Cost: 8.22s
Train Epoch: 1338 	Average Loss: -16.8130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6236

Learning rate: 0.00019991166800699146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1339 [0/90000 (0%)]	Loss: -11.1511	Cost: 24.04s
Train Epoch: 1339 [20480/90000 (23%)]	Loss: -17.5074	Cost: 6.06s
Train Epoch: 1339 [40960/90000 (45%)]	Loss: -16.9810	Cost: 8.21s
Train Epoch: 1339 [61440/90000 (68%)]	Loss: -17.6252	Cost: 5.80s
Train Epoch: 1339 [81920/90000 (91%)]	Loss: -17.5390	Cost: 6.09s
Train Epoch: 1339 	Average Loss: -17.0309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8784

Saving model as e1339_model.pt & e1339_waveforms_supplementary.hdf5
Learning rate: 0.00019991153594126483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1340 [0/90000 (0%)]	Loss: -10.7205	Cost: 22.34s
Train Epoch: 1340 [20480/90000 (23%)]	Loss: -17.8275	Cost: 5.97s
Train Epoch: 1340 [40960/90000 (45%)]	Loss: -17.2428	Cost: 9.24s
Train Epoch: 1340 [61440/90000 (68%)]	Loss: -17.5596	Cost: 6.14s
Train Epoch: 1340 [81920/90000 (91%)]	Loss: -17.6615	Cost: 11.56s
Train Epoch: 1340 	Average Loss: -17.1329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7466

Learning rate: 0.00019991140377692944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1341 [0/90000 (0%)]	Loss: -11.6146	Cost: 27.17s
Train Epoch: 1341 [20480/90000 (23%)]	Loss: -17.6234	Cost: 6.44s
Train Epoch: 1341 [40960/90000 (45%)]	Loss: -17.1326	Cost: 9.84s
Train Epoch: 1341 [61440/90000 (68%)]	Loss: -17.4562	Cost: 5.78s
Train Epoch: 1341 [81920/90000 (91%)]	Loss: -17.6177	Cost: 6.74s
Train Epoch: 1341 	Average Loss: -17.0584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7408

Learning rate: 0.00019991127151398547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1342 [0/90000 (0%)]	Loss: -11.3411	Cost: 25.83s
Train Epoch: 1342 [20480/90000 (23%)]	Loss: -17.5519	Cost: 6.14s
Train Epoch: 1342 [40960/90000 (45%)]	Loss: -17.0935	Cost: 7.47s
Train Epoch: 1342 [61440/90000 (68%)]	Loss: -17.4528	Cost: 6.02s
Train Epoch: 1342 [81920/90000 (91%)]	Loss: -17.6399	Cost: 8.04s
Train Epoch: 1342 	Average Loss: -17.0065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6769

Learning rate: 0.00019991113915243298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1343 [0/90000 (0%)]	Loss: -11.2351	Cost: 23.92s
Train Epoch: 1343 [20480/90000 (23%)]	Loss: -17.5292	Cost: 6.14s
Train Epoch: 1343 [40960/90000 (45%)]	Loss: -16.9192	Cost: 7.40s
Train Epoch: 1343 [61440/90000 (68%)]	Loss: -17.5666	Cost: 6.29s
Train Epoch: 1343 [81920/90000 (91%)]	Loss: -17.3515	Cost: 11.11s
Train Epoch: 1343 	Average Loss: -16.9559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7190

Learning rate: 0.0001999110066922722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1344 [0/90000 (0%)]	Loss: -11.0130	Cost: 25.69s
Train Epoch: 1344 [20480/90000 (23%)]	Loss: -17.4729	Cost: 6.35s
Train Epoch: 1344 [40960/90000 (45%)]	Loss: -16.7674	Cost: 11.17s
Train Epoch: 1344 [61440/90000 (68%)]	Loss: -17.2349	Cost: 6.25s
Train Epoch: 1344 [81920/90000 (91%)]	Loss: -17.4664	Cost: 8.36s
Train Epoch: 1344 	Average Loss: -16.8981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5884

Learning rate: 0.0001999108741335032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1345 [0/90000 (0%)]	Loss: -11.1626	Cost: 26.56s
Train Epoch: 1345 [20480/90000 (23%)]	Loss: -17.8630	Cost: 6.14s
Train Epoch: 1345 [40960/90000 (45%)]	Loss: -17.1605	Cost: 7.64s
Train Epoch: 1345 [61440/90000 (68%)]	Loss: -17.7277	Cost: 6.00s
Train Epoch: 1345 [81920/90000 (91%)]	Loss: -17.5883	Cost: 8.26s
Train Epoch: 1345 	Average Loss: -17.1507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7352

Learning rate: 0.00019991074147612608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1346 [0/90000 (0%)]	Loss: -12.0694	Cost: 23.22s
Train Epoch: 1346 [20480/90000 (23%)]	Loss: -17.7553	Cost: 6.12s
Train Epoch: 1346 [40960/90000 (45%)]	Loss: -16.9487	Cost: 7.76s
Train Epoch: 1346 [61440/90000 (68%)]	Loss: -17.3496	Cost: 5.91s
Train Epoch: 1346 [81920/90000 (91%)]	Loss: -16.7257	Cost: 7.52s
Train Epoch: 1346 	Average Loss: -16.9122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7879

Learning rate: 0.00019991060872014105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1347 [0/90000 (0%)]	Loss: -10.1138	Cost: 22.66s
Train Epoch: 1347 [20480/90000 (23%)]	Loss: -16.7570	Cost: 6.20s
Train Epoch: 1347 [40960/90000 (45%)]	Loss: -16.4158	Cost: 10.92s
Train Epoch: 1347 [61440/90000 (68%)]	Loss: -17.1918	Cost: 6.22s
Train Epoch: 1347 [81920/90000 (91%)]	Loss: -17.4518	Cost: 11.20s
Train Epoch: 1347 	Average Loss: -16.4409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7128

Learning rate: 0.0001999104758655482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1348 [0/90000 (0%)]	Loss: -11.2748	Cost: 26.99s
Train Epoch: 1348 [20480/90000 (23%)]	Loss: -17.5524	Cost: 6.38s
Train Epoch: 1348 [40960/90000 (45%)]	Loss: -17.1176	Cost: 8.77s
Train Epoch: 1348 [61440/90000 (68%)]	Loss: -17.5332	Cost: 6.03s
Train Epoch: 1348 [81920/90000 (91%)]	Loss: -17.7253	Cost: 8.00s
Train Epoch: 1348 	Average Loss: -17.0789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7721

Learning rate: 0.00019991034291234763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1349 [0/90000 (0%)]	Loss: -10.9080	Cost: 24.13s
Train Epoch: 1349 [20480/90000 (23%)]	Loss: -17.7355	Cost: 6.06s
Train Epoch: 1349 [40960/90000 (45%)]	Loss: -17.1517	Cost: 8.20s
Train Epoch: 1349 [61440/90000 (68%)]	Loss: -17.6851	Cost: 5.77s
Train Epoch: 1349 [81920/90000 (91%)]	Loss: -17.5824	Cost: 6.10s
Train Epoch: 1349 	Average Loss: -17.1449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6075

Learning rate: 0.00019991020986053954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1350 [0/90000 (0%)]	Loss: -10.5074	Cost: 22.54s
Train Epoch: 1350 [20480/90000 (23%)]	Loss: -17.9009	Cost: 6.01s
Train Epoch: 1350 [40960/90000 (45%)]	Loss: -17.2814	Cost: 8.68s
Train Epoch: 1350 [61440/90000 (68%)]	Loss: -17.4602	Cost: 6.21s
Train Epoch: 1350 [81920/90000 (91%)]	Loss: -17.2289	Cost: 11.54s
Train Epoch: 1350 	Average Loss: -17.0825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6966

Learning rate: 0.000199910076710124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1351 [0/90000 (0%)]	Loss: -11.6141	Cost: 25.30s
Train Epoch: 1351 [20480/90000 (23%)]	Loss: -17.6187	Cost: 6.40s
Train Epoch: 1351 [40960/90000 (45%)]	Loss: -17.1619	Cost: 10.89s
Train Epoch: 1351 [61440/90000 (68%)]	Loss: -17.6973	Cost: 5.86s
Train Epoch: 1351 [81920/90000 (91%)]	Loss: -17.6182	Cost: 6.86s
Train Epoch: 1351 	Average Loss: -17.1025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7352

Learning rate: 0.00019990994346110117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1352 [0/90000 (0%)]	Loss: -11.0356	Cost: 25.94s
Train Epoch: 1352 [20480/90000 (23%)]	Loss: -17.5457	Cost: 6.12s
Train Epoch: 1352 [40960/90000 (45%)]	Loss: -17.0719	Cost: 7.31s
Train Epoch: 1352 [61440/90000 (68%)]	Loss: -17.6960	Cost: 6.01s
Train Epoch: 1352 [81920/90000 (91%)]	Loss: -17.5954	Cost: 7.31s
Train Epoch: 1352 	Average Loss: -17.1598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8149

Learning rate: 0.00019990981011347122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1353 [0/90000 (0%)]	Loss: -11.9123	Cost: 23.43s
Train Epoch: 1353 [20480/90000 (23%)]	Loss: -17.8043	Cost: 6.08s
Train Epoch: 1353 [40960/90000 (45%)]	Loss: -17.2403	Cost: 6.97s
Train Epoch: 1353 [61440/90000 (68%)]	Loss: -17.5378	Cost: 6.09s
Train Epoch: 1353 [81920/90000 (91%)]	Loss: -17.5791	Cost: 9.24s
Train Epoch: 1353 	Average Loss: -17.1903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8417

Learning rate: 0.0001999096766672342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1354 [0/90000 (0%)]	Loss: -11.6095	Cost: 23.95s
Train Epoch: 1354 [20480/90000 (23%)]	Loss: -17.9434	Cost: 6.17s
Train Epoch: 1354 [40960/90000 (45%)]	Loss: -17.2980	Cost: 11.47s
Train Epoch: 1354 [61440/90000 (68%)]	Loss: -17.8878	Cost: 6.14s
Train Epoch: 1354 [81920/90000 (91%)]	Loss: -17.4963	Cost: 9.79s
Train Epoch: 1354 	Average Loss: -17.3516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5329

Learning rate: 0.00019990954312239028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1355 [0/90000 (0%)]	Loss: -11.8838	Cost: 27.69s
Train Epoch: 1355 [20480/90000 (23%)]	Loss: -17.7943	Cost: 6.30s
Train Epoch: 1355 [40960/90000 (45%)]	Loss: -17.2240	Cost: 9.20s
Train Epoch: 1355 [61440/90000 (68%)]	Loss: -17.7123	Cost: 5.87s
Train Epoch: 1355 [81920/90000 (91%)]	Loss: -17.6926	Cost: 7.27s
Train Epoch: 1355 	Average Loss: -17.1648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8059

Learning rate: 0.00019990940947893962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1356 [0/90000 (0%)]	Loss: -11.3965	Cost: 23.65s
Train Epoch: 1356 [20480/90000 (23%)]	Loss: -17.9701	Cost: 6.07s
Train Epoch: 1356 [40960/90000 (45%)]	Loss: -17.5696	Cost: 8.59s
Train Epoch: 1356 [61440/90000 (68%)]	Loss: -17.8162	Cost: 5.77s
Train Epoch: 1356 [81920/90000 (91%)]	Loss: -17.6760	Cost: 5.97s
Train Epoch: 1356 	Average Loss: -17.3453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8345

Learning rate: 0.00019990927573688231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1357 [0/90000 (0%)]	Loss: -10.5437	Cost: 23.58s
Train Epoch: 1357 [20480/90000 (23%)]	Loss: -17.8036	Cost: 6.08s
Train Epoch: 1357 [40960/90000 (45%)]	Loss: -17.1936	Cost: 7.30s
Train Epoch: 1357 [61440/90000 (68%)]	Loss: -17.6634	Cost: 6.18s
Train Epoch: 1357 [81920/90000 (91%)]	Loss: -17.6375	Cost: 11.60s
Train Epoch: 1357 	Average Loss: -17.1734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6633

Learning rate: 0.0001999091418962185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1358 [0/90000 (0%)]	Loss: -11.0778	Cost: 25.33s
Train Epoch: 1358 [20480/90000 (23%)]	Loss: -17.8188	Cost: 6.45s
Train Epoch: 1358 [40960/90000 (45%)]	Loss: -17.2968	Cost: 10.82s
Train Epoch: 1358 [61440/90000 (68%)]	Loss: -17.7893	Cost: 6.21s
Train Epoch: 1358 [81920/90000 (91%)]	Loss: -17.7146	Cost: 7.86s
Train Epoch: 1358 	Average Loss: -17.1885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6455

Learning rate: 0.00019990900795694832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1359 [0/90000 (0%)]	Loss: -10.7438	Cost: 26.63s
Train Epoch: 1359 [20480/90000 (23%)]	Loss: -17.6883	Cost: 6.11s
Train Epoch: 1359 [40960/90000 (45%)]	Loss: -17.1412	Cost: 7.31s
Train Epoch: 1359 [61440/90000 (68%)]	Loss: -17.6505	Cost: 6.00s
Train Epoch: 1359 [81920/90000 (91%)]	Loss: -17.3822	Cost: 8.23s
Train Epoch: 1359 	Average Loss: -17.0632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4510

Learning rate: 0.0001999088739190719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1360 [0/90000 (0%)]	Loss: -11.2023	Cost: 23.72s
Train Epoch: 1360 [20480/90000 (23%)]	Loss: -17.5893	Cost: 6.13s
Train Epoch: 1360 [40960/90000 (45%)]	Loss: -16.9765	Cost: 7.14s
Train Epoch: 1360 [61440/90000 (68%)]	Loss: -17.4520	Cost: 5.99s
Train Epoch: 1360 [81920/90000 (91%)]	Loss: -17.7168	Cost: 7.17s
Train Epoch: 1360 	Average Loss: -17.0215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8791

Saving model as e1360_model.pt & e1360_waveforms_supplementary.hdf5
Learning rate: 0.00019990873978258938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1361 [0/90000 (0%)]	Loss: -10.9189	Cost: 22.45s
Train Epoch: 1361 [20480/90000 (23%)]	Loss: -17.9178	Cost: 6.21s
Train Epoch: 1361 [40960/90000 (45%)]	Loss: -17.3477	Cost: 11.00s
Train Epoch: 1361 [61440/90000 (68%)]	Loss: -17.6085	Cost: 6.34s
Train Epoch: 1361 [81920/90000 (91%)]	Loss: -17.6882	Cost: 10.84s
Train Epoch: 1361 	Average Loss: -17.1416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6629

Learning rate: 0.00019990860554750087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1362 [0/90000 (0%)]	Loss: -11.3500	Cost: 27.17s
Train Epoch: 1362 [20480/90000 (23%)]	Loss: -17.8040	Cost: 6.34s
Train Epoch: 1362 [40960/90000 (45%)]	Loss: -16.8444	Cost: 9.57s
Train Epoch: 1362 [61440/90000 (68%)]	Loss: -17.4360	Cost: 5.88s
Train Epoch: 1362 [81920/90000 (91%)]	Loss: -17.6916	Cost: 7.99s
Train Epoch: 1362 	Average Loss: -17.1079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6337

Learning rate: 0.00019990847121380652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1363 [0/90000 (0%)]	Loss: -11.9667	Cost: 24.75s
Train Epoch: 1363 [20480/90000 (23%)]	Loss: -17.6210	Cost: 6.24s
Train Epoch: 1363 [40960/90000 (45%)]	Loss: -17.1671	Cost: 7.97s
Train Epoch: 1363 [61440/90000 (68%)]	Loss: -17.4595	Cost: 5.80s
Train Epoch: 1363 [81920/90000 (91%)]	Loss: -17.5894	Cost: 6.47s
Train Epoch: 1363 	Average Loss: -17.1548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7203

Learning rate: 0.00019990833678150646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1364 [0/90000 (0%)]	Loss: -11.3129	Cost: 22.16s
Train Epoch: 1364 [20480/90000 (23%)]	Loss: -17.6972	Cost: 6.12s
Train Epoch: 1364 [40960/90000 (45%)]	Loss: -17.5010	Cost: 8.98s
Train Epoch: 1364 [61440/90000 (68%)]	Loss: -17.7887	Cost: 6.21s
Train Epoch: 1364 [81920/90000 (91%)]	Loss: -18.1060	Cost: 11.54s
Train Epoch: 1364 	Average Loss: -17.3371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0174

Saving model as e1364_model.pt & e1364_waveforms_supplementary.hdf5
Learning rate: 0.00019990820225060084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1365 [0/90000 (0%)]	Loss: -11.9624	Cost: 27.81s
Train Epoch: 1365 [20480/90000 (23%)]	Loss: -17.9500	Cost: 6.43s
Train Epoch: 1365 [40960/90000 (45%)]	Loss: -17.4532	Cost: 10.09s
Train Epoch: 1365 [61440/90000 (68%)]	Loss: -17.8235	Cost: 5.82s
Train Epoch: 1365 [81920/90000 (91%)]	Loss: -17.8333	Cost: 6.12s
Train Epoch: 1365 	Average Loss: -17.3807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0671

Saving model as e1365_model.pt & e1365_waveforms_supplementary.hdf5
Learning rate: 0.00019990806762108977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1366 [0/90000 (0%)]	Loss: -11.6738	Cost: 25.59s
Train Epoch: 1366 [20480/90000 (23%)]	Loss: -18.0824	Cost: 6.08s
Train Epoch: 1366 [40960/90000 (45%)]	Loss: -17.6077	Cost: 8.69s
Train Epoch: 1366 [61440/90000 (68%)]	Loss: -18.2475	Cost: 5.75s
Train Epoch: 1366 [81920/90000 (91%)]	Loss: -17.2922	Cost: 6.51s
Train Epoch: 1366 	Average Loss: -17.4334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5001

Learning rate: 0.00019990793289297338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1367 [0/90000 (0%)]	Loss: -10.0567	Cost: 22.94s
Train Epoch: 1367 [20480/90000 (23%)]	Loss: -17.3741	Cost: 6.20s
Train Epoch: 1367 [40960/90000 (45%)]	Loss: -17.0001	Cost: 8.65s
Train Epoch: 1367 [61440/90000 (68%)]	Loss: -17.0713	Cost: 6.18s
Train Epoch: 1367 [81920/90000 (91%)]	Loss: -17.5072	Cost: 11.39s
Train Epoch: 1367 	Average Loss: -16.8861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7562

Learning rate: 0.00019990779806625182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1368 [0/90000 (0%)]	Loss: -11.5310	Cost: 27.15s
Train Epoch: 1368 [20480/90000 (23%)]	Loss: -17.5872	Cost: 6.50s
Train Epoch: 1368 [40960/90000 (45%)]	Loss: -17.2230	Cost: 10.39s
Train Epoch: 1368 [61440/90000 (68%)]	Loss: -17.8240	Cost: 5.80s
Train Epoch: 1368 [81920/90000 (91%)]	Loss: -18.0199	Cost: 6.35s
Train Epoch: 1368 	Average Loss: -17.1910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9831

Learning rate: 0.0001999076631409252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1369 [0/90000 (0%)]	Loss: -11.2648	Cost: 26.34s
Train Epoch: 1369 [20480/90000 (23%)]	Loss: -17.9344	Cost: 6.14s
Train Epoch: 1369 [40960/90000 (45%)]	Loss: -17.4552	Cost: 6.93s
Train Epoch: 1369 [61440/90000 (68%)]	Loss: -18.0183	Cost: 6.05s
Train Epoch: 1369 [81920/90000 (91%)]	Loss: -18.0845	Cost: 8.14s
Train Epoch: 1369 	Average Loss: -17.4012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7544

Learning rate: 0.00019990752811699372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1370 [0/90000 (0%)]	Loss: -11.8152	Cost: 24.20s
Train Epoch: 1370 [20480/90000 (23%)]	Loss: -17.8616	Cost: 6.16s
Train Epoch: 1370 [40960/90000 (45%)]	Loss: -15.5874	Cost: 6.90s
Train Epoch: 1370 [61440/90000 (68%)]	Loss: -15.7356	Cost: 6.03s
Train Epoch: 1370 [81920/90000 (91%)]	Loss: -16.2568	Cost: 9.77s
Train Epoch: 1370 	Average Loss: -16.2743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8504

Learning rate: 0.00019990739299445743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1371 [0/90000 (0%)]	Loss: -10.0249	Cost: 23.67s
Train Epoch: 1371 [20480/90000 (23%)]	Loss: -17.1243	Cost: 6.17s
Train Epoch: 1371 [40960/90000 (45%)]	Loss: -16.5081	Cost: 11.15s
Train Epoch: 1371 [61440/90000 (68%)]	Loss: -17.2039	Cost: 6.15s
Train Epoch: 1371 [81920/90000 (91%)]	Loss: -17.4738	Cost: 10.43s
Train Epoch: 1371 	Average Loss: -16.6143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6806

Learning rate: 0.0001999072577733165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1372 [0/90000 (0%)]	Loss: -11.3819	Cost: 27.28s
Train Epoch: 1372 [20480/90000 (23%)]	Loss: -17.7299	Cost: 6.45s
Train Epoch: 1372 [40960/90000 (45%)]	Loss: -17.2594	Cost: 8.99s
Train Epoch: 1372 [61440/90000 (68%)]	Loss: -17.7017	Cost: 5.96s
Train Epoch: 1372 [81920/90000 (91%)]	Loss: -17.8299	Cost: 9.25s
Train Epoch: 1372 	Average Loss: -17.2263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9306

Learning rate: 0.00019990712245357106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1373 [0/90000 (0%)]	Loss: -10.9350	Cost: 23.29s
Train Epoch: 1373 [20480/90000 (23%)]	Loss: -17.9922	Cost: 6.08s
Train Epoch: 1373 [40960/90000 (45%)]	Loss: -17.4812	Cost: 7.27s
Train Epoch: 1373 [61440/90000 (68%)]	Loss: -17.7748	Cost: 5.93s
Train Epoch: 1373 [81920/90000 (91%)]	Loss: -17.8206	Cost: 6.06s
Train Epoch: 1373 	Average Loss: -17.3457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8557

Learning rate: 0.00019990698703522124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1374 [0/90000 (0%)]	Loss: -10.2456	Cost: 23.47s
Train Epoch: 1374 [20480/90000 (23%)]	Loss: -17.5072	Cost: 6.28s
Train Epoch: 1374 [40960/90000 (45%)]	Loss: -16.8158	Cost: 10.34s
Train Epoch: 1374 [61440/90000 (68%)]	Loss: -17.3104	Cost: 6.61s
Train Epoch: 1374 [81920/90000 (91%)]	Loss: -17.7498	Cost: 10.98s
Train Epoch: 1374 	Average Loss: -16.9350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7236

Learning rate: 0.00019990685151826719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1375 [0/90000 (0%)]	Loss: -10.3991	Cost: 28.68s
Train Epoch: 1375 [20480/90000 (23%)]	Loss: -18.0501	Cost: 6.36s
Train Epoch: 1375 [40960/90000 (45%)]	Loss: -17.1483	Cost: 9.85s
Train Epoch: 1375 [61440/90000 (68%)]	Loss: -17.8160	Cost: 5.82s
Train Epoch: 1375 [81920/90000 (91%)]	Loss: -17.7629	Cost: 6.22s
Train Epoch: 1375 	Average Loss: -17.2614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8957

Learning rate: 0.00019990671590270901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1376 [0/90000 (0%)]	Loss: -10.8296	Cost: 25.06s
Train Epoch: 1376 [20480/90000 (23%)]	Loss: -18.0239	Cost: 6.10s
Train Epoch: 1376 [40960/90000 (45%)]	Loss: -17.6104	Cost: 8.12s
Train Epoch: 1376 [61440/90000 (68%)]	Loss: -17.8283	Cost: 6.00s
Train Epoch: 1376 [81920/90000 (91%)]	Loss: -18.1205	Cost: 7.00s
Train Epoch: 1376 	Average Loss: -17.5218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0952

Saving model as e1376_model.pt & e1376_waveforms_supplementary.hdf5
Learning rate: 0.00019990658018854686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1377 [0/90000 (0%)]	Loss: -10.6916	Cost: 22.62s
Train Epoch: 1377 [20480/90000 (23%)]	Loss: -18.1562	Cost: 6.05s
Train Epoch: 1377 [40960/90000 (45%)]	Loss: -17.4432	Cost: 9.43s
Train Epoch: 1377 [61440/90000 (68%)]	Loss: -17.8858	Cost: 6.46s
Train Epoch: 1377 [81920/90000 (91%)]	Loss: -17.8948	Cost: 9.18s
Train Epoch: 1377 	Average Loss: -17.4235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9372

Learning rate: 0.00019990644437578085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1378 [0/90000 (0%)]	Loss: -11.9092	Cost: 25.53s
Train Epoch: 1378 [20480/90000 (23%)]	Loss: -18.0212	Cost: 6.50s
Train Epoch: 1378 [40960/90000 (45%)]	Loss: -17.5042	Cost: 11.54s
Train Epoch: 1378 [61440/90000 (68%)]	Loss: -17.8377	Cost: 6.27s
Train Epoch: 1378 [81920/90000 (91%)]	Loss: -17.7740	Cost: 8.48s
Train Epoch: 1378 	Average Loss: -17.4350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8230

Learning rate: 0.00019990630846441115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1379 [0/90000 (0%)]	Loss: -10.6219	Cost: 26.57s
Train Epoch: 1379 [20480/90000 (23%)]	Loss: -17.9841	Cost: 6.22s
Train Epoch: 1379 [40960/90000 (45%)]	Loss: -17.1709	Cost: 8.82s
Train Epoch: 1379 [61440/90000 (68%)]	Loss: -17.8922	Cost: 6.02s
Train Epoch: 1379 [81920/90000 (91%)]	Loss: -17.5537	Cost: 8.52s
Train Epoch: 1379 	Average Loss: -17.2495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5029

Learning rate: 0.00019990617245443785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1380 [0/90000 (0%)]	Loss: -10.8799	Cost: 24.04s
Train Epoch: 1380 [20480/90000 (23%)]	Loss: -17.5172	Cost: 6.05s
Train Epoch: 1380 [40960/90000 (45%)]	Loss: -16.9104	Cost: 8.22s
Train Epoch: 1380 [61440/90000 (68%)]	Loss: -17.5658	Cost: 5.78s
Train Epoch: 1380 [81920/90000 (91%)]	Loss: -17.8165	Cost: 5.81s
Train Epoch: 1380 	Average Loss: -17.0315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9236

Learning rate: 0.00019990603634586116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1381 [0/90000 (0%)]	Loss: -11.9859	Cost: 22.53s
Train Epoch: 1381 [20480/90000 (23%)]	Loss: -17.7619	Cost: 6.01s
Train Epoch: 1381 [40960/90000 (45%)]	Loss: -17.2008	Cost: 8.71s
Train Epoch: 1381 [61440/90000 (68%)]	Loss: -17.6354	Cost: 6.14s
Train Epoch: 1381 [81920/90000 (91%)]	Loss: -17.5892	Cost: 11.45s
Train Epoch: 1381 	Average Loss: -17.1364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7621

Learning rate: 0.00019990590013868113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1382 [0/90000 (0%)]	Loss: -11.6478	Cost: 25.74s
Train Epoch: 1382 [20480/90000 (23%)]	Loss: -17.8721	Cost: 6.37s
Train Epoch: 1382 [40960/90000 (45%)]	Loss: -17.3705	Cost: 11.14s
Train Epoch: 1382 [61440/90000 (68%)]	Loss: -17.8170	Cost: 6.00s
Train Epoch: 1382 [81920/90000 (91%)]	Loss: -17.8147	Cost: 6.25s
Train Epoch: 1382 	Average Loss: -17.3168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0379

Learning rate: 0.0001999057638328979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1383 [0/90000 (0%)]	Loss: -11.2825	Cost: 26.55s
Train Epoch: 1383 [20480/90000 (23%)]	Loss: -18.1608	Cost: 6.15s
Train Epoch: 1383 [40960/90000 (45%)]	Loss: -17.6914	Cost: 7.28s
Train Epoch: 1383 [61440/90000 (68%)]	Loss: -18.0954	Cost: 6.01s
Train Epoch: 1383 [81920/90000 (91%)]	Loss: -18.0421	Cost: 7.83s
Train Epoch: 1383 	Average Loss: -17.5867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1286

Saving model as e1383_model.pt & e1383_waveforms_supplementary.hdf5
Learning rate: 0.00019990562742851166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1384 [0/90000 (0%)]	Loss: -11.7439	Cost: 23.96s
Train Epoch: 1384 [20480/90000 (23%)]	Loss: -17.4706	Cost: 6.09s
Train Epoch: 1384 [40960/90000 (45%)]	Loss: -16.9516	Cost: 7.95s
Train Epoch: 1384 [61440/90000 (68%)]	Loss: -17.6444	Cost: 5.91s
Train Epoch: 1384 [81920/90000 (91%)]	Loss: -17.5072	Cost: 7.40s
Train Epoch: 1384 	Average Loss: -17.1147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7983

Learning rate: 0.00019990549092552251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1385 [0/90000 (0%)]	Loss: -11.8303	Cost: 22.37s
Train Epoch: 1385 [20480/90000 (23%)]	Loss: -18.1522	Cost: 6.48s
Train Epoch: 1385 [40960/90000 (45%)]	Loss: -17.4618	Cost: 10.35s
Train Epoch: 1385 [61440/90000 (68%)]	Loss: -17.7700	Cost: 6.30s
Train Epoch: 1385 [81920/90000 (91%)]	Loss: -17.2506	Cost: 11.37s
Train Epoch: 1385 	Average Loss: -17.3284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3899

Learning rate: 0.00019990535432393063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1386 [0/90000 (0%)]	Loss: -10.7661	Cost: 27.92s
Train Epoch: 1386 [20480/90000 (23%)]	Loss: -17.6988	Cost: 6.31s
Train Epoch: 1386 [40960/90000 (45%)]	Loss: -17.2254	Cost: 10.07s
Train Epoch: 1386 [61440/90000 (68%)]	Loss: -17.7577	Cost: 5.75s
Train Epoch: 1386 [81920/90000 (91%)]	Loss: -17.6106	Cost: 6.16s
Train Epoch: 1386 	Average Loss: -17.1500
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9869

Learning rate: 0.0001999052176237361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1387 [0/90000 (0%)]	Loss: -11.7651	Cost: 25.91s
Train Epoch: 1387 [20480/90000 (23%)]	Loss: -18.0158	Cost: 6.07s
Train Epoch: 1387 [40960/90000 (45%)]	Loss: -17.7494	Cost: 7.49s
Train Epoch: 1387 [61440/90000 (68%)]	Loss: -18.0124	Cost: 6.00s
Train Epoch: 1387 [81920/90000 (91%)]	Loss: -17.9807	Cost: 7.35s
Train Epoch: 1387 	Average Loss: -17.5627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1723

Saving model as e1387_model.pt & e1387_waveforms_supplementary.hdf5
Learning rate: 0.00019990508082493906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1388 [0/90000 (0%)]	Loss: -11.9868	Cost: 24.46s
Train Epoch: 1388 [20480/90000 (23%)]	Loss: -18.2891	Cost: 6.06s
Train Epoch: 1388 [40960/90000 (45%)]	Loss: -17.8875	Cost: 7.64s
Train Epoch: 1388 [61440/90000 (68%)]	Loss: -18.0759	Cost: 6.31s
Train Epoch: 1388 [81920/90000 (91%)]	Loss: -17.9027	Cost: 11.60s
Train Epoch: 1388 	Average Loss: -17.6675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0873

Learning rate: 0.0001999049439275397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1389 [0/90000 (0%)]	Loss: -11.6852	Cost: 25.56s
Train Epoch: 1389 [20480/90000 (23%)]	Loss: -18.0503	Cost: 6.30s
Train Epoch: 1389 [40960/90000 (45%)]	Loss: -16.3927	Cost: 11.05s
Train Epoch: 1389 [61440/90000 (68%)]	Loss: -16.3379	Cost: 6.28s
Train Epoch: 1389 [81920/90000 (91%)]	Loss: -16.6198	Cost: 8.56s
Train Epoch: 1389 	Average Loss: -16.6240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1995

Learning rate: 0.00019990480693153807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1390 [0/90000 (0%)]	Loss: -10.4260	Cost: 26.49s
Train Epoch: 1390 [20480/90000 (23%)]	Loss: -17.1441	Cost: 6.22s
Train Epoch: 1390 [40960/90000 (45%)]	Loss: -16.5033	Cost: 8.52s
Train Epoch: 1390 [61440/90000 (68%)]	Loss: -17.2469	Cost: 5.98s
Train Epoch: 1390 [81920/90000 (91%)]	Loss: -17.6624	Cost: 10.02s
Train Epoch: 1390 	Average Loss: -16.6948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7636

Learning rate: 0.00019990466983693436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1391 [0/90000 (0%)]	Loss: -10.8221	Cost: 23.57s
Train Epoch: 1391 [20480/90000 (23%)]	Loss: -18.0101	Cost: 6.17s
Train Epoch: 1391 [40960/90000 (45%)]	Loss: -17.4762	Cost: 7.07s
Train Epoch: 1391 [61440/90000 (68%)]	Loss: -17.8162	Cost: 6.20s
Train Epoch: 1391 [81920/90000 (91%)]	Loss: -17.7135	Cost: 9.43s
Train Epoch: 1391 	Average Loss: -17.3087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9341

Learning rate: 0.0001999045326437287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1392 [0/90000 (0%)]	Loss: -11.2453	Cost: 23.54s
Train Epoch: 1392 [20480/90000 (23%)]	Loss: -18.0477	Cost: 6.23s
Train Epoch: 1392 [40960/90000 (45%)]	Loss: -17.4413	Cost: 11.23s
Train Epoch: 1392 [61440/90000 (68%)]	Loss: -17.7700	Cost: 6.21s
Train Epoch: 1392 [81920/90000 (91%)]	Loss: -17.9717	Cost: 9.83s
Train Epoch: 1392 	Average Loss: -17.3723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9473

Learning rate: 0.0001999043953519212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1393 [0/90000 (0%)]	Loss: -11.6809	Cost: 26.40s
Train Epoch: 1393 [20480/90000 (23%)]	Loss: -18.0296	Cost: 6.24s
Train Epoch: 1393 [40960/90000 (45%)]	Loss: -17.6143	Cost: 7.75s
Train Epoch: 1393 [61440/90000 (68%)]	Loss: -17.8936	Cost: 6.05s
Train Epoch: 1393 [81920/90000 (91%)]	Loss: -18.0958	Cost: 8.50s
Train Epoch: 1393 	Average Loss: -17.5287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0386

Learning rate: 0.000199904257961512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1394 [0/90000 (0%)]	Loss: -11.3088	Cost: 23.62s
Train Epoch: 1394 [20480/90000 (23%)]	Loss: -18.3410	Cost: 6.08s
Train Epoch: 1394 [40960/90000 (45%)]	Loss: -17.8597	Cost: 8.08s
Train Epoch: 1394 [61440/90000 (68%)]	Loss: -18.3097	Cost: 5.69s
Train Epoch: 1394 [81920/90000 (91%)]	Loss: -17.7279	Cost: 6.80s
Train Epoch: 1394 	Average Loss: -17.6197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6604

Learning rate: 0.0001999041204725013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1395 [0/90000 (0%)]	Loss: -10.2031	Cost: 23.50s
Train Epoch: 1395 [20480/90000 (23%)]	Loss: -16.6713	Cost: 6.20s
Train Epoch: 1395 [40960/90000 (45%)]	Loss: -16.6018	Cost: 11.14s
Train Epoch: 1395 [61440/90000 (68%)]	Loss: -17.1712	Cost: 6.23s
Train Epoch: 1395 [81920/90000 (91%)]	Loss: -17.4000	Cost: 10.92s
Train Epoch: 1395 	Average Loss: -16.4783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5723

Learning rate: 0.00019990398288488915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1396 [0/90000 (0%)]	Loss: -11.3537	Cost: 27.81s
Train Epoch: 1396 [20480/90000 (23%)]	Loss: -17.9248	Cost: 6.27s
Train Epoch: 1396 [40960/90000 (45%)]	Loss: -17.6349	Cost: 9.29s
Train Epoch: 1396 [61440/90000 (68%)]	Loss: -17.6487	Cost: 5.97s
Train Epoch: 1396 [81920/90000 (91%)]	Loss: -17.8206	Cost: 8.98s
Train Epoch: 1396 	Average Loss: -17.2539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9070

Learning rate: 0.00019990384519867572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1397 [0/90000 (0%)]	Loss: -11.7127	Cost: 24.10s
Train Epoch: 1397 [20480/90000 (23%)]	Loss: -18.2477	Cost: 6.09s
Train Epoch: 1397 [40960/90000 (45%)]	Loss: -17.5718	Cost: 7.22s
Train Epoch: 1397 [61440/90000 (68%)]	Loss: -17.9953	Cost: 6.08s
Train Epoch: 1397 [81920/90000 (91%)]	Loss: -17.9378	Cost: 6.12s
Train Epoch: 1397 	Average Loss: -17.5348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1474

Learning rate: 0.00019990370741386113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1398 [0/90000 (0%)]	Loss: -11.2754	Cost: 22.07s
Train Epoch: 1398 [20480/90000 (23%)]	Loss: -18.3236	Cost: 6.37s
Train Epoch: 1398 [40960/90000 (45%)]	Loss: -17.6692	Cost: 10.51s
Train Epoch: 1398 [61440/90000 (68%)]	Loss: -18.1966	Cost: 6.40s
Train Epoch: 1398 [81920/90000 (91%)]	Loss: -18.1571	Cost: 11.62s
Train Epoch: 1398 	Average Loss: -17.5938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0934

Learning rate: 0.00019990356953044556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1399 [0/90000 (0%)]	Loss: -10.7043	Cost: 27.82s
Train Epoch: 1399 [20480/90000 (23%)]	Loss: -18.1267	Cost: 6.24s
Train Epoch: 1399 [40960/90000 (45%)]	Loss: -17.7305	Cost: 9.03s
Train Epoch: 1399 [61440/90000 (68%)]	Loss: -17.9015	Cost: 5.93s
Train Epoch: 1399 [81920/90000 (91%)]	Loss: -18.1540	Cost: 7.84s
Train Epoch: 1399 	Average Loss: -17.5619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1564

Learning rate: 0.00019990343154842913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1400 [0/90000 (0%)]	Loss: -10.8415	Cost: 24.73s
Train Epoch: 1400 [20480/90000 (23%)]	Loss: -18.1313	Cost: 6.05s
Train Epoch: 1400 [40960/90000 (45%)]	Loss: -17.6403	Cost: 8.60s
Train Epoch: 1400 [61440/90000 (68%)]	Loss: -17.9605	Cost: 5.78s
Train Epoch: 1400 [81920/90000 (91%)]	Loss: -18.1149	Cost: 6.52s
Train Epoch: 1400 	Average Loss: -17.5620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2537

Saving model as e1400_model.pt & e1400_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1401 [0/90000 (0%)]	Loss: -11.7503	Cost: 22.73s
Train Epoch: 1401 [20480/90000 (23%)]	Loss: -17.9757	Cost: 6.33s
Train Epoch: 1401 [40960/90000 (45%)]	Loss: -17.8060	Cost: 11.31s
Train Epoch: 1401 [61440/90000 (68%)]	Loss: -18.1408	Cost: 6.41s
Train Epoch: 1401 [81920/90000 (91%)]	Loss: -18.3484	Cost: 11.68s
Train Epoch: 1401 	Average Loss: -17.6116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2280

Learning rate: 0.00019990315528859419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1402 [0/90000 (0%)]	Loss: -11.8190	Cost: 26.87s
Train Epoch: 1402 [20480/90000 (23%)]	Loss: -18.1422	Cost: 6.31s
Train Epoch: 1402 [40960/90000 (45%)]	Loss: -17.5256	Cost: 8.92s
Train Epoch: 1402 [61440/90000 (68%)]	Loss: -17.9323	Cost: 6.07s
Train Epoch: 1402 [81920/90000 (91%)]	Loss: -18.0235	Cost: 9.29s
Train Epoch: 1402 	Average Loss: -17.4565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2478

Learning rate: 0.00019990301701077598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1403 [0/90000 (0%)]	Loss: -11.9591	Cost: 23.44s
Train Epoch: 1403 [20480/90000 (23%)]	Loss: -18.3064	Cost: 6.10s
Train Epoch: 1403 [40960/90000 (45%)]	Loss: -17.5894	Cost: 6.82s
Train Epoch: 1403 [61440/90000 (68%)]	Loss: -18.0461	Cost: 6.04s
Train Epoch: 1403 [81920/90000 (91%)]	Loss: -18.1493	Cost: 7.67s
Train Epoch: 1403 	Average Loss: -17.6549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1901

Learning rate: 0.00019990287863435742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1404 [0/90000 (0%)]	Loss: -12.0489	Cost: 22.76s
Train Epoch: 1404 [20480/90000 (23%)]	Loss: -18.1322	Cost: 6.29s
Train Epoch: 1404 [40960/90000 (45%)]	Loss: -17.7453	Cost: 11.47s
Train Epoch: 1404 [61440/90000 (68%)]	Loss: -18.2314	Cost: 6.24s
Train Epoch: 1404 [81920/90000 (91%)]	Loss: -18.2176	Cost: 11.12s
Train Epoch: 1404 	Average Loss: -17.6844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3158

Saving model as e1404_model.pt & e1404_waveforms_supplementary.hdf5
Learning rate: 0.00019990274015933864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1405 [0/90000 (0%)]	Loss: -11.6359	Cost: 26.75s
Train Epoch: 1405 [20480/90000 (23%)]	Loss: -18.4128	Cost: 6.20s
Train Epoch: 1405 [40960/90000 (45%)]	Loss: -17.4527	Cost: 7.39s
Train Epoch: 1405 [61440/90000 (68%)]	Loss: -17.8790	Cost: 6.03s
Train Epoch: 1405 [81920/90000 (91%)]	Loss: -18.0890	Cost: 8.01s
Train Epoch: 1405 	Average Loss: -17.6081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1122

Learning rate: 0.00019990260158571984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1406 [0/90000 (0%)]	Loss: -11.3957	Cost: 23.55s
Train Epoch: 1406 [20480/90000 (23%)]	Loss: -18.0840	Cost: 6.12s
Train Epoch: 1406 [40960/90000 (45%)]	Loss: -17.4399	Cost: 7.51s
Train Epoch: 1406 [61440/90000 (68%)]	Loss: -17.9400	Cost: 5.81s
Train Epoch: 1406 [81920/90000 (91%)]	Loss: -17.9617	Cost: 6.10s
Train Epoch: 1406 	Average Loss: -17.5114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1715

Learning rate: 0.0001999024629135011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1407 [0/90000 (0%)]	Loss: -11.6719	Cost: 23.37s
Train Epoch: 1407 [20480/90000 (23%)]	Loss: -18.2858	Cost: 6.23s
Train Epoch: 1407 [40960/90000 (45%)]	Loss: -17.8341	Cost: 11.45s
Train Epoch: 1407 [61440/90000 (68%)]	Loss: -18.2690	Cost: 6.29s
Train Epoch: 1407 [81920/90000 (91%)]	Loss: -17.6356	Cost: 11.08s
Train Epoch: 1407 	Average Loss: -17.6398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4059

Learning rate: 0.00019990232414268262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1408 [0/90000 (0%)]	Loss: -10.6642	Cost: 30.56s
Train Epoch: 1408 [20480/90000 (23%)]	Loss: -17.3129	Cost: 6.51s
Train Epoch: 1408 [40960/90000 (45%)]	Loss: -17.0374	Cost: 8.93s
Train Epoch: 1408 [61440/90000 (68%)]	Loss: -17.2534	Cost: 5.76s
Train Epoch: 1408 [81920/90000 (91%)]	Loss: -17.1661	Cost: 6.13s
Train Epoch: 1408 	Average Loss: -16.8504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7973

Learning rate: 0.0001999021852732645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1409 [0/90000 (0%)]	Loss: -10.7457	Cost: 26.24s
Train Epoch: 1409 [20480/90000 (23%)]	Loss: -17.5869	Cost: 6.10s
Train Epoch: 1409 [40960/90000 (45%)]	Loss: -17.0481	Cost: 8.02s
Train Epoch: 1409 [61440/90000 (68%)]	Loss: -17.5824	Cost: 5.98s
Train Epoch: 1409 [81920/90000 (91%)]	Loss: -17.7839	Cost: 7.61s
Train Epoch: 1409 	Average Loss: -17.1150
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1200

Learning rate: 0.00019990204630524684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1410 [0/90000 (0%)]	Loss: -11.7652	Cost: 24.26s
Train Epoch: 1410 [20480/90000 (23%)]	Loss: -17.8315	Cost: 6.15s
Train Epoch: 1410 [40960/90000 (45%)]	Loss: -17.4985	Cost: 7.41s
Train Epoch: 1410 [61440/90000 (68%)]	Loss: -18.0105	Cost: 6.29s
Train Epoch: 1410 [81920/90000 (91%)]	Loss: -18.2604	Cost: 11.61s
Train Epoch: 1410 	Average Loss: -17.5796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2968

Learning rate: 0.00019990190723862984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1411 [0/90000 (0%)]	Loss: -12.3619	Cost: 26.00s
Train Epoch: 1411 [20480/90000 (23%)]	Loss: -18.4490	Cost: 6.52s
Train Epoch: 1411 [40960/90000 (45%)]	Loss: -17.8149	Cost: 11.16s
Train Epoch: 1411 [61440/90000 (68%)]	Loss: -18.1409	Cost: 6.05s
Train Epoch: 1411 [81920/90000 (91%)]	Loss: -18.0198	Cost: 8.00s
Train Epoch: 1411 	Average Loss: -17.7309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3046

Learning rate: 0.00019990176807341357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1412 [0/90000 (0%)]	Loss: -11.2185	Cost: 27.60s
Train Epoch: 1412 [20480/90000 (23%)]	Loss: -18.1726	Cost: 6.29s
Train Epoch: 1412 [40960/90000 (45%)]	Loss: -17.6844	Cost: 8.08s
Train Epoch: 1412 [61440/90000 (68%)]	Loss: -18.1011	Cost: 6.03s
Train Epoch: 1412 [81920/90000 (91%)]	Loss: -18.1014	Cost: 8.97s
Train Epoch: 1412 	Average Loss: -17.6537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2106

Learning rate: 0.00019990162880959822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1413 [0/90000 (0%)]	Loss: -11.3073	Cost: 23.32s
Train Epoch: 1413 [20480/90000 (23%)]	Loss: -18.3389	Cost: 6.09s
Train Epoch: 1413 [40960/90000 (45%)]	Loss: -17.8763	Cost: 6.75s
Train Epoch: 1413 [61440/90000 (68%)]	Loss: -18.0229	Cost: 6.29s
Train Epoch: 1413 [81920/90000 (91%)]	Loss: -18.0083	Cost: 8.29s
Train Epoch: 1413 	Average Loss: -17.6978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4920

Saving model as e1413_model.pt & e1413_waveforms_supplementary.hdf5
Learning rate: 0.00019990148944718395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1414 [0/90000 (0%)]	Loss: -12.4486	Cost: 24.53s
Train Epoch: 1414 [20480/90000 (23%)]	Loss: -18.4501	Cost: 6.34s
Train Epoch: 1414 [40960/90000 (45%)]	Loss: -17.6725	Cost: 11.21s
Train Epoch: 1414 [61440/90000 (68%)]	Loss: -18.1660	Cost: 6.20s
Train Epoch: 1414 [81920/90000 (91%)]	Loss: -18.3911	Cost: 9.02s
Train Epoch: 1414 	Average Loss: -17.8422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4723

Learning rate: 0.00019990134998617085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1415 [0/90000 (0%)]	Loss: -11.4577	Cost: 26.22s
Train Epoch: 1415 [20480/90000 (23%)]	Loss: -18.5317	Cost: 6.10s
Train Epoch: 1415 [40960/90000 (45%)]	Loss: -17.7737	Cost: 7.44s
Train Epoch: 1415 [61440/90000 (68%)]	Loss: -18.2435	Cost: 6.02s
Train Epoch: 1415 [81920/90000 (91%)]	Loss: -18.4744	Cost: 7.89s
Train Epoch: 1415 	Average Loss: -17.8634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5254

Saving model as e1415_model.pt & e1415_waveforms_supplementary.hdf5
Learning rate: 0.00019990121042655904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1416 [0/90000 (0%)]	Loss: -12.2913	Cost: 23.58s
Train Epoch: 1416 [20480/90000 (23%)]	Loss: -18.5530	Cost: 6.06s
Train Epoch: 1416 [40960/90000 (45%)]	Loss: -17.7493	Cost: 6.90s
Train Epoch: 1416 [61440/90000 (68%)]	Loss: -17.9993	Cost: 6.10s
Train Epoch: 1416 [81920/90000 (91%)]	Loss: -18.3028	Cost: 8.80s
Train Epoch: 1416 	Average Loss: -17.8127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3596

Learning rate: 0.0001999010707683487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1417 [0/90000 (0%)]	Loss: -11.5241	Cost: 22.48s
Train Epoch: 1417 [20480/90000 (23%)]	Loss: -18.4946	Cost: 6.28s
Train Epoch: 1417 [40960/90000 (45%)]	Loss: -17.2552	Cost: 11.71s
Train Epoch: 1417 [61440/90000 (68%)]	Loss: -17.6495	Cost: 6.28s
Train Epoch: 1417 [81920/90000 (91%)]	Loss: -17.7821	Cost: 11.24s
Train Epoch: 1417 	Average Loss: -17.4402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0398

Learning rate: 0.00019990093101153998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1418 [0/90000 (0%)]	Loss: -11.7512	Cost: 26.94s
Train Epoch: 1418 [20480/90000 (23%)]	Loss: -18.3611	Cost: 6.30s
Train Epoch: 1418 [40960/90000 (45%)]	Loss: -17.7058	Cost: 8.45s
Train Epoch: 1418 [61440/90000 (68%)]	Loss: -18.0894	Cost: 6.00s
Train Epoch: 1418 [81920/90000 (91%)]	Loss: -17.8524	Cost: 8.11s
Train Epoch: 1418 	Average Loss: -17.5598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0566

Learning rate: 0.00019990079115613296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1419 [0/90000 (0%)]	Loss: -11.1655	Cost: 24.14s
Train Epoch: 1419 [20480/90000 (23%)]	Loss: -16.7610	Cost: 6.06s
Train Epoch: 1419 [40960/90000 (45%)]	Loss: -16.4674	Cost: 7.44s
Train Epoch: 1419 [61440/90000 (68%)]	Loss: -17.2201	Cost: 5.95s
Train Epoch: 1419 [81920/90000 (91%)]	Loss: -17.5200	Cost: 5.99s
Train Epoch: 1419 	Average Loss: -16.6969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7576

Learning rate: 0.00019990065120212782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1420 [0/90000 (0%)]	Loss: -10.8876	Cost: 22.48s
Train Epoch: 1420 [20480/90000 (23%)]	Loss: -17.7865	Cost: 6.13s
Train Epoch: 1420 [40960/90000 (45%)]	Loss: -17.5680	Cost: 10.60s
Train Epoch: 1420 [61440/90000 (68%)]	Loss: -18.0924	Cost: 6.61s
Train Epoch: 1420 [81920/90000 (91%)]	Loss: -17.7921	Cost: 11.71s
Train Epoch: 1420 	Average Loss: -17.4576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8391

Learning rate: 0.0001999005111495247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1421 [0/90000 (0%)]	Loss: -11.2209	Cost: 28.56s
Train Epoch: 1421 [20480/90000 (23%)]	Loss: -17.6594	Cost: 6.47s
Train Epoch: 1421 [40960/90000 (45%)]	Loss: -17.3717	Cost: 10.11s
Train Epoch: 1421 [61440/90000 (68%)]	Loss: -17.7456	Cost: 5.77s
Train Epoch: 1421 [81920/90000 (91%)]	Loss: -18.1263	Cost: 6.01s
Train Epoch: 1421 	Average Loss: -17.3364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3886

Learning rate: 0.00019990037099832373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1422 [0/90000 (0%)]	Loss: -12.4283	Cost: 25.04s
Train Epoch: 1422 [20480/90000 (23%)]	Loss: -18.6287	Cost: 6.16s
Train Epoch: 1422 [40960/90000 (45%)]	Loss: -17.8927	Cost: 8.41s
Train Epoch: 1422 [61440/90000 (68%)]	Loss: -18.0674	Cost: 6.02s
Train Epoch: 1422 [81920/90000 (91%)]	Loss: -18.2056	Cost: 6.31s
Train Epoch: 1422 	Average Loss: -17.8023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2669

Learning rate: 0.00019990023074852506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1423 [0/90000 (0%)]	Loss: -10.9830	Cost: 23.46s
Train Epoch: 1423 [20480/90000 (23%)]	Loss: -18.1731	Cost: 6.03s
Train Epoch: 1423 [40960/90000 (45%)]	Loss: -17.8216	Cost: 7.03s
Train Epoch: 1423 [61440/90000 (68%)]	Loss: -18.4240	Cost: 6.14s
Train Epoch: 1423 [81920/90000 (91%)]	Loss: -18.2057	Cost: 11.17s
Train Epoch: 1423 	Average Loss: -17.7569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4866

Learning rate: 0.00019990009040012877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1424 [0/90000 (0%)]	Loss: -12.3895	Cost: 23.87s
Train Epoch: 1424 [20480/90000 (23%)]	Loss: -18.5899	Cost: 6.27s
Train Epoch: 1424 [40960/90000 (45%)]	Loss: -18.0483	Cost: 11.40s
Train Epoch: 1424 [61440/90000 (68%)]	Loss: -18.3955	Cost: 6.46s
Train Epoch: 1424 [81920/90000 (91%)]	Loss: -17.9355	Cost: 8.95s
Train Epoch: 1424 	Average Loss: -17.8844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1155

Learning rate: 0.0001998999499531351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1425 [0/90000 (0%)]	Loss: -12.2398	Cost: 27.12s
Train Epoch: 1425 [20480/90000 (23%)]	Loss: -18.0906	Cost: 6.36s
Train Epoch: 1425 [40960/90000 (45%)]	Loss: -17.5291	Cost: 8.08s
Train Epoch: 1425 [61440/90000 (68%)]	Loss: -17.9654	Cost: 6.01s
Train Epoch: 1425 [81920/90000 (91%)]	Loss: -18.0715	Cost: 6.96s
Train Epoch: 1425 	Average Loss: -17.6551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2957

Learning rate: 0.00019989980940754407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1426 [0/90000 (0%)]	Loss: -12.2331	Cost: 24.76s
Train Epoch: 1426 [20480/90000 (23%)]	Loss: -18.3477	Cost: 6.12s
Train Epoch: 1426 [40960/90000 (45%)]	Loss: -18.1584	Cost: 8.09s
Train Epoch: 1426 [61440/90000 (68%)]	Loss: -18.5088	Cost: 5.85s
Train Epoch: 1426 [81920/90000 (91%)]	Loss: -18.4681	Cost: 6.79s
Train Epoch: 1426 	Average Loss: -17.8834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1880

Learning rate: 0.0001998996687633559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1427 [0/90000 (0%)]	Loss: -11.6055	Cost: 23.83s
Train Epoch: 1427 [20480/90000 (23%)]	Loss: -18.1252	Cost: 6.09s
Train Epoch: 1427 [40960/90000 (45%)]	Loss: -17.6700	Cost: 7.28s
Train Epoch: 1427 [61440/90000 (68%)]	Loss: -18.2391	Cost: 6.14s
Train Epoch: 1427 [81920/90000 (91%)]	Loss: -18.0789	Cost: 11.83s
Train Epoch: 1427 	Average Loss: -17.6795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4329

Learning rate: 0.00019989952802057075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1428 [0/90000 (0%)]	Loss: -12.0095	Cost: 24.57s
Train Epoch: 1428 [20480/90000 (23%)]	Loss: -18.5209	Cost: 6.36s
Train Epoch: 1428 [40960/90000 (45%)]	Loss: -17.8416	Cost: 11.24s
Train Epoch: 1428 [61440/90000 (68%)]	Loss: -18.1745	Cost: 6.25s
Train Epoch: 1428 [81920/90000 (91%)]	Loss: -18.3489	Cost: 9.26s
Train Epoch: 1428 	Average Loss: -17.8167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4460

Learning rate: 0.00019989938717918869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1429 [0/90000 (0%)]	Loss: -12.8944	Cost: 26.57s
Train Epoch: 1429 [20480/90000 (23%)]	Loss: -18.6202	Cost: 6.24s
Train Epoch: 1429 [40960/90000 (45%)]	Loss: -18.0085	Cost: 8.08s
Train Epoch: 1429 [61440/90000 (68%)]	Loss: -18.2570	Cost: 5.98s
Train Epoch: 1429 [81920/90000 (91%)]	Loss: -18.5040	Cost: 8.21s
Train Epoch: 1429 	Average Loss: -17.9582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5653

Saving model as e1429_model.pt & e1429_waveforms_supplementary.hdf5
Learning rate: 0.00019989924623920987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1430 [0/90000 (0%)]	Loss: -12.0300	Cost: 24.11s
Train Epoch: 1430 [20480/90000 (23%)]	Loss: -18.6986	Cost: 6.03s
Train Epoch: 1430 [40960/90000 (45%)]	Loss: -17.7707	Cost: 8.11s
Train Epoch: 1430 [61440/90000 (68%)]	Loss: -17.9812	Cost: 5.75s
Train Epoch: 1430 [81920/90000 (91%)]	Loss: -18.2757	Cost: 6.57s
Train Epoch: 1430 	Average Loss: -17.7897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4612

Learning rate: 0.00019989910520063444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1431 [0/90000 (0%)]	Loss: -11.1315	Cost: 22.23s
Train Epoch: 1431 [20480/90000 (23%)]	Loss: -18.4622	Cost: 6.47s
Train Epoch: 1431 [40960/90000 (45%)]	Loss: -17.9482	Cost: 10.19s
Train Epoch: 1431 [61440/90000 (68%)]	Loss: -18.3082	Cost: 6.31s
Train Epoch: 1431 [81920/90000 (91%)]	Loss: -18.2905	Cost: 11.17s
Train Epoch: 1431 	Average Loss: -17.8533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4246

Learning rate: 0.00019989896406346258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1432 [0/90000 (0%)]	Loss: -11.7834	Cost: 28.00s
Train Epoch: 1432 [20480/90000 (23%)]	Loss: -18.3451	Cost: 6.35s
Train Epoch: 1432 [40960/90000 (45%)]	Loss: -17.9306	Cost: 9.45s
Train Epoch: 1432 [61440/90000 (68%)]	Loss: -18.4869	Cost: 5.89s
Train Epoch: 1432 [81920/90000 (91%)]	Loss: -18.4249	Cost: 7.26s
Train Epoch: 1432 	Average Loss: -17.9258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5864

Saving model as e1432_model.pt & e1432_waveforms_supplementary.hdf5
Learning rate: 0.00019989882282769438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1433 [0/90000 (0%)]	Loss: -11.9905	Cost: 23.94s
Train Epoch: 1433 [20480/90000 (23%)]	Loss: -18.6925	Cost: 6.08s
Train Epoch: 1433 [40960/90000 (45%)]	Loss: -18.3445	Cost: 8.69s
Train Epoch: 1433 [61440/90000 (68%)]	Loss: -16.1767	Cost: 5.74s
Train Epoch: 1433 [81920/90000 (91%)]	Loss: -16.2126	Cost: 6.42s
Train Epoch: 1433 	Average Loss: -17.1524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0635

Learning rate: 0.00019989868149333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1434 [0/90000 (0%)]	Loss: -10.5083	Cost: 22.31s
Train Epoch: 1434 [20480/90000 (23%)]	Loss: -17.3693	Cost: 6.08s
Train Epoch: 1434 [40960/90000 (45%)]	Loss: -17.1954	Cost: 7.36s
Train Epoch: 1434 [61440/90000 (68%)]	Loss: -17.7646	Cost: 6.22s
Train Epoch: 1434 [81920/90000 (91%)]	Loss: -18.2005	Cost: 11.55s
Train Epoch: 1434 	Average Loss: -17.1232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3005

Learning rate: 0.00019989854006036958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1435 [0/90000 (0%)]	Loss: -11.7366	Cost: 25.30s
Train Epoch: 1435 [20480/90000 (23%)]	Loss: -18.4601	Cost: 6.35s
Train Epoch: 1435 [40960/90000 (45%)]	Loss: -18.1193	Cost: 10.76s
Train Epoch: 1435 [61440/90000 (68%)]	Loss: -18.5469	Cost: 6.12s
Train Epoch: 1435 [81920/90000 (91%)]	Loss: -18.5006	Cost: 7.50s
Train Epoch: 1435 	Average Loss: -17.9853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5569

Learning rate: 0.00019989839852881325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1436 [0/90000 (0%)]	Loss: -12.0029	Cost: 26.59s
Train Epoch: 1436 [20480/90000 (23%)]	Loss: -18.8476	Cost: 6.16s
Train Epoch: 1436 [40960/90000 (45%)]	Loss: -18.1353	Cost: 7.54s
Train Epoch: 1436 [61440/90000 (68%)]	Loss: -18.5830	Cost: 6.00s
Train Epoch: 1436 [81920/90000 (91%)]	Loss: -18.5971	Cost: 7.81s
Train Epoch: 1436 	Average Loss: -18.1644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6153

Saving model as e1436_model.pt & e1436_waveforms_supplementary.hdf5
Learning rate: 0.00019989825689866115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1437 [0/90000 (0%)]	Loss: -11.9405	Cost: 23.36s
Train Epoch: 1437 [20480/90000 (23%)]	Loss: -18.8036	Cost: 6.05s
Train Epoch: 1437 [40960/90000 (45%)]	Loss: -18.1441	Cost: 8.33s
Train Epoch: 1437 [61440/90000 (68%)]	Loss: -18.5150	Cost: 5.73s
Train Epoch: 1437 [81920/90000 (91%)]	Loss: -18.5291	Cost: 6.63s
Train Epoch: 1437 	Average Loss: -18.0768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5801

Learning rate: 0.00019989811516991338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1438 [0/90000 (0%)]	Loss: -11.9337	Cost: 22.49s
Train Epoch: 1438 [20480/90000 (23%)]	Loss: -18.7780	Cost: 6.08s
Train Epoch: 1438 [40960/90000 (45%)]	Loss: -18.2282	Cost: 9.79s
Train Epoch: 1438 [61440/90000 (68%)]	Loss: -18.5358	Cost: 6.32s
Train Epoch: 1438 [81920/90000 (91%)]	Loss: -18.6109	Cost: 11.38s
Train Epoch: 1438 	Average Loss: -18.1250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7241

Saving model as e1438_model.pt & e1438_waveforms_supplementary.hdf5
Learning rate: 0.00019989797334257016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1439 [0/90000 (0%)]	Loss: -13.0701	Cost: 29.40s
Train Epoch: 1439 [20480/90000 (23%)]	Loss: -18.6252	Cost: 6.25s
Train Epoch: 1439 [40960/90000 (45%)]	Loss: -17.9491	Cost: 10.58s
Train Epoch: 1439 [61440/90000 (68%)]	Loss: -18.4676	Cost: 5.73s
Train Epoch: 1439 [81920/90000 (91%)]	Loss: -18.3452	Cost: 5.92s
Train Epoch: 1439 	Average Loss: -18.0407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6769

Learning rate: 0.00019989783141663155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1440 [0/90000 (0%)]	Loss: -11.9401	Cost: 24.79s
Train Epoch: 1440 [20480/90000 (23%)]	Loss: -18.6261	Cost: 6.07s
Train Epoch: 1440 [40960/90000 (45%)]	Loss: -17.8023	Cost: 8.35s
Train Epoch: 1440 [61440/90000 (68%)]	Loss: -18.4338	Cost: 5.81s
Train Epoch: 1440 [81920/90000 (91%)]	Loss: -18.5418	Cost: 6.46s
Train Epoch: 1440 	Average Loss: -17.9929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6802

Learning rate: 0.00019989768939209776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1441 [0/90000 (0%)]	Loss: -11.8738	Cost: 22.83s
Train Epoch: 1441 [20480/90000 (23%)]	Loss: -18.5236	Cost: 6.08s
Train Epoch: 1441 [40960/90000 (45%)]	Loss: -17.8572	Cost: 7.25s
Train Epoch: 1441 [61440/90000 (68%)]	Loss: -18.5645	Cost: 6.17s
Train Epoch: 1441 [81920/90000 (91%)]	Loss: -18.5442	Cost: 11.42s
Train Epoch: 1441 	Average Loss: -17.9735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6775

Learning rate: 0.00019989754726896893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1442 [0/90000 (0%)]	Loss: -10.7171	Cost: 24.91s
Train Epoch: 1442 [20480/90000 (23%)]	Loss: -18.3190	Cost: 6.21s
Train Epoch: 1442 [40960/90000 (45%)]	Loss: -17.7616	Cost: 10.46s
Train Epoch: 1442 [61440/90000 (68%)]	Loss: -18.2450	Cost: 6.28s
Train Epoch: 1442 [81920/90000 (91%)]	Loss: -18.4679	Cost: 9.05s
Train Epoch: 1442 	Average Loss: -17.8364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6476

Learning rate: 0.00019989740504724516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1443 [0/90000 (0%)]	Loss: -12.0577	Cost: 26.76s
Train Epoch: 1443 [20480/90000 (23%)]	Loss: -18.5847	Cost: 6.24s
Train Epoch: 1443 [40960/90000 (45%)]	Loss: -18.0074	Cost: 7.53s
Train Epoch: 1443 [61440/90000 (68%)]	Loss: -18.4939	Cost: 6.00s
Train Epoch: 1443 [81920/90000 (91%)]	Loss: -18.5884	Cost: 7.83s
Train Epoch: 1443 	Average Loss: -17.9456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7295

Saving model as e1443_model.pt & e1443_waveforms_supplementary.hdf5
Learning rate: 0.0001998972627269266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1444 [0/90000 (0%)]	Loss: -12.0360	Cost: 23.70s
Train Epoch: 1444 [20480/90000 (23%)]	Loss: -18.7497	Cost: 6.10s
Train Epoch: 1444 [40960/90000 (45%)]	Loss: -18.2130	Cost: 7.88s
Train Epoch: 1444 [61440/90000 (68%)]	Loss: -18.6181	Cost: 5.91s
Train Epoch: 1444 [81920/90000 (91%)]	Loss: -18.5051	Cost: 6.14s
Train Epoch: 1444 	Average Loss: -18.1382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4800

Learning rate: 0.0001998971203080134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1445 [0/90000 (0%)]	Loss: -12.3161	Cost: 22.41s
Train Epoch: 1445 [20480/90000 (23%)]	Loss: -18.5423	Cost: 6.48s
Train Epoch: 1445 [40960/90000 (45%)]	Loss: -18.0331	Cost: 11.34s
Train Epoch: 1445 [61440/90000 (68%)]	Loss: -18.6757	Cost: 6.43s
Train Epoch: 1445 [81920/90000 (91%)]	Loss: -18.4565	Cost: 11.24s
Train Epoch: 1445 	Average Loss: -18.0522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6693

Learning rate: 0.00019989697779050568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1446 [0/90000 (0%)]	Loss: -12.3384	Cost: 26.69s
Train Epoch: 1446 [20480/90000 (23%)]	Loss: -18.2793	Cost: 6.39s
Train Epoch: 1446 [40960/90000 (45%)]	Loss: -17.7847	Cost: 8.06s
Train Epoch: 1446 [61440/90000 (68%)]	Loss: -17.1835	Cost: 6.11s
Train Epoch: 1446 [81920/90000 (91%)]	Loss: -16.9432	Cost: 8.24s
Train Epoch: 1446 	Average Loss: -17.2957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3152

Learning rate: 0.0001998968351744036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1447 [0/90000 (0%)]	Loss: -10.6158	Cost: 23.93s
Train Epoch: 1447 [20480/90000 (23%)]	Loss: -17.3296	Cost: 6.09s
Train Epoch: 1447 [40960/90000 (45%)]	Loss: -16.9667	Cost: 7.98s
Train Epoch: 1447 [61440/90000 (68%)]	Loss: -17.9565	Cost: 6.00s
Train Epoch: 1447 [81920/90000 (91%)]	Loss: -18.2007	Cost: 6.34s
Train Epoch: 1447 	Average Loss: -17.0722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4713

Learning rate: 0.00019989669245970728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1448 [0/90000 (0%)]	Loss: -12.0634	Cost: 22.54s
Train Epoch: 1448 [20480/90000 (23%)]	Loss: -18.5290	Cost: 6.48s
Train Epoch: 1448 [40960/90000 (45%)]	Loss: -18.2079	Cost: 10.72s
Train Epoch: 1448 [61440/90000 (68%)]	Loss: -18.4211	Cost: 6.54s
Train Epoch: 1448 [81920/90000 (91%)]	Loss: -18.5570	Cost: 11.28s
Train Epoch: 1448 	Average Loss: -18.0528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6191

Learning rate: 0.00019989654964641687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1449 [0/90000 (0%)]	Loss: -11.6654	Cost: 26.62s
Train Epoch: 1449 [20480/90000 (23%)]	Loss: -18.7694	Cost: 6.43s
Train Epoch: 1449 [40960/90000 (45%)]	Loss: -18.4322	Cost: 8.94s
Train Epoch: 1449 [61440/90000 (68%)]	Loss: -18.3578	Cost: 5.96s
Train Epoch: 1449 [81920/90000 (91%)]	Loss: -18.4478	Cost: 7.93s
Train Epoch: 1449 	Average Loss: -18.1260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6099

Learning rate: 0.00019989640673453253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1450 [0/90000 (0%)]	Loss: -11.6702	Cost: 23.98s
Train Epoch: 1450 [20480/90000 (23%)]	Loss: -18.6085	Cost: 6.07s
Train Epoch: 1450 [40960/90000 (45%)]	Loss: -18.2431	Cost: 7.80s
Train Epoch: 1450 [61440/90000 (68%)]	Loss: -18.4169	Cost: 5.77s
Train Epoch: 1450 [81920/90000 (91%)]	Loss: -18.6678	Cost: 6.40s
Train Epoch: 1450 	Average Loss: -18.0756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6225

Learning rate: 0.0001998962637240544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1451 [0/90000 (0%)]	Loss: -12.2869	Cost: 22.65s
Train Epoch: 1451 [20480/90000 (23%)]	Loss: -18.9322	Cost: 6.02s
Train Epoch: 1451 [40960/90000 (45%)]	Loss: -18.2073	Cost: 8.63s
Train Epoch: 1451 [61440/90000 (68%)]	Loss: -18.3208	Cost: 6.18s
Train Epoch: 1451 [81920/90000 (91%)]	Loss: -18.5131	Cost: 11.36s
Train Epoch: 1451 	Average Loss: -18.0353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7431

Saving model as e1451_model.pt & e1451_waveforms_supplementary.hdf5
Learning rate: 0.0001998961206149826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1452 [0/90000 (0%)]	Loss: -12.3071	Cost: 28.22s
Train Epoch: 1452 [20480/90000 (23%)]	Loss: -18.4765	Cost: 6.33s
Train Epoch: 1452 [40960/90000 (45%)]	Loss: -16.6554	Cost: 10.14s
Train Epoch: 1452 [61440/90000 (68%)]	Loss: -16.7476	Cost: 5.76s
Train Epoch: 1452 [81920/90000 (91%)]	Loss: -17.4207	Cost: 6.52s
Train Epoch: 1452 	Average Loss: -17.1344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6159

Learning rate: 0.0001998959774073173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1453 [0/90000 (0%)]	Loss: -10.8250	Cost: 25.68s
Train Epoch: 1453 [20480/90000 (23%)]	Loss: -17.9327	Cost: 6.08s
Train Epoch: 1453 [40960/90000 (45%)]	Loss: -17.0616	Cost: 8.90s
Train Epoch: 1453 [61440/90000 (68%)]	Loss: -17.8590	Cost: 5.83s
Train Epoch: 1453 [81920/90000 (91%)]	Loss: -18.0374	Cost: 7.01s
Train Epoch: 1453 	Average Loss: -17.3063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3950

Learning rate: 0.0001998958341010586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1454 [0/90000 (0%)]	Loss: -11.8629	Cost: 22.61s
Train Epoch: 1454 [20480/90000 (23%)]	Loss: -18.5200	Cost: 6.07s
Train Epoch: 1454 [40960/90000 (45%)]	Loss: -17.9637	Cost: 7.77s
Train Epoch: 1454 [61440/90000 (68%)]	Loss: -18.5934	Cost: 6.29s
Train Epoch: 1454 [81920/90000 (91%)]	Loss: -18.6623	Cost: 11.60s
Train Epoch: 1454 	Average Loss: -18.0232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6692

Learning rate: 0.00019989569069620667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1455 [0/90000 (0%)]	Loss: -12.0251	Cost: 26.09s
Train Epoch: 1455 [20480/90000 (23%)]	Loss: -18.7786	Cost: 6.44s
Train Epoch: 1455 [40960/90000 (45%)]	Loss: -17.8356	Cost: 11.04s
Train Epoch: 1455 [61440/90000 (68%)]	Loss: -17.9775	Cost: 5.95s
Train Epoch: 1455 [81920/90000 (91%)]	Loss: -18.0055	Cost: 7.64s
Train Epoch: 1455 	Average Loss: -17.8103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3653

Learning rate: 0.00019989554719276168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1456 [0/90000 (0%)]	Loss: -11.2651	Cost: 27.50s
Train Epoch: 1456 [20480/90000 (23%)]	Loss: -18.4702	Cost: 6.25s
Train Epoch: 1456 [40960/90000 (45%)]	Loss: -18.1676	Cost: 8.05s
Train Epoch: 1456 [61440/90000 (68%)]	Loss: -18.4673	Cost: 6.04s
Train Epoch: 1456 [81920/90000 (91%)]	Loss: -18.5829	Cost: 8.37s
Train Epoch: 1456 	Average Loss: -17.9970
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6246

Learning rate: 0.0001998954035907237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1457 [0/90000 (0%)]	Loss: -12.6936	Cost: 24.06s
Train Epoch: 1457 [20480/90000 (23%)]	Loss: -18.6845	Cost: 6.05s
Train Epoch: 1457 [40960/90000 (45%)]	Loss: -17.7275	Cost: 7.21s
Train Epoch: 1457 [61440/90000 (68%)]	Loss: -18.3930	Cost: 5.79s
Train Epoch: 1457 [81920/90000 (91%)]	Loss: -18.3829	Cost: 6.49s
Train Epoch: 1457 	Average Loss: -17.9583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4835

Learning rate: 0.00019989525989009294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1458 [0/90000 (0%)]	Loss: -12.0606	Cost: 21.93s
Train Epoch: 1458 [20480/90000 (23%)]	Loss: -18.5334	Cost: 6.29s
Train Epoch: 1458 [40960/90000 (45%)]	Loss: -18.2358	Cost: 10.81s
Train Epoch: 1458 [61440/90000 (68%)]	Loss: -18.6088	Cost: 6.42s
Train Epoch: 1458 [81920/90000 (91%)]	Loss: -18.4167	Cost: 11.03s
Train Epoch: 1458 	Average Loss: -17.9832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4993

Learning rate: 0.00019989511609086946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1459 [0/90000 (0%)]	Loss: -11.6976	Cost: 27.21s
Train Epoch: 1459 [20480/90000 (23%)]	Loss: -18.3163	Cost: 6.33s
Train Epoch: 1459 [40960/90000 (45%)]	Loss: -18.1210	Cost: 9.58s
Train Epoch: 1459 [61440/90000 (68%)]	Loss: -18.6739	Cost: 6.03s
Train Epoch: 1459 [81920/90000 (91%)]	Loss: -18.7184	Cost: 6.81s
Train Epoch: 1459 	Average Loss: -18.1015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6191

Learning rate: 0.00019989497219305346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1460 [0/90000 (0%)]	Loss: -11.4044	Cost: 25.72s
Train Epoch: 1460 [20480/90000 (23%)]	Loss: -18.8305	Cost: 6.09s
Train Epoch: 1460 [40960/90000 (45%)]	Loss: -18.2018	Cost: 8.36s
Train Epoch: 1460 [61440/90000 (68%)]	Loss: -18.7494	Cost: 5.81s
Train Epoch: 1460 [81920/90000 (91%)]	Loss: -18.5213	Cost: 6.58s
Train Epoch: 1460 	Average Loss: -18.1478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3989

Learning rate: 0.0001998948281966451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1461 [0/90000 (0%)]	Loss: -10.8000	Cost: 22.79s
Train Epoch: 1461 [20480/90000 (23%)]	Loss: -16.5887	Cost: 6.08s
Train Epoch: 1461 [40960/90000 (45%)]	Loss: -16.2564	Cost: 8.74s
Train Epoch: 1461 [61440/90000 (68%)]	Loss: -17.0863	Cost: 6.45s
Train Epoch: 1461 [81920/90000 (91%)]	Loss: -17.4159	Cost: 11.52s
Train Epoch: 1461 	Average Loss: -16.4557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8156

Learning rate: 0.0001998946841016445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1462 [0/90000 (0%)]	Loss: -12.1893	Cost: 26.78s
Train Epoch: 1462 [20480/90000 (23%)]	Loss: -17.9507	Cost: 6.34s
Train Epoch: 1462 [40960/90000 (45%)]	Loss: -17.5468	Cost: 10.64s
Train Epoch: 1462 [61440/90000 (68%)]	Loss: -18.1320	Cost: 5.77s
Train Epoch: 1462 [81920/90000 (91%)]	Loss: -18.3665	Cost: 7.05s
Train Epoch: 1462 	Average Loss: -17.6105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6583

Learning rate: 0.0001998945399080518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1463 [0/90000 (0%)]	Loss: -11.6541	Cost: 26.75s
Train Epoch: 1463 [20480/90000 (23%)]	Loss: -18.6177	Cost: 6.11s
Train Epoch: 1463 [40960/90000 (45%)]	Loss: -17.9440	Cost: 7.55s
Train Epoch: 1463 [61440/90000 (68%)]	Loss: -18.4848	Cost: 6.21s
Train Epoch: 1463 [81920/90000 (91%)]	Loss: -18.6388	Cost: 8.62s
Train Epoch: 1463 	Average Loss: -18.0941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7578

Saving model as e1463_model.pt & e1463_waveforms_supplementary.hdf5
Learning rate: 0.0001998943956158671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1464 [0/90000 (0%)]	Loss: -12.1014	Cost: 23.36s
Train Epoch: 1464 [20480/90000 (23%)]	Loss: -18.8282	Cost: 6.13s
Train Epoch: 1464 [40960/90000 (45%)]	Loss: -17.4544	Cost: 6.96s
Train Epoch: 1464 [61440/90000 (68%)]	Loss: -18.1300	Cost: 6.11s
Train Epoch: 1464 [81920/90000 (91%)]	Loss: -17.7549	Cost: 9.50s
Train Epoch: 1464 	Average Loss: -17.7081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4176

Learning rate: 0.0001998942512250906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1465 [0/90000 (0%)]	Loss: -11.5980	Cost: 24.37s
Train Epoch: 1465 [20480/90000 (23%)]	Loss: -18.3755	Cost: 6.35s
Train Epoch: 1465 [40960/90000 (45%)]	Loss: -17.9572	Cost: 11.85s
Train Epoch: 1465 [61440/90000 (68%)]	Loss: -18.4072	Cost: 6.21s
Train Epoch: 1465 [81920/90000 (91%)]	Loss: -18.4802	Cost: 10.46s
Train Epoch: 1465 	Average Loss: -17.8710
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4964

Learning rate: 0.00019989410673572247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1466 [0/90000 (0%)]	Loss: -11.8579	Cost: 26.59s
Train Epoch: 1466 [20480/90000 (23%)]	Loss: -18.6461	Cost: 6.31s
Train Epoch: 1466 [40960/90000 (45%)]	Loss: -18.1100	Cost: 8.60s
Train Epoch: 1466 [61440/90000 (68%)]	Loss: -18.6649	Cost: 6.02s
Train Epoch: 1466 [81920/90000 (91%)]	Loss: -18.8572	Cost: 8.48s
Train Epoch: 1466 	Average Loss: -18.0901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7502

Learning rate: 0.00019989396214776275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1467 [0/90000 (0%)]	Loss: -12.6843	Cost: 23.80s
Train Epoch: 1467 [20480/90000 (23%)]	Loss: -18.9454	Cost: 6.09s
Train Epoch: 1467 [40960/90000 (45%)]	Loss: -18.4352	Cost: 8.05s
Train Epoch: 1467 [61440/90000 (68%)]	Loss: -18.7612	Cost: 5.75s
Train Epoch: 1467 [81920/90000 (91%)]	Loss: -18.8278	Cost: 6.26s
Train Epoch: 1467 	Average Loss: -18.3825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8106

Saving model as e1467_model.pt & e1467_waveforms_supplementary.hdf5
Learning rate: 0.00019989381746121168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1468 [0/90000 (0%)]	Loss: -12.1957	Cost: 22.28s
Train Epoch: 1468 [20480/90000 (23%)]	Loss: -18.6535	Cost: 6.37s
Train Epoch: 1468 [40960/90000 (45%)]	Loss: -18.1840	Cost: 9.42s
Train Epoch: 1468 [61440/90000 (68%)]	Loss: -18.5739	Cost: 6.27s
Train Epoch: 1468 [81920/90000 (91%)]	Loss: -18.4704	Cost: 11.31s
Train Epoch: 1468 	Average Loss: -18.1344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6690

Learning rate: 0.00019989367267606934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1469 [0/90000 (0%)]	Loss: -12.7257	Cost: 27.85s
Train Epoch: 1469 [20480/90000 (23%)]	Loss: -18.5761	Cost: 6.28s
Train Epoch: 1469 [40960/90000 (45%)]	Loss: -18.2847	Cost: 9.70s
Train Epoch: 1469 [61440/90000 (68%)]	Loss: -18.8905	Cost: 5.83s
Train Epoch: 1469 [81920/90000 (91%)]	Loss: -16.9968	Cost: 7.16s
Train Epoch: 1469 	Average Loss: -17.8912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2510

Learning rate: 0.00019989352779233594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1470 [0/90000 (0%)]	Loss: -11.0975	Cost: 24.85s
Train Epoch: 1470 [20480/90000 (23%)]	Loss: -17.5131	Cost: 6.05s
Train Epoch: 1470 [40960/90000 (45%)]	Loss: -17.2208	Cost: 8.63s
Train Epoch: 1470 [61440/90000 (68%)]	Loss: -18.0288	Cost: 5.82s
Train Epoch: 1470 [81920/90000 (91%)]	Loss: -18.3320	Cost: 6.04s
Train Epoch: 1470 	Average Loss: -17.2975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6185

Learning rate: 0.00019989338281001153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1471 [0/90000 (0%)]	Loss: -11.9104	Cost: 22.80s
Train Epoch: 1471 [20480/90000 (23%)]	Loss: -18.7130	Cost: 6.08s
Train Epoch: 1471 [40960/90000 (45%)]	Loss: -18.3999	Cost: 7.14s
Train Epoch: 1471 [61440/90000 (68%)]	Loss: -18.7593	Cost: 6.15s
Train Epoch: 1471 [81920/90000 (91%)]	Loss: -18.8341	Cost: 11.06s
Train Epoch: 1471 	Average Loss: -18.2659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8951

Saving model as e1471_model.pt & e1471_waveforms_supplementary.hdf5
Learning rate: 0.00019989323772909634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1472 [0/90000 (0%)]	Loss: -12.3322	Cost: 25.12s
Train Epoch: 1472 [20480/90000 (23%)]	Loss: -19.0389	Cost: 6.35s
Train Epoch: 1472 [40960/90000 (45%)]	Loss: -18.4507	Cost: 11.28s
Train Epoch: 1472 [61440/90000 (68%)]	Loss: -18.7008	Cost: 6.00s
Train Epoch: 1472 [81920/90000 (91%)]	Loss: -18.7512	Cost: 8.51s
Train Epoch: 1472 	Average Loss: -18.3438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8797

Learning rate: 0.00019989309254959045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1473 [0/90000 (0%)]	Loss: -11.6416	Cost: 26.71s
Train Epoch: 1473 [20480/90000 (23%)]	Loss: -18.9837	Cost: 6.14s
Train Epoch: 1473 [40960/90000 (45%)]	Loss: -18.0845	Cost: 7.99s
Train Epoch: 1473 [61440/90000 (68%)]	Loss: -18.7873	Cost: 5.96s
Train Epoch: 1473 [81920/90000 (91%)]	Loss: -18.6832	Cost: 8.10s
Train Epoch: 1473 	Average Loss: -18.2047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9158

Saving model as e1473_model.pt & e1473_waveforms_supplementary.hdf5
Learning rate: 0.000199892947271494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1474 [0/90000 (0%)]	Loss: -12.1222	Cost: 23.63s
Train Epoch: 1474 [20480/90000 (23%)]	Loss: -18.9467	Cost: 6.13s
Train Epoch: 1474 [40960/90000 (45%)]	Loss: -18.5388	Cost: 7.01s
Train Epoch: 1474 [61440/90000 (68%)]	Loss: -18.9637	Cost: 6.20s
Train Epoch: 1474 [81920/90000 (91%)]	Loss: -18.9532	Cost: 10.40s
Train Epoch: 1474 	Average Loss: -18.3494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9312

Saving model as e1474_model.pt & e1474_waveforms_supplementary.hdf5
Learning rate: 0.00019989280189480722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1475 [0/90000 (0%)]	Loss: -11.7494	Cost: 25.06s
Train Epoch: 1475 [20480/90000 (23%)]	Loss: -18.9711	Cost: 6.37s
Train Epoch: 1475 [40960/90000 (45%)]	Loss: -18.5165	Cost: 11.37s
Train Epoch: 1475 [61440/90000 (68%)]	Loss: -18.6583	Cost: 6.10s
Train Epoch: 1475 [81920/90000 (91%)]	Loss: -18.8050	Cost: 8.46s
Train Epoch: 1475 	Average Loss: -18.3797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9371

Saving model as e1475_model.pt & e1475_waveforms_supplementary.hdf5
Learning rate: 0.00019989265641953016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1476 [0/90000 (0%)]	Loss: -11.9989	Cost: 26.68s
Train Epoch: 1476 [20480/90000 (23%)]	Loss: -19.0497	Cost: 6.12s
Train Epoch: 1476 [40960/90000 (45%)]	Loss: -18.2980	Cost: 8.19s
Train Epoch: 1476 [61440/90000 (68%)]	Loss: -18.7877	Cost: 6.00s
Train Epoch: 1476 [81920/90000 (91%)]	Loss: -18.5282	Cost: 9.24s
Train Epoch: 1476 	Average Loss: -18.2813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7695

Learning rate: 0.000199892510845663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1477 [0/90000 (0%)]	Loss: -12.1761	Cost: 23.40s
Train Epoch: 1477 [20480/90000 (23%)]	Loss: -18.8850	Cost: 6.21s
Train Epoch: 1477 [40960/90000 (45%)]	Loss: -18.4159	Cost: 7.39s
Train Epoch: 1477 [61440/90000 (68%)]	Loss: -18.8060	Cost: 6.24s
Train Epoch: 1477 [81920/90000 (91%)]	Loss: -18.5931	Cost: 6.17s
Train Epoch: 1477 	Average Loss: -18.2968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8641

Learning rate: 0.00019989236517320593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1478 [0/90000 (0%)]	Loss: -12.4440	Cost: 22.08s
Train Epoch: 1478 [20480/90000 (23%)]	Loss: -18.8896	Cost: 6.50s
Train Epoch: 1478 [40960/90000 (45%)]	Loss: -18.4817	Cost: 10.86s
Train Epoch: 1478 [61440/90000 (68%)]	Loss: -18.9528	Cost: 6.32s
Train Epoch: 1478 [81920/90000 (91%)]	Loss: -18.6438	Cost: 11.39s
Train Epoch: 1478 	Average Loss: -18.3449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9799

Saving model as e1478_model.pt & e1478_waveforms_supplementary.hdf5
Learning rate: 0.000199892219402159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1479 [0/90000 (0%)]	Loss: -11.6438	Cost: 26.90s
Train Epoch: 1479 [20480/90000 (23%)]	Loss: -18.7832	Cost: 6.31s
Train Epoch: 1479 [40960/90000 (45%)]	Loss: -18.3878	Cost: 8.82s
Train Epoch: 1479 [61440/90000 (68%)]	Loss: -18.6857	Cost: 5.95s
Train Epoch: 1479 [81920/90000 (91%)]	Loss: -18.7458	Cost: 7.55s
Train Epoch: 1479 	Average Loss: -18.2477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6517

Learning rate: 0.0001998920735325224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1480 [0/90000 (0%)]	Loss: -12.7155	Cost: 24.50s
Train Epoch: 1480 [20480/90000 (23%)]	Loss: -18.6483	Cost: 6.07s
Train Epoch: 1480 [40960/90000 (45%)]	Loss: -18.2208	Cost: 8.50s
Train Epoch: 1480 [61440/90000 (68%)]	Loss: -18.8020	Cost: 5.78s
Train Epoch: 1480 [81920/90000 (91%)]	Loss: -18.8824	Cost: 6.18s
Train Epoch: 1480 	Average Loss: -18.2916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0216

Saving model as e1480_model.pt & e1480_waveforms_supplementary.hdf5
Learning rate: 0.0001998919275642963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1481 [0/90000 (0%)]	Loss: -12.3547	Cost: 22.47s
Train Epoch: 1481 [20480/90000 (23%)]	Loss: -18.6066	Cost: 6.19s
Train Epoch: 1481 [40960/90000 (45%)]	Loss: -17.9717	Cost: 9.39s
Train Epoch: 1481 [61440/90000 (68%)]	Loss: -18.6668	Cost: 6.30s
Train Epoch: 1481 [81920/90000 (91%)]	Loss: -18.9856	Cost: 11.42s
Train Epoch: 1481 	Average Loss: -18.2061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9009

Learning rate: 0.0001998917814974808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1482 [0/90000 (0%)]	Loss: -11.8568	Cost: 27.07s
Train Epoch: 1482 [20480/90000 (23%)]	Loss: -18.7918	Cost: 6.38s
Train Epoch: 1482 [40960/90000 (45%)]	Loss: -18.3549	Cost: 10.48s
Train Epoch: 1482 [61440/90000 (68%)]	Loss: -18.9146	Cost: 5.74s
Train Epoch: 1482 [81920/90000 (91%)]	Loss: -18.9054	Cost: 6.66s
Train Epoch: 1482 	Average Loss: -18.3766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9777

Learning rate: 0.00019989163533207604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1483 [0/90000 (0%)]	Loss: -11.5384	Cost: 26.69s
Train Epoch: 1483 [20480/90000 (23%)]	Loss: -18.8013	Cost: 6.02s
Train Epoch: 1483 [40960/90000 (45%)]	Loss: -18.3728	Cost: 7.42s
Train Epoch: 1483 [61440/90000 (68%)]	Loss: -18.7724	Cost: 6.01s
Train Epoch: 1483 [81920/90000 (91%)]	Loss: -18.7902	Cost: 8.42s
Train Epoch: 1483 	Average Loss: -18.2226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9892

Learning rate: 0.00019989148906808223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1484 [0/90000 (0%)]	Loss: -12.0425	Cost: 24.00s
Train Epoch: 1484 [20480/90000 (23%)]	Loss: -18.9527	Cost: 6.07s
Train Epoch: 1484 [40960/90000 (45%)]	Loss: -18.4224	Cost: 7.81s
Train Epoch: 1484 [61440/90000 (68%)]	Loss: -18.7731	Cost: 5.89s
Train Epoch: 1484 [81920/90000 (91%)]	Loss: -18.8210	Cost: 6.48s
Train Epoch: 1484 	Average Loss: -18.3731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0025

Learning rate: 0.00019989134270549948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1485 [0/90000 (0%)]	Loss: -12.7733	Cost: 22.56s
Train Epoch: 1485 [20480/90000 (23%)]	Loss: -19.0293	Cost: 6.28s
Train Epoch: 1485 [40960/90000 (45%)]	Loss: -18.5104	Cost: 10.59s
Train Epoch: 1485 [61440/90000 (68%)]	Loss: -18.8600	Cost: 6.31s
Train Epoch: 1485 [81920/90000 (91%)]	Loss: -18.9466	Cost: 11.22s
Train Epoch: 1485 	Average Loss: -18.4713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9882

Learning rate: 0.0001998911962443279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1486 [0/90000 (0%)]	Loss: -12.4638	Cost: 27.64s
Train Epoch: 1486 [20480/90000 (23%)]	Loss: -19.1471	Cost: 6.36s
Train Epoch: 1486 [40960/90000 (45%)]	Loss: -18.5306	Cost: 9.84s
Train Epoch: 1486 [61440/90000 (68%)]	Loss: -18.8277	Cost: 6.01s
Train Epoch: 1486 [81920/90000 (91%)]	Loss: -18.9652	Cost: 7.34s
Train Epoch: 1486 	Average Loss: -18.4294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1340

Saving model as e1486_model.pt & e1486_waveforms_supplementary.hdf5
Learning rate: 0.00019989104968456769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1487 [0/90000 (0%)]	Loss: -12.0067	Cost: 24.38s
Train Epoch: 1487 [20480/90000 (23%)]	Loss: -18.6044	Cost: 6.07s
Train Epoch: 1487 [40960/90000 (45%)]	Loss: -18.1253	Cost: 8.49s
Train Epoch: 1487 [61440/90000 (68%)]	Loss: -18.8332	Cost: 5.74s
Train Epoch: 1487 [81920/90000 (91%)]	Loss: -18.9597	Cost: 6.18s
Train Epoch: 1487 	Average Loss: -18.2257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9966

Learning rate: 0.00019989090302621897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1488 [0/90000 (0%)]	Loss: -12.2574	Cost: 23.63s
Train Epoch: 1488 [20480/90000 (23%)]	Loss: -19.0336	Cost: 6.04s
Train Epoch: 1488 [40960/90000 (45%)]	Loss: -18.5195	Cost: 7.82s
Train Epoch: 1488 [61440/90000 (68%)]	Loss: -19.1416	Cost: 6.14s
Train Epoch: 1488 [81920/90000 (91%)]	Loss: -18.9581	Cost: 11.94s
Train Epoch: 1488 	Average Loss: -18.4768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2008

Saving model as e1488_model.pt & e1488_waveforms_supplementary.hdf5
Learning rate: 0.00019989075626928183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1489 [0/90000 (0%)]	Loss: -13.1432	Cost: 25.57s
Train Epoch: 1489 [20480/90000 (23%)]	Loss: -19.2589	Cost: 6.36s
Train Epoch: 1489 [40960/90000 (45%)]	Loss: -18.7628	Cost: 10.57s
Train Epoch: 1489 [61440/90000 (68%)]	Loss: -18.7798	Cost: 5.84s
Train Epoch: 1489 [81920/90000 (91%)]	Loss: -18.5402	Cost: 7.00s
Train Epoch: 1489 	Average Loss: -18.5278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0431

Learning rate: 0.00019989060941375648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1490 [0/90000 (0%)]	Loss: -12.7375	Cost: 27.21s
Train Epoch: 1490 [20480/90000 (23%)]	Loss: -19.0252	Cost: 6.11s
Train Epoch: 1490 [40960/90000 (45%)]	Loss: -18.5397	Cost: 7.29s
Train Epoch: 1490 [61440/90000 (68%)]	Loss: -18.7852	Cost: 6.05s
Train Epoch: 1490 [81920/90000 (91%)]	Loss: -18.6383	Cost: 8.76s
Train Epoch: 1490 	Average Loss: -18.3696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9898

Learning rate: 0.00019989046245964308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1491 [0/90000 (0%)]	Loss: -13.0429	Cost: 25.48s
Train Epoch: 1491 [20480/90000 (23%)]	Loss: -19.0313	Cost: 6.07s
Train Epoch: 1491 [40960/90000 (45%)]	Loss: -18.7731	Cost: 6.87s
Train Epoch: 1491 [61440/90000 (68%)]	Loss: -19.1869	Cost: 5.80s
Train Epoch: 1491 [81920/90000 (91%)]	Loss: -19.1311	Cost: 7.10s
Train Epoch: 1491 	Average Loss: -18.6179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1364

Learning rate: 0.00019989031540694173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1492 [0/90000 (0%)]	Loss: -12.8021	Cost: 22.26s
Train Epoch: 1492 [20480/90000 (23%)]	Loss: -19.4810	Cost: 6.25s
Train Epoch: 1492 [40960/90000 (45%)]	Loss: -18.6177	Cost: 10.82s
Train Epoch: 1492 [61440/90000 (68%)]	Loss: -19.1534	Cost: 6.44s
Train Epoch: 1492 [81920/90000 (91%)]	Loss: -19.1896	Cost: 11.22s
Train Epoch: 1492 	Average Loss: -18.7145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1784

Learning rate: 0.0001998901682556526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1493 [0/90000 (0%)]	Loss: -11.8819	Cost: 26.74s
Train Epoch: 1493 [20480/90000 (23%)]	Loss: -19.2865	Cost: 6.31s
Train Epoch: 1493 [40960/90000 (45%)]	Loss: -18.0307	Cost: 9.41s
Train Epoch: 1493 [61440/90000 (68%)]	Loss: -18.5903	Cost: 5.93s
Train Epoch: 1493 [81920/90000 (91%)]	Loss: -18.6958	Cost: 6.96s
Train Epoch: 1493 	Average Loss: -18.2815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9589

Learning rate: 0.00019989002100577577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1494 [0/90000 (0%)]	Loss: -12.6870	Cost: 23.69s
Train Epoch: 1494 [20480/90000 (23%)]	Loss: -19.0488	Cost: 6.06s
Train Epoch: 1494 [40960/90000 (45%)]	Loss: -18.4960	Cost: 8.50s
Train Epoch: 1494 [61440/90000 (68%)]	Loss: -19.0405	Cost: 5.75s
Train Epoch: 1494 [81920/90000 (91%)]	Loss: -19.0523	Cost: 6.50s
Train Epoch: 1494 	Average Loss: -18.4573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2092

Saving model as e1494_model.pt & e1494_waveforms_supplementary.hdf5
Learning rate: 0.0001998898736573115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1495 [0/90000 (0%)]	Loss: -12.6045	Cost: 22.86s
Train Epoch: 1495 [20480/90000 (23%)]	Loss: -19.2997	Cost: 6.02s
Train Epoch: 1495 [40960/90000 (45%)]	Loss: -18.9147	Cost: 8.84s
Train Epoch: 1495 [61440/90000 (68%)]	Loss: -19.0085	Cost: 6.18s
Train Epoch: 1495 [81920/90000 (91%)]	Loss: -19.2856	Cost: 11.20s
Train Epoch: 1495 	Average Loss: -18.6575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3042

Saving model as e1495_model.pt & e1495_waveforms_supplementary.hdf5
Learning rate: 0.00019988972621025987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1496 [0/90000 (0%)]	Loss: -11.7584	Cost: 27.28s
Train Epoch: 1496 [20480/90000 (23%)]	Loss: -19.2907	Cost: 6.31s
Train Epoch: 1496 [40960/90000 (45%)]	Loss: -18.5336	Cost: 10.24s
Train Epoch: 1496 [61440/90000 (68%)]	Loss: -18.9472	Cost: 5.71s
Train Epoch: 1496 [81920/90000 (91%)]	Loss: -19.0725	Cost: 6.40s
Train Epoch: 1496 	Average Loss: -18.5347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1848

Learning rate: 0.00019988957866462102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1497 [0/90000 (0%)]	Loss: -12.7595	Cost: 26.69s
Train Epoch: 1497 [20480/90000 (23%)]	Loss: -19.3795	Cost: 6.12s
Train Epoch: 1497 [40960/90000 (45%)]	Loss: -18.6169	Cost: 7.12s
Train Epoch: 1497 [61440/90000 (68%)]	Loss: -18.8395	Cost: 6.02s
Train Epoch: 1497 [81920/90000 (91%)]	Loss: -19.2007	Cost: 7.95s
Train Epoch: 1497 	Average Loss: -18.6457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8397

Learning rate: 0.00019988943102039513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1498 [0/90000 (0%)]	Loss: -11.8881	Cost: 23.82s
Train Epoch: 1498 [20480/90000 (23%)]	Loss: -17.6847	Cost: 6.11s
Train Epoch: 1498 [40960/90000 (45%)]	Loss: -17.3368	Cost: 7.74s
Train Epoch: 1498 [61440/90000 (68%)]	Loss: -17.8838	Cost: 5.91s
Train Epoch: 1498 [81920/90000 (91%)]	Loss: -18.2733	Cost: 7.60s
Train Epoch: 1498 	Average Loss: -17.3806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5597

Learning rate: 0.0001998892832775823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1499 [0/90000 (0%)]	Loss: -12.5205	Cost: 22.12s
Train Epoch: 1499 [20480/90000 (23%)]	Loss: -18.6274	Cost: 6.54s
Train Epoch: 1499 [40960/90000 (45%)]	Loss: -18.5149	Cost: 10.91s
Train Epoch: 1499 [61440/90000 (68%)]	Loss: -18.8754	Cost: 6.30s
Train Epoch: 1499 [81920/90000 (91%)]	Loss: -19.1183	Cost: 11.21s
Train Epoch: 1499 	Average Loss: -18.3131
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0750

Learning rate: 0.0001998891354361827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1500 [0/90000 (0%)]	Loss: -13.3746	Cost: 27.29s
Train Epoch: 1500 [20480/90000 (23%)]	Loss: -19.1238	Cost: 6.24s
Train Epoch: 1500 [40960/90000 (45%)]	Loss: -18.4968	Cost: 9.27s
Train Epoch: 1500 [61440/90000 (68%)]	Loss: -18.8620	Cost: 5.97s
Train Epoch: 1500 [81920/90000 (91%)]	Loss: -18.8314	Cost: 7.80s
Train Epoch: 1500 	Average Loss: -18.4673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1451

Learning rate: 0.00019988898749619648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1501 [0/90000 (0%)]	Loss: -11.9527	Cost: 24.65s
Train Epoch: 1501 [20480/90000 (23%)]	Loss: -19.3802	Cost: 6.08s
Train Epoch: 1501 [40960/90000 (45%)]	Loss: -18.4459	Cost: 7.97s
Train Epoch: 1501 [61440/90000 (68%)]	Loss: -18.9672	Cost: 5.96s
Train Epoch: 1501 [81920/90000 (91%)]	Loss: -19.0702	Cost: 6.01s
Train Epoch: 1501 	Average Loss: -18.5265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7991

Learning rate: 0.00019988883945762376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1502 [0/90000 (0%)]	Loss: -10.7372	Cost: 22.71s
Train Epoch: 1502 [20480/90000 (23%)]	Loss: -16.7276	Cost: 6.15s
Train Epoch: 1502 [40960/90000 (45%)]	Loss: -16.7053	Cost: 9.72s
Train Epoch: 1502 [61440/90000 (68%)]	Loss: -17.4597	Cost: 6.27s
Train Epoch: 1502 [81920/90000 (91%)]	Loss: -18.1927	Cost: 11.10s
Train Epoch: 1502 	Average Loss: -16.8009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4865

Learning rate: 0.00019988869132046472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1503 [0/90000 (0%)]	Loss: -11.8794	Cost: 26.06s
Train Epoch: 1503 [20480/90000 (23%)]	Loss: -18.7641	Cost: 6.40s
Train Epoch: 1503 [40960/90000 (45%)]	Loss: -18.3689	Cost: 10.37s
Train Epoch: 1503 [61440/90000 (68%)]	Loss: -18.9569	Cost: 5.77s
Train Epoch: 1503 [81920/90000 (91%)]	Loss: -18.9724	Cost: 6.83s
Train Epoch: 1503 	Average Loss: -18.2972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0832

Learning rate: 0.0001998885430847195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1504 [0/90000 (0%)]	Loss: -13.2753	Cost: 25.78s
Train Epoch: 1504 [20480/90000 (23%)]	Loss: -19.0443	Cost: 6.11s
Train Epoch: 1504 [40960/90000 (45%)]	Loss: -18.5394	Cost: 7.66s
Train Epoch: 1504 [61440/90000 (68%)]	Loss: -19.1787	Cost: 6.13s
Train Epoch: 1504 [81920/90000 (91%)]	Loss: -19.0707	Cost: 6.76s
Train Epoch: 1504 	Average Loss: -18.5619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9163

Learning rate: 0.00019988839475038826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1505 [0/90000 (0%)]	Loss: -12.6698	Cost: 23.79s
Train Epoch: 1505 [20480/90000 (23%)]	Loss: -19.1725	Cost: 6.07s
Train Epoch: 1505 [40960/90000 (45%)]	Loss: -18.5850	Cost: 7.02s
Train Epoch: 1505 [61440/90000 (68%)]	Loss: -19.0877	Cost: 6.14s
Train Epoch: 1505 [81920/90000 (91%)]	Loss: -19.1431	Cost: 9.19s
Train Epoch: 1505 	Average Loss: -18.5948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1876

Learning rate: 0.0001998882463174711
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1506 [0/90000 (0%)]	Loss: -12.5357	Cost: 23.62s
Train Epoch: 1506 [20480/90000 (23%)]	Loss: -19.1641	Cost: 6.16s
Train Epoch: 1506 [40960/90000 (45%)]	Loss: -18.6458	Cost: 11.32s
Train Epoch: 1506 [61440/90000 (68%)]	Loss: -19.0447	Cost: 6.36s
Train Epoch: 1506 [81920/90000 (91%)]	Loss: -19.0866	Cost: 10.53s
Train Epoch: 1506 	Average Loss: -18.5855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8534

Learning rate: 0.00019988809778596821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1507 [0/90000 (0%)]	Loss: -12.1556	Cost: 26.70s
Train Epoch: 1507 [20480/90000 (23%)]	Loss: -19.1054	Cost: 6.12s
Train Epoch: 1507 [40960/90000 (45%)]	Loss: -18.6584	Cost: 8.96s
Train Epoch: 1507 [61440/90000 (68%)]	Loss: -19.1249	Cost: 5.90s
Train Epoch: 1507 [81920/90000 (91%)]	Loss: -18.8664	Cost: 9.03s
Train Epoch: 1507 	Average Loss: -18.4743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0139

Learning rate: 0.00019988794915587973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1508 [0/90000 (0%)]	Loss: -13.1865	Cost: 23.44s
Train Epoch: 1508 [20480/90000 (23%)]	Loss: -19.2186	Cost: 6.09s
Train Epoch: 1508 [40960/90000 (45%)]	Loss: -18.7177	Cost: 8.05s
Train Epoch: 1508 [61440/90000 (68%)]	Loss: -19.3182	Cost: 5.88s
Train Epoch: 1508 [81920/90000 (91%)]	Loss: -19.2981	Cost: 6.58s
Train Epoch: 1508 	Average Loss: -18.7135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1689

Learning rate: 0.00019988780042720576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1509 [0/90000 (0%)]	Loss: -12.6696	Cost: 23.60s
Train Epoch: 1509 [20480/90000 (23%)]	Loss: -19.4366	Cost: 6.24s
Train Epoch: 1509 [40960/90000 (45%)]	Loss: -18.8908	Cost: 11.01s
Train Epoch: 1509 [61440/90000 (68%)]	Loss: -19.1701	Cost: 6.34s
Train Epoch: 1509 [81920/90000 (91%)]	Loss: -19.2003	Cost: 11.76s
Train Epoch: 1509 	Average Loss: -18.6851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1066

Learning rate: 0.0001998876515999465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1510 [0/90000 (0%)]	Loss: -11.7964	Cost: 28.24s
Train Epoch: 1510 [20480/90000 (23%)]	Loss: -19.2416	Cost: 6.35s
Train Epoch: 1510 [40960/90000 (45%)]	Loss: -18.1649	Cost: 9.31s
Train Epoch: 1510 [61440/90000 (68%)]	Loss: -18.5264	Cost: 6.07s
Train Epoch: 1510 [81920/90000 (91%)]	Loss: -18.8387	Cost: 6.84s
Train Epoch: 1510 	Average Loss: -18.3434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9368

Learning rate: 0.00019988750267410207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1511 [0/90000 (0%)]	Loss: -12.4661	Cost: 23.75s
Train Epoch: 1511 [20480/90000 (23%)]	Loss: -19.1214	Cost: 6.08s
Train Epoch: 1511 [40960/90000 (45%)]	Loss: -18.5334	Cost: 8.89s
Train Epoch: 1511 [61440/90000 (68%)]	Loss: -18.9873	Cost: 5.93s
Train Epoch: 1511 [81920/90000 (91%)]	Loss: -19.0502	Cost: 6.04s
Train Epoch: 1511 	Average Loss: -18.4923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1033

Learning rate: 0.0001998873536496726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1512 [0/90000 (0%)]	Loss: -11.9048	Cost: 23.07s
Train Epoch: 1512 [20480/90000 (23%)]	Loss: -19.2965	Cost: 6.03s
Train Epoch: 1512 [40960/90000 (45%)]	Loss: -18.7960	Cost: 7.26s
Train Epoch: 1512 [61440/90000 (68%)]	Loss: -19.1287	Cost: 6.39s
Train Epoch: 1512 [81920/90000 (91%)]	Loss: -19.1027	Cost: 11.23s
Train Epoch: 1512 	Average Loss: -18.7145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1989

Learning rate: 0.00019988720452665832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1513 [0/90000 (0%)]	Loss: -12.9431	Cost: 25.21s
Train Epoch: 1513 [20480/90000 (23%)]	Loss: -19.3898	Cost: 6.41s
Train Epoch: 1513 [40960/90000 (45%)]	Loss: -18.9460	Cost: 10.82s
Train Epoch: 1513 [61440/90000 (68%)]	Loss: -19.0865	Cost: 6.19s
Train Epoch: 1513 [81920/90000 (91%)]	Loss: -19.0873	Cost: 8.35s
Train Epoch: 1513 	Average Loss: -18.7453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0708

Learning rate: 0.0001998870553050593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1514 [0/90000 (0%)]	Loss: -12.6262	Cost: 26.47s
Train Epoch: 1514 [20480/90000 (23%)]	Loss: -19.3774	Cost: 6.22s
Train Epoch: 1514 [40960/90000 (45%)]	Loss: -18.7573	Cost: 8.45s
Train Epoch: 1514 [61440/90000 (68%)]	Loss: -18.9377	Cost: 6.13s
Train Epoch: 1514 [81920/90000 (91%)]	Loss: -18.6484	Cost: 8.53s
Train Epoch: 1514 	Average Loss: -18.6114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7779

Learning rate: 0.0001998869059848757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1515 [0/90000 (0%)]	Loss: -12.6658	Cost: 23.96s
Train Epoch: 1515 [20480/90000 (23%)]	Loss: -18.7398	Cost: 6.11s
Train Epoch: 1515 [40960/90000 (45%)]	Loss: -18.3566	Cost: 7.39s
Train Epoch: 1515 [61440/90000 (68%)]	Loss: -18.8097	Cost: 5.78s
Train Epoch: 1515 [81920/90000 (91%)]	Loss: -19.0553	Cost: 6.18s
Train Epoch: 1515 	Average Loss: -18.3751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1603

Learning rate: 0.00019988675656610767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1516 [0/90000 (0%)]	Loss: -11.6934	Cost: 22.16s
Train Epoch: 1516 [20480/90000 (23%)]	Loss: -19.4680	Cost: 6.49s
Train Epoch: 1516 [40960/90000 (45%)]	Loss: -18.8916	Cost: 10.78s
Train Epoch: 1516 [61440/90000 (68%)]	Loss: -19.1461	Cost: 6.55s
Train Epoch: 1516 [81920/90000 (91%)]	Loss: -19.3319	Cost: 11.12s
Train Epoch: 1516 	Average Loss: -18.6885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9274

Learning rate: 0.00019988660704875537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1517 [0/90000 (0%)]	Loss: -12.5657	Cost: 27.91s
Train Epoch: 1517 [20480/90000 (23%)]	Loss: -18.8150	Cost: 6.52s
Train Epoch: 1517 [40960/90000 (45%)]	Loss: -18.5366	Cost: 9.32s
Train Epoch: 1517 [61440/90000 (68%)]	Loss: -18.8889	Cost: 5.85s
Train Epoch: 1517 [81920/90000 (91%)]	Loss: -19.0868	Cost: 7.03s
Train Epoch: 1517 	Average Loss: -18.3709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3540

Saving model as e1517_model.pt & e1517_waveforms_supplementary.hdf5
Learning rate: 0.00019988645743281895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1518 [0/90000 (0%)]	Loss: -11.3038	Cost: 25.08s
Train Epoch: 1518 [20480/90000 (23%)]	Loss: -19.3459	Cost: 6.05s
Train Epoch: 1518 [40960/90000 (45%)]	Loss: -19.0938	Cost: 8.33s
Train Epoch: 1518 [61440/90000 (68%)]	Loss: -19.4112	Cost: 5.73s
Train Epoch: 1518 [81920/90000 (91%)]	Loss: -19.3924	Cost: 5.90s
Train Epoch: 1518 	Average Loss: -18.7992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2855

Learning rate: 0.00019988630771829852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1519 [0/90000 (0%)]	Loss: -12.8836	Cost: 22.93s
Train Epoch: 1519 [20480/90000 (23%)]	Loss: -19.2054	Cost: 5.99s
Train Epoch: 1519 [40960/90000 (45%)]	Loss: -18.5482	Cost: 8.32s
Train Epoch: 1519 [61440/90000 (68%)]	Loss: -18.8895	Cost: 6.18s
Train Epoch: 1519 [81920/90000 (91%)]	Loss: -18.7919	Cost: 11.94s
Train Epoch: 1519 	Average Loss: -18.5398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1437

Learning rate: 0.00019988615790519427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1520 [0/90000 (0%)]	Loss: -13.1411	Cost: 27.60s
Train Epoch: 1520 [20480/90000 (23%)]	Loss: -18.8466	Cost: 6.39s
Train Epoch: 1520 [40960/90000 (45%)]	Loss: -18.3891	Cost: 10.46s
Train Epoch: 1520 [61440/90000 (68%)]	Loss: -18.8609	Cost: 5.75s
Train Epoch: 1520 [81920/90000 (91%)]	Loss: -18.9852	Cost: 7.32s
Train Epoch: 1520 	Average Loss: -18.3934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2163

Learning rate: 0.0001998860079935063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1521 [0/90000 (0%)]	Loss: -11.5843	Cost: 26.15s
Train Epoch: 1521 [20480/90000 (23%)]	Loss: -19.3323	Cost: 6.10s
Train Epoch: 1521 [40960/90000 (45%)]	Loss: -18.7476	Cost: 6.95s
Train Epoch: 1521 [61440/90000 (68%)]	Loss: -19.0473	Cost: 6.00s
Train Epoch: 1521 [81920/90000 (91%)]	Loss: -18.8542	Cost: 7.92s
Train Epoch: 1521 	Average Loss: -18.5651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0414

Learning rate: 0.00019988585798323488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1522 [0/90000 (0%)]	Loss: -12.6036	Cost: 23.57s
Train Epoch: 1522 [20480/90000 (23%)]	Loss: -19.1066	Cost: 6.10s
Train Epoch: 1522 [40960/90000 (45%)]	Loss: -18.7978	Cost: 7.36s
Train Epoch: 1522 [61440/90000 (68%)]	Loss: -19.3063	Cost: 6.18s
Train Epoch: 1522 [81920/90000 (91%)]	Loss: -19.3871	Cost: 6.17s
Train Epoch: 1522 	Average Loss: -18.7368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3662

Saving model as e1522_model.pt & e1522_waveforms_supplementary.hdf5
Learning rate: 0.00019988570787438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1523 [0/90000 (0%)]	Loss: -12.0400	Cost: 22.36s
Train Epoch: 1523 [20480/90000 (23%)]	Loss: -19.4729	Cost: 6.33s
Train Epoch: 1523 [40960/90000 (45%)]	Loss: -18.9605	Cost: 11.37s
Train Epoch: 1523 [61440/90000 (68%)]	Loss: -17.8309	Cost: 6.40s
Train Epoch: 1523 [81920/90000 (91%)]	Loss: -17.8298	Cost: 11.18s
Train Epoch: 1523 	Average Loss: -18.1628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1114

Learning rate: 0.00019988555766694188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1524 [0/90000 (0%)]	Loss: -11.0813	Cost: 26.78s
Train Epoch: 1524 [20480/90000 (23%)]	Loss: -18.3751	Cost: 6.31s
Train Epoch: 1524 [40960/90000 (45%)]	Loss: -18.2610	Cost: 7.98s
Train Epoch: 1524 [61440/90000 (68%)]	Loss: -18.7494	Cost: 6.01s
Train Epoch: 1524 [81920/90000 (91%)]	Loss: -18.6327	Cost: 8.47s
Train Epoch: 1524 	Average Loss: -18.0585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8359

Learning rate: 0.00019988540736092067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1525 [0/90000 (0%)]	Loss: -11.8610	Cost: 23.47s
Train Epoch: 1525 [20480/90000 (23%)]	Loss: -19.1395	Cost: 6.14s
Train Epoch: 1525 [40960/90000 (45%)]	Loss: -18.8568	Cost: 7.99s
Train Epoch: 1525 [61440/90000 (68%)]	Loss: -19.3083	Cost: 5.74s
Train Epoch: 1525 [81920/90000 (91%)]	Loss: -19.3191	Cost: 6.68s
Train Epoch: 1525 	Average Loss: -18.6942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3500

Learning rate: 0.0001998852569563165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1526 [0/90000 (0%)]	Loss: -11.8399	Cost: 22.70s
Train Epoch: 1526 [20480/90000 (23%)]	Loss: -19.2178	Cost: 6.28s
Train Epoch: 1526 [40960/90000 (45%)]	Loss: -18.5269	Cost: 11.73s
Train Epoch: 1526 [61440/90000 (68%)]	Loss: -19.1156	Cost: 6.36s
Train Epoch: 1526 [81920/90000 (91%)]	Loss: -19.1453	Cost: 11.07s
Train Epoch: 1526 	Average Loss: -18.6101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0872

Learning rate: 0.00019988510645312958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1527 [0/90000 (0%)]	Loss: -12.5467	Cost: 27.55s
Train Epoch: 1527 [20480/90000 (23%)]	Loss: -18.8211	Cost: 6.25s
Train Epoch: 1527 [40960/90000 (45%)]	Loss: -18.2700	Cost: 9.90s
Train Epoch: 1527 [61440/90000 (68%)]	Loss: -18.8454	Cost: 5.87s
Train Epoch: 1527 [81920/90000 (91%)]	Loss: -18.9711	Cost: 6.18s
Train Epoch: 1527 	Average Loss: -18.3770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1602

Learning rate: 0.00019988495585136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1528 [0/90000 (0%)]	Loss: -12.6935	Cost: 26.12s
Train Epoch: 1528 [20480/90000 (23%)]	Loss: -19.4379	Cost: 6.11s
Train Epoch: 1528 [40960/90000 (45%)]	Loss: -18.9498	Cost: 7.75s
Train Epoch: 1528 [61440/90000 (68%)]	Loss: -19.2628	Cost: 5.97s
Train Epoch: 1528 [81920/90000 (91%)]	Loss: -19.3014	Cost: 6.86s
Train Epoch: 1528 	Average Loss: -18.8179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2816

Learning rate: 0.00019988480515100793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1529 [0/90000 (0%)]	Loss: -12.5815	Cost: 23.08s
Train Epoch: 1529 [20480/90000 (23%)]	Loss: -19.5127	Cost: 6.06s
Train Epoch: 1529 [40960/90000 (45%)]	Loss: -18.8006	Cost: 7.87s
Train Epoch: 1529 [61440/90000 (68%)]	Loss: -19.1769	Cost: 6.24s
Train Epoch: 1529 [81920/90000 (91%)]	Loss: -19.1714	Cost: 9.47s
Train Epoch: 1529 	Average Loss: -18.7573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2309

Learning rate: 0.0001998846543520735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1530 [0/90000 (0%)]	Loss: -12.1799	Cost: 23.29s
Train Epoch: 1530 [20480/90000 (23%)]	Loss: -19.4023	Cost: 6.24s
Train Epoch: 1530 [40960/90000 (45%)]	Loss: -18.8119	Cost: 11.98s
Train Epoch: 1530 [61440/90000 (68%)]	Loss: -19.3626	Cost: 6.21s
Train Epoch: 1530 [81920/90000 (91%)]	Loss: -19.2963	Cost: 10.83s
Train Epoch: 1530 	Average Loss: -18.7294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2464

Learning rate: 0.00019988450345455685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1531 [0/90000 (0%)]	Loss: -12.5558	Cost: 26.78s
Train Epoch: 1531 [20480/90000 (23%)]	Loss: -19.4786	Cost: 6.20s
Train Epoch: 1531 [40960/90000 (45%)]	Loss: -18.9464	Cost: 8.82s
Train Epoch: 1531 [61440/90000 (68%)]	Loss: -19.4139	Cost: 5.96s
Train Epoch: 1531 [81920/90000 (91%)]	Loss: -19.1230	Cost: 8.80s
Train Epoch: 1531 	Average Loss: -18.8494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2564

Learning rate: 0.00019988435245845814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1532 [0/90000 (0%)]	Loss: -13.2706	Cost: 23.89s
Train Epoch: 1532 [20480/90000 (23%)]	Loss: -19.3049	Cost: 6.06s
Train Epoch: 1532 [40960/90000 (45%)]	Loss: -18.8090	Cost: 7.94s
Train Epoch: 1532 [61440/90000 (68%)]	Loss: -19.2116	Cost: 5.77s
Train Epoch: 1532 [81920/90000 (91%)]	Loss: -19.4328	Cost: 6.56s
Train Epoch: 1532 	Average Loss: -18.8374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4695

Saving model as e1532_model.pt & e1532_waveforms_supplementary.hdf5
Learning rate: 0.00019988420136377757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1533 [0/90000 (0%)]	Loss: -13.6260	Cost: 23.69s
Train Epoch: 1533 [20480/90000 (23%)]	Loss: -19.5282	Cost: 6.30s
Train Epoch: 1533 [40960/90000 (45%)]	Loss: -18.5610	Cost: 11.70s
Train Epoch: 1533 [61440/90000 (68%)]	Loss: -18.6008	Cost: 6.29s
Train Epoch: 1533 [81920/90000 (91%)]	Loss: -18.7308	Cost: 11.10s
Train Epoch: 1533 	Average Loss: -18.5989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9497

Learning rate: 0.0001998840501705152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1534 [0/90000 (0%)]	Loss: -12.1634	Cost: 26.70s
Train Epoch: 1534 [20480/90000 (23%)]	Loss: -18.8410	Cost: 6.25s
Train Epoch: 1534 [40960/90000 (45%)]	Loss: -18.1320	Cost: 7.89s
Train Epoch: 1534 [61440/90000 (68%)]	Loss: -18.3659	Cost: 6.00s
Train Epoch: 1534 [81920/90000 (91%)]	Loss: -18.6578	Cost: 8.15s
Train Epoch: 1534 	Average Loss: -18.1377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9856

Learning rate: 0.00019988389887867124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1535 [0/90000 (0%)]	Loss: -12.1236	Cost: 23.69s
Train Epoch: 1535 [20480/90000 (23%)]	Loss: -19.1074	Cost: 6.09s
Train Epoch: 1535 [40960/90000 (45%)]	Loss: -18.6756	Cost: 7.14s
Train Epoch: 1535 [61440/90000 (68%)]	Loss: -19.2642	Cost: 6.43s
Train Epoch: 1535 [81920/90000 (91%)]	Loss: -19.1346	Cost: 6.30s
Train Epoch: 1535 	Average Loss: -18.6070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1592

Learning rate: 0.00019988374748824582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1536 [0/90000 (0%)]	Loss: -12.8056	Cost: 22.53s
Train Epoch: 1536 [20480/90000 (23%)]	Loss: -19.3063	Cost: 6.28s
Train Epoch: 1536 [40960/90000 (45%)]	Loss: -18.9229	Cost: 10.89s
Train Epoch: 1536 [61440/90000 (68%)]	Loss: -19.4128	Cost: 6.34s
Train Epoch: 1536 [81920/90000 (91%)]	Loss: -19.3115	Cost: 11.46s
Train Epoch: 1536 	Average Loss: -18.8158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5579

Saving model as e1536_model.pt & e1536_waveforms_supplementary.hdf5
Learning rate: 0.0001998835959992391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1537 [0/90000 (0%)]	Loss: -12.3321	Cost: 27.44s
Train Epoch: 1537 [20480/90000 (23%)]	Loss: -19.5448	Cost: 6.31s
Train Epoch: 1537 [40960/90000 (45%)]	Loss: -19.0885	Cost: 8.77s
Train Epoch: 1537 [61440/90000 (68%)]	Loss: -19.4049	Cost: 5.98s
Train Epoch: 1537 [81920/90000 (91%)]	Loss: -19.3919	Cost: 8.09s
Train Epoch: 1537 	Average Loss: -18.9800
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5859

Saving model as e1537_model.pt & e1537_waveforms_supplementary.hdf5
Learning rate: 0.0001998834444116512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1538 [0/90000 (0%)]	Loss: -13.4311	Cost: 23.62s
Train Epoch: 1538 [20480/90000 (23%)]	Loss: -19.4520	Cost: 6.09s
Train Epoch: 1538 [40960/90000 (45%)]	Loss: -19.1798	Cost: 8.26s
Train Epoch: 1538 [61440/90000 (68%)]	Loss: -19.5150	Cost: 5.71s
Train Epoch: 1538 [81920/90000 (91%)]	Loss: -19.3359	Cost: 6.67s
Train Epoch: 1538 	Average Loss: -19.0113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6226

Saving model as e1538_model.pt & e1538_waveforms_supplementary.hdf5
Learning rate: 0.00019988329272548232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1539 [0/90000 (0%)]	Loss: -13.2087	Cost: 22.50s
Train Epoch: 1539 [20480/90000 (23%)]	Loss: -19.4794	Cost: 6.22s
Train Epoch: 1539 [40960/90000 (45%)]	Loss: -18.8881	Cost: 10.56s
Train Epoch: 1539 [61440/90000 (68%)]	Loss: -19.4180	Cost: 6.30s
Train Epoch: 1539 [81920/90000 (91%)]	Loss: -19.1534	Cost: 11.42s
Train Epoch: 1539 	Average Loss: -18.8983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3297

Learning rate: 0.00019988314094073257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1540 [0/90000 (0%)]	Loss: -11.8650	Cost: 27.23s
Train Epoch: 1540 [20480/90000 (23%)]	Loss: -19.4086	Cost: 6.23s
Train Epoch: 1540 [40960/90000 (45%)]	Loss: -18.8953	Cost: 9.67s
Train Epoch: 1540 [61440/90000 (68%)]	Loss: -19.1758	Cost: 5.75s
Train Epoch: 1540 [81920/90000 (91%)]	Loss: -19.0961	Cost: 6.74s
Train Epoch: 1540 	Average Loss: -18.7404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2919

Learning rate: 0.0001998829890574021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1541 [0/90000 (0%)]	Loss: -12.1964	Cost: 26.58s
Train Epoch: 1541 [20480/90000 (23%)]	Loss: -19.4868	Cost: 6.06s
Train Epoch: 1541 [40960/90000 (45%)]	Loss: -18.8213	Cost: 7.77s
Train Epoch: 1541 [61440/90000 (68%)]	Loss: -19.0931	Cost: 5.83s
Train Epoch: 1541 [81920/90000 (91%)]	Loss: -18.4642	Cost: 6.65s
Train Epoch: 1541 	Average Loss: -18.5991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3851

Learning rate: 0.00019988283707549108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1542 [0/90000 (0%)]	Loss: -12.6737	Cost: 24.29s
Train Epoch: 1542 [20480/90000 (23%)]	Loss: -18.6974	Cost: 6.27s
Train Epoch: 1542 [40960/90000 (45%)]	Loss: -18.5001	Cost: 6.75s
Train Epoch: 1542 [61440/90000 (68%)]	Loss: -19.1384	Cost: 6.29s
Train Epoch: 1542 [81920/90000 (91%)]	Loss: -19.3347	Cost: 12.10s
Train Epoch: 1542 	Average Loss: -18.4108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2537

Learning rate: 0.00019988268499499965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1543 [0/90000 (0%)]	Loss: -11.9776	Cost: 25.37s
Train Epoch: 1543 [20480/90000 (23%)]	Loss: -19.2183	Cost: 6.37s
Train Epoch: 1543 [40960/90000 (45%)]	Loss: -18.9170	Cost: 11.45s
Train Epoch: 1543 [61440/90000 (68%)]	Loss: -19.3929	Cost: 6.09s
Train Epoch: 1543 [81920/90000 (91%)]	Loss: -19.3395	Cost: 7.61s
Train Epoch: 1543 	Average Loss: -18.7180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3466

Learning rate: 0.00019988253281592796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1544 [0/90000 (0%)]	Loss: -13.2191	Cost: 26.58s
Train Epoch: 1544 [20480/90000 (23%)]	Loss: -19.6431	Cost: 6.18s
Train Epoch: 1544 [40960/90000 (45%)]	Loss: -18.9930	Cost: 7.48s
Train Epoch: 1544 [61440/90000 (68%)]	Loss: -19.4856	Cost: 6.04s
Train Epoch: 1544 [81920/90000 (91%)]	Loss: -19.3964	Cost: 8.33s
Train Epoch: 1544 	Average Loss: -18.9954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4500

Learning rate: 0.00019988238053827618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1545 [0/90000 (0%)]	Loss: -12.9944	Cost: 23.46s
Train Epoch: 1545 [20480/90000 (23%)]	Loss: -19.3557	Cost: 6.05s
Train Epoch: 1545 [40960/90000 (45%)]	Loss: -18.9635	Cost: 6.93s
Train Epoch: 1545 [61440/90000 (68%)]	Loss: -19.5493	Cost: 5.77s
Train Epoch: 1545 [81920/90000 (91%)]	Loss: -19.3686	Cost: 6.30s
Train Epoch: 1545 	Average Loss: -18.9985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6313

Saving model as e1545_model.pt & e1545_waveforms_supplementary.hdf5
Learning rate: 0.0001998822281620444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1546 [0/90000 (0%)]	Loss: -12.8773	Cost: 22.65s
Train Epoch: 1546 [20480/90000 (23%)]	Loss: -18.6899	Cost: 6.40s
Train Epoch: 1546 [40960/90000 (45%)]	Loss: -18.4555	Cost: 10.97s
Train Epoch: 1546 [61440/90000 (68%)]	Loss: -19.3084	Cost: 6.32s
Train Epoch: 1546 [81920/90000 (91%)]	Loss: -18.8336	Cost: 10.86s
Train Epoch: 1546 	Average Loss: -18.4796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1200

Learning rate: 0.00019988207568723284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1547 [0/90000 (0%)]	Loss: -12.0179	Cost: 27.18s
Train Epoch: 1547 [20480/90000 (23%)]	Loss: -18.6458	Cost: 6.32s
Train Epoch: 1547 [40960/90000 (45%)]	Loss: -17.7717	Cost: 9.15s
Train Epoch: 1547 [61440/90000 (68%)]	Loss: -18.3938	Cost: 5.91s
Train Epoch: 1547 [81920/90000 (91%)]	Loss: -18.7302	Cost: 7.05s
Train Epoch: 1547 	Average Loss: -17.9697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8389

Learning rate: 0.0001998819231138416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1548 [0/90000 (0%)]	Loss: -11.8992	Cost: 23.71s
Train Epoch: 1548 [20480/90000 (23%)]	Loss: -19.0549	Cost: 6.24s
Train Epoch: 1548 [40960/90000 (45%)]	Loss: -17.9783	Cost: 8.29s
Train Epoch: 1548 [61440/90000 (68%)]	Loss: -17.5030	Cost: 5.78s
Train Epoch: 1548 [81920/90000 (91%)]	Loss: -18.1049	Cost: 5.82s
Train Epoch: 1548 	Average Loss: -17.7864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4345

Learning rate: 0.00019988177044187092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1549 [0/90000 (0%)]	Loss: -11.4813	Cost: 23.20s
Train Epoch: 1549 [20480/90000 (23%)]	Loss: -18.6605	Cost: 6.06s
Train Epoch: 1549 [40960/90000 (45%)]	Loss: -18.3061	Cost: 7.19s
Train Epoch: 1549 [61440/90000 (68%)]	Loss: -18.6513	Cost: 6.16s
Train Epoch: 1549 [81920/90000 (91%)]	Loss: -18.9670	Cost: 11.78s
Train Epoch: 1549 	Average Loss: -18.1773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1866

Learning rate: 0.00019988161767132086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1550 [0/90000 (0%)]	Loss: -12.4842	Cost: 24.71s
Train Epoch: 1550 [20480/90000 (23%)]	Loss: -19.1164	Cost: 6.30s
Train Epoch: 1550 [40960/90000 (45%)]	Loss: -18.6452	Cost: 10.79s
Train Epoch: 1550 [61440/90000 (68%)]	Loss: -19.0651	Cost: 6.25s
Train Epoch: 1550 [81920/90000 (91%)]	Loss: -19.3927	Cost: 8.71s
Train Epoch: 1550 	Average Loss: -18.6207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3562

Learning rate: 0.0001998814648021916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1551 [0/90000 (0%)]	Loss: -13.1742	Cost: 26.43s
Train Epoch: 1551 [20480/90000 (23%)]	Loss: -19.4375	Cost: 6.22s
Train Epoch: 1551 [40960/90000 (45%)]	Loss: -18.7076	Cost: 7.52s
Train Epoch: 1551 [61440/90000 (68%)]	Loss: -19.1177	Cost: 6.00s
Train Epoch: 1551 [81920/90000 (91%)]	Loss: -19.2065	Cost: 8.22s
Train Epoch: 1551 	Average Loss: -18.7833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2491

Learning rate: 0.00019988131183448324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1552 [0/90000 (0%)]	Loss: -12.9197	Cost: 23.73s
Train Epoch: 1552 [20480/90000 (23%)]	Loss: -19.2878	Cost: 6.08s
Train Epoch: 1552 [40960/90000 (45%)]	Loss: -18.8872	Cost: 7.41s
Train Epoch: 1552 [61440/90000 (68%)]	Loss: -19.2446	Cost: 5.84s
Train Epoch: 1552 [81920/90000 (91%)]	Loss: -19.5661	Cost: 5.96s
Train Epoch: 1552 	Average Loss: -18.8290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5125

Learning rate: 0.000199881158768196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1553 [0/90000 (0%)]	Loss: -12.5556	Cost: 22.45s
Train Epoch: 1553 [20480/90000 (23%)]	Loss: -19.4043	Cost: 6.14s
Train Epoch: 1553 [40960/90000 (45%)]	Loss: -18.9231	Cost: 9.02s
Train Epoch: 1553 [61440/90000 (68%)]	Loss: -19.4059	Cost: 6.38s
Train Epoch: 1553 [81920/90000 (91%)]	Loss: -19.5024	Cost: 11.28s
Train Epoch: 1553 	Average Loss: -18.9085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6397

Saving model as e1553_model.pt & e1553_waveforms_supplementary.hdf5
Learning rate: 0.00019988100560333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1554 [0/90000 (0%)]	Loss: -11.1663	Cost: 26.67s
Train Epoch: 1554 [20480/90000 (23%)]	Loss: -19.5946	Cost: 6.52s
Train Epoch: 1554 [40960/90000 (45%)]	Loss: -19.0346	Cost: 8.61s
Train Epoch: 1554 [61440/90000 (68%)]	Loss: -19.5146	Cost: 5.99s
Train Epoch: 1554 [81920/90000 (91%)]	Loss: -19.5837	Cost: 8.26s
Train Epoch: 1554 	Average Loss: -18.9163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4915

Learning rate: 0.0001998808523398854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1555 [0/90000 (0%)]	Loss: -13.0579	Cost: 23.72s
Train Epoch: 1555 [20480/90000 (23%)]	Loss: -19.8346	Cost: 6.09s
Train Epoch: 1555 [40960/90000 (45%)]	Loss: -19.2635	Cost: 7.23s
Train Epoch: 1555 [61440/90000 (68%)]	Loss: -19.5448	Cost: 5.81s
Train Epoch: 1555 [81920/90000 (91%)]	Loss: -19.4903	Cost: 6.25s
Train Epoch: 1555 	Average Loss: -19.0593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5743

Learning rate: 0.00019988069897786237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1556 [0/90000 (0%)]	Loss: -12.3262	Cost: 22.46s
Train Epoch: 1556 [20480/90000 (23%)]	Loss: -19.7029	Cost: 6.43s
Train Epoch: 1556 [40960/90000 (45%)]	Loss: -19.1160	Cost: 10.06s
Train Epoch: 1556 [61440/90000 (68%)]	Loss: -19.5813	Cost: 6.28s
Train Epoch: 1556 [81920/90000 (91%)]	Loss: -19.6118	Cost: 11.36s
Train Epoch: 1556 	Average Loss: -19.0798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5862

Learning rate: 0.00019988054551726105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1557 [0/90000 (0%)]	Loss: -12.3612	Cost: 27.64s
Train Epoch: 1557 [20480/90000 (23%)]	Loss: -19.6995	Cost: 6.31s
Train Epoch: 1557 [40960/90000 (45%)]	Loss: -19.1476	Cost: 9.85s
Train Epoch: 1557 [61440/90000 (68%)]	Loss: -19.5282	Cost: 5.76s
Train Epoch: 1557 [81920/90000 (91%)]	Loss: -19.4318	Cost: 6.01s
Train Epoch: 1557 	Average Loss: -19.0750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4940

Learning rate: 0.00019988039195808154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1558 [0/90000 (0%)]	Loss: -13.0817	Cost: 26.31s
Train Epoch: 1558 [20480/90000 (23%)]	Loss: -19.5206	Cost: 6.10s
Train Epoch: 1558 [40960/90000 (45%)]	Loss: -19.1841	Cost: 7.91s
Train Epoch: 1558 [61440/90000 (68%)]	Loss: -19.3377	Cost: 5.97s
Train Epoch: 1558 [81920/90000 (91%)]	Loss: -19.6014	Cost: 8.20s
Train Epoch: 1558 	Average Loss: -19.0314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5866

Learning rate: 0.00019988023830032404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1559 [0/90000 (0%)]	Loss: -13.2799	Cost: 23.77s
Train Epoch: 1559 [20480/90000 (23%)]	Loss: -19.7456	Cost: 6.07s
Train Epoch: 1559 [40960/90000 (45%)]	Loss: -19.1580	Cost: 7.53s
Train Epoch: 1559 [61440/90000 (68%)]	Loss: -19.6602	Cost: 6.07s
Train Epoch: 1559 [81920/90000 (91%)]	Loss: -19.6375	Cost: 8.47s
Train Epoch: 1559 	Average Loss: -19.1609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6496

Saving model as e1559_model.pt & e1559_waveforms_supplementary.hdf5
Learning rate: 0.00019988008454398872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1560 [0/90000 (0%)]	Loss: -13.1642	Cost: 24.18s
Train Epoch: 1560 [20480/90000 (23%)]	Loss: -19.6326	Cost: 6.26s
Train Epoch: 1560 [40960/90000 (45%)]	Loss: -18.9566	Cost: 11.23s
Train Epoch: 1560 [61440/90000 (68%)]	Loss: -19.4742	Cost: 6.20s
Train Epoch: 1560 [81920/90000 (91%)]	Loss: -19.7324	Cost: 9.65s
Train Epoch: 1560 	Average Loss: -19.0883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6314

Learning rate: 0.0001998799306890757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1561 [0/90000 (0%)]	Loss: -12.6163	Cost: 27.10s
Train Epoch: 1561 [20480/90000 (23%)]	Loss: -19.8964	Cost: 6.19s
Train Epoch: 1561 [40960/90000 (45%)]	Loss: -18.6262	Cost: 8.00s
Train Epoch: 1561 [61440/90000 (68%)]	Loss: -19.2656	Cost: 6.01s
Train Epoch: 1561 [81920/90000 (91%)]	Loss: -19.3388	Cost: 8.90s
Train Epoch: 1561 	Average Loss: -18.9220
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5352

Learning rate: 0.0001998797767355851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1562 [0/90000 (0%)]	Loss: -13.5045	Cost: 23.33s
Train Epoch: 1562 [20480/90000 (23%)]	Loss: -19.6723	Cost: 6.11s
Train Epoch: 1562 [40960/90000 (45%)]	Loss: -18.9309	Cost: 8.13s
Train Epoch: 1562 [61440/90000 (68%)]	Loss: -19.1958	Cost: 5.75s
Train Epoch: 1562 [81920/90000 (91%)]	Loss: -19.4452	Cost: 6.75s
Train Epoch: 1562 	Average Loss: -18.9705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3139

Learning rate: 0.00019987962268351716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1563 [0/90000 (0%)]	Loss: -11.8614	Cost: 22.42s
Train Epoch: 1563 [20480/90000 (23%)]	Loss: -19.6508	Cost: 6.23s
Train Epoch: 1563 [40960/90000 (45%)]	Loss: -19.0390	Cost: 10.50s
Train Epoch: 1563 [61440/90000 (68%)]	Loss: -19.4161	Cost: 6.55s
Train Epoch: 1563 [81920/90000 (91%)]	Loss: -19.5444	Cost: 10.84s
Train Epoch: 1563 	Average Loss: -18.9210
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6584

Saving model as e1563_model.pt & e1563_waveforms_supplementary.hdf5
Learning rate: 0.00019987946853287198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1564 [0/90000 (0%)]	Loss: -13.2098	Cost: 27.10s
Train Epoch: 1564 [20480/90000 (23%)]	Loss: -19.8171	Cost: 6.37s
Train Epoch: 1564 [40960/90000 (45%)]	Loss: -19.0777	Cost: 9.99s
Train Epoch: 1564 [61440/90000 (68%)]	Loss: -19.2918	Cost: 5.80s
Train Epoch: 1564 [81920/90000 (91%)]	Loss: -19.4433	Cost: 6.19s
Train Epoch: 1564 	Average Loss: -19.0775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7685

Saving model as e1564_model.pt & e1564_waveforms_supplementary.hdf5
Learning rate: 0.0001998793142836497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1565 [0/90000 (0%)]	Loss: -13.0824	Cost: 23.52s
Train Epoch: 1565 [20480/90000 (23%)]	Loss: -19.7678	Cost: 6.05s
Train Epoch: 1565 [40960/90000 (45%)]	Loss: -19.1977	Cost: 8.30s
Train Epoch: 1565 [61440/90000 (68%)]	Loss: -19.5087	Cost: 5.82s
Train Epoch: 1565 [81920/90000 (91%)]	Loss: -19.2793	Cost: 6.58s
Train Epoch: 1565 	Average Loss: -19.1140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5493

Learning rate: 0.00019987915993585048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1566 [0/90000 (0%)]	Loss: -12.0951	Cost: 23.12s
Train Epoch: 1566 [20480/90000 (23%)]	Loss: -19.6535	Cost: 6.04s
Train Epoch: 1566 [40960/90000 (45%)]	Loss: -19.0631	Cost: 8.15s
Train Epoch: 1566 [61440/90000 (68%)]	Loss: -19.2269	Cost: 6.23s
Train Epoch: 1566 [81920/90000 (91%)]	Loss: -19.5871	Cost: 11.48s
Train Epoch: 1566 	Average Loss: -18.9578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5165

Learning rate: 0.0001998790054894745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1567 [0/90000 (0%)]	Loss: -12.7262	Cost: 25.24s
Train Epoch: 1567 [20480/90000 (23%)]	Loss: -19.6368	Cost: 6.36s
Train Epoch: 1567 [40960/90000 (45%)]	Loss: -19.2107	Cost: 10.89s
Train Epoch: 1567 [61440/90000 (68%)]	Loss: -19.3488	Cost: 6.09s
Train Epoch: 1567 [81920/90000 (91%)]	Loss: -19.5493	Cost: 7.32s
Train Epoch: 1567 	Average Loss: -19.0244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5820

Learning rate: 0.00019987885094452186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1568 [0/90000 (0%)]	Loss: -12.7226	Cost: 27.08s
Train Epoch: 1568 [20480/90000 (23%)]	Loss: -19.6583	Cost: 6.34s
Train Epoch: 1568 [40960/90000 (45%)]	Loss: -19.1338	Cost: 8.39s
Train Epoch: 1568 [61440/90000 (68%)]	Loss: -19.5316	Cost: 6.00s
Train Epoch: 1568 [81920/90000 (91%)]	Loss: -19.3758	Cost: 8.94s
Train Epoch: 1568 	Average Loss: -19.0499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4952

Learning rate: 0.0001998786963009928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1569 [0/90000 (0%)]	Loss: -12.6492	Cost: 23.81s
Train Epoch: 1569 [20480/90000 (23%)]	Loss: -19.2606	Cost: 6.10s
Train Epoch: 1569 [40960/90000 (45%)]	Loss: -18.9976	Cost: 7.16s
Train Epoch: 1569 [61440/90000 (68%)]	Loss: -19.4657	Cost: 6.01s
Train Epoch: 1569 [81920/90000 (91%)]	Loss: -19.6718	Cost: 8.52s
Train Epoch: 1569 	Average Loss: -18.8795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5376

Learning rate: 0.00019987854155888737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1570 [0/90000 (0%)]	Loss: -12.8334	Cost: 23.03s
Train Epoch: 1570 [20480/90000 (23%)]	Loss: -19.6340	Cost: 6.27s
Train Epoch: 1570 [40960/90000 (45%)]	Loss: -18.8149	Cost: 11.00s
Train Epoch: 1570 [61440/90000 (68%)]	Loss: -19.1856	Cost: 6.37s
Train Epoch: 1570 [81920/90000 (91%)]	Loss: -19.4491	Cost: 10.77s
Train Epoch: 1570 	Average Loss: -18.8688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2446

Learning rate: 0.0001998783867182058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1571 [0/90000 (0%)]	Loss: -12.1630	Cost: 26.71s
Train Epoch: 1571 [20480/90000 (23%)]	Loss: -19.5887	Cost: 6.49s
Train Epoch: 1571 [40960/90000 (45%)]	Loss: -19.0761	Cost: 8.62s
Train Epoch: 1571 [61440/90000 (68%)]	Loss: -19.4217	Cost: 6.04s
Train Epoch: 1571 [81920/90000 (91%)]	Loss: -19.2926	Cost: 8.74s
Train Epoch: 1571 	Average Loss: -18.8744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3705

Learning rate: 0.0001998782317789482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1572 [0/90000 (0%)]	Loss: -12.9333	Cost: 23.30s
Train Epoch: 1572 [20480/90000 (23%)]	Loss: -19.4804	Cost: 6.11s
Train Epoch: 1572 [40960/90000 (45%)]	Loss: -19.0881	Cost: 6.94s
Train Epoch: 1572 [61440/90000 (68%)]	Loss: -19.4356	Cost: 6.01s
Train Epoch: 1572 [81920/90000 (91%)]	Loss: -19.4645	Cost: 7.18s
Train Epoch: 1572 	Average Loss: -18.9005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0145

Learning rate: 0.00019987807674111475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1573 [0/90000 (0%)]	Loss: -12.7636	Cost: 23.16s
Train Epoch: 1573 [20480/90000 (23%)]	Loss: -19.2390	Cost: 6.24s
Train Epoch: 1573 [40960/90000 (45%)]	Loss: -18.6972	Cost: 11.42s
Train Epoch: 1573 [61440/90000 (68%)]	Loss: -19.2814	Cost: 6.23s
Train Epoch: 1573 [81920/90000 (91%)]	Loss: -19.2484	Cost: 11.25s
Train Epoch: 1573 	Average Loss: -18.6591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3039

Learning rate: 0.00019987792160470558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1574 [0/90000 (0%)]	Loss: -12.3050	Cost: 28.30s
Train Epoch: 1574 [20480/90000 (23%)]	Loss: -19.5515	Cost: 6.44s
Train Epoch: 1574 [40960/90000 (45%)]	Loss: -19.0473	Cost: 8.17s
Train Epoch: 1574 [61440/90000 (68%)]	Loss: -19.2724	Cost: 6.16s
Train Epoch: 1574 [81920/90000 (91%)]	Loss: -19.5584	Cost: 6.55s
Train Epoch: 1574 	Average Loss: -18.9060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6384

Learning rate: 0.00019987776636972085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1575 [0/90000 (0%)]	Loss: -12.4188	Cost: 23.27s
Train Epoch: 1575 [20480/90000 (23%)]	Loss: -19.9720	Cost: 6.11s
Train Epoch: 1575 [40960/90000 (45%)]	Loss: -19.3185	Cost: 8.82s
Train Epoch: 1575 [61440/90000 (68%)]	Loss: -19.6052	Cost: 5.78s
Train Epoch: 1575 [81920/90000 (91%)]	Loss: -18.7681	Cost: 6.07s
Train Epoch: 1575 	Average Loss: -19.0177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9037

Learning rate: 0.00019987761103616069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1576 [0/90000 (0%)]	Loss: -12.8213	Cost: 22.38s
Train Epoch: 1576 [20480/90000 (23%)]	Loss: -19.0853	Cost: 6.04s
Train Epoch: 1576 [40960/90000 (45%)]	Loss: -18.6102	Cost: 8.42s
Train Epoch: 1576 [61440/90000 (68%)]	Loss: -19.3001	Cost: 6.49s
Train Epoch: 1576 [81920/90000 (91%)]	Loss: -19.4368	Cost: 11.50s
Train Epoch: 1576 	Average Loss: -18.6755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5317

Learning rate: 0.0001998774556040253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1577 [0/90000 (0%)]	Loss: -12.9361	Cost: 27.12s
Train Epoch: 1577 [20480/90000 (23%)]	Loss: -19.5270	Cost: 6.37s
Train Epoch: 1577 [40960/90000 (45%)]	Loss: -18.9754	Cost: 10.57s
Train Epoch: 1577 [61440/90000 (68%)]	Loss: -19.2593	Cost: 5.78s
Train Epoch: 1577 [81920/90000 (91%)]	Loss: -19.3588	Cost: 6.69s
Train Epoch: 1577 	Average Loss: -18.9214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5196

Learning rate: 0.00019987730007331483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1578 [0/90000 (0%)]	Loss: -12.5215	Cost: 26.17s
Train Epoch: 1578 [20480/90000 (23%)]	Loss: -19.3753	Cost: 6.22s
Train Epoch: 1578 [40960/90000 (45%)]	Loss: -19.0437	Cost: 7.98s
Train Epoch: 1578 [61440/90000 (68%)]	Loss: -19.0628	Cost: 6.17s
Train Epoch: 1578 [81920/90000 (91%)]	Loss: -19.0629	Cost: 6.51s
Train Epoch: 1578 	Average Loss: -18.7986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2965

Learning rate: 0.0001998771444440294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1579 [0/90000 (0%)]	Loss: -13.0145	Cost: 24.53s
Train Epoch: 1579 [20480/90000 (23%)]	Loss: -19.5173	Cost: 6.56s
Train Epoch: 1579 [40960/90000 (45%)]	Loss: -19.0443	Cost: 6.93s
Train Epoch: 1579 [61440/90000 (68%)]	Loss: -19.4776	Cost: 6.25s
Train Epoch: 1579 [81920/90000 (91%)]	Loss: -19.4569	Cost: 12.05s
Train Epoch: 1579 	Average Loss: -18.9437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6684

Learning rate: 0.0001998769887161692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1580 [0/90000 (0%)]	Loss: -12.5852	Cost: 26.10s
Train Epoch: 1580 [20480/90000 (23%)]	Loss: -20.0131	Cost: 6.52s
Train Epoch: 1580 [40960/90000 (45%)]	Loss: -19.3376	Cost: 10.80s
Train Epoch: 1580 [61440/90000 (68%)]	Loss: -19.6046	Cost: 5.99s
Train Epoch: 1580 [81920/90000 (91%)]	Loss: -19.6947	Cost: 6.76s
Train Epoch: 1580 	Average Loss: -19.2100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7198

Learning rate: 0.00019987683288973435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1581 [0/90000 (0%)]	Loss: -13.1287	Cost: 27.20s
Train Epoch: 1581 [20480/90000 (23%)]	Loss: -20.0322	Cost: 6.12s
Train Epoch: 1581 [40960/90000 (45%)]	Loss: -19.5991	Cost: 7.50s
Train Epoch: 1581 [61440/90000 (68%)]	Loss: -19.9029	Cost: 6.04s
Train Epoch: 1581 [81920/90000 (91%)]	Loss: -19.7552	Cost: 8.24s
Train Epoch: 1581 	Average Loss: -19.3875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9716

Saving model as e1581_model.pt & e1581_waveforms_supplementary.hdf5
Learning rate: 0.000199876676964725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1582 [0/90000 (0%)]	Loss: -12.8694	Cost: 23.92s
Train Epoch: 1582 [20480/90000 (23%)]	Loss: -20.0086	Cost: 6.15s
Train Epoch: 1582 [40960/90000 (45%)]	Loss: -19.4381	Cost: 6.87s
Train Epoch: 1582 [61440/90000 (68%)]	Loss: -19.9283	Cost: 6.31s
Train Epoch: 1582 [81920/90000 (91%)]	Loss: -19.8378	Cost: 10.50s
Train Epoch: 1582 	Average Loss: -19.3054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7252

Learning rate: 0.00019987652094114133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1583 [0/90000 (0%)]	Loss: -12.7852	Cost: 23.81s
Train Epoch: 1583 [20480/90000 (23%)]	Loss: -19.5281	Cost: 6.24s
Train Epoch: 1583 [40960/90000 (45%)]	Loss: -19.1664	Cost: 11.13s
Train Epoch: 1583 [61440/90000 (68%)]	Loss: -19.3835	Cost: 6.22s
Train Epoch: 1583 [81920/90000 (91%)]	Loss: -19.9090	Cost: 9.79s
Train Epoch: 1583 	Average Loss: -19.0530
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9094

Learning rate: 0.0001998763648189835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1584 [0/90000 (0%)]	Loss: -13.5416	Cost: 26.69s
Train Epoch: 1584 [20480/90000 (23%)]	Loss: -19.2133	Cost: 6.34s
Train Epoch: 1584 [40960/90000 (45%)]	Loss: -18.4890	Cost: 8.24s
Train Epoch: 1584 [61440/90000 (68%)]	Loss: -18.8852	Cost: 6.06s
Train Epoch: 1584 [81920/90000 (91%)]	Loss: -19.1912	Cost: 8.84s
Train Epoch: 1584 	Average Loss: -18.7128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5410

Learning rate: 0.0001998762085982516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1585 [0/90000 (0%)]	Loss: -13.2644	Cost: 23.71s
Train Epoch: 1585 [20480/90000 (23%)]	Loss: -19.9714	Cost: 6.08s
Train Epoch: 1585 [40960/90000 (45%)]	Loss: -19.2349	Cost: 7.43s
Train Epoch: 1585 [61440/90000 (68%)]	Loss: -19.6619	Cost: 5.86s
Train Epoch: 1585 [81920/90000 (91%)]	Loss: -19.6692	Cost: 6.17s
Train Epoch: 1585 	Average Loss: -19.1896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7353

Learning rate: 0.00019987605227894588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1586 [0/90000 (0%)]	Loss: -12.9742	Cost: 22.98s
Train Epoch: 1586 [20480/90000 (23%)]	Loss: -19.8900	Cost: 6.37s
Train Epoch: 1586 [40960/90000 (45%)]	Loss: -19.3562	Cost: 11.37s
Train Epoch: 1586 [61440/90000 (68%)]	Loss: -19.9089	Cost: 6.35s
Train Epoch: 1586 [81920/90000 (91%)]	Loss: -19.7731	Cost: 11.32s
Train Epoch: 1586 	Average Loss: -19.2784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9485

Learning rate: 0.00019987589586106645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1587 [0/90000 (0%)]	Loss: -13.4809	Cost: 30.36s
Train Epoch: 1587 [20480/90000 (23%)]	Loss: -19.8880	Cost: 6.62s
Train Epoch: 1587 [40960/90000 (45%)]	Loss: -19.4161	Cost: 9.28s
Train Epoch: 1587 [61440/90000 (68%)]	Loss: -19.7418	Cost: 5.97s
Train Epoch: 1587 [81920/90000 (91%)]	Loss: -19.7544	Cost: 7.50s
Train Epoch: 1587 	Average Loss: -19.4544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7851

Learning rate: 0.00019987573934461347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1588 [0/90000 (0%)]	Loss: -13.2362	Cost: 24.47s
Train Epoch: 1588 [20480/90000 (23%)]	Loss: -19.7046	Cost: 6.08s
Train Epoch: 1588 [40960/90000 (45%)]	Loss: -19.3212	Cost: 8.50s
Train Epoch: 1588 [61440/90000 (68%)]	Loss: -19.5962	Cost: 5.74s
Train Epoch: 1588 [81920/90000 (91%)]	Loss: -19.9629	Cost: 6.91s
Train Epoch: 1588 	Average Loss: -19.1859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0003

Saving model as e1588_model.pt & e1588_waveforms_supplementary.hdf5
Learning rate: 0.00019987558272958707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1589 [0/90000 (0%)]	Loss: -13.0838	Cost: 22.24s
Train Epoch: 1589 [20480/90000 (23%)]	Loss: -20.1191	Cost: 6.31s
Train Epoch: 1589 [40960/90000 (45%)]	Loss: -19.1936	Cost: 9.14s
Train Epoch: 1589 [61440/90000 (68%)]	Loss: -19.5409	Cost: 6.24s
Train Epoch: 1589 [81920/90000 (91%)]	Loss: -19.7689	Cost: 11.36s
Train Epoch: 1589 	Average Loss: -19.2737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8860

Learning rate: 0.00019987542601598743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1590 [0/90000 (0%)]	Loss: -13.1935	Cost: 26.71s
Train Epoch: 1590 [20480/90000 (23%)]	Loss: -19.7328	Cost: 6.39s
Train Epoch: 1590 [40960/90000 (45%)]	Loss: -19.2396	Cost: 10.12s
Train Epoch: 1590 [61440/90000 (68%)]	Loss: -19.7662	Cost: 5.75s
Train Epoch: 1590 [81920/90000 (91%)]	Loss: -19.6828	Cost: 6.45s
Train Epoch: 1590 	Average Loss: -19.2521
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6986

Learning rate: 0.00019987526920381467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1591 [0/90000 (0%)]	Loss: -12.8622	Cost: 26.18s
Train Epoch: 1591 [20480/90000 (23%)]	Loss: -19.9084	Cost: 6.19s
Train Epoch: 1591 [40960/90000 (45%)]	Loss: -19.3285	Cost: 8.18s
Train Epoch: 1591 [61440/90000 (68%)]	Loss: -19.5234	Cost: 5.92s
Train Epoch: 1591 [81920/90000 (91%)]	Loss: -19.5511	Cost: 7.44s
Train Epoch: 1591 	Average Loss: -19.1987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6222

Learning rate: 0.000199875112293069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1592 [0/90000 (0%)]	Loss: -13.7847	Cost: 23.41s
Train Epoch: 1592 [20480/90000 (23%)]	Loss: -19.8897	Cost: 6.13s
Train Epoch: 1592 [40960/90000 (45%)]	Loss: -19.3940	Cost: 7.14s
Train Epoch: 1592 [61440/90000 (68%)]	Loss: -19.5787	Cost: 6.22s
Train Epoch: 1592 [81920/90000 (91%)]	Loss: -19.6431	Cost: 10.05s
Train Epoch: 1592 	Average Loss: -19.2338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7748

Learning rate: 0.00019987495528375055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1593 [0/90000 (0%)]	Loss: -12.7534	Cost: 22.91s
Train Epoch: 1593 [20480/90000 (23%)]	Loss: -19.8394	Cost: 6.25s
Train Epoch: 1593 [40960/90000 (45%)]	Loss: -19.3654	Cost: 11.41s
Train Epoch: 1593 [61440/90000 (68%)]	Loss: -19.4579	Cost: 6.13s
Train Epoch: 1593 [81920/90000 (91%)]	Loss: -19.8163	Cost: 10.70s
Train Epoch: 1593 	Average Loss: -19.1536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7191

Learning rate: 0.00019987479817585945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1594 [0/90000 (0%)]	Loss: -13.1570	Cost: 27.08s
Train Epoch: 1594 [20480/90000 (23%)]	Loss: -19.6601	Cost: 6.33s
Train Epoch: 1594 [40960/90000 (45%)]	Loss: -19.2709	Cost: 9.13s
Train Epoch: 1594 [61440/90000 (68%)]	Loss: -19.8143	Cost: 5.96s
Train Epoch: 1594 [81920/90000 (91%)]	Loss: -19.8012	Cost: 7.99s
Train Epoch: 1594 	Average Loss: -19.2109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9433

Learning rate: 0.0001998746409693959
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1595 [0/90000 (0%)]	Loss: -13.2690	Cost: 23.79s
Train Epoch: 1595 [20480/90000 (23%)]	Loss: -19.9240	Cost: 6.09s
Train Epoch: 1595 [40960/90000 (45%)]	Loss: -19.4902	Cost: 8.84s
Train Epoch: 1595 [61440/90000 (68%)]	Loss: -19.6449	Cost: 5.77s
Train Epoch: 1595 [81920/90000 (91%)]	Loss: -19.9511	Cost: 6.03s
Train Epoch: 1595 	Average Loss: -19.3237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8341

Learning rate: 0.00019987448366436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1596 [0/90000 (0%)]	Loss: -13.2160	Cost: 22.92s
Train Epoch: 1596 [20480/90000 (23%)]	Loss: -20.2537	Cost: 6.08s
Train Epoch: 1596 [40960/90000 (45%)]	Loss: -19.2297	Cost: 8.08s
Train Epoch: 1596 [61440/90000 (68%)]	Loss: -19.6942	Cost: 6.13s
Train Epoch: 1596 [81920/90000 (91%)]	Loss: -19.8277	Cost: 10.87s
Train Epoch: 1596 	Average Loss: -19.2590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7220

Learning rate: 0.00019987432626075193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1597 [0/90000 (0%)]	Loss: -13.5132	Cost: 25.65s
Train Epoch: 1597 [20480/90000 (23%)]	Loss: -20.1521	Cost: 6.42s
Train Epoch: 1597 [40960/90000 (45%)]	Loss: -19.3701	Cost: 11.40s
Train Epoch: 1597 [61440/90000 (68%)]	Loss: -19.9885	Cost: 6.27s
Train Epoch: 1597 [81920/90000 (91%)]	Loss: -19.7315	Cost: 7.24s
Train Epoch: 1597 	Average Loss: -19.3743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8062

Learning rate: 0.00019987416875857185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1598 [0/90000 (0%)]	Loss: -13.1011	Cost: 26.59s
Train Epoch: 1598 [20480/90000 (23%)]	Loss: -19.6899	Cost: 6.14s
Train Epoch: 1598 [40960/90000 (45%)]	Loss: -18.9453	Cost: 7.40s
Train Epoch: 1598 [61440/90000 (68%)]	Loss: -19.7632	Cost: 6.03s
Train Epoch: 1598 [81920/90000 (91%)]	Loss: -19.8271	Cost: 8.66s
Train Epoch: 1598 	Average Loss: -19.1433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0351

Saving model as e1598_model.pt & e1598_waveforms_supplementary.hdf5
Learning rate: 0.00019987401115781993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1599 [0/90000 (0%)]	Loss: -13.5783	Cost: 24.04s
Train Epoch: 1599 [20480/90000 (23%)]	Loss: -19.9546	Cost: 6.17s
Train Epoch: 1599 [40960/90000 (45%)]	Loss: -17.5355	Cost: 6.94s
Train Epoch: 1599 [61440/90000 (68%)]	Loss: -18.2788	Cost: 6.19s
Train Epoch: 1599 [81920/90000 (91%)]	Loss: -18.7873	Cost: 10.80s
Train Epoch: 1599 	Average Loss: -18.3099
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0286

Learning rate: 0.0001998738534584963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1600 [0/90000 (0%)]	Loss: -12.1927	Cost: 23.69s
Train Epoch: 1600 [20480/90000 (23%)]	Loss: -19.2813	Cost: 6.20s
Train Epoch: 1600 [40960/90000 (45%)]	Loss: -19.1070	Cost: 11.27s
Train Epoch: 1600 [61440/90000 (68%)]	Loss: -19.6128	Cost: 6.18s
Train Epoch: 1600 [81920/90000 (91%)]	Loss: -19.7305	Cost: 9.48s
Train Epoch: 1600 	Average Loss: -18.8831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6615

Learning rate: 0.00019987369566060113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1601 [0/90000 (0%)]	Loss: -13.3528	Cost: 27.74s
Train Epoch: 1601 [20480/90000 (23%)]	Loss: -19.9092	Cost: 6.17s
Train Epoch: 1601 [40960/90000 (45%)]	Loss: -19.5837	Cost: 8.06s
Train Epoch: 1601 [61440/90000 (68%)]	Loss: -20.0184	Cost: 6.04s
Train Epoch: 1601 [81920/90000 (91%)]	Loss: -19.9522	Cost: 7.90s
Train Epoch: 1601 	Average Loss: -19.3590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9432

Learning rate: 0.00019987353776413456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1602 [0/90000 (0%)]	Loss: -13.6721	Cost: 23.89s
Train Epoch: 1602 [20480/90000 (23%)]	Loss: -20.1688	Cost: 6.06s
Train Epoch: 1602 [40960/90000 (45%)]	Loss: -19.2761	Cost: 8.36s
Train Epoch: 1602 [61440/90000 (68%)]	Loss: -19.9591	Cost: 5.75s
Train Epoch: 1602 [81920/90000 (91%)]	Loss: -19.9107	Cost: 6.70s
Train Epoch: 1602 	Average Loss: -19.4025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9777

Learning rate: 0.0001998733797690968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1603 [0/90000 (0%)]	Loss: -13.1472	Cost: 22.57s
Train Epoch: 1603 [20480/90000 (23%)]	Loss: -19.9199	Cost: 6.19s
Train Epoch: 1603 [40960/90000 (45%)]	Loss: -19.3476	Cost: 8.25s
Train Epoch: 1603 [61440/90000 (68%)]	Loss: -19.7079	Cost: 6.21s
Train Epoch: 1603 [81920/90000 (91%)]	Loss: -20.0157	Cost: 11.47s
Train Epoch: 1603 	Average Loss: -19.3458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9005

Learning rate: 0.00019987322167548793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1604 [0/90000 (0%)]	Loss: -13.3193	Cost: 27.15s
Train Epoch: 1604 [20480/90000 (23%)]	Loss: -20.1329	Cost: 6.23s
Train Epoch: 1604 [40960/90000 (45%)]	Loss: -19.4141	Cost: 10.31s
Train Epoch: 1604 [61440/90000 (68%)]	Loss: -19.6684	Cost: 5.72s
Train Epoch: 1604 [81920/90000 (91%)]	Loss: -19.5931	Cost: 7.11s
Train Epoch: 1604 	Average Loss: -19.3042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6521

Learning rate: 0.00019987306348330817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1605 [0/90000 (0%)]	Loss: -13.1092	Cost: 26.24s
Train Epoch: 1605 [20480/90000 (23%)]	Loss: -19.9009	Cost: 6.08s
Train Epoch: 1605 [40960/90000 (45%)]	Loss: -19.3964	Cost: 7.99s
Train Epoch: 1605 [61440/90000 (68%)]	Loss: -19.7739	Cost: 5.95s
Train Epoch: 1605 [81920/90000 (91%)]	Loss: -20.0344	Cost: 7.04s
Train Epoch: 1605 	Average Loss: -19.3095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0328

Learning rate: 0.00019987290519255766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1606 [0/90000 (0%)]	Loss: -13.5706	Cost: 23.29s
Train Epoch: 1606 [20480/90000 (23%)]	Loss: -20.1330	Cost: 6.09s
Train Epoch: 1606 [40960/90000 (45%)]	Loss: -19.3507	Cost: 7.83s
Train Epoch: 1606 [61440/90000 (68%)]	Loss: -19.9418	Cost: 6.16s
Train Epoch: 1606 [81920/90000 (91%)]	Loss: -19.7504	Cost: 11.48s
Train Epoch: 1606 	Average Loss: -19.3757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9863

Learning rate: 0.00019987274680323652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1607 [0/90000 (0%)]	Loss: -13.3924	Cost: 24.41s
Train Epoch: 1607 [20480/90000 (23%)]	Loss: -19.9221	Cost: 6.27s
Train Epoch: 1607 [40960/90000 (45%)]	Loss: -19.6344	Cost: 11.32s
Train Epoch: 1607 [61440/90000 (68%)]	Loss: -19.9226	Cost: 6.33s
Train Epoch: 1607 [81920/90000 (91%)]	Loss: -19.5900	Cost: 7.94s
Train Epoch: 1607 	Average Loss: -19.3497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6737

Learning rate: 0.00019987258831534495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1608 [0/90000 (0%)]	Loss: -13.4264	Cost: 26.28s
Train Epoch: 1608 [20480/90000 (23%)]	Loss: -19.9436	Cost: 6.09s
Train Epoch: 1608 [40960/90000 (45%)]	Loss: -19.3410	Cost: 7.17s
Train Epoch: 1608 [61440/90000 (68%)]	Loss: -19.6238	Cost: 5.98s
Train Epoch: 1608 [81920/90000 (91%)]	Loss: -19.8439	Cost: 7.81s
Train Epoch: 1608 	Average Loss: -19.2519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7922

Learning rate: 0.00019987242972888307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1609 [0/90000 (0%)]	Loss: -12.8004	Cost: 23.72s
Train Epoch: 1609 [20480/90000 (23%)]	Loss: -19.9891	Cost: 6.07s
Train Epoch: 1609 [40960/90000 (45%)]	Loss: -19.0986	Cost: 8.50s
Train Epoch: 1609 [61440/90000 (68%)]	Loss: -19.7912	Cost: 5.95s
Train Epoch: 1609 [81920/90000 (91%)]	Loss: -19.8872	Cost: 6.07s
Train Epoch: 1609 	Average Loss: -19.2864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9498

Learning rate: 0.00019987227104385105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1610 [0/90000 (0%)]	Loss: -12.6304	Cost: 22.38s
Train Epoch: 1610 [20480/90000 (23%)]	Loss: -19.9696	Cost: 6.25s
Train Epoch: 1610 [40960/90000 (45%)]	Loss: -18.6764	Cost: 10.27s
Train Epoch: 1610 [61440/90000 (68%)]	Loss: -19.0877	Cost: 6.37s
Train Epoch: 1610 [81920/90000 (91%)]	Loss: -19.5791	Cost: 11.45s
Train Epoch: 1610 	Average Loss: -18.9489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6174

Learning rate: 0.00019987211226024906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1611 [0/90000 (0%)]	Loss: -13.0498	Cost: 27.86s
Train Epoch: 1611 [20480/90000 (23%)]	Loss: -19.8844	Cost: 6.47s
Train Epoch: 1611 [40960/90000 (45%)]	Loss: -19.4563	Cost: 9.53s
Train Epoch: 1611 [61440/90000 (68%)]	Loss: -19.9329	Cost: 6.13s
Train Epoch: 1611 [81920/90000 (91%)]	Loss: -19.8219	Cost: 8.13s
Train Epoch: 1611 	Average Loss: -19.3554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5055

Learning rate: 0.00019987195337807723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1612 [0/90000 (0%)]	Loss: -13.0725	Cost: 23.97s
Train Epoch: 1612 [20480/90000 (23%)]	Loss: -19.5634	Cost: 6.06s
Train Epoch: 1612 [40960/90000 (45%)]	Loss: -19.0108	Cost: 8.15s
Train Epoch: 1612 [61440/90000 (68%)]	Loss: -19.5449	Cost: 5.80s
Train Epoch: 1612 [81920/90000 (91%)]	Loss: -19.8306	Cost: 5.91s
Train Epoch: 1612 	Average Loss: -19.0411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9843

Learning rate: 0.0001998717943973357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1613 [0/90000 (0%)]	Loss: -13.3036	Cost: 22.26s
Train Epoch: 1613 [20480/90000 (23%)]	Loss: -20.2942	Cost: 6.05s
Train Epoch: 1613 [40960/90000 (45%)]	Loss: -19.4659	Cost: 8.15s
Train Epoch: 1613 [61440/90000 (68%)]	Loss: -20.0350	Cost: 6.36s
Train Epoch: 1613 [81920/90000 (91%)]	Loss: -20.1854	Cost: 11.37s
Train Epoch: 1613 	Average Loss: -19.5261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1217

Saving model as e1613_model.pt & e1613_waveforms_supplementary.hdf5
Learning rate: 0.0001998716353180247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1614 [0/90000 (0%)]	Loss: -12.6867	Cost: 26.21s
Train Epoch: 1614 [20480/90000 (23%)]	Loss: -19.9695	Cost: 6.32s
Train Epoch: 1614 [40960/90000 (45%)]	Loss: -19.6051	Cost: 10.84s
Train Epoch: 1614 [61440/90000 (68%)]	Loss: -19.8734	Cost: 5.74s
Train Epoch: 1614 [81920/90000 (91%)]	Loss: -19.8401	Cost: 7.59s
Train Epoch: 1614 	Average Loss: -19.4085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7931

Learning rate: 0.00019987147614014433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1615 [0/90000 (0%)]	Loss: -11.6163	Cost: 26.59s
Train Epoch: 1615 [20480/90000 (23%)]	Loss: -19.9613	Cost: 6.11s
Train Epoch: 1615 [40960/90000 (45%)]	Loss: -19.4808	Cost: 8.38s
Train Epoch: 1615 [61440/90000 (68%)]	Loss: -19.8348	Cost: 6.05s
Train Epoch: 1615 [81920/90000 (91%)]	Loss: -19.9427	Cost: 8.37s
Train Epoch: 1615 	Average Loss: -19.3475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9107

Learning rate: 0.0001998713168636948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1616 [0/90000 (0%)]	Loss: -12.7735	Cost: 23.29s
Train Epoch: 1616 [20480/90000 (23%)]	Loss: -20.0033	Cost: 6.11s
Train Epoch: 1616 [40960/90000 (45%)]	Loss: -19.4149	Cost: 7.11s
Train Epoch: 1616 [61440/90000 (68%)]	Loss: -19.8860	Cost: 6.17s
Train Epoch: 1616 [81920/90000 (91%)]	Loss: -20.0095	Cost: 10.63s
Train Epoch: 1616 	Average Loss: -19.4158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0229

Learning rate: 0.00019987115748867622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1617 [0/90000 (0%)]	Loss: -13.7612	Cost: 24.34s
Train Epoch: 1617 [20480/90000 (23%)]	Loss: -19.9001	Cost: 6.20s
Train Epoch: 1617 [40960/90000 (45%)]	Loss: -19.6492	Cost: 11.25s
Train Epoch: 1617 [61440/90000 (68%)]	Loss: -19.8736	Cost: 6.22s
Train Epoch: 1617 [81920/90000 (91%)]	Loss: -20.0211	Cost: 9.69s
Train Epoch: 1617 	Average Loss: -19.4512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9566

Learning rate: 0.00019987099801508875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1618 [0/90000 (0%)]	Loss: -13.5361	Cost: 26.64s
Train Epoch: 1618 [20480/90000 (23%)]	Loss: -20.2152	Cost: 6.24s
Train Epoch: 1618 [40960/90000 (45%)]	Loss: -19.7025	Cost: 7.66s
Train Epoch: 1618 [61440/90000 (68%)]	Loss: -20.1165	Cost: 6.04s
Train Epoch: 1618 [81920/90000 (91%)]	Loss: -20.0927	Cost: 8.96s
Train Epoch: 1618 	Average Loss: -19.5867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0047

Learning rate: 0.00019987083844293254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1619 [0/90000 (0%)]	Loss: -12.3257	Cost: 24.07s
Train Epoch: 1619 [20480/90000 (23%)]	Loss: -20.1721	Cost: 6.29s
Train Epoch: 1619 [40960/90000 (45%)]	Loss: -19.8986	Cost: 6.64s
Train Epoch: 1619 [61440/90000 (68%)]	Loss: -19.9264	Cost: 6.02s
Train Epoch: 1619 [81920/90000 (91%)]	Loss: -20.1880	Cost: 7.65s
Train Epoch: 1619 	Average Loss: -19.5742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0290

Learning rate: 0.00019987067877220776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1620 [0/90000 (0%)]	Loss: -13.6207	Cost: 23.02s
Train Epoch: 1620 [20480/90000 (23%)]	Loss: -20.3220	Cost: 6.31s
Train Epoch: 1620 [40960/90000 (45%)]	Loss: -19.6115	Cost: 12.06s
Train Epoch: 1620 [61440/90000 (68%)]	Loss: -19.9355	Cost: 6.34s
Train Epoch: 1620 [81920/90000 (91%)]	Loss: -20.1007	Cost: 11.20s
Train Epoch: 1620 	Average Loss: -19.5283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0652

Learning rate: 0.0001998705190029146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1621 [0/90000 (0%)]	Loss: -12.4988	Cost: 27.65s
Train Epoch: 1621 [20480/90000 (23%)]	Loss: -19.9912	Cost: 6.27s
Train Epoch: 1621 [40960/90000 (45%)]	Loss: -19.3835	Cost: 8.02s
Train Epoch: 1621 [61440/90000 (68%)]	Loss: -19.8880	Cost: 6.01s
Train Epoch: 1621 [81920/90000 (91%)]	Loss: -20.0724	Cost: 8.82s
Train Epoch: 1621 	Average Loss: -19.4112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0562

Learning rate: 0.0001998703591350532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1622 [0/90000 (0%)]	Loss: -12.8862	Cost: 23.76s
Train Epoch: 1622 [20480/90000 (23%)]	Loss: -20.2305	Cost: 6.08s
Train Epoch: 1622 [40960/90000 (45%)]	Loss: -19.5336	Cost: 7.55s
Train Epoch: 1622 [61440/90000 (68%)]	Loss: -19.8295	Cost: 5.81s
Train Epoch: 1622 [81920/90000 (91%)]	Loss: -19.9053	Cost: 6.62s
Train Epoch: 1622 	Average Loss: -19.4627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8123

Learning rate: 0.0001998701991686237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1623 [0/90000 (0%)]	Loss: -13.4091	Cost: 22.81s
Train Epoch: 1623 [20480/90000 (23%)]	Loss: -20.1220	Cost: 6.25s
Train Epoch: 1623 [40960/90000 (45%)]	Loss: -19.3345	Cost: 11.02s
Train Epoch: 1623 [61440/90000 (68%)]	Loss: -19.8724	Cost: 6.38s
Train Epoch: 1623 [81920/90000 (91%)]	Loss: -19.9380	Cost: 11.15s
Train Epoch: 1623 	Average Loss: -19.4437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0799

Learning rate: 0.00019987003910362623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1624 [0/90000 (0%)]	Loss: -13.6631	Cost: 27.46s
Train Epoch: 1624 [20480/90000 (23%)]	Loss: -20.2227	Cost: 6.28s
Train Epoch: 1624 [40960/90000 (45%)]	Loss: -19.5343	Cost: 9.83s
Train Epoch: 1624 [61440/90000 (68%)]	Loss: -20.0717	Cost: 5.76s
Train Epoch: 1624 [81920/90000 (91%)]	Loss: -19.7787	Cost: 6.08s
Train Epoch: 1624 	Average Loss: -19.5673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6979

Learning rate: 0.000199869878940061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1625 [0/90000 (0%)]	Loss: -12.1082	Cost: 27.01s
Train Epoch: 1625 [20480/90000 (23%)]	Loss: -19.7434	Cost: 6.10s
Train Epoch: 1625 [40960/90000 (45%)]	Loss: -19.4446	Cost: 8.16s
Train Epoch: 1625 [61440/90000 (68%)]	Loss: -19.7738	Cost: 6.03s
Train Epoch: 1625 [81920/90000 (91%)]	Loss: -19.9446	Cost: 6.34s
Train Epoch: 1625 	Average Loss: -19.2495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0583

Learning rate: 0.00019986971867792816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1626 [0/90000 (0%)]	Loss: -13.5205	Cost: 23.64s
Train Epoch: 1626 [20480/90000 (23%)]	Loss: -20.0993	Cost: 6.09s
Train Epoch: 1626 [40960/90000 (45%)]	Loss: -19.5010	Cost: 7.42s
Train Epoch: 1626 [61440/90000 (68%)]	Loss: -20.1105	Cost: 6.21s
Train Epoch: 1626 [81920/90000 (91%)]	Loss: -20.0600	Cost: 11.09s
Train Epoch: 1626 	Average Loss: -19.4977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0433

Learning rate: 0.00019986955831722782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1627 [0/90000 (0%)]	Loss: -13.3194	Cost: 23.67s
Train Epoch: 1627 [20480/90000 (23%)]	Loss: -20.1550	Cost: 6.15s
Train Epoch: 1627 [40960/90000 (45%)]	Loss: -19.5865	Cost: 11.14s
Train Epoch: 1627 [61440/90000 (68%)]	Loss: -19.9428	Cost: 6.31s
Train Epoch: 1627 [81920/90000 (91%)]	Loss: -19.9059	Cost: 10.05s
Train Epoch: 1627 	Average Loss: -19.5608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8060

Learning rate: 0.0001998693978579602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1628 [0/90000 (0%)]	Loss: -12.8814	Cost: 26.95s
Train Epoch: 1628 [20480/90000 (23%)]	Loss: -19.8877	Cost: 6.23s
Train Epoch: 1628 [40960/90000 (45%)]	Loss: -19.3781	Cost: 8.91s
Train Epoch: 1628 [61440/90000 (68%)]	Loss: -19.8903	Cost: 5.97s
Train Epoch: 1628 [81920/90000 (91%)]	Loss: -19.9737	Cost: 8.64s
Train Epoch: 1628 	Average Loss: -19.4110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9758

Learning rate: 0.00019986923730012544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1629 [0/90000 (0%)]	Loss: -13.2954	Cost: 23.85s
Train Epoch: 1629 [20480/90000 (23%)]	Loss: -20.1911	Cost: 6.10s
Train Epoch: 1629 [40960/90000 (45%)]	Loss: -19.6900	Cost: 8.21s
Train Epoch: 1629 [61440/90000 (68%)]	Loss: -19.8405	Cost: 5.93s
Train Epoch: 1629 [81920/90000 (91%)]	Loss: -19.2631	Cost: 6.38s
Train Epoch: 1629 	Average Loss: -19.3468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2595

Learning rate: 0.00019986907664372368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1630 [0/90000 (0%)]	Loss: -10.9041	Cost: 22.32s
Train Epoch: 1630 [20480/90000 (23%)]	Loss: -19.4791	Cost: 6.25s
Train Epoch: 1630 [40960/90000 (45%)]	Loss: -19.0814	Cost: 8.77s
Train Epoch: 1630 [61440/90000 (68%)]	Loss: -19.3433	Cost: 6.15s
Train Epoch: 1630 [81920/90000 (91%)]	Loss: -19.7837	Cost: 11.63s
Train Epoch: 1630 	Average Loss: -18.9184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9767

Learning rate: 0.0001998689158887551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1631 [0/90000 (0%)]	Loss: -12.0942	Cost: 26.74s
Train Epoch: 1631 [20480/90000 (23%)]	Loss: -20.0021	Cost: 6.22s
Train Epoch: 1631 [40960/90000 (45%)]	Loss: -19.8448	Cost: 10.68s
Train Epoch: 1631 [61440/90000 (68%)]	Loss: -20.0554	Cost: 5.82s
Train Epoch: 1631 [81920/90000 (91%)]	Loss: -20.0967	Cost: 6.75s
Train Epoch: 1631 	Average Loss: -19.4735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1166

Learning rate: 0.00019986875503521986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1632 [0/90000 (0%)]	Loss: -13.3570	Cost: 25.70s
Train Epoch: 1632 [20480/90000 (23%)]	Loss: -20.1428	Cost: 6.10s
Train Epoch: 1632 [40960/90000 (45%)]	Loss: -19.4434	Cost: 7.31s
Train Epoch: 1632 [61440/90000 (68%)]	Loss: -19.8106	Cost: 6.00s
Train Epoch: 1632 [81920/90000 (91%)]	Loss: -20.1701	Cost: 6.94s
Train Epoch: 1632 	Average Loss: -19.5146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1832

Saving model as e1632_model.pt & e1632_waveforms_supplementary.hdf5
Learning rate: 0.0001998685940831181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1633 [0/90000 (0%)]	Loss: -13.6164	Cost: 23.25s
Train Epoch: 1633 [20480/90000 (23%)]	Loss: -20.1774	Cost: 6.08s
Train Epoch: 1633 [40960/90000 (45%)]	Loss: -19.6467	Cost: 7.19s
Train Epoch: 1633 [61440/90000 (68%)]	Loss: -19.9297	Cost: 6.14s
Train Epoch: 1633 [81920/90000 (91%)]	Loss: -19.9934	Cost: 9.35s
Train Epoch: 1633 	Average Loss: -19.5310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1097

Learning rate: 0.00019986843303245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1634 [0/90000 (0%)]	Loss: -13.2164	Cost: 23.48s
Train Epoch: 1634 [20480/90000 (23%)]	Loss: -20.2277	Cost: 6.22s
Train Epoch: 1634 [40960/90000 (45%)]	Loss: -19.6334	Cost: 11.08s
Train Epoch: 1634 [61440/90000 (68%)]	Loss: -20.1520	Cost: 6.15s
Train Epoch: 1634 [81920/90000 (91%)]	Loss: -20.1379	Cost: 10.78s
Train Epoch: 1634 	Average Loss: -19.6158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2159

Saving model as e1634_model.pt & e1634_waveforms_supplementary.hdf5
Learning rate: 0.00019986827188321572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1635 [0/90000 (0%)]	Loss: -13.6917	Cost: 26.82s
Train Epoch: 1635 [20480/90000 (23%)]	Loss: -20.1051	Cost: 6.25s
Train Epoch: 1635 [40960/90000 (45%)]	Loss: -19.7317	Cost: 8.71s
Train Epoch: 1635 [61440/90000 (68%)]	Loss: -19.8455	Cost: 5.98s
Train Epoch: 1635 [81920/90000 (91%)]	Loss: -20.0806	Cost: 8.78s
Train Epoch: 1635 	Average Loss: -19.5559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8636

Learning rate: 0.00019986811063541537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1636 [0/90000 (0%)]	Loss: -13.0067	Cost: 23.85s
Train Epoch: 1636 [20480/90000 (23%)]	Loss: -19.9058	Cost: 6.06s
Train Epoch: 1636 [40960/90000 (45%)]	Loss: -19.3005	Cost: 7.37s
Train Epoch: 1636 [61440/90000 (68%)]	Loss: -19.9277	Cost: 5.93s
Train Epoch: 1636 [81920/90000 (91%)]	Loss: -19.8560	Cost: 6.03s
Train Epoch: 1636 	Average Loss: -19.2693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9288

Learning rate: 0.00019986794928904917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1637 [0/90000 (0%)]	Loss: -13.5208	Cost: 23.15s
Train Epoch: 1637 [20480/90000 (23%)]	Loss: -20.0891	Cost: 6.39s
Train Epoch: 1637 [40960/90000 (45%)]	Loss: -19.6559	Cost: 11.29s
Train Epoch: 1637 [61440/90000 (68%)]	Loss: -20.0733	Cost: 6.28s
Train Epoch: 1637 [81920/90000 (91%)]	Loss: -20.1457	Cost: 11.22s
Train Epoch: 1637 	Average Loss: -19.5398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1051

Learning rate: 0.00019986778784411726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1638 [0/90000 (0%)]	Loss: -14.3592	Cost: 27.40s
Train Epoch: 1638 [20480/90000 (23%)]	Loss: -17.9650	Cost: 6.30s
Train Epoch: 1638 [40960/90000 (45%)]	Loss: -17.1946	Cost: 8.54s
Train Epoch: 1638 [61440/90000 (68%)]	Loss: -17.8873	Cost: 6.05s
Train Epoch: 1638 [81920/90000 (91%)]	Loss: -18.5588	Cost: 8.66s
Train Epoch: 1638 	Average Loss: -17.7830
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9901

Learning rate: 0.00019986762630061977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1639 [0/90000 (0%)]	Loss: -12.1963	Cost: 24.01s
Train Epoch: 1639 [20480/90000 (23%)]	Loss: -19.2883	Cost: 6.02s
Train Epoch: 1639 [40960/90000 (45%)]	Loss: -19.1376	Cost: 8.14s
Train Epoch: 1639 [61440/90000 (68%)]	Loss: -19.6229	Cost: 5.74s
Train Epoch: 1639 [81920/90000 (91%)]	Loss: -19.9757	Cost: 6.19s
Train Epoch: 1639 	Average Loss: -18.9887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9378

Learning rate: 0.0001998674646585569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1640 [0/90000 (0%)]	Loss: -13.6947	Cost: 22.82s
Train Epoch: 1640 [20480/90000 (23%)]	Loss: -20.1794	Cost: 5.99s
Train Epoch: 1640 [40960/90000 (45%)]	Loss: -19.4323	Cost: 8.53s
Train Epoch: 1640 [61440/90000 (68%)]	Loss: -19.7714	Cost: 6.20s
Train Epoch: 1640 [81920/90000 (91%)]	Loss: -19.8048	Cost: 12.01s
Train Epoch: 1640 	Average Loss: -19.3867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1249

Learning rate: 0.00019986730291792875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1641 [0/90000 (0%)]	Loss: -13.7028	Cost: 26.21s
Train Epoch: 1641 [20480/90000 (23%)]	Loss: -20.2231	Cost: 6.48s
Train Epoch: 1641 [40960/90000 (45%)]	Loss: -19.7614	Cost: 10.85s
Train Epoch: 1641 [61440/90000 (68%)]	Loss: -20.1068	Cost: 5.74s
Train Epoch: 1641 [81920/90000 (91%)]	Loss: -20.2225	Cost: 7.38s
Train Epoch: 1641 	Average Loss: -19.7084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3029

Saving model as e1641_model.pt & e1641_waveforms_supplementary.hdf5
Learning rate: 0.00019986714107873558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1642 [0/90000 (0%)]	Loss: -14.1043	Cost: 26.86s
Train Epoch: 1642 [20480/90000 (23%)]	Loss: -20.3655	Cost: 6.08s
Train Epoch: 1642 [40960/90000 (45%)]	Loss: -19.8576	Cost: 7.31s
Train Epoch: 1642 [61440/90000 (68%)]	Loss: -20.0374	Cost: 5.99s
Train Epoch: 1642 [81920/90000 (91%)]	Loss: -19.6893	Cost: 7.87s
Train Epoch: 1642 	Average Loss: -19.6402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8005

Learning rate: 0.00019986697914097749
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1643 [0/90000 (0%)]	Loss: -13.4188	Cost: 23.47s
Train Epoch: 1643 [20480/90000 (23%)]	Loss: -19.7016	Cost: 6.12s
Train Epoch: 1643 [40960/90000 (45%)]	Loss: -19.1409	Cost: 6.85s
Train Epoch: 1643 [61440/90000 (68%)]	Loss: -19.6379	Cost: 6.22s
Train Epoch: 1643 [81920/90000 (91%)]	Loss: -19.9459	Cost: 7.88s
Train Epoch: 1643 	Average Loss: -19.1148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8957

Learning rate: 0.0001998668171046546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1644 [0/90000 (0%)]	Loss: -13.7361	Cost: 23.28s
Train Epoch: 1644 [20480/90000 (23%)]	Loss: -19.9224	Cost: 6.23s
Train Epoch: 1644 [40960/90000 (45%)]	Loss: -19.6221	Cost: 11.45s
Train Epoch: 1644 [61440/90000 (68%)]	Loss: -20.2316	Cost: 6.21s
Train Epoch: 1644 [81920/90000 (91%)]	Loss: -20.0898	Cost: 10.63s
Train Epoch: 1644 	Average Loss: -19.6138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1095

Learning rate: 0.00019986665496976716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1645 [0/90000 (0%)]	Loss: -12.8594	Cost: 27.21s
Train Epoch: 1645 [20480/90000 (23%)]	Loss: -20.3788	Cost: 6.34s
Train Epoch: 1645 [40960/90000 (45%)]	Loss: -19.7187	Cost: 8.93s
Train Epoch: 1645 [61440/90000 (68%)]	Loss: -20.4361	Cost: 5.94s
Train Epoch: 1645 [81920/90000 (91%)]	Loss: -20.3477	Cost: 7.21s
Train Epoch: 1645 	Average Loss: -19.7949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4021

Saving model as e1645_model.pt & e1645_waveforms_supplementary.hdf5
Learning rate: 0.00019986649273631525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1646 [0/90000 (0%)]	Loss: -14.1289	Cost: 23.96s
Train Epoch: 1646 [20480/90000 (23%)]	Loss: -20.3196	Cost: 6.09s
Train Epoch: 1646 [40960/90000 (45%)]	Loss: -19.8243	Cost: 7.84s
Train Epoch: 1646 [61440/90000 (68%)]	Loss: -20.0876	Cost: 5.80s
Train Epoch: 1646 [81920/90000 (91%)]	Loss: -20.0683	Cost: 6.18s
Train Epoch: 1646 	Average Loss: -19.6544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2127

Learning rate: 0.00019986633040429907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1647 [0/90000 (0%)]	Loss: -13.5581	Cost: 22.45s
Train Epoch: 1647 [20480/90000 (23%)]	Loss: -20.2522	Cost: 6.04s
Train Epoch: 1647 [40960/90000 (45%)]	Loss: -19.7324	Cost: 8.73s
Train Epoch: 1647 [61440/90000 (68%)]	Loss: -20.1216	Cost: 6.17s
Train Epoch: 1647 [81920/90000 (91%)]	Loss: -20.1040	Cost: 11.47s
Train Epoch: 1647 	Average Loss: -19.6446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0133

Learning rate: 0.0001998661679737188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1648 [0/90000 (0%)]	Loss: -12.8831	Cost: 27.05s
Train Epoch: 1648 [20480/90000 (23%)]	Loss: -20.1332	Cost: 6.41s
Train Epoch: 1648 [40960/90000 (45%)]	Loss: -19.6683	Cost: 11.04s
Train Epoch: 1648 [61440/90000 (68%)]	Loss: -20.1028	Cost: 5.74s
Train Epoch: 1648 [81920/90000 (91%)]	Loss: -20.2672	Cost: 7.01s
Train Epoch: 1648 	Average Loss: -19.5913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3249

Learning rate: 0.00019986600544457455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1649 [0/90000 (0%)]	Loss: -13.4324	Cost: 26.46s
Train Epoch: 1649 [20480/90000 (23%)]	Loss: -20.4032	Cost: 6.17s
Train Epoch: 1649 [40960/90000 (45%)]	Loss: -19.8139	Cost: 7.30s
Train Epoch: 1649 [61440/90000 (68%)]	Loss: -20.1985	Cost: 6.02s
Train Epoch: 1649 [81920/90000 (91%)]	Loss: -20.2960	Cost: 8.06s
Train Epoch: 1649 	Average Loss: -19.7929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1863

Learning rate: 0.0001998658428168665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1650 [0/90000 (0%)]	Loss: -14.2391	Cost: 23.48s
Train Epoch: 1650 [20480/90000 (23%)]	Loss: -20.4387	Cost: 6.09s
Train Epoch: 1650 [40960/90000 (45%)]	Loss: -19.8096	Cost: 7.93s
Train Epoch: 1650 [61440/90000 (68%)]	Loss: -20.0872	Cost: 5.89s
Train Epoch: 1650 [81920/90000 (91%)]	Loss: -20.1738	Cost: 7.67s
Train Epoch: 1650 	Average Loss: -19.7955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2990

Learning rate: 0.00019986568009059481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1651 [0/90000 (0%)]	Loss: -13.6324	Cost: 22.53s
Train Epoch: 1651 [20480/90000 (23%)]	Loss: -20.4135	Cost: 6.21s
Train Epoch: 1651 [40960/90000 (45%)]	Loss: -20.0711	Cost: 11.22s
Train Epoch: 1651 [61440/90000 (68%)]	Loss: -20.3600	Cost: 6.31s
Train Epoch: 1651 [81920/90000 (91%)]	Loss: -20.4872	Cost: 10.78s
Train Epoch: 1651 	Average Loss: -19.7769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3088

Learning rate: 0.00019986551726575966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1652 [0/90000 (0%)]	Loss: -13.7648	Cost: 27.40s
Train Epoch: 1652 [20480/90000 (23%)]	Loss: -20.2832	Cost: 6.27s
Train Epoch: 1652 [40960/90000 (45%)]	Loss: -19.9574	Cost: 9.49s
Train Epoch: 1652 [61440/90000 (68%)]	Loss: -20.0671	Cost: 5.98s
Train Epoch: 1652 [81920/90000 (91%)]	Loss: -19.9612	Cost: 6.56s
Train Epoch: 1652 	Average Loss: -19.7206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0364

Learning rate: 0.00019986535434236117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1653 [0/90000 (0%)]	Loss: -13.1790	Cost: 24.64s
Train Epoch: 1653 [20480/90000 (23%)]	Loss: -20.2982	Cost: 6.10s
Train Epoch: 1653 [40960/90000 (45%)]	Loss: -19.8402	Cost: 7.93s
Train Epoch: 1653 [61440/90000 (68%)]	Loss: -20.1738	Cost: 5.86s
Train Epoch: 1653 [81920/90000 (91%)]	Loss: -20.2932	Cost: 6.74s
Train Epoch: 1653 	Average Loss: -19.6902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2257

Learning rate: 0.00019986519132039954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1654 [0/90000 (0%)]	Loss: -13.7891	Cost: 23.43s
Train Epoch: 1654 [20480/90000 (23%)]	Loss: -20.1137	Cost: 6.11s
Train Epoch: 1654 [40960/90000 (45%)]	Loss: -19.6763	Cost: 8.46s
Train Epoch: 1654 [61440/90000 (68%)]	Loss: -19.9259	Cost: 6.23s
Train Epoch: 1654 [81920/90000 (91%)]	Loss: -20.1927	Cost: 12.56s
Train Epoch: 1654 	Average Loss: -19.5536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1194

Learning rate: 0.00019986502819987491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1655 [0/90000 (0%)]	Loss: -13.1005	Cost: 26.58s
Train Epoch: 1655 [20480/90000 (23%)]	Loss: -20.3830	Cost: 6.43s
Train Epoch: 1655 [40960/90000 (45%)]	Loss: -19.6862	Cost: 11.57s
Train Epoch: 1655 [61440/90000 (68%)]	Loss: -20.1993	Cost: 6.02s
Train Epoch: 1655 [81920/90000 (91%)]	Loss: -20.2412	Cost: 7.88s
Train Epoch: 1655 	Average Loss: -19.6917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2552

Learning rate: 0.00019986486498078747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1656 [0/90000 (0%)]	Loss: -12.5456	Cost: 26.23s
Train Epoch: 1656 [20480/90000 (23%)]	Loss: -20.0783	Cost: 6.15s
Train Epoch: 1656 [40960/90000 (45%)]	Loss: -19.6821	Cost: 7.91s
Train Epoch: 1656 [61440/90000 (68%)]	Loss: -19.8902	Cost: 5.98s
Train Epoch: 1656 [81920/90000 (91%)]	Loss: -20.2967	Cost: 8.24s
Train Epoch: 1656 	Average Loss: -19.4841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1215

Learning rate: 0.00019986470166313735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1657 [0/90000 (0%)]	Loss: -12.8175	Cost: 23.48s
Train Epoch: 1657 [20480/90000 (23%)]	Loss: -20.2103	Cost: 6.07s
Train Epoch: 1657 [40960/90000 (45%)]	Loss: -19.6527	Cost: 7.46s
Train Epoch: 1657 [61440/90000 (68%)]	Loss: -19.9840	Cost: 6.03s
Train Epoch: 1657 [81920/90000 (91%)]	Loss: -20.0929	Cost: 8.26s
Train Epoch: 1657 	Average Loss: -19.5847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1458

Learning rate: 0.00019986453824692474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1658 [0/90000 (0%)]	Loss: -13.9628	Cost: 23.19s
Train Epoch: 1658 [20480/90000 (23%)]	Loss: -20.0876	Cost: 6.24s
Train Epoch: 1658 [40960/90000 (45%)]	Loss: -19.8335	Cost: 11.07s
Train Epoch: 1658 [61440/90000 (68%)]	Loss: -20.3251	Cost: 6.27s
Train Epoch: 1658 [81920/90000 (91%)]	Loss: -20.2016	Cost: 11.03s
Train Epoch: 1658 	Average Loss: -19.7172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2396

Learning rate: 0.00019986437473214973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1659 [0/90000 (0%)]	Loss: -13.6998	Cost: 26.61s
Train Epoch: 1659 [20480/90000 (23%)]	Loss: -20.4629	Cost: 6.35s
Train Epoch: 1659 [40960/90000 (45%)]	Loss: -19.7057	Cost: 8.68s
Train Epoch: 1659 [61440/90000 (68%)]	Loss: -20.1850	Cost: 6.01s
Train Epoch: 1659 [81920/90000 (91%)]	Loss: -19.8201	Cost: 8.33s
Train Epoch: 1659 	Average Loss: -19.6866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0308

Learning rate: 0.00019986421111881257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1660 [0/90000 (0%)]	Loss: -13.2322	Cost: 23.76s
Train Epoch: 1660 [20480/90000 (23%)]	Loss: -19.8007	Cost: 6.09s
Train Epoch: 1660 [40960/90000 (45%)]	Loss: -19.4702	Cost: 8.13s
Train Epoch: 1660 [61440/90000 (68%)]	Loss: -19.5117	Cost: 5.74s
Train Epoch: 1660 [81920/90000 (91%)]	Loss: -19.6141	Cost: 6.82s
Train Epoch: 1660 	Average Loss: -19.2110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7491

Learning rate: 0.00019986404740691337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1661 [0/90000 (0%)]	Loss: -13.6469	Cost: 22.16s
Train Epoch: 1661 [20480/90000 (23%)]	Loss: -20.1420	Cost: 6.29s
Train Epoch: 1661 [40960/90000 (45%)]	Loss: -19.6789	Cost: 11.03s
Train Epoch: 1661 [61440/90000 (68%)]	Loss: -20.1995	Cost: 6.45s
Train Epoch: 1661 [81920/90000 (91%)]	Loss: -20.2102	Cost: 11.37s
Train Epoch: 1661 	Average Loss: -19.5125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3480

Learning rate: 0.00019986388359645232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1662 [0/90000 (0%)]	Loss: -13.5274	Cost: 26.72s
Train Epoch: 1662 [20480/90000 (23%)]	Loss: -20.4173	Cost: 6.38s
Train Epoch: 1662 [40960/90000 (45%)]	Loss: -19.8130	Cost: 9.34s
Train Epoch: 1662 [61440/90000 (68%)]	Loss: -20.1857	Cost: 5.90s
Train Epoch: 1662 [81920/90000 (91%)]	Loss: -20.3535	Cost: 8.60s
Train Epoch: 1662 	Average Loss: -19.7660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0621

Learning rate: 0.00019986371968742957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1663 [0/90000 (0%)]	Loss: -13.9606	Cost: 24.15s
Train Epoch: 1663 [20480/90000 (23%)]	Loss: -20.2941	Cost: 6.06s
Train Epoch: 1663 [40960/90000 (45%)]	Loss: -19.6499	Cost: 8.39s
Train Epoch: 1663 [61440/90000 (68%)]	Loss: -19.9373	Cost: 5.76s
Train Epoch: 1663 [81920/90000 (91%)]	Loss: -20.0932	Cost: 6.08s
Train Epoch: 1663 	Average Loss: -19.7052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0472

Learning rate: 0.00019986355567984526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1664 [0/90000 (0%)]	Loss: -13.9230	Cost: 22.41s
Train Epoch: 1664 [20480/90000 (23%)]	Loss: -20.6476	Cost: 6.06s
Train Epoch: 1664 [40960/90000 (45%)]	Loss: -19.9505	Cost: 7.14s
Train Epoch: 1664 [61440/90000 (68%)]	Loss: -20.3585	Cost: 6.16s
Train Epoch: 1664 [81920/90000 (91%)]	Loss: -20.3023	Cost: 11.60s
Train Epoch: 1664 	Average Loss: -19.7667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3410

Learning rate: 0.00019986339157369957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1665 [0/90000 (0%)]	Loss: -13.3172	Cost: 25.31s
Train Epoch: 1665 [20480/90000 (23%)]	Loss: -20.4064	Cost: 6.36s
Train Epoch: 1665 [40960/90000 (45%)]	Loss: -19.9845	Cost: 10.98s
Train Epoch: 1665 [61440/90000 (68%)]	Loss: -20.2464	Cost: 6.17s
Train Epoch: 1665 [81920/90000 (91%)]	Loss: -20.1702	Cost: 8.14s
Train Epoch: 1665 	Average Loss: -19.7219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1160

Learning rate: 0.00019986322736899266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1666 [0/90000 (0%)]	Loss: -12.9614	Cost: 26.39s
Train Epoch: 1666 [20480/90000 (23%)]	Loss: -20.4364	Cost: 6.20s
Train Epoch: 1666 [40960/90000 (45%)]	Loss: -19.9180	Cost: 8.07s
Train Epoch: 1666 [61440/90000 (68%)]	Loss: -20.0971	Cost: 6.02s
Train Epoch: 1666 [81920/90000 (91%)]	Loss: -20.2560	Cost: 8.81s
Train Epoch: 1666 	Average Loss: -19.7571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9727

Learning rate: 0.00019986306306572473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1667 [0/90000 (0%)]	Loss: -13.2885	Cost: 23.46s
Train Epoch: 1667 [20480/90000 (23%)]	Loss: -20.2383	Cost: 6.14s
Train Epoch: 1667 [40960/90000 (45%)]	Loss: -19.6575	Cost: 7.51s
Train Epoch: 1667 [61440/90000 (68%)]	Loss: -20.3040	Cost: 6.03s
Train Epoch: 1667 [81920/90000 (91%)]	Loss: -20.2185	Cost: 7.68s
Train Epoch: 1667 	Average Loss: -19.6840
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1440

Learning rate: 0.00019986289866389585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1668 [0/90000 (0%)]	Loss: -13.6201	Cost: 22.54s
Train Epoch: 1668 [20480/90000 (23%)]	Loss: -20.3548	Cost: 6.23s
Train Epoch: 1668 [40960/90000 (45%)]	Loss: -20.1090	Cost: 11.51s
Train Epoch: 1668 [61440/90000 (68%)]	Loss: -20.1101	Cost: 6.23s
Train Epoch: 1668 [81920/90000 (91%)]	Loss: -20.2258	Cost: 11.25s
Train Epoch: 1668 	Average Loss: -19.7852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2768

Learning rate: 0.00019986273416350628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1669 [0/90000 (0%)]	Loss: -13.1133	Cost: 27.92s
Train Epoch: 1669 [20480/90000 (23%)]	Loss: -20.3710	Cost: 6.30s
Train Epoch: 1669 [40960/90000 (45%)]	Loss: -19.8772	Cost: 9.04s
Train Epoch: 1669 [61440/90000 (68%)]	Loss: -20.3828	Cost: 6.08s
Train Epoch: 1669 [81920/90000 (91%)]	Loss: -20.0515	Cost: 7.86s
Train Epoch: 1669 	Average Loss: -19.7435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9358

Learning rate: 0.00019986256956455614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1670 [0/90000 (0%)]	Loss: -13.5328	Cost: 24.03s
Train Epoch: 1670 [20480/90000 (23%)]	Loss: -20.1841	Cost: 6.08s
Train Epoch: 1670 [40960/90000 (45%)]	Loss: -19.5775	Cost: 8.24s
Train Epoch: 1670 [61440/90000 (68%)]	Loss: -19.8353	Cost: 5.81s
Train Epoch: 1670 [81920/90000 (91%)]	Loss: -19.9987	Cost: 6.42s
Train Epoch: 1670 	Average Loss: -19.4807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8640

Learning rate: 0.0001998624048670456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1671 [0/90000 (0%)]	Loss: -13.4212	Cost: 23.09s
Train Epoch: 1671 [20480/90000 (23%)]	Loss: -20.4094	Cost: 6.29s
Train Epoch: 1671 [40960/90000 (45%)]	Loss: -19.7306	Cost: 9.45s
Train Epoch: 1671 [61440/90000 (68%)]	Loss: -20.0250	Cost: 6.30s
Train Epoch: 1671 [81920/90000 (91%)]	Loss: -20.2832	Cost: 11.59s
Train Epoch: 1671 	Average Loss: -19.6537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2655

Learning rate: 0.00019986224007097482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1672 [0/90000 (0%)]	Loss: -12.8292	Cost: 26.42s
Train Epoch: 1672 [20480/90000 (23%)]	Loss: -20.4621	Cost: 6.26s
Train Epoch: 1672 [40960/90000 (45%)]	Loss: -19.8154	Cost: 10.29s
Train Epoch: 1672 [61440/90000 (68%)]	Loss: -20.0843	Cost: 6.21s
Train Epoch: 1672 [81920/90000 (91%)]	Loss: -20.3579	Cost: 6.01s
Train Epoch: 1672 	Average Loss: -19.6993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2162

Learning rate: 0.00019986207517634394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1673 [0/90000 (0%)]	Loss: -12.8172	Cost: 27.55s
Train Epoch: 1673 [20480/90000 (23%)]	Loss: -20.5212	Cost: 6.10s
Train Epoch: 1673 [40960/90000 (45%)]	Loss: -19.9659	Cost: 8.20s
Train Epoch: 1673 [61440/90000 (68%)]	Loss: -20.0803	Cost: 5.86s
Train Epoch: 1673 [81920/90000 (91%)]	Loss: -20.2278	Cost: 7.00s
Train Epoch: 1673 	Average Loss: -19.7906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1652

Learning rate: 0.00019986191018315315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1674 [0/90000 (0%)]	Loss: -14.0176	Cost: 22.93s
Train Epoch: 1674 [20480/90000 (23%)]	Loss: -20.3832	Cost: 6.15s
Train Epoch: 1674 [40960/90000 (45%)]	Loss: -20.0100	Cost: 7.50s
Train Epoch: 1674 [61440/90000 (68%)]	Loss: -20.2056	Cost: 6.24s
Train Epoch: 1674 [81920/90000 (91%)]	Loss: -20.2165	Cost: 11.45s
Train Epoch: 1674 	Average Loss: -19.8615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3996

Learning rate: 0.0001998617450914026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1675 [0/90000 (0%)]	Loss: -13.7054	Cost: 26.30s
Train Epoch: 1675 [20480/90000 (23%)]	Loss: -20.3921	Cost: 6.83s
Train Epoch: 1675 [40960/90000 (45%)]	Loss: -19.9648	Cost: 11.57s
Train Epoch: 1675 [61440/90000 (68%)]	Loss: -20.4131	Cost: 6.23s
Train Epoch: 1675 [81920/90000 (91%)]	Loss: -20.4327	Cost: 8.51s
Train Epoch: 1675 	Average Loss: -19.8653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2607

Learning rate: 0.00019986157990109244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1676 [0/90000 (0%)]	Loss: -13.5530	Cost: 26.34s
Train Epoch: 1676 [20480/90000 (23%)]	Loss: -20.8676	Cost: 6.13s
Train Epoch: 1676 [40960/90000 (45%)]	Loss: -19.9883	Cost: 7.63s
Train Epoch: 1676 [61440/90000 (68%)]	Loss: -20.2519	Cost: 6.00s
Train Epoch: 1676 [81920/90000 (91%)]	Loss: -20.2625	Cost: 7.66s
Train Epoch: 1676 	Average Loss: -19.8677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3572

Learning rate: 0.00019986141461222288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1677 [0/90000 (0%)]	Loss: -13.9066	Cost: 23.63s
Train Epoch: 1677 [20480/90000 (23%)]	Loss: -20.6337	Cost: 6.12s
Train Epoch: 1677 [40960/90000 (45%)]	Loss: -19.8575	Cost: 7.33s
Train Epoch: 1677 [61440/90000 (68%)]	Loss: -20.1238	Cost: 6.04s
Train Epoch: 1677 [81920/90000 (91%)]	Loss: -19.9508	Cost: 7.87s
Train Epoch: 1677 	Average Loss: -19.8155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2969

Learning rate: 0.00019986124922479406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1678 [0/90000 (0%)]	Loss: -11.9589	Cost: 22.36s
Train Epoch: 1678 [20480/90000 (23%)]	Loss: -20.5081	Cost: 6.24s
Train Epoch: 1678 [40960/90000 (45%)]	Loss: -19.5923	Cost: 10.91s
Train Epoch: 1678 [61440/90000 (68%)]	Loss: -19.7980	Cost: 6.29s
Train Epoch: 1678 [81920/90000 (91%)]	Loss: -20.2422	Cost: 11.32s
Train Epoch: 1678 	Average Loss: -19.5826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0222

Learning rate: 0.0001998610837388061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1679 [0/90000 (0%)]	Loss: -13.6961	Cost: 29.22s
Train Epoch: 1679 [20480/90000 (23%)]	Loss: -20.3337	Cost: 6.21s
Train Epoch: 1679 [40960/90000 (45%)]	Loss: -19.9163	Cost: 9.86s
Train Epoch: 1679 [61440/90000 (68%)]	Loss: -20.0706	Cost: 5.71s
Train Epoch: 1679 [81920/90000 (91%)]	Loss: -20.3620	Cost: 6.61s
Train Epoch: 1679 	Average Loss: -19.6608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2158

Learning rate: 0.00019986091815425925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1680 [0/90000 (0%)]	Loss: -14.1713	Cost: 25.88s
Train Epoch: 1680 [20480/90000 (23%)]	Loss: -20.4003	Cost: 6.12s
Train Epoch: 1680 [40960/90000 (45%)]	Loss: -20.0022	Cost: 7.32s
Train Epoch: 1680 [61440/90000 (68%)]	Loss: -20.4019	Cost: 6.04s
Train Epoch: 1680 [81920/90000 (91%)]	Loss: -20.4729	Cost: 8.11s
Train Epoch: 1680 	Average Loss: -19.8532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5564

Saving model as e1680_model.pt & e1680_waveforms_supplementary.hdf5
Learning rate: 0.00019986075247115358
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1681 [0/90000 (0%)]	Loss: -13.4750	Cost: 23.75s
Train Epoch: 1681 [20480/90000 (23%)]	Loss: -20.5804	Cost: 6.13s
Train Epoch: 1681 [40960/90000 (45%)]	Loss: -20.2103	Cost: 7.80s
Train Epoch: 1681 [61440/90000 (68%)]	Loss: -20.3745	Cost: 6.30s
Train Epoch: 1681 [81920/90000 (91%)]	Loss: -20.6371	Cost: 11.29s
Train Epoch: 1681 	Average Loss: -20.0034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3830

Learning rate: 0.00019986058668948934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1682 [0/90000 (0%)]	Loss: -13.4278	Cost: 25.40s
Train Epoch: 1682 [20480/90000 (23%)]	Loss: -20.3768	Cost: 6.38s
Train Epoch: 1682 [40960/90000 (45%)]	Loss: -19.7366	Cost: 10.87s
Train Epoch: 1682 [61440/90000 (68%)]	Loss: -20.1262	Cost: 6.28s
Train Epoch: 1682 [81920/90000 (91%)]	Loss: -20.3030	Cost: 8.12s
Train Epoch: 1682 	Average Loss: -19.7355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2478

Learning rate: 0.00019986042080926664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1683 [0/90000 (0%)]	Loss: -13.8652	Cost: 27.08s
Train Epoch: 1683 [20480/90000 (23%)]	Loss: -19.7606	Cost: 6.27s
Train Epoch: 1683 [40960/90000 (45%)]	Loss: -19.5798	Cost: 8.06s
Train Epoch: 1683 [61440/90000 (68%)]	Loss: -20.1502	Cost: 5.98s
Train Epoch: 1683 [81920/90000 (91%)]	Loss: -20.1331	Cost: 9.08s
Train Epoch: 1683 	Average Loss: -19.5553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1895

Learning rate: 0.00019986025483048563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1684 [0/90000 (0%)]	Loss: -14.0172	Cost: 23.93s
Train Epoch: 1684 [20480/90000 (23%)]	Loss: -20.6278	Cost: 6.09s
Train Epoch: 1684 [40960/90000 (45%)]	Loss: -20.0545	Cost: 7.43s
Train Epoch: 1684 [61440/90000 (68%)]	Loss: -20.4849	Cost: 5.78s
Train Epoch: 1684 [81920/90000 (91%)]	Loss: -20.2937	Cost: 6.11s
Train Epoch: 1684 	Average Loss: -19.9002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2864

Learning rate: 0.00019986008875314652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1685 [0/90000 (0%)]	Loss: -12.4941	Cost: 22.64s
Train Epoch: 1685 [20480/90000 (23%)]	Loss: -20.2481	Cost: 6.31s
Train Epoch: 1685 [40960/90000 (45%)]	Loss: -19.9486	Cost: 11.47s
Train Epoch: 1685 [61440/90000 (68%)]	Loss: -20.4202	Cost: 6.26s
Train Epoch: 1685 [81920/90000 (91%)]	Loss: -20.4971	Cost: 11.13s
Train Epoch: 1685 	Average Loss: -19.8261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4258

Learning rate: 0.00019985992257724942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1686 [0/90000 (0%)]	Loss: -13.9792	Cost: 27.22s
Train Epoch: 1686 [20480/90000 (23%)]	Loss: -20.6115	Cost: 6.50s
Train Epoch: 1686 [40960/90000 (45%)]	Loss: -19.8271	Cost: 8.38s
Train Epoch: 1686 [61440/90000 (68%)]	Loss: -20.3749	Cost: 6.23s
Train Epoch: 1686 [81920/90000 (91%)]	Loss: -20.5596	Cost: 8.41s
Train Epoch: 1686 	Average Loss: -19.9337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3403

Learning rate: 0.00019985975630279455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1687 [0/90000 (0%)]	Loss: -14.1121	Cost: 23.63s
Train Epoch: 1687 [20480/90000 (23%)]	Loss: -20.7458	Cost: 6.07s
Train Epoch: 1687 [40960/90000 (45%)]	Loss: -20.0524	Cost: 7.66s
Train Epoch: 1687 [61440/90000 (68%)]	Loss: -20.4076	Cost: 5.77s
Train Epoch: 1687 [81920/90000 (91%)]	Loss: -20.3255	Cost: 6.30s
Train Epoch: 1687 	Average Loss: -19.9746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3088

Learning rate: 0.00019985958992978207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1688 [0/90000 (0%)]	Loss: -12.3618	Cost: 22.28s
Train Epoch: 1688 [20480/90000 (23%)]	Loss: -20.4307	Cost: 6.45s
Train Epoch: 1688 [40960/90000 (45%)]	Loss: -19.9182	Cost: 10.46s
Train Epoch: 1688 [61440/90000 (68%)]	Loss: -19.5426	Cost: 6.64s
Train Epoch: 1688 [81920/90000 (91%)]	Loss: -19.3087	Cost: 11.14s
Train Epoch: 1688 	Average Loss: -19.4863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4065

Learning rate: 0.00019985942345821208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1689 [0/90000 (0%)]	Loss: -12.3194	Cost: 28.18s
Train Epoch: 1689 [20480/90000 (23%)]	Loss: -20.0299	Cost: 6.41s
Train Epoch: 1689 [40960/90000 (45%)]	Loss: -19.5022	Cost: 9.02s
Train Epoch: 1689 [61440/90000 (68%)]	Loss: -19.9300	Cost: 6.07s
Train Epoch: 1689 [81920/90000 (91%)]	Loss: -20.2195	Cost: 8.86s
Train Epoch: 1689 	Average Loss: -19.4231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1320

Learning rate: 0.00019985925688808482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1690 [0/90000 (0%)]	Loss: -13.9369	Cost: 23.86s
Train Epoch: 1690 [20480/90000 (23%)]	Loss: -20.3132	Cost: 6.08s
Train Epoch: 1690 [40960/90000 (45%)]	Loss: -20.1379	Cost: 8.03s
Train Epoch: 1690 [61440/90000 (68%)]	Loss: -20.2922	Cost: 5.86s
Train Epoch: 1690 [81920/90000 (91%)]	Loss: -20.4305	Cost: 6.57s
Train Epoch: 1690 	Average Loss: -19.8943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1045

Learning rate: 0.00019985909021940043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1691 [0/90000 (0%)]	Loss: -13.1810	Cost: 22.96s
Train Epoch: 1691 [20480/90000 (23%)]	Loss: -20.3681	Cost: 6.23s
Train Epoch: 1691 [40960/90000 (45%)]	Loss: -19.8114	Cost: 11.15s
Train Epoch: 1691 [61440/90000 (68%)]	Loss: -20.2136	Cost: 6.30s
Train Epoch: 1691 [81920/90000 (91%)]	Loss: -20.4518	Cost: 10.88s
Train Epoch: 1691 	Average Loss: -19.8373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2727

Learning rate: 0.00019985892345215906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1692 [0/90000 (0%)]	Loss: -14.0965	Cost: 28.35s
Train Epoch: 1692 [20480/90000 (23%)]	Loss: -20.4242	Cost: 6.49s
Train Epoch: 1692 [40960/90000 (45%)]	Loss: -19.9026	Cost: 8.99s
Train Epoch: 1692 [61440/90000 (68%)]	Loss: -20.4921	Cost: 6.22s
Train Epoch: 1692 [81920/90000 (91%)]	Loss: -20.1592	Cost: 7.57s
Train Epoch: 1692 	Average Loss: -19.8151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1859

Learning rate: 0.00019985875658636091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1693 [0/90000 (0%)]	Loss: -13.9906	Cost: 24.91s
Train Epoch: 1693 [20480/90000 (23%)]	Loss: -20.5498	Cost: 6.05s
Train Epoch: 1693 [40960/90000 (45%)]	Loss: -20.0794	Cost: 7.71s
Train Epoch: 1693 [61440/90000 (68%)]	Loss: -20.3585	Cost: 5.79s
Train Epoch: 1693 [81920/90000 (91%)]	Loss: -20.5294	Cost: 6.42s
Train Epoch: 1693 	Average Loss: -20.0033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5647

Saving model as e1693_model.pt & e1693_waveforms_supplementary.hdf5
Learning rate: 0.00019985858962200608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1694 [0/90000 (0%)]	Loss: -13.8273	Cost: 22.37s
Train Epoch: 1694 [20480/90000 (23%)]	Loss: -20.5667	Cost: 6.49s
Train Epoch: 1694 [40960/90000 (45%)]	Loss: -20.1325	Cost: 11.56s
Train Epoch: 1694 [61440/90000 (68%)]	Loss: -20.4562	Cost: 6.34s
Train Epoch: 1694 [81920/90000 (91%)]	Loss: -20.2184	Cost: 11.11s
Train Epoch: 1694 	Average Loss: -19.9028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3449

Learning rate: 0.00019985842255909478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1695 [0/90000 (0%)]	Loss: -13.2630	Cost: 26.88s
Train Epoch: 1695 [20480/90000 (23%)]	Loss: -20.1813	Cost: 6.39s
Train Epoch: 1695 [40960/90000 (45%)]	Loss: -19.6881	Cost: 8.57s
Train Epoch: 1695 [61440/90000 (68%)]	Loss: -20.0549	Cost: 6.01s
Train Epoch: 1695 [81920/90000 (91%)]	Loss: -20.1477	Cost: 7.80s
Train Epoch: 1695 	Average Loss: -19.5936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2193

Learning rate: 0.0001998582553976272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1696 [0/90000 (0%)]	Loss: -13.5125	Cost: 24.81s
Train Epoch: 1696 [20480/90000 (23%)]	Loss: -20.5356	Cost: 6.33s
Train Epoch: 1696 [40960/90000 (45%)]	Loss: -20.0117	Cost: 7.56s
Train Epoch: 1696 [61440/90000 (68%)]	Loss: -20.3626	Cost: 6.00s
Train Epoch: 1696 [81920/90000 (91%)]	Loss: -20.4599	Cost: 6.37s
Train Epoch: 1696 	Average Loss: -19.8484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2787

Learning rate: 0.0001998580881376034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1697 [0/90000 (0%)]	Loss: -12.8677	Cost: 22.56s
Train Epoch: 1697 [20480/90000 (23%)]	Loss: -20.3156	Cost: 6.45s
Train Epoch: 1697 [40960/90000 (45%)]	Loss: -19.9268	Cost: 10.67s
Train Epoch: 1697 [61440/90000 (68%)]	Loss: -20.3759	Cost: 6.36s
Train Epoch: 1697 [81920/90000 (91%)]	Loss: -20.4646	Cost: 11.21s
Train Epoch: 1697 	Average Loss: -19.8312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3768

Learning rate: 0.00019985792077902367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1698 [0/90000 (0%)]	Loss: -13.9115	Cost: 27.93s
Train Epoch: 1698 [20480/90000 (23%)]	Loss: -20.2312	Cost: 6.53s
Train Epoch: 1698 [40960/90000 (45%)]	Loss: -19.9788	Cost: 8.82s
Train Epoch: 1698 [61440/90000 (68%)]	Loss: -20.1671	Cost: 6.08s
Train Epoch: 1698 [81920/90000 (91%)]	Loss: -20.2642	Cost: 7.99s
Train Epoch: 1698 	Average Loss: -19.7260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2306

Learning rate: 0.00019985775332188809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1699 [0/90000 (0%)]	Loss: -13.4899	Cost: 24.28s
Train Epoch: 1699 [20480/90000 (23%)]	Loss: -20.5751	Cost: 6.09s
Train Epoch: 1699 [40960/90000 (45%)]	Loss: -19.8925	Cost: 7.51s
Train Epoch: 1699 [61440/90000 (68%)]	Loss: -20.4332	Cost: 5.86s
Train Epoch: 1699 [81920/90000 (91%)]	Loss: -20.2479	Cost: 6.00s
Train Epoch: 1699 	Average Loss: -19.8806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3825

Learning rate: 0.0001998575857661969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1700 [0/90000 (0%)]	Loss: -13.6979	Cost: 22.05s
Train Epoch: 1700 [20480/90000 (23%)]	Loss: -20.2721	Cost: 6.33s
Train Epoch: 1700 [40960/90000 (45%)]	Loss: -19.4261	Cost: 10.84s
Train Epoch: 1700 [61440/90000 (68%)]	Loss: -19.5543	Cost: 6.61s
Train Epoch: 1700 [81920/90000 (91%)]	Loss: -19.8577	Cost: 11.17s
Train Epoch: 1700 	Average Loss: -19.3454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6275

Learning rate: 0.0001998574181119502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1701 [0/90000 (0%)]	Loss: -12.8138	Cost: 28.00s
Train Epoch: 1701 [20480/90000 (23%)]	Loss: -20.2961	Cost: 6.56s
Train Epoch: 1701 [40960/90000 (45%)]	Loss: -19.5144	Cost: 8.46s
Train Epoch: 1701 [61440/90000 (68%)]	Loss: -20.1921	Cost: 6.11s
Train Epoch: 1701 [81920/90000 (91%)]	Loss: -20.1706	Cost: 8.31s
Train Epoch: 1701 	Average Loss: -19.5552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1195

Learning rate: 0.00019985725035914822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1702 [0/90000 (0%)]	Loss: -12.6420	Cost: 25.17s
Train Epoch: 1702 [20480/90000 (23%)]	Loss: -20.4735	Cost: 6.17s
Train Epoch: 1702 [40960/90000 (45%)]	Loss: -19.7746	Cost: 7.27s
Train Epoch: 1702 [61440/90000 (68%)]	Loss: -20.1352	Cost: 5.95s
Train Epoch: 1702 [81920/90000 (91%)]	Loss: -20.3665	Cost: 6.07s
Train Epoch: 1702 	Average Loss: -19.7174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2753

Learning rate: 0.00019985708250779105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1703 [0/90000 (0%)]	Loss: -12.7236	Cost: 22.40s
Train Epoch: 1703 [20480/90000 (23%)]	Loss: -20.2404	Cost: 6.24s
Train Epoch: 1703 [40960/90000 (45%)]	Loss: -19.8840	Cost: 9.86s
Train Epoch: 1703 [61440/90000 (68%)]	Loss: -20.0232	Cost: 6.28s
Train Epoch: 1703 [81920/90000 (91%)]	Loss: -20.2780	Cost: 11.64s
Train Epoch: 1703 	Average Loss: -19.6913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2900

Learning rate: 0.00019985691455787888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1704 [0/90000 (0%)]	Loss: -14.2328	Cost: 26.83s
Train Epoch: 1704 [20480/90000 (23%)]	Loss: -20.4987	Cost: 6.27s
Train Epoch: 1704 [40960/90000 (45%)]	Loss: -20.1090	Cost: 11.89s
Train Epoch: 1704 [61440/90000 (68%)]	Loss: -20.2864	Cost: 5.86s
Train Epoch: 1704 [81920/90000 (91%)]	Loss: -20.4538	Cost: 5.95s
Train Epoch: 1704 	Average Loss: -19.9114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1715

Learning rate: 0.00019985674650941187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1705 [0/90000 (0%)]	Loss: -13.8284	Cost: 26.16s
Train Epoch: 1705 [20480/90000 (23%)]	Loss: -20.6133	Cost: 6.11s
Train Epoch: 1705 [40960/90000 (45%)]	Loss: -20.0820	Cost: 7.97s
Train Epoch: 1705 [61440/90000 (68%)]	Loss: -20.3686	Cost: 5.92s
Train Epoch: 1705 [81920/90000 (91%)]	Loss: -20.3858	Cost: 7.09s
Train Epoch: 1705 	Average Loss: -19.9604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5523

Learning rate: 0.00019985657836239023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1706 [0/90000 (0%)]	Loss: -13.4807	Cost: 23.78s
Train Epoch: 1706 [20480/90000 (23%)]	Loss: -20.3302	Cost: 6.21s
Train Epoch: 1706 [40960/90000 (45%)]	Loss: -19.8826	Cost: 7.31s
Train Epoch: 1706 [61440/90000 (68%)]	Loss: -20.2296	Cost: 6.41s
Train Epoch: 1706 [81920/90000 (91%)]	Loss: -20.4999	Cost: 11.84s
Train Epoch: 1706 	Average Loss: -19.8394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2821

Learning rate: 0.0001998564101168141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1707 [0/90000 (0%)]	Loss: -13.8909	Cost: 25.89s
Train Epoch: 1707 [20480/90000 (23%)]	Loss: -20.6372	Cost: 6.42s
Train Epoch: 1707 [40960/90000 (45%)]	Loss: -20.1368	Cost: 11.22s
Train Epoch: 1707 [61440/90000 (68%)]	Loss: -17.5416	Cost: 6.17s
Train Epoch: 1707 [81920/90000 (91%)]	Loss: -17.6168	Cost: 8.14s
Train Epoch: 1707 	Average Loss: -18.8735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1911

Learning rate: 0.00019985624177268363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1708 [0/90000 (0%)]	Loss: -11.3825	Cost: 26.40s
Train Epoch: 1708 [20480/90000 (23%)]	Loss: -18.6601	Cost: 6.36s
Train Epoch: 1708 [40960/90000 (45%)]	Loss: -18.6177	Cost: 8.24s
Train Epoch: 1708 [61440/90000 (68%)]	Loss: -19.3258	Cost: 6.19s
Train Epoch: 1708 [81920/90000 (91%)]	Loss: -19.8146	Cost: 8.43s
Train Epoch: 1708 	Average Loss: -18.5380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8663

Learning rate: 0.00019985607332999902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1709 [0/90000 (0%)]	Loss: -14.0253	Cost: 23.43s
Train Epoch: 1709 [20480/90000 (23%)]	Loss: -20.0870	Cost: 6.12s
Train Epoch: 1709 [40960/90000 (45%)]	Loss: -19.7419	Cost: 7.23s
Train Epoch: 1709 [61440/90000 (68%)]	Loss: -20.0667	Cost: 5.93s
Train Epoch: 1709 [81920/90000 (91%)]	Loss: -20.1284	Cost: 6.17s
Train Epoch: 1709 	Average Loss: -19.5997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2505

Learning rate: 0.00019985590478876038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1710 [0/90000 (0%)]	Loss: -13.6623	Cost: 22.25s
Train Epoch: 1710 [20480/90000 (23%)]	Loss: -20.6883	Cost: 6.46s
Train Epoch: 1710 [40960/90000 (45%)]	Loss: -19.8408	Cost: 10.87s
Train Epoch: 1710 [61440/90000 (68%)]	Loss: -20.0266	Cost: 6.50s
Train Epoch: 1710 [81920/90000 (91%)]	Loss: -20.1516	Cost: 11.26s
Train Epoch: 1710 	Average Loss: -19.7014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2174

Learning rate: 0.00019985573614896793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1711 [0/90000 (0%)]	Loss: -13.7253	Cost: 27.62s
Train Epoch: 1711 [20480/90000 (23%)]	Loss: -19.7260	Cost: 6.31s
Train Epoch: 1711 [40960/90000 (45%)]	Loss: -19.1025	Cost: 9.28s
Train Epoch: 1711 [61440/90000 (68%)]	Loss: -19.5079	Cost: 5.86s
Train Epoch: 1711 [81920/90000 (91%)]	Loss: -19.8215	Cost: 7.57s
Train Epoch: 1711 	Average Loss: -19.2119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0003

Learning rate: 0.00019985556741062183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1712 [0/90000 (0%)]	Loss: -13.0071	Cost: 25.95s
Train Epoch: 1712 [20480/90000 (23%)]	Loss: -20.2750	Cost: 6.06s
Train Epoch: 1712 [40960/90000 (45%)]	Loss: -19.7116	Cost: 8.48s
Train Epoch: 1712 [61440/90000 (68%)]	Loss: -20.2790	Cost: 5.94s
Train Epoch: 1712 [81920/90000 (91%)]	Loss: -20.3779	Cost: 6.57s
Train Epoch: 1712 	Average Loss: -19.6338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2437

Learning rate: 0.00019985539857372223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1713 [0/90000 (0%)]	Loss: -13.1593	Cost: 23.48s
Train Epoch: 1713 [20480/90000 (23%)]	Loss: -20.7344	Cost: 6.22s
Train Epoch: 1713 [40960/90000 (45%)]	Loss: -20.2742	Cost: 6.86s
Train Epoch: 1713 [61440/90000 (68%)]	Loss: -20.5267	Cost: 6.21s
Train Epoch: 1713 [81920/90000 (91%)]	Loss: -20.5725	Cost: 11.54s
Train Epoch: 1713 	Average Loss: -20.0390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5558

Learning rate: 0.0001998552296382693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1714 [0/90000 (0%)]	Loss: -13.7742	Cost: 25.19s
Train Epoch: 1714 [20480/90000 (23%)]	Loss: -20.9158	Cost: 6.28s
Train Epoch: 1714 [40960/90000 (45%)]	Loss: -20.3262	Cost: 11.03s
Train Epoch: 1714 [61440/90000 (68%)]	Loss: -20.5297	Cost: 6.31s
Train Epoch: 1714 [81920/90000 (91%)]	Loss: -20.7714	Cost: 8.17s
Train Epoch: 1714 	Average Loss: -20.1311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6070

Saving model as e1714_model.pt & e1714_waveforms_supplementary.hdf5
Learning rate: 0.0001998550606042632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1715 [0/90000 (0%)]	Loss: -13.6348	Cost: 26.61s
Train Epoch: 1715 [20480/90000 (23%)]	Loss: -20.8672	Cost: 6.13s
Train Epoch: 1715 [40960/90000 (45%)]	Loss: -19.7454	Cost: 7.31s
Train Epoch: 1715 [61440/90000 (68%)]	Loss: -19.9487	Cost: 6.01s
Train Epoch: 1715 [81920/90000 (91%)]	Loss: -19.9292	Cost: 8.19s
Train Epoch: 1715 	Average Loss: -19.7674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0226

Learning rate: 0.00019985489147170412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1716 [0/90000 (0%)]	Loss: -13.3684	Cost: 24.00s
Train Epoch: 1716 [20480/90000 (23%)]	Loss: -20.4550	Cost: 6.12s
Train Epoch: 1716 [40960/90000 (45%)]	Loss: -19.8915	Cost: 7.26s
Train Epoch: 1716 [61440/90000 (68%)]	Loss: -20.3597	Cost: 5.90s
Train Epoch: 1716 [81920/90000 (91%)]	Loss: -20.5769	Cost: 8.06s
Train Epoch: 1716 	Average Loss: -19.8608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4540

Learning rate: 0.00019985472224059222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1717 [0/90000 (0%)]	Loss: -14.1176	Cost: 22.67s
Train Epoch: 1717 [20480/90000 (23%)]	Loss: -20.8301	Cost: 6.24s
Train Epoch: 1717 [40960/90000 (45%)]	Loss: -20.2666	Cost: 11.44s
Train Epoch: 1717 [61440/90000 (68%)]	Loss: -20.4985	Cost: 6.34s
Train Epoch: 1717 [81920/90000 (91%)]	Loss: -20.7604	Cost: 11.09s
Train Epoch: 1717 	Average Loss: -20.1404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5679

Learning rate: 0.00019985455291092762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1718 [0/90000 (0%)]	Loss: -13.6345	Cost: 27.69s
Train Epoch: 1718 [20480/90000 (23%)]	Loss: -20.8894	Cost: 6.32s
Train Epoch: 1718 [40960/90000 (45%)]	Loss: -20.1110	Cost: 9.57s
Train Epoch: 1718 [61440/90000 (68%)]	Loss: -20.4651	Cost: 5.97s
Train Epoch: 1718 [81920/90000 (91%)]	Loss: -20.4543	Cost: 8.10s
Train Epoch: 1718 	Average Loss: -20.0378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4802

Learning rate: 0.00019985438348271055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1719 [0/90000 (0%)]	Loss: -14.0127	Cost: 24.44s
Train Epoch: 1719 [20480/90000 (23%)]	Loss: -20.7027	Cost: 6.08s
Train Epoch: 1719 [40960/90000 (45%)]	Loss: -20.2370	Cost: 8.28s
Train Epoch: 1719 [61440/90000 (68%)]	Loss: -20.4323	Cost: 5.78s
Train Epoch: 1719 [81920/90000 (91%)]	Loss: -20.6125	Cost: 6.29s
Train Epoch: 1719 	Average Loss: -20.0864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5208

Learning rate: 0.00019985421395594117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1720 [0/90000 (0%)]	Loss: -13.9311	Cost: 22.86s
Train Epoch: 1720 [20480/90000 (23%)]	Loss: -20.7451	Cost: 6.03s
Train Epoch: 1720 [40960/90000 (45%)]	Loss: -20.1794	Cost: 8.32s
Train Epoch: 1720 [61440/90000 (68%)]	Loss: -20.6007	Cost: 6.46s
Train Epoch: 1720 [81920/90000 (91%)]	Loss: -20.6776	Cost: 11.35s
Train Epoch: 1720 	Average Loss: -20.0718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5137

Learning rate: 0.0001998540443306196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1721 [0/90000 (0%)]	Loss: -13.9785	Cost: 27.00s
Train Epoch: 1721 [20480/90000 (23%)]	Loss: -20.8369	Cost: 6.38s
Train Epoch: 1721 [40960/90000 (45%)]	Loss: -20.2179	Cost: 10.10s
Train Epoch: 1721 [61440/90000 (68%)]	Loss: -20.5878	Cost: 5.75s
Train Epoch: 1721 [81920/90000 (91%)]	Loss: -20.7019	Cost: 6.68s
Train Epoch: 1721 	Average Loss: -20.0977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5545

Learning rate: 0.00019985387460674605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1722 [0/90000 (0%)]	Loss: -13.1445	Cost: 25.91s
Train Epoch: 1722 [20480/90000 (23%)]	Loss: -20.2404	Cost: 6.15s
Train Epoch: 1722 [40960/90000 (45%)]	Loss: -19.8158	Cost: 7.78s
Train Epoch: 1722 [61440/90000 (68%)]	Loss: -20.1271	Cost: 6.05s
Train Epoch: 1722 [81920/90000 (91%)]	Loss: -20.0835	Cost: 8.07s
Train Epoch: 1722 	Average Loss: -19.7393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2231

Learning rate: 0.0001998537047843207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1723 [0/90000 (0%)]	Loss: -13.6798	Cost: 23.74s
Train Epoch: 1723 [20480/90000 (23%)]	Loss: -20.3059	Cost: 6.20s
Train Epoch: 1723 [40960/90000 (45%)]	Loss: -19.6885	Cost: 7.75s
Train Epoch: 1723 [61440/90000 (68%)]	Loss: -20.0262	Cost: 6.30s
Train Epoch: 1723 [81920/90000 (91%)]	Loss: -20.3047	Cost: 11.06s
Train Epoch: 1723 	Average Loss: -19.6806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5870

Learning rate: 0.0001998535348633437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1724 [0/90000 (0%)]	Loss: -13.4886	Cost: 26.39s
Train Epoch: 1724 [20480/90000 (23%)]	Loss: -20.4250	Cost: 6.45s
Train Epoch: 1724 [40960/90000 (45%)]	Loss: -19.9104	Cost: 10.88s
Train Epoch: 1724 [61440/90000 (68%)]	Loss: -20.5015	Cost: 6.09s
Train Epoch: 1724 [81920/90000 (91%)]	Loss: -20.6694	Cost: 7.91s
Train Epoch: 1724 	Average Loss: -20.0024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6998

Saving model as e1724_model.pt & e1724_waveforms_supplementary.hdf5
Learning rate: 0.00019985336484381518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1725 [0/90000 (0%)]	Loss: -13.6575	Cost: 25.74s
Train Epoch: 1725 [20480/90000 (23%)]	Loss: -20.8318	Cost: 6.20s
Train Epoch: 1725 [40960/90000 (45%)]	Loss: -20.4624	Cost: 7.96s
Train Epoch: 1725 [61440/90000 (68%)]	Loss: -20.8167	Cost: 5.99s
Train Epoch: 1725 [81920/90000 (91%)]	Loss: -20.7014	Cost: 6.53s
Train Epoch: 1725 	Average Loss: -20.1990
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7340

Saving model as e1725_model.pt & e1725_waveforms_supplementary.hdf5
Learning rate: 0.00019985319472573535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1726 [0/90000 (0%)]	Loss: -14.0447	Cost: 23.37s
Train Epoch: 1726 [20480/90000 (23%)]	Loss: -20.7625	Cost: 6.09s
Train Epoch: 1726 [40960/90000 (45%)]	Loss: -20.0170	Cost: 6.94s
Train Epoch: 1726 [61440/90000 (68%)]	Loss: -20.3394	Cost: 6.13s
Train Epoch: 1726 [81920/90000 (91%)]	Loss: -20.4673	Cost: 11.19s
Train Epoch: 1726 	Average Loss: -20.0079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5086

Learning rate: 0.00019985302450910433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1727 [0/90000 (0%)]	Loss: -13.8473	Cost: 24.66s
Train Epoch: 1727 [20480/90000 (23%)]	Loss: -20.6258	Cost: 6.32s
Train Epoch: 1727 [40960/90000 (45%)]	Loss: -20.2623	Cost: 10.82s
Train Epoch: 1727 [61440/90000 (68%)]	Loss: -20.4007	Cost: 6.20s
Train Epoch: 1727 [81920/90000 (91%)]	Loss: -20.6679	Cost: 8.07s
Train Epoch: 1727 	Average Loss: -20.1188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4983

Learning rate: 0.00019985285419392237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1728 [0/90000 (0%)]	Loss: -13.8353	Cost: 26.74s
Train Epoch: 1728 [20480/90000 (23%)]	Loss: -20.6632	Cost: 6.11s
Train Epoch: 1728 [40960/90000 (45%)]	Loss: -20.0423	Cost: 7.42s
Train Epoch: 1728 [61440/90000 (68%)]	Loss: -20.4203	Cost: 6.03s
Train Epoch: 1728 [81920/90000 (91%)]	Loss: -20.6248	Cost: 8.10s
Train Epoch: 1728 	Average Loss: -20.0091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5016

Learning rate: 0.00019985268378018957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1729 [0/90000 (0%)]	Loss: -14.0547	Cost: 24.02s
Train Epoch: 1729 [20480/90000 (23%)]	Loss: -20.4275	Cost: 6.06s
Train Epoch: 1729 [40960/90000 (45%)]	Loss: -19.3419	Cost: 7.37s
Train Epoch: 1729 [61440/90000 (68%)]	Loss: -19.9990	Cost: 5.94s
Train Epoch: 1729 [81920/90000 (91%)]	Loss: -20.3415	Cost: 6.32s
Train Epoch: 1729 	Average Loss: -19.6301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3502

Learning rate: 0.00019985251326790613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1730 [0/90000 (0%)]	Loss: -13.3380	Cost: 22.30s
Train Epoch: 1730 [20480/90000 (23%)]	Loss: -20.6122	Cost: 6.13s
Train Epoch: 1730 [40960/90000 (45%)]	Loss: -20.1101	Cost: 10.65s
Train Epoch: 1730 [61440/90000 (68%)]	Loss: -20.2749	Cost: 6.27s
Train Epoch: 1730 [81920/90000 (91%)]	Loss: -20.6559	Cost: 11.43s
Train Epoch: 1730 	Average Loss: -19.9679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3856

Learning rate: 0.00019985234265707221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1731 [0/90000 (0%)]	Loss: -13.7329	Cost: 26.94s
Train Epoch: 1731 [20480/90000 (23%)]	Loss: -20.6701	Cost: 6.44s
Train Epoch: 1731 [40960/90000 (45%)]	Loss: -20.0913	Cost: 9.66s
Train Epoch: 1731 [61440/90000 (68%)]	Loss: -20.1608	Cost: 6.07s
Train Epoch: 1731 [81920/90000 (91%)]	Loss: -20.4533	Cost: 7.50s
Train Epoch: 1731 	Average Loss: -19.9562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3362

Learning rate: 0.000199852171947688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1732 [0/90000 (0%)]	Loss: -14.0927	Cost: 23.93s
Train Epoch: 1732 [20480/90000 (23%)]	Loss: -20.6239	Cost: 6.14s
Train Epoch: 1732 [40960/90000 (45%)]	Loss: -20.3182	Cost: 8.54s
Train Epoch: 1732 [61440/90000 (68%)]	Loss: -20.5923	Cost: 5.82s
Train Epoch: 1732 [81920/90000 (91%)]	Loss: -20.7181	Cost: 6.18s
Train Epoch: 1732 	Average Loss: -20.1450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5638

Learning rate: 0.00019985200113975364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1733 [0/90000 (0%)]	Loss: -14.4682	Cost: 23.99s
Train Epoch: 1733 [20480/90000 (23%)]	Loss: -20.6431	Cost: 6.06s
Train Epoch: 1733 [40960/90000 (45%)]	Loss: -20.1719	Cost: 7.30s
Train Epoch: 1733 [61440/90000 (68%)]	Loss: -20.5741	Cost: 6.18s
Train Epoch: 1733 [81920/90000 (91%)]	Loss: -20.7448	Cost: 11.67s
Train Epoch: 1733 	Average Loss: -20.1529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7218

Learning rate: 0.0001998518302332693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1734 [0/90000 (0%)]	Loss: -13.5536	Cost: 25.72s
Train Epoch: 1734 [20480/90000 (23%)]	Loss: -20.8591	Cost: 6.41s
Train Epoch: 1734 [40960/90000 (45%)]	Loss: -20.4324	Cost: 11.68s
Train Epoch: 1734 [61440/90000 (68%)]	Loss: -20.5543	Cost: 6.15s
Train Epoch: 1734 [81920/90000 (91%)]	Loss: -20.4488	Cost: 7.60s
Train Epoch: 1734 	Average Loss: -20.1371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5732

Learning rate: 0.00019985165922823515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1735 [0/90000 (0%)]	Loss: -13.4009	Cost: 26.97s
Train Epoch: 1735 [20480/90000 (23%)]	Loss: -20.6224	Cost: 6.12s
Train Epoch: 1735 [40960/90000 (45%)]	Loss: -20.2533	Cost: 8.02s
Train Epoch: 1735 [61440/90000 (68%)]	Loss: -20.4768	Cost: 5.98s
Train Epoch: 1735 [81920/90000 (91%)]	Loss: -20.6923	Cost: 8.66s
Train Epoch: 1735 	Average Loss: -20.0515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5371

Learning rate: 0.00019985148812465134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1736 [0/90000 (0%)]	Loss: -14.3884	Cost: 23.38s
Train Epoch: 1736 [20480/90000 (23%)]	Loss: -20.9153	Cost: 6.12s
Train Epoch: 1736 [40960/90000 (45%)]	Loss: -20.5961	Cost: 7.99s
Train Epoch: 1736 [61440/90000 (68%)]	Loss: -20.8335	Cost: 5.88s
Train Epoch: 1736 [81920/90000 (91%)]	Loss: -20.8431	Cost: 7.67s
Train Epoch: 1736 	Average Loss: -20.3573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8059

Saving model as e1736_model.pt & e1736_waveforms_supplementary.hdf5
Learning rate: 0.0001998513169225181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1737 [0/90000 (0%)]	Loss: -14.0273	Cost: 23.41s
Train Epoch: 1737 [20480/90000 (23%)]	Loss: -21.0409	Cost: 6.17s
Train Epoch: 1737 [40960/90000 (45%)]	Loss: -20.2687	Cost: 10.77s
Train Epoch: 1737 [61440/90000 (68%)]	Loss: -20.7666	Cost: 6.22s
Train Epoch: 1737 [81920/90000 (91%)]	Loss: -20.7330	Cost: 10.36s
Train Epoch: 1737 	Average Loss: -20.2438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7139

Learning rate: 0.00019985114562183552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1738 [0/90000 (0%)]	Loss: -14.1140	Cost: 26.68s
Train Epoch: 1738 [20480/90000 (23%)]	Loss: -20.8591	Cost: 6.22s
Train Epoch: 1738 [40960/90000 (45%)]	Loss: -20.1394	Cost: 8.71s
Train Epoch: 1738 [61440/90000 (68%)]	Loss: -20.4657	Cost: 5.97s
Train Epoch: 1738 [81920/90000 (91%)]	Loss: -20.4676	Cost: 8.63s
Train Epoch: 1738 	Average Loss: -20.0665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7116

Learning rate: 0.00019985097422260385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1739 [0/90000 (0%)]	Loss: -14.1490	Cost: 25.13s
Train Epoch: 1739 [20480/90000 (23%)]	Loss: -20.7834	Cost: 6.28s
Train Epoch: 1739 [40960/90000 (45%)]	Loss: -20.3190	Cost: 7.93s
Train Epoch: 1739 [61440/90000 (68%)]	Loss: -20.6923	Cost: 5.76s
Train Epoch: 1739 [81920/90000 (91%)]	Loss: -20.7144	Cost: 6.48s
Train Epoch: 1739 	Average Loss: -20.2296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6642

Learning rate: 0.0001998508027248232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1740 [0/90000 (0%)]	Loss: -13.5010	Cost: 22.67s
Train Epoch: 1740 [20480/90000 (23%)]	Loss: -20.8629	Cost: 6.15s
Train Epoch: 1740 [40960/90000 (45%)]	Loss: -20.2195	Cost: 10.34s
Train Epoch: 1740 [61440/90000 (68%)]	Loss: -20.4929	Cost: 6.33s
Train Epoch: 1740 [81920/90000 (91%)]	Loss: -20.5711	Cost: 11.88s
Train Epoch: 1740 	Average Loss: -20.0969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5290

Learning rate: 0.00019985063112849377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1741 [0/90000 (0%)]	Loss: -13.8065	Cost: 28.11s
Train Epoch: 1741 [20480/90000 (23%)]	Loss: -20.5662	Cost: 6.22s
Train Epoch: 1741 [40960/90000 (45%)]	Loss: -20.2818	Cost: 10.83s
Train Epoch: 1741 [61440/90000 (68%)]	Loss: -20.6773	Cost: 5.70s
Train Epoch: 1741 [81920/90000 (91%)]	Loss: -20.7376	Cost: 6.52s
Train Epoch: 1741 	Average Loss: -20.1798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6668

Learning rate: 0.0001998504594336157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1742 [0/90000 (0%)]	Loss: -14.7239	Cost: 25.26s
Train Epoch: 1742 [20480/90000 (23%)]	Loss: -20.7853	Cost: 6.13s
Train Epoch: 1742 [40960/90000 (45%)]	Loss: -20.3473	Cost: 8.31s
Train Epoch: 1742 [61440/90000 (68%)]	Loss: -20.6916	Cost: 5.87s
Train Epoch: 1742 [81920/90000 (91%)]	Loss: -20.6489	Cost: 6.80s
Train Epoch: 1742 	Average Loss: -20.2362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7033

Learning rate: 0.00019985028764018918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1743 [0/90000 (0%)]	Loss: -13.3337	Cost: 23.60s
Train Epoch: 1743 [20480/90000 (23%)]	Loss: -18.3765	Cost: 6.17s
Train Epoch: 1743 [40960/90000 (45%)]	Loss: -18.0315	Cost: 8.01s
Train Epoch: 1743 [61440/90000 (68%)]	Loss: -18.9177	Cost: 6.22s
Train Epoch: 1743 [81920/90000 (91%)]	Loss: -19.5252	Cost: 11.71s
Train Epoch: 1743 	Average Loss: -18.4418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6293

Learning rate: 0.00019985011574821435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1744 [0/90000 (0%)]	Loss: -13.3538	Cost: 25.77s
Train Epoch: 1744 [20480/90000 (23%)]	Loss: -20.0464	Cost: 6.43s
Train Epoch: 1744 [40960/90000 (45%)]	Loss: -20.1500	Cost: 10.82s
Train Epoch: 1744 [61440/90000 (68%)]	Loss: -20.5386	Cost: 6.09s
Train Epoch: 1744 [81920/90000 (91%)]	Loss: -20.5786	Cost: 7.22s
Train Epoch: 1744 	Average Loss: -19.7378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5500

Learning rate: 0.00019984994375769145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1745 [0/90000 (0%)]	Loss: -14.0135	Cost: 26.48s
Train Epoch: 1745 [20480/90000 (23%)]	Loss: -20.8269	Cost: 6.22s
Train Epoch: 1745 [40960/90000 (45%)]	Loss: -20.3738	Cost: 8.81s
Train Epoch: 1745 [61440/90000 (68%)]	Loss: -20.9545	Cost: 5.98s
Train Epoch: 1745 [81920/90000 (91%)]	Loss: -21.0794	Cost: 8.77s
Train Epoch: 1745 	Average Loss: -20.3612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9654

Saving model as e1745_model.pt & e1745_waveforms_supplementary.hdf5
Learning rate: 0.0001998497716686206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1746 [0/90000 (0%)]	Loss: -14.9204	Cost: 24.41s
Train Epoch: 1746 [20480/90000 (23%)]	Loss: -21.2065	Cost: 6.07s
Train Epoch: 1746 [40960/90000 (45%)]	Loss: -20.6303	Cost: 8.08s
Train Epoch: 1746 [61440/90000 (68%)]	Loss: -20.9373	Cost: 5.69s
Train Epoch: 1746 [81920/90000 (91%)]	Loss: -20.8700	Cost: 6.17s
Train Epoch: 1746 	Average Loss: -20.4903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8269

Learning rate: 0.00019984959948100194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1747 [0/90000 (0%)]	Loss: -14.1143	Cost: 25.27s
Train Epoch: 1747 [20480/90000 (23%)]	Loss: -20.5298	Cost: 6.05s
Train Epoch: 1747 [40960/90000 (45%)]	Loss: -20.0538	Cost: 9.27s
Train Epoch: 1747 [61440/90000 (68%)]	Loss: -20.4306	Cost: 6.26s
Train Epoch: 1747 [81920/90000 (91%)]	Loss: -20.7843	Cost: 11.05s
Train Epoch: 1747 	Average Loss: -20.0490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6773

Learning rate: 0.0001998494271948357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1748 [0/90000 (0%)]	Loss: -13.4380	Cost: 27.80s
Train Epoch: 1748 [20480/90000 (23%)]	Loss: -20.8675	Cost: 6.22s
Train Epoch: 1748 [40960/90000 (45%)]	Loss: -20.1620	Cost: 10.40s
Train Epoch: 1748 [61440/90000 (68%)]	Loss: -20.7474	Cost: 5.77s
Train Epoch: 1748 [81920/90000 (91%)]	Loss: -20.6583	Cost: 6.68s
Train Epoch: 1748 	Average Loss: -20.1503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5442

Learning rate: 0.00019984925481012202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1749 [0/90000 (0%)]	Loss: -14.0335	Cost: 25.96s
Train Epoch: 1749 [20480/90000 (23%)]	Loss: -20.8861	Cost: 6.09s
Train Epoch: 1749 [40960/90000 (45%)]	Loss: -20.3307	Cost: 8.43s
Train Epoch: 1749 [61440/90000 (68%)]	Loss: -20.7422	Cost: 5.81s
Train Epoch: 1749 [81920/90000 (91%)]	Loss: -20.6935	Cost: 6.71s
Train Epoch: 1749 	Average Loss: -20.2743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8492

Learning rate: 0.00019984908232686108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1750 [0/90000 (0%)]	Loss: -14.7977	Cost: 23.09s
Train Epoch: 1750 [20480/90000 (23%)]	Loss: -21.0715	Cost: 6.23s
Train Epoch: 1750 [40960/90000 (45%)]	Loss: -20.3667	Cost: 7.49s
Train Epoch: 1750 [61440/90000 (68%)]	Loss: -20.7353	Cost: 6.24s
Train Epoch: 1750 [81920/90000 (91%)]	Loss: -20.6329	Cost: 11.84s
Train Epoch: 1750 	Average Loss: -20.2574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5918

Learning rate: 0.00019984890974505305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1751 [0/90000 (0%)]	Loss: -13.9233	Cost: 26.25s
Train Epoch: 1751 [20480/90000 (23%)]	Loss: -20.9798	Cost: 6.60s
Train Epoch: 1751 [40960/90000 (45%)]	Loss: -20.5703	Cost: 10.61s
Train Epoch: 1751 [61440/90000 (68%)]	Loss: -20.7343	Cost: 6.21s
Train Epoch: 1751 [81920/90000 (91%)]	Loss: -20.7568	Cost: 6.97s
Train Epoch: 1751 	Average Loss: -20.3138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9370

Learning rate: 0.0001998487370646981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1752 [0/90000 (0%)]	Loss: -14.1820	Cost: 27.11s
Train Epoch: 1752 [20480/90000 (23%)]	Loss: -21.0239	Cost: 6.11s
Train Epoch: 1752 [40960/90000 (45%)]	Loss: -20.3521	Cost: 7.03s
Train Epoch: 1752 [61440/90000 (68%)]	Loss: -20.7461	Cost: 6.08s
Train Epoch: 1752 [81920/90000 (91%)]	Loss: -20.6861	Cost: 8.94s
Train Epoch: 1752 	Average Loss: -20.2645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2787

Learning rate: 0.0001998485642857964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1753 [0/90000 (0%)]	Loss: -13.8851	Cost: 23.62s
Train Epoch: 1753 [20480/90000 (23%)]	Loss: -20.7177	Cost: 6.21s
Train Epoch: 1753 [40960/90000 (45%)]	Loss: -20.4116	Cost: 7.60s
Train Epoch: 1753 [61440/90000 (68%)]	Loss: -20.7788	Cost: 6.35s
Train Epoch: 1753 [81920/90000 (91%)]	Loss: -20.9946	Cost: 8.87s
Train Epoch: 1753 	Average Loss: -20.1859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7708

Learning rate: 0.0001998483914083481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1754 [0/90000 (0%)]	Loss: -13.7733	Cost: 23.39s
Train Epoch: 1754 [20480/90000 (23%)]	Loss: -20.9009	Cost: 6.23s
Train Epoch: 1754 [40960/90000 (45%)]	Loss: -20.3856	Cost: 11.27s
Train Epoch: 1754 [61440/90000 (68%)]	Loss: -20.8029	Cost: 6.20s
Train Epoch: 1754 [81920/90000 (91%)]	Loss: -20.9847	Cost: 10.74s
Train Epoch: 1754 	Average Loss: -20.3816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0394

Saving model as e1754_model.pt & e1754_waveforms_supplementary.hdf5
Learning rate: 0.0001998482184323534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1755 [0/90000 (0%)]	Loss: -13.8547	Cost: 26.73s
Train Epoch: 1755 [20480/90000 (23%)]	Loss: -21.0689	Cost: 6.31s
Train Epoch: 1755 [40960/90000 (45%)]	Loss: -20.3190	Cost: 8.59s
Train Epoch: 1755 [61440/90000 (68%)]	Loss: -21.0504	Cost: 5.97s
Train Epoch: 1755 [81920/90000 (91%)]	Loss: -20.9817	Cost: 8.39s
Train Epoch: 1755 	Average Loss: -20.3525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9549

Learning rate: 0.00019984804535781245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1756 [0/90000 (0%)]	Loss: -14.3204	Cost: 25.02s
Train Epoch: 1756 [20480/90000 (23%)]	Loss: -21.2447	Cost: 6.06s
Train Epoch: 1756 [40960/90000 (45%)]	Loss: -20.7614	Cost: 8.29s
Train Epoch: 1756 [61440/90000 (68%)]	Loss: -21.0128	Cost: 5.75s
Train Epoch: 1756 [81920/90000 (91%)]	Loss: -21.1208	Cost: 6.39s
Train Epoch: 1756 	Average Loss: -20.6017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0777

Saving model as e1756_model.pt & e1756_waveforms_supplementary.hdf5
Learning rate: 0.00019984787218472542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1757 [0/90000 (0%)]	Loss: -14.1926	Cost: 22.42s
Train Epoch: 1757 [20480/90000 (23%)]	Loss: -21.1710	Cost: 6.38s
Train Epoch: 1757 [40960/90000 (45%)]	Loss: -20.7452	Cost: 8.63s
Train Epoch: 1757 [61440/90000 (68%)]	Loss: -21.1882	Cost: 6.17s
Train Epoch: 1757 [81920/90000 (91%)]	Loss: -20.9843	Cost: 11.74s
Train Epoch: 1757 	Average Loss: -20.5957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0119

Learning rate: 0.00019984769891309248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1758 [0/90000 (0%)]	Loss: -14.5577	Cost: 25.57s
Train Epoch: 1758 [20480/90000 (23%)]	Loss: -21.0080	Cost: 6.38s
Train Epoch: 1758 [40960/90000 (45%)]	Loss: -20.3510	Cost: 10.84s
Train Epoch: 1758 [61440/90000 (68%)]	Loss: -20.8225	Cost: 5.99s
Train Epoch: 1758 [81920/90000 (91%)]	Loss: -20.9617	Cost: 7.67s
Train Epoch: 1758 	Average Loss: -20.4750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0006

Learning rate: 0.00019984752554291386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1759 [0/90000 (0%)]	Loss: -14.6565	Cost: 26.95s
Train Epoch: 1759 [20480/90000 (23%)]	Loss: -21.0707	Cost: 6.20s
Train Epoch: 1759 [40960/90000 (45%)]	Loss: -20.6004	Cost: 8.42s
Train Epoch: 1759 [61440/90000 (68%)]	Loss: -21.0403	Cost: 5.98s
Train Epoch: 1759 [81920/90000 (91%)]	Loss: -14.3411	Cost: 8.43s
Train Epoch: 1759 	Average Loss: -19.1857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2418

Learning rate: 0.00019984735207418964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1760 [0/90000 (0%)]	Loss: -8.5428	Cost: 23.69s
Train Epoch: 1760 [20480/90000 (23%)]	Loss: -15.4354	Cost: 6.15s
Train Epoch: 1760 [40960/90000 (45%)]	Loss: -16.3207	Cost: 7.95s
Train Epoch: 1760 [61440/90000 (68%)]	Loss: -17.5797	Cost: 5.91s
Train Epoch: 1760 [81920/90000 (91%)]	Loss: -18.5993	Cost: 6.22s
Train Epoch: 1760 	Average Loss: -16.2441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1631

Learning rate: 0.00019984717850692006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1761 [0/90000 (0%)]	Loss: -11.8118	Cost: 22.38s
Train Epoch: 1761 [20480/90000 (23%)]	Loss: -18.1500	Cost: 6.37s
Train Epoch: 1761 [40960/90000 (45%)]	Loss: -17.9741	Cost: 9.94s
Train Epoch: 1761 [61440/90000 (68%)]	Loss: -19.2220	Cost: 6.28s
Train Epoch: 1761 [81920/90000 (91%)]	Loss: -19.6386	Cost: 11.49s
Train Epoch: 1761 	Average Loss: -18.3978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8821

Learning rate: 0.00019984700484110526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1762 [0/90000 (0%)]	Loss: -13.6950	Cost: 26.94s
Train Epoch: 1762 [20480/90000 (23%)]	Loss: -20.1944	Cost: 6.27s
Train Epoch: 1762 [40960/90000 (45%)]	Loss: -20.0374	Cost: 10.58s
Train Epoch: 1762 [61440/90000 (68%)]	Loss: -20.3734	Cost: 5.87s
Train Epoch: 1762 [81920/90000 (91%)]	Loss: -20.6048	Cost: 6.43s
Train Epoch: 1762 	Average Loss: -19.8438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6536

Learning rate: 0.0001998468310767454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1763 [0/90000 (0%)]	Loss: -13.9090	Cost: 26.55s
Train Epoch: 1763 [20480/90000 (23%)]	Loss: -20.7717	Cost: 6.06s
Train Epoch: 1763 [40960/90000 (45%)]	Loss: -20.1202	Cost: 7.36s
Train Epoch: 1763 [61440/90000 (68%)]	Loss: -20.7960	Cost: 6.02s
Train Epoch: 1763 [81920/90000 (91%)]	Loss: -20.8169	Cost: 8.68s
Train Epoch: 1763 	Average Loss: -20.1935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7301

Learning rate: 0.00019984665721384067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1764 [0/90000 (0%)]	Loss: -14.6255	Cost: 23.51s
Train Epoch: 1764 [20480/90000 (23%)]	Loss: -21.0448	Cost: 6.13s
Train Epoch: 1764 [40960/90000 (45%)]	Loss: -20.5761	Cost: 7.69s
Train Epoch: 1764 [61440/90000 (68%)]	Loss: -20.8381	Cost: 6.32s
Train Epoch: 1764 [81920/90000 (91%)]	Loss: -20.6639	Cost: 8.80s
Train Epoch: 1764 	Average Loss: -20.4058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7737

Learning rate: 0.00019984648325239125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1765 [0/90000 (0%)]	Loss: -14.5894	Cost: 24.42s
Train Epoch: 1765 [20480/90000 (23%)]	Loss: -20.9546	Cost: 6.22s
Train Epoch: 1765 [40960/90000 (45%)]	Loss: -20.8289	Cost: 11.38s
Train Epoch: 1765 [61440/90000 (68%)]	Loss: -21.0479	Cost: 6.15s
Train Epoch: 1765 [81920/90000 (91%)]	Loss: -21.1990	Cost: 11.03s
Train Epoch: 1765 	Average Loss: -20.5328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1609

Saving model as e1765_model.pt & e1765_waveforms_supplementary.hdf5
Learning rate: 0.00019984630919239732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1766 [0/90000 (0%)]	Loss: -14.6563	Cost: 26.76s
Train Epoch: 1766 [20480/90000 (23%)]	Loss: -21.1635	Cost: 6.25s
Train Epoch: 1766 [40960/90000 (45%)]	Loss: -20.4902	Cost: 8.34s
Train Epoch: 1766 [61440/90000 (68%)]	Loss: -20.7913	Cost: 5.98s
Train Epoch: 1766 [81920/90000 (91%)]	Loss: -20.9247	Cost: 8.74s
Train Epoch: 1766 	Average Loss: -20.5039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9880

Learning rate: 0.00019984613503385904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1767 [0/90000 (0%)]	Loss: -13.5212	Cost: 23.46s
Train Epoch: 1767 [20480/90000 (23%)]	Loss: -21.0159	Cost: 6.10s
Train Epoch: 1767 [40960/90000 (45%)]	Loss: -20.4756	Cost: 6.93s
Train Epoch: 1767 [61440/90000 (68%)]	Loss: -20.9757	Cost: 5.92s
Train Epoch: 1767 [81920/90000 (91%)]	Loss: -20.8570	Cost: 7.60s
Train Epoch: 1767 	Average Loss: -20.3548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9753

Learning rate: 0.0001998459607767765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1768 [0/90000 (0%)]	Loss: -14.4598	Cost: 23.99s
Train Epoch: 1768 [20480/90000 (23%)]	Loss: -20.2392	Cost: 6.30s
Train Epoch: 1768 [40960/90000 (45%)]	Loss: -19.4214	Cost: 11.31s
Train Epoch: 1768 [61440/90000 (68%)]	Loss: -20.1960	Cost: 6.19s
Train Epoch: 1768 [81920/90000 (91%)]	Loss: -20.4440	Cost: 10.66s
Train Epoch: 1768 	Average Loss: -19.7844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6572

Learning rate: 0.00019984578642115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1769 [0/90000 (0%)]	Loss: -13.9595	Cost: 26.77s
Train Epoch: 1769 [20480/90000 (23%)]	Loss: -20.8430	Cost: 6.18s
Train Epoch: 1769 [40960/90000 (45%)]	Loss: -20.4046	Cost: 8.62s
Train Epoch: 1769 [61440/90000 (68%)]	Loss: -20.9419	Cost: 6.01s
Train Epoch: 1769 [81920/90000 (91%)]	Loss: -20.6516	Cost: 8.84s
Train Epoch: 1769 	Average Loss: -20.2595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8559

Learning rate: 0.00019984561196697965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1770 [0/90000 (0%)]	Loss: -13.6779	Cost: 23.52s
Train Epoch: 1770 [20480/90000 (23%)]	Loss: -21.0123	Cost: 6.08s
Train Epoch: 1770 [40960/90000 (45%)]	Loss: -20.6426	Cost: 7.94s
Train Epoch: 1770 [61440/90000 (68%)]	Loss: -20.9240	Cost: 5.81s
Train Epoch: 1770 [81920/90000 (91%)]	Loss: -21.0400	Cost: 5.76s
Train Epoch: 1770 	Average Loss: -20.4889
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1444

Learning rate: 0.0001998454374142656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1771 [0/90000 (0%)]	Loss: -14.9238	Cost: 22.33s
Train Epoch: 1771 [20480/90000 (23%)]	Loss: -20.6911	Cost: 6.03s
Train Epoch: 1771 [40960/90000 (45%)]	Loss: -20.2158	Cost: 8.42s
Train Epoch: 1771 [61440/90000 (68%)]	Loss: -20.4757	Cost: 6.17s
Train Epoch: 1771 [81920/90000 (91%)]	Loss: -20.8120	Cost: 11.93s
Train Epoch: 1771 	Average Loss: -20.2660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7526

Learning rate: 0.00019984526276300806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1772 [0/90000 (0%)]	Loss: -14.5358	Cost: 27.18s
Train Epoch: 1772 [20480/90000 (23%)]	Loss: -21.2542	Cost: 6.31s
Train Epoch: 1772 [40960/90000 (45%)]	Loss: -20.5025	Cost: 10.10s
Train Epoch: 1772 [61440/90000 (68%)]	Loss: -21.0096	Cost: 5.95s
Train Epoch: 1772 [81920/90000 (91%)]	Loss: -20.9239	Cost: 6.78s
Train Epoch: 1772 	Average Loss: -20.4434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7748

Learning rate: 0.00019984508801320722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1773 [0/90000 (0%)]	Loss: -14.4409	Cost: 25.43s
Train Epoch: 1773 [20480/90000 (23%)]	Loss: -21.0955	Cost: 6.18s
Train Epoch: 1773 [40960/90000 (45%)]	Loss: -20.4669	Cost: 8.52s
Train Epoch: 1773 [61440/90000 (68%)]	Loss: -20.8272	Cost: 5.99s
Train Epoch: 1773 [81920/90000 (91%)]	Loss: -20.8644	Cost: 7.54s
Train Epoch: 1773 	Average Loss: -20.4222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8729

Learning rate: 0.00019984491316486322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1774 [0/90000 (0%)]	Loss: -14.7247	Cost: 23.71s
Train Epoch: 1774 [20480/90000 (23%)]	Loss: -21.2942	Cost: 6.07s
Train Epoch: 1774 [40960/90000 (45%)]	Loss: -20.6837	Cost: 7.59s
Train Epoch: 1774 [61440/90000 (68%)]	Loss: -21.0280	Cost: 6.42s
Train Epoch: 1774 [81920/90000 (91%)]	Loss: -21.0556	Cost: 11.47s
Train Epoch: 1774 	Average Loss: -20.5669
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0406

Learning rate: 0.00019984473821797624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1775 [0/90000 (0%)]	Loss: -13.8271	Cost: 26.26s
Train Epoch: 1775 [20480/90000 (23%)]	Loss: -21.0008	Cost: 6.66s
Train Epoch: 1775 [40960/90000 (45%)]	Loss: -20.3777	Cost: 10.94s
Train Epoch: 1775 [61440/90000 (68%)]	Loss: -21.0880	Cost: 6.13s
Train Epoch: 1775 [81920/90000 (91%)]	Loss: -20.9869	Cost: 8.09s
Train Epoch: 1775 	Average Loss: -20.4492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0661

Learning rate: 0.00019984456317254646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1776 [0/90000 (0%)]	Loss: -13.5702	Cost: 26.67s
Train Epoch: 1776 [20480/90000 (23%)]	Loss: -21.2025	Cost: 6.15s
Train Epoch: 1776 [40960/90000 (45%)]	Loss: -20.6453	Cost: 7.44s
Train Epoch: 1776 [61440/90000 (68%)]	Loss: -20.8395	Cost: 6.20s
Train Epoch: 1776 [81920/90000 (91%)]	Loss: -21.1664	Cost: 8.24s
Train Epoch: 1776 	Average Loss: -20.4605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8769

Learning rate: 0.00019984438802857405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1777 [0/90000 (0%)]	Loss: -14.8518	Cost: 24.03s
Train Epoch: 1777 [20480/90000 (23%)]	Loss: -21.1463	Cost: 6.04s
Train Epoch: 1777 [40960/90000 (45%)]	Loss: -20.6542	Cost: 6.89s
Train Epoch: 1777 [61440/90000 (68%)]	Loss: -21.1935	Cost: 6.04s
Train Epoch: 1777 [81920/90000 (91%)]	Loss: -21.1553	Cost: 8.14s
Train Epoch: 1777 	Average Loss: -20.5720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1341

Learning rate: 0.00019984421278605916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1778 [0/90000 (0%)]	Loss: -14.3983	Cost: 23.44s
Train Epoch: 1778 [20480/90000 (23%)]	Loss: -21.3174	Cost: 6.17s
Train Epoch: 1778 [40960/90000 (45%)]	Loss: -20.4452	Cost: 11.29s
Train Epoch: 1778 [61440/90000 (68%)]	Loss: -20.9011	Cost: 6.37s
Train Epoch: 1778 [81920/90000 (91%)]	Loss: -21.0662	Cost: 10.48s
Train Epoch: 1778 	Average Loss: -20.5737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9848

Learning rate: 0.000199844037445002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1779 [0/90000 (0%)]	Loss: -14.7834	Cost: 27.30s
Train Epoch: 1779 [20480/90000 (23%)]	Loss: -21.2086	Cost: 6.33s
Train Epoch: 1779 [40960/90000 (45%)]	Loss: -20.8776	Cost: 8.65s
Train Epoch: 1779 [61440/90000 (68%)]	Loss: -21.0805	Cost: 5.96s
Train Epoch: 1779 [81920/90000 (91%)]	Loss: -21.2229	Cost: 8.01s
Train Epoch: 1779 	Average Loss: -20.6989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0870

Learning rate: 0.00019984386200540272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1780 [0/90000 (0%)]	Loss: -13.9599	Cost: 24.83s
Train Epoch: 1780 [20480/90000 (23%)]	Loss: -21.0949	Cost: 6.09s
Train Epoch: 1780 [40960/90000 (45%)]	Loss: -20.7049	Cost: 8.43s
Train Epoch: 1780 [61440/90000 (68%)]	Loss: -21.1970	Cost: 5.89s
Train Epoch: 1780 [81920/90000 (91%)]	Loss: -21.0486	Cost: 6.08s
Train Epoch: 1780 	Average Loss: -20.6293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0005

Learning rate: 0.00019984368646726148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1781 [0/90000 (0%)]	Loss: -13.6886	Cost: 22.49s
Train Epoch: 1781 [20480/90000 (23%)]	Loss: -17.6467	Cost: 6.34s
Train Epoch: 1781 [40960/90000 (45%)]	Loss: -17.3918	Cost: 9.28s
Train Epoch: 1781 [61440/90000 (68%)]	Loss: -18.4910	Cost: 6.30s
Train Epoch: 1781 [81920/90000 (91%)]	Loss: -19.1066	Cost: 11.14s
Train Epoch: 1781 	Average Loss: -17.9476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5462

Learning rate: 0.0001998435108305785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1782 [0/90000 (0%)]	Loss: -13.0103	Cost: 27.13s
Train Epoch: 1782 [20480/90000 (23%)]	Loss: -19.1908	Cost: 6.28s
Train Epoch: 1782 [40960/90000 (45%)]	Loss: -18.9094	Cost: 10.61s
Train Epoch: 1782 [61440/90000 (68%)]	Loss: -19.6413	Cost: 5.97s
Train Epoch: 1782 [81920/90000 (91%)]	Loss: -20.1719	Cost: 6.05s
Train Epoch: 1782 	Average Loss: -18.9723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3534

Learning rate: 0.0001998433350953539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1783 [0/90000 (0%)]	Loss: -13.2710	Cost: 26.12s
Train Epoch: 1783 [20480/90000 (23%)]	Loss: -20.6881	Cost: 6.16s
Train Epoch: 1783 [40960/90000 (45%)]	Loss: -20.4892	Cost: 7.79s
Train Epoch: 1783 [61440/90000 (68%)]	Loss: -20.9836	Cost: 6.01s
Train Epoch: 1783 [81920/90000 (91%)]	Loss: -21.0489	Cost: 7.12s
Train Epoch: 1783 	Average Loss: -20.2591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2209

Saving model as e1783_model.pt & e1783_waveforms_supplementary.hdf5
Learning rate: 0.00019984315926158792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1784 [0/90000 (0%)]	Loss: -13.4360	Cost: 23.32s
Train Epoch: 1784 [20480/90000 (23%)]	Loss: -21.2914	Cost: 6.08s
Train Epoch: 1784 [40960/90000 (45%)]	Loss: -20.9809	Cost: 7.10s
Train Epoch: 1784 [61440/90000 (68%)]	Loss: -20.8988	Cost: 6.10s
Train Epoch: 1784 [81920/90000 (91%)]	Loss: -20.9273	Cost: 9.39s
Train Epoch: 1784 	Average Loss: -20.6172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8047

Learning rate: 0.00019984298332928067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1785 [0/90000 (0%)]	Loss: -14.3415	Cost: 24.07s
Train Epoch: 1785 [20480/90000 (23%)]	Loss: -20.9787	Cost: 6.30s
Train Epoch: 1785 [40960/90000 (45%)]	Loss: -19.8393	Cost: 11.15s
Train Epoch: 1785 [61440/90000 (68%)]	Loss: -20.2644	Cost: 6.28s
Train Epoch: 1785 [81920/90000 (91%)]	Loss: -20.5356	Cost: 10.61s
Train Epoch: 1785 	Average Loss: -19.9578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8461

Learning rate: 0.00019984280729843233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1786 [0/90000 (0%)]	Loss: -13.2344	Cost: 26.08s
Train Epoch: 1786 [20480/90000 (23%)]	Loss: -21.0078	Cost: 6.24s
Train Epoch: 1786 [40960/90000 (45%)]	Loss: -20.4784	Cost: 8.44s
Train Epoch: 1786 [61440/90000 (68%)]	Loss: -20.9171	Cost: 6.04s
Train Epoch: 1786 [81920/90000 (91%)]	Loss: -20.8296	Cost: 8.31s
Train Epoch: 1786 	Average Loss: -20.3549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5750

Learning rate: 0.0001998426311690431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1787 [0/90000 (0%)]	Loss: -14.1946	Cost: 24.27s
Train Epoch: 1787 [20480/90000 (23%)]	Loss: -20.7162	Cost: 6.39s
Train Epoch: 1787 [40960/90000 (45%)]	Loss: -20.3601	Cost: 7.12s
Train Epoch: 1787 [61440/90000 (68%)]	Loss: -20.7341	Cost: 5.98s
Train Epoch: 1787 [81920/90000 (91%)]	Loss: -20.8062	Cost: 6.11s
Train Epoch: 1787 	Average Loss: -20.2493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7913

Learning rate: 0.00019984245494111314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1788 [0/90000 (0%)]	Loss: -13.9876	Cost: 23.49s
Train Epoch: 1788 [20480/90000 (23%)]	Loss: -20.7130	Cost: 6.28s
Train Epoch: 1788 [40960/90000 (45%)]	Loss: -20.5640	Cost: 11.60s
Train Epoch: 1788 [61440/90000 (68%)]	Loss: -20.4347	Cost: 6.35s
Train Epoch: 1788 [81920/90000 (91%)]	Loss: -20.5079	Cost: 11.18s
Train Epoch: 1788 	Average Loss: -20.1925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5583

Learning rate: 0.00019984227861464263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1789 [0/90000 (0%)]	Loss: -14.3475	Cost: 29.71s
Train Epoch: 1789 [20480/90000 (23%)]	Loss: -20.8684	Cost: 6.52s
Train Epoch: 1789 [40960/90000 (45%)]	Loss: -20.4980	Cost: 9.11s
Train Epoch: 1789 [61440/90000 (68%)]	Loss: -20.8183	Cost: 5.96s
Train Epoch: 1789 [81920/90000 (91%)]	Loss: -21.0281	Cost: 6.66s
Train Epoch: 1789 	Average Loss: -20.3833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1167

Learning rate: 0.00019984210218963174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1790 [0/90000 (0%)]	Loss: -14.8515	Cost: 25.09s
Train Epoch: 1790 [20480/90000 (23%)]	Loss: -21.3549	Cost: 6.08s
Train Epoch: 1790 [40960/90000 (45%)]	Loss: -20.8297	Cost: 8.67s
Train Epoch: 1790 [61440/90000 (68%)]	Loss: -20.8672	Cost: 5.94s
Train Epoch: 1790 [81920/90000 (91%)]	Loss: -21.1300	Cost: 6.33s
Train Epoch: 1790 	Average Loss: -20.6112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0907

Learning rate: 0.00019984192566608062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1791 [0/90000 (0%)]	Loss: -13.7377	Cost: 22.56s
Train Epoch: 1791 [20480/90000 (23%)]	Loss: -21.2879	Cost: 6.06s
Train Epoch: 1791 [40960/90000 (45%)]	Loss: -20.7815	Cost: 9.01s
Train Epoch: 1791 [61440/90000 (68%)]	Loss: -21.0322	Cost: 6.18s
Train Epoch: 1791 [81920/90000 (91%)]	Loss: -21.1580	Cost: 11.81s
Train Epoch: 1791 	Average Loss: -20.6373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9985

Learning rate: 0.0001998417490439895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1792 [0/90000 (0%)]	Loss: -14.0906	Cost: 26.44s
Train Epoch: 1792 [20480/90000 (23%)]	Loss: -21.0962	Cost: 6.38s
Train Epoch: 1792 [40960/90000 (45%)]	Loss: -20.5231	Cost: 10.89s
Train Epoch: 1792 [61440/90000 (68%)]	Loss: -20.8756	Cost: 6.04s
Train Epoch: 1792 [81920/90000 (91%)]	Loss: -21.0808	Cost: 6.31s
Train Epoch: 1792 	Average Loss: -20.4614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2409

Saving model as e1792_model.pt & e1792_waveforms_supplementary.hdf5
Learning rate: 0.00019984157232335855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1793 [0/90000 (0%)]	Loss: -15.1913	Cost: 35.90s
Train Epoch: 1793 [20480/90000 (23%)]	Loss: -21.3015	Cost: 7.44s
Train Epoch: 1793 [40960/90000 (45%)]	Loss: -20.8464	Cost: 9.93s
Train Epoch: 1793 [61440/90000 (68%)]	Loss: -21.1568	Cost: 6.05s
Train Epoch: 1793 [81920/90000 (91%)]	Loss: -21.1537	Cost: 12.85s
Train Epoch: 1793 	Average Loss: -20.7585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0730

Learning rate: 0.00019984139550418789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1794 [0/90000 (0%)]	Loss: -14.5848	Cost: 51.39s
Train Epoch: 1794 [20480/90000 (23%)]	Loss: -21.0171	Cost: 9.79s
Train Epoch: 1794 [40960/90000 (45%)]	Loss: -20.1235	Cost: 17.01s
Train Epoch: 1794 [61440/90000 (68%)]	Loss: -20.7669	Cost: 11.29s
Train Epoch: 1794 [81920/90000 (91%)]	Loss: -21.1296	Cost: 22.14s
Train Epoch: 1794 	Average Loss: -20.4406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2091

Learning rate: 0.0001998412185864777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1795 [0/90000 (0%)]	Loss: -14.5325	Cost: 49.72s
Train Epoch: 1795 [20480/90000 (23%)]	Loss: -20.9238	Cost: 8.28s
Train Epoch: 1795 [40960/90000 (45%)]	Loss: -20.4819	Cost: 23.28s
Train Epoch: 1795 [61440/90000 (68%)]	Loss: -21.0586	Cost: 13.73s
Train Epoch: 1795 [81920/90000 (91%)]	Loss: -19.8964	Cost: 20.10s
Train Epoch: 1795 	Average Loss: -20.2926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1593

Learning rate: 0.00019984104157022822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1796 [0/90000 (0%)]	Loss: -13.8058	Cost: 76.85s
Train Epoch: 1796 [20480/90000 (23%)]	Loss: -20.1901	Cost: 10.98s
Train Epoch: 1796 [40960/90000 (45%)]	Loss: -19.9690	Cost: 19.45s
Train Epoch: 1796 [61440/90000 (68%)]	Loss: -20.4535	Cost: 14.60s
Train Epoch: 1796 [81920/90000 (91%)]	Loss: -20.6001	Cost: 24.27s
Train Epoch: 1796 	Average Loss: -19.7845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9463

Learning rate: 0.00019984086445543953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1797 [0/90000 (0%)]	Loss: -14.2633	Cost: 105.84s
Train Epoch: 1797 [20480/90000 (23%)]	Loss: -21.0831	Cost: 13.61s
Train Epoch: 1797 [40960/90000 (45%)]	Loss: -20.8217	Cost: 38.42s
Train Epoch: 1797 [61440/90000 (68%)]	Loss: -21.0003	Cost: 13.50s
Train Epoch: 1797 [81920/90000 (91%)]	Loss: -20.8756	Cost: 31.33s
Train Epoch: 1797 	Average Loss: -20.5753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1829

Learning rate: 0.0001998406872421119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1798 [0/90000 (0%)]	Loss: -14.4839	Cost: 79.10s
Train Epoch: 1798 [20480/90000 (23%)]	Loss: -21.3719	Cost: 9.38s
Train Epoch: 1798 [40960/90000 (45%)]	Loss: -20.8396	Cost: 20.65s
Train Epoch: 1798 [61440/90000 (68%)]	Loss: -21.1759	Cost: 11.71s
Train Epoch: 1798 [81920/90000 (91%)]	Loss: -21.2930	Cost: 23.00s
Train Epoch: 1798 	Average Loss: -20.6762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1736

Learning rate: 0.0001998405099302454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1799 [0/90000 (0%)]	Loss: -14.1913	Cost: 28.70s
Train Epoch: 1799 [20480/90000 (23%)]	Loss: -20.8772	Cost: 6.38s
Train Epoch: 1799 [40960/90000 (45%)]	Loss: -19.9361	Cost: 9.28s
Train Epoch: 1799 [61440/90000 (68%)]	Loss: -20.7023	Cost: 6.03s
Train Epoch: 1799 [81920/90000 (91%)]	Loss: -20.7258	Cost: 7.81s
Train Epoch: 1799 	Average Loss: -20.2132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0531

Learning rate: 0.00019984033251984031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1800 [0/90000 (0%)]	Loss: -14.3505	Cost: 26.20s
Train Epoch: 1800 [20480/90000 (23%)]	Loss: -21.2286	Cost: 6.08s
Train Epoch: 1800 [40960/90000 (45%)]	Loss: -20.6195	Cost: 8.96s
Train Epoch: 1800 [61440/90000 (68%)]	Loss: -21.2950	Cost: 5.97s
Train Epoch: 1800 [81920/90000 (91%)]	Loss: -21.5847	Cost: 6.67s
Train Epoch: 1800 	Average Loss: -20.6401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3514

Saving model as e1800_model.pt & e1800_waveforms_supplementary.hdf5
Learning rate: 0.00019984015501089676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1801 [0/90000 (0%)]	Loss: -15.0077	Cost: 23.62s
Train Epoch: 1801 [20480/90000 (23%)]	Loss: -21.4049	Cost: 6.27s
Train Epoch: 1801 [40960/90000 (45%)]	Loss: -21.0756	Cost: 10.35s
Train Epoch: 1801 [61440/90000 (68%)]	Loss: -21.4419	Cost: 6.28s
Train Epoch: 1801 [81920/90000 (91%)]	Loss: -21.1200	Cost: 11.56s
Train Epoch: 1801 	Average Loss: -20.7988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9132

Learning rate: 0.00019983997740341493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1802 [0/90000 (0%)]	Loss: -13.9838	Cost: 28.52s
Train Epoch: 1802 [20480/90000 (23%)]	Loss: -20.8775	Cost: 6.34s
Train Epoch: 1802 [40960/90000 (45%)]	Loss: -20.5187	Cost: 10.54s
Train Epoch: 1802 [61440/90000 (68%)]	Loss: -21.1000	Cost: 5.87s
Train Epoch: 1802 [81920/90000 (91%)]	Loss: -21.1285	Cost: 6.59s
Train Epoch: 1802 	Average Loss: -20.4948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1861

Learning rate: 0.00019983979969739497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1803 [0/90000 (0%)]	Loss: -13.5420	Cost: 27.55s
Train Epoch: 1803 [20480/90000 (23%)]	Loss: -21.4411	Cost: 6.10s
Train Epoch: 1803 [40960/90000 (45%)]	Loss: -20.9549	Cost: 8.06s
Train Epoch: 1803 [61440/90000 (68%)]	Loss: -21.3576	Cost: 5.99s
Train Epoch: 1803 [81920/90000 (91%)]	Loss: -21.3895	Cost: 7.53s
Train Epoch: 1803 	Average Loss: -20.7769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2769

Learning rate: 0.00019983962189283708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1804 [0/90000 (0%)]	Loss: -14.1991	Cost: 24.23s
Train Epoch: 1804 [20480/90000 (23%)]	Loss: -20.6510	Cost: 6.17s
Train Epoch: 1804 [40960/90000 (45%)]	Loss: -20.3590	Cost: 7.98s
Train Epoch: 1804 [61440/90000 (68%)]	Loss: -20.8337	Cost: 6.20s
Train Epoch: 1804 [81920/90000 (91%)]	Loss: -21.0553	Cost: 10.63s
Train Epoch: 1804 	Average Loss: -20.3020
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0086

Learning rate: 0.00019983944398974145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1805 [0/90000 (0%)]	Loss: -13.6442	Cost: 24.51s
Train Epoch: 1805 [20480/90000 (23%)]	Loss: -21.3250	Cost: 6.34s
Train Epoch: 1805 [40960/90000 (45%)]	Loss: -20.9163	Cost: 11.63s
Train Epoch: 1805 [61440/90000 (68%)]	Loss: -21.3135	Cost: 6.32s
Train Epoch: 1805 [81920/90000 (91%)]	Loss: -21.2650	Cost: 10.62s
Train Epoch: 1805 	Average Loss: -20.7406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4261

Saving model as e1805_model.pt & e1805_waveforms_supplementary.hdf5
Learning rate: 0.00019983926598810824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1806 [0/90000 (0%)]	Loss: -15.0603	Cost: 27.49s
Train Epoch: 1806 [20480/90000 (23%)]	Loss: -21.5755	Cost: 6.10s
Train Epoch: 1806 [40960/90000 (45%)]	Loss: -21.0923	Cost: 8.17s
Train Epoch: 1806 [61440/90000 (68%)]	Loss: -21.3071	Cost: 6.00s
Train Epoch: 1806 [81920/90000 (91%)]	Loss: -21.2603	Cost: 8.65s
Train Epoch: 1806 	Average Loss: -20.9016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3450

Learning rate: 0.00019983908788793762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1807 [0/90000 (0%)]	Loss: -13.8725	Cost: 25.57s
Train Epoch: 1807 [20480/90000 (23%)]	Loss: -21.5274	Cost: 6.13s
Train Epoch: 1807 [40960/90000 (45%)]	Loss: -20.9893	Cost: 8.20s
Train Epoch: 1807 [61440/90000 (68%)]	Loss: -21.3291	Cost: 6.04s
Train Epoch: 1807 [81920/90000 (91%)]	Loss: -21.2601	Cost: 8.72s
Train Epoch: 1807 	Average Loss: -20.8111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4409

Saving model as e1807_model.pt & e1807_waveforms_supplementary.hdf5
Learning rate: 0.00019983890968922977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1808 [0/90000 (0%)]	Loss: -15.0086	Cost: 23.55s
Train Epoch: 1808 [20480/90000 (23%)]	Loss: -21.4704	Cost: 6.16s
Train Epoch: 1808 [40960/90000 (45%)]	Loss: -20.8975	Cost: 11.52s
Train Epoch: 1808 [61440/90000 (68%)]	Loss: -21.3453	Cost: 6.23s
Train Epoch: 1808 [81920/90000 (91%)]	Loss: -21.6685	Cost: 10.97s
Train Epoch: 1808 	Average Loss: -20.9040
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4320

Learning rate: 0.00019983873139198485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1809 [0/90000 (0%)]	Loss: -14.2436	Cost: 28.08s
Train Epoch: 1809 [20480/90000 (23%)]	Loss: -21.4863	Cost: 6.41s
Train Epoch: 1809 [40960/90000 (45%)]	Loss: -20.9882	Cost: 9.17s
Train Epoch: 1809 [61440/90000 (68%)]	Loss: -21.4095	Cost: 6.01s
Train Epoch: 1809 [81920/90000 (91%)]	Loss: -21.5459	Cost: 8.85s
Train Epoch: 1809 	Average Loss: -20.8659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2060

Learning rate: 0.00019983855299620306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1810 [0/90000 (0%)]	Loss: -14.6463	Cost: 25.06s
Train Epoch: 1810 [20480/90000 (23%)]	Loss: -21.4301	Cost: 6.07s
Train Epoch: 1810 [40960/90000 (45%)]	Loss: -20.7854	Cost: 8.87s
Train Epoch: 1810 [61440/90000 (68%)]	Loss: -21.1670	Cost: 5.89s
Train Epoch: 1810 [81920/90000 (91%)]	Loss: -21.1671	Cost: 6.24s
Train Epoch: 1810 	Average Loss: -20.6313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2041

Learning rate: 0.0001998383745018846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1811 [0/90000 (0%)]	Loss: -15.0221	Cost: 23.44s
Train Epoch: 1811 [20480/90000 (23%)]	Loss: -21.0511	Cost: 6.09s
Train Epoch: 1811 [40960/90000 (45%)]	Loss: -20.7150	Cost: 10.21s
Train Epoch: 1811 [61440/90000 (68%)]	Loss: -21.3475	Cost: 6.40s
Train Epoch: 1811 [81920/90000 (91%)]	Loss: -21.3525	Cost: 11.44s
Train Epoch: 1811 	Average Loss: -20.7510
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3412

Learning rate: 0.0001998381959090296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1812 [0/90000 (0%)]	Loss: -15.2002	Cost: 27.38s
Train Epoch: 1812 [20480/90000 (23%)]	Loss: -21.6807	Cost: 6.32s
Train Epoch: 1812 [40960/90000 (45%)]	Loss: -21.0569	Cost: 11.11s
Train Epoch: 1812 [61440/90000 (68%)]	Loss: -21.3232	Cost: 5.76s
Train Epoch: 1812 [81920/90000 (91%)]	Loss: -21.5016	Cost: 6.87s
Train Epoch: 1812 	Average Loss: -20.9776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2699

Learning rate: 0.0001998380172176382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1813 [0/90000 (0%)]	Loss: -14.4716	Cost: 26.29s
Train Epoch: 1813 [20480/90000 (23%)]	Loss: -21.5611	Cost: 6.13s
Train Epoch: 1813 [40960/90000 (45%)]	Loss: -20.6472	Cost: 9.19s
Train Epoch: 1813 [61440/90000 (68%)]	Loss: -21.2228	Cost: 6.04s
Train Epoch: 1813 [81920/90000 (91%)]	Loss: -21.1850	Cost: 6.84s
Train Epoch: 1813 	Average Loss: -20.7288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2666

Learning rate: 0.00019983783842771069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1814 [0/90000 (0%)]	Loss: -14.4658	Cost: 24.37s
Train Epoch: 1814 [20480/90000 (23%)]	Loss: -21.3264	Cost: 6.15s
Train Epoch: 1814 [40960/90000 (45%)]	Loss: -20.9102	Cost: 7.78s
Train Epoch: 1814 [61440/90000 (68%)]	Loss: -21.2567	Cost: 6.15s
Train Epoch: 1814 [81920/90000 (91%)]	Loss: -21.2973	Cost: 11.79s
Train Epoch: 1814 	Average Loss: -20.8035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3725

Learning rate: 0.00019983765953924715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1815 [0/90000 (0%)]	Loss: -14.6172	Cost: 24.95s
Train Epoch: 1815 [20480/90000 (23%)]	Loss: -21.3230	Cost: 6.19s
Train Epoch: 1815 [40960/90000 (45%)]	Loss: -20.9502	Cost: 11.43s
Train Epoch: 1815 [61440/90000 (68%)]	Loss: -21.2945	Cost: 6.39s
Train Epoch: 1815 [81920/90000 (91%)]	Loss: -21.2645	Cost: 10.01s
Train Epoch: 1815 	Average Loss: -20.7877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1957

Learning rate: 0.00019983748055224783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1816 [0/90000 (0%)]	Loss: -14.6401	Cost: 28.44s
Train Epoch: 1816 [20480/90000 (23%)]	Loss: -21.0486	Cost: 6.31s
Train Epoch: 1816 [40960/90000 (45%)]	Loss: -20.2952	Cost: 9.20s
Train Epoch: 1816 [61440/90000 (68%)]	Loss: -20.8817	Cost: 6.02s
Train Epoch: 1816 [81920/90000 (91%)]	Loss: -21.0627	Cost: 8.02s
Train Epoch: 1816 	Average Loss: -20.3941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1836

Learning rate: 0.00019983730146671283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1817 [0/90000 (0%)]	Loss: -14.7696	Cost: 24.56s
Train Epoch: 1817 [20480/90000 (23%)]	Loss: -21.3344	Cost: 6.15s
Train Epoch: 1817 [40960/90000 (45%)]	Loss: -20.7967	Cost: 8.69s
Train Epoch: 1817 [61440/90000 (68%)]	Loss: -21.1536	Cost: 6.00s
Train Epoch: 1817 [81920/90000 (91%)]	Loss: -21.3852	Cost: 7.10s
Train Epoch: 1817 	Average Loss: -20.6992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3085

Learning rate: 0.0001998371222826424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1818 [0/90000 (0%)]	Loss: -14.9490	Cost: 23.36s
Train Epoch: 1818 [20480/90000 (23%)]	Loss: -21.3807	Cost: 6.40s
Train Epoch: 1818 [40960/90000 (45%)]	Loss: -21.1852	Cost: 10.32s
Train Epoch: 1818 [61440/90000 (68%)]	Loss: -21.3655	Cost: 6.35s
Train Epoch: 1818 [81920/90000 (91%)]	Loss: -21.2928	Cost: 11.89s
Train Epoch: 1818 	Average Loss: -20.9193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3532

Learning rate: 0.00019983694300003662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1819 [0/90000 (0%)]	Loss: -13.3776	Cost: 27.82s
Train Epoch: 1819 [20480/90000 (23%)]	Loss: -21.1312	Cost: 6.38s
Train Epoch: 1819 [40960/90000 (45%)]	Loss: -20.7325	Cost: 10.53s
Train Epoch: 1819 [61440/90000 (68%)]	Loss: -21.1913	Cost: 5.81s
Train Epoch: 1819 [81920/90000 (91%)]	Loss: -21.4620	Cost: 7.58s
Train Epoch: 1819 	Average Loss: -20.6554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2514

Learning rate: 0.00019983676361889577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1820 [0/90000 (0%)]	Loss: -14.3964	Cost: 26.60s
Train Epoch: 1820 [20480/90000 (23%)]	Loss: -21.4106	Cost: 6.13s
Train Epoch: 1820 [40960/90000 (45%)]	Loss: -20.7855	Cost: 9.40s
Train Epoch: 1820 [61440/90000 (68%)]	Loss: -21.2530	Cost: 5.85s
Train Epoch: 1820 [81920/90000 (91%)]	Loss: -21.4743	Cost: 7.01s
Train Epoch: 1820 	Average Loss: -20.8395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2928

Learning rate: 0.00019983658413921996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1821 [0/90000 (0%)]	Loss: -14.2399	Cost: 24.21s
Train Epoch: 1821 [20480/90000 (23%)]	Loss: -21.4190	Cost: 6.13s
Train Epoch: 1821 [40960/90000 (45%)]	Loss: -20.4705	Cost: 8.53s
Train Epoch: 1821 [61440/90000 (68%)]	Loss: -20.7990	Cost: 6.19s
Train Epoch: 1821 [81920/90000 (91%)]	Loss: -20.9407	Cost: 12.15s
Train Epoch: 1821 	Average Loss: -20.4775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7893

Learning rate: 0.0001998364045610094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1822 [0/90000 (0%)]	Loss: -14.2425	Cost: 25.62s
Train Epoch: 1822 [20480/90000 (23%)]	Loss: -21.2389	Cost: 6.41s
Train Epoch: 1822 [40960/90000 (45%)]	Loss: -20.9036	Cost: 11.98s
Train Epoch: 1822 [61440/90000 (68%)]	Loss: -21.1848	Cost: 6.06s
Train Epoch: 1822 [81920/90000 (91%)]	Loss: -21.4694	Cost: 8.48s
Train Epoch: 1822 	Average Loss: -20.7197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4118

Learning rate: 0.00019983622488426423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1823 [0/90000 (0%)]	Loss: -14.7582	Cost: 28.08s
Train Epoch: 1823 [20480/90000 (23%)]	Loss: -21.5048	Cost: 6.15s
Train Epoch: 1823 [40960/90000 (45%)]	Loss: -20.9018	Cost: 8.54s
Train Epoch: 1823 [61440/90000 (68%)]	Loss: -21.3381	Cost: 5.97s
Train Epoch: 1823 [81920/90000 (91%)]	Loss: -21.5520	Cost: 9.61s
Train Epoch: 1823 	Average Loss: -20.9068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4689

Saving model as e1823_model.pt & e1823_waveforms_supplementary.hdf5
Learning rate: 0.00019983604510898472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1824 [0/90000 (0%)]	Loss: -14.7714	Cost: 24.40s
Train Epoch: 1824 [20480/90000 (23%)]	Loss: -21.6173	Cost: 6.16s
Train Epoch: 1824 [40960/90000 (45%)]	Loss: -21.1205	Cost: 8.19s
Train Epoch: 1824 [61440/90000 (68%)]	Loss: -21.3321	Cost: 6.03s
Train Epoch: 1824 [81920/90000 (91%)]	Loss: -21.3823	Cost: 9.29s
Train Epoch: 1824 	Average Loss: -20.9630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3453

Learning rate: 0.00019983586523517096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1825 [0/90000 (0%)]	Loss: -13.9275	Cost: 24.15s
Train Epoch: 1825 [20480/90000 (23%)]	Loss: -21.2060	Cost: 6.31s
Train Epoch: 1825 [40960/90000 (45%)]	Loss: -20.5910	Cost: 11.89s
Train Epoch: 1825 [61440/90000 (68%)]	Loss: -21.1654	Cost: 6.29s
Train Epoch: 1825 [81920/90000 (91%)]	Loss: -21.4840	Cost: 11.42s
Train Epoch: 1825 	Average Loss: -20.6995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2723

Learning rate: 0.00019983568526282312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1826 [0/90000 (0%)]	Loss: -14.7146	Cost: 28.83s
Train Epoch: 1826 [20480/90000 (23%)]	Loss: -21.3128	Cost: 6.53s
Train Epoch: 1826 [40960/90000 (45%)]	Loss: -20.8446	Cost: 9.50s
Train Epoch: 1826 [61440/90000 (68%)]	Loss: -21.3321	Cost: 6.04s
Train Epoch: 1826 [81920/90000 (91%)]	Loss: -21.5177	Cost: 8.07s
Train Epoch: 1826 	Average Loss: -20.8878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4720

Saving model as e1826_model.pt & e1826_waveforms_supplementary.hdf5
Learning rate: 0.00019983550519194144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1827 [0/90000 (0%)]	Loss: -14.5353	Cost: 24.53s
Train Epoch: 1827 [20480/90000 (23%)]	Loss: -19.9745	Cost: 6.09s
Train Epoch: 1827 [40960/90000 (45%)]	Loss: -19.5723	Cost: 8.43s
Train Epoch: 1827 [61440/90000 (68%)]	Loss: -20.5922	Cost: 5.79s
Train Epoch: 1827 [81920/90000 (91%)]	Loss: -19.6558	Cost: 6.66s
Train Epoch: 1827 	Average Loss: -19.7265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6935

Learning rate: 0.00019983532502252605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1828 [0/90000 (0%)]	Loss: -12.9051	Cost: 23.24s
Train Epoch: 1828 [20480/90000 (23%)]	Loss: -20.0035	Cost: 6.25s
Train Epoch: 1828 [40960/90000 (45%)]	Loss: -19.7853	Cost: 10.65s
Train Epoch: 1828 [61440/90000 (68%)]	Loss: -20.4827	Cost: 6.40s
Train Epoch: 1828 [81920/90000 (91%)]	Loss: -20.7434	Cost: 11.52s
Train Epoch: 1828 	Average Loss: -19.7658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7411

Learning rate: 0.00019983514475457713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1829 [0/90000 (0%)]	Loss: -14.1498	Cost: 28.22s
Train Epoch: 1829 [20480/90000 (23%)]	Loss: -20.5552	Cost: 6.36s
Train Epoch: 1829 [40960/90000 (45%)]	Loss: -19.5663	Cost: 10.59s
Train Epoch: 1829 [61440/90000 (68%)]	Loss: -20.2603	Cost: 5.86s
Train Epoch: 1829 [81920/90000 (91%)]	Loss: -20.7394	Cost: 7.53s
Train Epoch: 1829 	Average Loss: -19.8201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8970

Learning rate: 0.0001998349643880949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1830 [0/90000 (0%)]	Loss: -14.0803	Cost: 25.14s
Train Epoch: 1830 [20480/90000 (23%)]	Loss: -21.0675	Cost: 6.07s
Train Epoch: 1830 [40960/90000 (45%)]	Loss: -20.7029	Cost: 9.47s
Train Epoch: 1830 [61440/90000 (68%)]	Loss: -21.1484	Cost: 5.97s
Train Epoch: 1830 [81920/90000 (91%)]	Loss: -21.3147	Cost: 6.12s
Train Epoch: 1830 	Average Loss: -20.5884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3189

Learning rate: 0.0001998347839230795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1831 [0/90000 (0%)]	Loss: -14.7525	Cost: 24.32s
Train Epoch: 1831 [20480/90000 (23%)]	Loss: -21.2016	Cost: 6.06s
Train Epoch: 1831 [40960/90000 (45%)]	Loss: -20.8155	Cost: 9.36s
Train Epoch: 1831 [61440/90000 (68%)]	Loss: -21.3767	Cost: 6.29s
Train Epoch: 1831 [81920/90000 (91%)]	Loss: -21.5602	Cost: 12.13s
Train Epoch: 1831 	Average Loss: -20.8310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5192

Saving model as e1831_model.pt & e1831_waveforms_supplementary.hdf5
Learning rate: 0.0001998346033595311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1832 [0/90000 (0%)]	Loss: -15.2079	Cost: 28.89s
Train Epoch: 1832 [20480/90000 (23%)]	Loss: -21.5604	Cost: 6.55s
Train Epoch: 1832 [40960/90000 (45%)]	Loss: -21.2591	Cost: 10.57s
Train Epoch: 1832 [61440/90000 (68%)]	Loss: -21.3528	Cost: 5.85s
Train Epoch: 1832 [81920/90000 (91%)]	Loss: -21.3997	Cost: 6.53s
Train Epoch: 1832 	Average Loss: -21.0770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5128

Learning rate: 0.00019983442269744993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1833 [0/90000 (0%)]	Loss: -15.4553	Cost: 27.52s
Train Epoch: 1833 [20480/90000 (23%)]	Loss: -21.6811	Cost: 6.14s
Train Epoch: 1833 [40960/90000 (45%)]	Loss: -21.1205	Cost: 8.41s
Train Epoch: 1833 [61440/90000 (68%)]	Loss: -21.3243	Cost: 6.03s
Train Epoch: 1833 [81920/90000 (91%)]	Loss: -21.5083	Cost: 7.95s
Train Epoch: 1833 	Average Loss: -20.9955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4662

Learning rate: 0.0001998342419368361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1834 [0/90000 (0%)]	Loss: -15.2001	Cost: 24.49s
Train Epoch: 1834 [20480/90000 (23%)]	Loss: -21.4432	Cost: 6.21s
Train Epoch: 1834 [40960/90000 (45%)]	Loss: -20.9799	Cost: 8.68s
Train Epoch: 1834 [61440/90000 (68%)]	Loss: -21.3741	Cost: 6.24s
Train Epoch: 1834 [81920/90000 (91%)]	Loss: -21.3225	Cost: 11.26s
Train Epoch: 1834 	Average Loss: -20.9170
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1186

Learning rate: 0.00019983406107768983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1835 [0/90000 (0%)]	Loss: -14.5010	Cost: 25.99s
Train Epoch: 1835 [20480/90000 (23%)]	Loss: -21.3489	Cost: 6.36s
Train Epoch: 1835 [40960/90000 (45%)]	Loss: -21.1109	Cost: 11.82s
Train Epoch: 1835 [61440/90000 (68%)]	Loss: -21.4805	Cost: 6.25s
Train Epoch: 1835 [81920/90000 (91%)]	Loss: -21.6414	Cost: 9.66s
Train Epoch: 1835 	Average Loss: -20.9323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1813

Learning rate: 0.0001998338801200113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1836 [0/90000 (0%)]	Loss: -14.3800	Cost: 27.49s
Train Epoch: 1836 [20480/90000 (23%)]	Loss: -21.2458	Cost: 6.15s
Train Epoch: 1836 [40960/90000 (45%)]	Loss: -20.5520	Cost: 8.54s
Train Epoch: 1836 [61440/90000 (68%)]	Loss: -21.3673	Cost: 6.00s
Train Epoch: 1836 [81920/90000 (91%)]	Loss: -21.3143	Cost: 8.87s
Train Epoch: 1836 	Average Loss: -20.6712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4282

Learning rate: 0.00019983369906380067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1837 [0/90000 (0%)]	Loss: -15.2378	Cost: 24.81s
Train Epoch: 1837 [20480/90000 (23%)]	Loss: -21.7740	Cost: 6.19s
Train Epoch: 1837 [40960/90000 (45%)]	Loss: -20.9365	Cost: 8.09s
Train Epoch: 1837 [61440/90000 (68%)]	Loss: -21.1252	Cost: 6.26s
Train Epoch: 1837 [81920/90000 (91%)]	Loss: -21.1556	Cost: 10.42s
Train Epoch: 1837 	Average Loss: -20.8123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2124

Learning rate: 0.00019983351790905815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1838 [0/90000 (0%)]	Loss: -14.6257	Cost: 24.98s
Train Epoch: 1838 [20480/90000 (23%)]	Loss: -21.5104	Cost: 6.38s
Train Epoch: 1838 [40960/90000 (45%)]	Loss: -21.1768	Cost: 11.83s
Train Epoch: 1838 [61440/90000 (68%)]	Loss: -21.4702	Cost: 6.30s
Train Epoch: 1838 [81920/90000 (91%)]	Loss: -21.2819	Cost: 10.06s
Train Epoch: 1838 	Average Loss: -20.8290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2173

Learning rate: 0.00019983333665578388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1839 [0/90000 (0%)]	Loss: -14.8265	Cost: 29.19s
Train Epoch: 1839 [20480/90000 (23%)]	Loss: -21.5265	Cost: 6.48s
Train Epoch: 1839 [40960/90000 (45%)]	Loss: -20.7742	Cost: 9.01s
Train Epoch: 1839 [61440/90000 (68%)]	Loss: -21.4581	Cost: 6.00s
Train Epoch: 1839 [81920/90000 (91%)]	Loss: -21.4355	Cost: 8.77s
Train Epoch: 1839 	Average Loss: -20.9373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4050

Learning rate: 0.00019983315530397807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1840 [0/90000 (0%)]	Loss: -14.2011	Cost: 25.50s
Train Epoch: 1840 [20480/90000 (23%)]	Loss: -21.6746	Cost: 6.05s
Train Epoch: 1840 [40960/90000 (45%)]	Loss: -20.9761	Cost: 8.20s
Train Epoch: 1840 [61440/90000 (68%)]	Loss: -21.3646	Cost: 5.90s
Train Epoch: 1840 [81920/90000 (91%)]	Loss: -21.6897	Cost: 8.44s
Train Epoch: 1840 	Average Loss: -20.9411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3702

Learning rate: 0.0001998329738536409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1841 [0/90000 (0%)]	Loss: -14.4455	Cost: 24.21s
Train Epoch: 1841 [20480/90000 (23%)]	Loss: -21.6105	Cost: 6.28s
Train Epoch: 1841 [40960/90000 (45%)]	Loss: -20.9860	Cost: 12.03s
Train Epoch: 1841 [61440/90000 (68%)]	Loss: -21.4235	Cost: 6.24s
Train Epoch: 1841 [81920/90000 (91%)]	Loss: -21.5082	Cost: 11.29s
Train Epoch: 1841 	Average Loss: -21.0210
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3949

Learning rate: 0.0001998327923047725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1842 [0/90000 (0%)]	Loss: -14.8164	Cost: 29.92s
Train Epoch: 1842 [20480/90000 (23%)]	Loss: -21.7551	Cost: 6.60s
Train Epoch: 1842 [40960/90000 (45%)]	Loss: -21.1447	Cost: 9.66s
Train Epoch: 1842 [61440/90000 (68%)]	Loss: -21.5756	Cost: 5.88s
Train Epoch: 1842 [81920/90000 (91%)]	Loss: -21.5630	Cost: 6.86s
Train Epoch: 1842 	Average Loss: -21.0630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6350

Saving model as e1842_model.pt & e1842_waveforms_supplementary.hdf5
Learning rate: 0.0001998326106573731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1843 [0/90000 (0%)]	Loss: -14.6787	Cost: 26.58s
Train Epoch: 1843 [20480/90000 (23%)]	Loss: -21.9877	Cost: 6.14s
Train Epoch: 1843 [40960/90000 (45%)]	Loss: -21.1493	Cost: 9.18s
Train Epoch: 1843 [61440/90000 (68%)]	Loss: -21.5867	Cost: 5.78s
Train Epoch: 1843 [81920/90000 (91%)]	Loss: -21.6909	Cost: 6.70s
Train Epoch: 1843 	Average Loss: -21.1954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5539

Learning rate: 0.00019983242891144287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1844 [0/90000 (0%)]	Loss: -14.1855	Cost: 24.79s
Train Epoch: 1844 [20480/90000 (23%)]	Loss: -21.7395	Cost: 6.29s
Train Epoch: 1844 [40960/90000 (45%)]	Loss: -20.8974	Cost: 9.86s
Train Epoch: 1844 [61440/90000 (68%)]	Loss: -21.6395	Cost: 6.31s
Train Epoch: 1844 [81920/90000 (91%)]	Loss: -21.5765	Cost: 11.60s
Train Epoch: 1844 	Average Loss: -21.0235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8296

Saving model as e1844_model.pt & e1844_waveforms_supplementary.hdf5
Learning rate: 0.00019983224706698197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1845 [0/90000 (0%)]	Loss: -14.5871	Cost: 26.93s
Train Epoch: 1845 [20480/90000 (23%)]	Loss: -21.8069	Cost: 6.65s
Train Epoch: 1845 [40960/90000 (45%)]	Loss: -21.0623	Cost: 10.71s
Train Epoch: 1845 [61440/90000 (68%)]	Loss: -21.5740	Cost: 5.84s
Train Epoch: 1845 [81920/90000 (91%)]	Loss: -21.5266	Cost: 7.19s
Train Epoch: 1845 	Average Loss: -21.0651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5192

Learning rate: 0.00019983206512399059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1846 [0/90000 (0%)]	Loss: -14.8979	Cost: 26.85s
Train Epoch: 1846 [20480/90000 (23%)]	Loss: -21.6304	Cost: 6.17s
Train Epoch: 1846 [40960/90000 (45%)]	Loss: -21.0814	Cost: 8.26s
Train Epoch: 1846 [61440/90000 (68%)]	Loss: -21.2949	Cost: 5.97s
Train Epoch: 1846 [81920/90000 (91%)]	Loss: -21.5122	Cost: 8.22s
Train Epoch: 1846 	Average Loss: -21.0121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5652

Learning rate: 0.00019983188308246892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1847 [0/90000 (0%)]	Loss: -15.3278	Cost: 23.89s
Train Epoch: 1847 [20480/90000 (23%)]	Loss: -21.5734	Cost: 6.14s
Train Epoch: 1847 [40960/90000 (45%)]	Loss: -21.0140	Cost: 7.75s
Train Epoch: 1847 [61440/90000 (68%)]	Loss: -21.3856	Cost: 6.26s
Train Epoch: 1847 [81920/90000 (91%)]	Loss: -21.5454	Cost: 10.67s
Train Epoch: 1847 	Average Loss: -21.0090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5037

Learning rate: 0.00019983170094241712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1848 [0/90000 (0%)]	Loss: -14.4021	Cost: 24.81s
Train Epoch: 1848 [20480/90000 (23%)]	Loss: -21.5016	Cost: 6.20s
Train Epoch: 1848 [40960/90000 (45%)]	Loss: -20.9138	Cost: 11.49s
Train Epoch: 1848 [61440/90000 (68%)]	Loss: -21.5082	Cost: 6.23s
Train Epoch: 1848 [81920/90000 (91%)]	Loss: -21.4751	Cost: 10.64s
Train Epoch: 1848 	Average Loss: -20.8609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2713

Learning rate: 0.00019983151870383537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1849 [0/90000 (0%)]	Loss: -14.5230	Cost: 27.17s
Train Epoch: 1849 [20480/90000 (23%)]	Loss: -21.4437	Cost: 6.18s
Train Epoch: 1849 [40960/90000 (45%)]	Loss: -21.1118	Cost: 8.40s
Train Epoch: 1849 [61440/90000 (68%)]	Loss: -21.5464	Cost: 5.95s
Train Epoch: 1849 [81920/90000 (91%)]	Loss: -21.7918	Cost: 9.58s
Train Epoch: 1849 	Average Loss: -20.9940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9132

Learning rate: 0.00019983133636672387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1850 [0/90000 (0%)]	Loss: -13.9903	Cost: 24.28s
Train Epoch: 1850 [20480/90000 (23%)]	Loss: -20.5815	Cost: 6.12s
Train Epoch: 1850 [40960/90000 (45%)]	Loss: -20.1981	Cost: 8.05s
Train Epoch: 1850 [61440/90000 (68%)]	Loss: -20.9275	Cost: 6.09s
Train Epoch: 1850 [81920/90000 (91%)]	Loss: -21.1656	Cost: 9.12s
Train Epoch: 1850 	Average Loss: -20.2879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4527

Learning rate: 0.00019983115393108278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1851 [0/90000 (0%)]	Loss: -14.3575	Cost: 23.51s
Train Epoch: 1851 [20480/90000 (23%)]	Loss: -21.4763	Cost: 6.35s
Train Epoch: 1851 [40960/90000 (45%)]	Loss: -20.6842	Cost: 11.86s
Train Epoch: 1851 [61440/90000 (68%)]	Loss: -21.0261	Cost: 6.34s
Train Epoch: 1851 [81920/90000 (91%)]	Loss: -21.0434	Cost: 11.21s
Train Epoch: 1851 	Average Loss: -20.6870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1924

Learning rate: 0.00019983097139691233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1852 [0/90000 (0%)]	Loss: -13.8962	Cost: 29.10s
Train Epoch: 1852 [20480/90000 (23%)]	Loss: -21.1885	Cost: 6.41s
Train Epoch: 1852 [40960/90000 (45%)]	Loss: -20.8042	Cost: 9.76s
Train Epoch: 1852 [61440/90000 (68%)]	Loss: -20.7971	Cost: 5.91s
Train Epoch: 1852 [81920/90000 (91%)]	Loss: -20.9423	Cost: 8.53s
Train Epoch: 1852 	Average Loss: -20.5933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0477

Learning rate: 0.0001998307887642126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1853 [0/90000 (0%)]	Loss: -14.3531	Cost: 25.71s
Train Epoch: 1853 [20480/90000 (23%)]	Loss: -21.2317	Cost: 6.07s
Train Epoch: 1853 [40960/90000 (45%)]	Loss: -20.6610	Cost: 8.86s
Train Epoch: 1853 [61440/90000 (68%)]	Loss: -21.1366	Cost: 5.81s
Train Epoch: 1853 [81920/90000 (91%)]	Loss: -19.6813	Cost: 6.28s
Train Epoch: 1853 	Average Loss: -20.1902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0636

Learning rate: 0.00019983060603298388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1854 [0/90000 (0%)]	Loss: -13.1584	Cost: 24.51s
Train Epoch: 1854 [20480/90000 (23%)]	Loss: -20.0347	Cost: 5.98s
Train Epoch: 1854 [40960/90000 (45%)]	Loss: -19.9999	Cost: 9.29s
Train Epoch: 1854 [61440/90000 (68%)]	Loss: -20.7107	Cost: 6.14s
Train Epoch: 1854 [81920/90000 (91%)]	Loss: -21.0601	Cost: 11.80s
Train Epoch: 1854 	Average Loss: -19.9612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2426

Learning rate: 0.00019983042320322628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1855 [0/90000 (0%)]	Loss: -14.0476	Cost: 26.73s
Train Epoch: 1855 [20480/90000 (23%)]	Loss: -21.5606	Cost: 6.73s
Train Epoch: 1855 [40960/90000 (45%)]	Loss: -21.0043	Cost: 10.87s
Train Epoch: 1855 [61440/90000 (68%)]	Loss: -21.6673	Cost: 6.15s
Train Epoch: 1855 [81920/90000 (91%)]	Loss: -21.6701	Cost: 8.77s
Train Epoch: 1855 	Average Loss: -21.0177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6929

Learning rate: 0.00019983024027494002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1856 [0/90000 (0%)]	Loss: -15.6683	Cost: 28.29s
Train Epoch: 1856 [20480/90000 (23%)]	Loss: -21.8249	Cost: 6.17s
Train Epoch: 1856 [40960/90000 (45%)]	Loss: -20.9479	Cost: 8.99s
Train Epoch: 1856 [61440/90000 (68%)]	Loss: -21.5475	Cost: 5.97s
Train Epoch: 1856 [81920/90000 (91%)]	Loss: -21.5477	Cost: 8.22s
Train Epoch: 1856 	Average Loss: -21.1773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4583

Learning rate: 0.00019983005724812523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1857 [0/90000 (0%)]	Loss: -14.6761	Cost: 24.58s
Train Epoch: 1857 [20480/90000 (23%)]	Loss: -21.8522	Cost: 6.14s
Train Epoch: 1857 [40960/90000 (45%)]	Loss: -21.1826	Cost: 8.27s
Train Epoch: 1857 [61440/90000 (68%)]	Loss: -21.5751	Cost: 5.92s
Train Epoch: 1857 [81920/90000 (91%)]	Loss: -21.6721	Cost: 7.00s
Train Epoch: 1857 	Average Loss: -21.0831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5251

Learning rate: 0.00019982987412278216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1858 [0/90000 (0%)]	Loss: -14.5149	Cost: 23.47s
Train Epoch: 1858 [20480/90000 (23%)]	Loss: -21.8405	Cost: 6.49s
Train Epoch: 1858 [40960/90000 (45%)]	Loss: -21.5630	Cost: 10.67s
Train Epoch: 1858 [61440/90000 (68%)]	Loss: -21.5552	Cost: 6.35s
Train Epoch: 1858 [81920/90000 (91%)]	Loss: -21.6578	Cost: 11.32s
Train Epoch: 1858 	Average Loss: -21.1653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8730

Saving model as e1858_model.pt & e1858_waveforms_supplementary.hdf5
Learning rate: 0.00019982969089891095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1859 [0/90000 (0%)]	Loss: -14.3157	Cost: 28.31s
Train Epoch: 1859 [20480/90000 (23%)]	Loss: -21.5982	Cost: 6.40s
Train Epoch: 1859 [40960/90000 (45%)]	Loss: -21.3575	Cost: 9.35s
Train Epoch: 1859 [61440/90000 (68%)]	Loss: -21.6090	Cost: 5.96s
Train Epoch: 1859 [81920/90000 (91%)]	Loss: -21.6741	Cost: 9.15s
Train Epoch: 1859 	Average Loss: -21.1355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6498

Learning rate: 0.00019982950757651177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1860 [0/90000 (0%)]	Loss: -13.8856	Cost: 24.68s
Train Epoch: 1860 [20480/90000 (23%)]	Loss: -21.6578	Cost: 6.09s
Train Epoch: 1860 [40960/90000 (45%)]	Loss: -21.2627	Cost: 8.53s
Train Epoch: 1860 [61440/90000 (68%)]	Loss: -21.3265	Cost: 5.80s
Train Epoch: 1860 [81920/90000 (91%)]	Loss: -21.4545	Cost: 6.78s
Train Epoch: 1860 	Average Loss: -21.0281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6025

Learning rate: 0.00019982932415558483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1861 [0/90000 (0%)]	Loss: -14.6711	Cost: 23.66s
Train Epoch: 1861 [20480/90000 (23%)]	Loss: -21.5628	Cost: 6.34s
Train Epoch: 1861 [40960/90000 (45%)]	Loss: -21.0417	Cost: 10.06s
Train Epoch: 1861 [61440/90000 (68%)]	Loss: -21.5059	Cost: 6.31s
Train Epoch: 1861 [81920/90000 (91%)]	Loss: -21.6213	Cost: 11.59s
Train Epoch: 1861 	Average Loss: -21.0192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5610

Learning rate: 0.00019982914063613026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1862 [0/90000 (0%)]	Loss: -15.2174	Cost: 27.67s
Train Epoch: 1862 [20480/90000 (23%)]	Loss: -21.8353	Cost: 6.50s
Train Epoch: 1862 [40960/90000 (45%)]	Loss: -21.3636	Cost: 10.83s
Train Epoch: 1862 [61440/90000 (68%)]	Loss: -21.5414	Cost: 5.88s
Train Epoch: 1862 [81920/90000 (91%)]	Loss: -21.6294	Cost: 8.22s
Train Epoch: 1862 	Average Loss: -21.1270
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7291

Learning rate: 0.00019982895701814828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1863 [0/90000 (0%)]	Loss: -14.0887	Cost: 26.81s
Train Epoch: 1863 [20480/90000 (23%)]	Loss: -21.6492	Cost: 6.11s
Train Epoch: 1863 [40960/90000 (45%)]	Loss: -21.2327	Cost: 8.67s
Train Epoch: 1863 [61440/90000 (68%)]	Loss: -21.5655	Cost: 6.11s
Train Epoch: 1863 [81920/90000 (91%)]	Loss: -21.5511	Cost: 7.15s
Train Epoch: 1863 	Average Loss: -20.9989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6032

Learning rate: 0.0001998287733016391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1864 [0/90000 (0%)]	Loss: -15.5607	Cost: 24.11s
Train Epoch: 1864 [20480/90000 (23%)]	Loss: -21.7726	Cost: 6.13s
Train Epoch: 1864 [40960/90000 (45%)]	Loss: -21.4622	Cost: 7.96s
Train Epoch: 1864 [61440/90000 (68%)]	Loss: -21.7834	Cost: 6.21s
Train Epoch: 1864 [81920/90000 (91%)]	Loss: -21.8853	Cost: 11.15s
Train Epoch: 1864 	Average Loss: -21.2696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9330

Saving model as e1864_model.pt & e1864_waveforms_supplementary.hdf5
Learning rate: 0.00019982858948660283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1865 [0/90000 (0%)]	Loss: -15.0745	Cost: 25.68s
Train Epoch: 1865 [20480/90000 (23%)]	Loss: -21.8180	Cost: 6.23s
Train Epoch: 1865 [40960/90000 (45%)]	Loss: -21.1619	Cost: 11.15s
Train Epoch: 1865 [61440/90000 (68%)]	Loss: -21.7299	Cost: 6.21s
Train Epoch: 1865 [81920/90000 (91%)]	Loss: -21.7153	Cost: 9.69s
Train Epoch: 1865 	Average Loss: -21.1485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5192

Learning rate: 0.0001998284055730397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1866 [0/90000 (0%)]	Loss: -15.4599	Cost: 27.41s
Train Epoch: 1866 [20480/90000 (23%)]	Loss: -21.7930	Cost: 6.24s
Train Epoch: 1866 [40960/90000 (45%)]	Loss: -20.8711	Cost: 8.37s
Train Epoch: 1866 [61440/90000 (68%)]	Loss: -21.3098	Cost: 5.96s
Train Epoch: 1866 [81920/90000 (91%)]	Loss: -21.4161	Cost: 8.00s
Train Epoch: 1866 	Average Loss: -20.9018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3776

Learning rate: 0.00019982822156094988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1867 [0/90000 (0%)]	Loss: -14.7487	Cost: 25.68s
Train Epoch: 1867 [20480/90000 (23%)]	Loss: -21.5984	Cost: 6.04s
Train Epoch: 1867 [40960/90000 (45%)]	Loss: -21.1154	Cost: 8.24s
Train Epoch: 1867 [61440/90000 (68%)]	Loss: -21.4592	Cost: 5.77s
Train Epoch: 1867 [81920/90000 (91%)]	Loss: -21.7626	Cost: 7.07s
Train Epoch: 1867 	Average Loss: -21.0840
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5792

Learning rate: 0.0001998280374503336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1868 [0/90000 (0%)]	Loss: -14.7864	Cost: 23.90s
Train Epoch: 1868 [20480/90000 (23%)]	Loss: -21.7992	Cost: 6.41s
Train Epoch: 1868 [40960/90000 (45%)]	Loss: -21.2946	Cost: 10.88s
Train Epoch: 1868 [61440/90000 (68%)]	Loss: -21.4112	Cost: 6.41s
Train Epoch: 1868 [81920/90000 (91%)]	Loss: -21.7421	Cost: 11.51s
Train Epoch: 1868 	Average Loss: -21.1526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7316

Learning rate: 0.00019982785324119097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1869 [0/90000 (0%)]	Loss: -15.1130	Cost: 30.27s
Train Epoch: 1869 [20480/90000 (23%)]	Loss: -22.0648	Cost: 6.27s
Train Epoch: 1869 [40960/90000 (45%)]	Loss: -21.2679	Cost: 10.62s
Train Epoch: 1869 [61440/90000 (68%)]	Loss: -21.7547	Cost: 6.05s
Train Epoch: 1869 [81920/90000 (91%)]	Loss: -21.7299	Cost: 5.79s
Train Epoch: 1869 	Average Loss: -21.2450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8198

Learning rate: 0.0001998276689335222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1870 [0/90000 (0%)]	Loss: -15.2631	Cost: 27.14s
Train Epoch: 1870 [20480/90000 (23%)]	Loss: -21.9362	Cost: 6.09s
Train Epoch: 1870 [40960/90000 (45%)]	Loss: -21.4540	Cost: 8.40s
Train Epoch: 1870 [61440/90000 (68%)]	Loss: -21.6062	Cost: 5.99s
Train Epoch: 1870 [81920/90000 (91%)]	Loss: -21.8896	Cost: 7.87s
Train Epoch: 1870 	Average Loss: -21.2999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7096

Learning rate: 0.0001998274845273275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1871 [0/90000 (0%)]	Loss: -15.1084	Cost: 24.10s
Train Epoch: 1871 [20480/90000 (23%)]	Loss: -21.7857	Cost: 6.21s
Train Epoch: 1871 [40960/90000 (45%)]	Loss: -21.3779	Cost: 7.99s
Train Epoch: 1871 [61440/90000 (68%)]	Loss: -21.7140	Cost: 6.34s
Train Epoch: 1871 [81920/90000 (91%)]	Loss: -21.6383	Cost: 9.74s
Train Epoch: 1871 	Average Loss: -21.2056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1223

Learning rate: 0.000199827300022607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1872 [0/90000 (0%)]	Loss: -14.3069	Cost: 24.30s
Train Epoch: 1872 [20480/90000 (23%)]	Loss: -20.6843	Cost: 6.26s
Train Epoch: 1872 [40960/90000 (45%)]	Loss: -20.6006	Cost: 11.81s
Train Epoch: 1872 [61440/90000 (68%)]	Loss: -21.2316	Cost: 6.28s
Train Epoch: 1872 [81920/90000 (91%)]	Loss: -21.4189	Cost: 11.17s
Train Epoch: 1872 	Average Loss: -20.5109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5378

Learning rate: 0.0001998271154193609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1873 [0/90000 (0%)]	Loss: -15.2519	Cost: 28.02s
Train Epoch: 1873 [20480/90000 (23%)]	Loss: -21.6252	Cost: 6.47s
Train Epoch: 1873 [40960/90000 (45%)]	Loss: -21.1234	Cost: 9.19s
Train Epoch: 1873 [61440/90000 (68%)]	Loss: -21.5981	Cost: 5.99s
Train Epoch: 1873 [81920/90000 (91%)]	Loss: -21.6522	Cost: 7.84s
Train Epoch: 1873 	Average Loss: -21.1713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6179

Learning rate: 0.00019982693071758938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1874 [0/90000 (0%)]	Loss: -14.4632	Cost: 25.84s
Train Epoch: 1874 [20480/90000 (23%)]	Loss: -21.9235	Cost: 6.02s
Train Epoch: 1874 [40960/90000 (45%)]	Loss: -21.2959	Cost: 8.73s
Train Epoch: 1874 [61440/90000 (68%)]	Loss: -21.5350	Cost: 5.83s
Train Epoch: 1874 [81920/90000 (91%)]	Loss: -21.9639	Cost: 6.73s
Train Epoch: 1874 	Average Loss: -21.2275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7281

Learning rate: 0.00019982674591729265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1875 [0/90000 (0%)]	Loss: -14.6714	Cost: 24.07s
Train Epoch: 1875 [20480/90000 (23%)]	Loss: -21.7167	Cost: 6.22s
Train Epoch: 1875 [40960/90000 (45%)]	Loss: -21.3256	Cost: 9.62s
Train Epoch: 1875 [61440/90000 (68%)]	Loss: -21.7544	Cost: 6.27s
Train Epoch: 1875 [81920/90000 (91%)]	Loss: -21.7553	Cost: 11.84s
Train Epoch: 1875 	Average Loss: -21.2335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6620

Learning rate: 0.00019982656101847086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1876 [0/90000 (0%)]	Loss: -15.0943	Cost: 26.56s
Train Epoch: 1876 [20480/90000 (23%)]	Loss: -21.7787	Cost: 6.54s
Train Epoch: 1876 [40960/90000 (45%)]	Loss: -21.5359	Cost: 10.63s
Train Epoch: 1876 [61440/90000 (68%)]	Loss: -21.8080	Cost: 5.81s
Train Epoch: 1876 [81920/90000 (91%)]	Loss: -21.9390	Cost: 7.35s
Train Epoch: 1876 	Average Loss: -21.3131
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7825

Learning rate: 0.00019982637602112418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1877 [0/90000 (0%)]	Loss: -13.8640	Cost: 27.58s
Train Epoch: 1877 [20480/90000 (23%)]	Loss: -21.9368	Cost: 6.05s
Train Epoch: 1877 [40960/90000 (45%)]	Loss: -21.2706	Cost: 8.15s
Train Epoch: 1877 [61440/90000 (68%)]	Loss: -21.6454	Cost: 5.99s
Train Epoch: 1877 [81920/90000 (91%)]	Loss: -21.9283	Cost: 8.05s
Train Epoch: 1877 	Average Loss: -21.2091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7483

Learning rate: 0.00019982619092525286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1878 [0/90000 (0%)]	Loss: -14.2735	Cost: 24.41s
Train Epoch: 1878 [20480/90000 (23%)]	Loss: -21.7626	Cost: 6.18s
Train Epoch: 1878 [40960/90000 (45%)]	Loss: -21.3390	Cost: 8.32s
Train Epoch: 1878 [61440/90000 (68%)]	Loss: -21.7918	Cost: 6.10s
Train Epoch: 1878 [81920/90000 (91%)]	Loss: -21.7799	Cost: 7.81s
Train Epoch: 1878 	Average Loss: -21.2148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8269

Learning rate: 0.00019982600573085699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1879 [0/90000 (0%)]	Loss: -15.2804	Cost: 23.33s
Train Epoch: 1879 [20480/90000 (23%)]	Loss: -21.9520	Cost: 6.40s
Train Epoch: 1879 [40960/90000 (45%)]	Loss: -21.5304	Cost: 11.39s
Train Epoch: 1879 [61440/90000 (68%)]	Loss: -21.7781	Cost: 6.26s
Train Epoch: 1879 [81920/90000 (91%)]	Loss: -21.8671	Cost: 11.27s
Train Epoch: 1879 	Average Loss: -21.3141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6552

Learning rate: 0.00019982582043793682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1880 [0/90000 (0%)]	Loss: -15.0212	Cost: 27.52s
Train Epoch: 1880 [20480/90000 (23%)]	Loss: -21.9583	Cost: 6.33s
Train Epoch: 1880 [40960/90000 (45%)]	Loss: -21.2379	Cost: 10.00s
Train Epoch: 1880 [61440/90000 (68%)]	Loss: -21.6188	Cost: 5.93s
Train Epoch: 1880 [81920/90000 (91%)]	Loss: -21.8251	Cost: 8.75s
Train Epoch: 1880 	Average Loss: -21.1805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5655

Learning rate: 0.00019982563504649254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1881 [0/90000 (0%)]	Loss: -14.8223	Cost: 25.15s
Train Epoch: 1881 [20480/90000 (23%)]	Loss: -21.5622	Cost: 6.07s
Train Epoch: 1881 [40960/90000 (45%)]	Loss: -20.9945	Cost: 8.95s
Train Epoch: 1881 [61440/90000 (68%)]	Loss: -21.6012	Cost: 5.83s
Train Epoch: 1881 [81920/90000 (91%)]	Loss: -21.7483	Cost: 6.48s
Train Epoch: 1881 	Average Loss: -20.9534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4903

Learning rate: 0.00019982544955652427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1882 [0/90000 (0%)]	Loss: -13.8401	Cost: 23.84s
Train Epoch: 1882 [20480/90000 (23%)]	Loss: -21.7887	Cost: 6.09s
Train Epoch: 1882 [40960/90000 (45%)]	Loss: -21.3168	Cost: 9.53s
Train Epoch: 1882 [61440/90000 (68%)]	Loss: -21.8140	Cost: 6.25s
Train Epoch: 1882 [81920/90000 (91%)]	Loss: -21.9638	Cost: 12.25s
Train Epoch: 1882 	Average Loss: -21.1690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8586

Learning rate: 0.00019982526396803224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1883 [0/90000 (0%)]	Loss: -14.9339	Cost: 27.90s
Train Epoch: 1883 [20480/90000 (23%)]	Loss: -22.0924	Cost: 6.48s
Train Epoch: 1883 [40960/90000 (45%)]	Loss: -21.4909	Cost: 10.48s
Train Epoch: 1883 [61440/90000 (68%)]	Loss: -21.8194	Cost: 5.77s
Train Epoch: 1883 [81920/90000 (91%)]	Loss: -21.9810	Cost: 6.79s
Train Epoch: 1883 	Average Loss: -21.4295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9195

Learning rate: 0.00019982507828101664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1884 [0/90000 (0%)]	Loss: -15.3996	Cost: 27.48s
Train Epoch: 1884 [20480/90000 (23%)]	Loss: -22.0259	Cost: 6.09s
Train Epoch: 1884 [40960/90000 (45%)]	Loss: -21.3153	Cost: 8.30s
Train Epoch: 1884 [61440/90000 (68%)]	Loss: -21.8590	Cost: 6.00s
Train Epoch: 1884 [81920/90000 (91%)]	Loss: -21.7923	Cost: 8.56s
Train Epoch: 1884 	Average Loss: -21.3163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7783

Learning rate: 0.00019982489249547762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1885 [0/90000 (0%)]	Loss: -14.8402	Cost: 24.08s
Train Epoch: 1885 [20480/90000 (23%)]	Loss: -21.7160	Cost: 6.12s
Train Epoch: 1885 [40960/90000 (45%)]	Loss: -21.1656	Cost: 8.16s
Train Epoch: 1885 [61440/90000 (68%)]	Loss: -21.6942	Cost: 5.80s
Train Epoch: 1885 [81920/90000 (91%)]	Loss: -21.3870	Cost: 7.04s
Train Epoch: 1885 	Average Loss: -21.1580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6474

Learning rate: 0.00019982470661141538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1886 [0/90000 (0%)]	Loss: -15.1663	Cost: 23.24s
Train Epoch: 1886 [20480/90000 (23%)]	Loss: -21.9504	Cost: 6.24s
Train Epoch: 1886 [40960/90000 (45%)]	Loss: -21.2526	Cost: 10.76s
Train Epoch: 1886 [61440/90000 (68%)]	Loss: -21.7875	Cost: 6.40s
Train Epoch: 1886 [81920/90000 (91%)]	Loss: -21.7906	Cost: 11.42s
Train Epoch: 1886 	Average Loss: -21.3027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8364

Learning rate: 0.00019982452062883014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1887 [0/90000 (0%)]	Loss: -14.5422	Cost: 27.62s
Train Epoch: 1887 [20480/90000 (23%)]	Loss: -22.0640	Cost: 6.39s
Train Epoch: 1887 [40960/90000 (45%)]	Loss: -21.6571	Cost: 10.45s
Train Epoch: 1887 [61440/90000 (68%)]	Loss: -21.5894	Cost: 5.81s
Train Epoch: 1887 [81920/90000 (91%)]	Loss: -21.6529	Cost: 6.76s
Train Epoch: 1887 	Average Loss: -21.3095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4676

Learning rate: 0.00019982433454772202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1888 [0/90000 (0%)]	Loss: -15.4844	Cost: 26.86s
Train Epoch: 1888 [20480/90000 (23%)]	Loss: -21.9003	Cost: 6.09s
Train Epoch: 1888 [40960/90000 (45%)]	Loss: -21.3732	Cost: 8.40s
Train Epoch: 1888 [61440/90000 (68%)]	Loss: -21.4935	Cost: 5.98s
Train Epoch: 1888 [81920/90000 (91%)]	Loss: -21.7091	Cost: 7.87s
Train Epoch: 1888 	Average Loss: -21.1988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6296

Learning rate: 0.0001998241483680912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1889 [0/90000 (0%)]	Loss: -15.1988	Cost: 24.29s
Train Epoch: 1889 [20480/90000 (23%)]	Loss: -21.8155	Cost: 6.12s
Train Epoch: 1889 [40960/90000 (45%)]	Loss: -21.2869	Cost: 8.22s
Train Epoch: 1889 [61440/90000 (68%)]	Loss: -21.6971	Cost: 6.16s
Train Epoch: 1889 [81920/90000 (91%)]	Loss: -21.6618	Cost: 9.49s
Train Epoch: 1889 	Average Loss: -21.2617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7164

Learning rate: 0.00019982396208993795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1890 [0/90000 (0%)]	Loss: -14.2871	Cost: 24.57s
Train Epoch: 1890 [20480/90000 (23%)]	Loss: -21.8895	Cost: 6.25s
Train Epoch: 1890 [40960/90000 (45%)]	Loss: -21.0463	Cost: 11.93s
Train Epoch: 1890 [61440/90000 (68%)]	Loss: -21.5579	Cost: 6.28s
Train Epoch: 1890 [81920/90000 (91%)]	Loss: -21.5750	Cost: 11.50s
Train Epoch: 1890 	Average Loss: -21.0724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4841

Learning rate: 0.00019982377571326233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1891 [0/90000 (0%)]	Loss: -14.2789	Cost: 28.00s
Train Epoch: 1891 [20480/90000 (23%)]	Loss: -22.0461	Cost: 6.48s
Train Epoch: 1891 [40960/90000 (45%)]	Loss: -21.6295	Cost: 9.12s
Train Epoch: 1891 [61440/90000 (68%)]	Loss: -21.9106	Cost: 5.98s
Train Epoch: 1891 [81920/90000 (91%)]	Loss: -21.9793	Cost: 9.06s
Train Epoch: 1891 	Average Loss: -21.3166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8956

Learning rate: 0.00019982358923806466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1892 [0/90000 (0%)]	Loss: -14.8171	Cost: 25.19s
Train Epoch: 1892 [20480/90000 (23%)]	Loss: -21.9627	Cost: 6.09s
Train Epoch: 1892 [40960/90000 (45%)]	Loss: -21.0451	Cost: 8.32s
Train Epoch: 1892 [61440/90000 (68%)]	Loss: -21.4551	Cost: 5.95s
Train Epoch: 1892 [81920/90000 (91%)]	Loss: -21.6055	Cost: 7.18s
Train Epoch: 1892 	Average Loss: -21.1801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6053

Learning rate: 0.00019982340266434502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1893 [0/90000 (0%)]	Loss: -14.9916	Cost: 23.15s
Train Epoch: 1893 [20480/90000 (23%)]	Loss: -21.7382	Cost: 6.18s
Train Epoch: 1893 [40960/90000 (45%)]	Loss: -21.2751	Cost: 10.89s
Train Epoch: 1893 [61440/90000 (68%)]	Loss: -21.4916	Cost: 6.30s
Train Epoch: 1893 [81920/90000 (91%)]	Loss: -21.6403	Cost: 11.51s
Train Epoch: 1893 	Average Loss: -21.1170
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7105

Learning rate: 0.00019982321599210364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1894 [0/90000 (0%)]	Loss: -15.4739	Cost: 27.90s
Train Epoch: 1894 [20480/90000 (23%)]	Loss: -21.8452	Cost: 6.38s
Train Epoch: 1894 [40960/90000 (45%)]	Loss: -21.2582	Cost: 10.64s
Train Epoch: 1894 [61440/90000 (68%)]	Loss: -21.8916	Cost: 5.79s
Train Epoch: 1894 [81920/90000 (91%)]	Loss: -21.6400	Cost: 6.98s
Train Epoch: 1894 	Average Loss: -21.2691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7150

Learning rate: 0.0001998230292213407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1895 [0/90000 (0%)]	Loss: -15.4843	Cost: 27.51s
Train Epoch: 1895 [20480/90000 (23%)]	Loss: -21.9952	Cost: 6.03s
Train Epoch: 1895 [40960/90000 (45%)]	Loss: -21.4410	Cost: 8.35s
Train Epoch: 1895 [61440/90000 (68%)]	Loss: -21.7781	Cost: 5.96s
Train Epoch: 1895 [81920/90000 (91%)]	Loss: -21.5621	Cost: 7.73s
Train Epoch: 1895 	Average Loss: -21.1973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5418

Learning rate: 0.00019982284235205638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1896 [0/90000 (0%)]	Loss: -14.7357	Cost: 24.57s
Train Epoch: 1896 [20480/90000 (23%)]	Loss: -21.6674	Cost: 6.15s
Train Epoch: 1896 [40960/90000 (45%)]	Loss: -21.5749	Cost: 7.95s
Train Epoch: 1896 [61440/90000 (68%)]	Loss: -21.6315	Cost: 6.06s
Train Epoch: 1896 [81920/90000 (91%)]	Loss: -21.7639	Cost: 8.62s
Train Epoch: 1896 	Average Loss: -21.2251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7100

Learning rate: 0.00019982265538425086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1897 [0/90000 (0%)]	Loss: -15.1118	Cost: 23.27s
Train Epoch: 1897 [20480/90000 (23%)]	Loss: -22.0072	Cost: 6.47s
Train Epoch: 1897 [40960/90000 (45%)]	Loss: -21.3459	Cost: 11.09s
Train Epoch: 1897 [61440/90000 (68%)]	Loss: -21.5938	Cost: 6.42s
Train Epoch: 1897 [81920/90000 (91%)]	Loss: -21.6529	Cost: 11.14s
Train Epoch: 1897 	Average Loss: -21.2565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7607

Learning rate: 0.00019982246831792432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1898 [0/90000 (0%)]	Loss: -15.1153	Cost: 27.98s
Train Epoch: 1898 [20480/90000 (23%)]	Loss: -21.9320	Cost: 6.39s
Train Epoch: 1898 [40960/90000 (45%)]	Loss: -21.3432	Cost: 9.62s
Train Epoch: 1898 [61440/90000 (68%)]	Loss: -22.0202	Cost: 5.96s
Train Epoch: 1898 [81920/90000 (91%)]	Loss: -21.4867	Cost: 8.27s
Train Epoch: 1898 	Average Loss: -21.2181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5983

Learning rate: 0.00019982228115307697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1899 [0/90000 (0%)]	Loss: -15.1190	Cost: 25.50s
Train Epoch: 1899 [20480/90000 (23%)]	Loss: -21.6133	Cost: 6.07s
Train Epoch: 1899 [40960/90000 (45%)]	Loss: -21.0977	Cost: 9.31s
Train Epoch: 1899 [61440/90000 (68%)]	Loss: -21.6915	Cost: 5.84s
Train Epoch: 1899 [81920/90000 (91%)]	Loss: -21.7980	Cost: 6.33s
Train Epoch: 1899 	Average Loss: -21.1506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7523

Learning rate: 0.00019982209388970894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1900 [0/90000 (0%)]	Loss: -15.0041	Cost: 23.60s
Train Epoch: 1900 [20480/90000 (23%)]	Loss: -21.9153	Cost: 5.99s
Train Epoch: 1900 [40960/90000 (45%)]	Loss: -21.4798	Cost: 9.59s
Train Epoch: 1900 [61440/90000 (68%)]	Loss: -21.9880	Cost: 6.14s
Train Epoch: 1900 [81920/90000 (91%)]	Loss: -21.8781	Cost: 12.11s
Train Epoch: 1900 	Average Loss: -21.3845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8696

Learning rate: 0.00019982190652782049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1901 [0/90000 (0%)]	Loss: -15.0485	Cost: 26.62s
Train Epoch: 1901 [20480/90000 (23%)]	Loss: -21.8906	Cost: 6.54s
Train Epoch: 1901 [40960/90000 (45%)]	Loss: -21.4199	Cost: 11.34s
Train Epoch: 1901 [61440/90000 (68%)]	Loss: -21.7856	Cost: 6.28s
Train Epoch: 1901 [81920/90000 (91%)]	Loss: -21.7776	Cost: 8.46s
Train Epoch: 1901 	Average Loss: -21.3101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8357

Learning rate: 0.00019982171906741174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1902 [0/90000 (0%)]	Loss: -14.8893	Cost: 27.44s
Train Epoch: 1902 [20480/90000 (23%)]	Loss: -22.0085	Cost: 6.14s
Train Epoch: 1902 [40960/90000 (45%)]	Loss: -21.4191	Cost: 8.53s
Train Epoch: 1902 [61440/90000 (68%)]	Loss: -21.4809	Cost: 5.97s
Train Epoch: 1902 [81920/90000 (91%)]	Loss: -21.7863	Cost: 9.39s
Train Epoch: 1902 	Average Loss: -21.2157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7545

Learning rate: 0.0001998215315084829
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1903 [0/90000 (0%)]	Loss: -15.2066	Cost: 24.46s
Train Epoch: 1903 [20480/90000 (23%)]	Loss: -22.0097	Cost: 6.14s
Train Epoch: 1903 [40960/90000 (45%)]	Loss: -21.2691	Cost: 8.21s
Train Epoch: 1903 [61440/90000 (68%)]	Loss: -21.7003	Cost: 5.95s
Train Epoch: 1903 [81920/90000 (91%)]	Loss: -21.7125	Cost: 7.86s
Train Epoch: 1903 	Average Loss: -21.2406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8409

Learning rate: 0.0001998213438510342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1904 [0/90000 (0%)]	Loss: -15.2833	Cost: 23.42s
Train Epoch: 1904 [20480/90000 (23%)]	Loss: -21.9698	Cost: 6.45s
Train Epoch: 1904 [40960/90000 (45%)]	Loss: -21.2352	Cost: 11.40s
Train Epoch: 1904 [61440/90000 (68%)]	Loss: -21.9020	Cost: 6.36s
Train Epoch: 1904 [81920/90000 (91%)]	Loss: -22.1648	Cost: 11.56s
Train Epoch: 1904 	Average Loss: -21.2956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7646

Learning rate: 0.00019982115609506576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1905 [0/90000 (0%)]	Loss: -15.0183	Cost: 27.70s
Train Epoch: 1905 [20480/90000 (23%)]	Loss: -22.1476	Cost: 6.32s
Train Epoch: 1905 [40960/90000 (45%)]	Loss: -21.6763	Cost: 9.80s
Train Epoch: 1905 [61440/90000 (68%)]	Loss: -21.9835	Cost: 5.93s
Train Epoch: 1905 [81920/90000 (91%)]	Loss: -21.7243	Cost: 8.26s
Train Epoch: 1905 	Average Loss: -21.4413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8116

Learning rate: 0.00019982096824057777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1906 [0/90000 (0%)]	Loss: -15.0857	Cost: 25.38s
Train Epoch: 1906 [20480/90000 (23%)]	Loss: -21.5757	Cost: 6.08s
Train Epoch: 1906 [40960/90000 (45%)]	Loss: -21.2546	Cost: 9.34s
Train Epoch: 1906 [61440/90000 (68%)]	Loss: -21.4097	Cost: 5.82s
Train Epoch: 1906 [81920/90000 (91%)]	Loss: -21.6268	Cost: 6.42s
Train Epoch: 1906 	Average Loss: -21.0967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6684

Learning rate: 0.00019982078028757045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1907 [0/90000 (0%)]	Loss: -15.3504	Cost: 23.57s
Train Epoch: 1907 [20480/90000 (23%)]	Loss: -21.7662	Cost: 6.09s
Train Epoch: 1907 [40960/90000 (45%)]	Loss: -21.5961	Cost: 9.79s
Train Epoch: 1907 [61440/90000 (68%)]	Loss: -22.0223	Cost: 6.16s
Train Epoch: 1907 [81920/90000 (91%)]	Loss: -21.8682	Cost: 12.20s
Train Epoch: 1907 	Average Loss: -21.3762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0645

Saving model as e1907_model.pt & e1907_waveforms_supplementary.hdf5
Learning rate: 0.00019982059223604397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1908 [0/90000 (0%)]	Loss: -14.9527	Cost: 28.86s
Train Epoch: 1908 [20480/90000 (23%)]	Loss: -22.0492	Cost: 6.47s
Train Epoch: 1908 [40960/90000 (45%)]	Loss: -21.2917	Cost: 10.62s
Train Epoch: 1908 [61440/90000 (68%)]	Loss: -21.6014	Cost: 5.82s
Train Epoch: 1908 [81920/90000 (91%)]	Loss: -21.6761	Cost: 6.55s
Train Epoch: 1908 	Average Loss: -21.1837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6479

Learning rate: 0.00019982040408599852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1909 [0/90000 (0%)]	Loss: -15.4285	Cost: 27.19s
Train Epoch: 1909 [20480/90000 (23%)]	Loss: -21.6858	Cost: 6.27s
Train Epoch: 1909 [40960/90000 (45%)]	Loss: -21.3361	Cost: 8.00s
Train Epoch: 1909 [61440/90000 (68%)]	Loss: -21.7797	Cost: 6.02s
Train Epoch: 1909 [81920/90000 (91%)]	Loss: -21.9822	Cost: 8.02s
Train Epoch: 1909 	Average Loss: -21.2863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8926

Learning rate: 0.00019982021583743426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1910 [0/90000 (0%)]	Loss: -15.1533	Cost: 24.88s
Train Epoch: 1910 [20480/90000 (23%)]	Loss: -21.7250	Cost: 6.08s
Train Epoch: 1910 [40960/90000 (45%)]	Loss: -20.9622	Cost: 7.80s
Train Epoch: 1910 [61440/90000 (68%)]	Loss: -21.3852	Cost: 6.12s
Train Epoch: 1910 [81920/90000 (91%)]	Loss: -21.6838	Cost: 10.88s
Train Epoch: 1910 	Average Loss: -21.0183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8208

Learning rate: 0.0001998200274903514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1911 [0/90000 (0%)]	Loss: -14.7709	Cost: 24.31s
Train Epoch: 1911 [20480/90000 (23%)]	Loss: -20.6272	Cost: 6.21s
Train Epoch: 1911 [40960/90000 (45%)]	Loss: -20.2752	Cost: 11.05s
Train Epoch: 1911 [61440/90000 (68%)]	Loss: -20.9844	Cost: 6.24s
Train Epoch: 1911 [81920/90000 (91%)]	Loss: -20.9958	Cost: 10.67s
Train Epoch: 1911 	Average Loss: -20.3810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0948

Learning rate: 0.00019981983904475013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1912 [0/90000 (0%)]	Loss: -14.6999	Cost: 27.88s
Train Epoch: 1912 [20480/90000 (23%)]	Loss: -21.4232	Cost: 6.32s
Train Epoch: 1912 [40960/90000 (45%)]	Loss: -20.9375	Cost: 9.34s
Train Epoch: 1912 [61440/90000 (68%)]	Loss: -21.5172	Cost: 6.00s
Train Epoch: 1912 [81920/90000 (91%)]	Loss: -21.5347	Cost: 8.24s
Train Epoch: 1912 	Average Loss: -20.9644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7303

Learning rate: 0.00019981965050063063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1913 [0/90000 (0%)]	Loss: -15.4304	Cost: 26.16s
Train Epoch: 1913 [20480/90000 (23%)]	Loss: -22.0361	Cost: 6.10s
Train Epoch: 1913 [40960/90000 (45%)]	Loss: -21.3884	Cost: 8.66s
Train Epoch: 1913 [61440/90000 (68%)]	Loss: -21.6918	Cost: 5.94s
Train Epoch: 1913 [81920/90000 (91%)]	Loss: -21.9045	Cost: 5.98s
Train Epoch: 1913 	Average Loss: -21.2938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8979

Learning rate: 0.00019981946185799307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1914 [0/90000 (0%)]	Loss: -13.7976	Cost: 23.46s
Train Epoch: 1914 [20480/90000 (23%)]	Loss: -20.4108	Cost: 6.02s
Train Epoch: 1914 [40960/90000 (45%)]	Loss: -20.3259	Cost: 10.26s
Train Epoch: 1914 [61440/90000 (68%)]	Loss: -20.4033	Cost: 6.24s
Train Epoch: 1914 [81920/90000 (91%)]	Loss: -20.7315	Cost: 11.86s
Train Epoch: 1914 	Average Loss: -20.1960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1834

Learning rate: 0.00019981927311683766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1915 [0/90000 (0%)]	Loss: -13.3937	Cost: 27.35s
Train Epoch: 1915 [20480/90000 (23%)]	Loss: -21.5400	Cost: 6.28s
Train Epoch: 1915 [40960/90000 (45%)]	Loss: -20.8474	Cost: 10.61s
Train Epoch: 1915 [61440/90000 (68%)]	Loss: -21.2700	Cost: 5.82s
Train Epoch: 1915 [81920/90000 (91%)]	Loss: -21.2901	Cost: 7.08s
Train Epoch: 1915 	Average Loss: -20.7341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4127

Learning rate: 0.0001998190842771646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1916 [0/90000 (0%)]	Loss: -15.1011	Cost: 26.58s
Train Epoch: 1916 [20480/90000 (23%)]	Loss: -21.8454	Cost: 6.16s
Train Epoch: 1916 [40960/90000 (45%)]	Loss: -21.4164	Cost: 8.50s
Train Epoch: 1916 [61440/90000 (68%)]	Loss: -21.6403	Cost: 5.98s
Train Epoch: 1916 [81920/90000 (91%)]	Loss: -21.9703	Cost: 7.79s
Train Epoch: 1916 	Average Loss: -21.2084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7223

Learning rate: 0.000199818895338974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1917 [0/90000 (0%)]	Loss: -14.3745	Cost: 24.34s
Train Epoch: 1917 [20480/90000 (23%)]	Loss: -22.1211	Cost: 6.15s
Train Epoch: 1917 [40960/90000 (45%)]	Loss: -20.9342	Cost: 8.16s
Train Epoch: 1917 [61440/90000 (68%)]	Loss: -21.5300	Cost: 6.10s
Train Epoch: 1917 [81920/90000 (91%)]	Loss: -21.8493	Cost: 10.45s
Train Epoch: 1917 	Average Loss: -21.1141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7829

Learning rate: 0.00019981870630226615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1918 [0/90000 (0%)]	Loss: -14.5799	Cost: 25.48s
Train Epoch: 1918 [20480/90000 (23%)]	Loss: -22.1674	Cost: 6.39s
Train Epoch: 1918 [40960/90000 (45%)]	Loss: -21.5295	Cost: 11.65s
Train Epoch: 1918 [61440/90000 (68%)]	Loss: -22.0400	Cost: 6.25s
Train Epoch: 1918 [81920/90000 (91%)]	Loss: -21.8902	Cost: 9.65s
Train Epoch: 1918 	Average Loss: -21.4386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0095

Learning rate: 0.00019981851716704117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1919 [0/90000 (0%)]	Loss: -14.6205	Cost: 27.33s
Train Epoch: 1919 [20480/90000 (23%)]	Loss: -21.8683	Cost: 6.26s
Train Epoch: 1919 [40960/90000 (45%)]	Loss: -21.3172	Cost: 8.72s
Train Epoch: 1919 [61440/90000 (68%)]	Loss: -21.7956	Cost: 5.98s
Train Epoch: 1919 [81920/90000 (91%)]	Loss: -21.8606	Cost: 8.34s
Train Epoch: 1919 	Average Loss: -21.2492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7468

Learning rate: 0.00019981832793329927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1920 [0/90000 (0%)]	Loss: -13.8902	Cost: 24.27s
Train Epoch: 1920 [20480/90000 (23%)]	Loss: -21.8578	Cost: 6.12s
Train Epoch: 1920 [40960/90000 (45%)]	Loss: -21.5024	Cost: 8.16s
Train Epoch: 1920 [61440/90000 (68%)]	Loss: -22.0313	Cost: 5.84s
Train Epoch: 1920 [81920/90000 (91%)]	Loss: -21.9543	Cost: 7.07s
Train Epoch: 1920 	Average Loss: -21.3723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9062

Learning rate: 0.0001998181386010406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1921 [0/90000 (0%)]	Loss: -15.2752	Cost: 23.65s
Train Epoch: 1921 [20480/90000 (23%)]	Loss: -21.9594	Cost: 6.39s
Train Epoch: 1921 [40960/90000 (45%)]	Loss: -21.4669	Cost: 10.79s
Train Epoch: 1921 [61440/90000 (68%)]	Loss: -22.0036	Cost: 6.38s
Train Epoch: 1921 [81920/90000 (91%)]	Loss: -21.9542	Cost: 11.56s
Train Epoch: 1921 	Average Loss: -21.4102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8858

Learning rate: 0.0001998179491702654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1922 [0/90000 (0%)]	Loss: -15.8896	Cost: 27.91s
Train Epoch: 1922 [20480/90000 (23%)]	Loss: -22.1023	Cost: 6.38s
Train Epoch: 1922 [40960/90000 (45%)]	Loss: -21.3031	Cost: 10.60s
Train Epoch: 1922 [61440/90000 (68%)]	Loss: -21.6921	Cost: 5.84s
Train Epoch: 1922 [81920/90000 (91%)]	Loss: -21.4623	Cost: 6.43s
Train Epoch: 1922 	Average Loss: -21.2885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6321

Learning rate: 0.0001998177596409738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1923 [0/90000 (0%)]	Loss: -14.6182	Cost: 26.92s
Train Epoch: 1923 [20480/90000 (23%)]	Loss: -21.6487	Cost: 6.18s
Train Epoch: 1923 [40960/90000 (45%)]	Loss: -20.9927	Cost: 8.38s
Train Epoch: 1923 [61440/90000 (68%)]	Loss: -21.4929	Cost: 5.98s
Train Epoch: 1923 [81920/90000 (91%)]	Loss: -21.9114	Cost: 8.39s
Train Epoch: 1923 	Average Loss: -21.1332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7360

Learning rate: 0.00019981757001316604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1924 [0/90000 (0%)]	Loss: -15.1683	Cost: 24.53s
Train Epoch: 1924 [20480/90000 (23%)]	Loss: -21.9162	Cost: 6.14s
Train Epoch: 1924 [40960/90000 (45%)]	Loss: -20.4507	Cost: 8.34s
Train Epoch: 1924 [61440/90000 (68%)]	Loss: -20.8650	Cost: 5.84s
Train Epoch: 1924 [81920/90000 (91%)]	Loss: -21.1799	Cost: 8.22s
Train Epoch: 1924 	Average Loss: -20.7497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4303

Learning rate: 0.00019981738028684227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1925 [0/90000 (0%)]	Loss: -13.8708	Cost: 22.67s
Train Epoch: 1925 [20480/90000 (23%)]	Loss: -21.4673	Cost: 6.68s
Train Epoch: 1925 [40960/90000 (45%)]	Loss: -21.1272	Cost: 10.65s
Train Epoch: 1925 [61440/90000 (68%)]	Loss: -21.7196	Cost: 6.42s
Train Epoch: 1925 [81920/90000 (91%)]	Loss: -21.6556	Cost: 11.47s
Train Epoch: 1925 	Average Loss: -21.0647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6268

Learning rate: 0.00019981719046200272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1926 [0/90000 (0%)]	Loss: -14.7097	Cost: 27.84s
Train Epoch: 1926 [20480/90000 (23%)]	Loss: -21.9062	Cost: 6.48s
Train Epoch: 1926 [40960/90000 (45%)]	Loss: -21.6090	Cost: 10.33s
Train Epoch: 1926 [61440/90000 (68%)]	Loss: -21.8725	Cost: 5.78s
Train Epoch: 1926 [81920/90000 (91%)]	Loss: -21.9107	Cost: 6.71s
Train Epoch: 1926 	Average Loss: -21.3143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6707

Learning rate: 0.00019981700053864755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1927 [0/90000 (0%)]	Loss: -15.2486	Cost: 25.28s
Train Epoch: 1927 [20480/90000 (23%)]	Loss: -21.9737	Cost: 6.18s
Train Epoch: 1927 [40960/90000 (45%)]	Loss: -21.6886	Cost: 8.76s
Train Epoch: 1927 [61440/90000 (68%)]	Loss: -21.7317	Cost: 5.96s
Train Epoch: 1927 [81920/90000 (91%)]	Loss: -21.7669	Cost: 7.11s
Train Epoch: 1927 	Average Loss: -21.3323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7890

Learning rate: 0.00019981681051677694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1928 [0/90000 (0%)]	Loss: -15.4032	Cost: 25.34s
Train Epoch: 1928 [20480/90000 (23%)]	Loss: -21.5643	Cost: 6.07s
Train Epoch: 1928 [40960/90000 (45%)]	Loss: -21.2819	Cost: 8.17s
Train Epoch: 1928 [61440/90000 (68%)]	Loss: -21.8720	Cost: 6.24s
Train Epoch: 1928 [81920/90000 (91%)]	Loss: -21.7923	Cost: 12.38s
Train Epoch: 1928 	Average Loss: -21.2597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8601

Learning rate: 0.0001998166203963911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1929 [0/90000 (0%)]	Loss: -15.2861	Cost: 25.23s
Train Epoch: 1929 [20480/90000 (23%)]	Loss: -22.0694	Cost: 6.32s
Train Epoch: 1929 [40960/90000 (45%)]	Loss: -21.5130	Cost: 11.73s
Train Epoch: 1929 [61440/90000 (68%)]	Loss: -21.8487	Cost: 6.19s
Train Epoch: 1929 [81920/90000 (91%)]	Loss: -22.0353	Cost: 8.07s
Train Epoch: 1929 	Average Loss: -21.3869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0525

Learning rate: 0.00019981643017749019
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1930 [0/90000 (0%)]	Loss: -15.7182	Cost: 27.48s
Train Epoch: 1930 [20480/90000 (23%)]	Loss: -22.0680	Cost: 6.18s
Train Epoch: 1930 [40960/90000 (45%)]	Loss: -21.4835	Cost: 8.52s
Train Epoch: 1930 [61440/90000 (68%)]	Loss: -22.0042	Cost: 5.96s
Train Epoch: 1930 [81920/90000 (91%)]	Loss: -21.8173	Cost: 8.00s
Train Epoch: 1930 	Average Loss: -21.5224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9039

Learning rate: 0.00019981623986007441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1931 [0/90000 (0%)]	Loss: -15.0374	Cost: 24.57s
Train Epoch: 1931 [20480/90000 (23%)]	Loss: -21.7949	Cost: 6.17s
Train Epoch: 1931 [40960/90000 (45%)]	Loss: -21.1075	Cost: 8.66s
Train Epoch: 1931 [61440/90000 (68%)]	Loss: -21.6697	Cost: 5.82s
Train Epoch: 1931 [81920/90000 (91%)]	Loss: -21.9088	Cost: 6.62s
Train Epoch: 1931 	Average Loss: -21.1168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8674

Learning rate: 0.00019981604944414397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1932 [0/90000 (0%)]	Loss: -14.8456	Cost: 23.64s
Train Epoch: 1932 [20480/90000 (23%)]	Loss: -22.2074	Cost: 6.25s
Train Epoch: 1932 [40960/90000 (45%)]	Loss: -21.7949	Cost: 9.76s
Train Epoch: 1932 [61440/90000 (68%)]	Loss: -22.0593	Cost: 6.27s
Train Epoch: 1932 [81920/90000 (91%)]	Loss: -21.9051	Cost: 11.71s
Train Epoch: 1932 	Average Loss: -21.5030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9915

Learning rate: 0.00019981585892969904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1933 [0/90000 (0%)]	Loss: -15.0282	Cost: 26.53s
Train Epoch: 1933 [20480/90000 (23%)]	Loss: -21.9635	Cost: 6.70s
Train Epoch: 1933 [40960/90000 (45%)]	Loss: -21.4473	Cost: 10.56s
Train Epoch: 1933 [61440/90000 (68%)]	Loss: -21.8030	Cost: 5.88s
Train Epoch: 1933 [81920/90000 (91%)]	Loss: -22.1423	Cost: 7.88s
Train Epoch: 1933 	Average Loss: -21.4216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9723

Learning rate: 0.00019981566831673978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1934 [0/90000 (0%)]	Loss: -13.6805	Cost: 22.97s
Train Epoch: 1934 [20480/90000 (23%)]	Loss: -22.1937	Cost: 6.00s
Train Epoch: 1934 [40960/90000 (45%)]	Loss: -21.4949	Cost: 8.03s
Train Epoch: 1934 [61440/90000 (68%)]	Loss: -22.0857	Cost: 5.85s
Train Epoch: 1934 [81920/90000 (91%)]	Loss: -21.7473	Cost: 5.91s
Train Epoch: 1934 	Average Loss: -21.4165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8063

Learning rate: 0.00019981547760526642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1935 [0/90000 (0%)]	Loss: -14.6668	Cost: 22.87s
Train Epoch: 1935 [20480/90000 (23%)]	Loss: -22.0562	Cost: 6.01s
Train Epoch: 1935 [40960/90000 (45%)]	Loss: -21.7606	Cost: 7.75s
Train Epoch: 1935 [61440/90000 (68%)]	Loss: -22.0809	Cost: 5.84s
Train Epoch: 1935 [81920/90000 (91%)]	Loss: -22.3455	Cost: 6.07s
Train Epoch: 1935 	Average Loss: -21.6371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0535

Learning rate: 0.00019981528679527915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1936 [0/90000 (0%)]	Loss: -15.6298	Cost: 22.81s
Train Epoch: 1936 [20480/90000 (23%)]	Loss: -21.9974	Cost: 5.97s
Train Epoch: 1936 [40960/90000 (45%)]	Loss: -21.7034	Cost: 7.97s
Train Epoch: 1936 [61440/90000 (68%)]	Loss: -22.0974	Cost: 5.78s
Train Epoch: 1936 [81920/90000 (91%)]	Loss: -22.0609	Cost: 6.52s
Train Epoch: 1936 	Average Loss: -21.5691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0012

Learning rate: 0.00019981509588677812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1937 [0/90000 (0%)]	Loss: -15.3330	Cost: 22.83s
Train Epoch: 1937 [20480/90000 (23%)]	Loss: -22.1916	Cost: 6.00s
Train Epoch: 1937 [40960/90000 (45%)]	Loss: -21.6163	Cost: 8.02s
Train Epoch: 1937 [61440/90000 (68%)]	Loss: -21.9700	Cost: 6.10s
Train Epoch: 1937 [81920/90000 (91%)]	Loss: -21.7165	Cost: 6.05s
Train Epoch: 1937 	Average Loss: -21.5018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6844

Learning rate: 0.00019981490487976355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1938 [0/90000 (0%)]	Loss: -15.1303	Cost: 22.68s
Train Epoch: 1938 [20480/90000 (23%)]	Loss: -22.0752	Cost: 6.01s
Train Epoch: 1938 [40960/90000 (45%)]	Loss: -21.5223	Cost: 7.60s
Train Epoch: 1938 [61440/90000 (68%)]	Loss: -22.1241	Cost: 5.85s
Train Epoch: 1938 [81920/90000 (91%)]	Loss: -22.1785	Cost: 6.23s
Train Epoch: 1938 	Average Loss: -21.5062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7853

Learning rate: 0.0001998147137742356
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1939 [0/90000 (0%)]	Loss: -15.2296	Cost: 22.96s
Train Epoch: 1939 [20480/90000 (23%)]	Loss: -22.0489	Cost: 5.99s
Train Epoch: 1939 [40960/90000 (45%)]	Loss: -21.6785	Cost: 7.79s
Train Epoch: 1939 [61440/90000 (68%)]	Loss: -22.0897	Cost: 5.76s
Train Epoch: 1939 [81920/90000 (91%)]	Loss: -21.2257	Cost: 6.46s
Train Epoch: 1939 	Average Loss: -21.4583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0346

Learning rate: 0.00019981452257019448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1940 [0/90000 (0%)]	Loss: -14.5260	Cost: 22.77s
Train Epoch: 1940 [20480/90000 (23%)]	Loss: -21.0893	Cost: 6.01s
Train Epoch: 1940 [40960/90000 (45%)]	Loss: -21.0779	Cost: 8.08s
Train Epoch: 1940 [61440/90000 (68%)]	Loss: -21.4762	Cost: 5.86s
Train Epoch: 1940 [81920/90000 (91%)]	Loss: -20.6152	Cost: 6.33s
Train Epoch: 1940 	Average Loss: -20.6650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8747

Learning rate: 0.00019981433126764036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1941 [0/90000 (0%)]	Loss: -13.6364	Cost: 22.74s
Train Epoch: 1941 [20480/90000 (23%)]	Loss: -20.9060	Cost: 6.01s
Train Epoch: 1941 [40960/90000 (45%)]	Loss: -20.5109	Cost: 8.20s
Train Epoch: 1941 [61440/90000 (68%)]	Loss: -21.4001	Cost: 5.82s
Train Epoch: 1941 [81920/90000 (91%)]	Loss: -21.8082	Cost: 6.45s
Train Epoch: 1941 	Average Loss: -20.6748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8184

Learning rate: 0.00019981413986657346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1942 [0/90000 (0%)]	Loss: -15.5325	Cost: 22.81s
Train Epoch: 1942 [20480/90000 (23%)]	Loss: -22.0886	Cost: 6.04s
Train Epoch: 1942 [40960/90000 (45%)]	Loss: -21.5098	Cost: 8.11s
Train Epoch: 1942 [61440/90000 (68%)]	Loss: -22.0797	Cost: 5.83s
Train Epoch: 1942 [81920/90000 (91%)]	Loss: -22.1453	Cost: 6.10s
Train Epoch: 1942 	Average Loss: -21.5527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0673

Saving model as e1942_model.pt & e1942_waveforms_supplementary.hdf5
Learning rate: 0.00019981394836699395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1943 [0/90000 (0%)]	Loss: -15.8737	Cost: 23.38s
Train Epoch: 1943 [20480/90000 (23%)]	Loss: -22.3842	Cost: 6.16s
Train Epoch: 1943 [40960/90000 (45%)]	Loss: -21.8720	Cost: 7.51s
Train Epoch: 1943 [61440/90000 (68%)]	Loss: -22.1360	Cost: 5.83s
Train Epoch: 1943 [81920/90000 (91%)]	Loss: -22.3530	Cost: 6.41s
Train Epoch: 1943 	Average Loss: -21.7145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0702

Saving model as e1943_model.pt & e1943_waveforms_supplementary.hdf5
Learning rate: 0.00019981375676890204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1944 [0/90000 (0%)]	Loss: -14.9211	Cost: 22.15s
Train Epoch: 1944 [20480/90000 (23%)]	Loss: -22.3556	Cost: 6.03s
Train Epoch: 1944 [40960/90000 (45%)]	Loss: -21.8149	Cost: 8.29s
Train Epoch: 1944 [61440/90000 (68%)]	Loss: -22.2014	Cost: 5.83s
Train Epoch: 1944 [81920/90000 (91%)]	Loss: -22.2550	Cost: 6.31s
Train Epoch: 1944 	Average Loss: -21.7264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9853

Learning rate: 0.00019981356507229787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1945 [0/90000 (0%)]	Loss: -16.0563	Cost: 22.49s
Train Epoch: 1945 [20480/90000 (23%)]	Loss: -22.1891	Cost: 6.05s
Train Epoch: 1945 [40960/90000 (45%)]	Loss: -21.6046	Cost: 8.02s
Train Epoch: 1945 [61440/90000 (68%)]	Loss: -22.0432	Cost: 5.98s
Train Epoch: 1945 [81920/90000 (91%)]	Loss: -21.9712	Cost: 6.18s
Train Epoch: 1945 	Average Loss: -21.5892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0339

Learning rate: 0.00019981337327718165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1946 [0/90000 (0%)]	Loss: -14.8268	Cost: 22.71s
Train Epoch: 1946 [20480/90000 (23%)]	Loss: -22.0833	Cost: 6.00s
Train Epoch: 1946 [40960/90000 (45%)]	Loss: -21.4123	Cost: 7.84s
Train Epoch: 1946 [61440/90000 (68%)]	Loss: -21.9697	Cost: 5.81s
Train Epoch: 1946 [81920/90000 (91%)]	Loss: -21.8034	Cost: 6.27s
Train Epoch: 1946 	Average Loss: -21.3342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9517

Learning rate: 0.00019981318138355362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1947 [0/90000 (0%)]	Loss: -15.3961	Cost: 22.91s
Train Epoch: 1947 [20480/90000 (23%)]	Loss: -21.7748	Cost: 6.02s
Train Epoch: 1947 [40960/90000 (45%)]	Loss: -21.5290	Cost: 7.78s
Train Epoch: 1947 [61440/90000 (68%)]	Loss: -21.7004	Cost: 5.82s
Train Epoch: 1947 [81920/90000 (91%)]	Loss: -22.0021	Cost: 6.23s
Train Epoch: 1947 	Average Loss: -21.3771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0754

Saving model as e1947_model.pt & e1947_waveforms_supplementary.hdf5
Learning rate: 0.0001998129893914139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1948 [0/90000 (0%)]	Loss: -14.9511	Cost: 22.70s
Train Epoch: 1948 [20480/90000 (23%)]	Loss: -22.2097	Cost: 5.99s
Train Epoch: 1948 [40960/90000 (45%)]	Loss: -21.8651	Cost: 7.90s
Train Epoch: 1948 [61440/90000 (68%)]	Loss: -21.9838	Cost: 5.78s
Train Epoch: 1948 [81920/90000 (91%)]	Loss: -21.7356	Cost: 6.22s
Train Epoch: 1948 	Average Loss: -21.5601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8176

Learning rate: 0.00019981279730076271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1949 [0/90000 (0%)]	Loss: -15.2629	Cost: 22.60s
Train Epoch: 1949 [20480/90000 (23%)]	Loss: -21.7189	Cost: 5.99s
Train Epoch: 1949 [40960/90000 (45%)]	Loss: -21.3399	Cost: 7.99s
Train Epoch: 1949 [61440/90000 (68%)]	Loss: -22.0503	Cost: 5.78s
Train Epoch: 1949 [81920/90000 (91%)]	Loss: -22.0152	Cost: 6.14s
Train Epoch: 1949 	Average Loss: -21.3294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9168

Learning rate: 0.00019981260511160026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1950 [0/90000 (0%)]	Loss: -15.4830	Cost: 22.84s
Train Epoch: 1950 [20480/90000 (23%)]	Loss: -22.0631	Cost: 6.12s
Train Epoch: 1950 [40960/90000 (45%)]	Loss: -21.5723	Cost: 7.96s
Train Epoch: 1950 [61440/90000 (68%)]	Loss: -21.9194	Cost: 5.79s
Train Epoch: 1950 [81920/90000 (91%)]	Loss: -22.1555	Cost: 6.38s
Train Epoch: 1950 	Average Loss: -21.4354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0110

Learning rate: 0.00019981241282392669
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1951 [0/90000 (0%)]	Loss: -15.0793	Cost: 22.56s
Train Epoch: 1951 [20480/90000 (23%)]	Loss: -21.9155	Cost: 5.96s
Train Epoch: 1951 [40960/90000 (45%)]	Loss: -21.4195	Cost: 8.02s
Train Epoch: 1951 [61440/90000 (68%)]	Loss: -21.5626	Cost: 5.78s
Train Epoch: 1951 [81920/90000 (91%)]	Loss: -22.0811	Cost: 6.32s
Train Epoch: 1951 	Average Loss: -21.3085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8699

Learning rate: 0.00019981222043774226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1952 [0/90000 (0%)]	Loss: -15.5682	Cost: 22.73s
Train Epoch: 1952 [20480/90000 (23%)]	Loss: -22.1359	Cost: 6.01s
Train Epoch: 1952 [40960/90000 (45%)]	Loss: -21.7412	Cost: 8.40s
Train Epoch: 1952 [61440/90000 (68%)]	Loss: -21.9217	Cost: 5.79s
Train Epoch: 1952 [81920/90000 (91%)]	Loss: -21.7876	Cost: 6.10s
Train Epoch: 1952 	Average Loss: -21.4718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9955

Learning rate: 0.00019981202795304708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1953 [0/90000 (0%)]	Loss: -14.8704	Cost: 22.64s
Train Epoch: 1953 [20480/90000 (23%)]	Loss: -21.9519	Cost: 6.00s
Train Epoch: 1953 [40960/90000 (45%)]	Loss: -21.4014	Cost: 7.99s
Train Epoch: 1953 [61440/90000 (68%)]	Loss: -21.9929	Cost: 5.76s
Train Epoch: 1953 [81920/90000 (91%)]	Loss: -20.2400	Cost: 6.14s
Train Epoch: 1953 	Average Loss: -21.1193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2221

Learning rate: 0.0001998118353698414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1954 [0/90000 (0%)]	Loss: -13.0884	Cost: 23.09s
Train Epoch: 1954 [20480/90000 (23%)]	Loss: -20.2319	Cost: 5.99s
Train Epoch: 1954 [40960/90000 (45%)]	Loss: -20.3595	Cost: 7.84s
Train Epoch: 1954 [61440/90000 (68%)]	Loss: -20.9770	Cost: 5.92s
Train Epoch: 1954 [81920/90000 (91%)]	Loss: -21.3360	Cost: 6.29s
Train Epoch: 1954 	Average Loss: -20.2952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6190

Learning rate: 0.0001998116426881254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1955 [0/90000 (0%)]	Loss: -15.4279	Cost: 22.87s
Train Epoch: 1955 [20480/90000 (23%)]	Loss: -21.6252	Cost: 5.98s
Train Epoch: 1955 [40960/90000 (45%)]	Loss: -21.5308	Cost: 7.96s
Train Epoch: 1955 [61440/90000 (68%)]	Loss: -21.8157	Cost: 5.83s
Train Epoch: 1955 [81920/90000 (91%)]	Loss: -22.0576	Cost: 6.10s
Train Epoch: 1955 	Average Loss: -21.2188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0557

Learning rate: 0.00019981144990789923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1956 [0/90000 (0%)]	Loss: -15.3781	Cost: 22.67s
Train Epoch: 1956 [20480/90000 (23%)]	Loss: -22.3013	Cost: 5.97s
Train Epoch: 1956 [40960/90000 (45%)]	Loss: -22.0263	Cost: 8.05s
Train Epoch: 1956 [61440/90000 (68%)]	Loss: -22.3944	Cost: 5.97s
Train Epoch: 1956 [81920/90000 (91%)]	Loss: -22.4461	Cost: 6.14s
Train Epoch: 1956 	Average Loss: -21.7826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2458

Saving model as e1956_model.pt & e1956_waveforms_supplementary.hdf5
Learning rate: 0.0001998112570291631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1957 [0/90000 (0%)]	Loss: -16.1610	Cost: 22.50s
Train Epoch: 1957 [20480/90000 (23%)]	Loss: -22.6007	Cost: 5.96s
Train Epoch: 1957 [40960/90000 (45%)]	Loss: -21.8894	Cost: 8.05s
Train Epoch: 1957 [61440/90000 (68%)]	Loss: -22.2941	Cost: 6.04s
Train Epoch: 1957 [81920/90000 (91%)]	Loss: -22.3379	Cost: 6.07s
Train Epoch: 1957 	Average Loss: -21.8666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2598

Saving model as e1957_model.pt & e1957_waveforms_supplementary.hdf5
Learning rate: 0.00019981106405191724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1958 [0/90000 (0%)]	Loss: -15.1764	Cost: 22.88s
Train Epoch: 1958 [20480/90000 (23%)]	Loss: -22.2906	Cost: 6.00s
Train Epoch: 1958 [40960/90000 (45%)]	Loss: -21.7682	Cost: 8.03s
Train Epoch: 1958 [61440/90000 (68%)]	Loss: -22.1022	Cost: 5.83s
Train Epoch: 1958 [81920/90000 (91%)]	Loss: -22.1669	Cost: 6.25s
Train Epoch: 1958 	Average Loss: -21.6962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0231

Learning rate: 0.0001998108709761618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1959 [0/90000 (0%)]	Loss: -15.7788	Cost: 23.17s
Train Epoch: 1959 [20480/90000 (23%)]	Loss: -22.2496	Cost: 6.01s
Train Epoch: 1959 [40960/90000 (45%)]	Loss: -21.8090	Cost: 7.88s
Train Epoch: 1959 [61440/90000 (68%)]	Loss: -22.1713	Cost: 5.79s
Train Epoch: 1959 [81920/90000 (91%)]	Loss: -22.3261	Cost: 6.23s
Train Epoch: 1959 	Average Loss: -21.7041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9308

Learning rate: 0.00019981067780189697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1960 [0/90000 (0%)]	Loss: -15.9543	Cost: 22.72s
Train Epoch: 1960 [20480/90000 (23%)]	Loss: -22.4139	Cost: 5.96s
Train Epoch: 1960 [40960/90000 (45%)]	Loss: -21.6200	Cost: 7.67s
Train Epoch: 1960 [61440/90000 (68%)]	Loss: -22.0805	Cost: 5.85s
Train Epoch: 1960 [81920/90000 (91%)]	Loss: -22.3616	Cost: 6.32s
Train Epoch: 1960 	Average Loss: -21.6935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2136

Learning rate: 0.0001998104845291229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1961 [0/90000 (0%)]	Loss: -15.7238	Cost: 23.20s
Train Epoch: 1961 [20480/90000 (23%)]	Loss: -22.3005	Cost: 6.00s
Train Epoch: 1961 [40960/90000 (45%)]	Loss: -21.7497	Cost: 7.53s
Train Epoch: 1961 [61440/90000 (68%)]	Loss: -22.3734	Cost: 5.84s
Train Epoch: 1961 [81920/90000 (91%)]	Loss: -22.4382	Cost: 6.12s
Train Epoch: 1961 	Average Loss: -21.7865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1509

Learning rate: 0.0001998102911578399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1962 [0/90000 (0%)]	Loss: -14.9082	Cost: 22.61s
Train Epoch: 1962 [20480/90000 (23%)]	Loss: -22.4571	Cost: 5.99s
Train Epoch: 1962 [40960/90000 (45%)]	Loss: -21.6428	Cost: 7.56s
Train Epoch: 1962 [61440/90000 (68%)]	Loss: -22.1255	Cost: 5.88s
Train Epoch: 1962 [81920/90000 (91%)]	Loss: -22.1915	Cost: 6.08s
Train Epoch: 1962 	Average Loss: -21.7066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2078

Learning rate: 0.00019981009768804805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1963 [0/90000 (0%)]	Loss: -15.7642	Cost: 22.51s
Train Epoch: 1963 [20480/90000 (23%)]	Loss: -22.4864	Cost: 6.01s
Train Epoch: 1963 [40960/90000 (45%)]	Loss: -21.8524	Cost: 7.88s
Train Epoch: 1963 [61440/90000 (68%)]	Loss: -22.1634	Cost: 5.80s
Train Epoch: 1963 [81920/90000 (91%)]	Loss: -22.1664	Cost: 6.16s
Train Epoch: 1963 	Average Loss: -21.6970
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8772

Learning rate: 0.0001998099041197476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1964 [0/90000 (0%)]	Loss: -15.5927	Cost: 22.60s
Train Epoch: 1964 [20480/90000 (23%)]	Loss: -22.3251	Cost: 6.04s
Train Epoch: 1964 [40960/90000 (45%)]	Loss: -21.5448	Cost: 7.87s
Train Epoch: 1964 [61440/90000 (68%)]	Loss: -21.9704	Cost: 5.84s
Train Epoch: 1964 [81920/90000 (91%)]	Loss: -22.1079	Cost: 6.33s
Train Epoch: 1964 	Average Loss: -21.6132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1715

Learning rate: 0.00019980971045293873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1965 [0/90000 (0%)]	Loss: -15.0996	Cost: 23.23s
Train Epoch: 1965 [20480/90000 (23%)]	Loss: -22.2172	Cost: 5.98s
Train Epoch: 1965 [40960/90000 (45%)]	Loss: -21.9679	Cost: 7.59s
Train Epoch: 1965 [61440/90000 (68%)]	Loss: -22.1501	Cost: 6.08s
Train Epoch: 1965 [81920/90000 (91%)]	Loss: -21.8295	Cost: 6.21s
Train Epoch: 1965 	Average Loss: -21.6561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7633

Learning rate: 0.0001998095166876216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1966 [0/90000 (0%)]	Loss: -15.2666	Cost: 22.62s
Train Epoch: 1966 [20480/90000 (23%)]	Loss: -22.2936	Cost: 6.02s
Train Epoch: 1966 [40960/90000 (45%)]	Loss: -21.9291	Cost: 8.29s
Train Epoch: 1966 [61440/90000 (68%)]	Loss: -21.9895	Cost: 5.74s
Train Epoch: 1966 [81920/90000 (91%)]	Loss: -22.2886	Cost: 6.56s
Train Epoch: 1966 	Average Loss: -21.6722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2581

Learning rate: 0.00019980932282379646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1967 [0/90000 (0%)]	Loss: -15.6945	Cost: 22.76s
Train Epoch: 1967 [20480/90000 (23%)]	Loss: -22.1637	Cost: 5.97s
Train Epoch: 1967 [40960/90000 (45%)]	Loss: -21.8288	Cost: 8.36s
Train Epoch: 1967 [61440/90000 (68%)]	Loss: -21.9339	Cost: 5.84s
Train Epoch: 1967 [81920/90000 (91%)]	Loss: -22.1843	Cost: 5.93s
Train Epoch: 1967 	Average Loss: -21.5954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0218

Learning rate: 0.00019980912886146345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1968 [0/90000 (0%)]	Loss: -15.2560	Cost: 22.92s
Train Epoch: 1968 [20480/90000 (23%)]	Loss: -21.9885	Cost: 6.00s
Train Epoch: 1968 [40960/90000 (45%)]	Loss: -21.7738	Cost: 7.83s
Train Epoch: 1968 [61440/90000 (68%)]	Loss: -22.0317	Cost: 5.83s
Train Epoch: 1968 [81920/90000 (91%)]	Loss: -22.3055	Cost: 6.27s
Train Epoch: 1968 	Average Loss: -21.5969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1360

Learning rate: 0.00019980893480062278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1969 [0/90000 (0%)]	Loss: -15.5356	Cost: 22.48s
Train Epoch: 1969 [20480/90000 (23%)]	Loss: -22.3462	Cost: 6.01s
Train Epoch: 1969 [40960/90000 (45%)]	Loss: -21.9347	Cost: 8.20s
Train Epoch: 1969 [61440/90000 (68%)]	Loss: -22.4076	Cost: 5.94s
Train Epoch: 1969 [81920/90000 (91%)]	Loss: -22.4001	Cost: 6.17s
Train Epoch: 1969 	Average Loss: -21.8564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2089

Learning rate: 0.00019980874064127462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1970 [0/90000 (0%)]	Loss: -16.0267	Cost: 22.75s
Train Epoch: 1970 [20480/90000 (23%)]	Loss: -22.2953	Cost: 6.03s
Train Epoch: 1970 [40960/90000 (45%)]	Loss: -21.8706	Cost: 7.61s
Train Epoch: 1970 [61440/90000 (68%)]	Loss: -22.1773	Cost: 5.80s
Train Epoch: 1970 [81920/90000 (91%)]	Loss: -22.2957	Cost: 6.36s
Train Epoch: 1970 	Average Loss: -21.7972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2225

Learning rate: 0.0001998085463834192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1971 [0/90000 (0%)]	Loss: -15.5605	Cost: 22.83s
Train Epoch: 1971 [20480/90000 (23%)]	Loss: -22.3630	Cost: 6.02s
Train Epoch: 1971 [40960/90000 (45%)]	Loss: -21.6283	Cost: 7.98s
Train Epoch: 1971 [61440/90000 (68%)]	Loss: -22.1223	Cost: 5.93s
Train Epoch: 1971 [81920/90000 (91%)]	Loss: -22.2840	Cost: 6.16s
Train Epoch: 1971 	Average Loss: -21.7072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3163

Saving model as e1971_model.pt & e1971_waveforms_supplementary.hdf5
Learning rate: 0.00019980835202705667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1972 [0/90000 (0%)]	Loss: -15.1506	Cost: 22.55s
Train Epoch: 1972 [20480/90000 (23%)]	Loss: -22.4340	Cost: 6.00s
Train Epoch: 1972 [40960/90000 (45%)]	Loss: -21.8879	Cost: 7.78s
Train Epoch: 1972 [61440/90000 (68%)]	Loss: -22.1679	Cost: 5.96s
Train Epoch: 1972 [81920/90000 (91%)]	Loss: -22.1632	Cost: 6.22s
Train Epoch: 1972 	Average Loss: -21.6859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0429

Learning rate: 0.00019980815757218725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1973 [0/90000 (0%)]	Loss: -15.4006	Cost: 23.08s
Train Epoch: 1973 [20480/90000 (23%)]	Loss: -22.3437	Cost: 6.01s
Train Epoch: 1973 [40960/90000 (45%)]	Loss: -21.7803	Cost: 7.91s
Train Epoch: 1973 [61440/90000 (68%)]	Loss: -22.2975	Cost: 5.76s
Train Epoch: 1973 [81920/90000 (91%)]	Loss: -22.2210	Cost: 6.24s
Train Epoch: 1973 	Average Loss: -21.7658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0490

Learning rate: 0.00019980796301881116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1974 [0/90000 (0%)]	Loss: -15.7953	Cost: 22.86s
Train Epoch: 1974 [20480/90000 (23%)]	Loss: -22.3246	Cost: 6.02s
Train Epoch: 1974 [40960/90000 (45%)]	Loss: -21.6000	Cost: 7.55s
Train Epoch: 1974 [61440/90000 (68%)]	Loss: -21.9113	Cost: 6.14s
Train Epoch: 1974 [81920/90000 (91%)]	Loss: -22.0047	Cost: 6.27s
Train Epoch: 1974 	Average Loss: -21.6248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0877

Learning rate: 0.00019980776836692855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1975 [0/90000 (0%)]	Loss: -14.3798	Cost: 22.61s
Train Epoch: 1975 [20480/90000 (23%)]	Loss: -22.2690	Cost: 6.00s
Train Epoch: 1975 [40960/90000 (45%)]	Loss: -21.7867	Cost: 7.75s
Train Epoch: 1975 [61440/90000 (68%)]	Loss: -21.9565	Cost: 5.81s
Train Epoch: 1975 [81920/90000 (91%)]	Loss: -22.1490	Cost: 6.26s
Train Epoch: 1975 	Average Loss: -21.5917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1099

Learning rate: 0.0001998075736165396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1976 [0/90000 (0%)]	Loss: -15.5112	Cost: 22.83s
Train Epoch: 1976 [20480/90000 (23%)]	Loss: -22.3592	Cost: 5.99s
Train Epoch: 1976 [40960/90000 (45%)]	Loss: -21.9758	Cost: 7.76s
Train Epoch: 1976 [61440/90000 (68%)]	Loss: -22.2081	Cost: 5.82s
Train Epoch: 1976 [81920/90000 (91%)]	Loss: -22.1331	Cost: 6.13s
Train Epoch: 1976 	Average Loss: -21.7840
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2244

Learning rate: 0.00019980737876764453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1977 [0/90000 (0%)]	Loss: -15.3981	Cost: 22.83s
Train Epoch: 1977 [20480/90000 (23%)]	Loss: -22.3195	Cost: 5.98s
Train Epoch: 1977 [40960/90000 (45%)]	Loss: -21.9920	Cost: 8.10s
Train Epoch: 1977 [61440/90000 (68%)]	Loss: -22.3048	Cost: 5.93s
Train Epoch: 1977 [81920/90000 (91%)]	Loss: -22.4221	Cost: 6.00s
Train Epoch: 1977 	Average Loss: -21.7435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2312

Learning rate: 0.00019980718382024357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1978 [0/90000 (0%)]	Loss: -14.7895	Cost: 23.01s
Train Epoch: 1978 [20480/90000 (23%)]	Loss: -22.3739	Cost: 6.01s
Train Epoch: 1978 [40960/90000 (45%)]	Loss: -21.9787	Cost: 7.52s
Train Epoch: 1978 [61440/90000 (68%)]	Loss: -22.3570	Cost: 5.83s
Train Epoch: 1978 [81920/90000 (91%)]	Loss: -22.3548	Cost: 6.26s
Train Epoch: 1978 	Average Loss: -21.8004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1984

Learning rate: 0.0001998069887743368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1979 [0/90000 (0%)]	Loss: -15.7123	Cost: 22.92s
Train Epoch: 1979 [20480/90000 (23%)]	Loss: -22.6040	Cost: 6.00s
Train Epoch: 1979 [40960/90000 (45%)]	Loss: -21.8883	Cost: 7.79s
Train Epoch: 1979 [61440/90000 (68%)]	Loss: -22.2089	Cost: 6.50s
Train Epoch: 1979 [81920/90000 (91%)]	Loss: -22.2539	Cost: 5.85s
Train Epoch: 1979 	Average Loss: -21.8227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2489

Learning rate: 0.00019980679362992455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1980 [0/90000 (0%)]	Loss: -15.8295	Cost: 22.52s
Train Epoch: 1980 [20480/90000 (23%)]	Loss: -22.6098	Cost: 5.99s
Train Epoch: 1980 [40960/90000 (45%)]	Loss: -21.8088	Cost: 7.96s
Train Epoch: 1980 [61440/90000 (68%)]	Loss: -22.0757	Cost: 5.78s
Train Epoch: 1980 [81920/90000 (91%)]	Loss: -22.0296	Cost: 6.31s
Train Epoch: 1980 	Average Loss: -21.7777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0704

Learning rate: 0.0001998065983870069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1981 [0/90000 (0%)]	Loss: -15.9724	Cost: 23.54s
Train Epoch: 1981 [20480/90000 (23%)]	Loss: -22.3708	Cost: 6.01s
Train Epoch: 1981 [40960/90000 (45%)]	Loss: -21.8617	Cost: 8.26s
Train Epoch: 1981 [61440/90000 (68%)]	Loss: -22.1075	Cost: 5.93s
Train Epoch: 1981 [81920/90000 (91%)]	Loss: -22.3404	Cost: 6.12s
Train Epoch: 1981 	Average Loss: -21.7247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3624

Saving model as e1981_model.pt & e1981_waveforms_supplementary.hdf5
Learning rate: 0.0001998064030455841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1982 [0/90000 (0%)]	Loss: -15.5520	Cost: 23.09s
Train Epoch: 1982 [20480/90000 (23%)]	Loss: -22.0109	Cost: 5.97s
Train Epoch: 1982 [40960/90000 (45%)]	Loss: -20.8298	Cost: 7.69s
Train Epoch: 1982 [61440/90000 (68%)]	Loss: -21.0244	Cost: 5.80s
Train Epoch: 1982 [81920/90000 (91%)]	Loss: -21.7029	Cost: 6.41s
Train Epoch: 1982 	Average Loss: -21.0889
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3376

Learning rate: 0.00019980620760565632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1983 [0/90000 (0%)]	Loss: -14.2721	Cost: 22.75s
Train Epoch: 1983 [20480/90000 (23%)]	Loss: -21.4111	Cost: 6.00s
Train Epoch: 1983 [40960/90000 (45%)]	Loss: -20.8797	Cost: 7.72s
Train Epoch: 1983 [61440/90000 (68%)]	Loss: -21.4516	Cost: 6.02s
Train Epoch: 1983 [81920/90000 (91%)]	Loss: -21.8924	Cost: 6.30s
Train Epoch: 1983 	Average Loss: -20.9010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9654

Learning rate: 0.00019980601206722376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1984 [0/90000 (0%)]	Loss: -15.1403	Cost: 22.83s
Train Epoch: 1984 [20480/90000 (23%)]	Loss: -22.3746	Cost: 6.02s
Train Epoch: 1984 [40960/90000 (45%)]	Loss: -21.6233	Cost: 7.99s
Train Epoch: 1984 [61440/90000 (68%)]	Loss: -21.9765	Cost: 5.77s
Train Epoch: 1984 [81920/90000 (91%)]	Loss: -22.2591	Cost: 6.23s
Train Epoch: 1984 	Average Loss: -21.5747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1538

Learning rate: 0.0001998058164302866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1985 [0/90000 (0%)]	Loss: -16.1890	Cost: 22.89s
Train Epoch: 1985 [20480/90000 (23%)]	Loss: -22.5794	Cost: 6.00s
Train Epoch: 1985 [40960/90000 (45%)]	Loss: -21.8802	Cost: 8.02s
Train Epoch: 1985 [61440/90000 (68%)]	Loss: -22.2268	Cost: 5.78s
Train Epoch: 1985 [81920/90000 (91%)]	Loss: -22.2791	Cost: 6.52s
Train Epoch: 1985 	Average Loss: -21.7863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3274

Learning rate: 0.00019980562069484508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1986 [0/90000 (0%)]	Loss: -15.8425	Cost: 23.13s
Train Epoch: 1986 [20480/90000 (23%)]	Loss: -22.2496	Cost: 5.98s
Train Epoch: 1986 [40960/90000 (45%)]	Loss: -21.9996	Cost: 8.03s
Train Epoch: 1986 [61440/90000 (68%)]	Loss: -21.9343	Cost: 5.97s
Train Epoch: 1986 [81920/90000 (91%)]	Loss: -21.9914	Cost: 6.14s
Train Epoch: 1986 	Average Loss: -21.7123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2721

Learning rate: 0.00019980542486089937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1987 [0/90000 (0%)]	Loss: -15.3119	Cost: 22.85s
Train Epoch: 1987 [20480/90000 (23%)]	Loss: -22.1516	Cost: 6.06s
Train Epoch: 1987 [40960/90000 (45%)]	Loss: -21.9040	Cost: 7.94s
Train Epoch: 1987 [61440/90000 (68%)]	Loss: -22.1802	Cost: 5.85s
Train Epoch: 1987 [81920/90000 (91%)]	Loss: -22.2592	Cost: 6.20s
Train Epoch: 1987 	Average Loss: -21.6899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2336

Learning rate: 0.0001998052289284496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1988 [0/90000 (0%)]	Loss: -15.3816	Cost: 22.83s
Train Epoch: 1988 [20480/90000 (23%)]	Loss: -22.6259	Cost: 6.04s
Train Epoch: 1988 [40960/90000 (45%)]	Loss: -21.8074	Cost: 7.89s
Train Epoch: 1988 [61440/90000 (68%)]	Loss: -22.2731	Cost: 5.78s
Train Epoch: 1988 [81920/90000 (91%)]	Loss: -22.0609	Cost: 6.27s
Train Epoch: 1988 	Average Loss: -21.8242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1690

Learning rate: 0.00019980503289749604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1989 [0/90000 (0%)]	Loss: -14.7899	Cost: 22.68s
Train Epoch: 1989 [20480/90000 (23%)]	Loss: -22.4617	Cost: 6.01s
Train Epoch: 1989 [40960/90000 (45%)]	Loss: -21.8802	Cost: 8.26s
Train Epoch: 1989 [61440/90000 (68%)]	Loss: -22.2901	Cost: 5.96s
Train Epoch: 1989 [81920/90000 (91%)]	Loss: -22.0659	Cost: 6.09s
Train Epoch: 1989 	Average Loss: -21.6956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1436

Learning rate: 0.00019980483676803885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1990 [0/90000 (0%)]	Loss: -15.4942	Cost: 22.75s
Train Epoch: 1990 [20480/90000 (23%)]	Loss: -22.3333	Cost: 5.99s
Train Epoch: 1990 [40960/90000 (45%)]	Loss: -22.2025	Cost: 8.05s
Train Epoch: 1990 [61440/90000 (68%)]	Loss: -22.2086	Cost: 5.77s
Train Epoch: 1990 [81920/90000 (91%)]	Loss: -22.4906	Cost: 6.31s
Train Epoch: 1990 	Average Loss: -21.9137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3384

Learning rate: 0.00019980464054007824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1991 [0/90000 (0%)]	Loss: -15.6867	Cost: 22.96s
Train Epoch: 1991 [20480/90000 (23%)]	Loss: -22.4315	Cost: 6.00s
Train Epoch: 1991 [40960/90000 (45%)]	Loss: -21.7377	Cost: 8.21s
Train Epoch: 1991 [61440/90000 (68%)]	Loss: -21.6008	Cost: 5.79s
Train Epoch: 1991 [81920/90000 (91%)]	Loss: -21.6737	Cost: 6.26s
Train Epoch: 1991 	Average Loss: -21.5146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6854

Learning rate: 0.0001998044442136144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1992 [0/90000 (0%)]	Loss: -15.5455	Cost: 22.70s
Train Epoch: 1992 [20480/90000 (23%)]	Loss: -22.0549	Cost: 5.98s
Train Epoch: 1992 [40960/90000 (45%)]	Loss: -21.7572	Cost: 8.04s
Train Epoch: 1992 [61440/90000 (68%)]	Loss: -22.0436	Cost: 5.78s
Train Epoch: 1992 [81920/90000 (91%)]	Loss: -22.2778	Cost: 6.50s
Train Epoch: 1992 	Average Loss: -21.5237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2623

Learning rate: 0.00019980424778864752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1993 [0/90000 (0%)]	Loss: -15.7875	Cost: 22.79s
Train Epoch: 1993 [20480/90000 (23%)]	Loss: -22.5085	Cost: 5.98s
Train Epoch: 1993 [40960/90000 (45%)]	Loss: -22.0657	Cost: 8.22s
Train Epoch: 1993 [61440/90000 (68%)]	Loss: -22.1006	Cost: 5.85s
Train Epoch: 1993 [81920/90000 (91%)]	Loss: -22.4276	Cost: 6.33s
Train Epoch: 1993 	Average Loss: -21.9056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1672

Learning rate: 0.0001998040512651778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1994 [0/90000 (0%)]	Loss: -15.4263	Cost: 23.12s
Train Epoch: 1994 [20480/90000 (23%)]	Loss: -21.9134	Cost: 5.97s
Train Epoch: 1994 [40960/90000 (45%)]	Loss: -21.8152	Cost: 7.89s
Train Epoch: 1994 [61440/90000 (68%)]	Loss: -22.2065	Cost: 5.94s
Train Epoch: 1994 [81920/90000 (91%)]	Loss: -22.0127	Cost: 6.00s
Train Epoch: 1994 	Average Loss: -21.5519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9648

Learning rate: 0.00019980385464320543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1995 [0/90000 (0%)]	Loss: -15.0847	Cost: 22.76s
Train Epoch: 1995 [20480/90000 (23%)]	Loss: -22.1532	Cost: 6.01s
Train Epoch: 1995 [40960/90000 (45%)]	Loss: -21.8814	Cost: 8.10s
Train Epoch: 1995 [61440/90000 (68%)]	Loss: -21.7368	Cost: 5.84s
Train Epoch: 1995 [81920/90000 (91%)]	Loss: -22.1194	Cost: 6.36s
Train Epoch: 1995 	Average Loss: -21.5557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1235

Learning rate: 0.0001998036579227306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1996 [0/90000 (0%)]	Loss: -15.1675	Cost: 22.71s
Train Epoch: 1996 [20480/90000 (23%)]	Loss: -22.2482	Cost: 6.01s
Train Epoch: 1996 [40960/90000 (45%)]	Loss: -21.6279	Cost: 8.05s
Train Epoch: 1996 [61440/90000 (68%)]	Loss: -22.1294	Cost: 5.76s
Train Epoch: 1996 [81920/90000 (91%)]	Loss: -22.4798	Cost: 6.27s
Train Epoch: 1996 	Average Loss: -21.6929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4699

Saving model as e1996_model.pt & e1996_waveforms_supplementary.hdf5
Learning rate: 0.0001998034611037535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1997 [0/90000 (0%)]	Loss: -15.5630	Cost: 22.91s
Train Epoch: 1997 [20480/90000 (23%)]	Loss: -22.5325	Cost: 6.00s
Train Epoch: 1997 [40960/90000 (45%)]	Loss: -22.0504	Cost: 7.64s
Train Epoch: 1997 [61440/90000 (68%)]	Loss: -22.4283	Cost: 5.80s
Train Epoch: 1997 [81920/90000 (91%)]	Loss: -22.4102	Cost: 6.33s
Train Epoch: 1997 	Average Loss: -22.0252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2931

Learning rate: 0.00019980326418627434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1998 [0/90000 (0%)]	Loss: -15.2990	Cost: 22.78s
Train Epoch: 1998 [20480/90000 (23%)]	Loss: -22.2225	Cost: 6.00s
Train Epoch: 1998 [40960/90000 (45%)]	Loss: -21.8614	Cost: 7.69s
Train Epoch: 1998 [61440/90000 (68%)]	Loss: -22.1758	Cost: 5.84s
Train Epoch: 1998 [81920/90000 (91%)]	Loss: -22.4309	Cost: 6.34s
Train Epoch: 1998 	Average Loss: -21.8241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1800

Learning rate: 0.00019980306717029333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1999 [0/90000 (0%)]	Loss: -15.7306	Cost: 23.55s
Train Epoch: 1999 [20480/90000 (23%)]	Loss: -22.4912	Cost: 5.97s
Train Epoch: 1999 [40960/90000 (45%)]	Loss: -21.9722	Cost: 8.13s
Train Epoch: 1999 [61440/90000 (68%)]	Loss: -22.3751	Cost: 5.77s
Train Epoch: 1999 [81920/90000 (91%)]	Loss: -22.2715	Cost: 6.27s
Train Epoch: 1999 	Average Loss: -21.9097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1924

Learning rate: 0.0001998028700558106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2000 [0/90000 (0%)]	Loss: -15.0393	Cost: 22.90s
Train Epoch: 2000 [20480/90000 (23%)]	Loss: -22.3071	Cost: 6.01s
Train Epoch: 2000 [40960/90000 (45%)]	Loss: -21.4919	Cost: 8.01s
Train Epoch: 2000 [61440/90000 (68%)]	Loss: -21.6085	Cost: 5.95s
Train Epoch: 2000 [81920/90000 (91%)]	Loss: -21.7354	Cost: 6.30s
Train Epoch: 2000 	Average Loss: -21.3900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6244

Learning rate: 0.0001998026728428264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2001 [0/90000 (0%)]	Loss: -15.1744	Cost: 22.89s
Train Epoch: 2001 [20480/90000 (23%)]	Loss: -22.1043	Cost: 6.06s
Train Epoch: 2001 [40960/90000 (45%)]	Loss: -21.7538	Cost: 7.72s
Train Epoch: 2001 [61440/90000 (68%)]	Loss: -22.2506	Cost: 5.87s
Train Epoch: 2001 [81920/90000 (91%)]	Loss: -22.2083	Cost: 6.34s
Train Epoch: 2001 	Average Loss: -21.5368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0512

Learning rate: 0.00019980247553134093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2002 [0/90000 (0%)]	Loss: -15.5355	Cost: 22.97s
Train Epoch: 2002 [20480/90000 (23%)]	Loss: -22.2863	Cost: 6.04s
Train Epoch: 2002 [40960/90000 (45%)]	Loss: -21.7062	Cost: 7.60s
Train Epoch: 2002 [61440/90000 (68%)]	Loss: -22.1489	Cost: 5.97s
Train Epoch: 2002 [81920/90000 (91%)]	Loss: -22.2757	Cost: 6.06s
Train Epoch: 2002 	Average Loss: -21.7132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3049

Learning rate: 0.00019980227812135435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2003 [0/90000 (0%)]	Loss: -16.0106	Cost: 23.47s
Train Epoch: 2003 [20480/90000 (23%)]	Loss: -22.2903	Cost: 5.96s
Train Epoch: 2003 [40960/90000 (45%)]	Loss: -22.0118	Cost: 7.55s
Train Epoch: 2003 [61440/90000 (68%)]	Loss: -22.3041	Cost: 5.89s
Train Epoch: 2003 [81920/90000 (91%)]	Loss: -22.5765	Cost: 5.97s
Train Epoch: 2003 	Average Loss: -21.8854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2680

Learning rate: 0.0001998020806128669
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2004 [0/90000 (0%)]	Loss: -15.3977	Cost: 22.69s
Train Epoch: 2004 [20480/90000 (23%)]	Loss: -22.0666	Cost: 6.01s
Train Epoch: 2004 [40960/90000 (45%)]	Loss: -21.3950	Cost: 7.57s
Train Epoch: 2004 [61440/90000 (68%)]	Loss: -22.1978	Cost: 5.85s
Train Epoch: 2004 [81920/90000 (91%)]	Loss: -22.2018	Cost: 6.18s
Train Epoch: 2004 	Average Loss: -21.5790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2568

Learning rate: 0.00019980188300587872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2005 [0/90000 (0%)]	Loss: -15.9525	Cost: 22.86s
Train Epoch: 2005 [20480/90000 (23%)]	Loss: -22.4083	Cost: 6.00s
Train Epoch: 2005 [40960/90000 (45%)]	Loss: -21.5038	Cost: 7.68s
Train Epoch: 2005 [61440/90000 (68%)]	Loss: -21.8996	Cost: 5.99s
Train Epoch: 2005 [81920/90000 (91%)]	Loss: -22.1513	Cost: 6.14s
Train Epoch: 2005 	Average Loss: -21.5794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2538

Learning rate: 0.00019980168530039002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2006 [0/90000 (0%)]	Loss: -15.7510	Cost: 22.75s
Train Epoch: 2006 [20480/90000 (23%)]	Loss: -22.4527	Cost: 5.99s
Train Epoch: 2006 [40960/90000 (45%)]	Loss: -21.8403	Cost: 7.84s
Train Epoch: 2006 [61440/90000 (68%)]	Loss: -22.4901	Cost: 5.80s
Train Epoch: 2006 [81920/90000 (91%)]	Loss: -22.6491	Cost: 6.28s
Train Epoch: 2006 	Average Loss: -21.8885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5394

Saving model as e2006_model.pt & e2006_waveforms_supplementary.hdf5
Learning rate: 0.00019980148749640101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2007 [0/90000 (0%)]	Loss: -16.2817	Cost: 23.09s
Train Epoch: 2007 [20480/90000 (23%)]	Loss: -22.6559	Cost: 6.00s
Train Epoch: 2007 [40960/90000 (45%)]	Loss: -22.0121	Cost: 7.43s
Train Epoch: 2007 [61440/90000 (68%)]	Loss: -22.5121	Cost: 5.79s
Train Epoch: 2007 [81920/90000 (91%)]	Loss: -22.5496	Cost: 6.60s
Train Epoch: 2007 	Average Loss: -21.9839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5171

Learning rate: 0.0001998012895939119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2008 [0/90000 (0%)]	Loss: -16.5575	Cost: 22.72s
Train Epoch: 2008 [20480/90000 (23%)]	Loss: -22.2915	Cost: 6.01s
Train Epoch: 2008 [40960/90000 (45%)]	Loss: -21.9367	Cost: 8.05s
Train Epoch: 2008 [61440/90000 (68%)]	Loss: -22.2604	Cost: 5.80s
Train Epoch: 2008 [81920/90000 (91%)]	Loss: -22.3387	Cost: 6.26s
Train Epoch: 2008 	Average Loss: -21.7608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2380

Learning rate: 0.00019980109159292286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2009 [0/90000 (0%)]	Loss: -15.8495	Cost: 23.10s
Train Epoch: 2009 [20480/90000 (23%)]	Loss: -22.3303	Cost: 6.00s
Train Epoch: 2009 [40960/90000 (45%)]	Loss: -21.9695	Cost: 7.67s
Train Epoch: 2009 [61440/90000 (68%)]	Loss: -22.4011	Cost: 5.95s
Train Epoch: 2009 [81920/90000 (91%)]	Loss: -22.3221	Cost: 6.46s
Train Epoch: 2009 	Average Loss: -21.8409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1082

Learning rate: 0.00019980089349343408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2010 [0/90000 (0%)]	Loss: -14.2333	Cost: 23.44s
Train Epoch: 2010 [20480/90000 (23%)]	Loss: -22.1374	Cost: 5.97s
Train Epoch: 2010 [40960/90000 (45%)]	Loss: -21.6671	Cost: 7.50s
Train Epoch: 2010 [61440/90000 (68%)]	Loss: -22.1565	Cost: 5.79s
Train Epoch: 2010 [81920/90000 (91%)]	Loss: -22.1477	Cost: 6.24s
Train Epoch: 2010 	Average Loss: -21.5579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9751

Learning rate: 0.0001998006952954458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2011 [0/90000 (0%)]	Loss: -15.1702	Cost: 22.51s
Train Epoch: 2011 [20480/90000 (23%)]	Loss: -22.2393	Cost: 5.99s
Train Epoch: 2011 [40960/90000 (45%)]	Loss: -21.7661	Cost: 7.66s
Train Epoch: 2011 [61440/90000 (68%)]	Loss: -22.4910	Cost: 5.87s
Train Epoch: 2011 [81920/90000 (91%)]	Loss: -22.5004	Cost: 6.38s
Train Epoch: 2011 	Average Loss: -21.8480
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3650

Learning rate: 0.00019980049699895813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2012 [0/90000 (0%)]	Loss: -15.7081	Cost: 23.05s
Train Epoch: 2012 [20480/90000 (23%)]	Loss: -22.8554	Cost: 6.01s
Train Epoch: 2012 [40960/90000 (45%)]	Loss: -22.0963	Cost: 7.99s
Train Epoch: 2012 [61440/90000 (68%)]	Loss: -22.4405	Cost: 5.80s
Train Epoch: 2012 [81920/90000 (91%)]	Loss: -22.4441	Cost: 6.25s
Train Epoch: 2012 	Average Loss: -22.0048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2599

Learning rate: 0.00019980029860397133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2013 [0/90000 (0%)]	Loss: -15.7077	Cost: 22.89s
Train Epoch: 2013 [20480/90000 (23%)]	Loss: -22.4874	Cost: 5.98s
Train Epoch: 2013 [40960/90000 (45%)]	Loss: -21.9991	Cost: 8.17s
Train Epoch: 2013 [61440/90000 (68%)]	Loss: -22.0554	Cost: 5.73s
Train Epoch: 2013 [81920/90000 (91%)]	Loss: -22.3079	Cost: 6.07s
Train Epoch: 2013 	Average Loss: -21.8182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0328

Learning rate: 0.00019980010011048558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2014 [0/90000 (0%)]	Loss: -15.0114	Cost: 22.79s
Train Epoch: 2014 [20480/90000 (23%)]	Loss: -22.2986	Cost: 5.99s
Train Epoch: 2014 [40960/90000 (45%)]	Loss: -21.7321	Cost: 8.20s
Train Epoch: 2014 [61440/90000 (68%)]	Loss: -22.1899	Cost: 5.76s
Train Epoch: 2014 [81920/90000 (91%)]	Loss: -22.3597	Cost: 6.38s
Train Epoch: 2014 	Average Loss: -21.7334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3741

Learning rate: 0.00019979990151850106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2015 [0/90000 (0%)]	Loss: -15.7432	Cost: 23.13s
Train Epoch: 2015 [20480/90000 (23%)]	Loss: -22.7373	Cost: 5.99s
Train Epoch: 2015 [40960/90000 (45%)]	Loss: -21.9860	Cost: 7.72s
Train Epoch: 2015 [61440/90000 (68%)]	Loss: -22.3926	Cost: 6.07s
Train Epoch: 2015 [81920/90000 (91%)]	Loss: -22.5059	Cost: 6.07s
Train Epoch: 2015 	Average Loss: -21.9905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6141

Saving model as e2015_model.pt & e2015_waveforms_supplementary.hdf5
Learning rate: 0.00019979970282801802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2016 [0/90000 (0%)]	Loss: -16.2511	Cost: 22.62s
Train Epoch: 2016 [20480/90000 (23%)]	Loss: -22.6346	Cost: 5.99s
Train Epoch: 2016 [40960/90000 (45%)]	Loss: -22.0092	Cost: 7.74s
Train Epoch: 2016 [61440/90000 (68%)]	Loss: -22.5742	Cost: 5.82s
Train Epoch: 2016 [81920/90000 (91%)]	Loss: -22.7708	Cost: 6.23s
Train Epoch: 2016 	Average Loss: -22.1182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5482

Learning rate: 0.0001997995040390366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2017 [0/90000 (0%)]	Loss: -13.4028	Cost: 22.85s
Train Epoch: 2017 [20480/90000 (23%)]	Loss: -22.7372	Cost: 5.99s
Train Epoch: 2017 [40960/90000 (45%)]	Loss: -22.2381	Cost: 7.83s
Train Epoch: 2017 [61440/90000 (68%)]	Loss: -22.4824	Cost: 5.80s
Train Epoch: 2017 [81920/90000 (91%)]	Loss: -22.3810	Cost: 6.42s
Train Epoch: 2017 	Average Loss: -21.9309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2271

Learning rate: 0.00019979930515155706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2018 [0/90000 (0%)]	Loss: -14.7204	Cost: 23.35s
Train Epoch: 2018 [20480/90000 (23%)]	Loss: -22.5197	Cost: 5.99s
Train Epoch: 2018 [40960/90000 (45%)]	Loss: -22.0992	Cost: 7.69s
Train Epoch: 2018 [61440/90000 (68%)]	Loss: -22.0329	Cost: 6.04s
Train Epoch: 2018 [81920/90000 (91%)]	Loss: -22.3185	Cost: 6.19s
Train Epoch: 2018 	Average Loss: -21.8069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2814

Learning rate: 0.00019979910616557952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2019 [0/90000 (0%)]	Loss: -14.9209	Cost: 22.89s
Train Epoch: 2019 [20480/90000 (23%)]	Loss: -22.3991	Cost: 6.01s
Train Epoch: 2019 [40960/90000 (45%)]	Loss: -21.5490	Cost: 7.96s
Train Epoch: 2019 [61440/90000 (68%)]	Loss: -21.9848	Cost: 5.90s
Train Epoch: 2019 [81920/90000 (91%)]	Loss: -22.1014	Cost: 6.37s
Train Epoch: 2019 	Average Loss: -21.6510
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1437

Learning rate: 0.0001997989070811042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2020 [0/90000 (0%)]	Loss: -14.1869	Cost: 22.53s
Train Epoch: 2020 [20480/90000 (23%)]	Loss: -22.2015	Cost: 6.00s
Train Epoch: 2020 [40960/90000 (45%)]	Loss: -21.6910	Cost: 7.89s
Train Epoch: 2020 [61440/90000 (68%)]	Loss: -22.1116	Cost: 5.79s
Train Epoch: 2020 [81920/90000 (91%)]	Loss: -22.2154	Cost: 6.27s
Train Epoch: 2020 	Average Loss: -21.5128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2109

Learning rate: 0.00019979870789813134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2021 [0/90000 (0%)]	Loss: -15.4709	Cost: 23.01s
Train Epoch: 2021 [20480/90000 (23%)]	Loss: -22.5105	Cost: 6.03s
Train Epoch: 2021 [40960/90000 (45%)]	Loss: -21.9899	Cost: 7.74s
Train Epoch: 2021 [61440/90000 (68%)]	Loss: -22.3681	Cost: 5.95s
Train Epoch: 2021 [81920/90000 (91%)]	Loss: -22.3854	Cost: 6.17s
Train Epoch: 2021 	Average Loss: -21.8716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4139

Learning rate: 0.00019979850861666108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2022 [0/90000 (0%)]	Loss: -15.9707	Cost: 23.39s
Train Epoch: 2022 [20480/90000 (23%)]	Loss: -22.6091	Cost: 5.96s
Train Epoch: 2022 [40960/90000 (45%)]	Loss: -22.0772	Cost: 7.72s
Train Epoch: 2022 [61440/90000 (68%)]	Loss: -22.4928	Cost: 5.81s
Train Epoch: 2022 [81920/90000 (91%)]	Loss: -22.4942	Cost: 6.24s
Train Epoch: 2022 	Average Loss: -22.0014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5227

Learning rate: 0.00019979830923669365
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2023 [0/90000 (0%)]	Loss: -15.3475	Cost: 22.96s
Train Epoch: 2023 [20480/90000 (23%)]	Loss: -22.7309	Cost: 5.98s
Train Epoch: 2023 [40960/90000 (45%)]	Loss: -21.9747	Cost: 7.89s
Train Epoch: 2023 [61440/90000 (68%)]	Loss: -22.4703	Cost: 5.81s
Train Epoch: 2023 [81920/90000 (91%)]	Loss: -22.7665	Cost: 6.35s
Train Epoch: 2023 	Average Loss: -21.9931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6141

Saving model as e2023_model.pt & e2023_waveforms_supplementary.hdf5
Learning rate: 0.00019979810975822925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2024 [0/90000 (0%)]	Loss: -15.9965	Cost: 23.22s
Train Epoch: 2024 [20480/90000 (23%)]	Loss: -22.8389	Cost: 6.13s
Train Epoch: 2024 [40960/90000 (45%)]	Loss: -22.0437	Cost: 7.64s
Train Epoch: 2024 [61440/90000 (68%)]	Loss: -22.2608	Cost: 5.91s
Train Epoch: 2024 [81920/90000 (91%)]	Loss: -22.2810	Cost: 6.32s
Train Epoch: 2024 	Average Loss: -21.9667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2734

Learning rate: 0.00019979791018126807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2025 [0/90000 (0%)]	Loss: -15.9773	Cost: 22.73s
Train Epoch: 2025 [20480/90000 (23%)]	Loss: -22.7085	Cost: 6.00s
Train Epoch: 2025 [40960/90000 (45%)]	Loss: -22.0929	Cost: 7.59s
Train Epoch: 2025 [61440/90000 (68%)]	Loss: -22.2807	Cost: 5.86s
Train Epoch: 2025 [81920/90000 (91%)]	Loss: -22.3172	Cost: 6.15s
Train Epoch: 2025 	Average Loss: -21.9689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2854

Learning rate: 0.00019979771050581029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2026 [0/90000 (0%)]	Loss: -15.5167	Cost: 23.41s
Train Epoch: 2026 [20480/90000 (23%)]	Loss: -22.2368	Cost: 5.98s
Train Epoch: 2026 [40960/90000 (45%)]	Loss: -22.0709	Cost: 7.56s
Train Epoch: 2026 [61440/90000 (68%)]	Loss: -22.1588	Cost: 5.90s
Train Epoch: 2026 [81920/90000 (91%)]	Loss: -22.0702	Cost: 6.00s
Train Epoch: 2026 	Average Loss: -21.7515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1934

Learning rate: 0.0001997975107318561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2027 [0/90000 (0%)]	Loss: -16.1039	Cost: 23.06s
Train Epoch: 2027 [20480/90000 (23%)]	Loss: -22.5548	Cost: 5.99s
Train Epoch: 2027 [40960/90000 (45%)]	Loss: -22.1272	Cost: 7.64s
Train Epoch: 2027 [61440/90000 (68%)]	Loss: -22.5166	Cost: 5.81s
Train Epoch: 2027 [81920/90000 (91%)]	Loss: -22.4942	Cost: 6.34s
Train Epoch: 2027 	Average Loss: -21.9179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5011

Learning rate: 0.00019979731085940572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2028 [0/90000 (0%)]	Loss: -15.4019	Cost: 22.77s
Train Epoch: 2028 [20480/90000 (23%)]	Loss: -22.5633	Cost: 5.99s
Train Epoch: 2028 [40960/90000 (45%)]	Loss: -22.0064	Cost: 7.76s
Train Epoch: 2028 [61440/90000 (68%)]	Loss: -22.4004	Cost: 5.98s
Train Epoch: 2028 [81920/90000 (91%)]	Loss: -22.5339	Cost: 6.43s
Train Epoch: 2028 	Average Loss: -21.9758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3568

Learning rate: 0.00019979711088845934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2029 [0/90000 (0%)]	Loss: -16.0379	Cost: 23.16s
Train Epoch: 2029 [20480/90000 (23%)]	Loss: -22.4560	Cost: 6.01s
Train Epoch: 2029 [40960/90000 (45%)]	Loss: -21.8506	Cost: 7.69s
Train Epoch: 2029 [61440/90000 (68%)]	Loss: -22.5089	Cost: 5.86s
Train Epoch: 2029 [81920/90000 (91%)]	Loss: -22.3747	Cost: 6.23s
Train Epoch: 2029 	Average Loss: -21.9327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5591

Learning rate: 0.00019979691081901715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2030 [0/90000 (0%)]	Loss: -15.5861	Cost: 22.66s
Train Epoch: 2030 [20480/90000 (23%)]	Loss: -22.5763	Cost: 6.02s
Train Epoch: 2030 [40960/90000 (45%)]	Loss: -22.4185	Cost: 8.06s
Train Epoch: 2030 [61440/90000 (68%)]	Loss: -22.4409	Cost: 6.00s
Train Epoch: 2030 [81920/90000 (91%)]	Loss: -22.5564	Cost: 6.09s
Train Epoch: 2030 	Average Loss: -22.0246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4160

Learning rate: 0.00019979671065107937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2031 [0/90000 (0%)]	Loss: -15.9904	Cost: 22.50s
Train Epoch: 2031 [20480/90000 (23%)]	Loss: -22.9465	Cost: 6.01s
Train Epoch: 2031 [40960/90000 (45%)]	Loss: -22.2374	Cost: 7.84s
Train Epoch: 2031 [61440/90000 (68%)]	Loss: -22.4070	Cost: 5.82s
Train Epoch: 2031 [81920/90000 (91%)]	Loss: -22.2704	Cost: 6.26s
Train Epoch: 2031 	Average Loss: -22.1004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4067

Learning rate: 0.0001997965103846462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2032 [0/90000 (0%)]	Loss: -14.7958	Cost: 23.10s
Train Epoch: 2032 [20480/90000 (23%)]	Loss: -22.6405	Cost: 6.02s
Train Epoch: 2032 [40960/90000 (45%)]	Loss: -21.9034	Cost: 8.20s
Train Epoch: 2032 [61440/90000 (68%)]	Loss: -22.4462	Cost: 5.92s
Train Epoch: 2032 [81920/90000 (91%)]	Loss: -22.5531	Cost: 6.32s
Train Epoch: 2032 	Average Loss: -21.9148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6770

Saving model as e2032_model.pt & e2032_waveforms_supplementary.hdf5
Learning rate: 0.0001997963100197178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2033 [0/90000 (0%)]	Loss: -15.4467	Cost: 23.07s
Train Epoch: 2033 [20480/90000 (23%)]	Loss: -22.7138	Cost: 5.99s
Train Epoch: 2033 [40960/90000 (45%)]	Loss: -22.0482	Cost: 7.72s
Train Epoch: 2033 [61440/90000 (68%)]	Loss: -22.2516	Cost: 5.81s
Train Epoch: 2033 [81920/90000 (91%)]	Loss: -22.3865	Cost: 6.09s
Train Epoch: 2033 	Average Loss: -21.9180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3215

Learning rate: 0.0001997961095562944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2034 [0/90000 (0%)]	Loss: -16.0442	Cost: 23.62s
Train Epoch: 2034 [20480/90000 (23%)]	Loss: -22.4560	Cost: 6.00s
Train Epoch: 2034 [40960/90000 (45%)]	Loss: -22.1767	Cost: 8.04s
Train Epoch: 2034 [61440/90000 (68%)]	Loss: -22.6044	Cost: 5.77s
Train Epoch: 2034 [81920/90000 (91%)]	Loss: -22.6928	Cost: 6.26s
Train Epoch: 2034 	Average Loss: -22.0616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7173

Saving model as e2034_model.pt & e2034_waveforms_supplementary.hdf5
Learning rate: 0.00019979590899437617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2035 [0/90000 (0%)]	Loss: -16.1015	Cost: 22.79s
Train Epoch: 2035 [20480/90000 (23%)]	Loss: -22.7670	Cost: 6.00s
Train Epoch: 2035 [40960/90000 (45%)]	Loss: -22.3512	Cost: 7.67s
Train Epoch: 2035 [61440/90000 (68%)]	Loss: -22.6117	Cost: 5.92s
Train Epoch: 2035 [81920/90000 (91%)]	Loss: -22.6482	Cost: 6.32s
Train Epoch: 2035 	Average Loss: -22.0948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6568

Learning rate: 0.00019979570833396335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2036 [0/90000 (0%)]	Loss: -15.9232	Cost: 22.80s
Train Epoch: 2036 [20480/90000 (23%)]	Loss: -22.7852	Cost: 6.03s
Train Epoch: 2036 [40960/90000 (45%)]	Loss: -22.0716	Cost: 7.76s
Train Epoch: 2036 [61440/90000 (68%)]	Loss: -22.6625	Cost: 5.80s
Train Epoch: 2036 [81920/90000 (91%)]	Loss: -22.5533	Cost: 6.39s
Train Epoch: 2036 	Average Loss: -22.1208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5535

Learning rate: 0.00019979550757505608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2037 [0/90000 (0%)]	Loss: -15.1974	Cost: 22.78s
Train Epoch: 2037 [20480/90000 (23%)]	Loss: -22.5949	Cost: 6.00s
Train Epoch: 2037 [40960/90000 (45%)]	Loss: -22.0831	Cost: 7.56s
Train Epoch: 2037 [61440/90000 (68%)]	Loss: -22.4167	Cost: 5.81s
Train Epoch: 2037 [81920/90000 (91%)]	Loss: -22.5603	Cost: 6.16s
Train Epoch: 2037 	Average Loss: -21.9819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4651

Learning rate: 0.00019979530671765462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2038 [0/90000 (0%)]	Loss: -15.5616	Cost: 22.93s
Train Epoch: 2038 [20480/90000 (23%)]	Loss: -22.4944	Cost: 5.99s
Train Epoch: 2038 [40960/90000 (45%)]	Loss: -22.0772	Cost: 7.75s
Train Epoch: 2038 [61440/90000 (68%)]	Loss: -22.4053	Cost: 5.80s
Train Epoch: 2038 [81920/90000 (91%)]	Loss: -22.6630	Cost: 6.20s
Train Epoch: 2038 	Average Loss: -21.9576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5787

Learning rate: 0.00019979510576175914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2039 [0/90000 (0%)]	Loss: -15.8893	Cost: 22.75s
Train Epoch: 2039 [20480/90000 (23%)]	Loss: -22.6057	Cost: 6.00s
Train Epoch: 2039 [40960/90000 (45%)]	Loss: -22.2071	Cost: 7.77s
Train Epoch: 2039 [61440/90000 (68%)]	Loss: -22.3386	Cost: 5.81s
Train Epoch: 2039 [81920/90000 (91%)]	Loss: -22.5524	Cost: 6.18s
Train Epoch: 2039 	Average Loss: -22.0153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9480

Learning rate: 0.00019979490470736983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2040 [0/90000 (0%)]	Loss: -14.8215	Cost: 23.45s
Train Epoch: 2040 [20480/90000 (23%)]	Loss: -21.5377	Cost: 5.99s
Train Epoch: 2040 [40960/90000 (45%)]	Loss: -20.9299	Cost: 7.46s
Train Epoch: 2040 [61440/90000 (68%)]	Loss: -21.4847	Cost: 5.81s
Train Epoch: 2040 [81920/90000 (91%)]	Loss: -21.6698	Cost: 6.19s
Train Epoch: 2040 	Average Loss: -21.0496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0055

Learning rate: 0.0001997947035544869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2041 [0/90000 (0%)]	Loss: -15.4770	Cost: 22.67s
Train Epoch: 2041 [20480/90000 (23%)]	Loss: -22.2541	Cost: 5.96s
Train Epoch: 2041 [40960/90000 (45%)]	Loss: -21.3534	Cost: 7.93s
Train Epoch: 2041 [61440/90000 (68%)]	Loss: -21.9435	Cost: 5.80s
Train Epoch: 2041 [81920/90000 (91%)]	Loss: -22.2864	Cost: 6.28s
Train Epoch: 2041 	Average Loss: -21.6014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4800

Learning rate: 0.00019979450230311056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2042 [0/90000 (0%)]	Loss: -15.6838	Cost: 23.02s
Train Epoch: 2042 [20480/90000 (23%)]	Loss: -22.7964	Cost: 6.00s
Train Epoch: 2042 [40960/90000 (45%)]	Loss: -22.3229	Cost: 8.00s
Train Epoch: 2042 [61440/90000 (68%)]	Loss: -22.6216	Cost: 5.76s
Train Epoch: 2042 [81920/90000 (91%)]	Loss: -22.6727	Cost: 6.54s
Train Epoch: 2042 	Average Loss: -22.1721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7223

Saving model as e2042_model.pt & e2042_waveforms_supplementary.hdf5
Learning rate: 0.00019979430095324097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2043 [0/90000 (0%)]	Loss: -16.3447	Cost: 23.38s
Train Epoch: 2043 [20480/90000 (23%)]	Loss: -22.9642	Cost: 6.16s
Train Epoch: 2043 [40960/90000 (45%)]	Loss: -22.2150	Cost: 7.42s
Train Epoch: 2043 [61440/90000 (68%)]	Loss: -22.6854	Cost: 5.85s
Train Epoch: 2043 [81920/90000 (91%)]	Loss: -22.6436	Cost: 6.07s
Train Epoch: 2043 	Average Loss: -22.1801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4209

Learning rate: 0.00019979409950487837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2044 [0/90000 (0%)]	Loss: -15.8857	Cost: 22.69s
Train Epoch: 2044 [20480/90000 (23%)]	Loss: -22.6218	Cost: 6.00s
Train Epoch: 2044 [40960/90000 (45%)]	Loss: -22.0804	Cost: 7.70s
Train Epoch: 2044 [61440/90000 (68%)]	Loss: -22.3597	Cost: 5.89s
Train Epoch: 2044 [81920/90000 (91%)]	Loss: -22.4506	Cost: 6.30s
Train Epoch: 2044 	Average Loss: -22.0544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5963

Learning rate: 0.0001997938979580229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2045 [0/90000 (0%)]	Loss: -15.2340	Cost: 23.36s
Train Epoch: 2045 [20480/90000 (23%)]	Loss: -22.7598	Cost: 6.00s
Train Epoch: 2045 [40960/90000 (45%)]	Loss: -22.2503	Cost: 7.81s
Train Epoch: 2045 [61440/90000 (68%)]	Loss: -22.6051	Cost: 6.13s
Train Epoch: 2045 [81920/90000 (91%)]	Loss: -22.7006	Cost: 5.77s
Train Epoch: 2045 	Average Loss: -22.1053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6861

Learning rate: 0.00019979369631267487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2046 [0/90000 (0%)]	Loss: -15.1556	Cost: 22.81s
Train Epoch: 2046 [20480/90000 (23%)]	Loss: -22.9442	Cost: 8.80s
Train Epoch: 2046 [40960/90000 (45%)]	Loss: -22.0783	Cost: 16.28s
Train Epoch: 2046 [61440/90000 (68%)]	Loss: -22.1988	Cost: 5.82s
Train Epoch: 2046 [81920/90000 (91%)]	Loss: -22.4654	Cost: 11.26s
Train Epoch: 2046 	Average Loss: -22.0253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3787

Learning rate: 0.0001997934945688344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2047 [0/90000 (0%)]	Loss: -14.7631	Cost: 28.29s
Train Epoch: 2047 [20480/90000 (23%)]	Loss: -22.4737	Cost: 8.16s
Train Epoch: 2047 [40960/90000 (45%)]	Loss: -21.8843	Cost: 17.07s
Train Epoch: 2047 [61440/90000 (68%)]	Loss: -22.2381	Cost: 7.36s
Train Epoch: 2047 [81920/90000 (91%)]	Loss: -22.5094	Cost: 9.01s
Train Epoch: 2047 	Average Loss: -21.8801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5106

Learning rate: 0.00019979329272650168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2048 [0/90000 (0%)]	Loss: -15.9562	Cost: 25.97s
Train Epoch: 2048 [20480/90000 (23%)]	Loss: -22.6416	Cost: 10.20s
Train Epoch: 2048 [40960/90000 (45%)]	Loss: -22.3282	Cost: 13.71s
Train Epoch: 2048 [61440/90000 (68%)]	Loss: -22.7150	Cost: 9.61s
Train Epoch: 2048 [81920/90000 (91%)]	Loss: -22.7704	Cost: 9.04s
Train Epoch: 2048 	Average Loss: -22.1567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8361

Saving model as e2048_model.pt & e2048_waveforms_supplementary.hdf5
Learning rate: 0.00019979309078567694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2049 [0/90000 (0%)]	Loss: -15.4282	Cost: 72.48s
Train Epoch: 2049 [20480/90000 (23%)]	Loss: -22.5889	Cost: 9.93s
Train Epoch: 2049 [40960/90000 (45%)]	Loss: -22.3616	Cost: 20.43s
Train Epoch: 2049 [61440/90000 (68%)]	Loss: -22.7459	Cost: 9.51s
Train Epoch: 2049 [81920/90000 (91%)]	Loss: -22.7366	Cost: 26.38s
Train Epoch: 2049 	Average Loss: -22.2210
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7222

Learning rate: 0.00019979288874636032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2050 [0/90000 (0%)]	Loss: -16.2785	Cost: 22.83s
Train Epoch: 2050 [20480/90000 (23%)]	Loss: -22.5323	Cost: 6.22s
Train Epoch: 2050 [40960/90000 (45%)]	Loss: -22.1455	Cost: 7.28s
Train Epoch: 2050 [61440/90000 (68%)]	Loss: -22.1871	Cost: 5.89s
Train Epoch: 2050 [81920/90000 (91%)]	Loss: -22.4746	Cost: 6.11s
Train Epoch: 2050 	Average Loss: -22.0051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5783

Learning rate: 0.0001997926866085521
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2051 [0/90000 (0%)]	Loss: -16.2067	Cost: 23.76s
Train Epoch: 2051 [20480/90000 (23%)]	Loss: -22.7367	Cost: 6.13s
Train Epoch: 2051 [40960/90000 (45%)]	Loss: -22.1784	Cost: 7.58s
Train Epoch: 2051 [61440/90000 (68%)]	Loss: -22.6798	Cost: 5.94s
Train Epoch: 2051 [81920/90000 (91%)]	Loss: -22.7569	Cost: 6.33s
Train Epoch: 2051 	Average Loss: -22.1233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7019

Learning rate: 0.00019979248437225245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2052 [0/90000 (0%)]	Loss: -15.6242	Cost: 22.37s
Train Epoch: 2052 [20480/90000 (23%)]	Loss: -22.7618	Cost: 6.05s
Train Epoch: 2052 [40960/90000 (45%)]	Loss: -22.1646	Cost: 7.38s
Train Epoch: 2052 [61440/90000 (68%)]	Loss: -22.6646	Cost: 6.01s
Train Epoch: 2052 [81920/90000 (91%)]	Loss: -22.8490	Cost: 6.30s
Train Epoch: 2052 	Average Loss: -22.2687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8026

Learning rate: 0.00019979228203746157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2053 [0/90000 (0%)]	Loss: -16.0462	Cost: 22.90s
Train Epoch: 2053 [20480/90000 (23%)]	Loss: -22.9371	Cost: 6.13s
Train Epoch: 2053 [40960/90000 (45%)]	Loss: -22.2684	Cost: 7.34s
Train Epoch: 2053 [61440/90000 (68%)]	Loss: -22.6284	Cost: 5.83s
Train Epoch: 2053 [81920/90000 (91%)]	Loss: -22.7883	Cost: 6.32s
Train Epoch: 2053 	Average Loss: -22.2115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7646

Learning rate: 0.00019979207960417963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2054 [0/90000 (0%)]	Loss: -16.7201	Cost: 22.69s
Train Epoch: 2054 [20480/90000 (23%)]	Loss: -22.9054	Cost: 6.13s
Train Epoch: 2054 [40960/90000 (45%)]	Loss: -22.4961	Cost: 7.27s
Train Epoch: 2054 [61440/90000 (68%)]	Loss: -22.7111	Cost: 5.92s
Train Epoch: 2054 [81920/90000 (91%)]	Loss: -22.7090	Cost: 6.36s
Train Epoch: 2054 	Average Loss: -22.2796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7394

Learning rate: 0.00019979187707240686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2055 [0/90000 (0%)]	Loss: -15.9338	Cost: 22.22s
Train Epoch: 2055 [20480/90000 (23%)]	Loss: -22.3481	Cost: 6.05s
Train Epoch: 2055 [40960/90000 (45%)]	Loss: -21.7311	Cost: 8.22s
Train Epoch: 2055 [61440/90000 (68%)]	Loss: -22.3168	Cost: 5.89s
Train Epoch: 2055 [81920/90000 (91%)]	Loss: -22.4960	Cost: 6.51s
Train Epoch: 2055 	Average Loss: -21.8649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4664

Learning rate: 0.00019979167444214346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2056 [0/90000 (0%)]	Loss: -15.5672	Cost: 23.29s
Train Epoch: 2056 [20480/90000 (23%)]	Loss: -22.7895	Cost: 6.24s
Train Epoch: 2056 [40960/90000 (45%)]	Loss: -22.3306	Cost: 6.74s
Train Epoch: 2056 [61440/90000 (68%)]	Loss: -22.7485	Cost: 5.85s
Train Epoch: 2056 [81920/90000 (91%)]	Loss: -22.6714	Cost: 6.71s
Train Epoch: 2056 	Average Loss: -22.1329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4366

Learning rate: 0.00019979147171338965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2057 [0/90000 (0%)]	Loss: -14.8794	Cost: 22.53s
Train Epoch: 2057 [20480/90000 (23%)]	Loss: -22.5698	Cost: 6.05s
Train Epoch: 2057 [40960/90000 (45%)]	Loss: -22.2442	Cost: 7.34s
Train Epoch: 2057 [61440/90000 (68%)]	Loss: -22.6785	Cost: 5.92s
Train Epoch: 2057 [81920/90000 (91%)]	Loss: -22.6270	Cost: 6.32s
Train Epoch: 2057 	Average Loss: -22.0474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5630

Learning rate: 0.00019979126888614558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2058 [0/90000 (0%)]	Loss: -16.1426	Cost: 22.32s
Train Epoch: 2058 [20480/90000 (23%)]	Loss: -22.9180	Cost: 6.16s
Train Epoch: 2058 [40960/90000 (45%)]	Loss: -22.3939	Cost: 7.74s
Train Epoch: 2058 [61440/90000 (68%)]	Loss: -22.5926	Cost: 5.82s
Train Epoch: 2058 [81920/90000 (91%)]	Loss: -22.8217	Cost: 5.94s
Train Epoch: 2058 	Average Loss: -22.2570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6010

Learning rate: 0.00019979106596041147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2059 [0/90000 (0%)]	Loss: -16.4026	Cost: 22.52s
Train Epoch: 2059 [20480/90000 (23%)]	Loss: -23.0408	Cost: 6.27s
Train Epoch: 2059 [40960/90000 (45%)]	Loss: -22.2588	Cost: 6.91s
Train Epoch: 2059 [61440/90000 (68%)]	Loss: -22.8425	Cost: 5.87s
Train Epoch: 2059 [81920/90000 (91%)]	Loss: -22.6534	Cost: 6.64s
Train Epoch: 2059 	Average Loss: -22.1906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3985

Learning rate: 0.00019979086293618752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2060 [0/90000 (0%)]	Loss: -14.1004	Cost: 22.49s
Train Epoch: 2060 [20480/90000 (23%)]	Loss: -22.6626	Cost: 6.31s
Train Epoch: 2060 [40960/90000 (45%)]	Loss: -22.1611	Cost: 7.39s
Train Epoch: 2060 [61440/90000 (68%)]	Loss: -22.6901	Cost: 5.88s
Train Epoch: 2060 [81920/90000 (91%)]	Loss: -22.9240	Cost: 6.26s
Train Epoch: 2060 	Average Loss: -21.9467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5452

Learning rate: 0.00019979065981347397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2061 [0/90000 (0%)]	Loss: -15.6164	Cost: 22.66s
Train Epoch: 2061 [20480/90000 (23%)]	Loss: -22.6861	Cost: 6.04s
Train Epoch: 2061 [40960/90000 (45%)]	Loss: -22.1626	Cost: 7.46s
Train Epoch: 2061 [61440/90000 (68%)]	Loss: -22.5505	Cost: 5.89s
Train Epoch: 2061 [81920/90000 (91%)]	Loss: -22.6627	Cost: 5.93s
Train Epoch: 2061 	Average Loss: -22.1721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5132

Learning rate: 0.00019979045659227097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2062 [0/90000 (0%)]	Loss: -15.2764	Cost: 22.39s
Train Epoch: 2062 [20480/90000 (23%)]	Loss: -22.9053	Cost: 6.34s
Train Epoch: 2062 [40960/90000 (45%)]	Loss: -20.3511	Cost: 7.65s
Train Epoch: 2062 [61440/90000 (68%)]	Loss: -20.5013	Cost: 5.86s
Train Epoch: 2062 [81920/90000 (91%)]	Loss: -20.9255	Cost: 6.49s
Train Epoch: 2062 	Average Loss: -20.9407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9724

Learning rate: 0.00019979025327257873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2063 [0/90000 (0%)]	Loss: -14.4122	Cost: 22.63s
Train Epoch: 2063 [20480/90000 (23%)]	Loss: -21.4249	Cost: 6.12s
Train Epoch: 2063 [40960/90000 (45%)]	Loss: -21.5063	Cost: 7.17s
Train Epoch: 2063 [61440/90000 (68%)]	Loss: -21.8912	Cost: 5.77s
Train Epoch: 2063 [81920/90000 (91%)]	Loss: -22.3176	Cost: 6.27s
Train Epoch: 2063 	Average Loss: -21.2965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3941

Learning rate: 0.00019979004985439745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2064 [0/90000 (0%)]	Loss: -15.4588	Cost: 23.45s
Train Epoch: 2064 [20480/90000 (23%)]	Loss: -22.6790	Cost: 6.07s
Train Epoch: 2064 [40960/90000 (45%)]	Loss: -22.2717	Cost: 7.49s
Train Epoch: 2064 [61440/90000 (68%)]	Loss: -21.9912	Cost: 5.84s
Train Epoch: 2064 [81920/90000 (91%)]	Loss: -22.0806	Cost: 6.05s
Train Epoch: 2064 	Average Loss: -21.8759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0243

Learning rate: 0.00019978984633772735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2065 [0/90000 (0%)]	Loss: -14.9346	Cost: 28.86s
Train Epoch: 2065 [20480/90000 (23%)]	Loss: -22.2753	Cost: 9.69s
Train Epoch: 2065 [40960/90000 (45%)]	Loss: -20.6705	Cost: 8.30s
Train Epoch: 2065 [61440/90000 (68%)]	Loss: -21.2723	Cost: 7.15s
Train Epoch: 2065 [81920/90000 (91%)]	Loss: -21.6011	Cost: 9.49s
Train Epoch: 2065 	Average Loss: -21.0969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8300

Learning rate: 0.00019978964272256863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2066 [0/90000 (0%)]	Loss: -14.8423	Cost: 36.57s
Train Epoch: 2066 [20480/90000 (23%)]	Loss: -21.9920	Cost: 8.68s
Train Epoch: 2066 [40960/90000 (45%)]	Loss: -21.5432	Cost: 10.79s
Train Epoch: 2066 [61440/90000 (68%)]	Loss: -22.4604	Cost: 9.69s
Train Epoch: 2066 [81920/90000 (91%)]	Loss: -22.6216	Cost: 7.59s
Train Epoch: 2066 	Average Loss: -21.6919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5943

Learning rate: 0.0001997894390089215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2067 [0/90000 (0%)]	Loss: -15.0998	Cost: 28.13s
Train Epoch: 2067 [20480/90000 (23%)]	Loss: -22.8516	Cost: 6.99s
Train Epoch: 2067 [40960/90000 (45%)]	Loss: -22.2105	Cost: 14.09s
Train Epoch: 2067 [61440/90000 (68%)]	Loss: -22.7117	Cost: 6.81s
Train Epoch: 2067 [81920/90000 (91%)]	Loss: -22.7216	Cost: 6.79s
Train Epoch: 2067 	Average Loss: -22.1423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7092

Learning rate: 0.00019978923519678609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2068 [0/90000 (0%)]	Loss: -16.2485	Cost: 62.35s
Train Epoch: 2068 [20480/90000 (23%)]	Loss: -22.6924	Cost: 9.91s
Train Epoch: 2068 [40960/90000 (45%)]	Loss: -21.8770	Cost: 18.49s
Train Epoch: 2068 [61440/90000 (68%)]	Loss: -22.2033	Cost: 8.87s
Train Epoch: 2068 [81920/90000 (91%)]	Loss: -22.2718	Cost: 21.21s
Train Epoch: 2068 	Average Loss: -21.9192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3668

Learning rate: 0.00019978903128616267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2069 [0/90000 (0%)]	Loss: -15.9711	Cost: 22.33s
Train Epoch: 2069 [20480/90000 (23%)]	Loss: -22.6087	Cost: 6.73s
Train Epoch: 2069 [40960/90000 (45%)]	Loss: -22.1898	Cost: 6.28s
Train Epoch: 2069 [61440/90000 (68%)]	Loss: -22.5264	Cost: 6.19s
Train Epoch: 2069 [81920/90000 (91%)]	Loss: -22.4979	Cost: 6.33s
Train Epoch: 2069 	Average Loss: -22.0078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3716

Learning rate: 0.00019978882727705142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2070 [0/90000 (0%)]	Loss: -15.1625	Cost: 22.65s
Train Epoch: 2070 [20480/90000 (23%)]	Loss: -22.8547	Cost: 6.13s
Train Epoch: 2070 [40960/90000 (45%)]	Loss: -22.1090	Cost: 7.20s
Train Epoch: 2070 [61440/90000 (68%)]	Loss: -22.6047	Cost: 6.45s
Train Epoch: 2070 [81920/90000 (91%)]	Loss: -22.5538	Cost: 6.09s
Train Epoch: 2070 	Average Loss: -22.0635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5266

Learning rate: 0.00019978862316945254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2071 [0/90000 (0%)]	Loss: -16.5057	Cost: 22.19s
Train Epoch: 2071 [20480/90000 (23%)]	Loss: -22.7492	Cost: 6.13s
Train Epoch: 2071 [40960/90000 (45%)]	Loss: -21.8570	Cost: 6.49s
Train Epoch: 2071 [61440/90000 (68%)]	Loss: -22.3543	Cost: 5.82s
Train Epoch: 2071 [81920/90000 (91%)]	Loss: -22.7339	Cost: 5.81s
Train Epoch: 2071 	Average Loss: -22.0576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5897

Learning rate: 0.00019978841896336626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2072 [0/90000 (0%)]	Loss: -15.7279	Cost: 21.99s
Train Epoch: 2072 [20480/90000 (23%)]	Loss: -22.7637	Cost: 6.02s
Train Epoch: 2072 [40960/90000 (45%)]	Loss: -22.3402	Cost: 7.02s
Train Epoch: 2072 [61440/90000 (68%)]	Loss: -22.8093	Cost: 5.79s
Train Epoch: 2072 [81920/90000 (91%)]	Loss: -23.0078	Cost: 5.76s
Train Epoch: 2072 	Average Loss: -22.3531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8608

Saving model as e2072_model.pt & e2072_waveforms_supplementary.hdf5
Learning rate: 0.00019978821465879275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2073 [0/90000 (0%)]	Loss: -15.7973	Cost: 22.08s
Train Epoch: 2073 [20480/90000 (23%)]	Loss: -22.9418	Cost: 5.96s
Train Epoch: 2073 [40960/90000 (45%)]	Loss: -22.3641	Cost: 6.78s
Train Epoch: 2073 [61440/90000 (68%)]	Loss: -22.8386	Cost: 5.82s
Train Epoch: 2073 [81920/90000 (91%)]	Loss: -22.8661	Cost: 5.89s
Train Epoch: 2073 	Average Loss: -22.3243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8248

Learning rate: 0.00019978801025573225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2074 [0/90000 (0%)]	Loss: -15.4065	Cost: 21.98s
Train Epoch: 2074 [20480/90000 (23%)]	Loss: -23.1159	Cost: 5.98s
Train Epoch: 2074 [40960/90000 (45%)]	Loss: -22.4391	Cost: 6.95s
Train Epoch: 2074 [61440/90000 (68%)]	Loss: -22.7889	Cost: 5.82s
Train Epoch: 2074 [81920/90000 (91%)]	Loss: -22.7950	Cost: 5.90s
Train Epoch: 2074 	Average Loss: -22.3743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5425

Learning rate: 0.00019978780575418488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2075 [0/90000 (0%)]	Loss: -15.9228	Cost: 20.91s
Train Epoch: 2075 [20480/90000 (23%)]	Loss: -22.8438	Cost: 5.99s
Train Epoch: 2075 [40960/90000 (45%)]	Loss: -22.4390	Cost: 7.07s
Train Epoch: 2075 [61440/90000 (68%)]	Loss: -22.8310	Cost: 5.86s
Train Epoch: 2075 [81920/90000 (91%)]	Loss: -22.7529	Cost: 5.83s
Train Epoch: 2075 	Average Loss: -22.2903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7435

Learning rate: 0.00019978760115415092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2076 [0/90000 (0%)]	Loss: -16.0468	Cost: 22.06s
Train Epoch: 2076 [20480/90000 (23%)]	Loss: -22.9100	Cost: 6.05s
Train Epoch: 2076 [40960/90000 (45%)]	Loss: -22.4636	Cost: 7.43s
Train Epoch: 2076 [61440/90000 (68%)]	Loss: -23.0084	Cost: 5.74s
Train Epoch: 2076 [81920/90000 (91%)]	Loss: -22.9854	Cost: 6.17s
Train Epoch: 2076 	Average Loss: -22.3958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6679

Learning rate: 0.0001997873964556305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2077 [0/90000 (0%)]	Loss: -15.5853	Cost: 21.93s
Train Epoch: 2077 [20480/90000 (23%)]	Loss: -23.0250	Cost: 5.99s
Train Epoch: 2077 [40960/90000 (45%)]	Loss: -22.2913	Cost: 7.57s
Train Epoch: 2077 [61440/90000 (68%)]	Loss: -22.8446	Cost: 5.75s
Train Epoch: 2077 [81920/90000 (91%)]	Loss: -22.7480	Cost: 5.87s
Train Epoch: 2077 	Average Loss: -22.2808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4786

Learning rate: 0.00019978719165862388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2078 [0/90000 (0%)]	Loss: -14.9554	Cost: 21.84s
Train Epoch: 2078 [20480/90000 (23%)]	Loss: -22.7781	Cost: 5.98s
Train Epoch: 2078 [40960/90000 (45%)]	Loss: -22.2206	Cost: 6.85s
Train Epoch: 2078 [61440/90000 (68%)]	Loss: -22.6892	Cost: 5.93s
Train Epoch: 2078 [81920/90000 (91%)]	Loss: -22.9595	Cost: 5.61s
Train Epoch: 2078 	Average Loss: -22.1500
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7564

Learning rate: 0.0001997869867631313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2079 [0/90000 (0%)]	Loss: -15.0668	Cost: 21.63s
Train Epoch: 2079 [20480/90000 (23%)]	Loss: -23.0939	Cost: 5.96s
Train Epoch: 2079 [40960/90000 (45%)]	Loss: -22.4137	Cost: 6.70s
Train Epoch: 2079 [61440/90000 (68%)]	Loss: -22.8622	Cost: 5.81s
Train Epoch: 2079 [81920/90000 (91%)]	Loss: -22.9803	Cost: 5.61s
Train Epoch: 2079 	Average Loss: -22.3900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7236

Learning rate: 0.00019978678176915286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2080 [0/90000 (0%)]	Loss: -16.1539	Cost: 21.74s
Train Epoch: 2080 [20480/90000 (23%)]	Loss: -23.0867	Cost: 6.01s
Train Epoch: 2080 [40960/90000 (45%)]	Loss: -22.3821	Cost: 7.18s
Train Epoch: 2080 [61440/90000 (68%)]	Loss: -22.9250	Cost: 6.10s
Train Epoch: 2080 [81920/90000 (91%)]	Loss: -22.9037	Cost: 5.81s
Train Epoch: 2080 	Average Loss: -22.3455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8879

Saving model as e2080_model.pt & e2080_waveforms_supplementary.hdf5
Learning rate: 0.00019978657667668885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2081 [0/90000 (0%)]	Loss: -15.7643	Cost: 21.28s
Train Epoch: 2081 [20480/90000 (23%)]	Loss: -22.9539	Cost: 6.01s
Train Epoch: 2081 [40960/90000 (45%)]	Loss: -22.3846	Cost: 6.63s
Train Epoch: 2081 [61440/90000 (68%)]	Loss: -22.9922	Cost: 5.81s
Train Epoch: 2081 [81920/90000 (91%)]	Loss: -22.7721	Cost: 5.72s
Train Epoch: 2081 	Average Loss: -22.2458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6828

Learning rate: 0.00019978637148573944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2082 [0/90000 (0%)]	Loss: -16.2682	Cost: 21.99s
Train Epoch: 2082 [20480/90000 (23%)]	Loss: -22.9060	Cost: 5.99s
Train Epoch: 2082 [40960/90000 (45%)]	Loss: -22.5219	Cost: 6.89s
Train Epoch: 2082 [61440/90000 (68%)]	Loss: -22.7994	Cost: 6.00s
Train Epoch: 2082 [81920/90000 (91%)]	Loss: -22.9018	Cost: 5.65s
Train Epoch: 2082 	Average Loss: -22.3802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7480

Learning rate: 0.0001997861661963048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2083 [0/90000 (0%)]	Loss: -14.7358	Cost: 22.23s
Train Epoch: 2083 [20480/90000 (23%)]	Loss: -23.0543	Cost: 5.99s
Train Epoch: 2083 [40960/90000 (45%)]	Loss: -21.9223	Cost: 6.34s
Train Epoch: 2083 [61440/90000 (68%)]	Loss: -22.3012	Cost: 5.84s
Train Epoch: 2083 [81920/90000 (91%)]	Loss: -22.4095	Cost: 5.65s
Train Epoch: 2083 	Average Loss: -22.0527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2445

Learning rate: 0.00019978596080838518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2084 [0/90000 (0%)]	Loss: -14.9829	Cost: 21.92s
Train Epoch: 2084 [20480/90000 (23%)]	Loss: -22.6273	Cost: 6.01s
Train Epoch: 2084 [40960/90000 (45%)]	Loss: -22.2490	Cost: 6.95s
Train Epoch: 2084 [61440/90000 (68%)]	Loss: -22.6880	Cost: 5.98s
Train Epoch: 2084 [81920/90000 (91%)]	Loss: -22.8979	Cost: 5.69s
Train Epoch: 2084 	Average Loss: -22.1564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8680

Learning rate: 0.00019978575532198075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2085 [0/90000 (0%)]	Loss: -16.1238	Cost: 21.61s
Train Epoch: 2085 [20480/90000 (23%)]	Loss: -23.0225	Cost: 5.97s
Train Epoch: 2085 [40960/90000 (45%)]	Loss: -22.2744	Cost: 6.65s
Train Epoch: 2085 [61440/90000 (68%)]	Loss: -22.7540	Cost: 5.80s
Train Epoch: 2085 [81920/90000 (91%)]	Loss: -22.7613	Cost: 5.62s
Train Epoch: 2085 	Average Loss: -22.2788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4958

Learning rate: 0.00019978554973709172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2086 [0/90000 (0%)]	Loss: -15.5735	Cost: 22.01s
Train Epoch: 2086 [20480/90000 (23%)]	Loss: -22.8530	Cost: 6.04s
Train Epoch: 2086 [40960/90000 (45%)]	Loss: -22.3932	Cost: 7.70s
Train Epoch: 2086 [61440/90000 (68%)]	Loss: -23.0284	Cost: 5.71s
Train Epoch: 2086 [81920/90000 (91%)]	Loss: -22.9588	Cost: 6.17s
Train Epoch: 2086 	Average Loss: -22.3184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7743

Learning rate: 0.00019978534405371833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2087 [0/90000 (0%)]	Loss: -14.5915	Cost: 21.58s
Train Epoch: 2087 [20480/90000 (23%)]	Loss: -22.9241	Cost: 5.93s
Train Epoch: 2087 [40960/90000 (45%)]	Loss: -22.6748	Cost: 6.52s
Train Epoch: 2087 [61440/90000 (68%)]	Loss: -22.9323	Cost: 5.83s
Train Epoch: 2087 [81920/90000 (91%)]	Loss: -23.0987	Cost: 5.60s
Train Epoch: 2087 	Average Loss: -22.3802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7568

Learning rate: 0.00019978513827186072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2088 [0/90000 (0%)]	Loss: -15.4836	Cost: 22.13s
Train Epoch: 2088 [20480/90000 (23%)]	Loss: -22.9669	Cost: 6.01s
Train Epoch: 2088 [40960/90000 (45%)]	Loss: -22.5617	Cost: 6.89s
Train Epoch: 2088 [61440/90000 (68%)]	Loss: -22.7802	Cost: 5.86s
Train Epoch: 2088 [81920/90000 (91%)]	Loss: -22.8960	Cost: 5.84s
Train Epoch: 2088 	Average Loss: -22.3130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5631

Learning rate: 0.00019978493239151913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2089 [0/90000 (0%)]	Loss: -16.1775	Cost: 21.55s
Train Epoch: 2089 [20480/90000 (23%)]	Loss: -23.1413	Cost: 6.04s
Train Epoch: 2089 [40960/90000 (45%)]	Loss: -22.0463	Cost: 6.95s
Train Epoch: 2089 [61440/90000 (68%)]	Loss: -22.2839	Cost: 5.79s
Train Epoch: 2089 [81920/90000 (91%)]	Loss: -22.6901	Cost: 5.64s
Train Epoch: 2089 	Average Loss: -22.0609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6338

Learning rate: 0.0001997847264126938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2090 [0/90000 (0%)]	Loss: -15.4215	Cost: 21.53s
Train Epoch: 2090 [20480/90000 (23%)]	Loss: -22.0805	Cost: 6.03s
Train Epoch: 2090 [40960/90000 (45%)]	Loss: -21.8660	Cost: 6.67s
Train Epoch: 2090 [61440/90000 (68%)]	Loss: -22.5046	Cost: 6.11s
Train Epoch: 2090 [81920/90000 (91%)]	Loss: -22.8285	Cost: 5.75s
Train Epoch: 2090 	Average Loss: -21.8462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6973

Learning rate: 0.00019978452033538488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2091 [0/90000 (0%)]	Loss: -16.2459	Cost: 21.29s
Train Epoch: 2091 [20480/90000 (23%)]	Loss: -23.0009	Cost: 6.01s
Train Epoch: 2091 [40960/90000 (45%)]	Loss: -22.6482	Cost: 6.70s
Train Epoch: 2091 [61440/90000 (68%)]	Loss: -22.5765	Cost: 5.93s
Train Epoch: 2091 [81920/90000 (91%)]	Loss: -22.7841	Cost: 5.65s
Train Epoch: 2091 	Average Loss: -22.2037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4264

Learning rate: 0.0001997843141595926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2092 [0/90000 (0%)]	Loss: -15.6191	Cost: 21.36s
Train Epoch: 2092 [20480/90000 (23%)]	Loss: -22.6270	Cost: 5.98s
Train Epoch: 2092 [40960/90000 (45%)]	Loss: -22.2174	Cost: 6.76s
Train Epoch: 2092 [61440/90000 (68%)]	Loss: -22.3151	Cost: 5.83s
Train Epoch: 2092 [81920/90000 (91%)]	Loss: -22.6283	Cost: 5.85s
Train Epoch: 2092 	Average Loss: -22.0931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5133

Learning rate: 0.00019978410788531713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2093 [0/90000 (0%)]	Loss: -16.6855	Cost: 21.75s
Train Epoch: 2093 [20480/90000 (23%)]	Loss: -22.6929	Cost: 6.04s
Train Epoch: 2093 [40960/90000 (45%)]	Loss: -22.3294	Cost: 6.70s
Train Epoch: 2093 [61440/90000 (68%)]	Loss: -22.8968	Cost: 5.84s
Train Epoch: 2093 [81920/90000 (91%)]	Loss: -22.8493	Cost: 5.72s
Train Epoch: 2093 	Average Loss: -22.2618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7012

Learning rate: 0.0001997839015125587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2094 [0/90000 (0%)]	Loss: -16.1946	Cost: 22.32s
Train Epoch: 2094 [20480/90000 (23%)]	Loss: -22.9652	Cost: 5.99s
Train Epoch: 2094 [40960/90000 (45%)]	Loss: -22.4065	Cost: 6.67s
Train Epoch: 2094 [61440/90000 (68%)]	Loss: -23.0642	Cost: 5.79s
Train Epoch: 2094 [81920/90000 (91%)]	Loss: -22.8560	Cost: 6.01s
Train Epoch: 2094 	Average Loss: -22.4042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6463

Learning rate: 0.00019978369504131748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2095 [0/90000 (0%)]	Loss: -15.4343	Cost: 22.89s
Train Epoch: 2095 [20480/90000 (23%)]	Loss: -22.9731	Cost: 5.98s
Train Epoch: 2095 [40960/90000 (45%)]	Loss: -22.5316	Cost: 6.86s
Train Epoch: 2095 [61440/90000 (68%)]	Loss: -22.7033	Cost: 5.82s
Train Epoch: 2095 [81920/90000 (91%)]	Loss: -22.5643	Cost: 5.81s
Train Epoch: 2095 	Average Loss: -22.2127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4193

Learning rate: 0.0001997834884715937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2096 [0/90000 (0%)]	Loss: -16.3705	Cost: 21.62s
Train Epoch: 2096 [20480/90000 (23%)]	Loss: -22.8406	Cost: 5.94s
Train Epoch: 2096 [40960/90000 (45%)]	Loss: -22.3222	Cost: 7.44s
Train Epoch: 2096 [61440/90000 (68%)]	Loss: -22.9168	Cost: 5.68s
Train Epoch: 2096 [81920/90000 (91%)]	Loss: -22.9678	Cost: 6.23s
Train Epoch: 2096 	Average Loss: -22.3349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8785

Learning rate: 0.00019978328180338757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2097 [0/90000 (0%)]	Loss: -16.1192	Cost: 22.17s
Train Epoch: 2097 [20480/90000 (23%)]	Loss: -23.2825	Cost: 5.99s
Train Epoch: 2097 [40960/90000 (45%)]	Loss: -22.0238	Cost: 6.64s
Train Epoch: 2097 [61440/90000 (68%)]	Loss: -22.3047	Cost: 5.79s
Train Epoch: 2097 [81920/90000 (91%)]	Loss: -22.7168	Cost: 5.87s
Train Epoch: 2097 	Average Loss: -22.1294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5407

Learning rate: 0.0001997830750366993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2098 [0/90000 (0%)]	Loss: -15.8520	Cost: 21.86s
Train Epoch: 2098 [20480/90000 (23%)]	Loss: -22.7833	Cost: 5.98s
Train Epoch: 2098 [40960/90000 (45%)]	Loss: -22.3959	Cost: 6.69s
Train Epoch: 2098 [61440/90000 (68%)]	Loss: -22.6963	Cost: 5.81s
Train Epoch: 2098 [81920/90000 (91%)]	Loss: -22.8844	Cost: 5.73s
Train Epoch: 2098 	Average Loss: -22.1997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6988

Learning rate: 0.00019978286817152907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2099 [0/90000 (0%)]	Loss: -15.7630	Cost: 21.89s
Train Epoch: 2099 [20480/90000 (23%)]	Loss: -22.9760	Cost: 5.96s
Train Epoch: 2099 [40960/90000 (45%)]	Loss: -22.7372	Cost: 6.98s
Train Epoch: 2099 [61440/90000 (68%)]	Loss: -22.9150	Cost: 5.78s
Train Epoch: 2099 [81920/90000 (91%)]	Loss: -22.7999	Cost: 6.30s
Train Epoch: 2099 	Average Loss: -22.3493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4819

Learning rate: 0.0001997826612078771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2100 [0/90000 (0%)]	Loss: -15.5357	Cost: 21.91s
Train Epoch: 2100 [20480/90000 (23%)]	Loss: -22.6793	Cost: 5.96s
Train Epoch: 2100 [40960/90000 (45%)]	Loss: -22.3683	Cost: 7.05s
Train Epoch: 2100 [61440/90000 (68%)]	Loss: -22.2142	Cost: 5.73s
Train Epoch: 2100 [81920/90000 (91%)]	Loss: -22.1805	Cost: 6.14s
Train Epoch: 2100 	Average Loss: -22.0092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2203

Learning rate: 0.00019978245414574363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2101 [0/90000 (0%)]	Loss: -15.4688	Cost: 22.07s
Train Epoch: 2101 [20480/90000 (23%)]	Loss: -22.4194	Cost: 5.99s
Train Epoch: 2101 [40960/90000 (45%)]	Loss: -22.3412	Cost: 7.31s
Train Epoch: 2101 [61440/90000 (68%)]	Loss: -23.0138	Cost: 5.74s
Train Epoch: 2101 [81920/90000 (91%)]	Loss: -22.8580	Cost: 6.03s
Train Epoch: 2101 	Average Loss: -22.1222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7855

Learning rate: 0.00019978224698512877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2102 [0/90000 (0%)]	Loss: -15.0273	Cost: 22.44s
Train Epoch: 2102 [20480/90000 (23%)]	Loss: -22.8813	Cost: 5.96s
Train Epoch: 2102 [40960/90000 (45%)]	Loss: -22.5337	Cost: 7.19s
Train Epoch: 2102 [61440/90000 (68%)]	Loss: -22.7175	Cost: 5.73s
Train Epoch: 2102 [81920/90000 (91%)]	Loss: -22.8455	Cost: 5.90s
Train Epoch: 2102 	Average Loss: -22.2454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7532

Learning rate: 0.00019978203972603279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2103 [0/90000 (0%)]	Loss: -16.1828	Cost: 22.03s
Train Epoch: 2103 [20480/90000 (23%)]	Loss: -22.9716	Cost: 5.99s
Train Epoch: 2103 [40960/90000 (45%)]	Loss: -22.5427	Cost: 6.76s
Train Epoch: 2103 [61440/90000 (68%)]	Loss: -22.8891	Cost: 5.89s
Train Epoch: 2103 [81920/90000 (91%)]	Loss: -22.9979	Cost: 5.61s
Train Epoch: 2103 	Average Loss: -22.4370
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7060

Learning rate: 0.00019978183236845588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2104 [0/90000 (0%)]	Loss: -15.4655	Cost: 22.59s
Train Epoch: 2104 [20480/90000 (23%)]	Loss: -23.2237	Cost: 6.04s
Train Epoch: 2104 [40960/90000 (45%)]	Loss: -22.6045	Cost: 6.68s
Train Epoch: 2104 [61440/90000 (68%)]	Loss: -23.2364	Cost: 5.84s
Train Epoch: 2104 [81920/90000 (91%)]	Loss: -22.9956	Cost: 5.88s
Train Epoch: 2104 	Average Loss: -22.5941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9677

Saving model as e2104_model.pt & e2104_waveforms_supplementary.hdf5
Learning rate: 0.00019978162491239825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2105 [0/90000 (0%)]	Loss: -16.4937	Cost: 21.60s
Train Epoch: 2105 [20480/90000 (23%)]	Loss: -23.2150	Cost: 6.00s
Train Epoch: 2105 [40960/90000 (45%)]	Loss: -22.4375	Cost: 6.94s
Train Epoch: 2105 [61440/90000 (68%)]	Loss: -22.9861	Cost: 5.78s
Train Epoch: 2105 [81920/90000 (91%)]	Loss: -23.1183	Cost: 5.81s
Train Epoch: 2105 	Average Loss: -22.5322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8813

Learning rate: 0.00019978141735786014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2106 [0/90000 (0%)]	Loss: -16.2883	Cost: 22.12s
Train Epoch: 2106 [20480/90000 (23%)]	Loss: -23.0125	Cost: 6.03s
Train Epoch: 2106 [40960/90000 (45%)]	Loss: -22.5024	Cost: 6.93s
Train Epoch: 2106 [61440/90000 (68%)]	Loss: -23.1582	Cost: 5.86s
Train Epoch: 2106 [81920/90000 (91%)]	Loss: -23.2076	Cost: 5.81s
Train Epoch: 2106 	Average Loss: -22.4728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9890

Saving model as e2106_model.pt & e2106_waveforms_supplementary.hdf5
Learning rate: 0.00019978120970484168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2107 [0/90000 (0%)]	Loss: -16.3359	Cost: 21.93s
Train Epoch: 2107 [20480/90000 (23%)]	Loss: -23.1975	Cost: 6.00s
Train Epoch: 2107 [40960/90000 (45%)]	Loss: -22.7560	Cost: 7.08s
Train Epoch: 2107 [61440/90000 (68%)]	Loss: -22.6598	Cost: 5.80s
Train Epoch: 2107 [81920/90000 (91%)]	Loss: -22.3113	Cost: 5.79s
Train Epoch: 2107 	Average Loss: -22.2867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0500

Learning rate: 0.00019978100195334314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2108 [0/90000 (0%)]	Loss: -15.8287	Cost: 21.99s
Train Epoch: 2108 [20480/90000 (23%)]	Loss: -21.5755	Cost: 6.00s
Train Epoch: 2108 [40960/90000 (45%)]	Loss: -21.4512	Cost: 6.71s
Train Epoch: 2108 [61440/90000 (68%)]	Loss: -22.1176	Cost: 5.99s
Train Epoch: 2108 [81920/90000 (91%)]	Loss: -22.2679	Cost: 5.73s
Train Epoch: 2108 	Average Loss: -21.4195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4720

Learning rate: 0.00019978079410336468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2109 [0/90000 (0%)]	Loss: -15.8718	Cost: 22.46s
Train Epoch: 2109 [20480/90000 (23%)]	Loss: -22.5081	Cost: 5.95s
Train Epoch: 2109 [40960/90000 (45%)]	Loss: -21.7047	Cost: 6.58s
Train Epoch: 2109 [61440/90000 (68%)]	Loss: -22.3629	Cost: 5.88s
Train Epoch: 2109 [81920/90000 (91%)]	Loss: -22.5133	Cost: 5.62s
Train Epoch: 2109 	Average Loss: -21.8026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5573

Learning rate: 0.00019978058615490653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2110 [0/90000 (0%)]	Loss: -16.4954	Cost: 21.86s
Train Epoch: 2110 [20480/90000 (23%)]	Loss: -22.7859	Cost: 5.99s
Train Epoch: 2110 [40960/90000 (45%)]	Loss: -22.3742	Cost: 6.89s
Train Epoch: 2110 [61440/90000 (68%)]	Loss: -22.8057	Cost: 5.78s
Train Epoch: 2110 [81920/90000 (91%)]	Loss: -22.9711	Cost: 5.61s
Train Epoch: 2110 	Average Loss: -22.4048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8786

Learning rate: 0.0001997803781079689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2111 [0/90000 (0%)]	Loss: -16.5347	Cost: 21.75s
Train Epoch: 2111 [20480/90000 (23%)]	Loss: -23.0919	Cost: 5.99s
Train Epoch: 2111 [40960/90000 (45%)]	Loss: -22.6713	Cost: 7.07s
Train Epoch: 2111 [61440/90000 (68%)]	Loss: -22.9816	Cost: 5.84s
Train Epoch: 2111 [81920/90000 (91%)]	Loss: -23.0678	Cost: 5.71s
Train Epoch: 2111 	Average Loss: -22.4741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9304

Learning rate: 0.00019978016996255197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2112 [0/90000 (0%)]	Loss: -16.0965	Cost: 22.13s
Train Epoch: 2112 [20480/90000 (23%)]	Loss: -23.1671	Cost: 6.00s
Train Epoch: 2112 [40960/90000 (45%)]	Loss: -22.7055	Cost: 6.89s
Train Epoch: 2112 [61440/90000 (68%)]	Loss: -23.0201	Cost: 5.88s
Train Epoch: 2112 [81920/90000 (91%)]	Loss: -23.0064	Cost: 5.64s
Train Epoch: 2112 	Average Loss: -22.4701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8972

Learning rate: 0.000199779961718656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2113 [0/90000 (0%)]	Loss: -15.8216	Cost: 21.83s
Train Epoch: 2113 [20480/90000 (23%)]	Loss: -23.0965	Cost: 6.01s
Train Epoch: 2113 [40960/90000 (45%)]	Loss: -22.4689	Cost: 6.86s
Train Epoch: 2113 [61440/90000 (68%)]	Loss: -22.6272	Cost: 5.87s
Train Epoch: 2113 [81920/90000 (91%)]	Loss: -23.0027	Cost: 5.87s
Train Epoch: 2113 	Average Loss: -22.4193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8976

Learning rate: 0.0001997797533762811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2114 [0/90000 (0%)]	Loss: -15.0933	Cost: 21.71s
Train Epoch: 2114 [20480/90000 (23%)]	Loss: -22.8797	Cost: 6.00s
Train Epoch: 2114 [40960/90000 (45%)]	Loss: -22.5800	Cost: 6.55s
Train Epoch: 2114 [61440/90000 (68%)]	Loss: -22.9789	Cost: 5.84s
Train Epoch: 2114 [81920/90000 (91%)]	Loss: -22.9115	Cost: 5.84s
Train Epoch: 2114 	Average Loss: -22.3776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8375

Learning rate: 0.00019977954493542756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2115 [0/90000 (0%)]	Loss: -16.1563	Cost: 22.29s
Train Epoch: 2115 [20480/90000 (23%)]	Loss: -22.9914	Cost: 6.01s
Train Epoch: 2115 [40960/90000 (45%)]	Loss: -22.6582	Cost: 7.31s
Train Epoch: 2115 [61440/90000 (68%)]	Loss: -23.0311	Cost: 5.72s
Train Epoch: 2115 [81920/90000 (91%)]	Loss: -23.4026	Cost: 6.07s
Train Epoch: 2115 	Average Loss: -22.5039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0087

Saving model as e2115_model.pt & e2115_waveforms_supplementary.hdf5
Learning rate: 0.00019977933639609555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2116 [0/90000 (0%)]	Loss: -16.0134	Cost: 22.08s
Train Epoch: 2116 [20480/90000 (23%)]	Loss: -23.1670	Cost: 6.01s
Train Epoch: 2116 [40960/90000 (45%)]	Loss: -22.5412	Cost: 7.24s
Train Epoch: 2116 [61440/90000 (68%)]	Loss: -22.9629	Cost: 5.75s
Train Epoch: 2116 [81920/90000 (91%)]	Loss: -23.0777	Cost: 6.03s
Train Epoch: 2116 	Average Loss: -22.5075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0654

Saving model as e2116_model.pt & e2116_waveforms_supplementary.hdf5
Learning rate: 0.0001997791277582853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2117 [0/90000 (0%)]	Loss: -16.0838	Cost: 21.87s
Train Epoch: 2117 [20480/90000 (23%)]	Loss: -22.8246	Cost: 5.97s
Train Epoch: 2117 [40960/90000 (45%)]	Loss: -22.4273	Cost: 6.86s
Train Epoch: 2117 [61440/90000 (68%)]	Loss: -22.5624	Cost: 5.86s
Train Epoch: 2117 [81920/90000 (91%)]	Loss: -22.7205	Cost: 5.73s
Train Epoch: 2117 	Average Loss: -22.1547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5785

Learning rate: 0.00019977891902199697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2118 [0/90000 (0%)]	Loss: -15.4884	Cost: 21.46s
Train Epoch: 2118 [20480/90000 (23%)]	Loss: -22.7866	Cost: 5.99s
Train Epoch: 2118 [40960/90000 (45%)]	Loss: -22.2427	Cost: 6.90s
Train Epoch: 2118 [61440/90000 (68%)]	Loss: -22.8890	Cost: 5.81s
Train Epoch: 2118 [81920/90000 (91%)]	Loss: -23.1127	Cost: 5.77s
Train Epoch: 2118 	Average Loss: -22.2868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7130

Learning rate: 0.0001997787101872308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2119 [0/90000 (0%)]	Loss: -16.9811	Cost: 22.04s
Train Epoch: 2119 [20480/90000 (23%)]	Loss: -22.9273	Cost: 5.93s
Train Epoch: 2119 [40960/90000 (45%)]	Loss: -22.4279	Cost: 6.76s
Train Epoch: 2119 [61440/90000 (68%)]	Loss: -22.9760	Cost: 5.72s
Train Epoch: 2119 [81920/90000 (91%)]	Loss: -23.0880	Cost: 6.18s
Train Epoch: 2119 	Average Loss: -22.5101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1325

Saving model as e2119_model.pt & e2119_waveforms_supplementary.hdf5
Learning rate: 0.000199778501253987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2120 [0/90000 (0%)]	Loss: -16.1902	Cost: 21.33s
Train Epoch: 2120 [20480/90000 (23%)]	Loss: -23.1234	Cost: 5.93s
Train Epoch: 2120 [40960/90000 (45%)]	Loss: -22.4713	Cost: 7.21s
Train Epoch: 2120 [61440/90000 (68%)]	Loss: -23.0294	Cost: 5.79s
Train Epoch: 2120 [81920/90000 (91%)]	Loss: -23.1372	Cost: 6.03s
Train Epoch: 2120 	Average Loss: -22.4484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9364

Learning rate: 0.00019977829222226576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2121 [0/90000 (0%)]	Loss: -16.7879	Cost: 21.54s
Train Epoch: 2121 [20480/90000 (23%)]	Loss: -23.1304	Cost: 6.02s
Train Epoch: 2121 [40960/90000 (45%)]	Loss: -22.5712	Cost: 6.61s
Train Epoch: 2121 [61440/90000 (68%)]	Loss: -23.1548	Cost: 5.79s
Train Epoch: 2121 [81920/90000 (91%)]	Loss: -23.0375	Cost: 6.22s
Train Epoch: 2121 	Average Loss: -22.5518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7000

Learning rate: 0.00019977808309206728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2122 [0/90000 (0%)]	Loss: -16.4574	Cost: 22.32s
Train Epoch: 2122 [20480/90000 (23%)]	Loss: -23.1599	Cost: 6.03s
Train Epoch: 2122 [40960/90000 (45%)]	Loss: -22.6879	Cost: 6.67s
Train Epoch: 2122 [61440/90000 (68%)]	Loss: -23.1216	Cost: 5.86s
Train Epoch: 2122 [81920/90000 (91%)]	Loss: -22.9936	Cost: 5.63s
Train Epoch: 2122 	Average Loss: -22.4845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7678

Learning rate: 0.00019977787386339177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2123 [0/90000 (0%)]	Loss: -15.4002	Cost: 21.90s
Train Epoch: 2123 [20480/90000 (23%)]	Loss: -22.7986	Cost: 5.98s
Train Epoch: 2123 [40960/90000 (45%)]	Loss: -22.4746	Cost: 6.81s
Train Epoch: 2123 [61440/90000 (68%)]	Loss: -22.8735	Cost: 5.80s
Train Epoch: 2123 [81920/90000 (91%)]	Loss: -22.6456	Cost: 6.06s
Train Epoch: 2123 	Average Loss: -22.2274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7654

Learning rate: 0.00019977766453623948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2124 [0/90000 (0%)]	Loss: -15.0304	Cost: 21.81s
Train Epoch: 2124 [20480/90000 (23%)]	Loss: -22.7209	Cost: 5.98s
Train Epoch: 2124 [40960/90000 (45%)]	Loss: -22.3877	Cost: 6.79s
Train Epoch: 2124 [61440/90000 (68%)]	Loss: -22.8135	Cost: 5.90s
Train Epoch: 2124 [81920/90000 (91%)]	Loss: -23.0299	Cost: 5.64s
Train Epoch: 2124 	Average Loss: -22.2160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9530

Learning rate: 0.00019977745511061054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2125 [0/90000 (0%)]	Loss: -15.4389	Cost: 21.91s
Train Epoch: 2125 [20480/90000 (23%)]	Loss: -22.9569	Cost: 6.04s
Train Epoch: 2125 [40960/90000 (45%)]	Loss: -22.4242	Cost: 7.25s
Train Epoch: 2125 [61440/90000 (68%)]	Loss: -22.9557	Cost: 5.76s
Train Epoch: 2125 [81920/90000 (91%)]	Loss: -22.9131	Cost: 5.64s
Train Epoch: 2125 	Average Loss: -22.3517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0520

Learning rate: 0.00019977724558650523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2126 [0/90000 (0%)]	Loss: -15.8105	Cost: 21.92s
Train Epoch: 2126 [20480/90000 (23%)]	Loss: -23.1545	Cost: 5.97s
Train Epoch: 2126 [40960/90000 (45%)]	Loss: -22.7134	Cost: 6.67s
Train Epoch: 2126 [61440/90000 (68%)]	Loss: -22.9894	Cost: 5.81s
Train Epoch: 2126 [81920/90000 (91%)]	Loss: -23.1320	Cost: 6.04s
Train Epoch: 2126 	Average Loss: -22.5158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8695

Learning rate: 0.0001997770359639237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2127 [0/90000 (0%)]	Loss: -16.0169	Cost: 22.13s
Train Epoch: 2127 [20480/90000 (23%)]	Loss: -23.2398	Cost: 5.99s
Train Epoch: 2127 [40960/90000 (45%)]	Loss: -22.6430	Cost: 7.22s
Train Epoch: 2127 [61440/90000 (68%)]	Loss: -22.9232	Cost: 5.78s
Train Epoch: 2127 [81920/90000 (91%)]	Loss: -22.8486	Cost: 5.76s
Train Epoch: 2127 	Average Loss: -22.4737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5954

Learning rate: 0.0001997768262428662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2128 [0/90000 (0%)]	Loss: -14.9244	Cost: 21.83s
Train Epoch: 2128 [20480/90000 (23%)]	Loss: -22.8165	Cost: 6.00s
Train Epoch: 2128 [40960/90000 (45%)]	Loss: -22.5011	Cost: 6.84s
Train Epoch: 2128 [61440/90000 (68%)]	Loss: -23.1404	Cost: 5.95s
Train Epoch: 2128 [81920/90000 (91%)]	Loss: -23.1836	Cost: 6.10s
Train Epoch: 2128 	Average Loss: -22.3949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0408

Learning rate: 0.00019977661642333296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2129 [0/90000 (0%)]	Loss: -16.1320	Cost: 21.63s
Train Epoch: 2129 [20480/90000 (23%)]	Loss: -23.1518	Cost: 6.02s
Train Epoch: 2129 [40960/90000 (45%)]	Loss: -21.2344	Cost: 6.99s
Train Epoch: 2129 [61440/90000 (68%)]	Loss: -21.4219	Cost: 5.82s
Train Epoch: 2129 [81920/90000 (91%)]	Loss: -21.7464	Cost: 5.62s
Train Epoch: 2129 	Average Loss: -21.5885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0190

Learning rate: 0.0001997764065053241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2130 [0/90000 (0%)]	Loss: -15.2102	Cost: 21.67s
Train Epoch: 2130 [20480/90000 (23%)]	Loss: -22.1731	Cost: 5.93s
Train Epoch: 2130 [40960/90000 (45%)]	Loss: -21.9875	Cost: 6.64s
Train Epoch: 2130 [61440/90000 (68%)]	Loss: -22.4737	Cost: 5.97s
Train Epoch: 2130 [81920/90000 (91%)]	Loss: -22.8713	Cost: 5.80s
Train Epoch: 2130 	Average Loss: -21.8676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7447

Learning rate: 0.00019977619648883988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2131 [0/90000 (0%)]	Loss: -15.2605	Cost: 21.82s
Train Epoch: 2131 [20480/90000 (23%)]	Loss: -22.9385	Cost: 5.99s
Train Epoch: 2131 [40960/90000 (45%)]	Loss: -22.2867	Cost: 6.72s
Train Epoch: 2131 [61440/90000 (68%)]	Loss: -22.9146	Cost: 5.86s
Train Epoch: 2131 [81920/90000 (91%)]	Loss: -23.0835	Cost: 5.71s
Train Epoch: 2131 	Average Loss: -22.3211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8394

Learning rate: 0.00019977598637388051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2132 [0/90000 (0%)]	Loss: -16.1891	Cost: 21.84s
Train Epoch: 2132 [20480/90000 (23%)]	Loss: -22.9482	Cost: 6.06s
Train Epoch: 2132 [40960/90000 (45%)]	Loss: -22.5335	Cost: 6.68s
Train Epoch: 2132 [61440/90000 (68%)]	Loss: -23.0750	Cost: 5.92s
Train Epoch: 2132 [81920/90000 (91%)]	Loss: -23.1375	Cost: 5.63s
Train Epoch: 2132 	Average Loss: -22.5262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9708

Learning rate: 0.0001997757761604462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2133 [0/90000 (0%)]	Loss: -15.7073	Cost: 21.90s
Train Epoch: 2133 [20480/90000 (23%)]	Loss: -23.1043	Cost: 6.00s
Train Epoch: 2133 [40960/90000 (45%)]	Loss: -22.6494	Cost: 7.60s
Train Epoch: 2133 [61440/90000 (68%)]	Loss: -23.0600	Cost: 5.74s
Train Epoch: 2133 [81920/90000 (91%)]	Loss: -22.9205	Cost: 5.84s
Train Epoch: 2133 	Average Loss: -22.4907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7404

Learning rate: 0.00019977556584853712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2134 [0/90000 (0%)]	Loss: -16.5483	Cost: 21.91s
Train Epoch: 2134 [20480/90000 (23%)]	Loss: -23.1254	Cost: 6.00s
Train Epoch: 2134 [40960/90000 (45%)]	Loss: -22.4610	Cost: 6.81s
Train Epoch: 2134 [61440/90000 (68%)]	Loss: -22.9227	Cost: 5.79s
Train Epoch: 2134 [81920/90000 (91%)]	Loss: -23.2031	Cost: 5.73s
Train Epoch: 2134 	Average Loss: -22.4431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8852

Learning rate: 0.0001997753554381535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2135 [0/90000 (0%)]	Loss: -15.8777	Cost: 22.32s
Train Epoch: 2135 [20480/90000 (23%)]	Loss: -22.9554	Cost: 5.97s
Train Epoch: 2135 [40960/90000 (45%)]	Loss: -22.2920	Cost: 6.81s
Train Epoch: 2135 [61440/90000 (68%)]	Loss: -22.8973	Cost: 5.81s
Train Epoch: 2135 [81920/90000 (91%)]	Loss: -22.8891	Cost: 5.82s
Train Epoch: 2135 	Average Loss: -22.3247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8496

Learning rate: 0.0001997751449292956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2136 [0/90000 (0%)]	Loss: -15.6629	Cost: 21.89s
Train Epoch: 2136 [20480/90000 (23%)]	Loss: -23.0593	Cost: 5.98s
Train Epoch: 2136 [40960/90000 (45%)]	Loss: -22.8091	Cost: 7.30s
Train Epoch: 2136 [61440/90000 (68%)]	Loss: -23.0121	Cost: 5.73s
Train Epoch: 2136 [81920/90000 (91%)]	Loss: -23.1702	Cost: 6.08s
Train Epoch: 2136 	Average Loss: -22.4974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9944

Learning rate: 0.00019977493432196355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2137 [0/90000 (0%)]	Loss: -16.1361	Cost: 21.57s
Train Epoch: 2137 [20480/90000 (23%)]	Loss: -23.2162	Cost: 5.98s
Train Epoch: 2137 [40960/90000 (45%)]	Loss: -22.6888	Cost: 6.76s
Train Epoch: 2137 [61440/90000 (68%)]	Loss: -23.1256	Cost: 5.80s
Train Epoch: 2137 [81920/90000 (91%)]	Loss: -23.1316	Cost: 5.60s
Train Epoch: 2137 	Average Loss: -22.5867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0302

Learning rate: 0.00019977472361615756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2138 [0/90000 (0%)]	Loss: -16.4267	Cost: 21.65s
Train Epoch: 2138 [20480/90000 (23%)]	Loss: -23.1326	Cost: 6.00s
Train Epoch: 2138 [40960/90000 (45%)]	Loss: -22.2976	Cost: 6.64s
Train Epoch: 2138 [61440/90000 (68%)]	Loss: -23.0340	Cost: 5.80s
Train Epoch: 2138 [81920/90000 (91%)]	Loss: -23.0525	Cost: 5.72s
Train Epoch: 2138 	Average Loss: -22.4051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0329

Learning rate: 0.00019977451281187787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2139 [0/90000 (0%)]	Loss: -16.1715	Cost: 21.77s
Train Epoch: 2139 [20480/90000 (23%)]	Loss: -23.0900	Cost: 5.98s
Train Epoch: 2139 [40960/90000 (45%)]	Loss: -22.3797	Cost: 7.79s
Train Epoch: 2139 [61440/90000 (68%)]	Loss: -23.0153	Cost: 5.72s
Train Epoch: 2139 [81920/90000 (91%)]	Loss: -23.1532	Cost: 5.94s
Train Epoch: 2139 	Average Loss: -22.4814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8223

Learning rate: 0.00019977430190912468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2140 [0/90000 (0%)]	Loss: -15.9854	Cost: 21.56s
Train Epoch: 2140 [20480/90000 (23%)]	Loss: -23.1125	Cost: 6.00s
Train Epoch: 2140 [40960/90000 (45%)]	Loss: -22.6478	Cost: 6.94s
Train Epoch: 2140 [61440/90000 (68%)]	Loss: -23.2164	Cost: 5.78s
Train Epoch: 2140 [81920/90000 (91%)]	Loss: -22.9547	Cost: 6.23s
Train Epoch: 2140 	Average Loss: -22.5141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0266

Learning rate: 0.00019977409090789824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2141 [0/90000 (0%)]	Loss: -16.2509	Cost: 21.05s
Train Epoch: 2141 [20480/90000 (23%)]	Loss: -23.3948	Cost: 6.05s
Train Epoch: 2141 [40960/90000 (45%)]	Loss: -22.3895	Cost: 6.46s
Train Epoch: 2141 [61440/90000 (68%)]	Loss: -22.7699	Cost: 5.84s
Train Epoch: 2141 [81920/90000 (91%)]	Loss: -22.8775	Cost: 6.44s
Train Epoch: 2141 	Average Loss: -22.4086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9062

Learning rate: 0.0001997738798081987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2142 [0/90000 (0%)]	Loss: -16.3509	Cost: 21.67s
Train Epoch: 2142 [20480/90000 (23%)]	Loss: -23.1650	Cost: 5.99s
Train Epoch: 2142 [40960/90000 (45%)]	Loss: -22.4349	Cost: 6.84s
Train Epoch: 2142 [61440/90000 (68%)]	Loss: -22.6920	Cost: 5.76s
Train Epoch: 2142 [81920/90000 (91%)]	Loss: -23.0176	Cost: 6.22s
Train Epoch: 2142 	Average Loss: -22.4904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8885

Learning rate: 0.00019977366861002627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2143 [0/90000 (0%)]	Loss: -15.7902	Cost: 22.22s
Train Epoch: 2143 [20480/90000 (23%)]	Loss: -23.0259	Cost: 5.95s
Train Epoch: 2143 [40960/90000 (45%)]	Loss: -22.6933	Cost: 7.40s
Train Epoch: 2143 [61440/90000 (68%)]	Loss: -23.3378	Cost: 5.87s
Train Epoch: 2143 [81920/90000 (91%)]	Loss: -23.2358	Cost: 5.71s
Train Epoch: 2143 	Average Loss: -22.5688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9004

Learning rate: 0.0001997734573133812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2144 [0/90000 (0%)]	Loss: -16.2855	Cost: 23.20s
Train Epoch: 2144 [20480/90000 (23%)]	Loss: -23.2701	Cost: 5.96s
Train Epoch: 2144 [40960/90000 (45%)]	Loss: -22.8921	Cost: 6.50s
Train Epoch: 2144 [61440/90000 (68%)]	Loss: -23.2102	Cost: 5.88s
Train Epoch: 2144 [81920/90000 (91%)]	Loss: -23.2007	Cost: 5.86s
Train Epoch: 2144 	Average Loss: -22.7038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0671

Learning rate: 0.00019977324591826366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2145 [0/90000 (0%)]	Loss: -15.6150	Cost: 21.33s
Train Epoch: 2145 [20480/90000 (23%)]	Loss: -23.2175	Cost: 6.03s
Train Epoch: 2145 [40960/90000 (45%)]	Loss: -22.4965	Cost: 7.60s
Train Epoch: 2145 [61440/90000 (68%)]	Loss: -23.0200	Cost: 6.01s
Train Epoch: 2145 [81920/90000 (91%)]	Loss: -22.9496	Cost: 5.64s
Train Epoch: 2145 	Average Loss: -22.4939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9372

Learning rate: 0.00019977303442467387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2146 [0/90000 (0%)]	Loss: -15.7853	Cost: 21.80s
Train Epoch: 2146 [20480/90000 (23%)]	Loss: -23.2331	Cost: 6.03s
Train Epoch: 2146 [40960/90000 (45%)]	Loss: -22.7745	Cost: 6.70s
Train Epoch: 2146 [61440/90000 (68%)]	Loss: -23.1444	Cost: 5.84s
Train Epoch: 2146 [81920/90000 (91%)]	Loss: -23.1812	Cost: 6.28s
Train Epoch: 2146 	Average Loss: -22.5826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0427

Learning rate: 0.00019977282283261208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2147 [0/90000 (0%)]	Loss: -15.7770	Cost: 21.58s
Train Epoch: 2147 [20480/90000 (23%)]	Loss: -22.8961	Cost: 6.01s
Train Epoch: 2147 [40960/90000 (45%)]	Loss: -22.6568	Cost: 6.64s
Train Epoch: 2147 [61440/90000 (68%)]	Loss: -22.9143	Cost: 5.91s
Train Epoch: 2147 [81920/90000 (91%)]	Loss: -23.0757	Cost: 5.61s
Train Epoch: 2147 	Average Loss: -22.4903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9415

Learning rate: 0.0001997726111420784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2148 [0/90000 (0%)]	Loss: -16.0678	Cost: 24.05s
Train Epoch: 2148 [20480/90000 (23%)]	Loss: -23.0716	Cost: 5.93s
Train Epoch: 2148 [40960/90000 (45%)]	Loss: -22.8755	Cost: 6.60s
Train Epoch: 2148 [61440/90000 (68%)]	Loss: -23.1573	Cost: 5.83s
Train Epoch: 2148 [81920/90000 (91%)]	Loss: -23.2806	Cost: 5.78s
Train Epoch: 2148 	Average Loss: -22.5974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0510

Learning rate: 0.00019977239935307312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2149 [0/90000 (0%)]	Loss: -15.7965	Cost: 21.97s
Train Epoch: 2149 [20480/90000 (23%)]	Loss: -23.1451	Cost: 6.02s
Train Epoch: 2149 [40960/90000 (45%)]	Loss: -22.8411	Cost: 6.65s
Train Epoch: 2149 [61440/90000 (68%)]	Loss: -23.1303	Cost: 5.84s
Train Epoch: 2149 [81920/90000 (91%)]	Loss: -23.1611	Cost: 5.76s
Train Epoch: 2149 	Average Loss: -22.6608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0531

Learning rate: 0.00019977218746559643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2150 [0/90000 (0%)]	Loss: -16.2623	Cost: 21.46s
Train Epoch: 2150 [20480/90000 (23%)]	Loss: -23.1526	Cost: 5.95s
Train Epoch: 2150 [40960/90000 (45%)]	Loss: -22.3591	Cost: 6.97s
Train Epoch: 2150 [61440/90000 (68%)]	Loss: -22.9045	Cost: 5.91s
Train Epoch: 2150 [81920/90000 (91%)]	Loss: -23.0958	Cost: 5.63s
Train Epoch: 2150 	Average Loss: -22.4884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9982

Learning rate: 0.0001997719754796486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2151 [0/90000 (0%)]	Loss: -15.8315	Cost: 21.59s
Train Epoch: 2151 [20480/90000 (23%)]	Loss: -23.1371	Cost: 6.01s
Train Epoch: 2151 [40960/90000 (45%)]	Loss: -22.6498	Cost: 6.73s
Train Epoch: 2151 [61440/90000 (68%)]	Loss: -22.9574	Cost: 6.01s
Train Epoch: 2151 [81920/90000 (91%)]	Loss: -23.0767	Cost: 5.66s
Train Epoch: 2151 	Average Loss: -22.5454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9516

Learning rate: 0.00019977176339522972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2152 [0/90000 (0%)]	Loss: -16.5202	Cost: 21.95s
Train Epoch: 2152 [20480/90000 (23%)]	Loss: -23.2304	Cost: 6.02s
Train Epoch: 2152 [40960/90000 (45%)]	Loss: -22.6680	Cost: 7.50s
Train Epoch: 2152 [61440/90000 (68%)]	Loss: -22.9869	Cost: 5.90s
Train Epoch: 2152 [81920/90000 (91%)]	Loss: -23.1616	Cost: 5.92s
Train Epoch: 2152 	Average Loss: -22.5570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8494

Learning rate: 0.00019977155121234005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2153 [0/90000 (0%)]	Loss: -16.0968	Cost: 21.98s
Train Epoch: 2153 [20480/90000 (23%)]	Loss: -23.3443	Cost: 5.98s
Train Epoch: 2153 [40960/90000 (45%)]	Loss: -22.7987	Cost: 6.70s
Train Epoch: 2153 [61440/90000 (68%)]	Loss: -23.2840	Cost: 5.82s
Train Epoch: 2153 [81920/90000 (91%)]	Loss: -23.2513	Cost: 5.62s
Train Epoch: 2153 	Average Loss: -22.7377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0572

Learning rate: 0.00019977133893097983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2154 [0/90000 (0%)]	Loss: -15.9854	Cost: 21.28s
Train Epoch: 2154 [20480/90000 (23%)]	Loss: -23.3289	Cost: 6.05s
Train Epoch: 2154 [40960/90000 (45%)]	Loss: -22.6023	Cost: 7.34s
Train Epoch: 2154 [61440/90000 (68%)]	Loss: -23.2361	Cost: 5.76s
Train Epoch: 2154 [81920/90000 (91%)]	Loss: -23.1568	Cost: 6.00s
Train Epoch: 2154 	Average Loss: -22.6072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9644

Learning rate: 0.00019977112655114923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2155 [0/90000 (0%)]	Loss: -16.0836	Cost: 21.78s
Train Epoch: 2155 [20480/90000 (23%)]	Loss: -23.0562	Cost: 5.95s
Train Epoch: 2155 [40960/90000 (45%)]	Loss: -22.6462	Cost: 7.15s
Train Epoch: 2155 [61440/90000 (68%)]	Loss: -23.0911	Cost: 5.76s
Train Epoch: 2155 [81920/90000 (91%)]	Loss: -23.1912	Cost: 6.08s
Train Epoch: 2155 	Average Loss: -22.5866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9188

Learning rate: 0.00019977091407284847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2156 [0/90000 (0%)]	Loss: -16.4987	Cost: 21.62s
Train Epoch: 2156 [20480/90000 (23%)]	Loss: -23.0028	Cost: 5.93s
Train Epoch: 2156 [40960/90000 (45%)]	Loss: -22.8820	Cost: 7.76s
Train Epoch: 2156 [61440/90000 (68%)]	Loss: -23.0582	Cost: 5.68s
Train Epoch: 2156 [81920/90000 (91%)]	Loss: -23.1675	Cost: 6.35s
Train Epoch: 2156 	Average Loss: -22.6212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8834

Learning rate: 0.00019977070149607777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2157 [0/90000 (0%)]	Loss: -16.0864	Cost: 21.82s
Train Epoch: 2157 [20480/90000 (23%)]	Loss: -23.3338	Cost: 5.97s
Train Epoch: 2157 [40960/90000 (45%)]	Loss: -22.7558	Cost: 6.82s
Train Epoch: 2157 [61440/90000 (68%)]	Loss: -23.1614	Cost: 5.77s
Train Epoch: 2157 [81920/90000 (91%)]	Loss: -23.2305	Cost: 5.95s
Train Epoch: 2157 	Average Loss: -22.6157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9742

Learning rate: 0.00019977048882083734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2158 [0/90000 (0%)]	Loss: -15.7331	Cost: 21.81s
Train Epoch: 2158 [20480/90000 (23%)]	Loss: -23.3015	Cost: 5.98s
Train Epoch: 2158 [40960/90000 (45%)]	Loss: -22.6118	Cost: 6.36s
Train Epoch: 2158 [61440/90000 (68%)]	Loss: -22.9519	Cost: 5.83s
Train Epoch: 2158 [81920/90000 (91%)]	Loss: -23.2322	Cost: 5.62s
Train Epoch: 2158 	Average Loss: -22.6056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9439

Learning rate: 0.00019977027604712742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2159 [0/90000 (0%)]	Loss: -16.3688	Cost: 21.97s
Train Epoch: 2159 [20480/90000 (23%)]	Loss: -23.5214	Cost: 5.97s
Train Epoch: 2159 [40960/90000 (45%)]	Loss: -22.9474	Cost: 6.74s
Train Epoch: 2159 [61440/90000 (68%)]	Loss: -23.2724	Cost: 5.78s
Train Epoch: 2159 [81920/90000 (91%)]	Loss: -23.2256	Cost: 5.68s
Train Epoch: 2159 	Average Loss: -22.7933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1662

Saving model as e2159_model.pt & e2159_waveforms_supplementary.hdf5
Learning rate: 0.00019977006317494815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2160 [0/90000 (0%)]	Loss: -16.0647	Cost: 21.78s
Train Epoch: 2160 [20480/90000 (23%)]	Loss: -23.3529	Cost: 5.99s
Train Epoch: 2160 [40960/90000 (45%)]	Loss: -22.8183	Cost: 6.49s
Train Epoch: 2160 [61440/90000 (68%)]	Loss: -23.2318	Cost: 5.96s
Train Epoch: 2160 [81920/90000 (91%)]	Loss: -23.2822	Cost: 5.70s
Train Epoch: 2160 	Average Loss: -22.6622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1562

Learning rate: 0.00019976985020429974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2161 [0/90000 (0%)]	Loss: -15.6487	Cost: 22.04s
Train Epoch: 2161 [20480/90000 (23%)]	Loss: -23.0665	Cost: 5.97s
Train Epoch: 2161 [40960/90000 (45%)]	Loss: -22.8014	Cost: 6.72s
Train Epoch: 2161 [61440/90000 (68%)]	Loss: -23.0021	Cost: 5.84s
Train Epoch: 2161 [81920/90000 (91%)]	Loss: -22.9875	Cost: 5.93s
Train Epoch: 2161 	Average Loss: -22.5598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9486

Learning rate: 0.00019976963713518245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2162 [0/90000 (0%)]	Loss: -16.6789	Cost: 21.74s
Train Epoch: 2162 [20480/90000 (23%)]	Loss: -23.4351	Cost: 6.01s
Train Epoch: 2162 [40960/90000 (45%)]	Loss: -22.9052	Cost: 7.58s
Train Epoch: 2162 [61440/90000 (68%)]	Loss: -23.2421	Cost: 5.88s
Train Epoch: 2162 [81920/90000 (91%)]	Loss: -23.2927	Cost: 6.16s
Train Epoch: 2162 	Average Loss: -22.7969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1547

Learning rate: 0.0001997694239675965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2163 [0/90000 (0%)]	Loss: -16.0453	Cost: 21.82s
Train Epoch: 2163 [20480/90000 (23%)]	Loss: -23.3806	Cost: 5.98s
Train Epoch: 2163 [40960/90000 (45%)]	Loss: -22.8365	Cost: 7.13s
Train Epoch: 2163 [61440/90000 (68%)]	Loss: -23.2275	Cost: 5.84s
Train Epoch: 2163 [81920/90000 (91%)]	Loss: -23.2338	Cost: 5.88s
Train Epoch: 2163 	Average Loss: -22.7526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9622

Learning rate: 0.00019976921070154207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2164 [0/90000 (0%)]	Loss: -16.3616	Cost: 21.59s
Train Epoch: 2164 [20480/90000 (23%)]	Loss: -23.4796	Cost: 6.01s
Train Epoch: 2164 [40960/90000 (45%)]	Loss: -22.7570	Cost: 7.23s
Train Epoch: 2164 [61440/90000 (68%)]	Loss: -23.0615	Cost: 5.78s
Train Epoch: 2164 [81920/90000 (91%)]	Loss: -23.1395	Cost: 6.38s
Train Epoch: 2164 	Average Loss: -22.6734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0946

Learning rate: 0.00019976899733701936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2165 [0/90000 (0%)]	Loss: -15.0228	Cost: 22.07s
Train Epoch: 2165 [20480/90000 (23%)]	Loss: -23.1916	Cost: 5.98s
Train Epoch: 2165 [40960/90000 (45%)]	Loss: -22.7730	Cost: 6.77s
Train Epoch: 2165 [61440/90000 (68%)]	Loss: -23.1243	Cost: 5.77s
Train Epoch: 2165 [81920/90000 (91%)]	Loss: -23.2837	Cost: 5.86s
Train Epoch: 2165 	Average Loss: -22.6167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1549

Learning rate: 0.0001997687838740286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2166 [0/90000 (0%)]	Loss: -16.3638	Cost: 22.41s
Train Epoch: 2166 [20480/90000 (23%)]	Loss: -23.4335	Cost: 5.94s
Train Epoch: 2166 [40960/90000 (45%)]	Loss: -22.8893	Cost: 6.75s
Train Epoch: 2166 [61440/90000 (68%)]	Loss: -22.9909	Cost: 5.92s
Train Epoch: 2166 [81920/90000 (91%)]	Loss: -23.0664	Cost: 5.99s
Train Epoch: 2166 	Average Loss: -22.6184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1626

Learning rate: 0.00019976857031257003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2167 [0/90000 (0%)]	Loss: -15.7173	Cost: 21.77s
Train Epoch: 2167 [20480/90000 (23%)]	Loss: -21.9663	Cost: 5.98s
Train Epoch: 2167 [40960/90000 (45%)]	Loss: -21.2612	Cost: 6.92s
Train Epoch: 2167 [61440/90000 (68%)]	Loss: -21.7798	Cost: 5.79s
Train Epoch: 2167 [81920/90000 (91%)]	Loss: -22.0588	Cost: 5.63s
Train Epoch: 2167 	Average Loss: -21.3739
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5322

Learning rate: 0.00019976835665264382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2168 [0/90000 (0%)]	Loss: -14.5847	Cost: 21.75s
Train Epoch: 2168 [20480/90000 (23%)]	Loss: -22.5385	Cost: 6.00s
Train Epoch: 2168 [40960/90000 (45%)]	Loss: -22.2711	Cost: 6.77s
Train Epoch: 2168 [61440/90000 (68%)]	Loss: -22.7151	Cost: 5.78s
Train Epoch: 2168 [81920/90000 (91%)]	Loss: -22.9732	Cost: 5.84s
Train Epoch: 2168 	Average Loss: -22.1314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8175

Learning rate: 0.00019976814289425016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2169 [0/90000 (0%)]	Loss: -16.0872	Cost: 22.21s
Train Epoch: 2169 [20480/90000 (23%)]	Loss: -23.2095	Cost: 5.97s
Train Epoch: 2169 [40960/90000 (45%)]	Loss: -22.6706	Cost: 7.03s
Train Epoch: 2169 [61440/90000 (68%)]	Loss: -23.3798	Cost: 5.87s
Train Epoch: 2169 [81920/90000 (91%)]	Loss: -23.2965	Cost: 5.62s
Train Epoch: 2169 	Average Loss: -22.6453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2955

Saving model as e2169_model.pt & e2169_waveforms_supplementary.hdf5
Learning rate: 0.00019976792903738928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2170 [0/90000 (0%)]	Loss: -16.2919	Cost: 22.36s
Train Epoch: 2170 [20480/90000 (23%)]	Loss: -23.4232	Cost: 6.02s
Train Epoch: 2170 [40960/90000 (45%)]	Loss: -23.0490	Cost: 6.64s
Train Epoch: 2170 [61440/90000 (68%)]	Loss: -23.2597	Cost: 6.15s
Train Epoch: 2170 [81920/90000 (91%)]	Loss: -23.2055	Cost: 5.64s
Train Epoch: 2170 	Average Loss: -22.8219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1035

Learning rate: 0.0001997677150820614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2171 [0/90000 (0%)]	Loss: -16.4766	Cost: 22.19s
Train Epoch: 2171 [20480/90000 (23%)]	Loss: -23.1499	Cost: 5.99s
Train Epoch: 2171 [40960/90000 (45%)]	Loss: -22.8471	Cost: 6.67s
Train Epoch: 2171 [61440/90000 (68%)]	Loss: -23.1981	Cost: 5.79s
Train Epoch: 2171 [81920/90000 (91%)]	Loss: -23.2350	Cost: 5.74s
Train Epoch: 2171 	Average Loss: -22.7295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0056

Learning rate: 0.00019976750102826675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2172 [0/90000 (0%)]	Loss: -15.3272	Cost: 21.90s
Train Epoch: 2172 [20480/90000 (23%)]	Loss: -23.4092	Cost: 5.99s
Train Epoch: 2172 [40960/90000 (45%)]	Loss: -22.7263	Cost: 7.11s
Train Epoch: 2172 [61440/90000 (68%)]	Loss: -23.3207	Cost: 6.03s
Train Epoch: 2172 [81920/90000 (91%)]	Loss: -23.1923	Cost: 5.63s
Train Epoch: 2172 	Average Loss: -22.6629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1839

Learning rate: 0.0001997672868760055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2173 [0/90000 (0%)]	Loss: -16.3509	Cost: 21.83s
Train Epoch: 2173 [20480/90000 (23%)]	Loss: -23.1841	Cost: 5.99s
Train Epoch: 2173 [40960/90000 (45%)]	Loss: -22.8493	Cost: 7.48s
Train Epoch: 2173 [61440/90000 (68%)]	Loss: -23.2132	Cost: 5.71s
Train Epoch: 2173 [81920/90000 (91%)]	Loss: -23.1480	Cost: 5.64s
Train Epoch: 2173 	Average Loss: -22.6553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0552

Learning rate: 0.00019976707262527794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2174 [0/90000 (0%)]	Loss: -15.8760	Cost: 22.27s
Train Epoch: 2174 [20480/90000 (23%)]	Loss: -23.2542	Cost: 5.98s
Train Epoch: 2174 [40960/90000 (45%)]	Loss: -22.9645	Cost: 6.61s
Train Epoch: 2174 [61440/90000 (68%)]	Loss: -23.2646	Cost: 5.79s
Train Epoch: 2174 [81920/90000 (91%)]	Loss: -23.1525	Cost: 5.91s
Train Epoch: 2174 	Average Loss: -22.7516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1292

Learning rate: 0.0001997668582760842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2175 [0/90000 (0%)]	Loss: -16.3574	Cost: 22.45s
Train Epoch: 2175 [20480/90000 (23%)]	Loss: -23.2220	Cost: 5.96s
Train Epoch: 2175 [40960/90000 (45%)]	Loss: -22.7709	Cost: 7.26s
Train Epoch: 2175 [61440/90000 (68%)]	Loss: -23.0894	Cost: 5.74s
Train Epoch: 2175 [81920/90000 (91%)]	Loss: -23.2717	Cost: 5.96s
Train Epoch: 2175 	Average Loss: -22.7062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2095

Learning rate: 0.0001997666438284245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2176 [0/90000 (0%)]	Loss: -14.6587	Cost: 21.60s
Train Epoch: 2176 [20480/90000 (23%)]	Loss: -23.3042	Cost: 6.00s
Train Epoch: 2176 [40960/90000 (45%)]	Loss: -22.8505	Cost: 7.41s
Train Epoch: 2176 [61440/90000 (68%)]	Loss: -22.9398	Cost: 5.74s
Train Epoch: 2176 [81920/90000 (91%)]	Loss: -23.0669	Cost: 6.34s
Train Epoch: 2176 	Average Loss: -22.6027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2246

Learning rate: 0.00019976642928229912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2177 [0/90000 (0%)]	Loss: -15.3773	Cost: 22.10s
Train Epoch: 2177 [20480/90000 (23%)]	Loss: -23.5265	Cost: 5.98s
Train Epoch: 2177 [40960/90000 (45%)]	Loss: -22.8745	Cost: 6.99s
Train Epoch: 2177 [61440/90000 (68%)]	Loss: -23.3515	Cost: 5.80s
Train Epoch: 2177 [81920/90000 (91%)]	Loss: -23.2738	Cost: 5.78s
Train Epoch: 2177 	Average Loss: -22.6588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2891

Learning rate: 0.00019976621463770817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2178 [0/90000 (0%)]	Loss: -16.9165	Cost: 22.07s
Train Epoch: 2178 [20480/90000 (23%)]	Loss: -23.3374	Cost: 5.99s
Train Epoch: 2178 [40960/90000 (45%)]	Loss: -22.9568	Cost: 6.85s
Train Epoch: 2178 [61440/90000 (68%)]	Loss: -23.2248	Cost: 5.75s
Train Epoch: 2178 [81920/90000 (91%)]	Loss: -23.3395	Cost: 5.96s
Train Epoch: 2178 	Average Loss: -22.7789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3138

Saving model as e2178_model.pt & e2178_waveforms_supplementary.hdf5
Learning rate: 0.00019976599989465194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2179 [0/90000 (0%)]	Loss: -16.4452	Cost: 22.06s
Train Epoch: 2179 [20480/90000 (23%)]	Loss: -23.4735	Cost: 5.96s
Train Epoch: 2179 [40960/90000 (45%)]	Loss: -22.9983	Cost: 6.81s
Train Epoch: 2179 [61440/90000 (68%)]	Loss: -23.2161	Cost: 5.86s
Train Epoch: 2179 [81920/90000 (91%)]	Loss: -23.5979	Cost: 5.72s
Train Epoch: 2179 	Average Loss: -22.9127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1783

Learning rate: 0.0001997657850531306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2180 [0/90000 (0%)]	Loss: -15.7739	Cost: 21.80s
Train Epoch: 2180 [20480/90000 (23%)]	Loss: -23.3733	Cost: 6.15s
Train Epoch: 2180 [40960/90000 (45%)]	Loss: -22.8496	Cost: 6.95s
Train Epoch: 2180 [61440/90000 (68%)]	Loss: -23.1958	Cost: 5.96s
Train Epoch: 2180 [81920/90000 (91%)]	Loss: -23.1573	Cost: 5.76s
Train Epoch: 2180 	Average Loss: -22.7193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0923

Learning rate: 0.00019976557011314438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2181 [0/90000 (0%)]	Loss: -16.3133	Cost: 21.54s
Train Epoch: 2181 [20480/90000 (23%)]	Loss: -23.4261	Cost: 6.02s
Train Epoch: 2181 [40960/90000 (45%)]	Loss: -22.8352	Cost: 6.77s
Train Epoch: 2181 [61440/90000 (68%)]	Loss: -23.2711	Cost: 5.85s
Train Epoch: 2181 [81920/90000 (91%)]	Loss: -23.3385	Cost: 5.64s
Train Epoch: 2181 	Average Loss: -22.7365
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1992

Learning rate: 0.00019976535507469347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2182 [0/90000 (0%)]	Loss: -16.7404	Cost: 21.42s
Train Epoch: 2182 [20480/90000 (23%)]	Loss: -23.1768	Cost: 5.99s
Train Epoch: 2182 [40960/90000 (45%)]	Loss: -22.6614	Cost: 6.63s
Train Epoch: 2182 [61440/90000 (68%)]	Loss: -23.1277	Cost: 5.98s
Train Epoch: 2182 [81920/90000 (91%)]	Loss: -23.2389	Cost: 5.96s
Train Epoch: 2182 	Average Loss: -22.6095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0374

Learning rate: 0.00019976513993777813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2183 [0/90000 (0%)]	Loss: -16.3602	Cost: 21.67s
Train Epoch: 2183 [20480/90000 (23%)]	Loss: -23.4710	Cost: 5.98s
Train Epoch: 2183 [40960/90000 (45%)]	Loss: -22.5297	Cost: 6.75s
Train Epoch: 2183 [61440/90000 (68%)]	Loss: -23.0195	Cost: 5.85s
Train Epoch: 2183 [81920/90000 (91%)]	Loss: -22.9093	Cost: 5.60s
Train Epoch: 2183 	Average Loss: -22.6000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9190

Learning rate: 0.00019976492470239856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2184 [0/90000 (0%)]	Loss: -15.9626	Cost: 21.21s
Train Epoch: 2184 [20480/90000 (23%)]	Loss: -23.4018	Cost: 6.00s
Train Epoch: 2184 [40960/90000 (45%)]	Loss: -22.7363	Cost: 6.94s
Train Epoch: 2184 [61440/90000 (68%)]	Loss: -23.4013	Cost: 5.83s
Train Epoch: 2184 [81920/90000 (91%)]	Loss: -23.1586	Cost: 6.13s
Train Epoch: 2184 	Average Loss: -22.6551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0534

Learning rate: 0.00019976470936855492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2185 [0/90000 (0%)]	Loss: -16.3581	Cost: 21.98s
Train Epoch: 2185 [20480/90000 (23%)]	Loss: -23.4365	Cost: 5.98s
Train Epoch: 2185 [40960/90000 (45%)]	Loss: -22.5757	Cost: 6.38s
Train Epoch: 2185 [61440/90000 (68%)]	Loss: -23.2457	Cost: 5.88s
Train Epoch: 2185 [81920/90000 (91%)]	Loss: -23.0854	Cost: 5.62s
Train Epoch: 2185 	Average Loss: -22.6837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0872

Learning rate: 0.00019976449393624746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2186 [0/90000 (0%)]	Loss: -16.8513	Cost: 21.47s
Train Epoch: 2186 [20480/90000 (23%)]	Loss: -23.2465	Cost: 6.06s
Train Epoch: 2186 [40960/90000 (45%)]	Loss: -22.9829	Cost: 6.62s
Train Epoch: 2186 [61440/90000 (68%)]	Loss: -23.5645	Cost: 6.09s
Train Epoch: 2186 [81920/90000 (91%)]	Loss: -23.3778	Cost: 5.88s
Train Epoch: 2186 	Average Loss: -22.8615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2038

Learning rate: 0.00019976427840547641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2187 [0/90000 (0%)]	Loss: -16.1967	Cost: 21.54s
Train Epoch: 2187 [20480/90000 (23%)]	Loss: -23.0284	Cost: 6.01s
Train Epoch: 2187 [40960/90000 (45%)]	Loss: -22.6996	Cost: 6.62s
Train Epoch: 2187 [61440/90000 (68%)]	Loss: -23.0480	Cost: 5.84s
Train Epoch: 2187 [81920/90000 (91%)]	Loss: -23.2160	Cost: 5.63s
Train Epoch: 2187 	Average Loss: -22.5878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2936

Learning rate: 0.00019976406277624198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2188 [0/90000 (0%)]	Loss: -16.5855	Cost: 21.85s
Train Epoch: 2188 [20480/90000 (23%)]	Loss: -23.2675	Cost: 5.97s
Train Epoch: 2188 [40960/90000 (45%)]	Loss: -22.8417	Cost: 6.89s
Train Epoch: 2188 [61440/90000 (68%)]	Loss: -23.0265	Cost: 5.79s
Train Epoch: 2188 [81920/90000 (91%)]	Loss: -23.1157	Cost: 6.17s
Train Epoch: 2188 	Average Loss: -22.6737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1565

Learning rate: 0.00019976384704854433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2189 [0/90000 (0%)]	Loss: -17.0352	Cost: 22.28s
Train Epoch: 2189 [20480/90000 (23%)]	Loss: -23.3239	Cost: 6.00s
Train Epoch: 2189 [40960/90000 (45%)]	Loss: -22.6290	Cost: 6.99s
Train Epoch: 2189 [61440/90000 (68%)]	Loss: -23.3428	Cost: 5.77s
Train Epoch: 2189 [81920/90000 (91%)]	Loss: -23.2514	Cost: 6.12s
Train Epoch: 2189 	Average Loss: -22.7833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1794

Learning rate: 0.00019976363122238373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2190 [0/90000 (0%)]	Loss: -16.5157	Cost: 21.84s
Train Epoch: 2190 [20480/90000 (23%)]	Loss: -23.3622	Cost: 6.07s
Train Epoch: 2190 [40960/90000 (45%)]	Loss: -22.8447	Cost: 6.62s
Train Epoch: 2190 [61440/90000 (68%)]	Loss: -23.3914	Cost: 5.84s
Train Epoch: 2190 [81920/90000 (91%)]	Loss: -23.3957	Cost: 5.63s
Train Epoch: 2190 	Average Loss: -22.8228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1719

Learning rate: 0.0001997634152977604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2191 [0/90000 (0%)]	Loss: -16.4039	Cost: 21.68s
Train Epoch: 2191 [20480/90000 (23%)]	Loss: -23.4612	Cost: 5.99s
Train Epoch: 2191 [40960/90000 (45%)]	Loss: -22.9859	Cost: 6.59s
Train Epoch: 2191 [61440/90000 (68%)]	Loss: -23.5776	Cost: 5.78s
Train Epoch: 2191 [81920/90000 (91%)]	Loss: -23.5273	Cost: 6.05s
Train Epoch: 2191 	Average Loss: -22.8098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3094

Learning rate: 0.00019976319927467447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2192 [0/90000 (0%)]	Loss: -16.4144	Cost: 22.05s
Train Epoch: 2192 [20480/90000 (23%)]	Loss: -23.6182	Cost: 5.97s
Train Epoch: 2192 [40960/90000 (45%)]	Loss: -22.9267	Cost: 7.03s
Train Epoch: 2192 [61440/90000 (68%)]	Loss: -23.5203	Cost: 5.77s
Train Epoch: 2192 [81920/90000 (91%)]	Loss: -23.3141	Cost: 5.66s
Train Epoch: 2192 	Average Loss: -22.8809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2007

Learning rate: 0.00019976298315312621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2193 [0/90000 (0%)]	Loss: -16.9297	Cost: 22.80s
Train Epoch: 2193 [20480/90000 (23%)]	Loss: -23.6287	Cost: 5.98s
Train Epoch: 2193 [40960/90000 (45%)]	Loss: -23.0944	Cost: 7.13s
Train Epoch: 2193 [61440/90000 (68%)]	Loss: -23.2602	Cost: 5.79s
Train Epoch: 2193 [81920/90000 (91%)]	Loss: -23.2329	Cost: 5.96s
Train Epoch: 2193 	Average Loss: -22.7854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0577

Learning rate: 0.0001997627669331159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2194 [0/90000 (0%)]	Loss: -15.8322	Cost: 21.54s
Train Epoch: 2194 [20480/90000 (23%)]	Loss: -23.2668	Cost: 6.02s
Train Epoch: 2194 [40960/90000 (45%)]	Loss: -23.0520	Cost: 7.08s
Train Epoch: 2194 [61440/90000 (68%)]	Loss: -23.2565	Cost: 5.79s
Train Epoch: 2194 [81920/90000 (91%)]	Loss: -23.4440	Cost: 5.85s
Train Epoch: 2194 	Average Loss: -22.6981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2753

Learning rate: 0.00019976255061464362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2195 [0/90000 (0%)]	Loss: -15.9757	Cost: 21.28s
Train Epoch: 2195 [20480/90000 (23%)]	Loss: -23.4143	Cost: 6.03s
Train Epoch: 2195 [40960/90000 (45%)]	Loss: -22.9539	Cost: 7.49s
Train Epoch: 2195 [61440/90000 (68%)]	Loss: -23.1387	Cost: 5.75s
Train Epoch: 2195 [81920/90000 (91%)]	Loss: -23.1680	Cost: 5.98s
Train Epoch: 2195 	Average Loss: -22.7315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2810

Learning rate: 0.00019976233419770966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2196 [0/90000 (0%)]	Loss: -16.5148	Cost: 21.49s
Train Epoch: 2196 [20480/90000 (23%)]	Loss: -23.5162	Cost: 6.01s
Train Epoch: 2196 [40960/90000 (45%)]	Loss: -22.7034	Cost: 6.58s
Train Epoch: 2196 [61440/90000 (68%)]	Loss: -23.0791	Cost: 5.81s
Train Epoch: 2196 [81920/90000 (91%)]	Loss: -23.3739	Cost: 5.62s
Train Epoch: 2196 	Average Loss: -22.6386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1902

Learning rate: 0.00019976211768231423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2197 [0/90000 (0%)]	Loss: -16.9626	Cost: 21.39s
Train Epoch: 2197 [20480/90000 (23%)]	Loss: -23.3356	Cost: 5.99s
Train Epoch: 2197 [40960/90000 (45%)]	Loss: -22.8430	Cost: 7.50s
Train Epoch: 2197 [61440/90000 (68%)]	Loss: -23.1845	Cost: 5.91s
Train Epoch: 2197 [81920/90000 (91%)]	Loss: -23.5437	Cost: 5.64s
Train Epoch: 2197 	Average Loss: -22.7496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2269

Learning rate: 0.00019976190106845755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2198 [0/90000 (0%)]	Loss: -15.6646	Cost: 22.01s
Train Epoch: 2198 [20480/90000 (23%)]	Loss: -23.4562	Cost: 6.00s
Train Epoch: 2198 [40960/90000 (45%)]	Loss: -22.8522	Cost: 6.80s
Train Epoch: 2198 [61440/90000 (68%)]	Loss: -23.1700	Cost: 5.81s
Train Epoch: 2198 [81920/90000 (91%)]	Loss: -23.2648	Cost: 5.85s
Train Epoch: 2198 	Average Loss: -22.6771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0096

Learning rate: 0.0001997616843561398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2199 [0/90000 (0%)]	Loss: -16.2306	Cost: 21.59s
Train Epoch: 2199 [20480/90000 (23%)]	Loss: -23.3676	Cost: 5.99s
Train Epoch: 2199 [40960/90000 (45%)]	Loss: -22.7437	Cost: 7.01s
Train Epoch: 2199 [61440/90000 (68%)]	Loss: -23.2597	Cost: 5.79s
Train Epoch: 2199 [81920/90000 (91%)]	Loss: -23.2512	Cost: 6.09s
Train Epoch: 2199 	Average Loss: -22.7239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3983

Saving model as e2199_model.pt & e2199_waveforms_supplementary.hdf5
Learning rate: 0.00019976146754536122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2200 [0/90000 (0%)]	Loss: -16.7662	Cost: 21.81s
Train Epoch: 2200 [20480/90000 (23%)]	Loss: -23.3703	Cost: 5.98s
Train Epoch: 2200 [40960/90000 (45%)]	Loss: -22.6636	Cost: 6.52s
Train Epoch: 2200 [61440/90000 (68%)]	Loss: -23.0151	Cost: 5.78s
Train Epoch: 2200 [81920/90000 (91%)]	Loss: -22.9942	Cost: 6.06s
Train Epoch: 2200 	Average Loss: -22.6857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0489

Learning rate: 0.000199761250636122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2201 [0/90000 (0%)]	Loss: -16.7889	Cost: 22.30s
Train Epoch: 2201 [20480/90000 (23%)]	Loss: -23.1829	Cost: 6.00s
Train Epoch: 2201 [40960/90000 (45%)]	Loss: -22.7889	Cost: 7.03s
Train Epoch: 2201 [61440/90000 (68%)]	Loss: -23.2321	Cost: 5.85s
Train Epoch: 2201 [81920/90000 (91%)]	Loss: -23.2905	Cost: 5.65s
Train Epoch: 2201 	Average Loss: -22.7171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3326

Learning rate: 0.0001997610336284224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2202 [0/90000 (0%)]	Loss: -16.2409	Cost: 21.70s
Train Epoch: 2202 [20480/90000 (23%)]	Loss: -23.2766	Cost: 5.97s
Train Epoch: 2202 [40960/90000 (45%)]	Loss: -22.4779	Cost: 6.40s
Train Epoch: 2202 [61440/90000 (68%)]	Loss: -22.9292	Cost: 5.84s
Train Epoch: 2202 [81920/90000 (91%)]	Loss: -23.2118	Cost: 5.72s
Train Epoch: 2202 	Average Loss: -22.4936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0428

Learning rate: 0.00019976081652226262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2203 [0/90000 (0%)]	Loss: -15.7445	Cost: 21.90s
Train Epoch: 2203 [20480/90000 (23%)]	Loss: -23.3191	Cost: 5.99s
Train Epoch: 2203 [40960/90000 (45%)]	Loss: -22.9855	Cost: 7.41s
Train Epoch: 2203 [61440/90000 (68%)]	Loss: -23.2896	Cost: 5.72s
Train Epoch: 2203 [81920/90000 (91%)]	Loss: -23.4747	Cost: 5.91s
Train Epoch: 2203 	Average Loss: -22.7512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2789

Learning rate: 0.00019976059931764282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2204 [0/90000 (0%)]	Loss: -16.1461	Cost: 22.06s
Train Epoch: 2204 [20480/90000 (23%)]	Loss: -23.5317	Cost: 6.07s
Train Epoch: 2204 [40960/90000 (45%)]	Loss: -22.9440	Cost: 6.64s
Train Epoch: 2204 [61440/90000 (68%)]	Loss: -23.1927	Cost: 6.16s
Train Epoch: 2204 [81920/90000 (91%)]	Loss: -23.3010	Cost: 5.81s
Train Epoch: 2204 	Average Loss: -22.8315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1622

Learning rate: 0.0001997603820145633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2205 [0/90000 (0%)]	Loss: -16.8012	Cost: 22.05s
Train Epoch: 2205 [20480/90000 (23%)]	Loss: -23.5283	Cost: 6.01s
Train Epoch: 2205 [40960/90000 (45%)]	Loss: -22.9156	Cost: 6.77s
Train Epoch: 2205 [61440/90000 (68%)]	Loss: -23.1671	Cost: 6.39s
Train Epoch: 2205 [81920/90000 (91%)]	Loss: -23.3318	Cost: 5.67s
Train Epoch: 2205 	Average Loss: -22.9005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2282

Learning rate: 0.0001997601646130242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2206 [0/90000 (0%)]	Loss: -15.5127	Cost: 21.69s
Train Epoch: 2206 [20480/90000 (23%)]	Loss: -23.6718	Cost: 6.01s
Train Epoch: 2206 [40960/90000 (45%)]	Loss: -23.1201	Cost: 6.76s
Train Epoch: 2206 [61440/90000 (68%)]	Loss: -23.4543	Cost: 5.81s
Train Epoch: 2206 [81920/90000 (91%)]	Loss: -23.3713	Cost: 5.89s
Train Epoch: 2206 	Average Loss: -22.8893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3241

Learning rate: 0.00019975994711302574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2207 [0/90000 (0%)]	Loss: -16.2861	Cost: 21.74s
Train Epoch: 2207 [20480/90000 (23%)]	Loss: -23.5493	Cost: 6.00s
Train Epoch: 2207 [40960/90000 (45%)]	Loss: -23.0377	Cost: 6.46s
Train Epoch: 2207 [61440/90000 (68%)]	Loss: -23.2085	Cost: 5.98s
Train Epoch: 2207 [81920/90000 (91%)]	Loss: -23.4637	Cost: 5.82s
Train Epoch: 2207 	Average Loss: -22.8710
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3057

Learning rate: 0.00019975972951456818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2208 [0/90000 (0%)]	Loss: -16.1785	Cost: 22.34s
Train Epoch: 2208 [20480/90000 (23%)]	Loss: -23.6133	Cost: 6.05s
Train Epoch: 2208 [40960/90000 (45%)]	Loss: -23.0475	Cost: 6.82s
Train Epoch: 2208 [61440/90000 (68%)]	Loss: -23.5206	Cost: 5.83s
Train Epoch: 2208 [81920/90000 (91%)]	Loss: -23.3514	Cost: 5.94s
Train Epoch: 2208 	Average Loss: -22.9897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4655

Saving model as e2208_model.pt & e2208_waveforms_supplementary.hdf5
Learning rate: 0.00019975951181765175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2209 [0/90000 (0%)]	Loss: -16.2344	Cost: 21.98s
Train Epoch: 2209 [20480/90000 (23%)]	Loss: -23.4017	Cost: 6.00s
Train Epoch: 2209 [40960/90000 (45%)]	Loss: -22.8278	Cost: 7.46s
Train Epoch: 2209 [61440/90000 (68%)]	Loss: -23.1111	Cost: 5.71s
Train Epoch: 2209 [81920/90000 (91%)]	Loss: -23.1344	Cost: 6.08s
Train Epoch: 2209 	Average Loss: -22.6930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1304

Learning rate: 0.0001997592940222766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2210 [0/90000 (0%)]	Loss: -14.4726	Cost: 21.52s
Train Epoch: 2210 [20480/90000 (23%)]	Loss: -23.4563	Cost: 5.99s
Train Epoch: 2210 [40960/90000 (45%)]	Loss: -23.1539	Cost: 7.15s
Train Epoch: 2210 [61440/90000 (68%)]	Loss: -23.3142	Cost: 5.84s
Train Epoch: 2210 [81920/90000 (91%)]	Loss: -23.4620	Cost: 5.83s
Train Epoch: 2210 	Average Loss: -22.8059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3045

Learning rate: 0.00019975907612844294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2211 [0/90000 (0%)]	Loss: -16.3263	Cost: 21.97s
Train Epoch: 2211 [20480/90000 (23%)]	Loss: -23.4054	Cost: 6.02s
Train Epoch: 2211 [40960/90000 (45%)]	Loss: -23.0016	Cost: 6.99s
Train Epoch: 2211 [61440/90000 (68%)]	Loss: -23.0783	Cost: 5.84s
Train Epoch: 2211 [81920/90000 (91%)]	Loss: -23.2660	Cost: 5.62s
Train Epoch: 2211 	Average Loss: -22.8041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2435

Learning rate: 0.00019975885813615105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2212 [0/90000 (0%)]	Loss: -16.2707	Cost: 22.27s
Train Epoch: 2212 [20480/90000 (23%)]	Loss: -23.5197	Cost: 6.00s
Train Epoch: 2212 [40960/90000 (45%)]	Loss: -23.0293	Cost: 6.56s
Train Epoch: 2212 [61440/90000 (68%)]	Loss: -23.0993	Cost: 5.83s
Train Epoch: 2212 [81920/90000 (91%)]	Loss: -23.4268	Cost: 5.62s
Train Epoch: 2212 	Average Loss: -22.8164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2688

Learning rate: 0.00019975864004540114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2213 [0/90000 (0%)]	Loss: -15.8299	Cost: 22.35s
Train Epoch: 2213 [20480/90000 (23%)]	Loss: -23.6661	Cost: 6.00s
Train Epoch: 2213 [40960/90000 (45%)]	Loss: -23.0113	Cost: 6.94s
Train Epoch: 2213 [61440/90000 (68%)]	Loss: -23.4025	Cost: 6.14s
Train Epoch: 2213 [81920/90000 (91%)]	Loss: -23.4980	Cost: 5.63s
Train Epoch: 2213 	Average Loss: -22.8643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4800

Saving model as e2213_model.pt & e2213_waveforms_supplementary.hdf5
Learning rate: 0.00019975842185619336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2214 [0/90000 (0%)]	Loss: -15.9544	Cost: 21.62s
Train Epoch: 2214 [20480/90000 (23%)]	Loss: -23.5841	Cost: 5.98s
Train Epoch: 2214 [40960/90000 (45%)]	Loss: -22.7148	Cost: 6.78s
Train Epoch: 2214 [61440/90000 (68%)]	Loss: -22.9050	Cost: 5.81s
Train Epoch: 2214 [81920/90000 (91%)]	Loss: -23.1679	Cost: 5.87s
Train Epoch: 2214 	Average Loss: -22.6707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1682

Learning rate: 0.00019975820356852794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2215 [0/90000 (0%)]	Loss: -14.9359	Cost: 22.28s
Train Epoch: 2215 [20480/90000 (23%)]	Loss: -23.3949	Cost: 5.97s
Train Epoch: 2215 [40960/90000 (45%)]	Loss: -22.9997	Cost: 6.75s
Train Epoch: 2215 [61440/90000 (68%)]	Loss: -23.1916	Cost: 5.78s
Train Epoch: 2215 [81920/90000 (91%)]	Loss: -23.3737	Cost: 5.92s
Train Epoch: 2215 	Average Loss: -22.7166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3095

Learning rate: 0.00019975798518240514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2216 [0/90000 (0%)]	Loss: -16.0463	Cost: 21.72s
Train Epoch: 2216 [20480/90000 (23%)]	Loss: -23.5645	Cost: 5.99s
Train Epoch: 2216 [40960/90000 (45%)]	Loss: -23.0272	Cost: 6.73s
Train Epoch: 2216 [61440/90000 (68%)]	Loss: -23.3312	Cost: 5.87s
Train Epoch: 2216 [81920/90000 (91%)]	Loss: -23.5614	Cost: 5.75s
Train Epoch: 2216 	Average Loss: -22.9198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5187

Saving model as e2216_model.pt & e2216_waveforms_supplementary.hdf5
Learning rate: 0.0001997577666978252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2217 [0/90000 (0%)]	Loss: -15.6188	Cost: 22.28s
Train Epoch: 2217 [20480/90000 (23%)]	Loss: -23.4920	Cost: 5.99s
Train Epoch: 2217 [40960/90000 (45%)]	Loss: -22.9860	Cost: 6.68s
Train Epoch: 2217 [61440/90000 (68%)]	Loss: -23.4121	Cost: 5.81s
Train Epoch: 2217 [81920/90000 (91%)]	Loss: -23.2585	Cost: 5.88s
Train Epoch: 2217 	Average Loss: -22.8420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4216

Learning rate: 0.00019975754811478826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2218 [0/90000 (0%)]	Loss: -17.3926	Cost: 22.35s
Train Epoch: 2218 [20480/90000 (23%)]	Loss: -23.4589	Cost: 5.97s
Train Epoch: 2218 [40960/90000 (45%)]	Loss: -23.0379	Cost: 6.72s
Train Epoch: 2218 [61440/90000 (68%)]	Loss: -23.4540	Cost: 5.86s
Train Epoch: 2218 [81920/90000 (91%)]	Loss: -23.3404	Cost: 5.62s
Train Epoch: 2218 	Average Loss: -22.9593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3476

Learning rate: 0.00019975732943329456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2219 [0/90000 (0%)]	Loss: -16.2220	Cost: 22.42s
Train Epoch: 2219 [20480/90000 (23%)]	Loss: -23.5319	Cost: 6.05s
Train Epoch: 2219 [40960/90000 (45%)]	Loss: -23.2735	Cost: 7.08s
Train Epoch: 2219 [61440/90000 (68%)]	Loss: -23.3653	Cost: 5.78s
Train Epoch: 2219 [81920/90000 (91%)]	Loss: -23.4957	Cost: 5.67s
Train Epoch: 2219 	Average Loss: -22.9681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4441

Learning rate: 0.00019975711065334435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2220 [0/90000 (0%)]	Loss: -16.4840	Cost: 22.14s
Train Epoch: 2220 [20480/90000 (23%)]	Loss: -23.3460	Cost: 5.98s
Train Epoch: 2220 [40960/90000 (45%)]	Loss: -22.8314	Cost: 6.69s
Train Epoch: 2220 [61440/90000 (68%)]	Loss: -23.2826	Cost: 5.91s
Train Epoch: 2220 [81920/90000 (91%)]	Loss: -23.4406	Cost: 5.81s
Train Epoch: 2220 	Average Loss: -22.7476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1836

Learning rate: 0.0001997568917749378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2221 [0/90000 (0%)]	Loss: -15.9125	Cost: 21.92s
Train Epoch: 2221 [20480/90000 (23%)]	Loss: -23.4597	Cost: 6.01s
Train Epoch: 2221 [40960/90000 (45%)]	Loss: -23.3383	Cost: 6.97s
Train Epoch: 2221 [61440/90000 (68%)]	Loss: -23.3976	Cost: 5.77s
Train Epoch: 2221 [81920/90000 (91%)]	Loss: -23.7366	Cost: 5.91s
Train Epoch: 2221 	Average Loss: -22.9486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4715

Learning rate: 0.0001997566727980751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2222 [0/90000 (0%)]	Loss: -16.1964	Cost: 21.80s
Train Epoch: 2222 [20480/90000 (23%)]	Loss: -23.6116	Cost: 6.01s
Train Epoch: 2222 [40960/90000 (45%)]	Loss: -23.1610	Cost: 6.89s
Train Epoch: 2222 [61440/90000 (68%)]	Loss: -23.1673	Cost: 6.07s
Train Epoch: 2222 [81920/90000 (91%)]	Loss: -23.1159	Cost: 5.79s
Train Epoch: 2222 	Average Loss: -22.9727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2137

Learning rate: 0.00019975645372275654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2223 [0/90000 (0%)]	Loss: -15.2358	Cost: 22.00s
Train Epoch: 2223 [20480/90000 (23%)]	Loss: -23.4033	Cost: 6.03s
Train Epoch: 2223 [40960/90000 (45%)]	Loss: -23.1138	Cost: 7.09s
Train Epoch: 2223 [61440/90000 (68%)]	Loss: -23.4782	Cost: 5.82s
Train Epoch: 2223 [81920/90000 (91%)]	Loss: -23.3666	Cost: 5.63s
Train Epoch: 2223 	Average Loss: -22.8646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3635

Learning rate: 0.00019975623454898233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2224 [0/90000 (0%)]	Loss: -16.3675	Cost: 21.72s
Train Epoch: 2224 [20480/90000 (23%)]	Loss: -23.5981	Cost: 6.02s
Train Epoch: 2224 [40960/90000 (45%)]	Loss: -23.4300	Cost: 7.38s
Train Epoch: 2224 [61440/90000 (68%)]	Loss: -23.5617	Cost: 5.72s
Train Epoch: 2224 [81920/90000 (91%)]	Loss: -23.5690	Cost: 5.79s
Train Epoch: 2224 	Average Loss: -23.1131
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3616

Learning rate: 0.00019975601527675264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2225 [0/90000 (0%)]	Loss: -16.6727	Cost: 22.00s
Train Epoch: 2225 [20480/90000 (23%)]	Loss: -23.5060	Cost: 6.03s
Train Epoch: 2225 [40960/90000 (45%)]	Loss: -22.5349	Cost: 7.06s
Train Epoch: 2225 [61440/90000 (68%)]	Loss: -22.8285	Cost: 6.06s
Train Epoch: 2225 [81920/90000 (91%)]	Loss: -22.9243	Cost: 5.60s
Train Epoch: 2225 	Average Loss: -22.5684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9969

Learning rate: 0.0001997557959060677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2226 [0/90000 (0%)]	Loss: -15.7669	Cost: 22.18s
Train Epoch: 2226 [20480/90000 (23%)]	Loss: -23.3662	Cost: 6.00s
Train Epoch: 2226 [40960/90000 (45%)]	Loss: -23.1745	Cost: 6.89s
Train Epoch: 2226 [61440/90000 (68%)]	Loss: -23.3513	Cost: 5.84s
Train Epoch: 2226 [81920/90000 (91%)]	Loss: -23.4524	Cost: 5.75s
Train Epoch: 2226 	Average Loss: -22.8078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4657

Learning rate: 0.00019975557643692776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2227 [0/90000 (0%)]	Loss: -16.1760	Cost: 21.47s
Train Epoch: 2227 [20480/90000 (23%)]	Loss: -23.4510	Cost: 6.07s
Train Epoch: 2227 [40960/90000 (45%)]	Loss: -22.4659	Cost: 6.79s
Train Epoch: 2227 [61440/90000 (68%)]	Loss: -22.6950	Cost: 5.94s
Train Epoch: 2227 [81920/90000 (91%)]	Loss: -23.0029	Cost: 5.65s
Train Epoch: 2227 	Average Loss: -22.5419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9101

Learning rate: 0.000199755356869333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2228 [0/90000 (0%)]	Loss: -16.6453	Cost: 21.81s
Train Epoch: 2228 [20480/90000 (23%)]	Loss: -22.9088	Cost: 6.03s
Train Epoch: 2228 [40960/90000 (45%)]	Loss: -22.6550	Cost: 6.76s
Train Epoch: 2228 [61440/90000 (68%)]	Loss: -23.1259	Cost: 5.82s
Train Epoch: 2228 [81920/90000 (91%)]	Loss: -23.4099	Cost: 5.68s
Train Epoch: 2228 	Average Loss: -22.5416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4700

Learning rate: 0.00019975513720328367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2229 [0/90000 (0%)]	Loss: -15.8307	Cost: 21.75s
Train Epoch: 2229 [20480/90000 (23%)]	Loss: -23.5253	Cost: 5.98s
Train Epoch: 2229 [40960/90000 (45%)]	Loss: -23.0466	Cost: 6.77s
Train Epoch: 2229 [61440/90000 (68%)]	Loss: -23.4850	Cost: 5.76s
Train Epoch: 2229 [81920/90000 (91%)]	Loss: -23.4898	Cost: 6.24s
Train Epoch: 2229 	Average Loss: -22.9187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4643

Learning rate: 0.00019975491743877993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2230 [0/90000 (0%)]	Loss: -16.8287	Cost: 21.75s
Train Epoch: 2230 [20480/90000 (23%)]	Loss: -23.6128	Cost: 6.00s
Train Epoch: 2230 [40960/90000 (45%)]	Loss: -22.9562	Cost: 6.73s
Train Epoch: 2230 [61440/90000 (68%)]	Loss: -23.3040	Cost: 5.77s
Train Epoch: 2230 [81920/90000 (91%)]	Loss: -23.3885	Cost: 5.91s
Train Epoch: 2230 	Average Loss: -22.8976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3288

Stopping timer.
Training time (including validation): 269003.8441708088 seconds
Saving model
