Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW170817_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW170817_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=100000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0001, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.0, mode='train', model_dir='models/GW170817_sample_uniform_100basis_all_uniform_prior/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='uniform', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=0, truncate_basis=100)
Waveform directory data/GW170817_sample_prior_basis/
Model directory models/GW170817_sample_uniform_100basis_all_uniform_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from uniform prior.
init training...
init relative whitening...
Truncating reduced basis from 2000 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
Loading load_all_bilby_samples...
Loading load_all_event_strain...
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
Detectors: ['H1', 'L1', 'V1']

Constructing model of type nde

Initial learning rate 0.0001
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 600
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 100000 epochs
Starting timer
Learning rate: 0.0001
Re-generating waveforms for uniform prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.5781	Cost: 18.74s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 22.0148	Cost: 6.53s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.8196	Cost: 15.41s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 21.5450	Cost: 6.29s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 21.3837	Cost: 13.52s
Train Epoch: 1 	Average Loss: 22.2337
Re-generating waveforms for uniform prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4082

(400,)
Stopping timer.
Training time (including validation): 80.35413122177124 seconds
Saving model
