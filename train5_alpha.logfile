  0%|          | 0/1001 [00:00<?, ?it/s]  1%|          | 6/1001 [00:00<00:19, 50.78it/s]  1%|          | 12/1001 [00:00<00:18, 52.43it/s]  2%|▏         | 18/1001 [00:00<00:18, 54.25it/s]  2%|▏         | 24/1001 [00:00<00:17, 54.48it/s]  3%|▎         | 30/1001 [00:00<00:17, 54.36it/s]  4%|▎         | 36/1001 [00:00<00:17, 54.70it/s]  4%|▍         | 42/1001 [00:00<00:17, 55.10it/s]  5%|▍         | 48/1001 [00:00<00:17, 55.30it/s]  5%|▌         | 54/1001 [00:00<00:17, 55.32it/s]  6%|▌         | 60/1001 [00:01<00:17, 55.21it/s]  7%|▋         | 66/1001 [00:01<00:16, 55.39it/s]  7%|▋         | 72/1001 [00:01<00:16, 55.03it/s]  8%|▊         | 78/1001 [00:01<00:16, 54.47it/s]  8%|▊         | 84/1001 [00:01<00:16, 54.66it/s]  9%|▉         | 90/1001 [00:01<00:16, 54.99it/s] 10%|▉         | 96/1001 [00:01<00:16, 55.03it/s] 10%|█         | 102/1001 [00:01<00:16, 55.18it/s] 11%|█         | 108/1001 [00:01<00:16, 55.04it/s] 11%|█▏        | 114/1001 [00:02<00:16, 55.18it/s] 12%|█▏        | 120/1001 [00:02<00:15, 55.42it/s] 13%|█▎        | 126/1001 [00:02<00:15, 55.63it/s] 13%|█▎        | 132/1001 [00:02<00:15, 55.42it/s] 14%|█▍        | 138/1001 [00:02<00:15, 54.92it/s] 14%|█▍        | 144/1001 [00:02<00:15, 54.42it/s] 15%|█▍        | 150/1001 [00:02<00:15, 54.26it/s] 16%|█▌        | 156/1001 [00:02<00:15, 54.73it/s] 16%|█▌        | 162/1001 [00:02<00:15, 54.74it/s] 17%|█▋        | 168/1001 [00:03<00:15, 55.07it/s] 17%|█▋        | 174/1001 [00:03<00:14, 55.28it/s] 18%|█▊        | 180/1001 [00:03<00:14, 55.35it/s] 19%|█▊        | 186/1001 [00:03<00:14, 55.27it/s] 19%|█▉        | 192/1001 [00:03<00:14, 55.37it/s] 20%|█▉        | 198/1001 [00:03<00:14, 55.59it/s] 20%|██        | 204/1001 [00:03<00:14, 55.69it/s] 21%|██        | 210/1001 [00:03<00:14, 55.73it/s] 22%|██▏       | 216/1001 [00:03<00:14, 55.69it/s] 22%|██▏       | 222/1001 [00:04<00:14, 55.60it/s] 23%|██▎       | 228/1001 [00:04<00:13, 55.63it/s] 23%|██▎       | 234/1001 [00:04<00:13, 55.69it/s] 24%|██▍       | 240/1001 [00:04<00:13, 55.67it/s] 25%|██▍       | 246/1001 [00:04<00:13, 55.73it/s] 25%|██▌       | 252/1001 [00:04<00:13, 53.98it/s] 26%|██▌       | 258/1001 [00:04<00:13, 54.51it/s] 26%|██▋       | 264/1001 [00:04<00:13, 54.78it/s] 27%|██▋       | 270/1001 [00:04<00:13, 54.99it/s] 28%|██▊       | 276/1001 [00:05<00:13, 55.35it/s] 28%|██▊       | 282/1001 [00:05<00:12, 55.60it/s] 29%|██▉       | 288/1001 [00:05<00:12, 55.64it/s] 29%|██▉       | 294/1001 [00:05<00:12, 55.63it/s] 30%|██▉       | 300/1001 [00:05<00:12, 55.73it/s] 31%|███       | 306/1001 [00:05<00:12, 55.73it/s] 31%|███       | 312/1001 [00:05<00:12, 55.74it/s] 32%|███▏      | 318/1001 [00:05<00:12, 55.73it/s] 32%|███▏      | 324/1001 [00:05<00:12, 55.86it/s] 33%|███▎      | 330/1001 [00:05<00:12, 55.90it/s] 34%|███▎      | 336/1001 [00:06<00:11, 55.95it/s] 34%|███▍      | 342/1001 [00:06<00:11, 55.90it/s] 35%|███▍      | 348/1001 [00:06<00:11, 55.82it/s] 35%|███▌      | 354/1001 [00:06<00:11, 55.83it/s] 36%|███▌      | 360/1001 [00:06<00:11, 55.15it/s] 37%|███▋      | 366/1001 [00:06<00:11, 54.80it/s] 37%|███▋      | 372/1001 [00:06<00:11, 54.73it/s] 38%|███▊      | 378/1001 [00:06<00:11, 54.68it/s] 38%|███▊      | 384/1001 [00:06<00:11, 55.08it/s] 39%|███▉      | 390/1001 [00:07<00:11, 55.42it/s] 40%|███▉      | 396/1001 [00:07<00:10, 55.59it/s] 40%|████      | 402/1001 [00:07<00:10, 55.81it/s] 41%|████      | 408/1001 [00:07<00:10, 55.97it/s] 41%|████▏     | 414/1001 [00:07<00:10, 56.01it/s] 42%|████▏     | 420/1001 [00:07<00:10, 55.98it/s] 43%|████▎     | 426/1001 [00:07<00:10, 55.94it/s] 43%|████▎     | 432/1001 [00:07<00:10, 55.97it/s] 44%|████▍     | 438/1001 [00:07<00:10, 55.81it/s] 44%|████▍     | 444/1001 [00:08<00:09, 55.93it/s] 45%|████▍     | 450/1001 [00:08<00:09, 55.91it/s] 46%|████▌     | 456/1001 [00:08<00:09, 55.93it/s] 46%|████▌     | 462/1001 [00:08<00:09, 55.97it/s] 47%|████▋     | 468/1001 [00:08<00:09, 55.99it/s] 47%|████▋     | 474/1001 [00:08<00:09, 55.85it/s] 48%|████▊     | 480/1001 [00:08<00:09, 55.82it/s] 49%|████▊     | 486/1001 [00:08<00:09, 55.97it/s] 49%|████▉     | 492/1001 [00:08<00:09, 56.06it/s] 50%|████▉     | 498/1001 [00:08<00:08, 56.02it/s] 50%|█████     | 504/1001 [00:09<00:08, 55.99it/s] 51%|█████     | 510/1001 [00:09<00:08, 56.03it/s] 52%|█████▏    | 516/1001 [00:09<00:08, 56.00it/s] 52%|█████▏    | 522/1001 [00:09<00:08, 55.96it/s] 53%|█████▎    | 528/1001 [00:09<00:08, 55.87it/s] 53%|█████▎    | 534/1001 [00:09<00:08, 56.00it/s] 54%|█████▍    | 540/1001 [00:09<00:08, 56.00it/s] 55%|█████▍    | 546/1001 [00:09<00:08, 56.01it/s] 55%|█████▌    | 552/1001 [00:09<00:08, 55.76it/s] 56%|█████▌    | 558/1001 [00:10<00:07, 55.60it/s] 56%|█████▋    | 564/1001 [00:10<00:07, 55.15it/s] 57%|█████▋    | 570/1001 [00:10<00:07, 55.02it/s] 58%|█████▊    | 576/1001 [00:10<00:07, 55.26it/s] 58%|█████▊    | 582/1001 [00:10<00:07, 55.00it/s] 59%|█████▊    | 588/1001 [00:10<00:07, 54.95it/s] 59%|█████▉    | 594/1001 [00:10<00:07, 55.23it/s] 60%|█████▉    | 600/1001 [00:10<00:07, 55.20it/s] 61%|██████    | 606/1001 [00:10<00:07, 55.30it/s] 61%|██████    | 612/1001 [00:11<00:07, 55.45it/s] 62%|██████▏   | 618/1001 [00:11<00:06, 55.44it/s] 62%|██████▏   | 624/1001 [00:11<00:06, 55.08it/s] 63%|██████▎   | 630/1001 [00:11<00:06, 55.03it/s] 64%|██████▎   | 636/1001 [00:11<00:06, 55.20it/s] 64%|██████▍   | 642/1001 [00:11<00:06, 55.05it/s] 65%|██████▍   | 648/1001 [00:11<00:06, 55.11it/s] 65%|██████▌   | 654/1001 [00:11<00:06, 55.22it/s] 66%|██████▌   | 660/1001 [00:11<00:06, 55.41it/s] 67%|██████▋   | 666/1001 [00:12<00:06, 55.55it/s] 67%|██████▋   | 672/1001 [00:12<00:05, 55.62it/s] 68%|██████▊   | 678/1001 [00:12<00:05, 55.63it/s] 68%|██████▊   | 684/1001 [00:12<00:05, 55.59it/s] 69%|██████▉   | 690/1001 [00:12<00:05, 55.58it/s] 70%|██████▉   | 696/1001 [00:12<00:05, 55.15it/s] 70%|███████   | 702/1001 [00:12<00:05, 55.17it/s] 71%|███████   | 708/1001 [00:12<00:05, 55.31it/s] 71%|███████▏  | 714/1001 [00:12<00:05, 55.37it/s] 72%|███████▏  | 720/1001 [00:13<00:05, 55.48it/s] 73%|███████▎  | 726/1001 [00:13<00:04, 55.62it/s] 73%|███████▎  | 732/1001 [00:13<00:04, 55.66it/s] 74%|███████▎  | 738/1001 [00:13<00:04, 55.69it/s] 74%|███████▍  | 744/1001 [00:13<00:04, 55.14it/s] 75%|███████▍  | 750/1001 [00:13<00:04, 54.97it/s] 76%|███████▌  | 756/1001 [00:13<00:04, 54.98it/s] 76%|███████▌  | 762/1001 [00:13<00:04, 55.18it/s] 77%|███████▋  | 768/1001 [00:13<00:04, 55.13it/s] 77%|███████▋  | 774/1001 [00:13<00:04, 54.46it/s] 78%|███████▊  | 780/1001 [00:14<00:04, 54.69it/s] 79%|███████▊  | 786/1001 [00:14<00:03, 54.75it/s] 79%|███████▉  | 792/1001 [00:14<00:03, 54.66it/s] 80%|███████▉  | 798/1001 [00:14<00:03, 54.88it/s] 80%|████████  | 804/1001 [00:14<00:03, 54.66it/s] 81%|████████  | 810/1001 [00:14<00:03, 54.34it/s] 82%|████████▏ | 816/1001 [00:14<00:03, 53.96it/s] 82%|████████▏ | 822/1001 [00:14<00:03, 54.27it/s] 83%|████████▎ | 828/1001 [00:14<00:03, 53.98it/s] 83%|████████▎ | 834/1001 [00:15<00:03, 54.05it/s] 84%|████████▍ | 840/1001 [00:15<00:02, 54.45it/s] 85%|████████▍ | 846/1001 [00:15<00:02, 54.15it/s] 85%|████████▌ | 852/1001 [00:15<00:02, 54.41it/s] 86%|████████▌ | 858/1001 [00:15<00:02, 53.50it/s] 86%|████████▋ | 864/1001 [00:15<00:02, 52.94it/s] 87%|████████▋ | 870/1001 [00:15<00:02, 52.91it/s] 88%|████████▊ | 876/1001 [00:15<00:02, 52.40it/s] 88%|████████▊ | 882/1001 [00:15<00:02, 52.64it/s] 89%|████████▊ | 888/1001 [00:16<00:02, 53.22it/s] 89%|████████▉ | 894/1001 [00:16<00:01, 53.67it/s] 90%|████████▉ | 900/1001 [00:16<00:01, 54.09it/s] 91%|█████████ | 906/1001 [00:16<00:01, 54.34it/s] 91%|█████████ | 912/1001 [00:16<00:01, 54.53it/s] 92%|█████████▏| 918/1001 [00:16<00:01, 54.25it/s] 92%|█████████▏| 924/1001 [00:16<00:01, 54.15it/s] 93%|█████████▎| 930/1001 [00:16<00:01, 54.22it/s] 94%|█████████▎| 936/1001 [00:16<00:01, 54.36it/s] 94%|█████████▍| 942/1001 [00:17<00:01, 54.08it/s] 95%|█████████▍| 948/1001 [00:17<00:00, 54.44it/s] 95%|█████████▌| 954/1001 [00:17<00:00, 53.73it/s] 96%|█████████▌| 960/1001 [00:17<00:00, 54.10it/s] 97%|█████████▋| 966/1001 [00:17<00:00, 54.39it/s] 97%|█████████▋| 972/1001 [00:17<00:00, 54.18it/s] 98%|█████████▊| 978/1001 [00:17<00:00, 53.95it/s] 98%|█████████▊| 984/1001 [00:17<00:00, 54.10it/s] 99%|█████████▉| 990/1001 [00:17<00:00, 54.38it/s]100%|█████████▉| 996/1001 [00:18<00:00, 54.63it/s]100%|██████████| 1001/1001 [00:18<00:00, 55.06it/s]
  0%|          | 0/90000 [00:00<?, ?it/s]  0%|          | 1/90000 [00:00<16:39:53,  1.50it/s]  0%|          | 25/90000 [00:00<34:29, 43.48it/s]    0%|          | 51/90000 [00:00<17:22, 86.25it/s]  0%|          | 76/90000 [00:00<12:16, 122.05it/s]  0%|          | 101/90000 [00:01<09:49, 152.54it/s]  0%|          | 127/90000 [00:01<08:21, 179.15it/s]  0%|          | 152/90000 [00:01<07:38, 196.05it/s]  0%|          | 176/90000 [00:01<07:13, 207.10it/s]  0%|          | 201/90000 [00:01<06:51, 218.33it/s]  0%|          | 227/90000 [00:01<06:33, 228.43it/s]  0%|          | 252/90000 [00:01<06:30, 230.12it/s]  0%|          | 277/90000 [00:01<06:21, 234.97it/s]  0%|          | 302/90000 [00:01<06:16, 238.43it/s]  0%|          | 328/90000 [00:01<06:08, 243.20it/s]  0%|          | 353/90000 [00:02<06:07, 243.84it/s]  0%|          | 378/90000 [00:02<06:07, 243.77it/s]  0%|          | 403/90000 [00:02<06:10, 241.79it/s]  0%|          | 428/90000 [00:02<06:12, 240.36it/s]  1%|          | 453/90000 [00:02<06:14, 239.13it/s]  1%|          | 478/90000 [00:02<06:11, 241.27it/s]  1%|          | 503/90000 [00:02<06:09, 242.22it/s]  1%|          | 528/90000 [00:02<06:11, 240.91it/s]  1%|          | 553/90000 [00:02<06:08, 242.57it/s]  1%|          | 578/90000 [00:03<06:08, 242.36it/s]  1%|          | 603/90000 [00:03<06:12, 239.92it/s]  1%|          | 629/90000 [00:03<06:07, 243.35it/s]  1%|          | 654/90000 [00:03<06:09, 242.08it/s]  1%|          | 679/90000 [00:03<06:14, 238.78it/s]  1%|          | 703/90000 [00:03<06:21, 233.82it/s]  1%|          | 728/90000 [00:03<06:14, 238.22it/s]  1%|          | 752/90000 [00:03<06:18, 235.87it/s]  1%|          | 776/90000 [00:03<06:18, 236.00it/s]  1%|          | 801/90000 [00:03<06:15, 237.43it/s]  1%|          | 827/90000 [00:04<06:09, 241.63it/s]  1%|          | 852/90000 [00:04<06:07, 242.71it/s]  1%|          | 878/90000 [00:04<06:04, 244.36it/s]  1%|          | 903/90000 [00:04<06:06, 242.89it/s]  1%|          | 928/90000 [00:04<06:09, 241.37it/s]  1%|          | 954/90000 [00:04<06:04, 244.06it/s]  1%|          | 979/90000 [00:04<06:07, 242.11it/s]  1%|          | 1004/90000 [00:04<06:06, 242.96it/s]  1%|          | 1029/90000 [00:04<06:05, 243.16it/s]  1%|          | 1055/90000 [00:05<06:02, 245.61it/s]  1%|          | 1080/90000 [00:05<06:08, 241.24it/s]  1%|          | 1105/90000 [00:05<06:06, 242.61it/s]  1%|▏         | 1131/90000 [00:05<06:02, 245.30it/s]  1%|▏         | 1156/90000 [00:05<06:05, 242.88it/s]  1%|▏         | 1182/90000 [00:05<06:03, 244.65it/s]  1%|▏         | 1207/90000 [00:05<06:03, 244.39it/s]  1%|▏         | 1232/90000 [00:05<06:10, 239.76it/s]  1%|▏         | 1258/90000 [00:05<06:05, 242.52it/s]  1%|▏         | 1283/90000 [00:05<06:02, 244.63it/s]  1%|▏         | 1308/90000 [00:06<06:00, 245.96it/s]  1%|▏         | 1333/90000 [00:06<06:02, 244.89it/s]  2%|▏         | 1358/90000 [00:06<06:05, 242.33it/s]  2%|▏         | 1383/90000 [00:06<06:04, 243.02it/s]  2%|▏         | 1408/90000 [00:06<06:04, 243.24it/s]  2%|▏         | 1434/90000 [00:06<05:58, 246.79it/s]  2%|▏         | 1459/90000 [00:06<05:59, 246.41it/s]  2%|▏         | 1484/90000 [00:06<05:59, 246.15it/s]  2%|▏         | 1509/90000 [00:06<05:59, 246.14it/s]  2%|▏         | 1534/90000 [00:06<06:01, 244.83it/s]  2%|▏         | 1559/90000 [00:07<06:04, 242.62it/s]  2%|▏         | 1584/90000 [00:07<06:10, 238.77it/s]  2%|▏         | 1608/90000 [00:07<06:16, 234.99it/s]  2%|▏         | 1632/90000 [00:07<06:15, 235.14it/s]  2%|▏         | 1657/90000 [00:07<06:10, 238.40it/s]  2%|▏         | 1681/90000 [00:07<06:10, 238.16it/s]  2%|▏         | 1707/90000 [00:07<06:04, 242.28it/s]  2%|▏         | 1732/90000 [00:07<06:08, 239.66it/s]  2%|▏         | 1757/90000 [00:07<06:06, 241.00it/s]  2%|▏         | 1782/90000 [00:08<06:03, 242.85it/s]  2%|▏         | 1807/90000 [00:08<06:00, 244.70it/s]  2%|▏         | 1832/90000 [00:08<05:58, 245.77it/s]  2%|▏         | 1857/90000 [00:08<06:00, 244.22it/s]  2%|▏         | 1882/90000 [00:08<06:07, 239.65it/s]  2%|▏         | 1906/90000 [00:08<06:07, 239.45it/s]  2%|▏         | 1932/90000 [00:08<06:00, 244.59it/s]  2%|▏         | 1957/90000 [00:08<05:59, 245.22it/s]  2%|▏         | 1983/90000 [00:08<05:56, 247.04it/s]  2%|▏         | 2008/90000 [00:08<05:57, 245.96it/s]  2%|▏         | 2033/90000 [00:09<06:04, 241.44it/s]  2%|▏         | 2058/90000 [00:09<06:05, 240.71it/s]  2%|▏         | 2083/90000 [00:09<06:07, 239.36it/s]  2%|▏         | 2108/90000 [00:09<06:03, 241.70it/s]  2%|▏         | 2133/90000 [00:09<06:00, 243.82it/s]  2%|▏         | 2158/90000 [00:09<06:02, 242.62it/s]  2%|▏         | 2183/90000 [00:09<05:59, 244.05it/s]  2%|▏         | 2208/90000 [00:09<06:04, 240.74it/s]  2%|▏         | 2233/90000 [00:09<06:04, 241.09it/s]  3%|▎         | 2258/90000 [00:09<06:06, 239.60it/s]  3%|▎         | 2283/90000 [00:10<06:01, 242.39it/s]  3%|▎         | 2308/90000 [00:10<06:02, 241.61it/s]  3%|▎         | 2333/90000 [00:10<05:59, 243.62it/s]  3%|▎         | 2358/90000 [00:10<05:57, 245.07it/s]  3%|▎         | 2383/90000 [00:10<05:59, 243.93it/s]  3%|▎         | 2408/90000 [00:10<06:09, 237.37it/s]  3%|▎         | 2432/90000 [00:10<06:09, 237.17it/s]  3%|▎         | 2457/90000 [00:10<06:05, 239.44it/s]  3%|▎         | 2481/90000 [00:10<06:08, 237.67it/s]  3%|▎         | 2507/90000 [00:11<06:01, 241.80it/s]  3%|▎         | 2532/90000 [00:11<06:04, 240.28it/s]  3%|▎         | 2557/90000 [00:11<06:04, 240.14it/s]  3%|▎         | 2583/90000 [00:11<05:58, 243.56it/s]  3%|▎         | 2608/90000 [00:11<06:00, 242.42it/s]  3%|▎         | 2634/90000 [00:11<05:55, 245.84it/s]  3%|▎         | 2659/90000 [00:11<05:57, 244.16it/s]  3%|▎         | 2684/90000 [00:11<05:58, 243.79it/s]  3%|▎         | 2709/90000 [00:11<06:03, 240.43it/s]  3%|▎         | 2734/90000 [00:11<06:00, 242.09it/s]  3%|▎         | 2759/90000 [00:12<06:04, 239.56it/s]  3%|▎         | 2784/90000 [00:12<06:02, 240.52it/s]  3%|▎         | 2809/90000 [00:12<05:59, 242.36it/s]  3%|▎         | 2835/90000 [00:12<05:53, 246.78it/s]  3%|▎         | 2861/90000 [00:12<05:51, 248.13it/s]  3%|▎         | 2886/90000 [00:12<05:55, 245.16it/s]  3%|▎         | 2911/90000 [00:12<05:54, 245.64it/s]  3%|▎         | 2936/90000 [00:12<05:54, 245.42it/s]  3%|▎         | 2961/90000 [00:12<05:53, 246.53it/s]  3%|▎         | 2986/90000 [00:12<05:55, 245.08it/s]  3%|▎         | 3011/90000 [00:13<05:56, 243.68it/s]  3%|▎         | 3036/90000 [00:13<05:56, 243.61it/s]  3%|▎         | 3061/90000 [00:13<05:58, 242.57it/s]  3%|▎         | 3086/90000 [00:13<05:56, 243.71it/s]  3%|▎         | 3111/90000 [00:13<06:00, 240.89it/s]  3%|▎         | 3136/90000 [00:13<06:08, 235.86it/s]  4%|▎         | 3160/90000 [00:13<06:10, 234.62it/s]  4%|▎         | 3184/90000 [00:13<06:08, 235.51it/s]  4%|▎         | 3208/90000 [00:13<06:11, 233.56it/s]  4%|▎         | 3234/90000 [00:14<06:02, 239.50it/s]  4%|▎         | 3259/90000 [00:14<06:00, 240.29it/s]  4%|▎         | 3284/90000 [00:14<05:57, 242.55it/s]  4%|▎         | 3310/90000 [00:14<05:52, 245.68it/s]  4%|▎         | 3335/90000 [00:14<05:51, 246.45it/s]  4%|▎         | 3360/90000 [00:14<05:58, 241.45it/s]  4%|▍         | 3386/90000 [00:14<05:54, 244.35it/s]  4%|▍         | 3411/90000 [00:14<05:55, 243.54it/s]  4%|▍         | 3436/90000 [00:14<05:54, 243.90it/s]  4%|▍         | 3461/90000 [00:14<05:58, 241.50it/s]  4%|▍         | 3486/90000 [00:15<05:56, 242.78it/s]  4%|▍         | 3511/90000 [00:15<05:59, 240.30it/s]  4%|▍         | 3536/90000 [00:15<05:57, 242.04it/s]  4%|▍         | 3561/90000 [00:15<05:54, 244.03it/s]  4%|▍         | 3586/90000 [00:15<05:59, 240.21it/s]  4%|▍         | 3611/90000 [00:15<06:01, 239.14it/s]  4%|▍         | 3638/90000 [00:15<05:50, 246.69it/s]  4%|▍         | 3663/90000 [00:15<05:54, 243.85it/s]  4%|▍         | 3688/90000 [00:15<05:52, 244.61it/s]  4%|▍         | 3713/90000 [00:15<05:52, 244.83it/s]  4%|▍         | 3738/90000 [00:16<05:50, 246.24it/s]  4%|▍         | 3763/90000 [00:16<05:53, 244.17it/s]  4%|▍         | 3788/90000 [00:16<05:56, 241.70it/s]  4%|▍         | 3813/90000 [00:16<05:59, 239.48it/s]  4%|▍         | 3837/90000 [00:16<06:00, 239.04it/s]  4%|▍         | 3861/90000 [00:16<06:01, 238.51it/s]  4%|▍         | 3886/90000 [00:16<05:59, 239.44it/s]  4%|▍         | 3911/90000 [00:16<05:58, 239.90it/s]  4%|▍         | 3936/90000 [00:16<05:58, 240.21it/s]  4%|▍         | 3961/90000 [00:17<05:57, 240.94it/s]  4%|▍         | 3986/90000 [00:17<05:56, 241.37it/s]  4%|▍         | 4012/90000 [00:17<05:52, 244.20it/s]  4%|▍         | 4037/90000 [00:17<05:53, 243.23it/s]  5%|▍         | 4062/90000 [00:17<06:00, 238.40it/s]  5%|▍         | 4087/90000 [00:17<05:56, 241.26it/s]  5%|▍         | 4112/90000 [00:17<05:54, 242.04it/s]  5%|▍         | 4137/90000 [00:17<05:56, 241.12it/s]  5%|▍         | 4162/90000 [00:17<05:53, 242.66it/s]  5%|▍         | 4187/90000 [00:17<05:56, 241.00it/s]  5%|▍         | 4212/90000 [00:18<05:56, 240.64it/s]  5%|▍         | 4237/90000 [00:18<05:58, 239.35it/s]  5%|▍         | 4262/90000 [00:18<05:55, 240.97it/s]  5%|▍         | 4287/90000 [00:18<05:54, 241.58it/s]  5%|▍         | 4313/90000 [00:18<05:50, 244.36it/s]  5%|▍         | 4338/90000 [00:18<05:59, 238.59it/s]  5%|▍         | 4362/90000 [00:18<05:58, 238.73it/s]  5%|▍         | 4387/90000 [00:18<05:56, 240.35it/s]  5%|▍         | 4413/90000 [00:18<05:51, 243.49it/s]  5%|▍         | 4438/90000 [00:18<05:52, 243.07it/s]  5%|▍         | 4464/90000 [00:19<05:48, 245.34it/s]  5%|▍         | 4489/90000 [00:19<05:51, 243.28it/s]  5%|▌         | 4515/90000 [00:19<05:48, 245.59it/s]  5%|▌         | 4540/90000 [00:19<05:48, 245.25it/s]  5%|▌         | 4565/90000 [00:19<05:52, 242.15it/s]  5%|▌         | 4590/90000 [00:19<05:50, 243.43it/s]  5%|▌         | 4615/90000 [00:19<05:51, 242.76it/s]  5%|▌         | 4640/90000 [00:19<05:49, 244.30it/s]  5%|▌         | 4665/90000 [00:19<05:55, 240.32it/s]  5%|▌         | 4690/90000 [00:20<06:00, 236.91it/s]  5%|▌         | 4714/90000 [00:20<06:01, 235.85it/s]  5%|▌         | 4738/90000 [00:20<06:01, 235.81it/s]  5%|▌         | 4763/90000 [00:20<05:55, 239.67it/s]  5%|▌         | 4788/90000 [00:20<05:54, 240.43it/s]  5%|▌         | 4815/90000 [00:20<05:47, 245.42it/s]  5%|▌         | 4840/90000 [00:20<05:47, 245.09it/s]  5%|▌         | 4865/90000 [00:20<05:52, 241.64it/s]  5%|▌         | 4891/90000 [00:20<05:46, 245.33it/s]  5%|▌         | 4916/90000 [00:20<05:48, 244.39it/s]  5%|▌         | 4942/90000 [00:21<05:46, 245.76it/s]  6%|▌         | 4967/90000 [00:21<05:53, 240.72it/s]  6%|▌         | 4993/90000 [00:21<05:46, 245.50it/s]  6%|▌         | 5018/90000 [00:21<05:48, 243.73it/s]  6%|▌         | 5044/90000 [00:21<05:44, 246.57it/s]  6%|▌         | 5069/90000 [00:21<05:49, 242.93it/s]  6%|▌         | 5094/90000 [00:21<05:54, 239.21it/s]  6%|▌         | 5120/90000 [00:21<05:50, 242.32it/s]  6%|▌         | 5145/90000 [00:21<05:53, 239.84it/s]  6%|▌         | 5170/90000 [00:22<05:50, 241.94it/s]  6%|▌         | 5195/90000 [00:22<05:48, 243.10it/s]  6%|▌         | 5220/90000 [00:22<05:46, 244.86it/s]  6%|▌         | 5245/90000 [00:22<05:47, 244.18it/s]  6%|▌         | 5270/90000 [00:22<05:47, 243.63it/s]  6%|▌         | 5295/90000 [00:22<05:54, 238.99it/s]  6%|▌         | 5320/90000 [00:22<05:51, 240.81it/s]  6%|▌         | 5345/90000 [00:22<05:49, 242.25it/s]  6%|▌         | 5370/90000 [00:22<05:49, 241.84it/s]  6%|▌         | 5396/90000 [00:22<05:44, 245.83it/s]  6%|▌         | 5422/90000 [00:23<05:42, 246.65it/s]  6%|▌         | 5447/90000 [00:23<05:46, 244.01it/s]  6%|▌         | 5472/90000 [00:23<05:51, 240.75it/s]  6%|▌         | 5497/90000 [00:23<05:49, 241.89it/s]  6%|▌         | 5522/90000 [00:23<05:48, 242.32it/s]  6%|▌         | 5547/90000 [00:23<05:48, 242.01it/s]  6%|▌         | 5572/90000 [00:23<05:46, 243.52it/s]  6%|▌         | 5597/90000 [00:23<05:47, 242.77it/s]  6%|▌         | 5622/90000 [00:23<05:50, 240.81it/s]  6%|▋         | 5648/90000 [00:23<05:47, 242.67it/s]  6%|▋         | 5673/90000 [00:24<05:53, 238.44it/s]  6%|▋         | 5698/90000 [00:24<05:51, 239.66it/s]  6%|▋         | 5722/90000 [00:24<05:52, 239.17it/s]  6%|▋         | 5748/90000 [00:24<05:45, 243.72it/s]  6%|▋         | 5773/90000 [00:24<05:47, 242.55it/s]  6%|▋         | 5798/90000 [00:24<05:47, 242.14it/s]  6%|▋         | 5824/90000 [00:24<05:42, 245.87it/s]  6%|▋         | 5849/90000 [00:24<05:45, 243.70it/s]  7%|▋         | 5874/90000 [00:24<05:47, 242.38it/s]  7%|▋         | 5900/90000 [00:25<05:41, 246.19it/s]  7%|▋         | 5925/90000 [00:25<05:44, 244.25it/s]  7%|▋         | 5950/90000 [00:25<05:42, 245.75it/s]  7%|▋         | 5975/90000 [00:25<05:46, 242.40it/s]  7%|▋         | 6000/90000 [00:25<05:45, 243.38it/s]  7%|▋         | 6025/90000 [00:25<05:51, 238.86it/s]  7%|▋         | 6050/90000 [00:25<05:48, 240.80it/s]  7%|▋         | 6075/90000 [00:25<05:46, 241.99it/s]  7%|▋         | 6100/90000 [00:25<05:45, 243.16it/s]  7%|▋         | 6125/90000 [00:25<05:47, 241.49it/s]  7%|▋         | 6150/90000 [00:26<05:48, 240.65it/s]  7%|▋         | 6175/90000 [00:26<05:44, 243.19it/s]  7%|▋         | 6200/90000 [00:26<05:46, 241.90it/s]  7%|▋         | 6225/90000 [00:26<05:44, 243.08it/s]  7%|▋         | 6251/90000 [00:26<05:40, 245.67it/s]  7%|▋         | 6276/90000 [00:26<05:45, 242.61it/s]  7%|▋         | 6301/90000 [00:26<05:43, 243.92it/s]  7%|▋         | 6326/90000 [00:26<05:41, 244.67it/s]  7%|▋         | 6351/90000 [00:26<05:48, 240.09it/s]  7%|▋         | 6376/90000 [00:26<05:47, 240.90it/s]  7%|▋         | 6401/90000 [00:27<05:47, 240.57it/s]  7%|▋         | 6426/90000 [00:27<05:50, 238.54it/s]  7%|▋         | 6452/90000 [00:27<05:41, 244.32it/s]  7%|▋         | 6477/90000 [00:27<05:42, 243.90it/s]  7%|▋         | 6503/90000 [00:27<05:40, 245.10it/s]  7%|▋         | 6528/90000 [00:27<05:41, 244.50it/s]  7%|▋         | 6553/90000 [00:27<05:42, 243.40it/s]  7%|▋         | 6578/90000 [00:27<05:42, 243.36it/s]  7%|▋         | 6603/90000 [00:27<05:44, 242.41it/s]  7%|▋         | 6628/90000 [00:28<05:44, 241.73it/s]  7%|▋         | 6653/90000 [00:28<05:44, 242.22it/s]  7%|▋         | 6678/90000 [00:28<05:42, 243.23it/s]  7%|▋         | 6703/90000 [00:28<05:43, 242.57it/s]  7%|▋         | 6728/90000 [00:28<05:45, 241.03it/s]  8%|▊         | 6753/90000 [00:28<05:48, 239.03it/s]  8%|▊         | 6779/90000 [00:28<05:42, 242.83it/s]  8%|▊         | 6805/90000 [00:28<05:40, 244.28it/s]  8%|▊         | 6830/90000 [00:28<05:40, 244.02it/s]  8%|▊         | 6855/90000 [00:28<05:40, 244.32it/s]  8%|▊         | 6880/90000 [00:29<05:41, 243.42it/s]  8%|▊         | 6905/90000 [00:29<05:43, 241.66it/s]  8%|▊         | 6930/90000 [00:29<05:41, 242.97it/s]  8%|▊         | 6956/90000 [00:29<05:37, 245.75it/s]  8%|▊         | 6981/90000 [00:29<05:39, 244.78it/s]  8%|▊         | 7006/90000 [00:29<05:44, 240.70it/s]  8%|▊         | 7031/90000 [00:29<05:45, 240.29it/s]  8%|▊         | 7056/90000 [00:29<05:45, 239.75it/s]  8%|▊         | 7081/90000 [00:29<05:44, 240.75it/s]  8%|▊         | 7106/90000 [00:29<05:46, 239.54it/s]  8%|▊         | 7130/90000 [00:30<05:49, 237.29it/s]  8%|▊         | 7154/90000 [00:30<05:48, 237.71it/s]  8%|▊         | 7179/90000 [00:30<05:47, 238.60it/s]  8%|▊         | 7204/90000 [00:30<05:42, 241.52it/s]  8%|▊         | 7229/90000 [00:30<05:40, 243.26it/s]  8%|▊         | 7254/90000 [00:30<05:41, 242.54it/s]  8%|▊         | 7279/90000 [00:30<05:40, 242.83it/s]  8%|▊         | 7305/90000 [00:30<05:36, 246.00it/s]  8%|▊         | 7330/90000 [00:30<05:42, 241.55it/s]  8%|▊         | 7355/90000 [00:31<05:48, 237.13it/s]  8%|▊         | 7381/90000 [00:31<05:41, 242.14it/s]  8%|▊         | 7406/90000 [00:31<05:43, 240.66it/s]  8%|▊         | 7431/90000 [00:31<05:49, 236.43it/s]  8%|▊         | 7455/90000 [00:31<05:48, 236.72it/s]  8%|▊         | 7480/90000 [00:31<05:43, 239.92it/s]  8%|▊         | 7505/90000 [00:31<05:46, 237.92it/s]  8%|▊         | 7530/90000 [00:31<05:43, 239.93it/s]  8%|▊         | 7555/90000 [00:31<05:44, 239.06it/s]  8%|▊         | 7579/90000 [00:31<05:46, 237.99it/s]  8%|▊         | 7604/90000 [00:32<05:42, 240.83it/s]  8%|▊         | 7629/90000 [00:32<05:44, 239.00it/s]  9%|▊         | 7654/90000 [00:32<05:40, 242.05it/s]  9%|▊         | 7679/90000 [00:32<05:40, 241.92it/s]  9%|▊         | 7704/90000 [00:32<05:38, 243.27it/s]  9%|▊         | 7729/90000 [00:32<05:42, 240.02it/s]  9%|▊         | 7754/90000 [00:32<05:46, 237.50it/s]  9%|▊         | 7780/90000 [00:32<05:39, 242.02it/s]  9%|▊         | 7805/90000 [00:32<05:36, 243.96it/s]  9%|▊         | 7830/90000 [00:32<05:38, 242.85it/s]  9%|▊         | 7855/90000 [00:33<05:36, 244.34it/s]  9%|▉         | 7880/90000 [00:33<05:36, 243.83it/s]  9%|▉         | 7906/90000 [00:33<05:32, 246.89it/s]  9%|▉         | 7932/90000 [00:33<05:30, 247.98it/s]  9%|▉         | 7957/90000 [00:33<05:31, 247.28it/s]  9%|▉         | 7982/90000 [00:33<05:33, 246.15it/s]  9%|▉         | 8007/90000 [00:33<05:33, 245.86it/s]  9%|▉         | 8032/90000 [00:33<05:33, 245.53it/s]  9%|▉         | 8057/90000 [00:33<05:36, 243.21it/s]  9%|▉         | 8082/90000 [00:34<05:40, 240.80it/s]  9%|▉         | 8107/90000 [00:34<05:37, 242.43it/s]  9%|▉         | 8132/90000 [00:34<05:36, 243.27it/s]  9%|▉         | 8157/90000 [00:34<05:38, 241.50it/s]  9%|▉         | 8182/90000 [00:34<05:38, 241.52it/s]  9%|▉         | 8207/90000 [00:34<05:38, 241.49it/s]  9%|▉         | 8232/90000 [00:34<05:37, 242.35it/s]  9%|▉         | 8257/90000 [00:34<05:38, 241.63it/s]  9%|▉         | 8282/90000 [00:34<05:41, 239.44it/s]  9%|▉         | 8307/90000 [00:34<05:38, 241.04it/s]  9%|▉         | 8332/90000 [00:35<05:39, 240.52it/s]  9%|▉         | 8357/90000 [00:35<05:35, 243.15it/s]  9%|▉         | 8382/90000 [00:35<05:35, 243.59it/s]  9%|▉         | 8407/90000 [00:35<05:37, 241.93it/s]  9%|▉         | 8432/90000 [00:35<05:35, 243.31it/s]  9%|▉         | 8457/90000 [00:35<05:34, 243.63it/s]  9%|▉         | 8482/90000 [00:35<05:35, 243.26it/s]  9%|▉         | 8507/90000 [00:35<05:36, 242.18it/s]  9%|▉         | 8532/90000 [00:35<05:35, 243.14it/s] 10%|▉         | 8557/90000 [00:35<05:42, 238.07it/s] 10%|▉         | 8583/90000 [00:36<05:37, 241.38it/s] 10%|▉         | 8608/90000 [00:36<05:38, 240.52it/s] 10%|▉         | 8633/90000 [00:36<05:37, 241.18it/s] 10%|▉         | 8658/90000 [00:36<05:35, 242.20it/s] 10%|▉         | 8684/90000 [00:36<05:32, 244.74it/s] 10%|▉         | 8709/90000 [00:36<05:32, 244.26it/s] 10%|▉         | 8734/90000 [00:36<05:35, 241.94it/s] 10%|▉         | 8759/90000 [00:36<05:41, 237.92it/s] 10%|▉         | 8785/90000 [00:36<05:36, 241.54it/s] 10%|▉         | 8810/90000 [00:37<05:35, 242.14it/s] 10%|▉         | 8835/90000 [00:37<05:32, 244.30it/s] 10%|▉         | 8860/90000 [00:37<05:32, 244.23it/s] 10%|▉         | 8885/90000 [00:37<05:35, 241.76it/s] 10%|▉         | 8910/90000 [00:37<05:37, 240.61it/s] 10%|▉         | 8935/90000 [00:37<05:36, 241.01it/s] 10%|▉         | 8960/90000 [00:37<05:37, 240.45it/s] 10%|▉         | 8985/90000 [00:37<05:36, 240.49it/s] 10%|█         | 9010/90000 [00:37<05:33, 242.62it/s] 10%|█         | 9035/90000 [00:37<05:31, 244.45it/s] 10%|█         | 9060/90000 [00:38<05:34, 242.13it/s] 10%|█         | 9085/90000 [00:38<05:33, 242.94it/s] 10%|█         | 9110/90000 [00:38<05:37, 239.97it/s] 10%|█         | 9135/90000 [00:38<05:35, 241.00it/s] 10%|█         | 9160/90000 [00:38<05:36, 240.28it/s] 10%|█         | 9185/90000 [00:38<05:32, 242.87it/s] 10%|█         | 9210/90000 [00:38<05:32, 242.65it/s] 10%|█         | 9235/90000 [00:38<05:34, 241.16it/s] 10%|█         | 9260/90000 [00:38<05:33, 241.81it/s] 10%|█         | 9286/90000 [00:38<05:28, 245.50it/s] 10%|█         | 9311/90000 [00:39<05:29, 245.10it/s] 10%|█         | 9337/90000 [00:39<05:25, 247.53it/s] 10%|█         | 9363/90000 [00:39<05:25, 247.96it/s] 10%|█         | 9389/90000 [00:39<05:23, 249.54it/s] 10%|█         | 9415/90000 [00:39<05:22, 249.85it/s] 10%|█         | 9441/90000 [00:39<05:19, 251.95it/s] 11%|█         | 9467/90000 [00:39<05:23, 248.57it/s] 11%|█         | 9493/90000 [00:39<05:22, 249.60it/s] 11%|█         | 9519/90000 [00:39<05:21, 250.08it/s] 11%|█         | 9545/90000 [00:40<05:22, 249.67it/s] 11%|█         | 9570/90000 [00:40<05:22, 249.13it/s] 11%|█         | 9595/90000 [00:40<05:26, 245.96it/s] 11%|█         | 9620/90000 [00:40<05:29, 244.23it/s] 11%|█         | 9645/90000 [00:40<05:33, 240.71it/s] 11%|█         | 9670/90000 [00:40<05:31, 242.24it/s] 11%|█         | 9695/90000 [00:40<05:30, 243.21it/s] 11%|█         | 9720/90000 [00:40<05:30, 242.57it/s] 11%|█         | 9745/90000 [00:40<05:27, 244.71it/s] 11%|█         | 9770/90000 [00:40<05:30, 242.40it/s] 11%|█         | 9795/90000 [00:41<05:32, 241.15it/s] 11%|█         | 9820/90000 [00:41<05:29, 243.35it/s] 11%|█         | 9845/90000 [00:41<05:28, 243.93it/s] 11%|█         | 9870/90000 [00:41<05:26, 245.61it/s] 11%|█         | 9895/90000 [00:41<05:27, 244.87it/s] 11%|█         | 9920/90000 [00:41<05:28, 244.01it/s] 11%|█         | 9945/90000 [00:41<05:30, 242.35it/s] 11%|█         | 9970/90000 [00:41<05:31, 241.12it/s] 11%|█         | 9995/90000 [00:41<05:31, 241.21it/s] 11%|█         | 10020/90000 [00:42<05:37, 237.31it/s] 11%|█         | 10044/90000 [00:42<05:39, 235.60it/s] 11%|█         | 10069/90000 [00:42<05:35, 237.91it/s] 11%|█         | 10096/90000 [00:42<05:26, 244.89it/s] 11%|█         | 10121/90000 [00:42<05:27, 243.75it/s] 11%|█▏        | 10146/90000 [00:42<05:34, 238.39it/s] 11%|█▏        | 10170/90000 [00:42<05:35, 238.20it/s] 11%|█▏        | 10196/90000 [00:42<05:28, 242.85it/s] 11%|█▏        | 10221/90000 [00:42<05:26, 244.27it/s] 11%|█▏        | 10247/90000 [00:42<05:21, 247.73it/s] 11%|█▏        | 10272/90000 [00:43<05:25, 245.27it/s] 11%|█▏        | 10297/90000 [00:43<05:23, 246.46it/s] 11%|█▏        | 10323/90000 [00:43<05:23, 246.66it/s] 11%|█▏        | 10348/90000 [00:43<05:23, 246.00it/s] 12%|█▏        | 10373/90000 [00:43<05:25, 244.55it/s] 12%|█▏        | 10398/90000 [00:43<05:24, 245.53it/s] 12%|█▏        | 10423/90000 [00:43<05:28, 242.17it/s] 12%|█▏        | 10449/90000 [00:43<05:25, 244.58it/s] 12%|█▏        | 10475/90000 [00:43<05:22, 246.36it/s] 12%|█▏        | 10500/90000 [00:43<05:22, 246.65it/s] 12%|█▏        | 10525/90000 [00:44<05:28, 242.24it/s] 12%|█▏        | 10550/90000 [00:44<05:30, 240.44it/s] 12%|█▏        | 10575/90000 [00:44<05:27, 242.56it/s] 12%|█▏        | 10600/90000 [00:44<05:28, 241.99it/s] 12%|█▏        | 10625/90000 [00:44<05:31, 239.63it/s] 12%|█▏        | 10649/90000 [00:44<05:33, 237.84it/s] 12%|█▏        | 10674/90000 [00:44<05:30, 240.05it/s] 12%|█▏        | 10699/90000 [00:44<05:30, 239.61it/s] 12%|█▏        | 10723/90000 [00:44<05:31, 239.47it/s] 12%|█▏        | 10748/90000 [00:44<05:27, 242.20it/s] 12%|█▏        | 10773/90000 [00:45<05:30, 239.72it/s] 12%|█▏        | 10797/90000 [00:45<05:31, 238.83it/s] 12%|█▏        | 10821/90000 [00:45<05:33, 237.28it/s] 12%|█▏        | 10845/90000 [00:45<05:35, 236.18it/s] 12%|█▏        | 10870/90000 [00:45<05:30, 239.54it/s] 12%|█▏        | 10894/90000 [00:45<05:32, 237.56it/s] 12%|█▏        | 10919/90000 [00:45<05:30, 239.44it/s] 12%|█▏        | 10944/90000 [00:45<05:28, 240.68it/s] 12%|█▏        | 10969/90000 [00:45<05:25, 243.15it/s] 12%|█▏        | 10994/90000 [00:46<05:23, 243.98it/s] 12%|█▏        | 11020/90000 [00:46<05:20, 246.57it/s] 12%|█▏        | 11045/90000 [00:46<05:21, 245.84it/s] 12%|█▏        | 11070/90000 [00:46<05:22, 245.07it/s] 12%|█▏        | 11095/90000 [00:46<05:20, 246.25it/s] 12%|█▏        | 11120/90000 [00:46<05:19, 247.03it/s] 12%|█▏        | 11145/90000 [00:46<05:23, 243.44it/s] 12%|█▏        | 11170/90000 [00:46<05:26, 241.78it/s] 12%|█▏        | 11195/90000 [00:46<05:22, 244.16it/s] 12%|█▏        | 11220/90000 [00:46<05:30, 238.06it/s] 12%|█▏        | 11245/90000 [00:47<05:28, 239.46it/s] 13%|█▎        | 11271/90000 [00:47<05:22, 244.16it/s] 13%|█▎        | 11297/90000 [00:47<05:21, 245.14it/s] 13%|█▎        | 11322/90000 [00:47<05:21, 244.92it/s] 13%|█▎        | 11347/90000 [00:47<05:19, 245.80it/s] 13%|█▎        | 11372/90000 [00:47<05:19, 245.72it/s] 13%|█▎        | 11397/90000 [00:47<05:19, 246.03it/s] 13%|█▎        | 11422/90000 [00:47<05:23, 243.13it/s] 13%|█▎        | 11448/90000 [00:47<05:18, 246.56it/s] 13%|█▎        | 11473/90000 [00:47<05:25, 241.25it/s] 13%|█▎        | 11498/90000 [00:48<05:25, 241.19it/s] 13%|█▎        | 11523/90000 [00:48<05:22, 243.65it/s] 13%|█▎        | 11548/90000 [00:48<05:21, 243.98it/s] 13%|█▎        | 11573/90000 [00:48<05:21, 243.99it/s] 13%|█▎        | 11599/90000 [00:48<05:18, 246.23it/s] 13%|█▎        | 11624/90000 [00:48<05:23, 242.63it/s] 13%|█▎        | 11649/90000 [00:48<05:27, 239.09it/s] 13%|█▎        | 11673/90000 [00:48<05:30, 236.99it/s] 13%|█▎        | 11697/90000 [00:48<05:30, 236.71it/s] 13%|█▎        | 11722/90000 [00:49<05:26, 239.70it/s] 13%|█▎        | 11747/90000 [00:49<05:22, 242.58it/s] 13%|█▎        | 11772/90000 [00:49<05:22, 242.32it/s] 13%|█▎        | 11797/90000 [00:49<05:21, 243.61it/s] 13%|█▎        | 11822/90000 [00:49<05:23, 241.73it/s] 13%|█▎        | 11847/90000 [00:49<05:28, 237.78it/s] 13%|█▎        | 11872/90000 [00:49<05:27, 238.91it/s] 13%|█▎        | 11897/90000 [00:49<05:27, 238.25it/s] 13%|█▎        | 11923/90000 [00:49<05:22, 242.26it/s] 13%|█▎        | 11948/90000 [00:49<05:22, 241.65it/s] 13%|█▎        | 11973/90000 [00:50<05:19, 244.08it/s] 13%|█▎        | 11998/90000 [00:50<05:18, 245.12it/s] 13%|█▎        | 12023/90000 [00:50<05:16, 246.37it/s] 13%|█▎        | 12049/90000 [00:50<05:14, 247.97it/s] 13%|█▎        | 12074/90000 [00:50<05:19, 244.24it/s] 13%|█▎        | 12099/90000 [00:50<05:21, 242.19it/s] 13%|█▎        | 12124/90000 [00:50<05:22, 241.79it/s] 13%|█▎        | 12149/90000 [00:50<05:21, 241.96it/s] 14%|█▎        | 12174/90000 [00:50<05:22, 241.30it/s] 14%|█▎        | 12199/90000 [00:50<05:28, 237.07it/s] 14%|█▎        | 12225/90000 [00:51<05:20, 242.48it/s] 14%|█▎        | 12250/90000 [00:51<05:26, 238.15it/s] 14%|█▎        | 12274/90000 [00:51<05:30, 235.18it/s] 14%|█▎        | 12298/90000 [00:51<05:28, 236.52it/s] 14%|█▎        | 12324/90000 [00:51<05:21, 241.65it/s] 14%|█▎        | 12349/90000 [00:51<05:20, 242.18it/s] 14%|█▎        | 12374/90000 [00:51<05:26, 237.88it/s] 14%|█▍        | 12399/90000 [00:51<05:24, 239.01it/s] 14%|█▍        | 12424/90000 [00:51<05:20, 241.94it/s] 14%|█▍        | 12449/90000 [00:52<05:20, 242.29it/s] 14%|█▍        | 12475/90000 [00:52<05:15, 245.55it/s] 14%|█▍        | 12501/90000 [00:52<05:15, 245.88it/s] 14%|█▍        | 12526/90000 [00:52<05:18, 242.93it/s] 14%|█▍        | 12551/90000 [00:52<05:19, 242.56it/s] 14%|█▍        | 12576/90000 [00:52<05:18, 242.76it/s] 14%|█▍        | 12601/90000 [00:52<05:22, 240.34it/s] 14%|█▍        | 12626/90000 [00:52<05:23, 239.29it/s] 14%|█▍        | 12651/90000 [00:52<05:21, 240.42it/s] 14%|█▍        | 12677/90000 [00:52<05:18, 242.97it/s] 14%|█▍        | 12703/90000 [00:53<05:16, 244.60it/s] 14%|█▍        | 12729/90000 [00:53<05:12, 246.92it/s] 14%|█▍        | 12754/90000 [00:53<05:14, 245.89it/s] 14%|█▍        | 12779/90000 [00:53<05:14, 245.30it/s] 14%|█▍        | 12805/90000 [00:53<05:12, 247.11it/s] 14%|█▍        | 12830/90000 [00:53<05:13, 245.98it/s] 14%|█▍        | 12855/90000 [00:53<05:12, 246.48it/s] 14%|█▍        | 12880/90000 [00:53<05:13, 246.06it/s] 14%|█▍        | 12905/90000 [00:53<05:12, 246.60it/s] 14%|█▍        | 12930/90000 [00:53<05:13, 246.16it/s] 14%|█▍        | 12955/90000 [00:54<05:17, 242.70it/s] 14%|█▍        | 12981/90000 [00:54<05:15, 244.37it/s] 14%|█▍        | 13006/90000 [00:54<05:16, 242.95it/s] 14%|█▍        | 13033/90000 [00:54<05:08, 249.09it/s] 15%|█▍        | 13059/90000 [00:54<05:08, 249.73it/s] 15%|█▍        | 13084/90000 [00:54<05:12, 245.88it/s] 15%|█▍        | 13109/90000 [00:54<05:16, 242.99it/s] 15%|█▍        | 13134/90000 [00:54<05:16, 243.24it/s] 15%|█▍        | 13159/90000 [00:54<05:18, 240.97it/s] 15%|█▍        | 13184/90000 [00:55<05:22, 238.26it/s] 15%|█▍        | 13208/90000 [00:55<05:25, 235.92it/s] 15%|█▍        | 13232/90000 [00:55<05:25, 235.79it/s] 15%|█▍        | 13257/90000 [00:55<05:20, 239.64it/s] 15%|█▍        | 13282/90000 [00:55<05:16, 242.27it/s] 15%|█▍        | 13307/90000 [00:55<05:15, 242.75it/s] 15%|█▍        | 13332/90000 [00:55<05:16, 242.31it/s] 15%|█▍        | 13357/90000 [00:55<05:20, 239.24it/s] 15%|█▍        | 13382/90000 [00:55<05:19, 239.98it/s] 15%|█▍        | 13408/90000 [00:55<05:14, 243.46it/s] 15%|█▍        | 13434/90000 [00:56<05:11, 245.93it/s] 15%|█▍        | 13459/90000 [00:56<05:14, 243.38it/s] 15%|█▍        | 13484/90000 [00:56<05:14, 243.67it/s] 15%|█▌        | 13509/90000 [00:56<05:12, 244.75it/s] 15%|█▌        | 13534/90000 [00:56<05:13, 243.97it/s] 15%|█▌        | 13559/90000 [00:56<05:13, 243.65it/s] 15%|█▌        | 13584/90000 [00:56<05:16, 241.69it/s] 15%|█▌        | 13609/90000 [00:56<05:13, 243.69it/s] 15%|█▌        | 13634/90000 [00:56<05:16, 241.45it/s] 15%|█▌        | 13659/90000 [00:57<05:17, 240.65it/s] 15%|█▌        | 13684/90000 [00:57<05:17, 240.19it/s] 15%|█▌        | 13709/90000 [00:57<05:17, 240.08it/s] 15%|█▌        | 13734/90000 [00:57<05:20, 237.99it/s] 15%|█▌        | 13758/90000 [00:57<05:20, 237.67it/s] 15%|█▌        | 13784/90000 [00:57<05:15, 241.72it/s] 15%|█▌        | 13809/90000 [00:57<05:14, 242.18it/s] 15%|█▌        | 13834/90000 [00:57<05:13, 242.64it/s] 15%|█▌        | 13860/90000 [00:57<05:10, 245.06it/s] 15%|█▌        | 13885/90000 [00:57<05:11, 244.58it/s] 15%|█▌        | 13910/90000 [00:58<05:10, 244.87it/s] 15%|█▌        | 13935/90000 [00:58<05:13, 242.39it/s] 16%|█▌        | 13960/90000 [00:58<05:23, 234.94it/s] 16%|█▌        | 13985/90000 [00:58<05:20, 236.83it/s] 16%|█▌        | 14010/90000 [00:58<05:17, 239.00it/s] 16%|█▌        | 14034/90000 [00:58<05:18, 238.29it/s] 16%|█▌        | 14058/90000 [00:58<05:20, 236.85it/s] 16%|█▌        | 14082/90000 [00:58<05:23, 234.97it/s] 16%|█▌        | 14107/90000 [00:58<05:19, 237.73it/s] 16%|█▌        | 14132/90000 [00:58<05:15, 240.23it/s] 16%|█▌        | 14157/90000 [00:59<05:13, 241.95it/s] 16%|█▌        | 14182/90000 [00:59<05:11, 243.74it/s] 16%|█▌        | 14207/90000 [00:59<05:12, 242.48it/s] 16%|█▌        | 14232/90000 [00:59<05:13, 241.83it/s] 16%|█▌        | 14257/90000 [00:59<05:14, 240.93it/s] 16%|█▌        | 14282/90000 [00:59<05:15, 239.62it/s] 16%|█▌        | 14307/90000 [00:59<05:15, 240.12it/s] 16%|█▌        | 14332/90000 [00:59<05:16, 239.20it/s] 16%|█▌        | 14356/90000 [00:59<05:17, 238.55it/s] 16%|█▌        | 14380/90000 [01:00<05:18, 237.20it/s] 16%|█▌        | 14405/90000 [01:00<05:15, 239.79it/s] 16%|█▌        | 14430/90000 [01:00<05:14, 240.11it/s] 16%|█▌        | 14455/90000 [01:00<05:11, 242.52it/s] 16%|█▌        | 14480/90000 [01:00<05:09, 243.94it/s] 16%|█▌        | 14505/90000 [01:00<05:11, 242.27it/s] 16%|█▌        | 14531/90000 [01:00<05:07, 245.46it/s] 16%|█▌        | 14557/90000 [01:00<05:05, 246.73it/s] 16%|█▌        | 14582/90000 [01:00<05:04, 247.29it/s] 16%|█▌        | 14607/90000 [01:00<05:05, 246.57it/s] 16%|█▋        | 14632/90000 [01:01<05:08, 244.54it/s] 16%|█▋        | 14658/90000 [01:01<05:05, 246.66it/s] 16%|█▋        | 14683/90000 [01:01<05:06, 245.53it/s] 16%|█▋        | 14708/90000 [01:01<05:06, 245.77it/s] 16%|█▋        | 14733/90000 [01:01<05:06, 245.73it/s] 16%|█▋        | 14759/90000 [01:01<05:03, 247.99it/s] 16%|█▋        | 14784/90000 [01:01<05:06, 245.53it/s] 16%|█▋        | 14809/90000 [01:01<05:07, 244.73it/s] 16%|█▋        | 14834/90000 [01:01<05:08, 243.58it/s] 17%|█▋        | 14859/90000 [01:01<05:12, 240.56it/s] 17%|█▋        | 14884/90000 [01:02<05:20, 234.18it/s] 17%|█▋        | 14908/90000 [01:02<05:19, 235.07it/s] 17%|█▋        | 14932/90000 [01:02<05:17, 236.38it/s] 17%|█▋        | 14957/90000 [01:02<05:15, 237.55it/s] 17%|█▋        | 14981/90000 [01:02<05:17, 236.21it/s] 17%|█▋        | 15006/90000 [01:02<05:15, 237.92it/s] 17%|█▋        | 15031/90000 [01:02<05:11, 240.49it/s] 17%|█▋        | 15056/90000 [01:02<05:10, 241.36it/s] 17%|█▋        | 15081/90000 [01:02<05:11, 240.47it/s] 17%|█▋        | 15106/90000 [01:03<05:11, 240.16it/s] 17%|█▋        | 15131/90000 [01:03<05:14, 237.70it/s] 17%|█▋        | 15156/90000 [01:03<05:12, 239.57it/s] 17%|█▋        | 15181/90000 [01:03<05:10, 240.84it/s] 17%|█▋        | 15206/90000 [01:03<05:09, 241.47it/s] 17%|█▋        | 15231/90000 [01:03<05:10, 240.83it/s] 17%|█▋        | 15256/90000 [01:03<05:11, 240.09it/s] 17%|█▋        | 15281/90000 [01:03<05:13, 238.06it/s] 17%|█▋        | 15306/90000 [01:03<05:12, 239.29it/s] 17%|█▋        | 15331/90000 [01:03<05:11, 239.88it/s] 17%|█▋        | 15355/90000 [01:04<05:11, 239.59it/s] 17%|█▋        | 15380/90000 [01:04<05:08, 241.87it/s] 17%|█▋        | 15405/90000 [01:04<05:12, 238.83it/s] 17%|█▋        | 15429/90000 [01:04<05:15, 236.61it/s] 17%|█▋        | 15453/90000 [01:04<05:16, 235.82it/s] 17%|█▋        | 15479/90000 [01:04<05:09, 241.10it/s] 17%|█▋        | 15504/90000 [01:04<05:07, 241.96it/s] 17%|█▋        | 15530/90000 [01:04<05:03, 245.08it/s] 17%|█▋        | 15555/90000 [01:04<05:04, 244.11it/s] 17%|█▋        | 15580/90000 [01:04<05:06, 243.15it/s] 17%|█▋        | 15605/90000 [01:05<05:05, 243.47it/s] 17%|█▋        | 15631/90000 [01:05<05:00, 247.20it/s] 17%|█▋        | 15656/90000 [01:05<04:59, 247.86it/s] 17%|█▋        | 15681/90000 [01:05<05:03, 244.98it/s] 17%|█▋        | 15706/90000 [01:05<05:04, 243.74it/s] 17%|█▋        | 15731/90000 [01:05<05:05, 243.19it/s] 18%|█▊        | 15757/90000 [01:05<05:02, 245.79it/s] 18%|█▊        | 15782/90000 [01:05<05:07, 241.26it/s] 18%|█▊        | 15807/90000 [01:05<05:08, 240.15it/s] 18%|█▊        | 15832/90000 [01:06<05:08, 240.68it/s] 18%|█▊        | 15857/90000 [01:06<05:08, 240.44it/s] 18%|█▊        | 15882/90000 [01:06<05:06, 241.66it/s] 18%|█▊        | 15907/90000 [01:06<05:06, 241.52it/s] 18%|█▊        | 15932/90000 [01:06<05:12, 237.04it/s] 18%|█▊        | 15957/90000 [01:06<05:08, 240.17it/s] 18%|█▊        | 15982/90000 [01:06<05:07, 240.64it/s] 18%|█▊        | 16007/90000 [01:06<05:05, 242.59it/s] 18%|█▊        | 16033/90000 [01:06<05:02, 244.89it/s] 18%|█▊        | 16058/90000 [01:06<05:08, 239.74it/s] 18%|█▊        | 16083/90000 [01:07<05:12, 236.39it/s] 18%|█▊        | 16108/90000 [01:07<05:08, 239.26it/s] 18%|█▊        | 16132/90000 [01:07<05:13, 235.74it/s] 18%|█▊        | 16157/90000 [01:07<05:07, 239.81it/s] 18%|█▊        | 16182/90000 [01:07<05:10, 237.88it/s] 18%|█▊        | 16207/90000 [01:07<05:08, 239.51it/s] 18%|█▊        | 16233/90000 [01:07<05:01, 245.07it/s] 18%|█▊        | 16258/90000 [01:07<05:02, 243.50it/s] 18%|█▊        | 16283/90000 [01:07<05:03, 242.57it/s] 18%|█▊        | 16309/90000 [01:07<04:59, 245.77it/s] 18%|█▊        | 16334/90000 [01:08<05:02, 243.52it/s] 18%|█▊        | 16359/90000 [01:08<05:04, 241.87it/s] 18%|█▊        | 16384/90000 [01:08<05:01, 244.18it/s] 18%|█▊        | 16409/90000 [01:08<05:02, 243.22it/s] 18%|█▊        | 16435/90000 [01:08<05:00, 245.11it/s] 18%|█▊        | 16460/90000 [01:08<05:00, 245.04it/s] 18%|█▊        | 16485/90000 [01:08<05:01, 244.12it/s] 18%|█▊        | 16510/90000 [01:08<05:01, 243.84it/s] 18%|█▊        | 16535/90000 [01:08<05:03, 241.73it/s] 18%|█▊        | 16560/90000 [01:09<05:06, 239.58it/s] 18%|█▊        | 16585/90000 [01:09<05:04, 241.17it/s] 18%|█▊        | 16610/90000 [01:09<05:02, 242.31it/s] 18%|█▊        | 16635/90000 [01:09<05:04, 241.13it/s] 19%|█▊        | 16660/90000 [01:09<05:03, 241.85it/s] 19%|█▊        | 16685/90000 [01:09<05:04, 240.48it/s] 19%|█▊        | 16710/90000 [01:09<05:01, 242.78it/s] 19%|█▊        | 16736/90000 [01:09<04:57, 246.01it/s] 19%|█▊        | 16761/90000 [01:09<04:58, 245.35it/s] 19%|█▊        | 16786/90000 [01:09<04:56, 246.59it/s] 19%|█▊        | 16811/90000 [01:10<04:58, 244.80it/s] 19%|█▊        | 16837/90000 [01:10<04:56, 246.62it/s] 19%|█▊        | 16862/90000 [01:10<04:55, 247.45it/s] 19%|█▉        | 16888/90000 [01:10<04:54, 248.41it/s] 19%|█▉        | 16913/90000 [01:10<04:57, 245.42it/s] 19%|█▉        | 16938/90000 [01:10<04:56, 246.37it/s] 19%|█▉        | 16963/90000 [01:10<04:59, 243.55it/s] 19%|█▉        | 16988/90000 [01:10<05:00, 243.31it/s] 19%|█▉        | 17013/90000 [01:10<05:01, 242.43it/s] 19%|█▉        | 17038/90000 [01:10<04:59, 243.76it/s] 19%|█▉        | 17063/90000 [01:11<04:58, 244.64it/s] 19%|█▉        | 17088/90000 [01:11<04:56, 245.65it/s] 19%|█▉        | 17113/90000 [01:11<04:57, 245.29it/s] 19%|█▉        | 17138/90000 [01:11<05:00, 242.79it/s] 19%|█▉        | 17163/90000 [01:11<04:57, 244.87it/s] 19%|█▉        | 17189/90000 [01:11<04:53, 248.18it/s] 19%|█▉        | 17214/90000 [01:11<04:58, 243.63it/s] 19%|█▉        | 17239/90000 [01:11<05:00, 242.36it/s] 19%|█▉        | 17264/90000 [01:11<05:05, 237.84it/s] 19%|█▉        | 17289/90000 [01:12<05:03, 239.23it/s] 19%|█▉        | 17314/90000 [01:12<05:01, 241.00it/s] 19%|█▉        | 17341/90000 [01:12<04:54, 246.99it/s] 19%|█▉        | 17366/90000 [01:12<05:02, 239.78it/s] 19%|█▉        | 17391/90000 [01:12<05:00, 242.03it/s] 19%|█▉        | 17417/90000 [01:12<04:53, 247.04it/s] 19%|█▉        | 17442/90000 [01:12<04:57, 243.67it/s] 19%|█▉        | 17467/90000 [01:12<05:02, 239.86it/s] 19%|█▉        | 17492/90000 [01:12<05:03, 238.83it/s] 19%|█▉        | 17517/90000 [01:12<05:00, 241.59it/s] 19%|█▉        | 17542/90000 [01:13<04:58, 242.99it/s] 20%|█▉        | 17567/90000 [01:13<05:07, 235.21it/s] 20%|█▉        | 17591/90000 [01:13<05:06, 235.92it/s] 20%|█▉        | 17615/90000 [01:13<05:08, 234.98it/s] 20%|█▉        | 17640/90000 [01:13<05:04, 237.95it/s] 20%|█▉        | 17664/90000 [01:13<05:06, 236.37it/s] 20%|█▉        | 17689/90000 [01:13<05:02, 238.86it/s] 20%|█▉        | 17713/90000 [01:13<05:03, 237.91it/s] 20%|█▉        | 17737/90000 [01:13<05:08, 234.28it/s] 20%|█▉        | 17762/90000 [01:13<05:02, 238.66it/s] 20%|█▉        | 17786/90000 [01:14<05:03, 237.80it/s] 20%|█▉        | 17811/90000 [01:14<05:01, 239.15it/s] 20%|█▉        | 17837/90000 [01:14<04:56, 243.40it/s] 20%|█▉        | 17862/90000 [01:14<04:56, 243.71it/s] 20%|█▉        | 17887/90000 [01:14<04:59, 240.68it/s] 20%|█▉        | 17912/90000 [01:14<04:59, 240.59it/s] 20%|█▉        | 17937/90000 [01:14<05:04, 236.61it/s] 20%|█▉        | 17962/90000 [01:14<05:00, 239.53it/s] 20%|█▉        | 17987/90000 [01:14<04:59, 240.80it/s] 20%|██        | 18012/90000 [01:15<04:58, 241.08it/s] 20%|██        | 18037/90000 [01:15<04:59, 240.60it/s] 20%|██        | 18062/90000 [01:15<04:58, 240.81it/s] 20%|██        | 18087/90000 [01:15<04:59, 239.74it/s] 20%|██        | 18111/90000 [01:15<05:02, 237.90it/s] 20%|██        | 18135/90000 [01:15<05:02, 237.92it/s] 20%|██        | 18160/90000 [01:15<05:00, 239.07it/s] 20%|██        | 18186/90000 [01:15<04:55, 242.62it/s] 20%|██        | 18211/90000 [01:15<04:58, 240.22it/s] 20%|██        | 18237/90000 [01:15<04:54, 243.61it/s] 20%|██        | 18262/90000 [01:16<04:58, 240.64it/s] 20%|██        | 18287/90000 [01:16<04:59, 239.55it/s] 20%|██        | 18311/90000 [01:16<04:59, 239.59it/s] 20%|██        | 18335/90000 [01:16<05:00, 238.54it/s] 20%|██        | 18360/90000 [01:16<04:58, 240.34it/s] 20%|██        | 18385/90000 [01:16<05:01, 237.30it/s] 20%|██        | 18409/90000 [01:16<05:00, 237.98it/s] 20%|██        | 18433/90000 [01:16<05:00, 238.12it/s] 21%|██        | 18458/90000 [01:16<04:56, 241.31it/s] 21%|██        | 18483/90000 [01:16<04:54, 242.77it/s] 21%|██        | 18508/90000 [01:17<04:57, 240.01it/s] 21%|██        | 18533/90000 [01:17<05:00, 237.48it/s] 21%|██        | 18559/90000 [01:17<04:55, 241.42it/s] 21%|██        | 18584/90000 [01:17<04:56, 240.59it/s] 21%|██        | 18609/90000 [01:17<04:55, 241.78it/s] 21%|██        | 18634/90000 [01:17<04:56, 240.54it/s] 21%|██        | 18659/90000 [01:17<04:57, 240.12it/s] 21%|██        | 18684/90000 [01:17<04:54, 242.53it/s] 21%|██        | 18709/90000 [01:17<04:54, 241.90it/s] 21%|██        | 18734/90000 [01:18<04:52, 243.82it/s] 21%|██        | 18759/90000 [01:18<04:55, 241.34it/s] 21%|██        | 18784/90000 [01:18<04:57, 239.52it/s] 21%|██        | 18808/90000 [01:18<05:02, 235.03it/s] 21%|██        | 18832/90000 [01:18<05:01, 235.94it/s] 21%|██        | 18857/90000 [01:18<04:58, 238.67it/s] 21%|██        | 18881/90000 [01:18<04:58, 238.48it/s] 21%|██        | 18906/90000 [01:18<04:55, 240.48it/s] 21%|██        | 18931/90000 [01:18<04:54, 241.19it/s] 21%|██        | 18956/90000 [01:18<04:59, 237.20it/s] 21%|██        | 18981/90000 [01:19<04:56, 239.74it/s] 21%|██        | 19005/90000 [01:19<05:01, 235.09it/s] 21%|██        | 19029/90000 [01:19<05:01, 235.12it/s] 21%|██        | 19053/90000 [01:19<05:06, 231.30it/s] 21%|██        | 19077/90000 [01:19<05:07, 230.76it/s] 21%|██        | 19101/90000 [01:19<05:07, 230.26it/s] 21%|██▏       | 19126/90000 [01:19<05:03, 233.56it/s] 21%|██▏       | 19150/90000 [01:19<05:02, 233.95it/s] 21%|██▏       | 19174/90000 [01:19<05:02, 234.03it/s] 21%|██▏       | 19198/90000 [01:20<05:02, 233.75it/s] 21%|██▏       | 19224/90000 [01:20<04:57, 238.30it/s] 21%|██▏       | 19249/90000 [01:20<04:53, 241.27it/s] 21%|██▏       | 19275/90000 [01:20<04:49, 244.61it/s] 21%|██▏       | 19300/90000 [01:20<04:48, 244.72it/s] 21%|██▏       | 19325/90000 [01:20<04:51, 242.82it/s] 22%|██▏       | 19350/90000 [01:20<04:58, 236.98it/s] 22%|██▏       | 19374/90000 [01:20<04:56, 237.83it/s] 22%|██▏       | 19398/90000 [01:20<04:58, 236.22it/s] 22%|██▏       | 19422/90000 [01:20<04:58, 236.40it/s] 22%|██▏       | 19447/90000 [01:21<04:54, 239.84it/s] 22%|██▏       | 19471/90000 [01:21<04:54, 239.33it/s] 22%|██▏       | 19495/90000 [01:21<04:55, 238.64it/s] 22%|██▏       | 19521/90000 [01:21<04:50, 242.42it/s] 22%|██▏       | 19546/90000 [01:21<04:51, 241.57it/s] 22%|██▏       | 19571/90000 [01:21<04:57, 236.49it/s] 22%|██▏       | 19595/90000 [01:21<04:58, 235.87it/s] 22%|██▏       | 19619/90000 [01:21<05:00, 234.29it/s] 22%|██▏       | 19644/90000 [01:21<04:55, 238.43it/s] 22%|██▏       | 19668/90000 [01:21<04:58, 235.63it/s] 22%|██▏       | 19693/90000 [01:22<04:56, 237.44it/s] 22%|██▏       | 19718/90000 [01:22<04:52, 240.11it/s] 22%|██▏       | 19743/90000 [01:22<04:56, 237.03it/s] 22%|██▏       | 19767/90000 [01:22<04:59, 234.39it/s] 22%|██▏       | 19791/90000 [01:22<04:57, 235.94it/s] 22%|██▏       | 19815/90000 [01:22<05:00, 233.73it/s] 22%|██▏       | 19839/90000 [01:22<04:59, 234.30it/s] 22%|██▏       | 19864/90000 [01:22<04:56, 236.54it/s] 22%|██▏       | 19888/90000 [01:22<04:55, 237.47it/s] 22%|██▏       | 19912/90000 [01:23<04:57, 235.94it/s] 22%|██▏       | 19937/90000 [01:23<04:53, 238.49it/s] 22%|██▏       | 19962/90000 [01:23<04:52, 239.73it/s] 22%|██▏       | 19986/90000 [01:23<04:52, 239.13it/s] 22%|██▏       | 20011/90000 [01:23<04:52, 239.44it/s] 22%|██▏       | 20036/90000 [01:23<04:51, 240.10it/s] 22%|██▏       | 20061/90000 [01:23<04:53, 238.65it/s] 22%|██▏       | 20086/90000 [01:23<04:52, 239.09it/s] 22%|██▏       | 20112/90000 [01:23<04:47, 243.22it/s] 22%|██▏       | 20139/90000 [01:23<04:41, 248.54it/s] 22%|██▏       | 20164/90000 [01:24<04:41, 248.02it/s] 22%|██▏       | 20189/90000 [01:24<04:41, 247.86it/s] 22%|██▏       | 20214/90000 [01:24<04:45, 244.79it/s] 22%|██▏       | 20239/90000 [01:24<04:46, 243.86it/s] 23%|██▎       | 20265/90000 [01:24<04:42, 246.53it/s] 23%|██▎       | 20290/90000 [01:24<04:41, 247.33it/s] 23%|██▎       | 20315/90000 [01:24<04:45, 244.31it/s] 23%|██▎       | 20340/90000 [01:24<04:49, 240.89it/s] 23%|██▎       | 20365/90000 [01:24<04:49, 240.45it/s] 23%|██▎       | 20391/90000 [01:24<04:46, 243.34it/s] 23%|██▎       | 20416/90000 [01:25<04:45, 243.94it/s] 23%|██▎       | 20441/90000 [01:25<04:45, 243.73it/s] 23%|██▎       | 20466/90000 [01:25<04:50, 239.45it/s] 23%|██▎       | 20490/90000 [01:25<04:54, 236.40it/s] 23%|██▎       | 20514/90000 [01:25<04:58, 233.11it/s] 23%|██▎       | 20539/90000 [01:25<04:56, 234.56it/s] 23%|██▎       | 20563/90000 [01:25<04:58, 232.79it/s] 23%|██▎       | 20587/90000 [01:25<04:55, 234.59it/s] 23%|██▎       | 20611/90000 [01:25<04:54, 235.30it/s] 23%|██▎       | 20636/90000 [01:26<04:52, 237.30it/s] 23%|██▎       | 20660/90000 [01:26<04:51, 237.62it/s] 23%|██▎       | 20686/90000 [01:26<04:45, 242.39it/s] 23%|██▎       | 20711/90000 [01:26<04:47, 240.59it/s] 23%|██▎       | 20736/90000 [01:26<04:51, 237.41it/s] 23%|██▎       | 20761/90000 [01:26<04:49, 238.93it/s] 23%|██▎       | 20786/90000 [01:26<04:46, 241.29it/s] 23%|██▎       | 20811/90000 [01:26<04:44, 243.46it/s] 23%|██▎       | 20836/90000 [01:26<04:47, 240.43it/s] 23%|██▎       | 20861/90000 [01:26<04:44, 242.98it/s] 23%|██▎       | 20886/90000 [01:27<04:44, 243.30it/s] 23%|██▎       | 20911/90000 [01:27<04:49, 238.92it/s] 23%|██▎       | 20936/90000 [01:27<04:48, 239.04it/s] 23%|██▎       | 20961/90000 [01:27<04:48, 239.54it/s] 23%|██▎       | 20986/90000 [01:27<04:45, 241.58it/s] 23%|██▎       | 21012/90000 [01:27<04:43, 243.66it/s] 23%|██▎       | 21037/90000 [01:27<04:45, 241.45it/s] 23%|██▎       | 21062/90000 [01:27<04:49, 238.46it/s] 23%|██▎       | 21087/90000 [01:27<04:46, 240.47it/s] 23%|██▎       | 21112/90000 [01:27<04:48, 238.73it/s] 23%|██▎       | 21136/90000 [01:28<04:48, 238.95it/s] 24%|██▎       | 21160/90000 [01:28<04:48, 239.01it/s] 24%|██▎       | 21185/90000 [01:28<04:44, 241.68it/s] 24%|██▎       | 21210/90000 [01:28<04:46, 239.93it/s] 24%|██▎       | 21235/90000 [01:28<04:51, 235.80it/s] 24%|██▎       | 21260/90000 [01:28<04:51, 236.12it/s] 24%|██▎       | 21285/90000 [01:28<04:46, 240.03it/s] 24%|██▎       | 21310/90000 [01:28<04:45, 240.52it/s] 24%|██▎       | 21335/90000 [01:28<04:42, 243.08it/s] 24%|██▎       | 21360/90000 [01:29<04:40, 245.08it/s] 24%|██▍       | 21385/90000 [01:29<04:44, 241.06it/s] 24%|██▍       | 21410/90000 [01:29<04:45, 240.59it/s] 24%|██▍       | 21435/90000 [01:29<04:45, 239.95it/s] 24%|██▍       | 21460/90000 [01:29<04:43, 241.35it/s] 24%|██▍       | 21485/90000 [01:29<04:47, 237.94it/s] 24%|██▍       | 21510/90000 [01:29<04:45, 239.87it/s] 24%|██▍       | 21535/90000 [01:29<04:43, 241.76it/s] 24%|██▍       | 21560/90000 [01:29<04:44, 240.51it/s] 24%|██▍       | 21586/90000 [01:29<04:40, 244.14it/s] 24%|██▍       | 21611/90000 [01:30<04:44, 240.12it/s] 24%|██▍       | 21636/90000 [01:30<04:43, 240.79it/s] 24%|██▍       | 21661/90000 [01:30<04:44, 240.61it/s] 24%|██▍       | 21686/90000 [01:30<04:50, 234.93it/s] 24%|██▍       | 21711/90000 [01:30<04:48, 236.84it/s] 24%|██▍       | 21736/90000 [01:30<04:46, 238.61it/s] 24%|██▍       | 21760/90000 [01:30<04:48, 236.36it/s] 24%|██▍       | 21784/90000 [01:30<04:48, 236.34it/s] 24%|██▍       | 21808/90000 [01:30<04:51, 233.95it/s] 24%|██▍       | 21833/90000 [01:30<04:47, 236.83it/s] 24%|██▍       | 21857/90000 [01:31<04:55, 230.89it/s] 24%|██▍       | 21882/90000 [01:31<04:50, 234.23it/s] 24%|██▍       | 21907/90000 [01:31<04:46, 237.54it/s] 24%|██▍       | 21933/90000 [01:31<04:41, 241.49it/s] 24%|██▍       | 21958/90000 [01:31<04:40, 242.90it/s] 24%|██▍       | 21983/90000 [01:31<04:42, 241.13it/s] 24%|██▍       | 22008/90000 [01:31<04:39, 243.60it/s] 24%|██▍       | 22033/90000 [01:31<04:44, 238.59it/s] 25%|██▍       | 22059/90000 [01:31<04:40, 242.45it/s] 25%|██▍       | 22084/90000 [01:32<04:44, 238.53it/s] 25%|██▍       | 22108/90000 [01:32<04:44, 238.87it/s] 25%|██▍       | 22133/90000 [01:32<04:41, 241.13it/s] 25%|██▍       | 22158/90000 [01:32<04:39, 242.35it/s] 25%|██▍       | 22184/90000 [01:32<04:35, 246.35it/s] 25%|██▍       | 22209/90000 [01:32<04:41, 240.74it/s] 25%|██▍       | 22234/90000 [01:32<04:42, 239.66it/s] 25%|██▍       | 22259/90000 [01:32<04:39, 242.00it/s] 25%|██▍       | 22284/90000 [01:32<04:39, 242.61it/s] 25%|██▍       | 22309/90000 [01:32<04:38, 243.44it/s] 25%|██▍       | 22334/90000 [01:33<04:38, 242.96it/s] 25%|██▍       | 22359/90000 [01:33<04:40, 241.20it/s] 25%|██▍       | 22384/90000 [01:33<04:38, 242.91it/s] 25%|██▍       | 22409/90000 [01:33<04:39, 242.15it/s] 25%|██▍       | 22434/90000 [01:33<04:38, 242.97it/s] 25%|██▍       | 22459/90000 [01:33<04:38, 242.69it/s] 25%|██▍       | 22484/90000 [01:33<04:42, 238.76it/s] 25%|██▌       | 22509/90000 [01:33<04:39, 241.74it/s] 25%|██▌       | 22534/90000 [01:33<04:40, 240.63it/s] 25%|██▌       | 22559/90000 [01:34<04:39, 241.37it/s] 25%|██▌       | 22584/90000 [01:34<04:39, 241.58it/s] 25%|██▌       | 22609/90000 [01:34<04:43, 237.69it/s] 25%|██▌       | 22634/90000 [01:34<04:43, 237.92it/s] 25%|██▌       | 22658/90000 [01:34<04:43, 237.21it/s] 25%|██▌       | 22682/90000 [01:34<04:44, 236.46it/s] 25%|██▌       | 22707/90000 [01:34<04:41, 239.11it/s] 25%|██▌       | 22732/90000 [01:34<04:40, 239.81it/s] 25%|██▌       | 22757/90000 [01:34<04:38, 241.38it/s] 25%|██▌       | 22782/90000 [01:34<04:42, 237.75it/s] 25%|██▌       | 22807/90000 [01:35<04:39, 240.39it/s] 25%|██▌       | 22833/90000 [01:35<04:34, 244.35it/s] 25%|██▌       | 22858/90000 [01:35<04:34, 244.51it/s] 25%|██▌       | 22884/90000 [01:35<04:31, 246.81it/s] 25%|██▌       | 22909/90000 [01:35<04:32, 246.08it/s] 25%|██▌       | 22934/90000 [01:35<04:33, 244.88it/s] 26%|██▌       | 22959/90000 [01:35<04:34, 244.63it/s] 26%|██▌       | 22984/90000 [01:35<04:39, 239.43it/s] 26%|██▌       | 23009/90000 [01:35<04:38, 240.64it/s] 26%|██▌       | 23034/90000 [01:35<04:39, 239.90it/s] 26%|██▌       | 23060/90000 [01:36<04:35, 242.58it/s] 26%|██▌       | 23085/90000 [01:36<04:33, 244.63it/s] 26%|██▌       | 23110/90000 [01:36<04:34, 244.08it/s] 26%|██▌       | 23136/90000 [01:36<04:31, 246.01it/s] 26%|██▌       | 23161/90000 [01:36<04:39, 238.81it/s] 26%|██▌       | 23185/90000 [01:36<04:41, 237.65it/s] 26%|██▌       | 23210/90000 [01:36<04:38, 240.17it/s] 26%|██▌       | 23235/90000 [01:36<04:39, 238.63it/s] 26%|██▌       | 23259/90000 [01:36<04:40, 238.00it/s] 26%|██▌       | 23284/90000 [01:37<04:38, 239.44it/s] 26%|██▌       | 23308/90000 [01:37<05:02, 220.14it/s] 26%|██▌       | 23331/90000 [01:37<05:17, 210.11it/s] 26%|██▌       | 23356/90000 [01:37<05:05, 218.08it/s] 26%|██▌       | 23380/90000 [01:37<04:59, 222.70it/s] 26%|██▌       | 23405/90000 [01:37<04:49, 230.03it/s] 26%|██▌       | 23430/90000 [01:37<04:43, 234.69it/s] 26%|██▌       | 23454/90000 [01:37<04:42, 235.57it/s] 26%|██▌       | 23479/90000 [01:37<04:39, 238.23it/s] 26%|██▌       | 23505/90000 [01:37<04:34, 242.53it/s] 26%|██▌       | 23530/90000 [01:38<04:35, 241.10it/s] 26%|██▌       | 23555/90000 [01:38<04:33, 242.53it/s] 26%|██▌       | 23580/90000 [01:38<04:40, 236.68it/s] 26%|██▌       | 23604/90000 [01:38<04:44, 233.58it/s] 26%|██▋       | 23629/90000 [01:38<04:39, 237.11it/s] 26%|██▋       | 23655/90000 [01:38<04:34, 241.45it/s] 26%|██▋       | 23680/90000 [01:38<04:34, 241.79it/s] 26%|██▋       | 23705/90000 [01:38<04:34, 241.73it/s] 26%|██▋       | 23730/90000 [01:38<04:32, 243.11it/s] 26%|██▋       | 23755/90000 [01:39<04:33, 241.93it/s] 26%|██▋       | 23780/90000 [01:39<04:37, 238.91it/s] 26%|██▋       | 23804/90000 [01:39<04:37, 238.77it/s] 26%|██▋       | 23829/90000 [01:39<04:35, 239.79it/s] 27%|██▋       | 23853/90000 [01:39<04:37, 238.16it/s] 27%|██▋       | 23878/90000 [01:39<04:33, 241.46it/s] 27%|██▋       | 23904/90000 [01:39<04:30, 243.91it/s] 27%|██▋       | 23929/90000 [01:39<04:38, 237.29it/s] 27%|██▋       | 23954/90000 [01:39<04:36, 238.53it/s] 27%|██▋       | 23978/90000 [01:39<04:37, 237.51it/s] 27%|██▋       | 24002/90000 [01:40<04:39, 236.25it/s] 27%|██▋       | 24026/90000 [01:40<04:40, 235.16it/s] 27%|██▋       | 24052/90000 [01:40<04:34, 240.31it/s] 27%|██▋       | 24077/90000 [01:40<04:35, 239.35it/s] 27%|██▋       | 24102/90000 [01:40<04:33, 240.68it/s] 27%|██▋       | 24127/90000 [01:40<04:33, 241.16it/s] 27%|██▋       | 24152/90000 [01:40<04:32, 241.24it/s] 27%|██▋       | 24177/90000 [01:40<04:32, 241.83it/s] 27%|██▋       | 24202/90000 [01:40<04:32, 241.09it/s] 27%|██▋       | 24227/90000 [01:41<04:39, 235.42it/s] 27%|██▋       | 24252/90000 [01:41<04:35, 238.34it/s] 27%|██▋       | 24276/90000 [01:41<04:42, 232.56it/s] 27%|██▋       | 24301/90000 [01:41<04:37, 236.75it/s] 27%|██▋       | 24325/90000 [01:41<04:39, 235.27it/s] 27%|██▋       | 24349/90000 [01:41<04:43, 231.72it/s] 27%|██▋       | 24374/90000 [01:41<04:38, 235.58it/s] 27%|██▋       | 24398/90000 [01:41<04:42, 232.62it/s] 27%|██▋       | 24422/90000 [01:41<04:44, 230.53it/s] 27%|██▋       | 24446/90000 [01:41<04:45, 229.36it/s] 27%|██▋       | 24470/90000 [01:42<04:43, 230.77it/s] 27%|██▋       | 24495/90000 [01:42<04:38, 234.98it/s] 27%|██▋       | 24519/90000 [01:42<04:39, 234.63it/s] 27%|██▋       | 24543/90000 [01:42<04:41, 232.12it/s] 27%|██▋       | 24567/90000 [01:42<04:42, 231.84it/s] 27%|██▋       | 24591/90000 [01:42<04:41, 232.35it/s] 27%|██▋       | 24615/90000 [01:42<04:42, 231.28it/s] 27%|██▋       | 24639/90000 [01:42<04:40, 233.28it/s] 27%|██▋       | 24664/90000 [01:42<04:37, 235.76it/s] 27%|██▋       | 24688/90000 [01:42<04:35, 236.83it/s] 27%|██▋       | 24712/90000 [01:43<04:35, 236.92it/s] 27%|██▋       | 24737/90000 [01:43<04:32, 239.84it/s] 28%|██▊       | 24761/90000 [01:43<04:33, 238.80it/s] 28%|██▊       | 24785/90000 [01:43<04:35, 236.56it/s] 28%|██▊       | 24810/90000 [01:43<04:33, 238.76it/s] 28%|██▊       | 24834/90000 [01:43<04:36, 235.48it/s] 28%|██▊       | 24858/90000 [01:43<04:37, 235.12it/s] 28%|██▊       | 24882/90000 [01:43<04:37, 234.99it/s] 28%|██▊       | 24907/90000 [01:43<04:35, 236.08it/s] 28%|██▊       | 24932/90000 [01:44<04:34, 236.82it/s] 28%|██▊       | 24957/90000 [01:44<04:32, 239.01it/s] 28%|██▊       | 24981/90000 [01:44<04:34, 237.28it/s] 28%|██▊       | 25007/90000 [01:44<04:29, 241.41it/s] 28%|██▊       | 25032/90000 [01:44<04:28, 242.02it/s] 28%|██▊       | 25057/90000 [01:44<04:28, 241.99it/s] 28%|██▊       | 25082/90000 [01:44<04:28, 242.03it/s] 28%|██▊       | 25108/90000 [01:44<04:24, 245.16it/s] 28%|██▊       | 25133/90000 [01:44<04:26, 243.64it/s] 28%|██▊       | 25159/90000 [01:44<04:24, 245.11it/s] 28%|██▊       | 25184/90000 [01:45<04:27, 242.19it/s] 28%|██▊       | 25209/90000 [01:45<04:34, 236.03it/s] 28%|██▊       | 25233/90000 [01:45<04:36, 234.40it/s] 28%|██▊       | 25257/90000 [01:45<04:40, 230.46it/s] 28%|██▊       | 25281/90000 [01:45<04:39, 231.39it/s] 28%|██▊       | 25305/90000 [01:45<04:39, 231.31it/s] 28%|██▊       | 25329/90000 [01:45<04:40, 230.18it/s] 28%|██▊       | 25353/90000 [01:45<04:43, 227.69it/s] 28%|██▊       | 25377/90000 [01:45<04:41, 229.92it/s] 28%|██▊       | 25401/90000 [01:45<04:44, 227.34it/s] 28%|██▊       | 25426/90000 [01:46<04:37, 232.63it/s] 28%|██▊       | 25451/90000 [01:46<04:34, 235.33it/s] 28%|██▊       | 25475/90000 [01:46<04:34, 234.84it/s] 28%|██▊       | 25499/90000 [01:46<04:33, 235.66it/s] 28%|██▊       | 25523/90000 [01:46<04:32, 236.45it/s] 28%|██▊       | 25547/90000 [01:46<04:32, 236.72it/s] 28%|██▊       | 25571/90000 [01:46<04:36, 232.67it/s] 28%|██▊       | 25596/90000 [01:46<04:32, 235.91it/s] 28%|██▊       | 25621/90000 [01:46<04:30, 238.19it/s] 28%|██▊       | 25647/90000 [01:47<04:23, 244.16it/s] 29%|██▊       | 25672/90000 [01:47<04:26, 241.66it/s] 29%|██▊       | 25697/90000 [01:47<04:28, 239.63it/s] 29%|██▊       | 25721/90000 [01:47<04:32, 235.79it/s] 29%|██▊       | 25746/90000 [01:47<04:30, 237.81it/s] 29%|██▊       | 25771/90000 [01:47<04:27, 240.09it/s] 29%|██▊       | 25796/90000 [01:47<04:32, 235.98it/s] 29%|██▊       | 25821/90000 [01:47<04:30, 237.57it/s] 29%|██▊       | 25845/90000 [01:47<04:33, 234.82it/s] 29%|██▊       | 25870/90000 [01:47<04:29, 237.53it/s] 29%|██▉       | 25894/90000 [01:48<04:29, 237.56it/s] 29%|██▉       | 25918/90000 [01:48<04:29, 237.42it/s] 29%|██▉       | 25942/90000 [01:48<04:31, 235.66it/s] 29%|██▉       | 25967/90000 [01:48<04:28, 238.66it/s] 29%|██▉       | 25993/90000 [01:48<04:24, 242.25it/s] 29%|██▉       | 26018/90000 [01:48<04:27, 239.24it/s] 29%|██▉       | 26042/90000 [01:48<04:29, 236.97it/s] 29%|██▉       | 26066/90000 [01:48<04:29, 237.17it/s] 29%|██▉       | 26090/90000 [01:48<04:28, 237.93it/s] 29%|██▉       | 26115/90000 [01:48<04:27, 239.03it/s] 29%|██▉       | 26139/90000 [01:49<04:28, 237.69it/s] 29%|██▉       | 26163/90000 [01:49<04:28, 237.91it/s] 29%|██▉       | 26187/90000 [01:49<04:28, 237.23it/s] 29%|██▉       | 26211/90000 [01:49<04:28, 237.55it/s] 29%|██▉       | 26236/90000 [01:49<04:27, 238.56it/s] 29%|██▉       | 26260/90000 [01:49<04:27, 238.46it/s] 29%|██▉       | 26284/90000 [01:49<04:29, 236.25it/s] 29%|██▉       | 26308/90000 [01:49<04:29, 236.57it/s] 29%|██▉       | 26332/90000 [01:49<04:29, 236.29it/s] 29%|██▉       | 26357/90000 [01:50<04:26, 238.85it/s] 29%|██▉       | 26382/90000 [01:50<04:23, 241.40it/s] 29%|██▉       | 26407/90000 [01:50<04:22, 242.28it/s] 29%|██▉       | 26432/90000 [01:50<04:21, 242.74it/s] 29%|██▉       | 26458/90000 [01:50<04:19, 244.97it/s] 29%|██▉       | 26483/90000 [01:50<04:24, 240.53it/s] 29%|██▉       | 26508/90000 [01:50<04:23, 240.77it/s] 29%|██▉       | 26533/90000 [01:50<04:28, 236.82it/s] 30%|██▉       | 26557/90000 [01:50<04:27, 237.13it/s] 30%|██▉       | 26581/90000 [01:50<04:26, 237.71it/s] 30%|██▉       | 26606/90000 [01:51<04:26, 237.96it/s] 30%|██▉       | 26630/90000 [01:51<04:26, 237.56it/s] 30%|██▉       | 26655/90000 [01:51<04:23, 240.26it/s] 30%|██▉       | 26680/90000 [01:51<04:21, 242.42it/s] 30%|██▉       | 26705/90000 [01:51<04:23, 240.47it/s] 30%|██▉       | 26730/90000 [01:51<04:24, 238.93it/s] 30%|██▉       | 26754/90000 [01:51<04:25, 238.25it/s] 30%|██▉       | 26778/90000 [01:51<04:27, 236.24it/s] 30%|██▉       | 26802/90000 [01:51<04:26, 237.18it/s] 30%|██▉       | 26828/90000 [01:51<04:22, 240.92it/s] 30%|██▉       | 26853/90000 [01:52<04:22, 240.98it/s] 30%|██▉       | 26878/90000 [01:52<04:21, 241.30it/s] 30%|██▉       | 26903/90000 [01:52<04:20, 242.46it/s] 30%|██▉       | 26928/90000 [01:52<04:23, 239.37it/s] 30%|██▉       | 26952/90000 [01:52<04:26, 236.63it/s] 30%|██▉       | 26977/90000 [01:52<04:23, 239.62it/s] 30%|███       | 27001/90000 [01:52<04:24, 238.49it/s] 30%|███       | 27025/90000 [01:52<04:24, 238.16it/s] 30%|███       | 27050/90000 [01:52<04:22, 239.43it/s] 30%|███       | 27074/90000 [01:53<04:23, 238.46it/s] 30%|███       | 27098/90000 [01:53<04:25, 237.30it/s] 30%|███       | 27122/90000 [01:53<04:26, 235.68it/s] 30%|███       | 27146/90000 [01:53<04:25, 236.66it/s] 30%|███       | 27171/90000 [01:53<04:23, 238.78it/s] 30%|███       | 27195/90000 [01:53<04:24, 237.29it/s] 30%|███       | 27220/90000 [01:53<04:23, 238.69it/s] 30%|███       | 27244/90000 [01:53<04:22, 239.05it/s] 30%|███       | 27269/90000 [01:53<04:21, 240.32it/s] 30%|███       | 27294/90000 [01:53<04:18, 242.77it/s] 30%|███       | 27319/90000 [01:54<04:17, 242.99it/s] 30%|███       | 27344/90000 [01:54<04:19, 241.11it/s] 30%|███       | 27369/90000 [01:54<04:20, 240.36it/s] 30%|███       | 27395/90000 [01:54<04:16, 243.98it/s] 30%|███       | 27420/90000 [01:54<04:17, 242.88it/s] 30%|███       | 27445/90000 [01:54<04:18, 242.23it/s] 31%|███       | 27470/90000 [01:54<04:17, 242.38it/s] 31%|███       | 27496/90000 [01:54<04:14, 245.47it/s] 31%|███       | 27521/90000 [01:54<04:14, 245.13it/s] 31%|███       | 27546/90000 [01:54<04:20, 239.54it/s] 31%|███       | 27570/90000 [01:55<04:21, 239.05it/s] 31%|███       | 27595/90000 [01:55<04:19, 240.68it/s] 31%|███       | 27620/90000 [01:55<04:22, 238.05it/s] 31%|███       | 27644/90000 [01:55<04:24, 236.09it/s] 31%|███       | 27670/90000 [01:55<04:17, 242.44it/s] 31%|███       | 27695/90000 [01:55<04:14, 244.64it/s] 31%|███       | 27720/90000 [01:55<04:13, 245.79it/s] 31%|███       | 27745/90000 [01:55<04:17, 241.97it/s] 31%|███       | 27770/90000 [01:55<04:16, 242.38it/s] 31%|███       | 27795/90000 [01:55<04:19, 239.76it/s] 31%|███       | 27820/90000 [01:56<04:17, 241.44it/s] 31%|███       | 27845/90000 [01:56<04:18, 240.73it/s] 31%|███       | 27870/90000 [01:56<04:23, 235.52it/s] 31%|███       | 27894/90000 [01:56<04:23, 235.53it/s] 31%|███       | 27918/90000 [01:56<04:24, 234.78it/s] 31%|███       | 27944/90000 [01:56<04:18, 239.72it/s] 31%|███       | 27968/90000 [01:56<04:20, 238.13it/s] 31%|███       | 27992/90000 [01:56<04:22, 236.37it/s] 31%|███       | 28017/90000 [01:56<04:19, 239.02it/s] 31%|███       | 28041/90000 [01:57<04:23, 234.86it/s] 31%|███       | 28066/90000 [01:57<04:21, 237.04it/s] 31%|███       | 28090/90000 [01:57<04:20, 237.21it/s] 31%|███       | 28115/90000 [01:57<04:19, 238.69it/s] 31%|███▏      | 28140/90000 [01:57<04:16, 240.95it/s] 31%|███▏      | 28165/90000 [01:57<04:19, 238.52it/s] 31%|███▏      | 28189/90000 [01:57<04:23, 234.74it/s] 31%|███▏      | 28213/90000 [01:57<04:22, 235.21it/s] 31%|███▏      | 28238/90000 [01:57<04:21, 235.94it/s] 31%|███▏      | 28262/90000 [01:57<04:20, 236.88it/s] 31%|███▏      | 28286/90000 [01:58<04:22, 235.51it/s] 31%|███▏      | 28311/90000 [01:58<04:19, 237.32it/s] 31%|███▏      | 28336/90000 [01:58<04:16, 240.06it/s] 32%|███▏      | 28361/90000 [01:58<04:16, 240.76it/s] 32%|███▏      | 28386/90000 [01:58<04:17, 239.31it/s] 32%|███▏      | 28411/90000 [01:58<04:15, 241.10it/s] 32%|███▏      | 28436/90000 [01:58<04:19, 237.47it/s] 32%|███▏      | 28460/90000 [01:58<04:21, 234.92it/s] 32%|███▏      | 28484/90000 [01:58<04:24, 232.85it/s] 32%|███▏      | 28509/90000 [01:59<04:19, 237.41it/s] 32%|███▏      | 28534/90000 [01:59<04:18, 237.49it/s] 32%|███▏      | 28558/90000 [01:59<04:18, 237.45it/s] 32%|███▏      | 28582/90000 [01:59<04:19, 236.32it/s] 32%|███▏      | 28607/90000 [01:59<04:15, 240.18it/s] 32%|███▏      | 28632/90000 [01:59<04:17, 238.72it/s] 32%|███▏      | 28657/90000 [01:59<04:14, 241.19it/s] 32%|███▏      | 28682/90000 [01:59<04:19, 236.31it/s] 32%|███▏      | 28707/90000 [01:59<04:16, 238.60it/s] 32%|███▏      | 28732/90000 [01:59<04:14, 240.46it/s] 32%|███▏      | 28757/90000 [02:00<04:14, 240.40it/s] 32%|███▏      | 28783/90000 [02:00<04:10, 244.39it/s] 32%|███▏      | 28808/90000 [02:00<04:12, 242.15it/s] 32%|███▏      | 28833/90000 [02:00<04:13, 241.00it/s] 32%|███▏      | 28859/90000 [02:00<04:10, 244.39it/s] 32%|███▏      | 28884/90000 [02:00<04:17, 237.29it/s] 32%|███▏      | 28909/90000 [02:00<04:13, 240.86it/s] 32%|███▏      | 28934/90000 [02:00<04:14, 239.65it/s] 32%|███▏      | 28959/90000 [02:00<04:12, 242.02it/s] 32%|███▏      | 28985/90000 [02:00<04:10, 243.89it/s] 32%|███▏      | 29011/90000 [02:01<04:07, 246.28it/s] 32%|███▏      | 29036/90000 [02:01<04:07, 246.02it/s] 32%|███▏      | 29061/90000 [02:01<04:09, 243.88it/s] 32%|███▏      | 29086/90000 [02:01<04:09, 244.53it/s] 32%|███▏      | 29111/90000 [02:01<04:11, 241.82it/s] 32%|███▏      | 29137/90000 [02:01<04:07, 245.55it/s] 32%|███▏      | 29162/90000 [02:01<04:09, 244.03it/s] 32%|███▏      | 29187/90000 [02:01<04:09, 243.42it/s] 32%|███▏      | 29212/90000 [02:01<04:19, 233.84it/s] 32%|███▏      | 29236/90000 [02:02<04:18, 235.30it/s] 33%|███▎      | 29261/90000 [02:02<04:15, 237.85it/s] 33%|███▎      | 29285/90000 [02:02<04:17, 235.67it/s] 33%|███▎      | 29309/90000 [02:02<04:16, 236.78it/s] 33%|███▎      | 29333/90000 [02:02<04:15, 237.59it/s] 33%|███▎      | 29357/90000 [02:02<04:14, 238.28it/s] 33%|███▎      | 29381/90000 [02:02<04:14, 238.34it/s] 33%|███▎      | 29406/90000 [02:02<04:11, 241.09it/s] 33%|███▎      | 29431/90000 [02:02<04:11, 240.98it/s] 33%|███▎      | 29456/90000 [02:02<04:13, 238.64it/s] 33%|███▎      | 29480/90000 [02:03<04:16, 236.25it/s] 33%|███▎      | 29505/90000 [02:03<04:12, 239.75it/s] 33%|███▎      | 29531/90000 [02:03<04:07, 244.47it/s] 33%|███▎      | 29557/90000 [02:03<04:05, 246.44it/s] 33%|███▎      | 29582/90000 [02:03<04:07, 243.90it/s] 33%|███▎      | 29607/90000 [02:03<04:10, 241.37it/s] 33%|███▎      | 29632/90000 [02:03<04:10, 241.22it/s] 33%|███▎      | 29657/90000 [02:03<04:11, 239.60it/s] 33%|███▎      | 29682/90000 [02:03<04:10, 241.12it/s] 33%|███▎      | 29707/90000 [02:03<04:08, 242.92it/s] 33%|███▎      | 29732/90000 [02:04<04:09, 241.93it/s] 33%|███▎      | 29757/90000 [02:04<04:13, 237.97it/s] 33%|███▎      | 29781/90000 [02:04<04:15, 235.93it/s] 33%|███▎      | 29805/90000 [02:04<04:16, 234.98it/s] 33%|███▎      | 29829/90000 [02:04<04:14, 236.27it/s] 33%|███▎      | 29853/90000 [02:04<04:16, 234.73it/s] 33%|███▎      | 29878/90000 [02:04<04:12, 237.95it/s] 33%|███▎      | 29903/90000 [02:04<04:10, 240.33it/s] 33%|███▎      | 29928/90000 [02:04<04:10, 239.96it/s] 33%|███▎      | 29953/90000 [02:05<04:12, 237.91it/s] 33%|███▎      | 29977/90000 [02:05<04:12, 238.06it/s] 33%|███▎      | 30002/90000 [02:05<04:11, 238.52it/s] 33%|███▎      | 30026/90000 [02:05<04:13, 236.87it/s] 33%|███▎      | 30050/90000 [02:05<04:12, 237.66it/s] 33%|███▎      | 30074/90000 [02:05<04:14, 235.07it/s] 33%|███▎      | 30099/90000 [02:05<04:11, 238.15it/s] 33%|███▎      | 30123/90000 [02:05<04:14, 235.66it/s] 33%|███▎      | 30148/90000 [02:05<04:12, 237.16it/s] 34%|███▎      | 30172/90000 [02:05<04:17, 232.06it/s] 34%|███▎      | 30198/90000 [02:06<04:11, 237.62it/s] 34%|███▎      | 30223/90000 [02:06<04:09, 239.60it/s] 34%|███▎      | 30247/90000 [02:06<04:10, 238.37it/s] 34%|███▎      | 30271/90000 [02:06<04:12, 236.84it/s] 34%|███▎      | 30295/90000 [02:06<04:13, 235.49it/s] 34%|███▎      | 30319/90000 [02:06<04:18, 231.07it/s] 34%|███▎      | 30345/90000 [02:06<04:11, 237.42it/s] 34%|███▎      | 30370/90000 [02:06<04:08, 240.28it/s] 34%|███▍      | 30395/90000 [02:06<04:12, 236.36it/s] 34%|███▍      | 30420/90000 [02:06<04:09, 238.76it/s] 34%|███▍      | 30445/90000 [02:07<04:08, 239.61it/s] 34%|███▍      | 30469/90000 [02:07<04:08, 239.45it/s] 34%|███▍      | 30494/90000 [02:07<04:05, 241.97it/s] 34%|███▍      | 30519/90000 [02:07<04:07, 240.40it/s] 34%|███▍      | 30544/90000 [02:07<04:06, 241.51it/s] 34%|███▍      | 30569/90000 [02:07<04:06, 240.87it/s] 34%|███▍      | 30594/90000 [02:07<04:04, 242.90it/s] 34%|███▍      | 30619/90000 [02:07<04:08, 239.07it/s] 34%|███▍      | 30645/90000 [02:07<04:02, 244.67it/s] 34%|███▍      | 30670/90000 [02:08<04:02, 244.31it/s] 34%|███▍      | 30695/90000 [02:08<04:01, 245.26it/s] 34%|███▍      | 30720/90000 [02:08<04:00, 246.03it/s] 34%|███▍      | 30745/90000 [02:08<04:01, 245.45it/s] 34%|███▍      | 30770/90000 [02:08<04:01, 244.94it/s] 34%|███▍      | 30795/90000 [02:08<04:03, 243.29it/s] 34%|███▍      | 30820/90000 [02:08<04:05, 240.78it/s] 34%|███▍      | 30845/90000 [02:08<04:07, 238.76it/s] 34%|███▍      | 30869/90000 [02:08<04:08, 237.84it/s] 34%|███▍      | 30893/90000 [02:08<04:10, 235.80it/s] 34%|███▍      | 30917/90000 [02:09<04:15, 231.68it/s] 34%|███▍      | 30941/90000 [02:09<04:13, 232.92it/s] 34%|███▍      | 30966/90000 [02:09<04:09, 236.36it/s] 34%|███▍      | 30990/90000 [02:09<04:08, 237.13it/s] 34%|███▍      | 31014/90000 [02:09<04:09, 236.22it/s] 34%|███▍      | 31038/90000 [02:09<04:10, 235.24it/s] 35%|███▍      | 31062/90000 [02:09<04:11, 234.23it/s] 35%|███▍      | 31087/90000 [02:09<04:07, 238.03it/s] 35%|███▍      | 31111/90000 [02:09<04:09, 235.66it/s] 35%|███▍      | 31135/90000 [02:09<04:08, 236.88it/s] 35%|███▍      | 31161/90000 [02:10<04:03, 241.65it/s] 35%|███▍      | 31186/90000 [02:10<04:02, 242.21it/s] 35%|███▍      | 31211/90000 [02:10<04:04, 240.86it/s] 35%|███▍      | 31236/90000 [02:10<04:06, 238.43it/s] 35%|███▍      | 31260/90000 [02:10<04:10, 234.70it/s] 35%|███▍      | 31284/90000 [02:10<04:14, 230.68it/s] 35%|███▍      | 31310/90000 [02:10<04:07, 237.19it/s] 35%|███▍      | 31334/90000 [02:10<04:08, 236.10it/s] 35%|███▍      | 31360/90000 [02:10<04:02, 241.97it/s] 35%|███▍      | 31386/90000 [02:11<03:58, 245.93it/s] 35%|███▍      | 31411/90000 [02:11<04:00, 243.79it/s] 35%|███▍      | 31436/90000 [02:11<03:59, 244.75it/s] 35%|███▍      | 31461/90000 [02:11<03:58, 245.08it/s] 35%|███▍      | 31486/90000 [02:11<04:03, 240.18it/s] 35%|███▌      | 31511/90000 [02:11<04:04, 238.95it/s] 35%|███▌      | 31536/90000 [02:11<04:02, 241.28it/s] 35%|███▌      | 31561/90000 [02:11<04:02, 240.58it/s] 35%|███▌      | 31586/90000 [02:11<04:01, 241.57it/s] 35%|███▌      | 31611/90000 [02:11<04:01, 242.12it/s] 35%|███▌      | 31636/90000 [02:12<04:01, 242.02it/s] 35%|███▌      | 31661/90000 [02:12<03:59, 243.63it/s] 35%|███▌      | 31686/90000 [02:12<03:59, 243.10it/s] 35%|███▌      | 31711/90000 [02:12<04:00, 242.86it/s] 35%|███▌      | 31737/90000 [02:12<03:57, 245.40it/s] 35%|███▌      | 31763/90000 [02:12<03:56, 246.61it/s] 35%|███▌      | 31788/90000 [02:12<03:57, 245.01it/s] 35%|███▌      | 31813/90000 [02:12<03:58, 244.37it/s] 35%|███▌      | 31838/90000 [02:12<03:59, 242.62it/s] 35%|███▌      | 31863/90000 [02:12<04:00, 241.54it/s] 35%|███▌      | 31888/90000 [02:13<03:58, 243.63it/s] 35%|███▌      | 31913/90000 [02:13<04:00, 241.13it/s] 35%|███▌      | 31938/90000 [02:13<04:00, 241.75it/s] 36%|███▌      | 31963/90000 [02:13<04:00, 241.57it/s] 36%|███▌      | 31988/90000 [02:13<04:01, 239.78it/s] 36%|███▌      | 32013/90000 [02:13<04:01, 240.30it/s] 36%|███▌      | 32038/90000 [02:13<04:02, 238.59it/s] 36%|███▌      | 32062/90000 [02:13<04:04, 236.73it/s] 36%|███▌      | 32088/90000 [02:13<03:59, 241.40it/s] 36%|███▌      | 32113/90000 [02:14<03:58, 242.34it/s] 36%|███▌      | 32138/90000 [02:14<03:57, 243.47it/s] 36%|███▌      | 32163/90000 [02:14<03:58, 242.60it/s] 36%|███▌      | 32189/90000 [02:14<03:55, 245.75it/s] 36%|███▌      | 32215/90000 [02:14<03:54, 246.43it/s] 36%|███▌      | 32240/90000 [02:14<04:00, 239.72it/s] 36%|███▌      | 32265/90000 [02:14<03:58, 241.75it/s] 36%|███▌      | 32290/90000 [02:14<04:01, 238.59it/s] 36%|███▌      | 32314/90000 [02:14<04:02, 237.66it/s] 36%|███▌      | 32339/90000 [02:14<04:01, 238.63it/s] 36%|███▌      | 32363/90000 [02:15<04:01, 238.76it/s] 36%|███▌      | 32388/90000 [02:15<03:58, 241.26it/s] 36%|███▌      | 32413/90000 [02:15<03:57, 242.24it/s] 36%|███▌      | 32438/90000 [02:15<04:03, 236.76it/s] 36%|███▌      | 32463/90000 [02:15<04:01, 238.05it/s] 36%|███▌      | 32488/90000 [02:15<04:01, 238.50it/s] 36%|███▌      | 32512/90000 [02:15<04:02, 236.67it/s] 36%|███▌      | 32536/90000 [02:15<04:04, 235.28it/s] 36%|███▌      | 32561/90000 [02:15<04:00, 238.45it/s] 36%|███▌      | 32585/90000 [02:15<04:02, 236.51it/s] 36%|███▌      | 32610/90000 [02:16<04:00, 239.03it/s] 36%|███▋      | 32634/90000 [02:16<04:01, 237.62it/s] 36%|███▋      | 32659/90000 [02:16<03:59, 239.24it/s] 36%|███▋      | 32683/90000 [02:16<04:03, 235.63it/s] 36%|███▋      | 32707/90000 [02:16<04:02, 236.45it/s] 36%|███▋      | 32732/90000 [02:16<03:58, 240.27it/s] 36%|███▋      | 32757/90000 [02:16<03:57, 240.98it/s] 36%|███▋      | 32782/90000 [02:16<03:58, 239.83it/s] 36%|███▋      | 32806/90000 [02:16<03:58, 239.81it/s] 36%|███▋      | 32831/90000 [02:17<03:57, 240.81it/s] 37%|███▋      | 32856/90000 [02:17<03:56, 241.49it/s] 37%|███▋      | 32881/90000 [02:17<03:57, 240.01it/s] 37%|███▋      | 32906/90000 [02:17<04:00, 237.59it/s] 37%|███▋      | 32930/90000 [02:17<04:00, 237.13it/s] 37%|███▋      | 32955/90000 [02:17<03:58, 239.41it/s] 37%|███▋      | 32981/90000 [02:17<03:53, 244.22it/s] 37%|███▋      | 33006/90000 [02:17<03:57, 239.90it/s] 37%|███▋      | 33031/90000 [02:17<03:59, 237.66it/s] 37%|███▋      | 33055/90000 [02:17<04:00, 236.33it/s] 37%|███▋      | 33079/90000 [02:18<04:00, 236.89it/s] 37%|███▋      | 33105/90000 [02:18<03:55, 241.37it/s] 37%|███▋      | 33130/90000 [02:18<03:57, 239.48it/s] 37%|███▋      | 33154/90000 [02:18<03:58, 238.65it/s] 37%|███▋      | 33180/90000 [02:18<03:53, 243.08it/s] 37%|███▋      | 33205/90000 [02:18<03:54, 241.72it/s] 37%|███▋      | 33230/90000 [02:18<03:56, 240.42it/s] 37%|███▋      | 33256/90000 [02:18<03:52, 243.66it/s] 37%|███▋      | 33281/90000 [02:18<03:53, 242.92it/s] 37%|███▋      | 33307/90000 [02:18<03:50, 246.39it/s] 37%|███▋      | 33333/90000 [02:19<03:48, 248.03it/s] 37%|███▋      | 33358/90000 [02:19<03:53, 242.12it/s] 37%|███▋      | 33384/90000 [02:19<03:50, 245.45it/s] 37%|███▋      | 33409/90000 [02:19<03:52, 243.91it/s] 37%|███▋      | 33434/90000 [02:19<03:51, 243.83it/s] 37%|███▋      | 33459/90000 [02:19<03:51, 244.34it/s] 37%|███▋      | 33484/90000 [02:19<03:53, 242.11it/s] 37%|███▋      | 33510/90000 [02:19<03:50, 244.57it/s] 37%|███▋      | 33536/90000 [02:19<03:49, 246.12it/s] 37%|███▋      | 33561/90000 [02:20<03:53, 241.78it/s] 37%|███▋      | 33586/90000 [02:20<03:56, 238.61it/s] 37%|███▋      | 33610/90000 [02:20<03:55, 239.01it/s] 37%|███▋      | 33635/90000 [02:20<03:54, 239.87it/s] 37%|███▋      | 33660/90000 [02:20<03:54, 240.06it/s] 37%|███▋      | 33686/90000 [02:20<03:51, 242.84it/s] 37%|███▋      | 33711/90000 [02:20<03:55, 239.11it/s] 37%|███▋      | 33736/90000 [02:20<03:55, 239.21it/s] 38%|███▊      | 33761/90000 [02:20<03:53, 240.61it/s] 38%|███▊      | 33786/90000 [02:20<03:53, 240.66it/s] 38%|███▊      | 33811/90000 [02:21<03:52, 241.27it/s] 38%|███▊      | 33836/90000 [02:21<04:00, 233.80it/s] 38%|███▊      | 33860/90000 [02:21<03:58, 235.53it/s] 38%|███▊      | 33884/90000 [02:21<03:58, 235.46it/s] 38%|███▊      | 33909/90000 [02:21<03:55, 238.38it/s] 38%|███▊      | 33934/90000 [02:21<03:54, 239.20it/s] 38%|███▊      | 33958/90000 [02:21<03:57, 236.44it/s] 38%|███▊      | 33982/90000 [02:21<03:56, 237.04it/s] 38%|███▊      | 34007/90000 [02:21<03:52, 240.55it/s] 38%|███▊      | 34032/90000 [02:22<03:55, 237.67it/s] 38%|███▊      | 34056/90000 [02:22<03:55, 237.98it/s] 38%|███▊      | 34081/90000 [02:22<03:52, 240.83it/s] 38%|███▊      | 34106/90000 [02:22<03:52, 240.76it/s] 38%|███▊      | 34131/90000 [02:22<03:52, 240.33it/s] 38%|███▊      | 34156/90000 [02:22<03:50, 242.48it/s] 38%|███▊      | 34181/90000 [02:22<04:06, 226.88it/s] 38%|███▊      | 34205/90000 [02:22<04:02, 230.09it/s] 38%|███▊      | 34230/90000 [02:22<03:58, 234.14it/s] 38%|███▊      | 34254/90000 [02:22<03:58, 233.57it/s] 38%|███▊      | 34279/90000 [02:23<03:54, 238.10it/s] 38%|███▊      | 34303/90000 [02:23<03:57, 234.93it/s] 38%|███▊      | 34329/90000 [02:23<03:50, 241.49it/s] 38%|███▊      | 34354/90000 [02:23<03:52, 239.25it/s] 38%|███▊      | 34379/90000 [02:23<03:50, 241.40it/s] 38%|███▊      | 34404/90000 [02:23<03:50, 241.61it/s] 38%|███▊      | 34429/90000 [02:23<03:50, 241.42it/s] 38%|███▊      | 34454/90000 [02:23<03:50, 240.85it/s] 38%|███▊      | 34479/90000 [02:23<03:49, 241.64it/s] 38%|███▊      | 34504/90000 [02:23<03:48, 242.42it/s] 38%|███▊      | 34529/90000 [02:24<03:49, 241.39it/s] 38%|███▊      | 34554/90000 [02:24<03:50, 240.10it/s] 38%|███▊      | 34580/90000 [02:24<03:46, 244.20it/s] 38%|███▊      | 34606/90000 [02:24<03:44, 246.20it/s] 38%|███▊      | 34631/90000 [02:24<03:43, 247.26it/s] 39%|███▊      | 34656/90000 [02:24<03:45, 245.20it/s] 39%|███▊      | 34682/90000 [02:24<03:44, 246.69it/s] 39%|███▊      | 34707/90000 [02:24<03:49, 241.01it/s] 39%|███▊      | 34732/90000 [02:24<03:47, 242.47it/s] 39%|███▊      | 34757/90000 [02:25<03:51, 238.30it/s] 39%|███▊      | 34781/90000 [02:25<03:51, 238.19it/s] 39%|███▊      | 34806/90000 [02:25<03:51, 238.74it/s] 39%|███▊      | 34830/90000 [02:25<03:52, 237.39it/s] 39%|███▊      | 34855/90000 [02:25<03:50, 239.31it/s] 39%|███▉      | 34879/90000 [02:25<03:51, 238.10it/s] 39%|███▉      | 34904/90000 [02:25<03:48, 240.71it/s] 39%|███▉      | 34929/90000 [02:25<03:49, 239.75it/s] 39%|███▉      | 34953/90000 [02:25<03:50, 238.70it/s] 39%|███▉      | 34978/90000 [02:25<03:49, 239.90it/s] 39%|███▉      | 35003/90000 [02:26<03:47, 241.58it/s] 39%|███▉      | 35028/90000 [02:26<03:48, 241.10it/s] 39%|███▉      | 35053/90000 [02:26<03:47, 241.34it/s] 39%|███▉      | 35078/90000 [02:26<03:48, 240.42it/s] 39%|███▉      | 35103/90000 [02:26<03:50, 237.66it/s] 39%|███▉      | 35129/90000 [02:26<03:46, 242.64it/s] 39%|███▉      | 35154/90000 [02:26<03:50, 238.12it/s] 39%|███▉      | 35178/90000 [02:26<03:51, 236.92it/s] 39%|███▉      | 35202/90000 [02:26<03:53, 234.31it/s] 39%|███▉      | 35226/90000 [02:27<03:52, 235.42it/s] 39%|███▉      | 35251/90000 [02:27<03:48, 239.62it/s] 39%|███▉      | 35277/90000 [02:27<03:44, 243.80it/s] 39%|███▉      | 35302/90000 [02:27<03:47, 240.80it/s] 39%|███▉      | 35328/90000 [02:27<03:43, 244.32it/s] 39%|███▉      | 35353/90000 [02:27<03:49, 238.60it/s] 39%|███▉      | 35379/90000 [02:27<03:45, 241.88it/s] 39%|███▉      | 35404/90000 [02:27<03:45, 242.31it/s] 39%|███▉      | 35430/90000 [02:27<03:40, 246.93it/s] 39%|███▉      | 35456/90000 [02:27<03:39, 248.22it/s] 39%|███▉      | 35481/90000 [02:28<03:42, 245.14it/s] 39%|███▉      | 35506/90000 [02:28<03:43, 243.91it/s] 39%|███▉      | 35531/90000 [02:28<03:45, 241.84it/s] 40%|███▉      | 35556/90000 [02:28<03:46, 239.96it/s] 40%|███▉      | 35581/90000 [02:28<03:46, 239.77it/s] 40%|███▉      | 35605/90000 [02:28<03:47, 239.19it/s] 40%|███▉      | 35630/90000 [02:28<03:45, 240.81it/s] 40%|███▉      | 35655/90000 [02:28<03:47, 238.83it/s] 40%|███▉      | 35680/90000 [02:28<03:44, 241.94it/s] 40%|███▉      | 35705/90000 [02:28<03:43, 242.43it/s] 40%|███▉      | 35730/90000 [02:29<03:48, 237.11it/s] 40%|███▉      | 35754/90000 [02:29<03:51, 234.46it/s] 40%|███▉      | 35779/90000 [02:29<03:47, 238.84it/s] 40%|███▉      | 35804/90000 [02:29<03:45, 240.24it/s] 40%|███▉      | 35829/90000 [02:29<03:44, 241.29it/s] 40%|███▉      | 35854/90000 [02:29<03:47, 238.01it/s] 40%|███▉      | 35880/90000 [02:29<03:41, 244.03it/s] 40%|███▉      | 35905/90000 [02:29<03:46, 239.24it/s] 40%|███▉      | 35930/90000 [02:29<03:43, 241.84it/s] 40%|███▉      | 35955/90000 [02:30<03:45, 240.01it/s] 40%|███▉      | 35980/90000 [02:30<03:43, 241.72it/s] 40%|████      | 36005/90000 [02:30<03:47, 236.99it/s] 40%|████      | 36029/90000 [02:30<03:49, 234.94it/s] 40%|████      | 36053/90000 [02:30<03:48, 236.08it/s] 40%|████      | 36078/90000 [02:30<03:45, 238.90it/s] 40%|████      | 36102/90000 [02:30<03:46, 238.46it/s] 40%|████      | 36126/90000 [02:30<03:47, 237.24it/s] 40%|████      | 36151/90000 [02:30<03:44, 239.95it/s] 40%|████      | 36176/90000 [02:30<03:45, 239.03it/s] 40%|████      | 36201/90000 [02:31<03:44, 240.07it/s] 40%|████      | 36226/90000 [02:31<03:44, 239.21it/s] 40%|████      | 36250/90000 [02:31<03:45, 237.98it/s] 40%|████      | 36274/90000 [02:31<03:45, 237.87it/s] 40%|████      | 36298/90000 [02:31<03:47, 236.10it/s] 40%|████      | 36322/90000 [02:31<03:48, 235.38it/s] 40%|████      | 36346/90000 [02:31<03:49, 233.56it/s] 40%|████      | 36371/90000 [02:31<03:46, 236.42it/s] 40%|████      | 36395/90000 [02:31<03:46, 236.28it/s] 40%|████      | 36420/90000 [02:31<03:43, 239.58it/s] 40%|████      | 36445/90000 [02:32<03:42, 240.24it/s] 41%|████      | 36470/90000 [02:32<03:41, 241.98it/s] 41%|████      | 36495/90000 [02:32<03:40, 242.64it/s] 41%|████      | 36520/90000 [02:32<03:39, 243.65it/s] 41%|████      | 36545/90000 [02:32<03:40, 242.90it/s] 41%|████      | 36571/90000 [02:32<03:37, 246.09it/s] 41%|████      | 36596/90000 [02:32<03:37, 245.13it/s] 41%|████      | 36621/90000 [02:32<03:38, 244.83it/s] 41%|████      | 36646/90000 [02:32<03:40, 242.50it/s] 41%|████      | 36672/90000 [02:33<03:36, 245.85it/s] 41%|████      | 36697/90000 [02:33<03:36, 246.39it/s] 41%|████      | 36722/90000 [02:33<03:37, 245.23it/s] 41%|████      | 36747/90000 [02:33<03:39, 242.67it/s] 41%|████      | 36773/90000 [02:33<03:36, 246.00it/s] 41%|████      | 36798/90000 [02:33<03:36, 246.05it/s] 41%|████      | 36823/90000 [02:33<03:35, 246.23it/s] 41%|████      | 36848/90000 [02:33<03:36, 245.12it/s] 41%|████      | 36873/90000 [02:33<03:35, 246.14it/s] 41%|████      | 36898/90000 [02:33<03:35, 245.89it/s] 41%|████      | 36924/90000 [02:34<03:35, 245.94it/s] 41%|████      | 36949/90000 [02:34<03:41, 239.82it/s] 41%|████      | 36974/90000 [02:34<03:42, 238.42it/s] 41%|████      | 36999/90000 [02:34<03:40, 240.25it/s] 41%|████      | 37024/90000 [02:34<03:38, 242.59it/s] 41%|████      | 37049/90000 [02:34<03:39, 240.71it/s] 41%|████      | 37074/90000 [02:34<03:39, 241.06it/s] 41%|████      | 37099/90000 [02:34<03:40, 240.00it/s] 41%|████      | 37124/90000 [02:34<03:43, 236.23it/s] 41%|████▏     | 37148/90000 [02:34<03:43, 236.68it/s] 41%|████▏     | 37173/90000 [02:35<03:41, 238.62it/s] 41%|████▏     | 37197/90000 [02:35<03:42, 237.79it/s] 41%|████▏     | 37221/90000 [02:35<03:44, 235.43it/s] 41%|████▏     | 37246/90000 [02:35<03:42, 237.43it/s] 41%|████▏     | 37271/90000 [02:35<03:39, 240.70it/s] 41%|████▏     | 37296/90000 [02:35<03:40, 239.54it/s] 41%|████▏     | 37320/90000 [02:35<03:41, 237.82it/s] 41%|████▏     | 37345/90000 [02:35<03:38, 240.78it/s] 42%|████▏     | 37370/90000 [02:35<03:38, 240.61it/s] 42%|████▏     | 37395/90000 [02:36<03:37, 241.55it/s] 42%|████▏     | 37420/90000 [02:36<03:40, 238.74it/s] 42%|████▏     | 37444/90000 [02:36<03:41, 236.75it/s] 42%|████▏     | 37469/90000 [02:36<03:39, 239.26it/s] 42%|████▏     | 37493/90000 [02:36<03:39, 238.97it/s] 42%|████▏     | 37518/90000 [02:36<03:37, 241.64it/s] 42%|████▏     | 37543/90000 [02:36<03:38, 239.85it/s] 42%|████▏     | 37567/90000 [02:36<03:42, 236.14it/s] 42%|████▏     | 37592/90000 [02:36<03:41, 236.25it/s] 42%|████▏     | 37617/90000 [02:36<03:39, 238.76it/s] 42%|████▏     | 37641/90000 [02:37<03:42, 235.53it/s] 42%|████▏     | 37665/90000 [02:37<03:41, 235.98it/s] 42%|████▏     | 37689/90000 [02:37<03:41, 236.05it/s] 42%|████▏     | 37713/90000 [02:37<03:41, 236.42it/s] 42%|████▏     | 37737/90000 [02:37<03:43, 234.35it/s] 42%|████▏     | 37762/90000 [02:37<03:40, 236.80it/s] 42%|████▏     | 37787/90000 [02:37<03:39, 238.09it/s] 42%|████▏     | 37812/90000 [02:37<03:38, 239.27it/s] 42%|████▏     | 37836/90000 [02:37<03:41, 235.55it/s] 42%|████▏     | 37860/90000 [02:37<03:41, 235.54it/s] 42%|████▏     | 37884/90000 [02:38<03:40, 235.92it/s] 42%|████▏     | 37908/90000 [02:38<03:41, 235.64it/s] 42%|████▏     | 37932/90000 [02:38<03:40, 236.66it/s] 42%|████▏     | 37958/90000 [02:38<03:34, 242.56it/s] 42%|████▏     | 37983/90000 [02:38<03:35, 241.54it/s] 42%|████▏     | 38009/90000 [02:38<03:32, 244.64it/s] 42%|████▏     | 38034/90000 [02:38<03:36, 239.69it/s] 42%|████▏     | 38058/90000 [02:38<03:39, 236.60it/s] 42%|████▏     | 38082/90000 [02:38<03:40, 234.95it/s] 42%|████▏     | 38106/90000 [02:39<03:42, 232.77it/s] 42%|████▏     | 38130/90000 [02:39<03:44, 230.68it/s] 42%|████▏     | 38155/90000 [02:39<03:39, 236.18it/s] 42%|████▏     | 38181/90000 [02:39<03:34, 241.46it/s] 42%|████▏     | 38206/90000 [02:39<03:35, 240.79it/s] 42%|████▏     | 38231/90000 [02:39<03:36, 239.21it/s] 43%|████▎     | 38257/90000 [02:39<03:32, 243.98it/s] 43%|████▎     | 38282/90000 [02:39<03:30, 245.43it/s] 43%|████▎     | 38307/90000 [02:39<03:34, 240.98it/s] 43%|████▎     | 38332/90000 [02:39<03:35, 239.70it/s] 43%|████▎     | 38356/90000 [02:40<03:35, 239.34it/s] 43%|████▎     | 38381/90000 [02:40<03:34, 240.33it/s] 43%|████▎     | 38406/90000 [02:40<03:34, 240.72it/s] 43%|████▎     | 38431/90000 [02:40<03:35, 239.72it/s] 43%|████▎     | 38456/90000 [02:40<03:34, 240.53it/s] 43%|████▎     | 38481/90000 [02:40<03:36, 237.64it/s] 43%|████▎     | 38505/90000 [02:40<03:39, 234.48it/s] 43%|████▎     | 38530/90000 [02:40<03:37, 236.96it/s] 43%|████▎     | 38554/90000 [02:40<03:37, 236.23it/s] 43%|████▎     | 38580/90000 [02:40<03:34, 240.17it/s] 43%|████▎     | 38605/90000 [02:41<03:34, 239.81it/s] 43%|████▎     | 38630/90000 [02:41<03:33, 240.61it/s] 43%|████▎     | 38655/90000 [02:41<03:32, 241.55it/s] 43%|████▎     | 38680/90000 [02:41<03:31, 242.24it/s] 43%|████▎     | 38706/90000 [02:41<03:29, 244.48it/s] 43%|████▎     | 38731/90000 [02:41<03:31, 242.08it/s] 43%|████▎     | 38756/90000 [02:41<03:34, 238.99it/s] 43%|████▎     | 38780/90000 [02:41<03:37, 235.81it/s] 43%|████▎     | 38804/90000 [02:41<03:38, 234.23it/s] 43%|████▎     | 38829/90000 [02:42<03:36, 235.89it/s] 43%|████▎     | 38853/90000 [02:42<03:37, 235.31it/s] 43%|████▎     | 38878/90000 [02:42<03:34, 238.48it/s] 43%|████▎     | 38902/90000 [02:42<03:36, 236.45it/s] 43%|████▎     | 38927/90000 [02:42<03:34, 238.35it/s] 43%|████▎     | 38952/90000 [02:42<03:32, 239.67it/s] 43%|████▎     | 38976/90000 [02:42<03:33, 238.97it/s] 43%|████▎     | 39000/90000 [02:42<03:33, 238.68it/s] 43%|████▎     | 39024/90000 [02:42<03:34, 238.09it/s] 43%|████▎     | 39049/90000 [02:42<03:31, 240.43it/s] 43%|████▎     | 39074/90000 [02:43<03:34, 237.11it/s] 43%|████▎     | 39098/90000 [02:43<03:34, 237.59it/s] 43%|████▎     | 39122/90000 [02:43<03:36, 234.49it/s] 43%|████▎     | 39146/90000 [02:43<03:39, 232.19it/s] 44%|████▎     | 39171/90000 [02:43<03:36, 235.13it/s] 44%|████▎     | 39195/90000 [02:43<03:37, 233.97it/s] 44%|████▎     | 39220/90000 [02:43<03:32, 238.52it/s] 44%|████▎     | 39246/90000 [02:43<03:29, 242.83it/s] 44%|████▎     | 39271/90000 [02:43<03:28, 243.06it/s] 44%|████▎     | 39296/90000 [02:43<03:31, 239.41it/s] 44%|████▎     | 39320/90000 [02:44<03:34, 235.95it/s] 44%|████▎     | 39344/90000 [02:44<03:35, 234.97it/s] 44%|████▎     | 39368/90000 [02:44<03:38, 231.92it/s] 44%|████▍     | 39392/90000 [02:44<03:38, 231.84it/s] 44%|████▍     | 39417/90000 [02:44<03:36, 233.92it/s] 44%|████▍     | 39443/90000 [02:44<03:31, 239.39it/s] 44%|████▍     | 39468/90000 [02:44<03:29, 241.73it/s] 44%|████▍     | 39493/90000 [02:44<03:29, 241.25it/s] 44%|████▍     | 39518/90000 [02:44<03:30, 240.08it/s] 44%|████▍     | 39543/90000 [02:45<03:31, 238.84it/s] 44%|████▍     | 39568/90000 [02:45<03:30, 239.63it/s] 44%|████▍     | 39592/90000 [02:45<03:32, 237.27it/s] 44%|████▍     | 39617/90000 [02:45<03:31, 238.67it/s] 44%|████▍     | 39643/90000 [02:45<03:27, 242.49it/s] 44%|████▍     | 39668/90000 [02:45<03:26, 243.57it/s] 44%|████▍     | 39693/90000 [02:45<03:25, 245.20it/s] 44%|████▍     | 39718/90000 [02:45<03:23, 246.52it/s] 44%|████▍     | 39744/90000 [02:45<03:24, 246.24it/s] 44%|████▍     | 39769/90000 [02:45<03:25, 244.11it/s] 44%|████▍     | 39794/90000 [02:46<03:25, 244.72it/s] 44%|████▍     | 39819/90000 [02:46<03:28, 240.24it/s] 44%|████▍     | 39844/90000 [02:46<03:28, 240.48it/s] 44%|████▍     | 39869/90000 [02:46<03:30, 238.68it/s] 44%|████▍     | 39894/90000 [02:46<03:29, 239.32it/s] 44%|████▍     | 39918/90000 [02:46<03:33, 234.71it/s] 44%|████▍     | 39943/90000 [02:46<03:30, 237.51it/s] 44%|████▍     | 39968/90000 [02:46<03:29, 239.36it/s] 44%|████▍     | 39993/90000 [02:46<03:28, 239.45it/s] 44%|████▍     | 40017/90000 [02:47<03:30, 237.95it/s] 44%|████▍     | 40041/90000 [02:47<03:29, 238.14it/s] 45%|████▍     | 40067/90000 [02:47<03:26, 242.32it/s] 45%|████▍     | 40092/90000 [02:47<03:32, 234.64it/s] 45%|████▍     | 40117/90000 [02:47<03:30, 237.19it/s] 45%|████▍     | 40142/90000 [02:47<03:29, 238.00it/s] 45%|████▍     | 40166/90000 [02:47<03:33, 233.84it/s] 45%|████▍     | 40191/90000 [02:47<03:29, 237.49it/s] 45%|████▍     | 40215/90000 [02:47<03:29, 238.00it/s] 45%|████▍     | 40240/90000 [02:47<03:26, 240.75it/s] 45%|████▍     | 40265/90000 [02:48<03:26, 241.27it/s] 45%|████▍     | 40291/90000 [02:48<03:23, 244.86it/s] 45%|████▍     | 40316/90000 [02:48<03:27, 239.00it/s] 45%|████▍     | 40341/90000 [02:48<03:25, 241.74it/s] 45%|████▍     | 40366/90000 [02:48<03:26, 240.65it/s] 45%|████▍     | 40391/90000 [02:48<03:25, 240.84it/s] 45%|████▍     | 40416/90000 [02:48<03:25, 241.78it/s] 45%|████▍     | 40442/90000 [02:48<03:23, 243.78it/s] 45%|████▍     | 40467/90000 [02:48<03:26, 239.98it/s] 45%|████▍     | 40493/90000 [02:48<03:23, 243.53it/s] 45%|████▌     | 40518/90000 [02:49<03:27, 237.91it/s] 45%|████▌     | 40542/90000 [02:49<03:28, 237.24it/s] 45%|████▌     | 40566/90000 [02:49<03:29, 236.49it/s] 45%|████▌     | 40590/90000 [02:49<03:33, 231.97it/s] 45%|████▌     | 40614/90000 [02:49<03:31, 233.98it/s] 45%|████▌     | 40638/90000 [02:49<03:30, 234.09it/s] 45%|████▌     | 40663/90000 [02:49<03:28, 236.56it/s] 45%|████▌     | 40687/90000 [02:49<03:29, 235.85it/s] 45%|████▌     | 40711/90000 [02:49<03:32, 232.09it/s] 45%|████▌     | 40736/90000 [02:50<03:28, 236.64it/s] 45%|████▌     | 40760/90000 [02:50<03:28, 236.52it/s] 45%|████▌     | 40784/90000 [02:50<03:29, 234.50it/s] 45%|████▌     | 40808/90000 [02:50<03:30, 233.82it/s] 45%|████▌     | 40833/90000 [02:50<03:27, 236.89it/s] 45%|████▌     | 40857/90000 [02:50<03:27, 236.70it/s] 45%|████▌     | 40882/90000 [02:50<03:24, 240.31it/s] 45%|████▌     | 40907/90000 [02:50<03:22, 242.84it/s] 45%|████▌     | 40933/90000 [02:50<03:20, 245.14it/s] 46%|████▌     | 40958/90000 [02:50<03:21, 243.45it/s] 46%|████▌     | 40983/90000 [02:51<03:22, 242.12it/s] 46%|████▌     | 41008/90000 [02:51<03:26, 237.76it/s] 46%|████▌     | 41033/90000 [02:51<03:23, 240.77it/s] 46%|████▌     | 41058/90000 [02:51<03:24, 239.61it/s] 46%|████▌     | 41082/90000 [02:51<03:25, 237.74it/s] 46%|████▌     | 41106/90000 [02:51<03:26, 236.32it/s] 46%|████▌     | 41130/90000 [02:51<03:27, 236.08it/s] 46%|████▌     | 41156/90000 [02:51<03:22, 241.03it/s] 46%|████▌     | 41181/90000 [02:51<03:22, 240.91it/s] 46%|████▌     | 41206/90000 [02:51<03:26, 236.74it/s] 46%|████▌     | 41230/90000 [02:52<03:27, 234.62it/s] 46%|████▌     | 41255/90000 [02:52<03:25, 237.34it/s] 46%|████▌     | 41279/90000 [02:52<03:24, 237.76it/s] 46%|████▌     | 41303/90000 [02:52<03:26, 235.96it/s] 46%|████▌     | 41327/90000 [02:52<03:25, 236.29it/s] 46%|████▌     | 41351/90000 [02:52<03:35, 226.20it/s] 46%|████▌     | 41375/90000 [02:52<03:32, 228.76it/s] 46%|████▌     | 41400/90000 [02:52<03:28, 233.45it/s] 46%|████▌     | 41425/90000 [02:52<03:27, 234.66it/s] 46%|████▌     | 41450/90000 [02:53<03:24, 237.34it/s] 46%|████▌     | 41476/90000 [02:53<03:20, 242.59it/s] 46%|████▌     | 41501/90000 [02:53<03:21, 240.85it/s] 46%|████▌     | 41526/90000 [02:53<03:23, 238.24it/s] 46%|████▌     | 41551/90000 [02:53<03:21, 240.50it/s] 46%|████▌     | 41576/90000 [02:53<03:20, 241.82it/s] 46%|████▌     | 41601/90000 [02:53<03:22, 239.43it/s] 46%|████▋     | 41627/90000 [02:53<03:18, 243.67it/s] 46%|████▋     | 41652/90000 [02:53<03:18, 243.49it/s] 46%|████▋     | 41677/90000 [02:53<03:17, 244.47it/s] 46%|████▋     | 41702/90000 [02:54<03:18, 243.13it/s] 46%|████▋     | 41727/90000 [02:54<03:17, 244.52it/s] 46%|████▋     | 41752/90000 [02:54<03:17, 243.84it/s] 46%|████▋     | 41777/90000 [02:54<03:17, 244.27it/s] 46%|████▋     | 41802/90000 [02:54<03:18, 243.10it/s] 46%|████▋     | 41828/90000 [02:54<03:16, 245.40it/s] 47%|████▋     | 41853/90000 [02:54<03:17, 244.29it/s] 47%|████▋     | 41878/90000 [02:54<03:18, 242.56it/s] 47%|████▋     | 41903/90000 [02:54<03:20, 239.88it/s] 47%|████▋     | 41927/90000 [02:54<03:23, 236.03it/s] 47%|████▋     | 41951/90000 [02:55<03:24, 235.00it/s] 47%|████▋     | 41976/90000 [02:55<03:22, 237.28it/s] 47%|████▋     | 42000/90000 [02:55<03:22, 236.72it/s] 47%|████▋     | 42024/90000 [02:55<03:25, 233.60it/s] 47%|████▋     | 42049/90000 [02:55<03:23, 235.71it/s] 47%|████▋     | 42073/90000 [02:55<03:23, 235.00it/s] 47%|████▋     | 42097/90000 [02:55<03:25, 232.59it/s] 47%|████▋     | 42121/90000 [02:55<03:24, 233.89it/s] 47%|████▋     | 42146/90000 [02:55<03:22, 236.59it/s] 47%|████▋     | 42171/90000 [02:56<03:19, 240.18it/s] 47%|████▋     | 42196/90000 [02:56<03:19, 239.47it/s] 47%|████▋     | 42220/90000 [02:56<03:23, 235.09it/s] 47%|████▋     | 42245/90000 [02:56<03:20, 238.32it/s] 47%|████▋     | 42270/90000 [02:56<03:19, 239.23it/s] 47%|████▋     | 42295/90000 [02:56<03:17, 241.69it/s] 47%|████▋     | 42320/90000 [02:56<03:17, 240.98it/s] 47%|████▋     | 42345/90000 [02:56<03:17, 241.52it/s] 47%|████▋     | 42370/90000 [02:56<03:20, 237.74it/s] 47%|████▋     | 42394/90000 [02:56<03:19, 238.14it/s] 47%|████▋     | 42419/90000 [02:57<03:18, 239.46it/s] 47%|████▋     | 42444/90000 [02:57<03:18, 239.09it/s] 47%|████▋     | 42469/90000 [02:57<03:16, 241.68it/s] 47%|████▋     | 42494/90000 [02:57<03:18, 238.96it/s] 47%|████▋     | 42519/90000 [02:57<03:18, 239.01it/s] 47%|████▋     | 42544/90000 [02:57<03:17, 240.06it/s] 47%|████▋     | 42569/90000 [02:57<03:17, 239.71it/s] 47%|████▋     | 42595/90000 [02:57<03:14, 243.50it/s] 47%|████▋     | 42620/90000 [02:57<03:13, 244.70it/s] 47%|████▋     | 42645/90000 [02:58<03:16, 241.55it/s] 47%|████▋     | 42670/90000 [02:58<03:17, 239.70it/s] 47%|████▋     | 42695/90000 [02:58<03:16, 240.62it/s] 47%|████▋     | 42720/90000 [02:58<03:17, 239.92it/s] 47%|████▋     | 42746/90000 [02:58<03:13, 244.13it/s] 48%|████▊     | 42771/90000 [02:58<03:15, 241.16it/s] 48%|████▊     | 42796/90000 [02:58<03:15, 240.94it/s] 48%|████▊     | 42821/90000 [02:58<03:16, 240.67it/s] 48%|████▊     | 42846/90000 [02:58<03:15, 241.13it/s] 48%|████▊     | 42872/90000 [02:58<03:12, 244.46it/s] 48%|████▊     | 42897/90000 [02:59<03:19, 235.82it/s] 48%|████▊     | 42922/90000 [02:59<03:17, 238.84it/s] 48%|████▊     | 42947/90000 [02:59<03:16, 239.78it/s] 48%|████▊     | 42972/90000 [02:59<03:18, 236.67it/s] 48%|████▊     | 42997/90000 [02:59<03:16, 239.69it/s] 48%|████▊     | 43022/90000 [02:59<03:15, 240.05it/s] 48%|████▊     | 43047/90000 [02:59<03:15, 239.74it/s] 48%|████▊     | 43072/90000 [02:59<03:15, 240.24it/s] 48%|████▊     | 43097/90000 [02:59<03:15, 239.40it/s] 48%|████▊     | 43122/90000 [02:59<03:15, 240.15it/s] 48%|████▊     | 43147/90000 [03:00<03:18, 236.63it/s] 48%|████▊     | 43173/90000 [03:00<03:14, 240.66it/s] 48%|████▊     | 43198/90000 [03:00<03:16, 237.58it/s] 48%|████▊     | 43223/90000 [03:00<03:15, 239.77it/s] 48%|████▊     | 43249/90000 [03:00<03:11, 244.69it/s] 48%|████▊     | 43275/90000 [03:00<03:09, 246.53it/s] 48%|████▊     | 43300/90000 [03:00<03:11, 244.42it/s] 48%|████▊     | 43325/90000 [03:00<03:11, 243.50it/s] 48%|████▊     | 43351/90000 [03:00<03:10, 245.24it/s] 48%|████▊     | 43376/90000 [03:01<03:11, 243.80it/s] 48%|████▊     | 43401/90000 [03:01<03:10, 244.64it/s] 48%|████▊     | 43427/90000 [03:01<03:08, 246.95it/s] 48%|████▊     | 43452/90000 [03:01<03:11, 242.47it/s] 48%|████▊     | 43477/90000 [03:01<03:12, 241.21it/s] 48%|████▊     | 43502/90000 [03:01<03:14, 239.06it/s] 48%|████▊     | 43527/90000 [03:01<03:13, 240.14it/s] 48%|████▊     | 43552/90000 [03:01<03:13, 239.72it/s] 48%|████▊     | 43577/90000 [03:01<03:12, 241.71it/s] 48%|████▊     | 43602/90000 [03:01<03:11, 242.03it/s] 48%|████▊     | 43627/90000 [03:02<03:12, 241.05it/s] 49%|████▊     | 43652/90000 [03:02<03:11, 242.50it/s] 49%|████▊     | 43677/90000 [03:02<03:11, 242.37it/s] 49%|████▊     | 43702/90000 [03:02<03:12, 240.67it/s] 49%|████▊     | 43727/90000 [03:02<03:15, 237.25it/s] 49%|████▊     | 43751/90000 [03:02<03:15, 236.35it/s] 49%|████▊     | 43776/90000 [03:02<03:14, 238.11it/s] 49%|████▊     | 43801/90000 [03:02<03:12, 239.87it/s] 49%|████▊     | 43826/90000 [03:02<03:11, 240.67it/s] 49%|████▊     | 43851/90000 [03:03<03:11, 241.41it/s] 49%|████▉     | 43876/90000 [03:03<03:09, 243.02it/s] 49%|████▉     | 43901/90000 [03:03<03:10, 241.50it/s] 49%|████▉     | 43926/90000 [03:03<03:11, 240.30it/s] 49%|████▉     | 43951/90000 [03:03<03:09, 242.68it/s] 49%|████▉     | 43976/90000 [03:03<03:14, 236.51it/s] 49%|████▉     | 44001/90000 [03:03<03:12, 239.46it/s] 49%|████▉     | 44025/90000 [03:03<03:12, 238.61it/s] 49%|████▉     | 44049/90000 [03:03<03:12, 238.87it/s] 49%|████▉     | 44074/90000 [03:03<03:10, 241.08it/s] 49%|████▉     | 44099/90000 [03:04<03:09, 242.11it/s] 49%|████▉     | 44124/90000 [03:04<03:11, 239.62it/s] 49%|████▉     | 44148/90000 [03:04<03:12, 238.54it/s] 49%|████▉     | 44172/90000 [03:04<03:14, 235.38it/s] 49%|████▉     | 44196/90000 [03:04<03:15, 234.01it/s] 49%|████▉     | 44220/90000 [03:04<03:14, 234.78it/s] 49%|████▉     | 44245/90000 [03:04<03:12, 238.13it/s] 49%|████▉     | 44269/90000 [03:04<03:11, 238.62it/s] 49%|████▉     | 44293/90000 [03:04<03:12, 237.05it/s] 49%|████▉     | 44317/90000 [03:04<03:12, 236.80it/s] 49%|████▉     | 44341/90000 [03:05<03:13, 236.20it/s] 49%|████▉     | 44365/90000 [03:05<03:15, 233.66it/s] 49%|████▉     | 44391/90000 [03:05<03:11, 238.26it/s] 49%|████▉     | 44415/90000 [03:05<03:11, 237.89it/s] 49%|████▉     | 44439/90000 [03:05<03:12, 236.32it/s] 49%|████▉     | 44463/90000 [03:05<03:12, 236.42it/s] 49%|████▉     | 44487/90000 [03:05<03:14, 233.44it/s] 49%|████▉     | 44512/90000 [03:05<03:12, 235.72it/s] 49%|████▉     | 44537/90000 [03:05<03:11, 237.46it/s] 50%|████▉     | 44562/90000 [03:06<03:10, 238.74it/s] 50%|████▉     | 44589/90000 [03:06<03:04, 245.47it/s] 50%|████▉     | 44614/90000 [03:06<03:06, 243.76it/s] 50%|████▉     | 44640/90000 [03:06<03:03, 246.54it/s] 50%|████▉     | 44665/90000 [03:06<03:03, 247.03it/s] 50%|████▉     | 44690/90000 [03:06<03:05, 244.79it/s] 50%|████▉     | 44715/90000 [03:06<03:06, 242.59it/s] 50%|████▉     | 44740/90000 [03:06<03:06, 242.75it/s] 50%|████▉     | 44765/90000 [03:06<03:08, 240.16it/s] 50%|████▉     | 44790/90000 [03:06<03:08, 239.44it/s] 50%|████▉     | 44814/90000 [03:07<03:11, 235.76it/s] 50%|████▉     | 44839/90000 [03:07<03:09, 238.88it/s] 50%|████▉     | 44865/90000 [03:07<03:05, 243.78it/s] 50%|████▉     | 44890/90000 [03:07<03:06, 241.84it/s] 50%|████▉     | 44915/90000 [03:07<03:07, 240.62it/s] 50%|████▉     | 44940/90000 [03:07<03:08, 239.53it/s] 50%|████▉     | 44966/90000 [03:07<03:04, 243.44it/s] 50%|████▉     | 44991/90000 [03:07<03:03, 245.10it/s] 50%|█████     | 45016/90000 [03:07<03:03, 245.43it/s] 50%|█████     | 45041/90000 [03:07<03:08, 238.31it/s] 50%|█████     | 45065/90000 [03:08<03:08, 238.57it/s] 50%|█████     | 45089/90000 [03:08<03:09, 236.51it/s] 50%|█████     | 45114/90000 [03:08<03:08, 238.11it/s] 50%|█████     | 45138/90000 [03:08<03:09, 237.36it/s] 50%|█████     | 45163/90000 [03:08<03:06, 240.17it/s] 50%|█████     | 45188/90000 [03:08<03:10, 235.83it/s] 50%|█████     | 45213/90000 [03:08<03:07, 238.54it/s] 50%|█████     | 45238/90000 [03:08<03:07, 239.33it/s] 50%|█████     | 45262/90000 [03:08<03:07, 238.31it/s] 50%|█████     | 45286/90000 [03:09<03:08, 237.34it/s] 50%|█████     | 45312/90000 [03:09<03:05, 241.08it/s] 50%|█████     | 45337/90000 [03:09<03:04, 242.00it/s] 50%|█████     | 45362/90000 [03:09<03:06, 238.79it/s] 50%|█████     | 45386/90000 [03:09<03:06, 238.78it/s] 50%|█████     | 45410/90000 [03:09<03:07, 238.15it/s] 50%|█████     | 45435/90000 [03:09<03:05, 240.65it/s] 51%|█████     | 45460/90000 [03:09<03:05, 239.55it/s] 51%|█████     | 45486/90000 [03:09<03:03, 243.12it/s] 51%|█████     | 45511/90000 [03:09<03:03, 241.83it/s] 51%|█████     | 45536/90000 [03:10<03:05, 239.99it/s] 51%|█████     | 45561/90000 [03:10<03:04, 240.86it/s] 51%|█████     | 45586/90000 [03:10<03:05, 238.95it/s] 51%|█████     | 45610/90000 [03:10<03:05, 239.14it/s] 51%|█████     | 45634/90000 [03:10<03:05, 238.80it/s] 51%|█████     | 45659/90000 [03:10<03:04, 240.87it/s] 51%|█████     | 45684/90000 [03:10<03:04, 240.05it/s] 51%|█████     | 45709/90000 [03:10<03:05, 238.89it/s] 51%|█████     | 45733/90000 [03:10<03:05, 238.76it/s] 51%|█████     | 45759/90000 [03:10<03:02, 242.55it/s] 51%|█████     | 45784/90000 [03:11<03:03, 241.55it/s] 51%|█████     | 45809/90000 [03:11<03:02, 242.19it/s] 51%|█████     | 45834/90000 [03:11<03:02, 241.82it/s] 51%|█████     | 45860/90000 [03:11<03:00, 245.19it/s] 51%|█████     | 45885/90000 [03:11<03:00, 244.80it/s] 51%|█████     | 45910/90000 [03:11<03:00, 244.69it/s] 51%|█████     | 45935/90000 [03:11<03:02, 241.93it/s] 51%|█████     | 45960/90000 [03:11<03:01, 242.13it/s] 51%|█████     | 45985/90000 [03:11<03:02, 240.85it/s] 51%|█████     | 46010/90000 [03:12<03:03, 239.29it/s] 51%|█████     | 46034/90000 [03:12<03:05, 237.01it/s] 51%|█████     | 46059/90000 [03:12<03:05, 237.45it/s] 51%|█████     | 46084/90000 [03:12<03:04, 238.67it/s] 51%|█████     | 46108/90000 [03:12<03:04, 237.48it/s] 51%|█████▏    | 46132/90000 [03:12<03:05, 236.64it/s] 51%|█████▏    | 46156/90000 [03:12<03:04, 237.40it/s] 51%|█████▏    | 46181/90000 [03:12<03:03, 238.84it/s] 51%|█████▏    | 46206/90000 [03:12<03:02, 240.29it/s] 51%|█████▏    | 46231/90000 [03:12<03:03, 238.12it/s] 51%|█████▏    | 46256/90000 [03:13<03:02, 239.26it/s] 51%|█████▏    | 46281/90000 [03:13<03:01, 240.81it/s] 51%|█████▏    | 46306/90000 [03:13<02:59, 243.37it/s] 51%|█████▏    | 46331/90000 [03:13<03:00, 241.46it/s] 52%|█████▏    | 46357/90000 [03:13<02:58, 244.79it/s] 52%|█████▏    | 46382/90000 [03:13<02:58, 244.49it/s] 52%|█████▏    | 46407/90000 [03:13<02:59, 243.11it/s] 52%|█████▏    | 46432/90000 [03:13<02:58, 244.06it/s] 52%|█████▏    | 46457/90000 [03:13<02:58, 244.00it/s] 52%|█████▏    | 46482/90000 [03:13<02:59, 242.93it/s] 52%|█████▏    | 46507/90000 [03:14<02:59, 242.29it/s] 52%|█████▏    | 46532/90000 [03:14<03:02, 238.38it/s] 52%|█████▏    | 46556/90000 [03:14<03:04, 235.60it/s] 52%|█████▏    | 46582/90000 [03:14<03:00, 240.34it/s] 52%|█████▏    | 46607/90000 [03:14<02:58, 242.67it/s] 52%|█████▏    | 46632/90000 [03:14<02:57, 244.33it/s] 52%|█████▏    | 46658/90000 [03:14<02:55, 246.45it/s] 52%|█████▏    | 46683/90000 [03:14<02:55, 246.21it/s] 52%|█████▏    | 46708/90000 [03:14<02:59, 240.81it/s] 52%|█████▏    | 46733/90000 [03:15<03:00, 240.14it/s] 52%|█████▏    | 46758/90000 [03:15<03:00, 239.89it/s] 52%|█████▏    | 46783/90000 [03:15<02:58, 242.45it/s] 52%|█████▏    | 46808/90000 [03:15<03:00, 239.93it/s] 52%|█████▏    | 46834/90000 [03:15<02:57, 243.13it/s] 52%|█████▏    | 46859/90000 [03:15<02:59, 240.43it/s] 52%|█████▏    | 46884/90000 [03:15<02:58, 241.09it/s] 52%|█████▏    | 46909/90000 [03:15<02:59, 240.48it/s] 52%|█████▏    | 46934/90000 [03:15<03:00, 238.13it/s] 52%|█████▏    | 46958/90000 [03:15<03:02, 236.06it/s] 52%|█████▏    | 46982/90000 [03:16<03:02, 236.23it/s] 52%|█████▏    | 47006/90000 [03:16<03:02, 236.20it/s] 52%|█████▏    | 47031/90000 [03:16<03:01, 237.39it/s] 52%|█████▏    | 47056/90000 [03:16<03:00, 237.64it/s] 52%|█████▏    | 47081/90000 [03:16<02:59, 239.01it/s] 52%|█████▏    | 47105/90000 [03:16<03:02, 234.78it/s] 52%|█████▏    | 47130/90000 [03:16<02:59, 238.34it/s] 52%|█████▏    | 47154/90000 [03:16<03:01, 235.50it/s] 52%|█████▏    | 47179/90000 [03:16<03:00, 237.88it/s] 52%|█████▏    | 47203/90000 [03:16<02:59, 238.44it/s] 52%|█████▏    | 47227/90000 [03:17<02:59, 237.76it/s] 53%|█████▎    | 47251/90000 [03:17<03:01, 234.92it/s] 53%|█████▎    | 47276/90000 [03:17<02:59, 238.09it/s] 53%|█████▎    | 47300/90000 [03:17<03:02, 233.64it/s] 53%|█████▎    | 47325/90000 [03:17<03:01, 235.71it/s] 53%|█████▎    | 47350/90000 [03:17<02:59, 237.94it/s] 53%|█████▎    | 47374/90000 [03:17<02:58, 238.43it/s] 53%|█████▎    | 47399/90000 [03:17<02:57, 240.47it/s] 53%|█████▎    | 47424/90000 [03:17<02:56, 241.20it/s] 53%|█████▎    | 47449/90000 [03:18<02:57, 240.25it/s] 53%|█████▎    | 47474/90000 [03:18<02:56, 241.01it/s] 53%|█████▎    | 47499/90000 [03:18<03:00, 235.87it/s] 53%|█████▎    | 47525/90000 [03:18<02:57, 239.86it/s] 53%|█████▎    | 47550/90000 [03:18<02:56, 241.07it/s] 53%|█████▎    | 47575/90000 [03:18<02:56, 240.55it/s] 53%|█████▎    | 47600/90000 [03:18<02:55, 242.00it/s] 53%|█████▎    | 47625/90000 [03:18<02:57, 238.75it/s] 53%|█████▎    | 47649/90000 [03:18<03:00, 234.82it/s] 53%|█████▎    | 47673/90000 [03:18<02:59, 235.66it/s] 53%|█████▎    | 47699/90000 [03:19<02:54, 242.59it/s] 53%|█████▎    | 47724/90000 [03:19<02:54, 242.74it/s] 53%|█████▎    | 47749/90000 [03:19<02:55, 241.00it/s] 53%|█████▎    | 47774/90000 [03:19<02:57, 237.91it/s] 53%|█████▎    | 47799/90000 [03:19<02:57, 237.85it/s] 53%|█████▎    | 47824/90000 [03:19<02:55, 240.77it/s] 53%|█████▎    | 47849/90000 [03:19<02:56, 238.91it/s] 53%|█████▎    | 47873/90000 [03:19<02:57, 236.92it/s] 53%|█████▎    | 47898/90000 [03:19<02:55, 239.74it/s] 53%|█████▎    | 47922/90000 [03:19<02:55, 239.10it/s] 53%|█████▎    | 47946/90000 [03:20<02:55, 239.25it/s] 53%|█████▎    | 47970/90000 [03:20<02:56, 238.79it/s] 53%|█████▎    | 47994/90000 [03:20<02:55, 239.05it/s] 53%|█████▎    | 48019/90000 [03:20<02:54, 240.34it/s] 53%|█████▎    | 48045/90000 [03:20<02:51, 244.25it/s] 53%|█████▎    | 48070/90000 [03:20<02:50, 245.38it/s] 53%|█████▎    | 48095/90000 [03:20<02:50, 245.79it/s] 53%|█████▎    | 48120/90000 [03:20<02:49, 246.70it/s] 53%|█████▎    | 48145/90000 [03:20<02:51, 244.08it/s] 54%|█████▎    | 48170/90000 [03:21<02:53, 241.26it/s] 54%|█████▎    | 48195/90000 [03:21<02:52, 242.57it/s] 54%|█████▎    | 48220/90000 [03:21<02:53, 241.32it/s] 54%|█████▎    | 48245/90000 [03:21<02:53, 240.61it/s] 54%|█████▎    | 48270/90000 [03:21<02:55, 238.40it/s] 54%|█████▎    | 48294/90000 [03:21<02:55, 237.50it/s] 54%|█████▎    | 48318/90000 [03:21<02:55, 237.40it/s] 54%|█████▎    | 48342/90000 [03:21<02:56, 236.63it/s] 54%|█████▎    | 48367/90000 [03:21<02:55, 237.64it/s] 54%|█████▍    | 48392/90000 [03:21<02:54, 238.80it/s] 54%|█████▍    | 48416/90000 [03:22<02:54, 238.96it/s] 54%|█████▍    | 48440/90000 [03:22<02:54, 237.83it/s] 54%|█████▍    | 48465/90000 [03:22<02:52, 240.55it/s] 54%|█████▍    | 48490/90000 [03:22<02:51, 242.05it/s] 54%|█████▍    | 48515/90000 [03:22<02:51, 242.14it/s] 54%|█████▍    | 48540/90000 [03:22<02:52, 240.15it/s] 54%|█████▍    | 48565/90000 [03:22<02:52, 239.77it/s] 54%|█████▍    | 48591/90000 [03:22<02:50, 243.48it/s] 54%|█████▍    | 48616/90000 [03:22<02:52, 239.48it/s] 54%|█████▍    | 48642/90000 [03:22<02:49, 243.65it/s] 54%|█████▍    | 48667/90000 [03:23<02:49, 243.69it/s] 54%|█████▍    | 48692/90000 [03:23<02:53, 237.59it/s] 54%|█████▍    | 48716/90000 [03:23<02:53, 237.96it/s] 54%|█████▍    | 48740/90000 [03:23<02:53, 237.66it/s] 54%|█████▍    | 48764/90000 [03:23<02:56, 233.49it/s] 54%|█████▍    | 48788/90000 [03:23<02:57, 232.83it/s] 54%|█████▍    | 48813/90000 [03:23<02:54, 236.13it/s] 54%|█████▍    | 48837/90000 [03:23<02:53, 236.58it/s] 54%|█████▍    | 48862/90000 [03:23<02:53, 237.18it/s] 54%|█████▍    | 48887/90000 [03:24<02:51, 240.16it/s] 54%|█████▍    | 48912/90000 [03:24<02:50, 240.33it/s] 54%|█████▍    | 48937/90000 [03:24<02:53, 236.63it/s] 54%|█████▍    | 48963/90000 [03:24<02:49, 241.42it/s] 54%|█████▍    | 48989/90000 [03:24<02:47, 244.47it/s] 54%|█████▍    | 49014/90000 [03:24<02:50, 240.61it/s] 54%|█████▍    | 49039/90000 [03:24<02:49, 241.37it/s] 55%|█████▍    | 49064/90000 [03:24<02:49, 241.33it/s] 55%|█████▍    | 49089/90000 [03:24<02:49, 240.94it/s] 55%|█████▍    | 49114/90000 [03:24<02:50, 240.34it/s] 55%|█████▍    | 49139/90000 [03:25<02:48, 242.12it/s] 55%|█████▍    | 49164/90000 [03:25<02:49, 241.19it/s] 55%|█████▍    | 49189/90000 [03:25<02:48, 242.91it/s] 55%|█████▍    | 49214/90000 [03:25<02:47, 244.09it/s] 55%|█████▍    | 49239/90000 [03:25<02:49, 240.72it/s] 55%|█████▍    | 49264/90000 [03:25<02:48, 241.45it/s] 55%|█████▍    | 49289/90000 [03:25<02:48, 242.28it/s] 55%|█████▍    | 49314/90000 [03:25<02:51, 236.88it/s] 55%|█████▍    | 49338/90000 [03:25<02:54, 232.41it/s] 55%|█████▍    | 49362/90000 [03:26<02:55, 231.83it/s] 55%|█████▍    | 49388/90000 [03:26<02:50, 238.28it/s] 55%|█████▍    | 49413/90000 [03:26<02:49, 239.96it/s] 55%|█████▍    | 49438/90000 [03:26<02:50, 237.50it/s] 55%|█████▍    | 49462/90000 [03:26<02:53, 234.12it/s] 55%|█████▍    | 49486/90000 [03:26<02:52, 234.68it/s] 55%|█████▌    | 49512/90000 [03:26<02:47, 241.02it/s] 55%|█████▌    | 49538/90000 [03:26<02:45, 244.44it/s] 55%|█████▌    | 49563/90000 [03:26<02:46, 242.16it/s] 55%|█████▌    | 49588/90000 [03:26<02:47, 241.95it/s] 55%|█████▌    | 49613/90000 [03:27<02:47, 241.19it/s] 55%|█████▌    | 49638/90000 [03:27<02:46, 242.35it/s] 55%|█████▌    | 49663/90000 [03:27<02:45, 243.94it/s] 55%|█████▌    | 49688/90000 [03:27<02:48, 239.36it/s] 55%|█████▌    | 49713/90000 [03:27<02:46, 241.83it/s] 55%|█████▌    | 49738/90000 [03:27<02:46, 241.89it/s] 55%|█████▌    | 49763/90000 [03:27<02:45, 242.69it/s] 55%|█████▌    | 49789/90000 [03:27<02:42, 246.90it/s] 55%|█████▌    | 49814/90000 [03:27<02:43, 246.01it/s] 55%|█████▌    | 49839/90000 [03:27<02:46, 240.78it/s] 55%|█████▌    | 49864/90000 [03:28<02:45, 242.76it/s] 55%|█████▌    | 49889/90000 [03:28<02:44, 244.38it/s] 55%|█████▌    | 49914/90000 [03:28<02:47, 239.78it/s] 55%|█████▌    | 49939/90000 [03:28<02:48, 238.08it/s] 56%|█████▌    | 49964/90000 [03:28<02:47, 239.57it/s] 56%|█████▌    | 49988/90000 [03:28<02:48, 237.34it/s] 56%|█████▌    | 50013/90000 [03:28<02:46, 239.81it/s] 56%|█████▌    | 50038/90000 [03:28<02:46, 239.71it/s] 56%|█████▌    | 50064/90000 [03:28<02:44, 242.26it/s] 56%|█████▌    | 50089/90000 [03:29<02:43, 243.65it/s] 56%|█████▌    | 50114/90000 [03:29<02:45, 240.63it/s] 56%|█████▌    | 50139/90000 [03:29<02:43, 243.08it/s] 56%|█████▌    | 50164/90000 [03:29<02:43, 243.01it/s] 56%|█████▌    | 50190/90000 [03:29<02:42, 244.92it/s] 56%|█████▌    | 50215/90000 [03:29<02:43, 243.17it/s] 56%|█████▌    | 50240/90000 [03:29<02:43, 243.38it/s] 56%|█████▌    | 50265/90000 [03:29<02:41, 245.29it/s] 56%|█████▌    | 50290/90000 [03:29<02:42, 244.49it/s] 56%|█████▌    | 50315/90000 [03:29<02:43, 241.99it/s] 56%|█████▌    | 50340/90000 [03:30<02:45, 239.43it/s] 56%|█████▌    | 50365/90000 [03:30<02:45, 240.15it/s] 56%|█████▌    | 50390/90000 [03:30<02:44, 240.79it/s] 56%|█████▌    | 50415/90000 [03:30<02:46, 237.08it/s] 56%|█████▌    | 50439/90000 [03:30<02:47, 236.18it/s] 56%|█████▌    | 50463/90000 [03:30<02:47, 235.35it/s] 56%|█████▌    | 50488/90000 [03:30<02:46, 237.63it/s] 56%|█████▌    | 50512/90000 [03:30<02:46, 236.67it/s] 56%|█████▌    | 50536/90000 [03:30<02:46, 237.04it/s] 56%|█████▌    | 50560/90000 [03:30<02:45, 237.73it/s] 56%|█████▌    | 50584/90000 [03:31<02:46, 236.67it/s] 56%|█████▌    | 50610/90000 [03:31<02:41, 243.24it/s] 56%|█████▋    | 50635/90000 [03:31<02:41, 243.94it/s] 56%|█████▋    | 50660/90000 [03:31<02:40, 244.86it/s] 56%|█████▋    | 50685/90000 [03:31<02:40, 244.29it/s] 56%|█████▋    | 50711/90000 [03:31<02:39, 246.80it/s] 56%|█████▋    | 50736/90000 [03:31<02:40, 244.44it/s] 56%|█████▋    | 50761/90000 [03:31<02:42, 241.72it/s] 56%|█████▋    | 50786/90000 [03:31<02:41, 242.23it/s] 56%|█████▋    | 50811/90000 [03:32<02:44, 238.41it/s] 56%|█████▋    | 50835/90000 [03:32<02:45, 237.13it/s] 57%|█████▋    | 50861/90000 [03:32<02:41, 241.78it/s] 57%|█████▋    | 50886/90000 [03:32<02:41, 241.55it/s] 57%|█████▋    | 50911/90000 [03:32<02:41, 241.46it/s] 57%|█████▋    | 50936/90000 [03:32<02:42, 239.88it/s] 57%|█████▋    | 50961/90000 [03:32<02:41, 242.05it/s] 57%|█████▋    | 50986/90000 [03:32<02:43, 238.65it/s] 57%|█████▋    | 51012/90000 [03:32<02:41, 241.92it/s] 57%|█████▋    | 51037/90000 [03:32<02:41, 241.34it/s] 57%|█████▋    | 51062/90000 [03:33<02:41, 240.40it/s] 57%|█████▋    | 51087/90000 [03:33<02:43, 238.63it/s] 57%|█████▋    | 51112/90000 [03:33<02:42, 239.66it/s] 57%|█████▋    | 51138/90000 [03:33<02:40, 242.62it/s] 57%|█████▋    | 51163/90000 [03:33<02:40, 241.52it/s] 57%|█████▋    | 51188/90000 [03:33<02:42, 238.86it/s] 57%|█████▋    | 51213/90000 [03:33<02:41, 239.97it/s] 57%|█████▋    | 51238/90000 [03:33<02:44, 234.93it/s] 57%|█████▋    | 51263/90000 [03:33<02:43, 236.29it/s] 57%|█████▋    | 51288/90000 [03:33<02:43, 237.42it/s] 57%|█████▋    | 51312/90000 [03:34<02:43, 236.98it/s] 57%|█████▋    | 51336/90000 [03:34<02:45, 234.31it/s] 57%|█████▋    | 51361/90000 [03:34<02:43, 236.62it/s] 57%|█████▋    | 51385/90000 [03:34<02:48, 229.60it/s] 57%|█████▋    | 51408/90000 [03:34<02:48, 228.75it/s] 57%|█████▋    | 51431/90000 [03:34<02:49, 227.59it/s] 57%|█████▋    | 51456/90000 [03:34<02:45, 232.96it/s] 57%|█████▋    | 51480/90000 [03:34<02:44, 234.21it/s] 57%|█████▋    | 51504/90000 [03:34<02:44, 234.54it/s] 57%|█████▋    | 51528/90000 [03:35<02:42, 236.12it/s] 57%|█████▋    | 51552/90000 [03:35<02:43, 235.27it/s] 57%|█████▋    | 51576/90000 [03:35<02:43, 235.43it/s] 57%|█████▋    | 51602/90000 [03:35<02:39, 240.95it/s] 57%|█████▋    | 51627/90000 [03:35<02:38, 241.36it/s] 57%|█████▋    | 51652/90000 [03:35<02:39, 240.70it/s] 57%|█████▋    | 51677/90000 [03:35<02:38, 241.99it/s] 57%|█████▋    | 51702/90000 [03:35<02:38, 241.47it/s] 57%|█████▋    | 51727/90000 [03:35<02:48, 226.81it/s] 58%|█████▊    | 51751/90000 [03:35<02:46, 230.18it/s] 58%|█████▊    | 51775/90000 [03:36<02:45, 230.81it/s] 58%|█████▊    | 51800/90000 [03:36<02:43, 234.22it/s] 58%|█████▊    | 51824/90000 [03:36<02:42, 234.65it/s] 58%|█████▊    | 51848/90000 [03:36<02:44, 232.31it/s] 58%|█████▊    | 51872/90000 [03:36<02:43, 233.76it/s] 58%|█████▊    | 51898/90000 [03:36<02:40, 238.11it/s] 58%|█████▊    | 51923/90000 [03:36<02:38, 239.66it/s] 58%|█████▊    | 51947/90000 [03:36<02:42, 234.41it/s] 58%|█████▊    | 51972/90000 [03:36<02:41, 235.79it/s] 58%|█████▊    | 51996/90000 [03:37<02:41, 234.97it/s] 58%|█████▊    | 52021/90000 [03:37<02:39, 238.31it/s] 58%|█████▊    | 52045/90000 [03:37<02:39, 237.87it/s] 58%|█████▊    | 52069/90000 [03:37<02:41, 234.93it/s] 58%|█████▊    | 52093/90000 [03:37<02:41, 234.28it/s] 58%|█████▊    | 52118/90000 [03:37<02:39, 237.84it/s] 58%|█████▊    | 52142/90000 [03:37<02:39, 237.29it/s] 58%|█████▊    | 52166/90000 [03:37<02:42, 232.79it/s] 58%|█████▊    | 52190/90000 [03:37<02:41, 234.74it/s] 58%|█████▊    | 52214/90000 [03:37<02:40, 235.89it/s] 58%|█████▊    | 52238/90000 [03:38<02:40, 234.92it/s] 58%|█████▊    | 52263/90000 [03:38<02:38, 237.64it/s] 58%|█████▊    | 52288/90000 [03:38<02:37, 240.08it/s] 58%|█████▊    | 52313/90000 [03:38<02:37, 239.59it/s] 58%|█████▊    | 52337/90000 [03:38<02:38, 238.06it/s] 58%|█████▊    | 52361/90000 [03:38<02:39, 236.63it/s] 58%|█████▊    | 52387/90000 [03:38<02:37, 239.49it/s] 58%|█████▊    | 52411/90000 [03:38<02:38, 237.51it/s] 58%|█████▊    | 52436/90000 [03:38<02:37, 238.67it/s] 58%|█████▊    | 52461/90000 [03:38<02:36, 239.55it/s] 58%|█████▊    | 52485/90000 [03:39<02:38, 236.92it/s] 58%|█████▊    | 52509/90000 [03:39<02:39, 235.39it/s] 58%|█████▊    | 52533/90000 [03:39<02:40, 234.06it/s] 58%|█████▊    | 52558/90000 [03:39<02:37, 237.48it/s] 58%|█████▊    | 52582/90000 [03:39<02:38, 235.34it/s] 58%|█████▊    | 52607/90000 [03:39<02:37, 237.51it/s] 58%|█████▊    | 52632/90000 [03:39<02:35, 240.23it/s] 59%|█████▊    | 52657/90000 [03:39<02:35, 239.90it/s] 59%|█████▊    | 52681/90000 [03:39<02:36, 237.91it/s] 59%|█████▊    | 52705/90000 [03:39<02:37, 237.32it/s] 59%|█████▊    | 52731/90000 [03:40<02:33, 242.07it/s] 59%|█████▊    | 52756/90000 [03:40<02:34, 240.62it/s] 59%|█████▊    | 52781/90000 [03:40<02:33, 241.88it/s] 59%|█████▊    | 52806/90000 [03:40<02:34, 241.18it/s] 59%|█████▊    | 52831/90000 [03:40<02:33, 242.68it/s] 59%|█████▊    | 52856/90000 [03:40<02:33, 242.47it/s] 59%|█████▉    | 52881/90000 [03:40<02:35, 239.01it/s] 59%|█████▉    | 52905/90000 [03:40<02:36, 236.84it/s] 59%|█████▉    | 52929/90000 [03:40<02:36, 237.07it/s] 59%|█████▉    | 52954/90000 [03:41<02:34, 239.75it/s] 59%|█████▉    | 52978/90000 [03:41<02:34, 239.61it/s] 59%|█████▉    | 53003/90000 [03:41<02:33, 240.81it/s] 59%|█████▉    | 53028/90000 [03:41<02:32, 242.29it/s] 59%|█████▉    | 53053/90000 [03:41<02:32, 242.82it/s] 59%|█████▉    | 53078/90000 [03:41<02:33, 240.81it/s] 59%|█████▉    | 53104/90000 [03:41<02:30, 244.91it/s] 59%|█████▉    | 53129/90000 [03:41<02:31, 244.05it/s] 59%|█████▉    | 53155/90000 [03:41<02:28, 247.48it/s] 59%|█████▉    | 53180/90000 [03:41<02:29, 246.94it/s] 59%|█████▉    | 53205/90000 [03:42<02:32, 241.93it/s] 59%|█████▉    | 53230/90000 [03:42<02:31, 241.92it/s] 59%|█████▉    | 53255/90000 [03:42<02:31, 243.11it/s] 59%|█████▉    | 53280/90000 [03:42<02:30, 244.10it/s] 59%|█████▉    | 53305/90000 [03:42<02:29, 244.67it/s] 59%|█████▉    | 53330/90000 [03:42<02:33, 239.13it/s] 59%|█████▉    | 53355/90000 [03:42<02:31, 241.95it/s] 59%|█████▉    | 53380/90000 [03:42<02:32, 240.42it/s] 59%|█████▉    | 53405/90000 [03:42<02:34, 237.27it/s] 59%|█████▉    | 53429/90000 [03:42<02:34, 237.26it/s] 59%|█████▉    | 53455/90000 [03:43<02:31, 240.70it/s] 59%|█████▉    | 53480/90000 [03:43<02:35, 235.52it/s] 59%|█████▉    | 53505/90000 [03:43<02:33, 237.32it/s] 59%|█████▉    | 53530/90000 [03:43<02:32, 238.81it/s] 60%|█████▉    | 53556/90000 [03:43<02:30, 242.60it/s] 60%|█████▉    | 53581/90000 [03:43<02:29, 244.26it/s] 60%|█████▉    | 53606/90000 [03:43<02:33, 236.34it/s] 60%|█████▉    | 53630/90000 [03:43<02:33, 236.93it/s] 60%|█████▉    | 53655/90000 [03:43<02:31, 239.40it/s] 60%|█████▉    | 53679/90000 [03:44<02:31, 239.48it/s] 60%|█████▉    | 53704/90000 [03:44<02:29, 242.19it/s] 60%|█████▉    | 53729/90000 [03:44<02:31, 240.17it/s] 60%|█████▉    | 53754/90000 [03:44<02:30, 240.44it/s] 60%|█████▉    | 53779/90000 [03:44<02:29, 241.96it/s] 60%|█████▉    | 53804/90000 [03:44<02:31, 239.17it/s] 60%|█████▉    | 53829/90000 [03:44<02:30, 241.12it/s] 60%|█████▉    | 53854/90000 [03:44<02:31, 238.42it/s] 60%|█████▉    | 53878/90000 [03:44<02:31, 238.85it/s] 60%|█████▉    | 53902/90000 [03:44<02:32, 237.00it/s] 60%|█████▉    | 53928/90000 [03:45<02:28, 242.57it/s] 60%|█████▉    | 53953/90000 [03:45<02:31, 238.50it/s] 60%|█████▉    | 53977/90000 [03:45<02:31, 238.05it/s] 60%|██████    | 54001/90000 [03:45<02:31, 236.97it/s] 60%|██████    | 54025/90000 [03:45<02:31, 237.01it/s] 60%|██████    | 54049/90000 [03:45<02:31, 237.38it/s] 60%|██████    | 54074/90000 [03:45<02:30, 238.73it/s] 60%|██████    | 54098/90000 [03:45<02:32, 236.14it/s] 60%|██████    | 54123/90000 [03:45<02:30, 239.06it/s] 60%|██████    | 54147/90000 [03:45<02:30, 237.68it/s] 60%|██████    | 54172/90000 [03:46<02:29, 240.08it/s] 60%|██████    | 54197/90000 [03:46<02:28, 241.83it/s] 60%|██████    | 54222/90000 [03:46<02:29, 239.97it/s] 60%|██████    | 54247/90000 [03:46<02:28, 240.41it/s] 60%|██████    | 54272/90000 [03:46<02:29, 239.27it/s] 60%|██████    | 54297/90000 [03:46<02:28, 241.20it/s] 60%|██████    | 54322/90000 [03:46<02:27, 242.54it/s] 60%|██████    | 54347/90000 [03:46<02:27, 241.83it/s] 60%|██████    | 54372/90000 [03:46<02:29, 238.43it/s] 60%|██████    | 54397/90000 [03:47<02:27, 241.72it/s] 60%|██████    | 54422/90000 [03:47<02:29, 237.42it/s] 60%|██████    | 54446/90000 [03:47<02:29, 237.38it/s] 61%|██████    | 54471/90000 [03:47<02:27, 240.26it/s] 61%|██████    | 54496/90000 [03:47<02:26, 242.39it/s] 61%|██████    | 54521/90000 [03:47<02:27, 240.15it/s] 61%|██████    | 54546/90000 [03:47<02:28, 239.27it/s] 61%|██████    | 54570/90000 [03:47<02:28, 238.82it/s] 61%|██████    | 54595/90000 [03:47<02:26, 241.19it/s] 61%|██████    | 54620/90000 [03:47<02:27, 239.16it/s] 61%|██████    | 54645/90000 [03:48<02:26, 240.71it/s] 61%|██████    | 54670/90000 [03:48<02:26, 241.64it/s] 61%|██████    | 54695/90000 [03:48<02:27, 239.51it/s] 61%|██████    | 54721/90000 [03:48<02:24, 243.59it/s] 61%|██████    | 54746/90000 [03:48<02:26, 241.21it/s] 61%|██████    | 54771/90000 [03:48<02:28, 237.10it/s] 61%|██████    | 54795/90000 [03:48<02:28, 237.11it/s] 61%|██████    | 54820/90000 [03:48<02:27, 239.24it/s] 61%|██████    | 54844/90000 [03:48<02:29, 235.93it/s] 61%|██████    | 54870/90000 [03:49<02:25, 242.27it/s] 61%|██████    | 54895/90000 [03:49<02:26, 239.74it/s] 61%|██████    | 54920/90000 [03:49<02:24, 242.05it/s] 61%|██████    | 54945/90000 [03:49<02:25, 241.07it/s] 61%|██████    | 54971/90000 [03:49<02:22, 245.11it/s] 61%|██████    | 54996/90000 [03:49<02:24, 242.49it/s] 61%|██████    | 55021/90000 [03:49<02:26, 239.28it/s] 61%|██████    | 55045/90000 [03:49<02:26, 237.99it/s] 61%|██████    | 55070/90000 [03:49<02:26, 238.72it/s] 61%|██████    | 55095/90000 [03:49<02:25, 239.65it/s] 61%|██████    | 55119/90000 [03:50<02:26, 238.02it/s] 61%|██████▏   | 55143/90000 [03:50<02:27, 235.94it/s] 61%|██████▏   | 55167/90000 [03:50<02:27, 236.84it/s] 61%|██████▏   | 55191/90000 [03:50<02:28, 234.78it/s] 61%|██████▏   | 55216/90000 [03:50<02:26, 236.80it/s] 61%|██████▏   | 55241/90000 [03:50<02:25, 239.48it/s] 61%|██████▏   | 55266/90000 [03:50<02:23, 242.27it/s] 61%|██████▏   | 55291/90000 [03:50<02:23, 241.81it/s] 61%|██████▏   | 55316/90000 [03:50<02:23, 241.86it/s] 61%|██████▏   | 55341/90000 [03:50<02:23, 240.72it/s] 62%|██████▏   | 55366/90000 [03:51<02:24, 239.55it/s] 62%|██████▏   | 55391/90000 [03:51<02:23, 240.57it/s] 62%|██████▏   | 55416/90000 [03:51<02:23, 240.76it/s] 62%|██████▏   | 55441/90000 [03:51<02:24, 238.81it/s] 62%|██████▏   | 55466/90000 [03:51<02:24, 239.55it/s] 62%|██████▏   | 55491/90000 [03:51<02:23, 241.24it/s] 62%|██████▏   | 55516/90000 [03:51<02:23, 239.81it/s] 62%|██████▏   | 55540/90000 [03:51<02:23, 239.51it/s] 62%|██████▏   | 55565/90000 [03:51<02:22, 241.93it/s] 62%|██████▏   | 55590/90000 [03:52<02:21, 242.64it/s] 62%|██████▏   | 55615/90000 [03:52<02:22, 240.72it/s] 62%|██████▏   | 55640/90000 [03:52<02:22, 241.44it/s] 62%|██████▏   | 55665/90000 [03:52<02:22, 240.91it/s] 62%|██████▏   | 55690/90000 [03:52<02:23, 239.30it/s] 62%|██████▏   | 55715/90000 [03:52<02:22, 240.72it/s] 62%|██████▏   | 55740/90000 [03:52<02:22, 240.45it/s] 62%|██████▏   | 55765/90000 [03:52<02:21, 242.20it/s] 62%|██████▏   | 55790/90000 [03:52<02:22, 240.68it/s] 62%|██████▏   | 55815/90000 [03:52<02:22, 239.41it/s] 62%|██████▏   | 55840/90000 [03:53<02:21, 240.58it/s] 62%|██████▏   | 55865/90000 [03:53<02:21, 240.41it/s] 62%|██████▏   | 55890/90000 [03:53<02:22, 239.16it/s] 62%|██████▏   | 55916/90000 [03:53<02:19, 243.78it/s] 62%|██████▏   | 55941/90000 [03:53<02:20, 242.18it/s] 62%|██████▏   | 55966/90000 [03:53<02:23, 236.81it/s] 62%|██████▏   | 55991/90000 [03:53<02:22, 239.50it/s] 62%|██████▏   | 56016/90000 [03:53<02:21, 240.49it/s] 62%|██████▏   | 56041/90000 [03:53<02:20, 242.11it/s] 62%|██████▏   | 56067/90000 [03:53<02:18, 245.04it/s] 62%|██████▏   | 56092/90000 [03:54<02:19, 243.68it/s] 62%|██████▏   | 56117/90000 [03:54<02:21, 239.86it/s] 62%|██████▏   | 56142/90000 [03:54<02:20, 240.73it/s] 62%|██████▏   | 56167/90000 [03:54<02:20, 240.66it/s] 62%|██████▏   | 56192/90000 [03:54<02:21, 238.27it/s] 62%|██████▏   | 56216/90000 [03:54<02:21, 238.17it/s] 62%|██████▏   | 56240/90000 [03:54<02:21, 238.51it/s] 63%|██████▎   | 56265/90000 [03:54<02:20, 240.77it/s] 63%|██████▎   | 56292/90000 [03:54<02:17, 245.76it/s] 63%|██████▎   | 56317/90000 [03:55<02:18, 243.46it/s] 63%|██████▎   | 56342/90000 [03:55<02:17, 244.07it/s] 63%|██████▎   | 56367/90000 [03:55<02:17, 243.97it/s] 63%|██████▎   | 56392/90000 [03:55<02:18, 241.92it/s] 63%|██████▎   | 56417/90000 [03:55<02:21, 237.07it/s] 63%|██████▎   | 56442/90000 [03:55<02:19, 240.64it/s] 63%|██████▎   | 56468/90000 [03:55<02:17, 243.26it/s] 63%|██████▎   | 56493/90000 [03:55<02:20, 238.96it/s] 63%|██████▎   | 56517/90000 [03:55<02:20, 238.84it/s] 63%|██████▎   | 56542/90000 [03:55<02:19, 240.05it/s] 63%|██████▎   | 56567/90000 [03:56<02:18, 241.48it/s] 63%|██████▎   | 56592/90000 [03:56<02:17, 242.68it/s] 63%|██████▎   | 56617/90000 [03:56<02:17, 242.12it/s] 63%|██████▎   | 56642/90000 [03:56<02:19, 239.02it/s] 63%|██████▎   | 56666/90000 [03:56<02:19, 238.77it/s] 63%|██████▎   | 56692/90000 [03:56<02:17, 243.06it/s] 63%|██████▎   | 56717/90000 [03:56<02:19, 239.04it/s] 63%|██████▎   | 56741/90000 [03:56<02:19, 239.04it/s] 63%|██████▎   | 56765/90000 [03:56<02:20, 236.59it/s] 63%|██████▎   | 56790/90000 [03:56<02:18, 238.93it/s] 63%|██████▎   | 56814/90000 [03:57<02:20, 235.74it/s] 63%|██████▎   | 56839/90000 [03:57<02:18, 238.68it/s] 63%|██████▎   | 56864/90000 [03:57<02:17, 240.82it/s] 63%|██████▎   | 56889/90000 [03:57<02:17, 240.47it/s] 63%|██████▎   | 56914/90000 [03:57<02:17, 240.77it/s] 63%|██████▎   | 56939/90000 [03:57<02:18, 238.92it/s] 63%|██████▎   | 56964/90000 [03:57<02:17, 240.46it/s] 63%|██████▎   | 56989/90000 [03:57<02:19, 237.07it/s] 63%|██████▎   | 57014/90000 [03:57<02:18, 237.89it/s] 63%|██████▎   | 57040/90000 [03:58<02:16, 242.19it/s] 63%|██████▎   | 57065/90000 [03:58<02:15, 242.53it/s] 63%|██████▎   | 57090/90000 [03:58<02:15, 242.39it/s] 63%|██████▎   | 57115/90000 [03:58<02:15, 242.44it/s] 63%|██████▎   | 57140/90000 [03:58<02:18, 238.00it/s] 64%|██████▎   | 57165/90000 [03:58<02:16, 240.08it/s] 64%|██████▎   | 57190/90000 [03:58<02:17, 238.96it/s] 64%|██████▎   | 57215/90000 [03:58<02:16, 240.65it/s] 64%|██████▎   | 57240/90000 [03:58<02:16, 240.75it/s] 64%|██████▎   | 57265/90000 [03:58<02:15, 240.90it/s] 64%|██████▎   | 57290/90000 [03:59<02:16, 239.95it/s] 64%|██████▎   | 57315/90000 [03:59<02:16, 240.30it/s] 64%|██████▎   | 57340/90000 [03:59<02:14, 242.96it/s] 64%|██████▎   | 57365/90000 [03:59<02:15, 241.58it/s] 64%|██████▍   | 57390/90000 [03:59<02:13, 243.87it/s] 64%|██████▍   | 57416/90000 [03:59<02:12, 245.36it/s] 64%|██████▍   | 57441/90000 [03:59<02:15, 240.52it/s] 64%|██████▍   | 57466/90000 [03:59<02:15, 240.89it/s] 64%|██████▍   | 57491/90000 [03:59<02:16, 237.54it/s] 64%|██████▍   | 57515/90000 [04:00<02:17, 235.50it/s] 64%|██████▍   | 57540/90000 [04:00<02:16, 237.28it/s] 64%|██████▍   | 57564/90000 [04:00<02:17, 236.53it/s] 64%|██████▍   | 57589/90000 [04:00<02:15, 240.03it/s] 64%|██████▍   | 57614/90000 [04:00<02:13, 241.72it/s] 64%|██████▍   | 57639/90000 [04:00<02:15, 239.18it/s] 64%|██████▍   | 57665/90000 [04:00<02:12, 243.30it/s] 64%|██████▍   | 57690/90000 [04:00<02:12, 243.18it/s] 64%|██████▍   | 57715/90000 [04:00<02:14, 240.24it/s] 64%|██████▍   | 57740/90000 [04:00<02:15, 237.97it/s] 64%|██████▍   | 57765/90000 [04:01<02:13, 240.70it/s] 64%|██████▍   | 57790/90000 [04:01<02:14, 239.33it/s] 64%|██████▍   | 57815/90000 [04:01<02:13, 241.06it/s] 64%|██████▍   | 57840/90000 [04:01<02:15, 237.72it/s] 64%|██████▍   | 57864/90000 [04:01<02:16, 235.10it/s] 64%|██████▍   | 57889/90000 [04:01<02:15, 237.26it/s] 64%|██████▍   | 57914/90000 [04:01<02:15, 237.57it/s] 64%|██████▍   | 57938/90000 [04:01<02:15, 236.27it/s] 64%|██████▍   | 57962/90000 [04:01<02:16, 234.81it/s] 64%|██████▍   | 57986/90000 [04:01<02:16, 234.19it/s] 64%|██████▍   | 58012/90000 [04:02<02:13, 238.87it/s] 64%|██████▍   | 58036/90000 [04:02<02:15, 236.35it/s] 65%|██████▍   | 58061/90000 [04:02<02:14, 237.04it/s] 65%|██████▍   | 58085/90000 [04:02<02:14, 237.82it/s] 65%|██████▍   | 58110/90000 [04:02<02:13, 239.77it/s] 65%|██████▍   | 58134/90000 [04:02<02:13, 238.17it/s] 65%|██████▍   | 58159/90000 [04:02<02:12, 239.47it/s] 65%|██████▍   | 58183/90000 [04:02<02:14, 237.14it/s] 65%|██████▍   | 58207/90000 [04:02<02:14, 236.64it/s] 65%|██████▍   | 58232/90000 [04:03<02:12, 239.04it/s] 65%|██████▍   | 58257/90000 [04:03<02:12, 240.46it/s] 65%|██████▍   | 58282/90000 [04:03<02:12, 239.83it/s] 65%|██████▍   | 58308/90000 [04:03<02:10, 243.14it/s] 65%|██████▍   | 58333/90000 [04:03<02:10, 242.03it/s] 65%|██████▍   | 58358/90000 [04:03<02:10, 241.94it/s] 65%|██████▍   | 58383/90000 [04:03<02:12, 239.03it/s] 65%|██████▍   | 58407/90000 [04:03<02:12, 237.81it/s] 65%|██████▍   | 58431/90000 [04:03<02:13, 237.04it/s] 65%|██████▍   | 58456/90000 [04:03<02:12, 237.89it/s] 65%|██████▍   | 58480/90000 [04:04<02:13, 236.27it/s] 65%|██████▌   | 58505/90000 [04:04<02:12, 238.26it/s] 65%|██████▌   | 58530/90000 [04:04<02:10, 241.14it/s] 65%|██████▌   | 58556/90000 [04:04<02:08, 244.21it/s] 65%|██████▌   | 58581/90000 [04:04<02:08, 243.83it/s] 65%|██████▌   | 58606/90000 [04:04<02:10, 240.10it/s] 65%|██████▌   | 58632/90000 [04:04<02:07, 245.07it/s] 65%|██████▌   | 58657/90000 [04:04<02:07, 244.91it/s] 65%|██████▌   | 58682/90000 [04:04<02:09, 242.21it/s] 65%|██████▌   | 58707/90000 [04:04<02:10, 239.11it/s] 65%|██████▌   | 58731/90000 [04:05<02:11, 237.62it/s] 65%|██████▌   | 58755/90000 [04:05<02:12, 236.17it/s] 65%|██████▌   | 58779/90000 [04:05<02:11, 237.16it/s] 65%|██████▌   | 58803/90000 [04:05<02:11, 237.01it/s] 65%|██████▌   | 58829/90000 [04:05<02:09, 241.47it/s] 65%|██████▌   | 58854/90000 [04:05<02:09, 240.28it/s] 65%|██████▌   | 58879/90000 [04:05<02:09, 239.52it/s] 65%|██████▌   | 58903/90000 [04:05<02:10, 238.75it/s] 65%|██████▌   | 58927/90000 [04:05<02:11, 235.49it/s] 66%|██████▌   | 58952/90000 [04:06<02:10, 237.98it/s] 66%|██████▌   | 58976/90000 [04:06<02:12, 233.99it/s] 66%|██████▌   | 59001/90000 [04:06<02:10, 236.74it/s] 66%|██████▌   | 59026/90000 [04:06<02:09, 238.41it/s] 66%|██████▌   | 59052/90000 [04:06<02:06, 243.99it/s] 66%|██████▌   | 59077/90000 [04:06<02:07, 243.44it/s] 66%|██████▌   | 59102/90000 [04:06<02:08, 240.40it/s] 66%|██████▌   | 59127/90000 [04:06<02:11, 235.52it/s] 66%|██████▌   | 59151/90000 [04:06<02:11, 235.43it/s] 66%|██████▌   | 59177/90000 [04:06<02:08, 239.93it/s] 66%|██████▌   | 59203/90000 [04:07<02:06, 243.80it/s] 66%|██████▌   | 59228/90000 [04:07<02:07, 240.59it/s] 66%|██████▌   | 59253/90000 [04:07<02:10, 235.99it/s] 66%|██████▌   | 59277/90000 [04:07<02:10, 235.64it/s] 66%|██████▌   | 59301/90000 [04:07<02:11, 234.13it/s] 66%|██████▌   | 59326/90000 [04:07<02:09, 237.51it/s] 66%|██████▌   | 59350/90000 [04:07<02:09, 237.40it/s] 66%|██████▌   | 59375/90000 [04:07<02:07, 239.42it/s] 66%|██████▌   | 59399/90000 [04:07<02:09, 236.84it/s] 66%|██████▌   | 59423/90000 [04:08<02:09, 236.21it/s] 66%|██████▌   | 59449/90000 [04:08<02:06, 241.25it/s] 66%|██████▌   | 59474/90000 [04:08<02:07, 238.99it/s] 66%|██████▌   | 59498/90000 [04:08<02:08, 237.21it/s] 66%|██████▌   | 59523/90000 [04:08<02:07, 238.96it/s] 66%|██████▌   | 59548/90000 [04:08<02:05, 242.01it/s] 66%|██████▌   | 59573/90000 [04:08<02:06, 240.39it/s] 66%|██████▌   | 59598/90000 [04:08<02:06, 240.37it/s] 66%|██████▌   | 59623/90000 [04:08<02:06, 240.27it/s] 66%|██████▋   | 59648/90000 [04:08<02:04, 242.92it/s] 66%|██████▋   | 59673/90000 [04:09<02:06, 240.06it/s] 66%|██████▋   | 59698/90000 [04:09<02:04, 242.70it/s] 66%|██████▋   | 59723/90000 [04:09<02:04, 242.39it/s] 66%|██████▋   | 59748/90000 [04:09<02:05, 241.06it/s] 66%|██████▋   | 59774/90000 [04:09<02:03, 244.45it/s] 66%|██████▋   | 59799/90000 [04:09<02:03, 245.46it/s] 66%|██████▋   | 59824/90000 [04:09<02:03, 243.54it/s] 66%|██████▋   | 59849/90000 [04:09<02:04, 241.57it/s] 67%|██████▋   | 59874/90000 [04:09<02:05, 240.11it/s] 67%|██████▋   | 59899/90000 [04:09<02:04, 242.01it/s] 67%|██████▋   | 59924/90000 [04:10<02:03, 242.66it/s] 67%|██████▋   | 59949/90000 [04:10<02:04, 241.60it/s] 67%|██████▋   | 59974/90000 [04:10<02:04, 240.67it/s] 67%|██████▋   | 59999/90000 [04:10<02:05, 239.12it/s] 67%|██████▋   | 60025/90000 [04:10<02:04, 241.06it/s] 67%|██████▋   | 60050/90000 [04:10<02:04, 239.97it/s] 67%|██████▋   | 60074/90000 [04:10<02:05, 237.70it/s] 67%|██████▋   | 60098/90000 [04:10<02:05, 237.47it/s] 67%|██████▋   | 60123/90000 [04:10<02:04, 240.69it/s] 67%|██████▋   | 60148/90000 [04:11<02:03, 241.35it/s] 67%|██████▋   | 60173/90000 [04:11<02:05, 237.55it/s] 67%|██████▋   | 60197/90000 [04:11<02:06, 234.84it/s] 67%|██████▋   | 60222/90000 [04:11<02:05, 236.97it/s] 67%|██████▋   | 60246/90000 [04:11<02:08, 232.11it/s] 67%|██████▋   | 60272/90000 [04:11<02:04, 238.72it/s] 67%|██████▋   | 60296/90000 [04:11<02:04, 238.76it/s] 67%|██████▋   | 60320/90000 [04:11<02:05, 236.55it/s] 67%|██████▋   | 60345/90000 [04:11<02:04, 238.54it/s] 67%|██████▋   | 60370/90000 [04:11<02:03, 240.47it/s] 67%|██████▋   | 60396/90000 [04:12<02:01, 244.22it/s] 67%|██████▋   | 60421/90000 [04:12<02:00, 244.91it/s] 67%|██████▋   | 60446/90000 [04:12<02:04, 238.14it/s] 67%|██████▋   | 60470/90000 [04:12<02:05, 235.55it/s] 67%|██████▋   | 60495/90000 [04:12<02:04, 237.89it/s] 67%|██████▋   | 60519/90000 [04:12<02:05, 235.15it/s] 67%|██████▋   | 60543/90000 [04:12<02:05, 234.48it/s] 67%|██████▋   | 60568/90000 [04:12<02:03, 237.88it/s] 67%|██████▋   | 60592/90000 [04:12<02:04, 235.93it/s] 67%|██████▋   | 60617/90000 [04:12<02:03, 238.55it/s] 67%|██████▋   | 60642/90000 [04:13<02:01, 241.09it/s] 67%|██████▋   | 60667/90000 [04:13<02:02, 239.50it/s] 67%|██████▋   | 60692/90000 [04:13<02:01, 241.25it/s] 67%|██████▋   | 60717/90000 [04:13<02:02, 239.86it/s] 67%|██████▋   | 60741/90000 [04:13<02:03, 237.26it/s] 68%|██████▊   | 60766/90000 [04:13<02:02, 239.34it/s] 68%|██████▊   | 60791/90000 [04:13<02:00, 241.41it/s] 68%|██████▊   | 60816/90000 [04:13<02:01, 240.62it/s] 68%|██████▊   | 60842/90000 [04:13<01:58, 245.68it/s] 68%|██████▊   | 60867/90000 [04:14<01:58, 246.45it/s] 68%|██████▊   | 60892/90000 [04:14<01:58, 245.16it/s] 68%|██████▊   | 60917/90000 [04:14<01:58, 246.37it/s] 68%|██████▊   | 60943/90000 [04:14<01:57, 247.52it/s] 68%|██████▊   | 60968/90000 [04:14<01:58, 245.90it/s] 68%|██████▊   | 60993/90000 [04:14<01:59, 242.62it/s] 68%|██████▊   | 61018/90000 [04:14<01:59, 241.76it/s] 68%|██████▊   | 61043/90000 [04:14<02:00, 239.64it/s] 68%|██████▊   | 61068/90000 [04:14<02:00, 240.14it/s] 68%|██████▊   | 61093/90000 [04:14<02:00, 239.68it/s] 68%|██████▊   | 61118/90000 [04:15<01:59, 240.69it/s] 68%|██████▊   | 61143/90000 [04:15<01:58, 242.86it/s] 68%|██████▊   | 61168/90000 [04:15<01:59, 240.80it/s] 68%|██████▊   | 61193/90000 [04:15<01:59, 241.41it/s] 68%|██████▊   | 61218/90000 [04:15<01:59, 240.62it/s] 68%|██████▊   | 61243/90000 [04:15<01:58, 243.23it/s] 68%|██████▊   | 61268/90000 [04:15<01:58, 243.20it/s] 68%|██████▊   | 61294/90000 [04:15<01:57, 244.28it/s] 68%|██████▊   | 61319/90000 [04:15<01:58, 241.53it/s] 68%|██████▊   | 61344/90000 [04:15<01:58, 242.45it/s] 68%|██████▊   | 61369/90000 [04:16<01:57, 243.63it/s] 68%|██████▊   | 61394/90000 [04:16<01:59, 239.13it/s] 68%|██████▊   | 61418/90000 [04:16<01:59, 238.75it/s] 68%|██████▊   | 61442/90000 [04:16<01:59, 238.25it/s] 68%|██████▊   | 61466/90000 [04:16<01:59, 237.80it/s] 68%|██████▊   | 61491/90000 [04:16<01:59, 238.63it/s] 68%|██████▊   | 61515/90000 [04:16<02:00, 236.14it/s] 68%|██████▊   | 61540/90000 [04:16<01:59, 238.90it/s] 68%|██████▊   | 61565/90000 [04:16<01:57, 241.76it/s] 68%|██████▊   | 61590/90000 [04:17<01:58, 239.17it/s] 68%|██████▊   | 61615/90000 [04:17<01:58, 239.61it/s] 68%|██████▊   | 61640/90000 [04:17<01:57, 240.56it/s] 69%|██████▊   | 61665/90000 [04:17<01:57, 241.09it/s] 69%|██████▊   | 61690/90000 [04:17<01:58, 239.38it/s] 69%|██████▊   | 61715/90000 [04:17<01:57, 240.23it/s] 69%|██████▊   | 61741/90000 [04:17<01:56, 243.47it/s] 69%|██████▊   | 61766/90000 [04:17<01:55, 244.37it/s] 69%|██████▊   | 61791/90000 [04:17<01:54, 245.38it/s] 69%|██████▊   | 61816/90000 [04:17<01:55, 243.87it/s] 69%|██████▊   | 61841/90000 [04:18<01:56, 242.03it/s] 69%|██████▊   | 61866/90000 [04:18<01:55, 243.27it/s] 69%|██████▉   | 61891/90000 [04:18<01:57, 239.63it/s] 69%|██████▉   | 61915/90000 [04:18<01:57, 239.02it/s] 69%|██████▉   | 61940/90000 [04:18<01:57, 238.85it/s] 69%|██████▉   | 61964/90000 [04:18<01:57, 238.77it/s] 69%|██████▉   | 61988/90000 [04:18<01:57, 238.17it/s] 69%|██████▉   | 62012/90000 [04:18<01:58, 236.80it/s] 69%|██████▉   | 62037/90000 [04:18<01:57, 238.78it/s] 69%|██████▉   | 62062/90000 [04:18<01:55, 241.03it/s] 69%|██████▉   | 62087/90000 [04:19<01:56, 240.38it/s] 69%|██████▉   | 62112/90000 [04:19<01:55, 241.28it/s] 69%|██████▉   | 62138/90000 [04:19<01:53, 244.87it/s] 69%|██████▉   | 62163/90000 [04:19<01:54, 244.18it/s] 69%|██████▉   | 62188/90000 [04:19<01:53, 245.65it/s] 69%|██████▉   | 62213/90000 [04:19<01:53, 244.48it/s] 69%|██████▉   | 62238/90000 [04:19<01:54, 241.67it/s] 69%|██████▉   | 62263/90000 [04:19<01:56, 238.33it/s] 69%|██████▉   | 62287/90000 [04:19<01:56, 238.79it/s] 69%|██████▉   | 62312/90000 [04:20<01:55, 240.34it/s] 69%|██████▉   | 62337/90000 [04:20<01:56, 237.99it/s] 69%|██████▉   | 62362/90000 [04:20<01:54, 240.81it/s] 69%|██████▉   | 62387/90000 [04:20<01:57, 235.57it/s] 69%|██████▉   | 62413/90000 [04:20<01:55, 239.88it/s] 69%|██████▉   | 62438/90000 [04:20<01:55, 238.03it/s] 69%|██████▉   | 62463/90000 [04:20<01:54, 241.11it/s] 69%|██████▉   | 62488/90000 [04:20<01:54, 241.02it/s] 69%|██████▉   | 62513/90000 [04:20<01:54, 240.91it/s] 69%|██████▉   | 62538/90000 [04:20<01:53, 241.50it/s] 70%|██████▉   | 62563/90000 [04:21<01:52, 243.19it/s] 70%|██████▉   | 62588/90000 [04:21<01:53, 240.88it/s] 70%|██████▉   | 62613/90000 [04:21<01:53, 240.64it/s] 70%|██████▉   | 62639/90000 [04:21<01:52, 243.92it/s] 70%|██████▉   | 62664/90000 [04:21<01:53, 241.75it/s] 70%|██████▉   | 62689/90000 [04:21<01:54, 237.76it/s] 70%|██████▉   | 62714/90000 [04:21<01:53, 240.20it/s] 70%|██████▉   | 62740/90000 [04:21<01:51, 243.92it/s] 70%|██████▉   | 62765/90000 [04:21<01:51, 244.30it/s] 70%|██████▉   | 62790/90000 [04:21<01:50, 245.57it/s] 70%|██████▉   | 62815/90000 [04:22<01:50, 245.05it/s] 70%|██████▉   | 62840/90000 [04:22<01:51, 243.27it/s] 70%|██████▉   | 62865/90000 [04:22<01:50, 244.98it/s] 70%|██████▉   | 62890/90000 [04:22<01:51, 244.05it/s] 70%|██████▉   | 62916/90000 [04:22<01:49, 247.24it/s] 70%|██████▉   | 62941/90000 [04:22<01:56, 231.46it/s] 70%|██████▉   | 62965/90000 [04:22<01:55, 233.55it/s] 70%|██████▉   | 62989/90000 [04:22<01:55, 234.71it/s] 70%|███████   | 63013/90000 [04:22<01:54, 234.94it/s] 70%|███████   | 63037/90000 [04:23<01:54, 235.98it/s] 70%|███████   | 63062/90000 [04:23<01:52, 238.57it/s] 70%|███████   | 63086/90000 [04:23<01:54, 235.48it/s] 70%|███████   | 63112/90000 [04:23<01:51, 240.13it/s] 70%|███████   | 63137/90000 [04:23<01:50, 242.75it/s] 70%|███████   | 63162/90000 [04:23<01:52, 238.51it/s] 70%|███████   | 63187/90000 [04:23<01:51, 239.74it/s] 70%|███████   | 63212/90000 [04:23<01:50, 242.37it/s] 70%|███████   | 63237/90000 [04:23<01:49, 244.25it/s] 70%|███████   | 63262/90000 [04:23<01:51, 240.12it/s] 70%|███████   | 63288/90000 [04:24<01:49, 244.70it/s] 70%|███████   | 63313/90000 [04:24<01:50, 242.50it/s] 70%|███████   | 63338/90000 [04:24<01:51, 239.97it/s] 70%|███████   | 63363/90000 [04:24<01:50, 242.10it/s] 70%|███████   | 63388/90000 [04:24<01:49, 242.78it/s] 70%|███████   | 63413/90000 [04:24<01:49, 241.70it/s] 70%|███████   | 63438/90000 [04:24<01:49, 243.55it/s] 71%|███████   | 63463/90000 [04:24<01:50, 240.83it/s] 71%|███████   | 63488/90000 [04:24<01:49, 242.24it/s] 71%|███████   | 63513/90000 [04:24<01:50, 240.57it/s] 71%|███████   | 63539/90000 [04:25<01:48, 243.63it/s] 71%|███████   | 63564/90000 [04:25<01:48, 244.47it/s] 71%|███████   | 63589/90000 [04:25<01:48, 244.17it/s] 71%|███████   | 63614/90000 [04:25<01:49, 241.29it/s] 71%|███████   | 63639/90000 [04:25<01:49, 241.69it/s] 71%|███████   | 63665/90000 [04:25<01:48, 243.59it/s] 71%|███████   | 63690/90000 [04:25<01:49, 240.71it/s] 71%|███████   | 63715/90000 [04:25<01:48, 242.19it/s] 71%|███████   | 63740/90000 [04:25<01:48, 241.72it/s] 71%|███████   | 63765/90000 [04:26<01:48, 241.93it/s] 71%|███████   | 63790/90000 [04:26<01:48, 241.73it/s] 71%|███████   | 63815/90000 [04:26<01:47, 242.52it/s] 71%|███████   | 63840/90000 [04:26<01:47, 243.57it/s] 71%|███████   | 63865/90000 [04:26<01:48, 240.58it/s] 71%|███████   | 63891/90000 [04:26<01:47, 243.78it/s] 71%|███████   | 63916/90000 [04:26<01:48, 239.54it/s] 71%|███████   | 63941/90000 [04:26<01:48, 241.26it/s] 71%|███████   | 63966/90000 [04:26<01:48, 240.27it/s] 71%|███████   | 63991/90000 [04:26<01:50, 235.71it/s] 71%|███████   | 64015/90000 [04:27<01:50, 235.38it/s] 71%|███████   | 64039/90000 [04:27<01:50, 234.80it/s] 71%|███████   | 64063/90000 [04:27<01:49, 236.19it/s] 71%|███████   | 64088/90000 [04:27<01:49, 237.62it/s] 71%|███████   | 64113/90000 [04:27<01:48, 239.62it/s] 71%|███████▏  | 64137/90000 [04:27<01:48, 238.48it/s] 71%|███████▏  | 64162/90000 [04:27<01:47, 241.11it/s] 71%|███████▏  | 64187/90000 [04:27<01:47, 239.77it/s] 71%|███████▏  | 64211/90000 [04:27<01:47, 239.49it/s] 71%|███████▏  | 64237/90000 [04:27<01:45, 243.57it/s] 71%|███████▏  | 64262/90000 [04:28<01:46, 241.07it/s] 71%|███████▏  | 64287/90000 [04:28<01:46, 241.54it/s] 71%|███████▏  | 64312/90000 [04:28<01:46, 242.19it/s] 71%|███████▏  | 64338/90000 [04:28<01:44, 245.17it/s] 72%|███████▏  | 64363/90000 [04:28<01:44, 246.07it/s] 72%|███████▏  | 64388/90000 [04:28<01:44, 244.88it/s] 72%|███████▏  | 64413/90000 [04:28<01:45, 243.27it/s] 72%|███████▏  | 64438/90000 [04:28<01:45, 241.70it/s] 72%|███████▏  | 64463/90000 [04:28<01:45, 243.09it/s] 72%|███████▏  | 64488/90000 [04:29<01:45, 241.76it/s] 72%|███████▏  | 64513/90000 [04:29<01:46, 239.32it/s] 72%|███████▏  | 64538/90000 [04:29<01:45, 240.54it/s] 72%|███████▏  | 64563/90000 [04:29<01:45, 241.74it/s] 72%|███████▏  | 64588/90000 [04:29<01:44, 243.48it/s] 72%|███████▏  | 64613/90000 [04:29<01:45, 240.13it/s] 72%|███████▏  | 64638/90000 [04:29<01:44, 242.73it/s] 72%|███████▏  | 64663/90000 [04:29<01:45, 241.29it/s] 72%|███████▏  | 64688/90000 [04:29<01:45, 239.33it/s] 72%|███████▏  | 64713/90000 [04:29<01:45, 240.69it/s] 72%|███████▏  | 64738/90000 [04:30<01:46, 236.78it/s] 72%|███████▏  | 64763/90000 [04:30<01:45, 239.45it/s] 72%|███████▏  | 64789/90000 [04:30<01:43, 244.26it/s] 72%|███████▏  | 64814/90000 [04:30<01:43, 244.04it/s] 72%|███████▏  | 64839/90000 [04:30<01:42, 245.22it/s] 72%|███████▏  | 64864/90000 [04:30<01:42, 245.73it/s] 72%|███████▏  | 64889/90000 [04:30<01:43, 242.39it/s] 72%|███████▏  | 64914/90000 [04:30<01:44, 240.17it/s] 72%|███████▏  | 64939/90000 [04:30<01:44, 238.72it/s] 72%|███████▏  | 64963/90000 [04:31<01:44, 239.03it/s] 72%|███████▏  | 64988/90000 [04:31<01:44, 239.61it/s] 72%|███████▏  | 65012/90000 [04:31<01:44, 238.37it/s] 72%|███████▏  | 65038/90000 [04:31<01:42, 243.17it/s] 72%|███████▏  | 65063/90000 [04:31<01:42, 244.11it/s] 72%|███████▏  | 65088/90000 [04:31<01:42, 243.05it/s] 72%|███████▏  | 65113/90000 [04:31<01:43, 239.90it/s] 72%|███████▏  | 65138/90000 [04:31<01:42, 241.54it/s] 72%|███████▏  | 65163/90000 [04:31<01:42, 243.37it/s] 72%|███████▏  | 65188/90000 [04:31<01:44, 237.94it/s] 72%|███████▏  | 65213/90000 [04:32<01:44, 237.80it/s] 72%|███████▏  | 65239/90000 [04:32<01:41, 242.80it/s] 73%|███████▎  | 65264/90000 [04:32<01:42, 240.93it/s] 73%|███████▎  | 65289/90000 [04:32<01:43, 238.95it/s] 73%|███████▎  | 65313/90000 [04:32<01:44, 237.00it/s] 73%|███████▎  | 65338/90000 [04:32<01:43, 238.91it/s] 73%|███████▎  | 65363/90000 [04:32<01:41, 241.62it/s] 73%|███████▎  | 65388/90000 [04:32<01:41, 243.08it/s] 73%|███████▎  | 65413/90000 [04:32<01:41, 242.71it/s] 73%|███████▎  | 65438/90000 [04:32<01:40, 244.31it/s] 73%|███████▎  | 65463/90000 [04:33<01:40, 245.08it/s] 73%|███████▎  | 65488/90000 [04:33<01:42, 239.04it/s] 73%|███████▎  | 65513/90000 [04:33<01:41, 240.90it/s] 73%|███████▎  | 65538/90000 [04:33<01:41, 241.45it/s] 73%|███████▎  | 65563/90000 [04:33<01:41, 241.00it/s] 73%|███████▎  | 65588/90000 [04:33<01:42, 237.49it/s] 73%|███████▎  | 65612/90000 [04:33<01:42, 237.84it/s] 73%|███████▎  | 65636/90000 [04:33<01:44, 234.08it/s] 73%|███████▎  | 65660/90000 [04:33<01:45, 230.72it/s] 73%|███████▎  | 65685/90000 [04:34<01:43, 234.07it/s] 73%|███████▎  | 65709/90000 [04:34<01:43, 233.69it/s] 73%|███████▎  | 65734/90000 [04:34<01:42, 235.81it/s] 73%|███████▎  | 65758/90000 [04:34<01:42, 235.38it/s] 73%|███████▎  | 65782/90000 [04:34<01:42, 236.52it/s] 73%|███████▎  | 65807/90000 [04:34<01:41, 238.02it/s] 73%|███████▎  | 65831/90000 [04:34<01:41, 238.40it/s] 73%|███████▎  | 65856/90000 [04:34<01:39, 241.74it/s] 73%|███████▎  | 65882/90000 [04:34<01:38, 245.79it/s] 73%|███████▎  | 65907/90000 [04:34<01:39, 241.94it/s] 73%|███████▎  | 65932/90000 [04:35<01:38, 243.86it/s] 73%|███████▎  | 65957/90000 [04:35<01:39, 241.48it/s] 73%|███████▎  | 65982/90000 [04:35<01:40, 238.58it/s] 73%|███████▎  | 66007/90000 [04:35<01:40, 239.87it/s] 73%|███████▎  | 66032/90000 [04:35<01:41, 236.93it/s] 73%|███████▎  | 66056/90000 [04:35<01:40, 237.33it/s] 73%|███████▎  | 66081/90000 [04:35<01:40, 238.78it/s] 73%|███████▎  | 66105/90000 [04:35<01:40, 238.48it/s] 73%|███████▎  | 66130/90000 [04:35<01:39, 239.25it/s] 74%|███████▎  | 66154/90000 [04:35<01:39, 239.04it/s] 74%|███████▎  | 66178/90000 [04:36<01:39, 238.51it/s] 74%|███████▎  | 66203/90000 [04:36<01:39, 240.03it/s] 74%|███████▎  | 66228/90000 [04:36<01:38, 240.52it/s] 74%|███████▎  | 66253/90000 [04:36<01:38, 239.94it/s] 74%|███████▎  | 66278/90000 [04:36<01:37, 242.55it/s] 74%|███████▎  | 66303/90000 [04:36<01:37, 243.48it/s] 74%|███████▎  | 66328/90000 [04:36<01:39, 239.05it/s] 74%|███████▎  | 66352/90000 [04:36<01:39, 237.26it/s] 74%|███████▍  | 66377/90000 [04:36<01:39, 237.90it/s] 74%|███████▍  | 66401/90000 [04:37<01:42, 230.55it/s] 74%|███████▍  | 66425/90000 [04:37<01:43, 228.80it/s] 74%|███████▍  | 66450/90000 [04:37<01:40, 233.90it/s] 74%|███████▍  | 66474/90000 [04:37<01:41, 232.29it/s] 74%|███████▍  | 66499/90000 [04:37<01:39, 235.25it/s] 74%|███████▍  | 66524/90000 [04:37<01:38, 237.57it/s] 74%|███████▍  | 66549/90000 [04:37<01:37, 240.14it/s] 74%|███████▍  | 66574/90000 [04:37<01:38, 237.45it/s] 74%|███████▍  | 66598/90000 [04:37<01:38, 237.62it/s] 74%|███████▍  | 66623/90000 [04:37<01:36, 241.07it/s] 74%|███████▍  | 66648/90000 [04:38<01:36, 242.73it/s] 74%|███████▍  | 66673/90000 [04:38<01:35, 243.72it/s] 74%|███████▍  | 66698/90000 [04:38<01:35, 244.93it/s] 74%|███████▍  | 66723/90000 [04:38<01:35, 243.80it/s] 74%|███████▍  | 66748/90000 [04:38<01:34, 245.03it/s] 74%|███████▍  | 66773/90000 [04:38<01:35, 242.35it/s] 74%|███████▍  | 66798/90000 [04:38<01:35, 242.16it/s] 74%|███████▍  | 66823/90000 [04:38<01:34, 244.02it/s] 74%|███████▍  | 66848/90000 [04:38<01:35, 242.69it/s] 74%|███████▍  | 66873/90000 [04:38<01:36, 240.83it/s] 74%|███████▍  | 66898/90000 [04:39<01:36, 239.30it/s] 74%|███████▍  | 66922/90000 [04:39<01:38, 235.34it/s] 74%|███████▍  | 66947/90000 [04:39<01:36, 238.54it/s] 74%|███████▍  | 66971/90000 [04:39<01:37, 235.00it/s] 74%|███████▍  | 66995/90000 [04:39<01:39, 231.06it/s] 74%|███████▍  | 67019/90000 [04:39<01:39, 229.95it/s] 74%|███████▍  | 67045/90000 [04:39<01:37, 236.10it/s] 75%|███████▍  | 67069/90000 [04:39<01:37, 235.53it/s] 75%|███████▍  | 67094/90000 [04:39<01:35, 238.83it/s] 75%|███████▍  | 67119/90000 [04:40<01:34, 241.90it/s] 75%|███████▍  | 67144/90000 [04:40<01:34, 241.81it/s] 75%|███████▍  | 67169/90000 [04:40<01:34, 242.34it/s] 75%|███████▍  | 67194/90000 [04:40<01:35, 238.20it/s] 75%|███████▍  | 67218/90000 [04:40<01:35, 237.97it/s] 75%|███████▍  | 67245/90000 [04:40<01:33, 243.13it/s] 75%|███████▍  | 67270/90000 [04:40<01:34, 241.78it/s] 75%|███████▍  | 67295/90000 [04:40<01:35, 237.68it/s] 75%|███████▍  | 67320/90000 [04:40<01:35, 238.59it/s] 75%|███████▍  | 67345/90000 [04:40<01:34, 240.31it/s] 75%|███████▍  | 67370/90000 [04:41<01:33, 242.10it/s] 75%|███████▍  | 67395/90000 [04:41<01:32, 244.04it/s] 75%|███████▍  | 67420/90000 [04:41<01:32, 243.98it/s] 75%|███████▍  | 67445/90000 [04:41<01:32, 242.88it/s] 75%|███████▍  | 67471/90000 [04:41<01:31, 245.68it/s] 75%|███████▍  | 67496/90000 [04:41<01:31, 245.24it/s] 75%|███████▌  | 67521/90000 [04:41<01:32, 242.25it/s] 75%|███████▌  | 67546/90000 [04:41<01:33, 240.86it/s] 75%|███████▌  | 67571/90000 [04:41<01:33, 240.87it/s] 75%|███████▌  | 67596/90000 [04:41<01:32, 241.37it/s] 75%|███████▌  | 67621/90000 [04:42<01:32, 242.81it/s] 75%|███████▌  | 67646/90000 [04:42<01:32, 241.88it/s] 75%|███████▌  | 67671/90000 [04:42<01:33, 238.54it/s] 75%|███████▌  | 67695/90000 [04:42<01:33, 238.69it/s] 75%|███████▌  | 67719/90000 [04:42<01:35, 234.43it/s] 75%|███████▌  | 67743/90000 [04:42<01:34, 235.28it/s] 75%|███████▌  | 67767/90000 [04:42<01:36, 231.51it/s] 75%|███████▌  | 67792/90000 [04:42<01:34, 234.22it/s] 75%|███████▌  | 67817/90000 [04:42<01:33, 237.92it/s] 75%|███████▌  | 67842/90000 [04:43<01:32, 240.02it/s] 75%|███████▌  | 67867/90000 [04:43<01:31, 240.88it/s] 75%|███████▌  | 67892/90000 [04:43<01:32, 238.90it/s] 75%|███████▌  | 67917/90000 [04:43<01:32, 239.42it/s] 75%|███████▌  | 67941/90000 [04:43<01:32, 237.28it/s] 76%|███████▌  | 67966/90000 [04:43<01:32, 238.12it/s] 76%|███████▌  | 67990/90000 [04:43<01:32, 237.66it/s] 76%|███████▌  | 68014/90000 [04:43<01:32, 236.81it/s] 76%|███████▌  | 68038/90000 [04:43<01:32, 237.54it/s] 76%|███████▌  | 68062/90000 [04:43<01:32, 237.04it/s] 76%|███████▌  | 68088/90000 [04:44<01:31, 239.94it/s] 76%|███████▌  | 68113/90000 [04:44<01:30, 241.87it/s] 76%|███████▌  | 68138/90000 [04:44<01:30, 242.12it/s] 76%|███████▌  | 68163/90000 [04:44<01:29, 243.24it/s] 76%|███████▌  | 68188/90000 [04:44<01:29, 244.04it/s] 76%|███████▌  | 68213/90000 [04:44<01:29, 242.67it/s] 76%|███████▌  | 68239/90000 [04:44<01:28, 246.27it/s] 76%|███████▌  | 68264/90000 [04:44<01:29, 243.68it/s] 76%|███████▌  | 68289/90000 [04:44<01:28, 244.04it/s] 76%|███████▌  | 68314/90000 [04:44<01:29, 242.81it/s] 76%|███████▌  | 68339/90000 [04:45<01:29, 242.29it/s] 76%|███████▌  | 68364/90000 [04:45<01:29, 243.00it/s] 76%|███████▌  | 68389/90000 [04:45<01:30, 237.52it/s] 76%|███████▌  | 68413/90000 [04:45<01:30, 237.28it/s] 76%|███████▌  | 68438/90000 [04:45<01:30, 239.23it/s] 76%|███████▌  | 68463/90000 [04:45<01:29, 240.57it/s] 76%|███████▌  | 68488/90000 [04:45<01:30, 238.05it/s] 76%|███████▌  | 68512/90000 [04:45<01:30, 238.01it/s] 76%|███████▌  | 68537/90000 [04:45<01:29, 240.69it/s] 76%|███████▌  | 68562/90000 [04:46<01:28, 241.87it/s] 76%|███████▌  | 68587/90000 [04:46<01:28, 242.50it/s] 76%|███████▌  | 68613/90000 [04:46<01:27, 244.83it/s] 76%|███████▋  | 68638/90000 [04:46<01:27, 244.91it/s] 76%|███████▋  | 68663/90000 [04:46<01:29, 239.48it/s] 76%|███████▋  | 68688/90000 [04:46<01:28, 241.29it/s] 76%|███████▋  | 68713/90000 [04:46<01:28, 241.65it/s] 76%|███████▋  | 68738/90000 [04:46<01:28, 241.01it/s] 76%|███████▋  | 68763/90000 [04:46<01:28, 238.97it/s] 76%|███████▋  | 68788/90000 [04:46<01:28, 239.67it/s] 76%|███████▋  | 68812/90000 [04:47<01:29, 237.74it/s] 76%|███████▋  | 68836/90000 [04:47<01:29, 237.09it/s] 77%|███████▋  | 68861/90000 [04:47<01:28, 239.11it/s] 77%|███████▋  | 68886/90000 [04:47<01:28, 239.50it/s] 77%|███████▋  | 68910/90000 [04:47<01:29, 234.71it/s] 77%|███████▋  | 68934/90000 [04:47<01:29, 234.13it/s] 77%|███████▋  | 68960/90000 [04:47<01:27, 240.25it/s] 77%|███████▋  | 68985/90000 [04:47<01:26, 241.82it/s] 77%|███████▋  | 69010/90000 [04:47<01:26, 241.28it/s] 77%|███████▋  | 69035/90000 [04:47<01:27, 240.88it/s] 77%|███████▋  | 69060/90000 [04:48<01:26, 242.58it/s] 77%|███████▋  | 69085/90000 [04:48<01:27, 239.07it/s] 77%|███████▋  | 69110/90000 [04:48<01:26, 242.09it/s] 77%|███████▋  | 69136/90000 [04:48<01:24, 246.62it/s] 77%|███████▋  | 69161/90000 [04:48<01:24, 247.37it/s] 77%|███████▋  | 69186/90000 [04:48<01:26, 241.09it/s] 77%|███████▋  | 69211/90000 [04:48<01:25, 243.54it/s] 77%|███████▋  | 69236/90000 [04:48<01:25, 241.59it/s] 77%|███████▋  | 69262/90000 [04:48<01:25, 243.98it/s] 77%|███████▋  | 69287/90000 [04:49<01:25, 243.30it/s] 77%|███████▋  | 69312/90000 [04:49<01:26, 238.95it/s] 77%|███████▋  | 69336/90000 [04:49<01:26, 239.06it/s] 77%|███████▋  | 69360/90000 [04:49<01:26, 238.02it/s] 77%|███████▋  | 69386/90000 [04:49<01:25, 242.07it/s] 77%|███████▋  | 69411/90000 [04:49<01:26, 239.04it/s] 77%|███████▋  | 69435/90000 [04:49<01:26, 238.83it/s] 77%|███████▋  | 69459/90000 [04:49<01:26, 238.14it/s] 77%|███████▋  | 69485/90000 [04:49<01:24, 242.02it/s] 77%|███████▋  | 69510/90000 [04:49<01:25, 240.97it/s] 77%|███████▋  | 69536/90000 [04:50<01:23, 244.19it/s] 77%|███████▋  | 69561/90000 [04:50<01:23, 245.58it/s] 77%|███████▋  | 69586/90000 [04:50<01:22, 246.31it/s] 77%|███████▋  | 69611/90000 [04:50<01:23, 242.96it/s] 77%|███████▋  | 69636/90000 [04:50<01:23, 243.65it/s] 77%|███████▋  | 69661/90000 [04:50<01:23, 243.24it/s] 77%|███████▋  | 69686/90000 [04:50<01:24, 241.35it/s] 77%|███████▋  | 69711/90000 [04:50<01:24, 240.73it/s] 77%|███████▋  | 69736/90000 [04:50<01:23, 242.04it/s] 78%|███████▊  | 69761/90000 [04:50<01:24, 240.06it/s] 78%|███████▊  | 69786/90000 [04:51<01:23, 241.20it/s] 78%|███████▊  | 69811/90000 [04:51<01:23, 242.63it/s] 78%|███████▊  | 69836/90000 [04:51<01:24, 239.43it/s] 78%|███████▊  | 69861/90000 [04:51<01:23, 239.96it/s] 78%|███████▊  | 69886/90000 [04:51<01:23, 241.16it/s] 78%|███████▊  | 69911/90000 [04:51<01:22, 242.87it/s] 78%|███████▊  | 69936/90000 [04:51<01:22, 243.17it/s] 78%|███████▊  | 69961/90000 [04:51<01:23, 238.77it/s] 78%|███████▊  | 69985/90000 [04:51<01:24, 237.49it/s] 78%|███████▊  | 70009/90000 [04:52<01:24, 237.18it/s] 78%|███████▊  | 70033/90000 [04:52<01:24, 237.57it/s] 78%|███████▊  | 70059/90000 [04:52<01:22, 241.33it/s] 78%|███████▊  | 70084/90000 [04:52<01:23, 237.68it/s] 78%|███████▊  | 70110/90000 [04:52<01:22, 242.03it/s] 78%|███████▊  | 70135/90000 [04:52<01:22, 240.85it/s] 78%|███████▊  | 70161/90000 [04:52<01:20, 245.92it/s] 78%|███████▊  | 70186/90000 [04:52<01:21, 242.24it/s] 78%|███████▊  | 70211/90000 [04:52<01:22, 240.62it/s] 78%|███████▊  | 70236/90000 [04:52<01:23, 235.39it/s] 78%|███████▊  | 70262/90000 [04:53<01:22, 240.22it/s] 78%|███████▊  | 70287/90000 [04:53<01:21, 240.75it/s] 78%|███████▊  | 70312/90000 [04:53<01:21, 242.09it/s] 78%|███████▊  | 70337/90000 [04:53<01:21, 240.10it/s] 78%|███████▊  | 70362/90000 [04:53<01:21, 239.69it/s] 78%|███████▊  | 70387/90000 [04:53<01:20, 242.27it/s] 78%|███████▊  | 70412/90000 [04:53<01:20, 241.91it/s] 78%|███████▊  | 70438/90000 [04:53<01:19, 245.11it/s] 78%|███████▊  | 70463/90000 [04:53<01:20, 241.48it/s] 78%|███████▊  | 70488/90000 [04:54<01:22, 237.50it/s] 78%|███████▊  | 70514/90000 [04:54<01:20, 241.57it/s] 78%|███████▊  | 70539/90000 [04:54<01:20, 242.79it/s] 78%|███████▊  | 70564/90000 [04:54<01:21, 239.59it/s] 78%|███████▊  | 70588/90000 [04:54<01:21, 237.10it/s] 78%|███████▊  | 70613/90000 [04:54<01:20, 239.35it/s] 78%|███████▊  | 70638/90000 [04:54<01:20, 241.60it/s] 79%|███████▊  | 70663/90000 [04:54<01:19, 243.54it/s] 79%|███████▊  | 70688/90000 [04:54<01:18, 244.64it/s] 79%|███████▊  | 70713/90000 [04:54<01:18, 245.42it/s] 79%|███████▊  | 70738/90000 [04:55<01:19, 242.97it/s] 79%|███████▊  | 70764/90000 [04:55<01:18, 244.61it/s] 79%|███████▊  | 70790/90000 [04:55<01:17, 246.51it/s] 79%|███████▊  | 70815/90000 [04:55<01:18, 244.88it/s] 79%|███████▊  | 70841/90000 [04:55<01:17, 246.35it/s] 79%|███████▊  | 70866/90000 [04:55<01:17, 246.86it/s] 79%|███████▉  | 70891/90000 [04:55<01:19, 241.82it/s] 79%|███████▉  | 70916/90000 [04:55<01:18, 243.12it/s] 79%|███████▉  | 70941/90000 [04:55<01:18, 242.71it/s] 79%|███████▉  | 70966/90000 [04:55<01:18, 241.79it/s] 79%|███████▉  | 70991/90000 [04:56<01:19, 238.73it/s] 79%|███████▉  | 71016/90000 [04:56<01:19, 240.04it/s] 79%|███████▉  | 71041/90000 [04:56<01:19, 238.05it/s] 79%|███████▉  | 71066/90000 [04:56<01:18, 241.27it/s] 79%|███████▉  | 71091/90000 [04:56<01:18, 240.40it/s] 79%|███████▉  | 71116/90000 [04:56<01:18, 241.20it/s] 79%|███████▉  | 71141/90000 [04:56<01:18, 239.82it/s] 79%|███████▉  | 71167/90000 [04:56<01:17, 243.50it/s] 79%|███████▉  | 71192/90000 [04:56<01:17, 243.98it/s] 79%|███████▉  | 71217/90000 [04:57<01:17, 242.01it/s] 79%|███████▉  | 71242/90000 [04:57<01:17, 240.63it/s] 79%|███████▉  | 71267/90000 [04:57<01:17, 242.61it/s] 79%|███████▉  | 71292/90000 [04:57<01:17, 240.00it/s] 79%|███████▉  | 71317/90000 [04:57<01:18, 239.27it/s] 79%|███████▉  | 71341/90000 [04:57<01:18, 238.81it/s] 79%|███████▉  | 71366/90000 [04:57<01:17, 240.87it/s] 79%|███████▉  | 71391/90000 [04:57<01:17, 240.99it/s] 79%|███████▉  | 71416/90000 [04:57<01:16, 241.87it/s] 79%|███████▉  | 71441/90000 [04:57<01:17, 239.90it/s] 79%|███████▉  | 71465/90000 [04:58<01:18, 237.63it/s] 79%|███████▉  | 71490/90000 [04:58<01:16, 240.75it/s] 79%|███████▉  | 71516/90000 [04:58<01:15, 245.12it/s] 79%|███████▉  | 71541/90000 [04:58<01:16, 240.97it/s] 80%|███████▉  | 71567/90000 [04:58<01:15, 243.79it/s] 80%|███████▉  | 71592/90000 [04:58<01:15, 243.70it/s] 80%|███████▉  | 71618/90000 [04:58<01:14, 247.09it/s] 80%|███████▉  | 71644/90000 [04:58<01:14, 247.73it/s] 80%|███████▉  | 71669/90000 [04:58<01:14, 246.81it/s] 80%|███████▉  | 71694/90000 [04:58<01:15, 243.95it/s] 80%|███████▉  | 71719/90000 [04:59<01:15, 241.84it/s] 80%|███████▉  | 71744/90000 [04:59<01:16, 239.55it/s] 80%|███████▉  | 71769/90000 [04:59<01:15, 242.10it/s] 80%|███████▉  | 71795/90000 [04:59<01:14, 245.11it/s] 80%|███████▉  | 71820/90000 [04:59<01:15, 241.30it/s] 80%|███████▉  | 71845/90000 [04:59<01:14, 242.76it/s] 80%|███████▉  | 71870/90000 [04:59<01:14, 241.89it/s] 80%|███████▉  | 71895/90000 [04:59<01:14, 241.67it/s] 80%|███████▉  | 71920/90000 [04:59<01:14, 243.00it/s] 80%|███████▉  | 71945/90000 [05:00<01:15, 238.13it/s] 80%|███████▉  | 71970/90000 [05:00<01:14, 240.46it/s] 80%|███████▉  | 71996/90000 [05:00<01:14, 243.28it/s] 80%|████████  | 72021/90000 [05:00<01:14, 241.32it/s] 80%|████████  | 72046/90000 [05:00<01:14, 242.40it/s] 80%|████████  | 72071/90000 [05:00<01:14, 241.86it/s] 80%|████████  | 72096/90000 [05:00<01:14, 241.58it/s] 80%|████████  | 72121/90000 [05:00<01:14, 239.15it/s] 80%|████████  | 72146/90000 [05:00<01:13, 241.41it/s] 80%|████████  | 72171/90000 [05:00<01:15, 237.06it/s] 80%|████████  | 72196/90000 [05:01<01:14, 239.85it/s] 80%|████████  | 72221/90000 [05:01<01:13, 240.30it/s] 80%|████████  | 72246/90000 [05:01<01:13, 242.35it/s] 80%|████████  | 72271/90000 [05:01<01:13, 240.51it/s] 80%|████████  | 72296/90000 [05:01<01:13, 239.74it/s] 80%|████████  | 72321/90000 [05:01<01:13, 240.84it/s] 80%|████████  | 72346/90000 [05:01<01:13, 241.60it/s] 80%|████████  | 72371/90000 [05:01<01:14, 238.11it/s] 80%|████████  | 72396/90000 [05:01<01:13, 240.90it/s] 80%|████████  | 72421/90000 [05:02<01:14, 235.34it/s] 80%|████████  | 72446/90000 [05:02<01:13, 238.91it/s] 81%|████████  | 72472/90000 [05:02<01:12, 242.15it/s] 81%|████████  | 72498/90000 [05:02<01:10, 246.90it/s] 81%|████████  | 72523/90000 [05:02<01:10, 246.17it/s] 81%|████████  | 72549/90000 [05:02<01:10, 248.06it/s] 81%|████████  | 72574/90000 [05:02<01:10, 247.50it/s] 81%|████████  | 72599/90000 [05:02<01:10, 246.57it/s] 81%|████████  | 72624/90000 [05:02<01:10, 246.45it/s] 81%|████████  | 72649/90000 [05:02<01:11, 242.01it/s] 81%|████████  | 72674/90000 [05:03<01:10, 244.16it/s] 81%|████████  | 72699/90000 [05:03<01:12, 239.77it/s] 81%|████████  | 72725/90000 [05:03<01:10, 244.71it/s] 81%|████████  | 72750/90000 [05:03<01:11, 240.86it/s] 81%|████████  | 72775/90000 [05:03<01:11, 239.70it/s] 81%|████████  | 72800/90000 [05:03<01:11, 241.40it/s] 81%|████████  | 72825/90000 [05:03<01:11, 239.27it/s] 81%|████████  | 72850/90000 [05:03<01:11, 241.41it/s] 81%|████████  | 72875/90000 [05:03<01:12, 236.83it/s] 81%|████████  | 72900/90000 [05:03<01:11, 238.91it/s] 81%|████████  | 72925/90000 [05:04<01:10, 241.60it/s] 81%|████████  | 72950/90000 [05:04<01:10, 242.85it/s] 81%|████████  | 72975/90000 [05:04<01:11, 239.63it/s] 81%|████████  | 72999/90000 [05:04<01:11, 238.83it/s] 81%|████████  | 73023/90000 [05:04<01:11, 239.01it/s] 81%|████████  | 73048/90000 [05:04<01:10, 239.00it/s] 81%|████████  | 73072/90000 [05:04<01:11, 237.01it/s] 81%|████████  | 73096/90000 [05:04<01:11, 236.50it/s] 81%|████████  | 73120/90000 [05:04<01:11, 234.45it/s] 81%|████████▏ | 73144/90000 [05:05<01:12, 231.48it/s] 81%|████████▏ | 73168/90000 [05:05<01:13, 230.23it/s] 81%|████████▏ | 73192/90000 [05:05<01:12, 231.21it/s] 81%|████████▏ | 73217/90000 [05:05<01:11, 234.48it/s] 81%|████████▏ | 73241/90000 [05:05<01:11, 234.41it/s] 81%|████████▏ | 73266/90000 [05:05<01:10, 237.04it/s] 81%|████████▏ | 73291/90000 [05:05<01:09, 240.52it/s] 81%|████████▏ | 73316/90000 [05:05<01:09, 240.82it/s] 81%|████████▏ | 73341/90000 [05:05<01:09, 239.88it/s] 82%|████████▏ | 73365/90000 [05:05<01:09, 239.32it/s] 82%|████████▏ | 73389/90000 [05:06<01:10, 237.21it/s] 82%|████████▏ | 73413/90000 [05:06<01:09, 237.73it/s] 82%|████████▏ | 73438/90000 [05:06<01:09, 239.06it/s] 82%|████████▏ | 73463/90000 [05:06<01:08, 239.89it/s] 82%|████████▏ | 73487/90000 [05:06<01:09, 239.21it/s] 82%|████████▏ | 73512/90000 [05:06<01:08, 240.03it/s] 82%|████████▏ | 73537/90000 [05:06<01:07, 242.14it/s] 82%|████████▏ | 73563/90000 [05:06<01:06, 245.92it/s] 82%|████████▏ | 73588/90000 [05:06<01:07, 244.10it/s] 82%|████████▏ | 73613/90000 [05:06<01:07, 241.98it/s] 82%|████████▏ | 73638/90000 [05:07<01:08, 238.31it/s] 82%|████████▏ | 73662/90000 [05:07<01:09, 235.37it/s] 82%|████████▏ | 73686/90000 [05:07<01:09, 234.75it/s] 82%|████████▏ | 73711/90000 [05:07<01:08, 238.21it/s] 82%|████████▏ | 73736/90000 [05:07<01:07, 240.73it/s] 82%|████████▏ | 73761/90000 [05:07<01:07, 240.03it/s] 82%|████████▏ | 73786/90000 [05:07<01:08, 237.88it/s] 82%|████████▏ | 73810/90000 [05:07<01:07, 238.09it/s] 82%|████████▏ | 73834/90000 [05:07<01:07, 238.40it/s] 82%|████████▏ | 73858/90000 [05:08<01:07, 237.70it/s] 82%|████████▏ | 73884/90000 [05:08<01:06, 240.92it/s] 82%|████████▏ | 73909/90000 [05:08<01:06, 240.60it/s] 82%|████████▏ | 73934/90000 [05:08<01:06, 242.24it/s] 82%|████████▏ | 73959/90000 [05:08<01:05, 244.01it/s] 82%|████████▏ | 73984/90000 [05:08<01:07, 238.81it/s] 82%|████████▏ | 74010/90000 [05:08<01:05, 242.39it/s] 82%|████████▏ | 74035/90000 [05:08<01:05, 242.16it/s] 82%|████████▏ | 74060/90000 [05:08<01:05, 242.38it/s] 82%|████████▏ | 74085/90000 [05:08<01:06, 240.59it/s] 82%|████████▏ | 74110/90000 [05:09<01:05, 241.48it/s] 82%|████████▏ | 74135/90000 [05:09<01:05, 241.02it/s] 82%|████████▏ | 74160/90000 [05:09<01:05, 242.00it/s] 82%|████████▏ | 74185/90000 [05:09<01:05, 240.08it/s] 82%|████████▏ | 74211/90000 [05:09<01:04, 243.89it/s] 82%|████████▏ | 74236/90000 [05:09<01:04, 243.18it/s] 83%|████████▎ | 74261/90000 [05:09<01:05, 240.03it/s] 83%|████████▎ | 74286/90000 [05:09<01:05, 239.76it/s] 83%|████████▎ | 74310/90000 [05:09<01:05, 239.64it/s] 83%|████████▎ | 74334/90000 [05:09<01:05, 238.46it/s] 83%|████████▎ | 74359/90000 [05:10<01:05, 239.39it/s] 83%|████████▎ | 74384/90000 [05:10<01:04, 241.04it/s] 83%|████████▎ | 74409/90000 [05:10<01:04, 240.16it/s] 83%|████████▎ | 74434/90000 [05:10<01:04, 240.08it/s] 83%|████████▎ | 74459/90000 [05:10<01:04, 240.28it/s] 83%|████████▎ | 74484/90000 [05:10<01:04, 238.80it/s] 83%|████████▎ | 74508/90000 [05:10<01:05, 238.19it/s] 83%|████████▎ | 74534/90000 [05:10<01:03, 242.74it/s] 83%|████████▎ | 74560/90000 [05:10<01:02, 245.39it/s] 83%|████████▎ | 74585/90000 [05:11<01:03, 243.36it/s] 83%|████████▎ | 74610/90000 [05:11<01:02, 244.29it/s] 83%|████████▎ | 74635/90000 [05:11<01:02, 245.24it/s] 83%|████████▎ | 74660/90000 [05:11<01:02, 245.15it/s] 83%|████████▎ | 74685/90000 [05:11<01:03, 241.70it/s] 83%|████████▎ | 74710/90000 [05:11<01:03, 242.52it/s] 83%|████████▎ | 74735/90000 [05:11<01:03, 241.10it/s] 83%|████████▎ | 74760/90000 [05:11<01:03, 240.11it/s] 83%|████████▎ | 74785/90000 [05:11<01:03, 240.87it/s] 83%|████████▎ | 74810/90000 [05:11<01:03, 237.54it/s] 83%|████████▎ | 74834/90000 [05:12<01:03, 237.44it/s] 83%|████████▎ | 74858/90000 [05:12<01:04, 236.26it/s] 83%|████████▎ | 74883/90000 [05:12<01:03, 237.69it/s] 83%|████████▎ | 74908/90000 [05:12<01:02, 241.23it/s] 83%|████████▎ | 74933/90000 [05:12<01:02, 239.54it/s] 83%|████████▎ | 74957/90000 [05:12<01:03, 235.15it/s] 83%|████████▎ | 74981/90000 [05:12<01:03, 234.89it/s] 83%|████████▎ | 75006/90000 [05:12<01:03, 238.00it/s] 83%|████████▎ | 75031/90000 [05:12<01:02, 239.96it/s] 83%|████████▎ | 75056/90000 [05:12<01:03, 235.01it/s] 83%|████████▎ | 75080/90000 [05:13<01:03, 235.42it/s] 83%|████████▎ | 75104/90000 [05:13<01:03, 235.35it/s] 83%|████████▎ | 75128/90000 [05:13<01:02, 236.61it/s] 84%|████████▎ | 75152/90000 [05:13<01:02, 236.49it/s] 84%|████████▎ | 75178/90000 [05:13<01:01, 241.14it/s] 84%|████████▎ | 75203/90000 [05:13<01:01, 239.47it/s] 84%|████████▎ | 75227/90000 [05:13<01:02, 236.36it/s] 84%|████████▎ | 75252/90000 [05:13<01:01, 238.07it/s] 84%|████████▎ | 75276/90000 [05:13<01:01, 237.83it/s] 84%|████████▎ | 75300/90000 [05:14<01:01, 237.80it/s] 84%|████████▎ | 75324/90000 [05:14<01:01, 237.39it/s] 84%|████████▎ | 75348/90000 [05:14<01:02, 234.33it/s] 84%|████████▎ | 75372/90000 [05:14<01:02, 234.67it/s] 84%|████████▍ | 75396/90000 [05:14<01:02, 234.43it/s] 84%|████████▍ | 75420/90000 [05:14<01:02, 234.06it/s] 84%|████████▍ | 75445/90000 [05:14<01:01, 238.35it/s] 84%|████████▍ | 75469/90000 [05:14<01:01, 236.69it/s] 84%|████████▍ | 75494/90000 [05:14<01:00, 238.68it/s] 84%|████████▍ | 75519/90000 [05:14<01:00, 240.22it/s] 84%|████████▍ | 75544/90000 [05:15<01:00, 239.51it/s] 84%|████████▍ | 75568/90000 [05:15<01:00, 237.12it/s] 84%|████████▍ | 75593/90000 [05:15<01:00, 238.25it/s] 84%|████████▍ | 75618/90000 [05:15<00:59, 239.73it/s] 84%|████████▍ | 75642/90000 [05:15<01:01, 233.42it/s] 84%|████████▍ | 75666/90000 [05:15<01:01, 231.61it/s] 84%|████████▍ | 75691/90000 [05:15<01:00, 235.49it/s] 84%|████████▍ | 75715/90000 [05:15<01:00, 236.39it/s] 84%|████████▍ | 75740/90000 [05:15<01:00, 237.52it/s] 84%|████████▍ | 75764/90000 [05:15<01:00, 237.13it/s] 84%|████████▍ | 75790/90000 [05:16<00:58, 242.16it/s] 84%|████████▍ | 75815/90000 [05:16<00:58, 240.54it/s] 84%|████████▍ | 75840/90000 [05:16<00:58, 242.16it/s] 84%|████████▍ | 75865/90000 [05:16<00:58, 241.67it/s] 84%|████████▍ | 75890/90000 [05:16<00:58, 242.93it/s] 84%|████████▍ | 75915/90000 [05:16<00:58, 241.16it/s] 84%|████████▍ | 75940/90000 [05:16<00:58, 241.64it/s] 84%|████████▍ | 75965/90000 [05:16<00:57, 242.36it/s] 84%|████████▍ | 75990/90000 [05:16<00:58, 241.02it/s] 84%|████████▍ | 76015/90000 [05:17<00:57, 243.18it/s] 84%|████████▍ | 76040/90000 [05:17<00:57, 243.94it/s] 85%|████████▍ | 76065/90000 [05:17<00:57, 243.04it/s] 85%|████████▍ | 76090/90000 [05:17<00:57, 242.12it/s] 85%|████████▍ | 76116/90000 [05:17<00:56, 246.09it/s] 85%|████████▍ | 76141/90000 [05:17<00:57, 241.43it/s] 85%|████████▍ | 76166/90000 [05:17<00:57, 238.57it/s] 85%|████████▍ | 76190/90000 [05:17<00:58, 236.91it/s] 85%|████████▍ | 76216/90000 [05:17<00:56, 242.33it/s] 85%|████████▍ | 76241/90000 [05:17<00:56, 242.72it/s] 85%|████████▍ | 76266/90000 [05:18<00:56, 241.07it/s] 85%|████████▍ | 76292/90000 [05:18<00:56, 244.55it/s] 85%|████████▍ | 76317/90000 [05:18<00:57, 239.91it/s] 85%|████████▍ | 76342/90000 [05:18<00:57, 239.40it/s] 85%|████████▍ | 76368/90000 [05:18<00:56, 243.17it/s] 85%|████████▍ | 76393/90000 [05:18<00:56, 241.83it/s] 85%|████████▍ | 76418/90000 [05:18<00:56, 242.12it/s] 85%|████████▍ | 76443/90000 [05:18<00:56, 238.54it/s] 85%|████████▍ | 76468/90000 [05:18<00:56, 241.26it/s] 85%|████████▍ | 76493/90000 [05:18<00:55, 242.99it/s] 85%|████████▌ | 76518/90000 [05:19<00:55, 242.03it/s] 85%|████████▌ | 76543/90000 [05:19<00:55, 242.01it/s] 85%|████████▌ | 76568/90000 [05:19<00:55, 243.26it/s] 85%|████████▌ | 76593/90000 [05:19<00:55, 241.83it/s] 85%|████████▌ | 76618/90000 [05:19<00:55, 241.26it/s] 85%|████████▌ | 76643/90000 [05:19<00:54, 243.69it/s] 85%|████████▌ | 76668/90000 [05:19<00:54, 244.77it/s] 85%|████████▌ | 76693/90000 [05:19<00:54, 244.40it/s] 85%|████████▌ | 76719/90000 [05:19<00:53, 246.59it/s] 85%|████████▌ | 76744/90000 [05:20<00:53, 246.43it/s] 85%|████████▌ | 76769/90000 [05:20<00:54, 244.28it/s] 85%|████████▌ | 76794/90000 [05:20<00:54, 242.45it/s] 85%|████████▌ | 76819/90000 [05:20<00:54, 241.64it/s] 85%|████████▌ | 76845/90000 [05:20<00:53, 244.76it/s] 85%|████████▌ | 76870/90000 [05:20<00:54, 240.04it/s] 85%|████████▌ | 76895/90000 [05:20<00:54, 239.25it/s] 85%|████████▌ | 76920/90000 [05:20<00:54, 238.80it/s] 85%|████████▌ | 76945/90000 [05:20<00:54, 239.31it/s] 86%|████████▌ | 76969/90000 [05:20<00:54, 238.76it/s] 86%|████████▌ | 76993/90000 [05:21<00:54, 237.36it/s] 86%|████████▌ | 77018/90000 [05:21<00:54, 239.76it/s] 86%|████████▌ | 77042/90000 [05:21<00:54, 239.70it/s] 86%|████████▌ | 77066/90000 [05:21<00:54, 239.50it/s] 86%|████████▌ | 77090/90000 [05:21<00:53, 239.35it/s] 86%|████████▌ | 77116/90000 [05:21<00:52, 243.54it/s] 86%|████████▌ | 77141/90000 [05:21<00:52, 243.71it/s] 86%|████████▌ | 77166/90000 [05:21<00:52, 243.09it/s] 86%|████████▌ | 77191/90000 [05:21<00:52, 242.19it/s] 86%|████████▌ | 77216/90000 [05:21<00:53, 240.13it/s] 86%|████████▌ | 77241/90000 [05:22<00:52, 241.10it/s] 86%|████████▌ | 77267/90000 [05:22<00:52, 244.75it/s] 86%|████████▌ | 77292/90000 [05:22<00:52, 240.01it/s] 86%|████████▌ | 77317/90000 [05:22<00:53, 237.10it/s] 86%|████████▌ | 77341/90000 [05:22<00:54, 233.52it/s] 86%|████████▌ | 77367/90000 [05:22<00:52, 239.54it/s] 86%|████████▌ | 77392/90000 [05:22<00:52, 241.46it/s] 86%|████████▌ | 77417/90000 [05:22<00:51, 243.74it/s] 86%|████████▌ | 77442/90000 [05:22<00:51, 245.19it/s] 86%|████████▌ | 77467/90000 [05:23<00:51, 244.40it/s] 86%|████████▌ | 77492/90000 [05:23<00:50, 245.43it/s] 86%|████████▌ | 77517/90000 [05:23<00:51, 242.80it/s] 86%|████████▌ | 77542/90000 [05:23<00:51, 241.08it/s] 86%|████████▌ | 77567/90000 [05:23<00:51, 239.21it/s] 86%|████████▌ | 77591/90000 [05:23<00:52, 238.49it/s] 86%|████████▌ | 77615/90000 [05:23<00:52, 236.92it/s] 86%|████████▋ | 77639/90000 [05:23<00:52, 234.73it/s] 86%|████████▋ | 77663/90000 [05:23<00:52, 234.50it/s] 86%|████████▋ | 77687/90000 [05:23<00:52, 235.64it/s] 86%|████████▋ | 77712/90000 [05:24<00:51, 239.71it/s] 86%|████████▋ | 77736/90000 [05:24<00:51, 236.42it/s] 86%|████████▋ | 77760/90000 [05:24<00:51, 236.95it/s] 86%|████████▋ | 77784/90000 [05:24<00:51, 237.54it/s] 86%|████████▋ | 77809/90000 [05:24<00:50, 239.65it/s] 86%|████████▋ | 77835/90000 [05:24<00:50, 243.02it/s] 87%|████████▋ | 77860/90000 [05:24<00:50, 241.58it/s] 87%|████████▋ | 77885/90000 [05:24<00:51, 235.91it/s] 87%|████████▋ | 77910/90000 [05:24<00:50, 237.25it/s] 87%|████████▋ | 77935/90000 [05:24<00:50, 239.27it/s] 87%|████████▋ | 77959/90000 [05:25<00:51, 235.14it/s] 87%|████████▋ | 77983/90000 [05:25<00:51, 234.66it/s] 87%|████████▋ | 78008/90000 [05:25<00:50, 237.02it/s] 87%|████████▋ | 78032/90000 [05:25<00:50, 236.42it/s] 87%|████████▋ | 78056/90000 [05:25<00:50, 236.75it/s] 87%|████████▋ | 78081/90000 [05:25<00:49, 239.71it/s] 87%|████████▋ | 78106/90000 [05:25<00:49, 242.23it/s] 87%|████████▋ | 78131/90000 [05:25<00:49, 238.59it/s] 87%|████████▋ | 78156/90000 [05:25<00:49, 240.58it/s] 87%|████████▋ | 78182/90000 [05:26<00:48, 244.25it/s] 87%|████████▋ | 78208/90000 [05:26<00:47, 246.91it/s] 87%|████████▋ | 78233/90000 [05:26<00:47, 245.44it/s] 87%|████████▋ | 78258/90000 [05:26<00:48, 240.12it/s] 87%|████████▋ | 78283/90000 [05:26<00:49, 238.40it/s] 87%|████████▋ | 78309/90000 [05:26<00:48, 242.42it/s] 87%|████████▋ | 78334/90000 [05:26<00:48, 239.54it/s] 87%|████████▋ | 78360/90000 [05:26<00:48, 241.55it/s] 87%|████████▋ | 78386/90000 [05:26<00:47, 244.82it/s] 87%|████████▋ | 78411/90000 [05:26<00:47, 246.12it/s] 87%|████████▋ | 78436/90000 [05:27<00:47, 243.51it/s] 87%|████████▋ | 78461/90000 [05:27<00:47, 243.91it/s] 87%|████████▋ | 78486/90000 [05:27<00:47, 240.45it/s] 87%|████████▋ | 78511/90000 [05:27<00:48, 237.92it/s] 87%|████████▋ | 78535/90000 [05:27<00:48, 237.40it/s] 87%|████████▋ | 78560/90000 [05:27<00:47, 239.45it/s] 87%|████████▋ | 78585/90000 [05:27<00:47, 241.72it/s] 87%|████████▋ | 78610/90000 [05:27<00:46, 242.43it/s] 87%|████████▋ | 78635/90000 [05:27<00:46, 242.56it/s] 87%|████████▋ | 78661/90000 [05:27<00:46, 245.09it/s] 87%|████████▋ | 78687/90000 [05:28<00:45, 247.21it/s] 87%|████████▋ | 78712/90000 [05:28<00:46, 243.44it/s] 87%|████████▋ | 78737/90000 [05:28<00:46, 241.44it/s] 88%|████████▊ | 78762/90000 [05:28<00:46, 243.63it/s] 88%|████████▊ | 78789/90000 [05:28<00:45, 248.97it/s] 88%|████████▊ | 78814/90000 [05:28<00:44, 249.19it/s] 88%|████████▊ | 78839/90000 [05:28<00:44, 248.81it/s] 88%|████████▊ | 78864/90000 [05:28<00:45, 244.65it/s] 88%|████████▊ | 78889/90000 [05:28<00:45, 244.92it/s] 88%|████████▊ | 78914/90000 [05:29<00:45, 241.80it/s] 88%|████████▊ | 78939/90000 [05:29<00:45, 243.14it/s] 88%|████████▊ | 78964/90000 [05:29<00:46, 238.98it/s] 88%|████████▊ | 78989/90000 [05:29<00:45, 240.92it/s] 88%|████████▊ | 79014/90000 [05:29<00:46, 237.95it/s] 88%|████████▊ | 79038/90000 [05:29<00:45, 238.50it/s] 88%|████████▊ | 79063/90000 [05:29<00:45, 240.13it/s] 88%|████████▊ | 79088/90000 [05:29<00:45, 239.61it/s] 88%|████████▊ | 79113/90000 [05:29<00:45, 240.24it/s] 88%|████████▊ | 79138/90000 [05:29<00:45, 240.76it/s] 88%|████████▊ | 79163/90000 [05:30<00:45, 240.47it/s] 88%|████████▊ | 79188/90000 [05:30<00:44, 240.32it/s] 88%|████████▊ | 79214/90000 [05:30<00:44, 244.54it/s] 88%|████████▊ | 79239/90000 [05:30<00:43, 244.71it/s] 88%|████████▊ | 79264/90000 [05:30<00:44, 243.00it/s] 88%|████████▊ | 79289/90000 [05:30<00:44, 243.20it/s] 88%|████████▊ | 79314/90000 [05:30<00:44, 238.75it/s] 88%|████████▊ | 79339/90000 [05:30<00:44, 239.81it/s] 88%|████████▊ | 79363/90000 [05:30<00:44, 238.73it/s] 88%|████████▊ | 79388/90000 [05:30<00:43, 241.50it/s] 88%|████████▊ | 79413/90000 [05:31<00:44, 240.59it/s] 88%|████████▊ | 79438/90000 [05:31<00:43, 240.28it/s] 88%|████████▊ | 79463/90000 [05:31<00:44, 238.70it/s] 88%|████████▊ | 79488/90000 [05:31<00:43, 241.06it/s] 88%|████████▊ | 79513/90000 [05:31<00:44, 238.16it/s] 88%|████████▊ | 79538/90000 [05:31<00:43, 239.54it/s] 88%|████████▊ | 79564/90000 [05:31<00:42, 244.74it/s] 88%|████████▊ | 79589/90000 [05:31<00:43, 237.44it/s] 88%|████████▊ | 79613/90000 [05:31<00:43, 237.42it/s] 88%|████████▊ | 79637/90000 [05:32<00:43, 235.97it/s] 89%|████████▊ | 79661/90000 [05:32<00:43, 236.63it/s] 89%|████████▊ | 79685/90000 [05:32<00:43, 234.78it/s] 89%|████████▊ | 79709/90000 [05:32<00:43, 235.34it/s] 89%|████████▊ | 79734/90000 [05:32<00:43, 237.37it/s] 89%|████████▊ | 79758/90000 [05:32<00:43, 237.47it/s] 89%|████████▊ | 79782/90000 [05:32<00:42, 237.93it/s] 89%|████████▊ | 79807/90000 [05:32<00:42, 238.95it/s] 89%|████████▊ | 79831/90000 [05:32<00:42, 237.37it/s] 89%|████████▊ | 79855/90000 [05:32<00:43, 235.00it/s] 89%|████████▉ | 79879/90000 [05:33<00:43, 234.55it/s] 89%|████████▉ | 79903/90000 [05:33<00:43, 233.08it/s] 89%|████████▉ | 79927/90000 [05:33<00:42, 234.71it/s] 89%|████████▉ | 79952/90000 [05:33<00:42, 239.13it/s] 89%|████████▉ | 79977/90000 [05:33<00:41, 241.94it/s] 89%|████████▉ | 80002/90000 [05:33<00:41, 240.39it/s] 89%|████████▉ | 80027/90000 [05:33<00:41, 238.21it/s] 89%|████████▉ | 80053/90000 [05:33<00:41, 242.02it/s] 89%|████████▉ | 80078/90000 [05:33<00:40, 242.80it/s] 89%|████████▉ | 80103/90000 [05:33<00:41, 240.84it/s] 89%|████████▉ | 80129/90000 [05:34<00:40, 243.60it/s] 89%|████████▉ | 80154/90000 [05:34<00:41, 239.93it/s] 89%|████████▉ | 80180/90000 [05:34<00:40, 243.66it/s] 89%|████████▉ | 80205/90000 [05:34<00:39, 245.35it/s] 89%|████████▉ | 80230/90000 [05:34<00:40, 241.90it/s] 89%|████████▉ | 80255/90000 [05:34<00:40, 242.50it/s] 89%|████████▉ | 80280/90000 [05:34<00:40, 241.35it/s] 89%|████████▉ | 80305/90000 [05:34<00:40, 241.23it/s] 89%|████████▉ | 80330/90000 [05:34<00:39, 241.79it/s] 89%|████████▉ | 80355/90000 [05:35<00:40, 238.89it/s] 89%|████████▉ | 80380/90000 [05:35<00:40, 240.40it/s] 89%|████████▉ | 80405/90000 [05:35<00:39, 240.92it/s] 89%|████████▉ | 80431/90000 [05:35<00:39, 243.30it/s] 89%|████████▉ | 80457/90000 [05:35<00:38, 245.60it/s] 89%|████████▉ | 80482/90000 [05:35<00:39, 238.92it/s] 89%|████████▉ | 80506/90000 [05:35<00:40, 233.47it/s] 89%|████████▉ | 80530/90000 [05:35<00:41, 230.54it/s] 90%|████████▉ | 80554/90000 [05:35<00:40, 231.37it/s] 90%|████████▉ | 80578/90000 [05:35<00:40, 231.38it/s] 90%|████████▉ | 80603/90000 [05:36<00:39, 235.33it/s] 90%|████████▉ | 80627/90000 [05:36<00:40, 232.27it/s] 90%|████████▉ | 80651/90000 [05:36<00:40, 232.45it/s] 90%|████████▉ | 80675/90000 [05:36<00:39, 234.04it/s] 90%|████████▉ | 80701/90000 [05:36<00:38, 239.69it/s] 90%|████████▉ | 80725/90000 [05:36<00:38, 238.58it/s] 90%|████████▉ | 80750/90000 [05:36<00:38, 240.26it/s] 90%|████████▉ | 80775/90000 [05:36<00:39, 232.82it/s] 90%|████████▉ | 80799/90000 [05:36<00:40, 228.95it/s] 90%|████████▉ | 80823/90000 [05:37<00:40, 229.32it/s] 90%|████████▉ | 80847/90000 [05:37<00:39, 232.23it/s] 90%|████████▉ | 80871/90000 [05:37<00:38, 234.09it/s] 90%|████████▉ | 80895/90000 [05:37<00:38, 234.72it/s] 90%|████████▉ | 80919/90000 [05:37<00:38, 234.10it/s] 90%|████████▉ | 80945/90000 [05:37<00:37, 240.65it/s] 90%|████████▉ | 80970/90000 [05:37<00:37, 242.23it/s] 90%|████████▉ | 80995/90000 [05:37<00:37, 242.48it/s] 90%|█████████ | 81020/90000 [05:37<00:36, 243.11it/s] 90%|█████████ | 81046/90000 [05:37<00:36, 245.60it/s] 90%|█████████ | 81072/90000 [05:38<00:35, 249.63it/s] 90%|█████████ | 81097/90000 [05:38<00:36, 246.67it/s] 90%|█████████ | 81122/90000 [05:38<00:35, 247.16it/s] 90%|█████████ | 81147/90000 [05:38<00:35, 246.21it/s] 90%|█████████ | 81172/90000 [05:38<00:36, 242.13it/s] 90%|█████████ | 81197/90000 [05:38<00:36, 240.08it/s] 90%|█████████ | 81222/90000 [05:38<00:36, 240.55it/s] 90%|█████████ | 81247/90000 [05:38<00:36, 240.14it/s] 90%|█████████ | 81272/90000 [05:38<00:35, 242.64it/s] 90%|█████████ | 81298/90000 [05:38<00:35, 245.65it/s] 90%|█████████ | 81324/90000 [05:39<00:35, 246.08it/s] 90%|█████████ | 81349/90000 [05:39<00:35, 243.88it/s] 90%|█████████ | 81374/90000 [05:39<00:35, 242.08it/s] 90%|█████████ | 81399/90000 [05:39<00:35, 239.71it/s] 90%|█████████ | 81423/90000 [05:39<00:36, 236.94it/s] 90%|█████████ | 81448/90000 [05:39<00:35, 239.72it/s] 91%|█████████ | 81472/90000 [05:39<00:35, 239.61it/s] 91%|█████████ | 81498/90000 [05:39<00:34, 243.22it/s] 91%|█████████ | 81523/90000 [05:39<00:35, 241.16it/s] 91%|█████████ | 81548/90000 [05:40<00:34, 242.68it/s] 91%|█████████ | 81573/90000 [05:40<00:35, 240.14it/s] 91%|█████████ | 81598/90000 [05:40<00:34, 240.44it/s] 91%|█████████ | 81623/90000 [05:40<00:34, 242.43it/s] 91%|█████████ | 81648/90000 [05:40<00:34, 240.46it/s] 91%|█████████ | 81673/90000 [05:40<00:34, 241.36it/s] 91%|█████████ | 81698/90000 [05:40<00:34, 240.07it/s] 91%|█████████ | 81723/90000 [05:40<00:34, 237.67it/s] 91%|█████████ | 81747/90000 [05:40<00:34, 237.99it/s] 91%|█████████ | 81771/90000 [05:40<00:34, 235.71it/s] 91%|█████████ | 81795/90000 [05:41<00:34, 235.75it/s] 91%|█████████ | 81820/90000 [05:41<00:34, 237.50it/s] 91%|█████████ | 81844/90000 [05:41<00:34, 237.88it/s] 91%|█████████ | 81869/90000 [05:41<00:33, 239.45it/s] 91%|█████████ | 81894/90000 [05:41<00:33, 242.44it/s] 91%|█████████ | 81919/90000 [05:41<00:33, 244.00it/s] 91%|█████████ | 81944/90000 [05:41<00:32, 245.11it/s] 91%|█████████ | 81969/90000 [05:41<00:33, 241.77it/s] 91%|█████████ | 81994/90000 [05:41<00:33, 240.41it/s] 91%|█████████ | 82019/90000 [05:41<00:33, 239.33it/s] 91%|█████████ | 82045/90000 [05:42<00:32, 243.46it/s] 91%|█████████ | 82070/90000 [05:42<00:32, 244.53it/s] 91%|█████████ | 82095/90000 [05:42<00:32, 241.52it/s] 91%|█████████ | 82120/90000 [05:42<00:32, 238.87it/s] 91%|█████████▏| 82145/90000 [05:42<00:32, 238.68it/s] 91%|█████████▏| 82169/90000 [05:42<00:33, 235.33it/s] 91%|█████████▏| 82193/90000 [05:42<00:33, 234.92it/s] 91%|█████████▏| 82218/90000 [05:42<00:32, 237.74it/s] 91%|█████████▏| 82242/90000 [05:42<00:32, 237.09it/s] 91%|█████████▏| 82266/90000 [05:43<00:33, 232.97it/s] 91%|█████████▏| 82292/90000 [05:43<00:32, 238.62it/s] 91%|█████████▏| 82316/90000 [05:43<00:32, 238.27it/s] 91%|█████████▏| 82340/90000 [05:43<00:32, 234.37it/s] 92%|█████████▏| 82364/90000 [05:43<00:32, 234.38it/s] 92%|█████████▏| 82388/90000 [05:43<00:32, 235.66it/s] 92%|█████████▏| 82412/90000 [05:43<00:32, 235.30it/s] 92%|█████████▏| 82436/90000 [05:43<00:32, 231.80it/s] 92%|█████████▏| 82460/90000 [05:43<00:32, 232.12it/s] 92%|█████████▏| 82485/90000 [05:43<00:31, 236.50it/s] 92%|█████████▏| 82510/90000 [05:44<00:31, 238.38it/s] 92%|█████████▏| 82535/90000 [05:44<00:30, 241.29it/s] 92%|█████████▏| 82560/90000 [05:44<00:31, 237.63it/s] 92%|█████████▏| 82584/90000 [05:44<00:31, 235.72it/s] 92%|█████████▏| 82610/90000 [05:44<00:30, 242.10it/s] 92%|█████████▏| 82635/90000 [05:44<00:30, 242.55it/s] 92%|█████████▏| 82661/90000 [05:44<00:29, 245.17it/s] 92%|█████████▏| 82687/90000 [05:44<00:29, 248.57it/s] 92%|█████████▏| 82712/90000 [05:44<00:29, 245.77it/s] 92%|█████████▏| 82737/90000 [05:44<00:30, 241.85it/s] 92%|█████████▏| 82762/90000 [05:45<00:30, 236.06it/s] 92%|█████████▏| 82787/90000 [05:45<00:30, 238.77it/s] 92%|█████████▏| 82811/90000 [05:45<00:30, 235.50it/s] 92%|█████████▏| 82836/90000 [05:45<00:30, 237.19it/s] 92%|█████████▏| 82860/90000 [05:45<00:30, 237.37it/s] 92%|█████████▏| 82884/90000 [05:45<00:29, 237.75it/s] 92%|█████████▏| 82909/90000 [05:45<00:29, 240.24it/s] 92%|█████████▏| 82934/90000 [05:45<00:29, 239.58it/s] 92%|█████████▏| 82959/90000 [05:45<00:29, 240.24it/s] 92%|█████████▏| 82984/90000 [05:46<00:29, 240.39it/s] 92%|█████████▏| 83009/90000 [05:46<00:29, 239.48it/s] 92%|█████████▏| 83033/90000 [05:46<00:29, 239.23it/s] 92%|█████████▏| 83057/90000 [05:46<00:29, 238.64it/s] 92%|█████████▏| 83083/90000 [05:46<00:28, 243.03it/s] 92%|█████████▏| 83108/90000 [05:46<00:28, 244.39it/s] 92%|█████████▏| 83133/90000 [05:46<00:28, 242.27it/s] 92%|█████████▏| 83158/90000 [05:46<00:28, 239.30it/s] 92%|█████████▏| 83183/90000 [05:46<00:28, 239.75it/s] 92%|█████████▏| 83209/90000 [05:46<00:27, 243.15it/s] 92%|█████████▏| 83234/90000 [05:47<00:27, 245.07it/s] 93%|█████████▎| 83259/90000 [05:47<00:27, 244.65it/s] 93%|█████████▎| 83284/90000 [05:47<00:27, 240.51it/s] 93%|█████████▎| 83309/90000 [05:47<00:28, 238.70it/s] 93%|█████████▎| 83334/90000 [05:47<00:27, 240.09it/s] 93%|█████████▎| 83359/90000 [05:47<00:27, 241.03it/s] 93%|█████████▎| 83384/90000 [05:47<00:27, 242.67it/s] 93%|█████████▎| 83409/90000 [05:47<00:27, 241.59it/s] 93%|█████████▎| 83434/90000 [05:47<00:27, 240.37it/s] 93%|█████████▎| 83459/90000 [05:48<00:27, 239.64it/s] 93%|█████████▎| 83483/90000 [05:48<00:27, 238.96it/s] 93%|█████████▎| 83508/90000 [05:48<00:26, 241.45it/s] 93%|█████████▎| 83533/90000 [05:48<00:26, 239.81it/s] 93%|█████████▎| 83557/90000 [05:48<00:27, 236.80it/s] 93%|█████████▎| 83582/90000 [05:48<00:26, 238.24it/s] 93%|█████████▎| 83607/90000 [05:48<00:26, 238.62it/s] 93%|█████████▎| 83632/90000 [05:48<00:26, 241.67it/s] 93%|█████████▎| 83657/90000 [05:48<00:26, 242.19it/s] 93%|█████████▎| 83682/90000 [05:48<00:26, 240.79it/s] 93%|█████████▎| 83707/90000 [05:49<00:26, 240.25it/s] 93%|█████████▎| 83732/90000 [05:49<00:26, 240.48it/s] 93%|█████████▎| 83757/90000 [05:49<00:26, 238.11it/s] 93%|█████████▎| 83781/90000 [05:49<00:26, 237.85it/s] 93%|█████████▎| 83806/90000 [05:49<00:25, 239.17it/s] 93%|█████████▎| 83830/90000 [05:49<00:25, 238.22it/s] 93%|█████████▎| 83855/90000 [05:49<00:25, 240.02it/s] 93%|█████████▎| 83880/90000 [05:49<00:25, 242.73it/s] 93%|█████████▎| 83905/90000 [05:49<00:24, 244.37it/s] 93%|█████████▎| 83931/90000 [05:49<00:24, 246.49it/s] 93%|█████████▎| 83957/90000 [05:50<00:24, 249.14it/s] 93%|█████████▎| 83982/90000 [05:50<00:24, 248.56it/s] 93%|█████████▎| 84007/90000 [05:50<00:24, 246.90it/s] 93%|█████████▎| 84032/90000 [05:50<00:24, 247.54it/s] 93%|█████████▎| 84057/90000 [05:50<00:24, 243.84it/s] 93%|█████████▎| 84082/90000 [05:50<00:24, 243.14it/s] 93%|█████████▎| 84107/90000 [05:50<00:24, 239.03it/s] 93%|█████████▎| 84132/90000 [05:50<00:24, 238.30it/s] 94%|█████████▎| 84157/90000 [05:50<00:24, 238.31it/s] 94%|█████████▎| 84181/90000 [05:50<00:24, 235.50it/s] 94%|█████████▎| 84206/90000 [05:51<00:24, 238.60it/s] 94%|█████████▎| 84230/90000 [05:51<00:24, 238.19it/s] 94%|█████████▎| 84256/90000 [05:51<00:23, 242.46it/s] 94%|█████████▎| 84281/90000 [05:51<00:23, 241.59it/s] 94%|█████████▎| 84306/90000 [05:51<00:23, 238.86it/s] 94%|█████████▎| 84330/90000 [05:51<00:24, 233.35it/s] 94%|█████████▎| 84354/90000 [05:51<00:24, 233.70it/s] 94%|█████████▍| 84379/90000 [05:51<00:23, 235.96it/s] 94%|█████████▍| 84403/90000 [05:51<00:23, 236.54it/s] 94%|█████████▍| 84427/90000 [05:52<00:23, 234.17it/s] 94%|█████████▍| 84451/90000 [05:52<00:23, 235.14it/s] 94%|█████████▍| 84476/90000 [05:52<00:23, 239.07it/s] 94%|█████████▍| 84500/90000 [05:52<00:23, 237.23it/s] 94%|█████████▍| 84524/90000 [05:52<00:23, 236.71it/s] 94%|█████████▍| 84549/90000 [05:52<00:23, 236.37it/s] 94%|█████████▍| 84573/90000 [05:52<00:22, 235.96it/s] 94%|█████████▍| 84597/90000 [05:52<00:22, 236.19it/s] 94%|█████████▍| 84621/90000 [05:52<00:22, 236.50it/s] 94%|█████████▍| 84645/90000 [05:52<00:22, 236.92it/s] 94%|█████████▍| 84669/90000 [05:53<00:22, 235.80it/s] 94%|█████████▍| 84693/90000 [05:53<00:22, 235.02it/s] 94%|█████████▍| 84717/90000 [05:53<00:22, 232.75it/s] 94%|█████████▍| 84742/90000 [05:53<00:22, 235.92it/s] 94%|█████████▍| 84767/90000 [05:53<00:21, 239.90it/s] 94%|█████████▍| 84792/90000 [05:53<00:21, 241.74it/s] 94%|█████████▍| 84817/90000 [05:53<00:21, 240.88it/s] 94%|█████████▍| 84842/90000 [05:53<00:21, 238.53it/s] 94%|█████████▍| 84866/90000 [05:53<00:21, 236.46it/s] 94%|█████████▍| 84890/90000 [05:53<00:21, 233.80it/s] 94%|█████████▍| 84914/90000 [05:54<00:21, 233.84it/s] 94%|█████████▍| 84938/90000 [05:54<00:21, 234.91it/s] 94%|█████████▍| 84962/90000 [05:54<00:21, 234.46it/s] 94%|█████████▍| 84986/90000 [05:54<00:21, 233.76it/s] 94%|█████████▍| 85010/90000 [05:54<00:21, 235.58it/s] 94%|█████████▍| 85034/90000 [05:54<00:21, 234.06it/s] 95%|█████████▍| 85058/90000 [05:54<00:21, 234.43it/s] 95%|█████████▍| 85082/90000 [05:54<00:21, 233.49it/s] 95%|█████████▍| 85106/90000 [05:54<00:21, 232.56it/s] 95%|█████████▍| 85130/90000 [05:55<00:20, 232.90it/s] 95%|█████████▍| 85154/90000 [05:55<00:20, 234.66it/s] 95%|█████████▍| 85178/90000 [05:55<00:20, 235.57it/s] 95%|█████████▍| 85202/90000 [05:55<00:20, 235.07it/s] 95%|█████████▍| 85227/90000 [05:55<00:20, 236.25it/s] 95%|█████████▍| 85251/90000 [05:55<00:20, 234.92it/s] 95%|█████████▍| 85275/90000 [05:55<00:20, 232.09it/s] 95%|█████████▍| 85300/90000 [05:55<00:20, 234.50it/s] 95%|█████████▍| 85324/90000 [05:55<00:19, 235.15it/s] 95%|█████████▍| 85350/90000 [05:55<00:19, 239.63it/s] 95%|█████████▍| 85374/90000 [05:56<00:19, 235.24it/s] 95%|█████████▍| 85399/90000 [05:56<00:19, 238.54it/s] 95%|█████████▍| 85423/90000 [05:56<00:19, 234.10it/s] 95%|█████████▍| 85447/90000 [05:56<00:19, 232.87it/s] 95%|█████████▍| 85473/90000 [05:56<00:18, 238.40it/s] 95%|█████████▍| 85497/90000 [05:56<00:18, 238.14it/s] 95%|█████████▌| 85522/90000 [05:56<00:18, 239.54it/s] 95%|█████████▌| 85547/90000 [05:56<00:18, 242.10it/s] 95%|█████████▌| 85572/90000 [05:56<00:18, 238.92it/s] 95%|█████████▌| 85596/90000 [05:56<00:18, 238.59it/s] 95%|█████████▌| 85620/90000 [05:57<00:18, 236.04it/s] 95%|█████████▌| 85646/90000 [05:57<00:18, 239.94it/s] 95%|█████████▌| 85671/90000 [05:57<00:17, 240.58it/s] 95%|█████████▌| 85697/90000 [05:57<00:17, 243.07it/s] 95%|█████████▌| 85722/90000 [05:57<00:17, 242.36it/s] 95%|█████████▌| 85747/90000 [05:57<00:17, 242.95it/s] 95%|█████████▌| 85772/90000 [05:57<00:17, 243.43it/s] 95%|█████████▌| 85797/90000 [05:57<00:17, 243.72it/s] 95%|█████████▌| 85822/90000 [05:57<00:17, 243.57it/s] 95%|█████████▌| 85847/90000 [05:58<00:17, 240.90it/s] 95%|█████████▌| 85872/90000 [05:58<00:17, 240.76it/s] 95%|█████████▌| 85897/90000 [05:58<00:17, 239.90it/s] 95%|█████████▌| 85921/90000 [05:58<00:17, 239.72it/s] 95%|█████████▌| 85946/90000 [05:58<00:16, 240.76it/s] 96%|█████████▌| 85971/90000 [05:58<00:16, 237.75it/s] 96%|█████████▌| 85996/90000 [05:58<00:16, 238.54it/s] 96%|█████████▌| 86021/90000 [05:58<00:16, 239.59it/s] 96%|█████████▌| 86046/90000 [05:58<00:16, 239.67it/s] 96%|█████████▌| 86070/90000 [05:58<00:16, 237.67it/s] 96%|█████████▌| 86095/90000 [05:59<00:16, 240.64it/s] 96%|█████████▌| 86120/90000 [05:59<00:16, 239.85it/s] 96%|█████████▌| 86144/90000 [05:59<00:16, 237.69it/s] 96%|█████████▌| 86171/90000 [05:59<00:15, 244.75it/s] 96%|█████████▌| 86196/90000 [05:59<00:15, 238.38it/s] 96%|█████████▌| 86221/90000 [05:59<00:15, 239.00it/s] 96%|█████████▌| 86246/90000 [05:59<00:15, 241.41it/s] 96%|█████████▌| 86272/90000 [05:59<00:15, 243.82it/s] 96%|█████████▌| 86297/90000 [05:59<00:15, 240.09it/s] 96%|█████████▌| 86323/90000 [05:59<00:14, 245.23it/s] 96%|█████████▌| 86348/90000 [06:00<00:14, 245.10it/s] 96%|█████████▌| 86373/90000 [06:00<00:14, 245.34it/s] 96%|█████████▌| 86398/90000 [06:00<00:14, 243.53it/s] 96%|█████████▌| 86423/90000 [06:00<00:14, 242.29it/s] 96%|█████████▌| 86449/90000 [06:00<00:14, 244.60it/s] 96%|█████████▌| 86474/90000 [06:00<00:14, 239.95it/s] 96%|█████████▌| 86499/90000 [06:00<00:14, 242.73it/s] 96%|█████████▌| 86525/90000 [06:00<00:14, 246.39it/s] 96%|█████████▌| 86550/90000 [06:00<00:14, 241.62it/s] 96%|█████████▌| 86575/90000 [06:01<00:14, 240.24it/s] 96%|█████████▌| 86600/90000 [06:01<00:14, 241.20it/s] 96%|█████████▋| 86625/90000 [06:01<00:13, 243.71it/s] 96%|█████████▋| 86650/90000 [06:01<00:13, 242.99it/s] 96%|█████████▋| 86675/90000 [06:01<00:13, 241.25it/s] 96%|█████████▋| 86700/90000 [06:01<00:13, 238.08it/s] 96%|█████████▋| 86725/90000 [06:01<00:13, 239.63it/s] 96%|█████████▋| 86750/90000 [06:01<00:13, 241.50it/s] 96%|█████████▋| 86775/90000 [06:01<00:13, 238.60it/s] 96%|█████████▋| 86799/90000 [06:01<00:13, 237.49it/s] 96%|█████████▋| 86824/90000 [06:02<00:13, 238.43it/s] 96%|█████████▋| 86848/90000 [06:02<00:13, 236.34it/s] 97%|█████████▋| 86874/90000 [06:02<00:12, 240.80it/s] 97%|█████████▋| 86899/90000 [06:02<00:12, 240.82it/s] 97%|█████████▋| 86924/90000 [06:02<00:12, 238.75it/s] 97%|█████████▋| 86949/90000 [06:02<00:12, 240.40it/s] 97%|█████████▋| 86974/90000 [06:02<00:12, 241.98it/s] 97%|█████████▋| 86999/90000 [06:02<00:12, 241.17it/s] 97%|█████████▋| 87024/90000 [06:02<00:12, 241.50it/s] 97%|█████████▋| 87050/90000 [06:03<00:12, 244.03it/s] 97%|█████████▋| 87076/90000 [06:03<00:11, 247.20it/s] 97%|█████████▋| 87101/90000 [06:03<00:11, 247.27it/s] 97%|█████████▋| 87126/90000 [06:03<00:11, 247.37it/s] 97%|█████████▋| 87151/90000 [06:03<00:11, 242.06it/s] 97%|█████████▋| 87176/90000 [06:03<00:11, 240.50it/s] 97%|█████████▋| 87201/90000 [06:03<00:11, 243.03it/s] 97%|█████████▋| 87226/90000 [06:03<00:11, 243.20it/s] 97%|█████████▋| 87251/90000 [06:03<00:11, 239.99it/s] 97%|█████████▋| 87276/90000 [06:03<00:11, 240.75it/s] 97%|█████████▋| 87301/90000 [06:04<00:11, 237.70it/s] 97%|█████████▋| 87325/90000 [06:04<00:11, 234.43it/s] 97%|█████████▋| 87349/90000 [06:04<00:11, 234.88it/s] 97%|█████████▋| 87375/90000 [06:04<00:10, 240.84it/s] 97%|█████████▋| 87400/90000 [06:04<00:10, 242.83it/s] 97%|█████████▋| 87425/90000 [06:04<00:10, 241.90it/s] 97%|█████████▋| 87450/90000 [06:04<00:10, 240.55it/s] 97%|█████████▋| 87476/90000 [06:04<00:10, 244.81it/s] 97%|█████████▋| 87501/90000 [06:04<00:10, 245.14it/s] 97%|█████████▋| 87526/90000 [06:04<00:10, 243.83it/s] 97%|█████████▋| 87552/90000 [06:05<00:09, 246.49it/s] 97%|█████████▋| 87578/90000 [06:05<00:09, 247.80it/s] 97%|█████████▋| 87603/90000 [06:05<00:09, 242.73it/s] 97%|█████████▋| 87628/90000 [06:05<00:09, 243.07it/s] 97%|█████████▋| 87653/90000 [06:05<00:09, 241.98it/s] 97%|█████████▋| 87678/90000 [06:05<00:09, 241.18it/s] 97%|█████████▋| 87703/90000 [06:05<00:09, 242.06it/s] 97%|█████████▋| 87728/90000 [06:05<00:09, 243.86it/s] 98%|█████████▊| 87753/90000 [06:05<00:09, 239.90it/s] 98%|█████████▊| 87778/90000 [06:06<00:09, 242.22it/s] 98%|█████████▊| 87803/90000 [06:06<00:09, 241.29it/s] 98%|█████████▊| 87828/90000 [06:06<00:09, 240.67it/s] 98%|█████████▊| 87853/90000 [06:06<00:08, 242.83it/s] 98%|█████████▊| 87878/90000 [06:06<00:08, 237.91it/s] 98%|█████████▊| 87902/90000 [06:06<00:08, 238.49it/s] 98%|█████████▊| 87927/90000 [06:06<00:08, 240.38it/s] 98%|█████████▊| 87952/90000 [06:06<00:08, 243.09it/s] 98%|█████████▊| 87977/90000 [06:06<00:08, 244.71it/s] 98%|█████████▊| 88002/90000 [06:06<00:08, 244.01it/s] 98%|█████████▊| 88027/90000 [06:07<00:08, 244.65it/s] 98%|█████████▊| 88052/90000 [06:07<00:08, 243.43it/s] 98%|█████████▊| 88077/90000 [06:07<00:07, 243.94it/s] 98%|█████████▊| 88102/90000 [06:07<00:07, 243.06it/s] 98%|█████████▊| 88127/90000 [06:07<00:07, 242.18it/s] 98%|█████████▊| 88153/90000 [06:07<00:07, 244.58it/s] 98%|█████████▊| 88178/90000 [06:07<00:07, 243.39it/s] 98%|█████████▊| 88203/90000 [06:07<00:07, 239.76it/s] 98%|█████████▊| 88228/90000 [06:07<00:07, 241.14it/s] 98%|█████████▊| 88253/90000 [06:07<00:07, 242.38it/s] 98%|█████████▊| 88278/90000 [06:08<00:07, 241.72it/s] 98%|█████████▊| 88304/90000 [06:08<00:06, 244.44it/s] 98%|█████████▊| 88329/90000 [06:08<00:06, 244.54it/s] 98%|█████████▊| 88354/90000 [06:08<00:06, 243.28it/s] 98%|█████████▊| 88379/90000 [06:08<00:06, 243.27it/s] 98%|█████████▊| 88404/90000 [06:08<00:06, 242.05it/s] 98%|█████████▊| 88429/90000 [06:08<00:06, 242.86it/s] 98%|█████████▊| 88454/90000 [06:08<00:06, 241.58it/s] 98%|█████████▊| 88479/90000 [06:08<00:06, 238.85it/s] 98%|█████████▊| 88504/90000 [06:09<00:06, 240.22it/s] 98%|█████████▊| 88529/90000 [06:09<00:06, 242.75it/s] 98%|█████████▊| 88554/90000 [06:09<00:05, 243.10it/s] 98%|█████████▊| 88579/90000 [06:09<00:05, 244.42it/s] 98%|█████████▊| 88604/90000 [06:09<00:05, 238.88it/s] 98%|█████████▊| 88628/90000 [06:09<00:05, 238.27it/s] 99%|█████████▊| 88652/90000 [06:09<00:05, 238.77it/s] 99%|█████████▊| 88677/90000 [06:09<00:05, 241.33it/s] 99%|█████████▊| 88702/90000 [06:09<00:05, 241.80it/s] 99%|█████████▊| 88727/90000 [06:09<00:05, 242.12it/s] 99%|█████████▊| 88752/90000 [06:10<00:05, 243.65it/s] 99%|█████████▊| 88777/90000 [06:10<00:05, 243.17it/s] 99%|█████████▊| 88802/90000 [06:10<00:04, 240.70it/s] 99%|█████████▊| 88827/90000 [06:10<00:04, 239.44it/s] 99%|█████████▊| 88852/90000 [06:10<00:04, 241.07it/s] 99%|█████████▉| 88878/90000 [06:10<00:04, 244.65it/s] 99%|█████████▉| 88903/90000 [06:10<00:04, 245.65it/s] 99%|█████████▉| 88928/90000 [06:10<00:04, 242.41it/s] 99%|█████████▉| 88953/90000 [06:10<00:04, 243.30it/s] 99%|█████████▉| 88978/90000 [06:10<00:04, 242.52it/s] 99%|█████████▉| 89003/90000 [06:11<00:04, 241.76it/s] 99%|█████████▉| 89028/90000 [06:11<00:04, 240.14it/s] 99%|█████████▉| 89054/90000 [06:11<00:03, 245.42it/s] 99%|█████████▉| 89079/90000 [06:11<00:03, 242.87it/s] 99%|█████████▉| 89105/90000 [06:11<00:03, 246.42it/s] 99%|█████████▉| 89130/90000 [06:11<00:03, 246.48it/s] 99%|█████████▉| 89155/90000 [06:11<00:03, 243.72it/s] 99%|█████████▉| 89180/90000 [06:11<00:03, 242.03it/s] 99%|█████████▉| 89205/90000 [06:11<00:03, 242.30it/s] 99%|█████████▉| 89230/90000 [06:12<00:03, 242.02it/s] 99%|█████████▉| 89255/90000 [06:12<00:03, 241.82it/s] 99%|█████████▉| 89280/90000 [06:12<00:03, 239.79it/s] 99%|█████████▉| 89305/90000 [06:12<00:02, 241.62it/s] 99%|█████████▉| 89330/90000 [06:12<00:02, 238.72it/s] 99%|█████████▉| 89356/90000 [06:12<00:02, 243.03it/s] 99%|█████████▉| 89381/90000 [06:12<00:02, 242.75it/s] 99%|█████████▉| 89406/90000 [06:12<00:02, 237.74it/s] 99%|█████████▉| 89431/90000 [06:12<00:02, 238.91it/s] 99%|█████████▉| 89457/90000 [06:12<00:02, 244.40it/s] 99%|█████████▉| 89482/90000 [06:13<00:02, 244.63it/s] 99%|█████████▉| 89507/90000 [06:13<00:02, 241.55it/s] 99%|█████████▉| 89532/90000 [06:13<00:01, 241.04it/s]100%|█████████▉| 89557/90000 [06:13<00:01, 236.88it/s]100%|█████████▉| 89581/90000 [06:13<00:01, 236.56it/s]100%|█████████▉| 89606/90000 [06:13<00:01, 238.40it/s]100%|█████████▉| 89630/90000 [06:13<00:01, 234.87it/s]100%|█████████▉| 89656/90000 [06:13<00:01, 239.72it/s]100%|█████████▉| 89681/90000 [06:13<00:01, 241.15it/s]100%|█████████▉| 89706/90000 [06:13<00:01, 239.89it/s]100%|█████████▉| 89730/90000 [06:14<00:01, 239.20it/s]100%|█████████▉| 89755/90000 [06:14<00:01, 240.39it/s]100%|█████████▉| 89780/90000 [06:14<00:00, 238.59it/s]100%|█████████▉| 89805/90000 [06:14<00:00, 239.44it/s]100%|█████████▉| 89830/90000 [06:14<00:00, 241.42it/s]100%|█████████▉| 89855/90000 [06:14<00:00, 238.25it/s]100%|█████████▉| 89880/90000 [06:14<00:00, 239.76it/s]100%|█████████▉| 89904/90000 [06:14<00:00, 237.56it/s]100%|█████████▉| 89929/90000 [06:14<00:00, 237.81it/s]100%|█████████▉| 89953/90000 [06:15<00:00, 233.62it/s]100%|█████████▉| 89977/90000 [06:15<00:00, 234.87it/s]100%|██████████| 90000/90000 [06:15<00:00, 239.85it/s]Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW170104_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW170104_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.05, mode='train', model_dir='models3/GW170104_sample_uniform_100basis_all_mixed_prior_a005/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=100)
Waveform directory data/GW170104_sample_prior_basis/
Model directory models3/GW170104_sample_uniform_100basis_all_mixed_prior_a005/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Learning rate: 0.0002

Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.0126	Cost: 23.56s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 22.1709	Cost: 6.07s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.5871	Cost: 6.04s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 21.5099	Cost: 5.79s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 21.2923	Cost: 5.68s
Train Epoch: 1 	Average Loss: 21.9946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3956

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 21.4570	Cost: 21.21s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 21.2928	Cost: 7.31s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 21.2741	Cost: 6.01s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 21.2188	Cost: 5.87s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 21.2747	Cost: 5.83s
Train Epoch: 2 	Average Loss: 21.2885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2820

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999998026079186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 21.2411	Cost: 19.86s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 21.1974	Cost: 6.79s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 21.2346	Cost: 6.13s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 21.1993	Cost: 5.88s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 21.2049	Cost: 5.88s
Train Epoch: 3 	Average Loss: 21.2268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2430

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019999995558678347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 21.1911	Cost: 18.86s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 21.1836	Cost: 6.51s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 21.1212	Cost: 6.71s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 21.1576	Cost: 5.84s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 21.1377	Cost: 5.74s
Train Epoch: 4 	Average Loss: 21.1772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2205

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.0001999999210431752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 21.1748	Cost: 18.92s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 21.1237	Cost: 6.08s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 21.0848	Cost: 6.10s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 21.0863	Cost: 5.90s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 21.0566	Cost: 5.69s
Train Epoch: 5 	Average Loss: 21.1185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1383

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019999987662997035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 21.0363	Cost: 19.78s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 21.0137	Cost: 6.04s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 21.0160	Cost: 6.07s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 20.9965	Cost: 5.85s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 21.0171	Cost: 5.72s
Train Epoch: 6 	Average Loss: 21.0438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0764

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019999982234717337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 20.9846	Cost: 19.13s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 20.9531	Cost: 5.96s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 21.0574	Cost: 6.62s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 20.9565	Cost: 5.83s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 20.9309	Cost: 5.69s
Train Epoch: 7 	Average Loss: 20.9820
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0160

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 20.9755	Cost: 18.56s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 20.8745	Cost: 6.06s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 20.8291	Cost: 6.39s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 20.8659	Cost: 5.97s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 20.8744	Cost: 5.71s
Train Epoch: 8 	Average Loss: 20.9073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9588

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.0001999996841728254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 20.7940	Cost: 19.37s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 20.8628	Cost: 6.07s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 20.8574	Cost: 6.03s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 20.7711	Cost: 6.02s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 20.8496	Cost: 6.02s
Train Epoch: 9 	Average Loss: 20.8562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8742

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 20.8251	Cost: 18.93s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 20.8401	Cost: 5.95s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 20.8596	Cost: 6.09s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 20.7787	Cost: 5.99s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 20.7637	Cost: 6.15s
Train Epoch: 10 	Average Loss: 20.8037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8057

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019999950652018584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 20.7668	Cost: 19.10s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 20.7558	Cost: 5.95s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 20.7872	Cost: 5.98s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 20.7255	Cost: 6.02s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 20.6985	Cost: 6.25s
Train Epoch: 11 	Average Loss: 20.7500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7567

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019999940288952797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 20.7026	Cost: 19.50s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 20.6609	Cost: 6.00s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 20.6842	Cost: 6.01s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 20.6880	Cost: 5.82s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 20.6986	Cost: 5.85s
Train Epoch: 12 	Average Loss: 20.6824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7022

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019999928938932473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 20.6293	Cost: 20.16s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 20.6499	Cost: 5.94s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 20.5033	Cost: 6.31s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 20.5697	Cost: 5.88s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 20.5827	Cost: 5.86s
Train Epoch: 13 	Average Loss: 20.6218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6591

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.0001999991660195873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 20.5811	Cost: 19.07s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 20.5935	Cost: 6.00s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 20.5518	Cost: 5.95s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 20.5690	Cost: 5.99s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 20.5399	Cost: 5.72s
Train Epoch: 14 	Average Loss: 20.5713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6049

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 20.4849	Cost: 19.57s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 20.4060	Cost: 6.13s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 20.5100	Cost: 5.97s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 20.5073	Cost: 5.82s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 20.5071	Cost: 5.80s
Train Epoch: 15 	Average Loss: 20.5143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5278

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019999888967155963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 20.4744	Cost: 20.56s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 20.4492	Cost: 5.93s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 20.4393	Cost: 6.25s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 20.4763	Cost: 5.82s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 20.4108	Cost: 5.69s
Train Epoch: 16 	Average Loss: 20.4533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5042

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001999987366932966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 20.4558	Cost: 19.96s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 20.3316	Cost: 5.98s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 20.3711	Cost: 6.33s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 20.3534	Cost: 5.81s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 20.3831	Cost: 5.67s
Train Epoch: 17 	Average Loss: 20.4056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4289

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019999857384555393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 20.4982	Cost: 19.74s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 20.3303	Cost: 6.00s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 20.3407	Cost: 6.01s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 20.3318	Cost: 5.81s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 20.3124	Cost: 5.68s
Train Epoch: 18 	Average Loss: 20.3451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3564

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.0001999984011283477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 20.2549	Cost: 19.97s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 20.2812	Cost: 5.94s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 20.2399	Cost: 5.97s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 20.2544	Cost: 5.90s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 20.2010	Cost: 5.73s
Train Epoch: 19 	Average Loss: 20.2809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2933

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019999821854169497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 20.1728	Cost: 20.24s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 20.2528	Cost: 5.97s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 20.2333	Cost: 6.35s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 20.2077	Cost: 5.82s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 20.1102	Cost: 5.93s
Train Epoch: 20 	Average Loss: 20.2099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2563

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 20.1981	Cost: 19.33s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 20.1414	Cost: 6.08s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 20.1090	Cost: 6.09s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 20.0593	Cost: 5.83s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 20.0984	Cost: 5.67s
Train Epoch: 21 	Average Loss: 20.1396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1417

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 20.1497	Cost: 19.42s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 20.1136	Cost: 6.08s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 20.0621	Cost: 6.04s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 20.0475	Cost: 5.84s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 20.1099	Cost: 5.68s
Train Epoch: 22 	Average Loss: 20.0997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1578

Learning rate: 0.00019999761156524272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 20.0763	Cost: 19.86s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 20.0806	Cost: 6.13s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 20.1036	Cost: 6.05s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 20.0394	Cost: 5.84s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 20.0381	Cost: 5.69s
Train Epoch: 23 	Average Loss: 20.0478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0843

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 20.0918	Cost: 20.63s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 19.9728	Cost: 6.05s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 19.9594	Cost: 6.55s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 19.9765	Cost: 5.82s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 19.9860	Cost: 6.08s
Train Epoch: 24 	Average Loss: 20.0024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0407

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.00019999715756739833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 20.0514	Cost: 19.82s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 19.9391	Cost: 5.97s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 19.8464	Cost: 6.07s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 19.9195	Cost: 5.91s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 19.9799	Cost: 5.69s
Train Epoch: 25 	Average Loss: 19.9562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0332

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.000199996915764479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 19.9788	Cost: 19.76s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 19.9522	Cost: 6.02s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 19.9538	Cost: 6.00s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 19.8811	Cost: 5.83s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 19.8147	Cost: 5.68s
Train Epoch: 26 	Average Loss: 19.9170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9555

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019999666409225975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 19.8936	Cost: 20.76s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 19.8582	Cost: 6.00s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 19.9120	Cost: 6.10s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 19.9260	Cost: 5.85s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 19.8722	Cost: 5.70s
Train Epoch: 27 	Average Loss: 19.8839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9321

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019999640255076543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 19.9210	Cost: 20.08s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 19.7850	Cost: 6.02s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 19.8229	Cost: 6.07s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 19.8237	Cost: 5.86s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 19.8036	Cost: 5.78s
Train Epoch: 28 	Average Loss: 19.8433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8533

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019999613114002186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 19.7973	Cost: 20.21s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 19.7682	Cost: 6.00s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 19.7692	Cost: 6.05s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 19.7812	Cost: 5.91s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 19.7204	Cost: 5.68s
Train Epoch: 29 	Average Loss: 19.8034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8403

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.0001999958498600558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 19.7637	Cost: 21.43s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 19.6606	Cost: 6.00s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 19.7213	Cost: 5.99s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 19.7338	Cost: 5.89s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 19.7445	Cost: 5.69s
Train Epoch: 30 	Average Loss: 19.7646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8250

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.000199995558710895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 19.7629	Cost: 20.59s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 19.7492	Cost: 5.92s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 19.6833	Cost: 5.96s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 19.6287	Cost: 5.88s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 19.6572	Cost: 5.70s
Train Epoch: 31 	Average Loss: 19.7259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7492

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 0.00019999525769256825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 19.7493	Cost: 22.03s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 19.6863	Cost: 5.91s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 19.6841	Cost: 6.44s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 19.6259	Cost: 5.89s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 19.6622	Cost: 5.84s
Train Epoch: 32 	Average Loss: 19.6777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7213

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.00019999494680510518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 19.5997	Cost: 21.06s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 19.6118	Cost: 5.95s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 19.6033	Cost: 6.24s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 19.5977	Cost: 5.87s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 19.5529	Cost: 5.73s
Train Epoch: 33 	Average Loss: 19.6200
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6718

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019999462604853658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 19.6708	Cost: 20.15s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 19.5808	Cost: 6.05s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 19.5213	Cost: 6.01s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 19.5140	Cost: 5.88s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 19.5206	Cost: 5.78s
Train Epoch: 34 	Average Loss: 19.5677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6020

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019999429542289402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 19.6341	Cost: 20.54s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 19.5237	Cost: 5.94s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 19.4798	Cost: 5.98s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 19.4946	Cost: 5.86s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 19.5155	Cost: 5.80s
Train Epoch: 35 	Average Loss: 19.5402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5925

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.00019999395492821016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 19.5043	Cost: 21.45s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 19.5287	Cost: 6.07s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 19.4542	Cost: 5.97s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 19.5074	Cost: 5.80s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 19.5297	Cost: 5.75s
Train Epoch: 36 	Average Loss: 19.4875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5407

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.0001999936045645186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 19.5400	Cost: 23.59s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 19.4410	Cost: 6.03s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 19.4077	Cost: 6.00s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 19.4904	Cost: 5.83s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 19.4769	Cost: 5.82s
Train Epoch: 37 	Average Loss: 19.4677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4965

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.00019999324433185394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 19.4445	Cost: 21.94s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 19.4428	Cost: 6.09s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 19.3888	Cost: 6.12s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 19.4246	Cost: 5.83s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 19.4593	Cost: 5.67s
Train Epoch: 38 	Average Loss: 19.4266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4700

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.0001999928742302517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 19.4572	Cost: 22.39s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 19.3923	Cost: 6.03s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 19.3388	Cost: 6.12s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 19.3306	Cost: 5.84s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 19.4213	Cost: 5.69s
Train Epoch: 39 	Average Loss: 19.4110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4517

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019999249425974844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 19.4640	Cost: 19.98s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 19.3940	Cost: 6.09s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 19.3771	Cost: 6.15s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 19.3285	Cost: 5.92s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 19.3527	Cost: 5.75s
Train Epoch: 40 	Average Loss: 19.3647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4207

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 19.5083	Cost: 21.15s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 19.3673	Cost: 6.57s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 19.1819	Cost: 6.15s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 19.3304	Cost: 5.93s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 19.3360	Cost: 5.73s
Train Epoch: 41 	Average Loss: 19.3485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3781

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019999170471218976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 19.4113	Cost: 19.98s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 19.2704	Cost: 6.02s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 19.3532	Cost: 6.41s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 19.3822	Cost: 5.84s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 19.3579	Cost: 5.83s
Train Epoch: 42 	Average Loss: 19.3152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3728

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.0001999912951352123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 19.3662	Cost: 20.32s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 19.2759	Cost: 6.94s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 19.1670	Cost: 6.03s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 19.3398	Cost: 5.86s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 19.2185	Cost: 5.70s
Train Epoch: 43 	Average Loss: 19.2975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3012

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.00019999087568948966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 19.2239	Cost: 20.51s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 19.3395	Cost: 6.08s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 19.2729	Cost: 6.05s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 19.2534	Cost: 5.85s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 19.2290	Cost: 5.72s
Train Epoch: 44 	Average Loss: 19.2605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2803

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 0.0001999904463750632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 19.2390	Cost: 20.62s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 19.2118	Cost: 6.04s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 19.1662	Cost: 6.14s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 19.1693	Cost: 5.89s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 19.2161	Cost: 5.70s
Train Epoch: 45 	Average Loss: 19.2291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3065

Learning rate: 0.00019999000719197536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 19.1715	Cost: 20.52s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 19.1697	Cost: 6.16s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 19.1148	Cost: 6.19s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 19.1811	Cost: 5.86s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 19.1585	Cost: 5.74s
Train Epoch: 46 	Average Loss: 19.2038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2434

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 0.00019998955814026943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 19.2418	Cost: 18.80s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 19.1180	Cost: 7.36s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 19.0932	Cost: 6.08s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 19.2258	Cost: 5.90s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 19.1530	Cost: 5.74s
Train Epoch: 47 	Average Loss: 19.1624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2373

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 0.00019998909921998973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 19.2294	Cost: 18.95s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 19.1233	Cost: 6.28s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 19.1732	Cost: 6.79s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 19.1897	Cost: 5.84s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 19.1419	Cost: 5.72s
Train Epoch: 48 	Average Loss: 19.1513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1953

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 0.0001999886304311816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 19.0720	Cost: 18.40s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 19.0955	Cost: 6.57s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 19.0688	Cost: 6.30s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 19.1168	Cost: 5.87s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 19.0062	Cost: 5.71s
Train Epoch: 49 	Average Loss: 19.1046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1590

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019998815177389132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 19.0569	Cost: 18.68s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 19.0863	Cost: 6.08s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 19.0650	Cost: 6.36s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 19.0332	Cost: 5.90s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 19.0483	Cost: 5.76s
Train Epoch: 50 	Average Loss: 19.0758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0870

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 19.0835	Cost: 18.82s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 19.0182	Cost: 6.25s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 19.0259	Cost: 6.41s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 19.0705	Cost: 5.87s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 19.0625	Cost: 5.70s
Train Epoch: 51 	Average Loss: 19.0392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0807

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019998716485405404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 19.0871	Cost: 18.32s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 18.9412	Cost: 6.02s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 18.9102	Cost: 6.17s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 18.9328	Cost: 5.86s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 18.9595	Cost: 5.68s
Train Epoch: 52 	Average Loss: 18.9901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0360

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 0.0001999866565916045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 19.0252	Cost: 19.31s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 18.9072	Cost: 6.11s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 18.9908	Cost: 6.31s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 18.9670	Cost: 6.06s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 18.9994	Cost: 5.71s
Train Epoch: 53 	Average Loss: 18.9786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0254

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 0.0001999861384608676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 19.0046	Cost: 17.45s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 18.8951	Cost: 6.12s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 18.8911	Cost: 6.38s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 18.9350	Cost: 5.88s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 19.0274	Cost: 5.75s
Train Epoch: 54 	Average Loss: 18.9452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9381

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 0.00019998561046189446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 18.9245	Cost: 19.60s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 18.8676	Cost: 6.01s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 19.0042	Cost: 6.13s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 18.9265	Cost: 5.94s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 18.8735	Cost: 6.04s
Train Epoch: 55 	Average Loss: 18.9082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9455

Learning rate: 0.00019998507259473718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 18.8859	Cost: 19.87s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 18.8644	Cost: 6.09s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 18.8855	Cost: 5.98s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 18.8490	Cost: 6.01s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 18.7709	Cost: 5.72s
Train Epoch: 56 	Average Loss: 18.8741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9096

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019998452485944885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 18.9809	Cost: 20.04s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 18.8670	Cost: 5.94s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 18.8220	Cost: 6.03s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 18.9201	Cost: 6.13s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 18.8334	Cost: 5.81s
Train Epoch: 57 	Average Loss: 18.8617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8654

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 0.00019998396725608354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 18.8612	Cost: 19.32s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 18.7435	Cost: 5.99s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 18.7865	Cost: 6.58s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 18.8089	Cost: 5.86s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 18.7680	Cost: 5.69s
Train Epoch: 58 	Average Loss: 18.8317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8574

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 18.8684	Cost: 19.29s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 18.8017	Cost: 5.94s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 18.7983	Cost: 6.00s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 18.8497	Cost: 5.94s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 18.8591	Cost: 5.70s
Train Epoch: 59 	Average Loss: 18.8201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8723

Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 18.8075	Cost: 20.40s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 18.7404	Cost: 5.98s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 18.7624	Cost: 6.21s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 18.7935	Cost: 5.92s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 18.7677	Cost: 5.71s
Train Epoch: 60 	Average Loss: 18.7891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8568

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 18.8685	Cost: 19.63s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 18.7763	Cost: 6.06s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 18.8426	Cost: 6.02s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 18.7369	Cost: 5.80s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 18.7840	Cost: 5.68s
Train Epoch: 61 	Average Loss: 18.7627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8092

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 18.7347	Cost: 20.07s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 18.6170	Cost: 5.96s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 18.7269	Cost: 6.00s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 18.7718	Cost: 5.83s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 18.7287	Cost: 5.83s
Train Epoch: 62 	Average Loss: 18.7303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7576

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019998103122006246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 18.7901	Cost: 19.68s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 18.7685	Cost: 5.94s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 18.7334	Cost: 6.03s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 18.7661	Cost: 5.82s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 18.6814	Cost: 5.83s
Train Epoch: 63 	Average Loss: 18.7281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7524

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 0.00019998041440942506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 18.7033	Cost: 19.39s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 18.6851	Cost: 5.99s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 18.7605	Cost: 5.95s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 18.7793	Cost: 5.83s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 18.6020	Cost: 5.98s
Train Epoch: 64 	Average Loss: 18.7054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7683

Learning rate: 0.00019997978773111632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 18.7695	Cost: 19.80s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 18.7003	Cost: 6.01s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 18.6960	Cost: 6.04s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 18.6722	Cost: 5.85s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 18.6194	Cost: 5.81s
Train Epoch: 65 	Average Loss: 18.6689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7117

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 0.00019997915118519813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 18.6891	Cost: 20.10s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 18.6966	Cost: 5.98s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 18.6347	Cost: 5.98s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 18.7239	Cost: 5.90s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 18.6503	Cost: 5.67s
Train Epoch: 66 	Average Loss: 18.6537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6894

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.0001999785047717333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 18.6468	Cost: 19.75s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 18.6567	Cost: 5.95s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 18.5880	Cost: 5.98s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 18.5407	Cost: 5.83s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 18.5327	Cost: 5.68s
Train Epoch: 67 	Average Loss: 18.6089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6769

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Learning rate: 0.00019997784849078566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 18.5960	Cost: 19.60s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 18.5812	Cost: 6.00s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 18.5421	Cost: 6.01s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 18.4992	Cost: 5.86s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 18.5326	Cost: 5.66s
Train Epoch: 68 	Average Loss: 18.5921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6380

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 0.00019997718234242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 18.6016	Cost: 20.67s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 18.5262	Cost: 5.95s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 18.5464	Cost: 5.96s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 18.4889	Cost: 5.85s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 18.5151	Cost: 5.79s
Train Epoch: 69 	Average Loss: 18.5631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6438

Learning rate: 0.00019997650632670199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 18.5674	Cost: 19.12s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 18.5205	Cost: 6.06s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 18.5134	Cost: 6.07s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 18.5805	Cost: 5.83s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 18.4785	Cost: 5.69s
Train Epoch: 70 	Average Loss: 18.5535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5873

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Learning rate: 0.0001999758204436984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 18.5550	Cost: 20.59s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 18.4242	Cost: 5.97s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 18.5732	Cost: 6.02s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 18.4995	Cost: 5.82s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 18.5106	Cost: 5.71s
Train Epoch: 71 	Average Loss: 18.5292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5660

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00019997512469347695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 18.5885	Cost: 19.30s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 18.4917	Cost: 6.05s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 18.5180	Cost: 6.04s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 18.5230	Cost: 5.85s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 18.5783	Cost: 5.70s
Train Epoch: 72 	Average Loss: 18.4960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5197

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 0.00019997441907610624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 18.5680	Cost: 20.12s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 18.4684	Cost: 6.03s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 18.4787	Cost: 6.61s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 18.5117	Cost: 5.85s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 18.4255	Cost: 5.78s
Train Epoch: 73 	Average Loss: 18.4929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5333

Learning rate: 0.00019997370359165596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 18.5353	Cost: 20.26s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 18.4795	Cost: 6.05s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 18.4723	Cost: 6.14s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 18.3897	Cost: 5.82s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 18.3981	Cost: 5.71s
Train Epoch: 74 	Average Loss: 18.4655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4797

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.0001999729782401967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 18.5206	Cost: 19.66s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 18.4328	Cost: 6.11s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 18.4442	Cost: 6.06s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 18.4663	Cost: 5.86s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 18.4395	Cost: 5.81s
Train Epoch: 75 	Average Loss: 18.4472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4845

Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 18.4529	Cost: 19.90s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 18.3783	Cost: 6.08s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 18.4245	Cost: 6.03s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 18.3824	Cost: 5.87s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 18.3628	Cost: 5.73s
Train Epoch: 76 	Average Loss: 18.4083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4748

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00019997149793653861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 18.4472	Cost: 19.03s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 18.3656	Cost: 6.06s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 18.4087	Cost: 6.23s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 18.4866	Cost: 5.83s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 18.3332	Cost: 5.71s
Train Epoch: 77 	Average Loss: 18.4103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4266

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Learning rate: 0.00019997074298448586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 18.3704	Cost: 20.38s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 18.3800	Cost: 5.97s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 18.3317	Cost: 6.69s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 18.3846	Cost: 5.83s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 18.3215	Cost: 5.73s
Train Epoch: 78 	Average Loss: 18.3782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3813

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Learning rate: 0.00019996997816571638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 18.3741	Cost: 19.32s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 18.3541	Cost: 6.05s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 18.2637	Cost: 6.08s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 18.3864	Cost: 5.87s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 18.3034	Cost: 5.71s
Train Epoch: 79 	Average Loss: 18.3549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4076

Learning rate: 0.00019996920348030559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 18.4672	Cost: 20.07s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 18.3495	Cost: 6.02s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 18.2512	Cost: 6.23s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 18.3848	Cost: 5.84s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 18.3043	Cost: 5.67s
Train Epoch: 80 	Average Loss: 18.3442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3885

Learning rate: 0.00019996841892832998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 18.3519	Cost: 20.13s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 18.3194	Cost: 5.93s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 18.2308	Cost: 6.12s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 18.3662	Cost: 5.89s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 18.2822	Cost: 5.66s
Train Epoch: 81 	Average Loss: 18.3181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4016

Learning rate: 0.00019996762450986697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 18.2922	Cost: 20.41s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 18.3218	Cost: 5.99s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 18.2453	Cost: 6.08s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 18.3061	Cost: 5.95s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 18.3613	Cost: 5.71s
Train Epoch: 82 	Average Loss: 18.2962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3520

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Learning rate: 0.00019996682022499498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 18.3197	Cost: 19.93s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 18.2501	Cost: 5.92s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 18.2446	Cost: 6.06s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 18.3625	Cost: 5.83s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 18.3843	Cost: 5.71s
Train Epoch: 83 	Average Loss: 18.2787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3303

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Learning rate: 0.0001999660060737934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 18.3087	Cost: 19.41s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 18.2813	Cost: 6.01s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 18.2549	Cost: 6.62s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 18.3074	Cost: 5.80s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 18.3183	Cost: 5.67s
Train Epoch: 84 	Average Loss: 18.2816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3374

Learning rate: 0.00019996518205634255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 18.2760	Cost: 20.02s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 18.2065	Cost: 5.98s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 18.2161	Cost: 6.01s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 18.2425	Cost: 5.85s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 18.1687	Cost: 5.68s
Train Epoch: 85 	Average Loss: 18.2495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2714

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Learning rate: 0.0001999643481727238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 18.3824	Cost: 19.82s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 18.2529	Cost: 6.07s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 18.1359	Cost: 6.03s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 18.2656	Cost: 5.83s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 18.2341	Cost: 5.67s
Train Epoch: 86 	Average Loss: 18.2342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2773

Learning rate: 0.0001999635044230194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 18.2691	Cost: 20.02s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 18.2088	Cost: 6.13s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 18.1425	Cost: 5.97s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 18.2120	Cost: 5.89s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 18.2364	Cost: 5.72s
Train Epoch: 87 	Average Loss: 18.2018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2654

Saving model as e87_model.pt & e87_waveforms_supplementary.hdf5
Learning rate: 0.00019996265080731267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 18.2375	Cost: 20.36s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 18.1355	Cost: 6.12s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 18.1714	Cost: 6.17s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 18.2467	Cost: 5.91s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 18.2152	Cost: 5.75s
Train Epoch: 88 	Average Loss: 18.1960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2593

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 0.00019996178732568782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 18.2032	Cost: 19.70s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 18.2019	Cost: 6.01s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 18.1783	Cost: 6.17s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 18.1968	Cost: 5.88s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 18.1409	Cost: 5.80s
Train Epoch: 89 	Average Loss: 18.1844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2171

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 0.00019996091397823007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 18.2217	Cost: 20.17s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 18.0548	Cost: 6.00s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 18.0666	Cost: 6.69s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 18.1657	Cost: 5.98s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 18.1610	Cost: 5.73s
Train Epoch: 90 	Average Loss: 18.1731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2124

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 0.00019996003076502562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 18.0779	Cost: 20.51s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 18.1334	Cost: 6.02s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 18.1689	Cost: 6.00s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 18.1232	Cost: 5.84s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 18.1027	Cost: 5.67s
Train Epoch: 91 	Average Loss: 18.1389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1942

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Learning rate: 0.0001999591376861617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 18.1106	Cost: 20.35s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 18.1113	Cost: 6.00s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 18.1322	Cost: 6.02s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 18.1921	Cost: 5.77s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 18.0941	Cost: 5.46s
Train Epoch: 92 	Average Loss: 18.1248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2218

Learning rate: 0.0001999582347417264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 18.1792	Cost: 20.12s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 18.1285	Cost: 6.02s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 18.0726	Cost: 6.16s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 18.0651	Cost: 5.94s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 18.0554	Cost: 5.69s
Train Epoch: 93 	Average Loss: 18.1068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1792

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 0.00019995732193180883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 18.0460	Cost: 19.98s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 18.1017	Cost: 6.05s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 18.1618	Cost: 6.25s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 18.1865	Cost: 5.86s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 18.0778	Cost: 5.71s
Train Epoch: 94 	Average Loss: 18.1075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1975

Learning rate: 0.00019995639925649909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 18.1914	Cost: 19.95s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 18.0503	Cost: 6.18s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 18.1493	Cost: 6.08s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 18.2067	Cost: 5.88s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 18.0468	Cost: 5.67s
Train Epoch: 95 	Average Loss: 18.0849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1566

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00019995546671588827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 18.1368	Cost: 19.87s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 18.1073	Cost: 5.97s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 18.0699	Cost: 6.03s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 18.0189	Cost: 5.85s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 18.1478	Cost: 5.70s
Train Epoch: 96 	Average Loss: 18.0737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1457

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Learning rate: 0.0001999545243100684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 18.0967	Cost: 20.33s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 17.9775	Cost: 6.01s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 18.0560	Cost: 6.31s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 17.9195	Cost: 5.83s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 18.0556	Cost: 5.69s
Train Epoch: 97 	Average Loss: 18.0545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0985

Saving model as e97_model.pt & e97_waveforms_supplementary.hdf5
Learning rate: 0.00019995357203913245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 18.1783	Cost: 19.60s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 18.0009	Cost: 6.17s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 18.0436	Cost: 6.06s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 18.0875	Cost: 5.88s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 18.0049	Cost: 5.71s
Train Epoch: 98 	Average Loss: 18.0303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1017

Learning rate: 0.00019995260990317447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 18.0187	Cost: 19.99s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 17.9607	Cost: 6.03s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 17.9011	Cost: 6.16s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 17.9789	Cost: 5.95s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 18.0245	Cost: 5.71s
Train Epoch: 99 	Average Loss: 17.9988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0414

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Learning rate: 0.00019995163790228936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 18.0060	Cost: 19.78s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 17.9750	Cost: 6.00s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 17.9673	Cost: 6.02s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 17.9836	Cost: 5.85s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 18.0255	Cost: 5.69s
Train Epoch: 100 	Average Loss: 17.9823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0810

Learning rate: 0.0001999506560365731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 17.9891	Cost: 20.58s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 18.0566	Cost: 5.97s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 17.9532	Cost: 6.03s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 18.0671	Cost: 5.84s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 17.9346	Cost: 5.75s
Train Epoch: 101 	Average Loss: 17.9847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0712

Learning rate: 0.00019994966430612258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 17.9723	Cost: 19.90s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 18.0058	Cost: 5.91s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 18.0569	Cost: 6.10s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 18.0735	Cost: 5.82s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 17.9973	Cost: 5.68s
Train Epoch: 102 	Average Loss: 17.9737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0310

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00019994866271103568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 17.9077	Cost: 20.37s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 17.9103	Cost: 6.04s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 17.8558	Cost: 6.34s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 17.9155	Cost: 5.92s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 17.9345	Cost: 5.75s
Train Epoch: 103 	Average Loss: 17.9608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0043

Saving model as e103_model.pt & e103_waveforms_supplementary.hdf5
Learning rate: 0.0001999476512514112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 18.0057	Cost: 20.02s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 17.9507	Cost: 5.96s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 17.9458	Cost: 6.17s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 17.9940	Cost: 5.82s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 17.9909	Cost: 5.66s
Train Epoch: 104 	Average Loss: 17.9495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9981

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Learning rate: 0.00019994662992734905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 17.9993	Cost: 19.91s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 17.9577	Cost: 6.14s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 18.0067	Cost: 6.35s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 17.8696	Cost: 5.90s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 17.8660	Cost: 5.69s
Train Epoch: 105 	Average Loss: 17.9323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0236

Learning rate: 0.00019994559873894998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 17.9619	Cost: 20.25s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 17.8468	Cost: 5.95s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 17.8551	Cost: 6.47s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 17.8677	Cost: 5.83s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 18.0352	Cost: 5.84s
Train Epoch: 106 	Average Loss: 17.9234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0142

Learning rate: 0.00019994455768631577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 18.0201	Cost: 20.34s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 17.8513	Cost: 5.98s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 17.9243	Cost: 5.89s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 17.9629	Cost: 5.78s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 17.8896	Cost: 5.47s
Train Epoch: 107 	Average Loss: 17.9082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9413

Saving model as e107_model.pt & e107_waveforms_supplementary.hdf5
Learning rate: 0.00019994350676954918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 17.8737	Cost: 19.95s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 17.9537	Cost: 6.05s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 17.9086	Cost: 6.05s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 17.8957	Cost: 5.87s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 17.8682	Cost: 5.70s
Train Epoch: 108 	Average Loss: 17.9048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9162

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Learning rate: 0.00019994244598875392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 18.0353	Cost: 20.04s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 17.8290	Cost: 6.00s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 17.9215	Cost: 6.07s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 17.8372	Cost: 5.83s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 17.8120	Cost: 5.69s
Train Epoch: 109 	Average Loss: 17.8740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8977

Saving model as e109_model.pt & e109_waveforms_supplementary.hdf5
Learning rate: 0.00019994137534403472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 17.8198	Cost: 20.26s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 17.8872	Cost: 5.94s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 17.7591	Cost: 6.01s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 17.8345	Cost: 6.14s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 17.8300	Cost: 5.91s
Train Epoch: 110 	Average Loss: 17.8508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8959

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 0.00019994029483549723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 17.8678	Cost: 20.89s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 17.8614	Cost: 5.98s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 17.6525	Cost: 6.40s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 17.7185	Cost: 5.85s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 17.9198	Cost: 5.80s
Train Epoch: 111 	Average Loss: 17.8336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9041

Learning rate: 0.00019993920446324803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 17.9236	Cost: 20.42s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 17.9051	Cost: 5.76s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 17.8017	Cost: 6.12s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 17.7851	Cost: 5.64s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 17.8888	Cost: 5.63s
Train Epoch: 112 	Average Loss: 17.8333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9377

Learning rate: 0.00019993810422739487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 17.8522	Cost: 20.85s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 17.8834	Cost: 5.99s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 17.7379	Cost: 6.32s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 17.7980	Cost: 5.84s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 17.8447	Cost: 5.90s
Train Epoch: 113 	Average Loss: 17.8228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8748

Saving model as e113_model.pt & e113_waveforms_supplementary.hdf5
Learning rate: 0.00019993699412804622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 17.7479	Cost: 20.27s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 17.7179	Cost: 5.92s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 17.8699	Cost: 6.01s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 17.8594	Cost: 5.82s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 17.8116	Cost: 5.68s
Train Epoch: 114 	Average Loss: 17.7991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8516

Saving model as e114_model.pt & e114_waveforms_supplementary.hdf5
Learning rate: 0.00019993587416531166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 17.7723	Cost: 19.36s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 17.7902	Cost: 6.06s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 17.7742	Cost: 6.10s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 17.8549	Cost: 5.84s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 17.8452	Cost: 5.69s
Train Epoch: 115 	Average Loss: 17.7858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9067

Learning rate: 0.00019993474433930176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 17.8132	Cost: 20.50s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 17.7322	Cost: 6.01s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 17.7649	Cost: 6.08s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 17.7782	Cost: 5.87s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 17.7718	Cost: 5.68s
Train Epoch: 116 	Average Loss: 17.7745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8394

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Learning rate: 0.000199933604650128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 17.8302	Cost: 20.89s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 17.8534	Cost: 6.08s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 17.6568	Cost: 6.08s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 17.7268	Cost: 5.82s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 17.7857	Cost: 5.67s
Train Epoch: 117 	Average Loss: 17.7663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8478

Learning rate: 0.0001999324550979029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 17.7243	Cost: 20.05s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 17.6537	Cost: 5.99s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 17.7380	Cost: 6.02s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 17.8056	Cost: 5.84s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 17.6923	Cost: 5.74s
Train Epoch: 118 	Average Loss: 17.7389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7339

Saving model as e118_model.pt & e118_waveforms_supplementary.hdf5
Learning rate: 0.00019993129568273988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 17.6935	Cost: 20.24s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 17.6856	Cost: 6.01s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 17.8069	Cost: 6.26s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 17.7255	Cost: 5.82s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 17.7949	Cost: 5.70s
Train Epoch: 119 	Average Loss: 17.7390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7852

Learning rate: 0.0001999301264047534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 17.8329	Cost: 19.51s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 17.8060	Cost: 6.05s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 17.6651	Cost: 6.35s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 17.6920	Cost: 5.65s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 17.7615	Cost: 5.88s
Train Epoch: 120 	Average Loss: 17.7248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7828

Learning rate: 0.00019992894726405882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 17.7032	Cost: 20.46s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 17.6362	Cost: 5.93s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 17.6143	Cost: 6.03s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 17.6456	Cost: 5.83s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 17.7572	Cost: 5.72s
Train Epoch: 121 	Average Loss: 17.7122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7599

Learning rate: 0.00019992775826077256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 17.7130	Cost: 20.07s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 17.6833	Cost: 6.05s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 17.7316	Cost: 6.02s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 17.7262	Cost: 5.91s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 17.6898	Cost: 5.74s
Train Epoch: 122 	Average Loss: 17.6981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8183

Learning rate: 0.00019992655939501196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 17.7198	Cost: 20.63s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 17.6981	Cost: 6.06s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 17.6190	Cost: 6.11s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 17.8645	Cost: 5.93s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 17.6691	Cost: 5.73s
Train Epoch: 123 	Average Loss: 17.6913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7732

Learning rate: 0.00019992535066689534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 17.7495	Cost: 22.52s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 17.7350	Cost: 6.72s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 17.7180	Cost: 6.25s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 17.6944	Cost: 5.85s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 17.7220	Cost: 5.87s
Train Epoch: 124 	Average Loss: 17.6930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7204

Saving model as e124_model.pt & e124_waveforms_supplementary.hdf5
Learning rate: 0.00019992413207654198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 17.6430	Cost: 20.90s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 17.6485	Cost: 5.99s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 17.5938	Cost: 5.99s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 17.6399	Cost: 5.85s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 17.6653	Cost: 5.70s
Train Epoch: 125 	Average Loss: 17.6642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7345

Learning rate: 0.0001999229036240722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 17.7583	Cost: 21.10s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 17.6151	Cost: 6.00s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 17.6618	Cost: 6.08s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 17.6581	Cost: 5.85s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 17.7246	Cost: 5.70s
Train Epoch: 126 	Average Loss: 17.6629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7477

Learning rate: 0.0001999216653096072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 17.6770	Cost: 23.98s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 17.7062	Cost: 5.98s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 17.6712	Cost: 6.49s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 17.5929	Cost: 5.66s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 17.6107	Cost: 5.71s
Train Epoch: 127 	Average Loss: 17.6496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7383

Learning rate: 0.00019992041713326917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 17.6211	Cost: 22.97s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 17.6206	Cost: 6.68s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 17.5181	Cost: 6.09s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 17.6041	Cost: 5.86s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 17.6211	Cost: 5.71s
Train Epoch: 128 	Average Loss: 17.6242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6562

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Learning rate: 0.00019991915909518135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 17.6179	Cost: 22.14s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 17.6228	Cost: 5.96s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 17.6556	Cost: 6.00s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 17.7354	Cost: 5.83s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 17.5993	Cost: 5.68s
Train Epoch: 129 	Average Loss: 17.6289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6779

Learning rate: 0.0001999178911954679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 17.5768	Cost: 21.29s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 17.6819	Cost: 6.04s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 17.6432	Cost: 6.04s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 17.6546	Cost: 5.84s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 17.7700	Cost: 5.70s
Train Epoch: 130 	Average Loss: 17.6202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6444

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 0.0001999166134342539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 17.5918	Cost: 18.80s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 17.6022	Cost: 6.10s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 17.5944	Cost: 6.08s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 17.6241	Cost: 5.91s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 17.6565	Cost: 5.70s
Train Epoch: 131 	Average Loss: 17.5998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6708

Learning rate: 0.00019991532581166554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 17.6239	Cost: 20.65s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 17.5262	Cost: 6.72s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 17.6578	Cost: 6.07s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 17.6358	Cost: 5.86s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 17.7423	Cost: 5.70s
Train Epoch: 132 	Average Loss: 17.6062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6580

Learning rate: 0.00019991402832782987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 17.5523	Cost: 18.52s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 17.5834	Cost: 6.10s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 17.6079	Cost: 6.49s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 17.6269	Cost: 5.88s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 17.5211	Cost: 5.75s
Train Epoch: 133 	Average Loss: 17.5834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6527

Learning rate: 0.00019991272098287494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 17.6402	Cost: 19.75s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 17.6766	Cost: 6.09s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 17.4742	Cost: 6.20s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 17.6233	Cost: 5.90s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 17.5100	Cost: 5.72s
Train Epoch: 134 	Average Loss: 17.5882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6458

Learning rate: 0.00019991140377692977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 17.5366	Cost: 19.65s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 17.5269	Cost: 6.07s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 17.5673	Cost: 6.11s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 17.6244	Cost: 5.97s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 17.6269	Cost: 5.71s
Train Epoch: 135 	Average Loss: 17.5612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6816

Learning rate: 0.0001999100767101244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 17.6946	Cost: 19.88s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 17.5452	Cost: 6.04s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 17.5396	Cost: 6.10s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 17.5747	Cost: 5.86s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 17.5951	Cost: 5.72s
Train Epoch: 136 	Average Loss: 17.5709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6126

Saving model as e136_model.pt & e136_waveforms_supplementary.hdf5
Learning rate: 0.00019990873978258976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 17.5397	Cost: 19.89s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 17.5025	Cost: 5.97s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 17.5010	Cost: 6.10s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 17.4836	Cost: 5.92s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 17.6042	Cost: 5.71s
Train Epoch: 137 	Average Loss: 17.5312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5992

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 0.0001999073929944578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 17.5684	Cost: 19.53s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 17.4365	Cost: 5.98s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 17.4768	Cost: 6.17s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 17.6291	Cost: 6.04s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 17.4799	Cost: 6.13s
Train Epoch: 138 	Average Loss: 17.5268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6360

Learning rate: 0.00019990603634586154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 17.5867	Cost: 18.94s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 17.5167	Cost: 6.00s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 17.5442	Cost: 6.00s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 17.4866	Cost: 5.84s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 17.5779	Cost: 5.70s
Train Epoch: 139 	Average Loss: 17.5525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5585

Saving model as e139_model.pt & e139_waveforms_supplementary.hdf5
Learning rate: 0.00019990466983693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 17.4598	Cost: 19.93s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 17.5654	Cost: 5.97s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 17.5121	Cost: 6.15s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 17.5054	Cost: 5.83s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 17.5355	Cost: 5.76s
Train Epoch: 140 	Average Loss: 17.5026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5423

Saving model as e140_model.pt & e140_waveforms_supplementary.hdf5
Learning rate: 0.00019990329346781236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 17.6462	Cost: 20.06s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 17.4970	Cost: 5.88s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 17.4051	Cost: 6.56s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 17.4532	Cost: 5.84s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 17.5793	Cost: 5.84s
Train Epoch: 141 	Average Loss: 17.5039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5494

Learning rate: 0.00019990190723863022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 17.5744	Cost: 20.91s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 17.3773	Cost: 5.94s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 17.4450	Cost: 6.38s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 17.5119	Cost: 5.83s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 17.4273	Cost: 5.77s
Train Epoch: 142 	Average Loss: 17.4968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5614

Learning rate: 0.00019990051114952508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 17.4839	Cost: 19.97s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 17.6104	Cost: 6.13s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 17.4013	Cost: 6.06s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 17.6035	Cost: 5.87s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 17.3940	Cost: 5.83s
Train Epoch: 143 	Average Loss: 17.4888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5987

Learning rate: 0.0001998991052006348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 17.4493	Cost: 20.32s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 17.4711	Cost: 6.00s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 17.4256	Cost: 6.31s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 17.5492	Cost: 5.86s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 17.4491	Cost: 5.70s
Train Epoch: 144 	Average Loss: 17.4687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5457

Learning rate: 0.0001998976893920981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 17.3617	Cost: 19.57s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 17.4397	Cost: 6.05s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 17.5065	Cost: 6.51s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 17.5465	Cost: 5.84s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 17.4810	Cost: 5.76s
Train Epoch: 145 	Average Loss: 17.4643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5432

Learning rate: 0.00019989626372405477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 17.4484	Cost: 20.07s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 17.4653	Cost: 6.10s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 17.3934	Cost: 6.11s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 17.4211	Cost: 5.90s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 17.3659	Cost: 5.72s
Train Epoch: 146 	Average Loss: 17.4498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5722

Learning rate: 0.00019989482819664545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 17.5725	Cost: 19.78s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 17.4376	Cost: 6.00s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 17.3437	Cost: 5.98s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 17.4935	Cost: 5.84s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 17.4263	Cost: 5.71s
Train Epoch: 147 	Average Loss: 17.4604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4794

Saving model as e147_model.pt & e147_waveforms_supplementary.hdf5
Learning rate: 0.00019989338281001189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 17.5399	Cost: 20.11s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 17.3405	Cost: 5.97s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 17.3304	Cost: 6.32s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 17.3283	Cost: 5.85s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 17.3422	Cost: 5.72s
Train Epoch: 148 	Average Loss: 17.4309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5602

Learning rate: 0.00019989192756429667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 17.5436	Cost: 21.82s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 17.4309	Cost: 6.10s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 17.3901	Cost: 6.16s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 17.4644	Cost: 5.89s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 17.5069	Cost: 5.72s
Train Epoch: 149 	Average Loss: 17.4363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4714

Saving model as e149_model.pt & e149_waveforms_supplementary.hdf5
Learning rate: 0.00019989046245964345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 17.5988	Cost: 20.10s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 17.4102	Cost: 6.01s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 17.4047	Cost: 6.11s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 17.4086	Cost: 5.88s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 17.4125	Cost: 5.72s
Train Epoch: 150 	Average Loss: 17.4346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5056

Learning rate: 0.00019988898749619688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 17.4967	Cost: 20.11s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 17.4851	Cost: 5.98s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 17.3768	Cost: 6.01s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 17.3495	Cost: 5.86s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 17.5749	Cost: 5.71s
Train Epoch: 151 	Average Loss: 17.4070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5293

Learning rate: 0.00019988750267410245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 17.3955	Cost: 19.38s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 17.3307	Cost: 5.97s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 17.3619	Cost: 6.03s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 17.4190	Cost: 5.84s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 17.4105	Cost: 5.67s
Train Epoch: 152 	Average Loss: 17.3943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5091

Learning rate: 0.0001998860079935067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 17.5041	Cost: 21.10s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 17.3941	Cost: 5.94s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 17.4271	Cost: 6.15s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 17.3922	Cost: 5.88s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 17.3795	Cost: 5.71s
Train Epoch: 153 	Average Loss: 17.4074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5261

Learning rate: 0.00019988450345455726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 17.4690	Cost: 20.42s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 17.4664	Cost: 6.14s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 17.3805	Cost: 6.01s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 17.4284	Cost: 5.89s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 17.3896	Cost: 5.70s
Train Epoch: 154 	Average Loss: 17.3922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4911

Learning rate: 0.00019988298905740252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 17.4431	Cost: 21.43s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 17.3953	Cost: 5.98s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 17.4484	Cost: 6.02s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 17.3579	Cost: 5.87s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 17.4489	Cost: 5.84s
Train Epoch: 155 	Average Loss: 17.3624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4834

Learning rate: 0.000199881464802192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 17.5423	Cost: 21.32s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 17.3705	Cost: 5.97s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 17.3136	Cost: 5.99s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 17.4117	Cost: 5.82s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 17.3550	Cost: 5.76s
Train Epoch: 156 	Average Loss: 17.3832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4433

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Learning rate: 0.0001998799306890761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 17.3996	Cost: 21.80s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 17.3507	Cost: 5.98s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 17.3372	Cost: 6.09s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 17.3426	Cost: 5.87s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 17.3717	Cost: 5.74s
Train Epoch: 157 	Average Loss: 17.3809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4410

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Learning rate: 0.00019987838671820622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 17.3291	Cost: 20.12s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 17.2911	Cost: 5.97s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 17.4753	Cost: 6.05s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 17.3775	Cost: 5.77s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 17.3907	Cost: 5.50s
Train Epoch: 158 	Average Loss: 17.3529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3965

Saving model as e158_model.pt & e158_waveforms_supplementary.hdf5
Learning rate: 0.00019987683288973478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 17.3343	Cost: 20.21s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 17.2958	Cost: 5.93s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 17.3472	Cost: 6.05s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 17.2557	Cost: 5.84s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 17.3713	Cost: 5.69s
Train Epoch: 159 	Average Loss: 17.3493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4703

Learning rate: 0.00019987526920381513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 17.4663	Cost: 20.40s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 17.3365	Cost: 5.98s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 17.2461	Cost: 6.05s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 17.3362	Cost: 5.83s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 17.4073	Cost: 5.74s
Train Epoch: 160 	Average Loss: 17.3513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4092

Learning rate: 0.00019987369566060162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 17.3806	Cost: 20.63s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 17.3104	Cost: 6.04s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 17.2896	Cost: 6.03s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 17.3303	Cost: 5.92s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 17.3732	Cost: 5.70s
Train Epoch: 161 	Average Loss: 17.3382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4547

Learning rate: 0.0001998721122602495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 17.3208	Cost: 20.87s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 17.3387	Cost: 5.97s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 17.3393	Cost: 6.04s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 17.3359	Cost: 5.88s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 17.3676	Cost: 5.72s
Train Epoch: 162 	Average Loss: 17.3345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4429

Learning rate: 0.00019987051900291508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 17.2602	Cost: 24.80s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 17.3406	Cost: 5.98s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 17.3084	Cost: 6.04s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 17.3219	Cost: 5.98s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 17.2577	Cost: 5.72s
Train Epoch: 163 	Average Loss: 17.3219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4023

Learning rate: 0.00019986891588875562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 17.5051	Cost: 21.69s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 17.3200	Cost: 5.99s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 17.2115	Cost: 6.07s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 17.2916	Cost: 5.84s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 17.3346	Cost: 5.71s
Train Epoch: 164 	Average Loss: 17.2942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3514

Saving model as e164_model.pt & e164_waveforms_supplementary.hdf5
Learning rate: 0.0001998673029179293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 17.3141	Cost: 22.71s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 17.3392	Cost: 5.99s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 17.2356	Cost: 6.25s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 17.3060	Cost: 5.83s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 17.2860	Cost: 5.91s
Train Epoch: 165 	Average Loss: 17.3016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4294

Learning rate: 0.00019986568009059536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 17.2977	Cost: 22.55s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 17.3066	Cost: 5.99s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 17.2460	Cost: 6.34s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 17.2267	Cost: 5.89s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 17.3247	Cost: 5.71s
Train Epoch: 166 	Average Loss: 17.2967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3815

Learning rate: 0.00019986404740691393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 17.3912	Cost: 22.21s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 17.4319	Cost: 6.02s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 17.1982	Cost: 6.67s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 17.2888	Cost: 5.86s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 17.3490	Cost: 5.70s
Train Epoch: 167 	Average Loss: 17.2838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3757

Learning rate: 0.00019986240486704617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 17.3554	Cost: 20.66s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 17.3866	Cost: 6.09s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 17.1316	Cost: 6.05s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 17.2903	Cost: 5.85s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 17.2982	Cost: 5.73s
Train Epoch: 168 	Average Loss: 17.2928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3546

Learning rate: 0.00019986075247115415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 17.4109	Cost: 22.15s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 17.3005	Cost: 6.53s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 17.2618	Cost: 6.13s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 17.1287	Cost: 5.85s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 17.2442	Cost: 5.84s
Train Epoch: 169 	Average Loss: 17.2639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3975

Learning rate: 0.00019985909021940103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 17.3888	Cost: 19.41s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 17.3219	Cost: 6.42s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 17.3092	Cost: 6.09s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 17.2648	Cost: 5.85s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 17.2526	Cost: 5.70s
Train Epoch: 170 	Average Loss: 17.2813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3489

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 0.0001998574181119508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 17.2702	Cost: 19.13s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 17.2741	Cost: 6.07s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 17.1541	Cost: 6.26s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 17.3446	Cost: 5.87s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 17.2375	Cost: 5.81s
Train Epoch: 171 	Average Loss: 17.2596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3443

Saving model as e171_model.pt & e171_waveforms_supplementary.hdf5
Learning rate: 0.00019985573614896853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 17.3637	Cost: 19.48s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 17.3516	Cost: 7.31s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 17.1973	Cost: 6.65s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 17.2488	Cost: 5.91s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 17.1463	Cost: 5.79s
Train Epoch: 172 	Average Loss: 17.2734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3428

Saving model as e172_model.pt & e172_waveforms_supplementary.hdf5
Learning rate: 0.00019985404433062024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 17.4832	Cost: 19.91s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 17.2279	Cost: 6.44s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 17.2265	Cost: 6.10s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 17.1807	Cost: 5.90s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 17.2894	Cost: 5.78s
Train Epoch: 173 	Average Loss: 17.2650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3410

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 0.00019985234265707287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 17.3126	Cost: 19.59s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 17.2144	Cost: 6.13s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 17.2210	Cost: 6.07s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 17.1453	Cost: 5.88s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 17.2919	Cost: 5.70s
Train Epoch: 174 	Average Loss: 17.2463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3645

Learning rate: 0.00019985063112849436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 17.2824	Cost: 20.72s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 17.1622	Cost: 6.42s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 17.2285	Cost: 6.24s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 17.1539	Cost: 6.00s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 17.2868	Cost: 5.70s
Train Epoch: 175 	Average Loss: 17.2206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3109

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 17.3060	Cost: 20.00s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 17.2247	Cost: 6.11s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 17.2419	Cost: 6.08s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 17.2079	Cost: 5.84s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 17.1811	Cost: 5.78s
Train Epoch: 176 	Average Loss: 17.2336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2792

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Learning rate: 0.00019984717850692066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 17.2673	Cost: 20.47s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 17.2513	Cost: 6.19s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 17.2377	Cost: 6.09s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 17.1996	Cost: 5.88s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 17.2434	Cost: 5.75s
Train Epoch: 177 	Average Loss: 17.2232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3232

Learning rate: 0.00019984543741426617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 17.3471	Cost: 21.33s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 17.2103	Cost: 6.04s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 17.2547	Cost: 6.07s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 17.2186	Cost: 5.83s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 17.2361	Cost: 5.70s
Train Epoch: 178 	Average Loss: 17.2295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3270

Learning rate: 0.0001998436864672621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 17.3400	Cost: 18.73s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 17.2276	Cost: 6.30s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 17.2676	Cost: 6.15s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 17.3044	Cost: 5.88s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 17.2487	Cost: 5.80s
Train Epoch: 179 	Average Loss: 17.2085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3247

Learning rate: 0.00019984192566608125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 17.2642	Cost: 19.49s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 17.3139	Cost: 6.07s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 17.1958	Cost: 6.08s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 17.2122	Cost: 6.05s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 17.1958	Cost: 5.76s
Train Epoch: 180 	Average Loss: 17.2046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2927

Learning rate: 0.00019984015501089739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 17.2164	Cost: 19.41s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 17.1920	Cost: 6.09s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 17.2213	Cost: 6.03s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 17.2332	Cost: 6.02s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 17.1977	Cost: 5.74s
Train Epoch: 181 	Average Loss: 17.2063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3323

Learning rate: 0.00019983837450188524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 17.2301	Cost: 20.65s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 17.1747	Cost: 5.93s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 17.1451	Cost: 6.26s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 17.0818	Cost: 5.83s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 17.2233	Cost: 6.02s
Train Epoch: 182 	Average Loss: 17.1841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3026

Learning rate: 0.0001998365841392206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 17.2614	Cost: 19.32s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 17.1172	Cost: 5.94s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 17.1543	Cost: 6.01s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 17.0910	Cost: 5.83s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 17.2167	Cost: 5.81s
Train Epoch: 183 	Average Loss: 17.1810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2664

Saving model as e183_model.pt & e183_waveforms_supplementary.hdf5
Learning rate: 0.00019983478392308012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 17.3562	Cost: 20.32s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 17.1090	Cost: 5.96s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 17.1938	Cost: 6.00s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 17.2452	Cost: 5.83s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 17.3183	Cost: 5.75s
Train Epoch: 184 	Average Loss: 17.1780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2501

Saving model as e184_model.pt & e184_waveforms_supplementary.hdf5
Learning rate: 0.0001998329738536415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 17.2334	Cost: 20.44s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 17.1695	Cost: 6.04s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 17.2325	Cost: 6.14s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 17.1597	Cost: 5.82s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 17.1976	Cost: 5.69s
Train Epoch: 185 	Average Loss: 17.1951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2817

Learning rate: 0.00019983115393108338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 17.2328	Cost: 20.05s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 17.2053	Cost: 5.95s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 17.1413	Cost: 6.01s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 17.2437	Cost: 5.86s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 17.1786	Cost: 5.70s
Train Epoch: 186 	Average Loss: 17.1701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2534

Learning rate: 0.0001998293241555854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 17.1884	Cost: 19.95s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 17.1396	Cost: 6.05s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 17.1451	Cost: 6.62s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 17.1734	Cost: 5.93s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 17.2880	Cost: 5.72s
Train Epoch: 187 	Average Loss: 17.1711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2152

Saving model as e187_model.pt & e187_waveforms_supplementary.hdf5
Learning rate: 0.0001998274845273281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 17.2817	Cost: 20.07s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 17.1364	Cost: 6.11s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 17.1052	Cost: 6.06s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 17.1376	Cost: 5.84s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 17.1047	Cost: 5.71s
Train Epoch: 188 	Average Loss: 17.1316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2785

Learning rate: 0.00019982563504649309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 17.0303	Cost: 20.10s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 17.2091	Cost: 6.17s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 17.1272	Cost: 6.07s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 17.0919	Cost: 5.82s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 17.1396	Cost: 5.69s
Train Epoch: 189 	Average Loss: 17.1355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2844

Learning rate: 0.00019982377571326284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 17.2700	Cost: 20.16s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 17.1490	Cost: 6.07s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 17.1552	Cost: 6.01s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 17.0048	Cost: 5.83s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 17.1311	Cost: 5.69s
Train Epoch: 190 	Average Loss: 17.1586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2600

Learning rate: 0.00019982190652782097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 17.1934	Cost: 20.39s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 17.1212	Cost: 6.06s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 17.1990	Cost: 6.22s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 17.2191	Cost: 5.99s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 17.2015	Cost: 5.68s
Train Epoch: 191 	Average Loss: 17.1430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2090

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Learning rate: 0.0001998200274903519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 17.2710	Cost: 20.39s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 17.1265	Cost: 6.07s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 17.1741	Cost: 6.33s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 17.2121	Cost: 5.84s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 17.1204	Cost: 5.71s
Train Epoch: 192 	Average Loss: 17.1438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2215

Learning rate: 0.00019981813860104106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 17.1940	Cost: 19.30s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 17.0917	Cost: 6.06s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 17.0760	Cost: 6.06s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 17.1008	Cost: 5.89s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 17.1906	Cost: 5.67s
Train Epoch: 193 	Average Loss: 17.1283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2148

Learning rate: 0.0001998162398600749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 17.1741	Cost: 20.42s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 17.0626	Cost: 6.02s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 17.0567	Cost: 6.22s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 17.0859	Cost: 5.84s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 17.0284	Cost: 5.69s
Train Epoch: 194 	Average Loss: 17.0991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2243

Learning rate: 0.00019981433126764085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 17.0904	Cost: 20.89s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 17.1909	Cost: 5.98s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 17.1328	Cost: 6.67s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 17.1427	Cost: 5.82s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 17.0144	Cost: 5.79s
Train Epoch: 195 	Average Loss: 17.1077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2135

Learning rate: 0.00019981241282392723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 17.1714	Cost: 20.80s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 17.1385	Cost: 5.98s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 17.0318	Cost: 6.03s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 17.0815	Cost: 5.88s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 17.2264	Cost: 5.69s
Train Epoch: 196 	Average Loss: 17.1070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2144

Learning rate: 0.0001998104845291234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 17.2346	Cost: 23.21s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 17.0343	Cost: 5.99s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 17.0046	Cost: 6.10s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 17.0291	Cost: 6.07s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 17.1094	Cost: 5.72s
Train Epoch: 197 	Average Loss: 17.0813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2096

Learning rate: 0.00019980854638341968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 17.0996	Cost: 21.25s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 16.9709	Cost: 6.04s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 17.0775	Cost: 6.03s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 17.0594	Cost: 5.96s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 17.0662	Cost: 5.80s
Train Epoch: 198 	Average Loss: 17.0935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1887

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 0.00019980659838700736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 17.1857	Cost: 21.67s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 17.0447	Cost: 6.06s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 17.0743	Cost: 6.00s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 17.0856	Cost: 5.83s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 17.1256	Cost: 5.78s
Train Epoch: 199 	Average Loss: 17.0990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1973

Learning rate: 0.0001998046405400787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 17.1821	Cost: 22.84s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 17.2033	Cost: 5.97s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 17.2193	Cost: 6.06s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 17.1773	Cost: 5.87s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 17.0793	Cost: 5.67s
Train Epoch: 200 	Average Loss: 17.1061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1637

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 17.1213	Cost: 22.45s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 17.0586	Cost: 6.00s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 17.0354	Cost: 6.05s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 17.1008	Cost: 5.86s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 17.0584	Cost: 5.72s
Train Epoch: 201 	Average Loss: 17.0833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1629

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 0.00019980069529544622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 17.1783	Cost: 23.30s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 17.0647	Cost: 5.98s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 17.0696	Cost: 6.05s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 17.1007	Cost: 5.87s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 16.9941	Cost: 5.72s
Train Epoch: 202 	Average Loss: 17.0691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2358

Learning rate: 0.0001997987078981318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 17.1429	Cost: 25.96s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 17.0115	Cost: 6.08s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 17.0655	Cost: 6.07s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 16.9760	Cost: 5.92s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 17.0577	Cost: 5.70s
Train Epoch: 203 	Average Loss: 17.0604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1975

Learning rate: 0.00019979671065107978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 17.2231	Cost: 21.84s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 17.1031	Cost: 6.17s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 17.0382	Cost: 6.02s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 17.0127	Cost: 5.91s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 17.0792	Cost: 5.70s
Train Epoch: 204 	Average Loss: 17.0474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1517

Saving model as e204_model.pt & e204_waveforms_supplementary.hdf5
Learning rate: 0.0001997947035544873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 17.1099	Cost: 22.51s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 16.9451	Cost: 6.51s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 16.8795	Cost: 6.04s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 17.1255	Cost: 5.91s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 17.0805	Cost: 5.72s
Train Epoch: 205 	Average Loss: 17.0560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1400

Saving model as e205_model.pt & e205_waveforms_supplementary.hdf5
Learning rate: 0.00019979268660855247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 17.1859	Cost: 21.08s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 17.0676	Cost: 6.11s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 17.0603	Cost: 6.05s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 17.0650	Cost: 5.88s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 16.9743	Cost: 5.75s
Train Epoch: 206 	Average Loss: 17.0516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2324

Learning rate: 0.00019979065981347432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 17.1692	Cost: 21.12s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 17.0763	Cost: 6.06s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 17.0160	Cost: 6.08s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 17.1675	Cost: 5.85s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 17.0293	Cost: 5.72s
Train Epoch: 207 	Average Loss: 17.0311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1728

Learning rate: 0.0001997886231694529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 17.0562	Cost: 19.70s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 17.1105	Cost: 6.90s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 17.0380	Cost: 6.06s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 16.9773	Cost: 5.92s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 17.1207	Cost: 5.75s
Train Epoch: 208 	Average Loss: 17.0391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1541

Learning rate: 0.0001997865766766892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 17.0691	Cost: 20.18s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 16.9550	Cost: 6.51s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 17.0285	Cost: 6.25s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 17.0193	Cost: 5.87s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 17.0036	Cost: 5.72s
Train Epoch: 209 	Average Loss: 17.0348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1749

Learning rate: 0.00019978452033538524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 17.1555	Cost: 19.34s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 17.1379	Cost: 6.40s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 17.0732	Cost: 7.07s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 17.1292	Cost: 5.86s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 17.0630	Cost: 5.71s
Train Epoch: 210 	Average Loss: 17.0343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1329

Saving model as e210_model.pt & e210_waveforms_supplementary.hdf5
Learning rate: 0.00019978245414574395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 16.9856	Cost: 18.30s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 17.0202	Cost: 6.49s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 17.1521	Cost: 6.50s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 16.8855	Cost: 5.84s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 16.9614	Cost: 5.69s
Train Epoch: 211 	Average Loss: 17.0129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1614

Learning rate: 0.00019978037810796924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 17.0960	Cost: 18.00s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 16.9218	Cost: 6.06s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 16.9832	Cost: 6.17s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 16.9942	Cost: 5.93s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 16.9577	Cost: 5.71s
Train Epoch: 212 	Average Loss: 17.0065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1199

Saving model as e212_model.pt & e212_waveforms_supplementary.hdf5
Learning rate: 0.000199778292222266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 16.9843	Cost: 18.76s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 17.0272	Cost: 6.00s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 17.0247	Cost: 6.01s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 17.0020	Cost: 6.02s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 17.1079	Cost: 6.75s
Train Epoch: 213 	Average Loss: 17.0306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1347

Learning rate: 0.00019977619648884015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 17.1024	Cost: 20.23s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 16.9934	Cost: 5.94s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 16.9151	Cost: 6.00s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 17.0836	Cost: 5.94s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 17.0395	Cost: 5.72s
Train Epoch: 214 	Average Loss: 16.9991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1563

Learning rate: 0.0001997740909078985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 16.9323	Cost: 20.24s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 17.1096	Cost: 5.97s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 16.9720	Cost: 5.98s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 16.9042	Cost: 5.85s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 16.9002	Cost: 5.70s
Train Epoch: 215 	Average Loss: 16.9957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1394

Learning rate: 0.0001997719754796489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 17.0446	Cost: 19.71s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 17.0931	Cost: 6.02s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 16.9131	Cost: 6.07s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 16.9494	Cost: 5.86s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 16.9423	Cost: 5.69s
Train Epoch: 216 	Average Loss: 16.9930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1588

Learning rate: 0.00019976985020430003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 17.1792	Cost: 20.40s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 17.0209	Cost: 6.04s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 16.9871	Cost: 6.05s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 16.9961	Cost: 5.86s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 17.0432	Cost: 5.70s
Train Epoch: 217 	Average Loss: 17.0072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1155

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 0.00019976771508206176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 17.1730	Cost: 19.75s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 17.0291	Cost: 6.10s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 16.9179	Cost: 6.34s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 17.0391	Cost: 5.86s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 16.8784	Cost: 5.72s
Train Epoch: 218 	Average Loss: 16.9731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1435

Learning rate: 0.00019976557011314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 17.1607	Cost: 20.09s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 16.9349	Cost: 6.02s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 16.9802	Cost: 6.03s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 17.0912	Cost: 5.84s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 16.9406	Cost: 5.73s
Train Epoch: 219 	Average Loss: 16.9712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0717

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 0.00019976341529776072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 16.9720	Cost: 20.04s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 16.9086	Cost: 6.04s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 16.9012	Cost: 6.04s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 16.9691	Cost: 5.84s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 16.9426	Cost: 5.75s
Train Epoch: 220 	Average Loss: 16.9889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0704

Saving model as e220_model.pt & e220_waveforms_supplementary.hdf5
Learning rate: 0.00019976125063612233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 17.0484	Cost: 20.03s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 16.9657	Cost: 5.93s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 16.9005	Cost: 6.47s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 17.0994	Cost: 5.82s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 17.0190	Cost: 5.91s
Train Epoch: 221 	Average Loss: 16.9857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0810

Learning rate: 0.00019975907612844327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 16.9887	Cost: 19.41s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 16.9711	Cost: 6.14s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 16.9411	Cost: 5.99s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 16.9206	Cost: 5.83s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 17.0159	Cost: 5.69s
Train Epoch: 222 	Average Loss: 16.9499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0858

Learning rate: 0.00019975689177493812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 17.0958	Cost: 19.03s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 16.9479	Cost: 6.00s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 16.9110	Cost: 6.29s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 16.8964	Cost: 5.87s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 16.8667	Cost: 5.68s
Train Epoch: 223 	Average Loss: 16.9465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0576

Saving model as e223_model.pt & e223_waveforms_supplementary.hdf5
Learning rate: 0.00019975469757582245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 17.0350	Cost: 20.33s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 16.9838	Cost: 6.07s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 16.9175	Cost: 6.12s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 17.0594	Cost: 5.85s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 16.8321	Cost: 5.69s
Train Epoch: 224 	Average Loss: 16.9560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9950

Saving model as e224_model.pt & e224_waveforms_supplementary.hdf5
Learning rate: 0.00019975249353131286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 16.9281	Cost: 19.56s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 16.9704	Cost: 5.97s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 17.0558	Cost: 5.97s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 16.9081	Cost: 5.85s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 17.0094	Cost: 5.67s
Train Epoch: 225 	Average Loss: 16.9554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0881

Learning rate: 0.00019975027964162683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 17.0844	Cost: 19.56s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 16.9268	Cost: 6.04s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 16.8968	Cost: 6.11s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 16.9208	Cost: 5.87s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 17.0079	Cost: 5.71s
Train Epoch: 226 	Average Loss: 16.9498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1503

Learning rate: 0.0001997480559069829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 17.0582	Cost: 20.18s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 16.9623	Cost: 5.98s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 16.7985	Cost: 6.02s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 16.9789	Cost: 5.86s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 16.9628	Cost: 5.76s
Train Epoch: 227 	Average Loss: 16.9333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0950

Learning rate: 0.00019974582232760058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 16.9238	Cost: 20.15s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 17.0164	Cost: 6.00s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 16.9137	Cost: 6.21s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 16.9965	Cost: 5.62s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 16.9403	Cost: 5.54s
Train Epoch: 228 	Average Loss: 16.9236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1620

Learning rate: 0.0001997435789037002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 16.9636	Cost: 20.55s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 16.8673	Cost: 5.91s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 16.9288	Cost: 6.29s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 16.8519	Cost: 5.98s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 16.7663	Cost: 5.69s
Train Epoch: 229 	Average Loss: 16.9086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1203

Learning rate: 0.0001997413256355033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 16.9488	Cost: 20.81s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 16.8777	Cost: 5.90s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 16.9238	Cost: 6.09s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 16.9606	Cost: 5.85s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 16.8344	Cost: 5.69s
Train Epoch: 230 	Average Loss: 16.9125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1216

Learning rate: 0.0001997390625232322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 17.1184	Cost: 20.13s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 16.9291	Cost: 5.75s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 16.9050	Cost: 5.97s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 16.9669	Cost: 5.83s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 16.9326	Cost: 5.71s
Train Epoch: 231 	Average Loss: 16.9105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0549

Learning rate: 0.00019973678956711026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 17.0039	Cost: 21.90s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 16.8540	Cost: 6.06s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 16.8768	Cost: 6.08s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 16.9397	Cost: 5.91s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 16.9277	Cost: 5.89s
Train Epoch: 232 	Average Loss: 16.9037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0694

Learning rate: 0.00019973450676736185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 16.9958	Cost: 23.11s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 16.9471	Cost: 6.05s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 16.8910	Cost: 6.05s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 16.8248	Cost: 5.84s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 16.9776	Cost: 5.66s
Train Epoch: 233 	Average Loss: 16.8964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0331

Learning rate: 0.00019973221412421225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 16.8959	Cost: 22.80s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 16.9633	Cost: 5.97s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 16.8785	Cost: 5.86s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 16.9928	Cost: 5.69s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 16.9733	Cost: 5.51s
Train Epoch: 234 	Average Loss: 16.9064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0215

Learning rate: 0.0001997299116378877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 17.0353	Cost: 21.74s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 16.8437	Cost: 6.28s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 16.7533	Cost: 6.04s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 16.9016	Cost: 5.87s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 16.8207	Cost: 5.68s
Train Epoch: 235 	Average Loss: 16.8898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0741

Learning rate: 0.0001997275993086155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 16.9353	Cost: 21.77s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 16.9213	Cost: 6.31s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 16.8438	Cost: 6.05s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 16.7683	Cost: 5.85s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 16.8946	Cost: 5.70s
Train Epoch: 236 	Average Loss: 16.8790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0509

Learning rate: 0.0001997252771366239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 16.9664	Cost: 19.25s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 16.8473	Cost: 6.60s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 16.8390	Cost: 6.06s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 16.9006	Cost: 5.85s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 16.9209	Cost: 5.70s
Train Epoch: 237 	Average Loss: 16.8862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0837

Learning rate: 0.000199722945122142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 17.0546	Cost: 18.19s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 16.8575	Cost: 6.93s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 16.7082	Cost: 6.73s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 16.9381	Cost: 5.99s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 16.9901	Cost: 5.70s
Train Epoch: 238 	Average Loss: 16.8721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0697

Learning rate: 0.0001997206032654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 17.0527	Cost: 19.38s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 16.9734	Cost: 6.14s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 16.7881	Cost: 6.70s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 16.8524	Cost: 5.84s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 16.7920	Cost: 5.99s
Train Epoch: 239 	Average Loss: 16.8788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9803

Saving model as e239_model.pt & e239_waveforms_supplementary.hdf5
Learning rate: 0.00019971825156662903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 16.8672	Cost: 20.75s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 16.8864	Cost: 6.06s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 16.7369	Cost: 6.04s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 16.8582	Cost: 5.90s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 16.8517	Cost: 5.71s
Train Epoch: 240 	Average Loss: 16.8497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0573

Learning rate: 0.00019971589002606117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 17.0730	Cost: 18.91s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 16.8350	Cost: 6.01s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 16.8082	Cost: 6.37s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 16.8887	Cost: 5.87s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 16.8124	Cost: 5.72s
Train Epoch: 241 	Average Loss: 16.8464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9914

Learning rate: 0.00019971351864392958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 16.9607	Cost: 20.25s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 16.8864	Cost: 6.05s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 16.7878	Cost: 6.58s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 16.8472	Cost: 5.89s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 16.8965	Cost: 5.70s
Train Epoch: 242 	Average Loss: 16.8594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9970

Learning rate: 0.00019971113742046817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 17.0553	Cost: 19.02s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 16.8404	Cost: 6.07s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 16.7888	Cost: 6.26s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 16.8568	Cost: 6.14s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 16.7823	Cost: 5.74s
Train Epoch: 243 	Average Loss: 16.8368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0000

Learning rate: 0.00019970874635591207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 16.9311	Cost: 20.86s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 16.8932	Cost: 5.94s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 16.7731	Cost: 6.12s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 16.9542	Cost: 5.96s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 16.8120	Cost: 6.28s
Train Epoch: 244 	Average Loss: 16.8457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0232

Learning rate: 0.00019970634545049727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 17.0436	Cost: 19.78s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 16.8356	Cost: 5.91s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 16.8090	Cost: 6.10s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 16.8078	Cost: 5.84s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 16.8430	Cost: 5.99s
Train Epoch: 245 	Average Loss: 16.8331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9387

Saving model as e245_model.pt & e245_waveforms_supplementary.hdf5
Learning rate: 0.0001997039347044607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 17.0315	Cost: 19.52s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 16.8367	Cost: 5.98s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 16.7254	Cost: 6.01s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 16.8503	Cost: 6.03s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 16.8067	Cost: 5.92s
Train Epoch: 246 	Average Loss: 16.8361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0242

Learning rate: 0.00019970151411804023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 17.0163	Cost: 20.34s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 16.8326	Cost: 5.94s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 16.8654	Cost: 6.14s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 16.9491	Cost: 5.83s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 16.8839	Cost: 5.93s
Train Epoch: 247 	Average Loss: 16.8300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9593

Learning rate: 0.00019969908369147485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 16.9633	Cost: 20.31s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 16.9053	Cost: 6.02s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 16.8239	Cost: 5.94s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 16.8041	Cost: 5.66s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 16.8077	Cost: 5.50s
Train Epoch: 248 	Average Loss: 16.8210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9819

Learning rate: 0.00019969664342500438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 16.9818	Cost: 19.88s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 16.8663	Cost: 6.02s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 16.6265	Cost: 6.38s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 16.7665	Cost: 5.85s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 16.7093	Cost: 5.85s
Train Epoch: 249 	Average Loss: 16.8204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9706

Learning rate: 0.00019969419331886966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 17.0375	Cost: 19.72s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 16.7949	Cost: 6.05s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 16.6536	Cost: 6.09s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 16.8005	Cost: 5.85s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 16.8894	Cost: 5.67s
Train Epoch: 250 	Average Loss: 16.8090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9579

Learning rate: 0.0001996917333733126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 17.0184	Cost: 20.67s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 16.7744	Cost: 6.07s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 16.7689	Cost: 6.19s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 16.8085	Cost: 5.85s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 16.7452	Cost: 5.71s
Train Epoch: 251 	Average Loss: 16.8123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0441

Learning rate: 0.00019968926358857587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 16.8826	Cost: 21.14s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 16.7978	Cost: 6.15s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 16.7918	Cost: 6.38s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 16.8162	Cost: 5.87s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 16.8940	Cost: 5.71s
Train Epoch: 252 	Average Loss: 16.8243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9822

Learning rate: 0.00019968678396490325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 17.0541	Cost: 20.65s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 16.8614	Cost: 6.04s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 16.7745	Cost: 6.10s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 16.8853	Cost: 5.90s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 16.8287	Cost: 5.75s
Train Epoch: 253 	Average Loss: 16.8004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9326

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 0.00019968429450253954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 16.9134	Cost: 19.58s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 16.8379	Cost: 6.00s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 16.7914	Cost: 6.11s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 16.7316	Cost: 5.93s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 16.7288	Cost: 5.78s
Train Epoch: 254 	Average Loss: 16.7985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9769

Learning rate: 0.0001996817952017304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 16.9836	Cost: 20.40s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 16.8488	Cost: 6.00s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 16.6858	Cost: 6.07s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 16.7828	Cost: 5.90s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 16.7497	Cost: 5.72s
Train Epoch: 255 	Average Loss: 16.7932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0058

Learning rate: 0.00019967928606272244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 16.9511	Cost: 23.78s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 16.8437	Cost: 5.97s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 16.7543	Cost: 6.55s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 16.8317	Cost: 5.97s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 16.7666	Cost: 5.78s
Train Epoch: 256 	Average Loss: 16.7957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9230

Saving model as e256_model.pt & e256_waveforms_supplementary.hdf5
Learning rate: 0.0001996767670857634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 16.9311	Cost: 22.69s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 16.7684	Cost: 5.99s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 16.6858	Cost: 6.05s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 16.7846	Cost: 5.84s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 16.6496	Cost: 5.77s
Train Epoch: 257 	Average Loss: 16.7801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9692

Learning rate: 0.00019967423827110182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 16.9789	Cost: 22.54s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 16.7277	Cost: 6.06s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 16.7229	Cost: 6.09s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 16.6975	Cost: 5.89s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 16.7008	Cost: 5.70s
Train Epoch: 258 	Average Loss: 16.7767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9963

Learning rate: 0.00019967169961898734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 17.0277	Cost: 22.19s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 16.7998	Cost: 5.99s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 16.7816	Cost: 6.07s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 16.7733	Cost: 5.91s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 16.8734	Cost: 5.75s
Train Epoch: 259 	Average Loss: 16.7690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0120

Learning rate: 0.00019966915112967047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 17.0249	Cost: 21.10s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 16.8706	Cost: 6.09s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 16.7463	Cost: 6.22s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 16.7229	Cost: 5.85s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 16.6962	Cost: 5.70s
Train Epoch: 260 	Average Loss: 16.7670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9422

Learning rate: 0.00019966659280340273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 16.9685	Cost: 20.42s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 16.8263	Cost: 6.05s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 16.6767	Cost: 6.11s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 16.6924	Cost: 5.86s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 16.6576	Cost: 5.71s
Train Epoch: 261 	Average Loss: 16.7542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0089

Learning rate: 0.00019966402464043667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 16.9301	Cost: 22.19s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 16.6641	Cost: 6.05s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 16.6001	Cost: 6.09s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 16.7081	Cost: 5.92s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 16.7437	Cost: 5.78s
Train Epoch: 262 	Average Loss: 16.7432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9837

Learning rate: 0.00019966144664102572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 16.8990	Cost: 20.46s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 16.7354	Cost: 6.06s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 16.7754	Cost: 6.06s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 16.6718	Cost: 5.89s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 16.7846	Cost: 5.70s
Train Epoch: 263 	Average Loss: 16.7501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9359

Learning rate: 0.00019965885880542434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 16.7537	Cost: 20.24s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 16.7557	Cost: 6.42s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 16.7002	Cost: 6.04s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 16.7947	Cost: 5.99s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 16.8196	Cost: 5.72s
Train Epoch: 264 	Average Loss: 16.7368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9899

Learning rate: 0.00019965626113388794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 16.8766	Cost: 20.52s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 16.8293	Cost: 5.93s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 16.7867	Cost: 6.56s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 16.6750	Cost: 5.99s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 16.7227	Cost: 5.70s
Train Epoch: 265 	Average Loss: 16.7458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9852

Learning rate: 0.00019965365362667288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 16.9042	Cost: 19.96s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 16.7661	Cost: 6.04s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 16.7238	Cost: 6.19s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 16.6423	Cost: 5.94s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 16.7265	Cost: 5.73s
Train Epoch: 266 	Average Loss: 16.7498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9886

Learning rate: 0.0001996510362840365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 16.9485	Cost: 19.52s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 16.6728	Cost: 5.80s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 16.6998	Cost: 6.31s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 16.7422	Cost: 6.08s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 16.7506	Cost: 6.47s
Train Epoch: 267 	Average Loss: 16.7081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9465

Learning rate: 0.00019964840910623716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 16.7944	Cost: 20.14s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 16.7906	Cost: 6.00s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 16.8661	Cost: 6.30s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 16.7033	Cost: 5.90s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 16.7511	Cost: 6.01s
Train Epoch: 268 	Average Loss: 16.7282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9754

Learning rate: 0.00019964577209353413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 16.9631	Cost: 20.15s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 16.7597	Cost: 6.01s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 16.6613	Cost: 6.07s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 16.6316	Cost: 5.85s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 16.6923	Cost: 5.80s
Train Epoch: 269 	Average Loss: 16.7195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9422

Learning rate: 0.00019964312524618766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 17.0257	Cost: 20.01s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 16.6865	Cost: 5.99s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 16.6337	Cost: 5.99s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 16.6002	Cost: 5.85s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 16.6235	Cost: 5.77s
Train Epoch: 270 	Average Loss: 16.6963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9353

Learning rate: 0.000199640468564459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 16.9940	Cost: 19.06s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 16.8176	Cost: 6.01s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 16.6588	Cost: 6.06s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 16.7491	Cost: 5.85s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 16.6696	Cost: 5.79s
Train Epoch: 271 	Average Loss: 16.7042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9977

Learning rate: 0.00019963780204861037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 16.9654	Cost: 18.63s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 16.7374	Cost: 6.14s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 16.6013	Cost: 7.10s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 16.6352	Cost: 5.94s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 16.6316	Cost: 5.74s
Train Epoch: 272 	Average Loss: 16.7174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9139

Saving model as e272_model.pt & e272_waveforms_supplementary.hdf5
Learning rate: 0.0001996351256989049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 16.9670	Cost: 20.57s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 16.7371	Cost: 6.03s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 16.7261	Cost: 6.08s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 16.7580	Cost: 5.89s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 16.5247	Cost: 5.78s
Train Epoch: 273 	Average Loss: 16.7057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9293

Learning rate: 0.0001996324395156068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 16.8833	Cost: 19.91s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 16.6895	Cost: 6.09s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 16.6643	Cost: 6.12s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 16.7295	Cost: 6.04s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 16.6784	Cost: 5.74s
Train Epoch: 274 	Average Loss: 16.6961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9336

Learning rate: 0.00019962974349898107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 16.8600	Cost: 19.99s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 16.6343	Cost: 5.97s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 16.6489	Cost: 6.60s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 16.6873	Cost: 5.88s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 16.6788	Cost: 5.88s
Train Epoch: 275 	Average Loss: 16.7107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9590

Learning rate: 0.0001996270376492939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 16.8745	Cost: 19.80s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 16.8335	Cost: 6.14s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 16.6247	Cost: 6.08s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 16.6686	Cost: 5.90s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 16.6726	Cost: 5.75s
Train Epoch: 276 	Average Loss: 16.6721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9493

Learning rate: 0.00019962432196681234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 16.8705	Cost: 20.67s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 16.7039	Cost: 5.94s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 16.5709	Cost: 6.16s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 16.6474	Cost: 5.92s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 16.7645	Cost: 5.81s
Train Epoch: 277 	Average Loss: 16.6616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9466

Learning rate: 0.00019962159645180437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 16.8721	Cost: 22.03s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 16.7146	Cost: 5.92s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 16.4838	Cost: 5.97s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 16.6176	Cost: 5.96s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 16.7105	Cost: 5.79s
Train Epoch: 278 	Average Loss: 16.6569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9306

Learning rate: 0.00019961886110453903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 16.8984	Cost: 22.03s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 16.4775	Cost: 5.92s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 16.5209	Cost: 5.92s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 16.6595	Cost: 5.95s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 16.6558	Cost: 5.81s
Train Epoch: 279 	Average Loss: 16.6560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9468

Learning rate: 0.00019961611592528625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 16.9536	Cost: 22.74s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 16.6713	Cost: 6.04s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 16.6483	Cost: 5.93s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 16.6190	Cost: 5.94s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 16.6551	Cost: 6.03s
Train Epoch: 280 	Average Loss: 16.6622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9465

Learning rate: 0.000199613360914317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 16.7791	Cost: 22.42s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 16.6870	Cost: 6.02s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 16.5151	Cost: 6.00s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 16.6124	Cost: 5.93s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 16.6226	Cost: 5.91s
Train Epoch: 281 	Average Loss: 16.6569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8924

Saving model as e281_model.pt & e281_waveforms_supplementary.hdf5
Learning rate: 0.00019961059607190318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 16.8934	Cost: 20.56s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 16.6438	Cost: 6.09s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 16.5312	Cost: 6.02s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 16.5967	Cost: 5.92s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 16.5280	Cost: 5.81s
Train Epoch: 282 	Average Loss: 16.6561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9163

Learning rate: 0.00019960782139831766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 16.8638	Cost: 24.63s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 16.5733	Cost: 6.20s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 16.6756	Cost: 6.15s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 16.6772	Cost: 5.85s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 16.7207	Cost: 5.82s
Train Epoch: 283 	Average Loss: 16.6642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9699

Learning rate: 0.00019960503689383428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 16.8880	Cost: 21.83s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 16.5247	Cost: 6.19s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 16.5239	Cost: 6.20s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 16.6840	Cost: 5.99s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 16.7502	Cost: 5.81s
Train Epoch: 284 	Average Loss: 16.6474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9158

Learning rate: 0.0001996022425587279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 16.9208	Cost: 21.46s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 16.7016	Cost: 6.08s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 16.6026	Cost: 6.18s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 16.5577	Cost: 5.99s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 16.6728	Cost: 5.78s
Train Epoch: 285 	Average Loss: 16.6383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8680

Saving model as e285_model.pt & e285_waveforms_supplementary.hdf5
Learning rate: 0.0001995994383932743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 16.8638	Cost: 22.09s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 16.5542	Cost: 6.12s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 16.6513	Cost: 6.03s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 16.6472	Cost: 5.86s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 16.5493	Cost: 5.81s
Train Epoch: 286 	Average Loss: 16.6286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9413

Learning rate: 0.0001995966243977502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 16.9439	Cost: 23.91s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 16.6401	Cost: 6.05s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 16.5163	Cost: 6.13s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 16.5461	Cost: 5.88s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 16.7969	Cost: 5.74s
Train Epoch: 287 	Average Loss: 16.6300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8939

Learning rate: 0.0001995938005724334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 16.8393	Cost: 26.04s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 16.6705	Cost: 6.12s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 16.5660	Cost: 6.27s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 16.6930	Cost: 5.89s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 16.4848	Cost: 5.78s
Train Epoch: 288 	Average Loss: 16.6132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8726

Learning rate: 0.00019959096691760252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 16.8455	Cost: 22.35s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 16.5791	Cost: 6.33s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 16.6127	Cost: 6.12s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 16.6916	Cost: 5.98s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 16.7940	Cost: 5.76s
Train Epoch: 289 	Average Loss: 16.6412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8937

Learning rate: 0.00019958812343353726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 16.8038	Cost: 22.89s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 16.5846	Cost: 6.12s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 16.6034	Cost: 6.07s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 16.7185	Cost: 6.06s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 16.6943	Cost: 5.93s
Train Epoch: 290 	Average Loss: 16.6048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9572

Learning rate: 0.0001995852701205183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 16.8199	Cost: 21.55s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 16.6013	Cost: 6.43s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 16.4473	Cost: 6.10s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 16.6133	Cost: 6.03s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 16.5429	Cost: 5.95s
Train Epoch: 291 	Average Loss: 16.5911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9071

Learning rate: 0.0001995824069788272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 16.7371	Cost: 21.67s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 16.5912	Cost: 6.11s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 16.5649	Cost: 6.15s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 16.5256	Cost: 6.02s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 16.6988	Cost: 5.94s
Train Epoch: 292 	Average Loss: 16.5970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8900

Learning rate: 0.00019957953400874656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 16.9047	Cost: 20.80s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 16.6429	Cost: 6.61s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 16.4756	Cost: 6.17s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 16.5951	Cost: 5.97s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 16.6198	Cost: 5.91s
Train Epoch: 293 	Average Loss: 16.6006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9133

Learning rate: 0.00019957665121055995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 16.7525	Cost: 19.79s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 16.6089	Cost: 6.39s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 16.6407	Cost: 6.25s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 16.5007	Cost: 6.04s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 16.5383	Cost: 6.05s
Train Epoch: 294 	Average Loss: 16.5893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8707

Learning rate: 0.00019957375858455185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 16.9218	Cost: 19.64s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 16.6244	Cost: 6.94s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 16.5094	Cost: 6.17s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 16.6031	Cost: 6.09s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 16.5871	Cost: 5.95s
Train Epoch: 295 	Average Loss: 16.5920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8395

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 0.00019957085613100776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 16.8144	Cost: 19.45s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 16.5724	Cost: 6.78s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 16.4826	Cost: 6.19s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 16.5800	Cost: 6.08s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 16.6191	Cost: 6.11s
Train Epoch: 296 	Average Loss: 16.5938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9026

Learning rate: 0.00019956794385021415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 16.9842	Cost: 18.21s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 16.5489	Cost: 5.97s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 16.4121	Cost: 6.77s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 16.6521	Cost: 6.05s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 16.4908	Cost: 5.96s
Train Epoch: 297 	Average Loss: 16.5688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8894

Learning rate: 0.00019956502174245846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 16.8309	Cost: 19.31s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 16.6389	Cost: 6.00s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 16.6068	Cost: 6.29s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 16.5203	Cost: 6.15s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 16.7133	Cost: 5.90s
Train Epoch: 298 	Average Loss: 16.5970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8878

Learning rate: 0.0001995620898080291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 16.9391	Cost: 18.81s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 16.5579	Cost: 6.15s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 16.5645	Cost: 6.02s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 16.5349	Cost: 6.11s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 16.5444	Cost: 6.18s
Train Epoch: 299 	Average Loss: 16.5763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8663

Learning rate: 0.00019955914804721542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 16.8372	Cost: 20.66s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 16.5196	Cost: 5.96s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 16.5394	Cost: 6.01s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 16.6300	Cost: 6.08s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 16.6148	Cost: 6.22s
Train Epoch: 300 	Average Loss: 16.5505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9084

Learning rate: 0.00019955619646030775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 16.9818	Cost: 19.98s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 16.5728	Cost: 5.94s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 16.4590	Cost: 6.01s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 16.4373	Cost: 5.84s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 16.4875	Cost: 5.90s
Train Epoch: 301 	Average Loss: 16.5609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8361

Saving model as e301_model.pt & e301_waveforms_supplementary.hdf5
Learning rate: 0.0001995532350475974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 16.8235	Cost: 18.96s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 16.5319	Cost: 5.95s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 16.5136	Cost: 6.04s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 16.6210	Cost: 5.88s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 16.5110	Cost: 5.86s
Train Epoch: 302 	Average Loss: 16.5525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8362

Learning rate: 0.00019955026380937669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 16.8530	Cost: 20.29s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 16.4914	Cost: 6.02s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 16.4976	Cost: 6.33s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 16.4703	Cost: 5.93s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 16.6043	Cost: 5.76s
Train Epoch: 303 	Average Loss: 16.5240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8813

Learning rate: 0.00019954728274593884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 16.8633	Cost: 20.31s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 16.4518	Cost: 6.04s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 16.5912	Cost: 6.05s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 16.5583	Cost: 5.97s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 16.5789	Cost: 5.70s
Train Epoch: 304 	Average Loss: 16.5438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8725

Learning rate: 0.00019954429185757805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 16.6899	Cost: 20.05s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 16.5655	Cost: 6.01s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 16.5201	Cost: 6.10s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 16.6117	Cost: 5.86s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 16.4915	Cost: 5.73s
Train Epoch: 305 	Average Loss: 16.5301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8322

Saving model as e305_model.pt & e305_waveforms_supplementary.hdf5
Learning rate: 0.00019954129114458955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 16.7089	Cost: 19.56s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 16.5258	Cost: 6.05s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 16.3747	Cost: 6.00s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 16.4888	Cost: 5.88s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 16.5137	Cost: 5.71s
Train Epoch: 306 	Average Loss: 16.5134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9022

Learning rate: 0.00019953828060726943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 16.8750	Cost: 20.67s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 16.5164	Cost: 6.11s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 16.5643	Cost: 6.10s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 16.4752	Cost: 5.84s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 16.5349	Cost: 5.83s
Train Epoch: 307 	Average Loss: 16.4948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8719

Learning rate: 0.00019953526024591494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 16.8570	Cost: 19.45s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 16.5672	Cost: 6.17s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 16.4663	Cost: 6.28s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 16.2996	Cost: 5.85s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 16.5402	Cost: 5.70s
Train Epoch: 308 	Average Loss: 16.5153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8930

Learning rate: 0.00019953223006082406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 16.7694	Cost: 20.18s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 16.5017	Cost: 6.05s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 16.3206	Cost: 6.10s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 16.3304	Cost: 5.84s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 16.4844	Cost: 5.70s
Train Epoch: 309 	Average Loss: 16.5112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7721

Saving model as e309_model.pt & e309_waveforms_supplementary.hdf5
Learning rate: 0.00019952919005229592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 16.9059	Cost: 19.65s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 16.3666	Cost: 6.09s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 16.5461	Cost: 6.22s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 16.5473	Cost: 5.91s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 16.5645	Cost: 5.73s
Train Epoch: 310 	Average Loss: 16.4912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8662

Learning rate: 0.00019952614022063054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 16.6033	Cost: 19.06s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 16.5118	Cost: 6.09s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 16.4236	Cost: 6.05s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 16.4824	Cost: 5.90s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 16.5032	Cost: 5.70s
Train Epoch: 311 	Average Loss: 16.4767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8023

Learning rate: 0.00019952308056612892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 16.7387	Cost: 20.60s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 16.4455	Cost: 5.97s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 16.3954	Cost: 6.04s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 16.3534	Cost: 5.88s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 16.5226	Cost: 5.71s
Train Epoch: 312 	Average Loss: 16.4897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8880

Learning rate: 0.00019952001108909304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 16.8360	Cost: 22.58s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 16.4640	Cost: 6.07s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 16.4544	Cost: 6.00s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 16.4505	Cost: 5.89s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 16.5685	Cost: 5.76s
Train Epoch: 313 	Average Loss: 16.4735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8515

Learning rate: 0.00019951693178982586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 16.8935	Cost: 21.95s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 16.4616	Cost: 5.99s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 16.4021	Cost: 6.15s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 16.3066	Cost: 6.03s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 16.4721	Cost: 5.87s
Train Epoch: 314 	Average Loss: 16.4819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8744

Learning rate: 0.00019951384266863126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 16.6714	Cost: 21.49s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 16.3917	Cost: 5.96s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 16.4076	Cost: 5.97s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 16.3131	Cost: 5.84s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 16.5412	Cost: 5.78s
Train Epoch: 315 	Average Loss: 16.4705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8617

Learning rate: 0.00019951074372581416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 16.7546	Cost: 23.67s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 16.3259	Cost: 5.74s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 16.5194	Cost: 6.19s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 16.4717	Cost: 5.83s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 16.4683	Cost: 5.78s
Train Epoch: 316 	Average Loss: 16.4806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8933

Learning rate: 0.00019950763496168037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 16.8600	Cost: 24.03s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 16.3882	Cost: 5.95s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 16.3593	Cost: 6.00s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 16.5207	Cost: 5.84s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 16.4791	Cost: 5.71s
Train Epoch: 317 	Average Loss: 16.4527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8511

Learning rate: 0.00019950451637653678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 16.7180	Cost: 23.59s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 16.3388	Cost: 5.95s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 16.5387	Cost: 6.15s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 16.4521	Cost: 5.85s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 16.4416	Cost: 5.70s
Train Epoch: 318 	Average Loss: 16.4567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8599

Learning rate: 0.00019950138797069118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 16.8911	Cost: 22.57s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 16.4996	Cost: 6.09s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 16.4529	Cost: 6.06s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 16.4192	Cost: 5.87s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 16.4674	Cost: 5.71s
Train Epoch: 319 	Average Loss: 16.4630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8427

Learning rate: 0.00019949824974445222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 16.7072	Cost: 23.24s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 16.5161	Cost: 6.00s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 16.2795	Cost: 6.02s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 16.3704	Cost: 5.84s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 16.4589	Cost: 5.70s
Train Epoch: 320 	Average Loss: 16.4356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9325

Learning rate: 0.00019949510169812976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 16.7423	Cost: 20.81s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 16.4307	Cost: 7.35s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 16.4091	Cost: 6.15s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 16.4515	Cost: 5.87s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 16.3591	Cost: 5.73s
Train Epoch: 321 	Average Loss: 16.4529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9144

Learning rate: 0.00019949194383203438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 16.9676	Cost: 21.31s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 16.4042	Cost: 6.04s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 16.4374	Cost: 6.06s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 16.3397	Cost: 5.85s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 16.4389	Cost: 5.69s
Train Epoch: 322 	Average Loss: 16.4412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8657

Learning rate: 0.00019948877614647787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 16.7598	Cost: 20.60s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 16.4620	Cost: 6.47s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 16.4366	Cost: 6.18s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 16.2984	Cost: 5.86s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 16.4316	Cost: 5.74s
Train Epoch: 323 	Average Loss: 16.4326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8007

Learning rate: 0.0001994855986417728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 16.7259	Cost: 19.16s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 16.4308	Cost: 6.21s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 16.4641	Cost: 6.09s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 16.3529	Cost: 5.90s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 16.3474	Cost: 5.76s
Train Epoch: 324 	Average Loss: 16.4225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9376

Learning rate: 0.0001994824113182328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 16.8241	Cost: 18.82s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 16.3905	Cost: 6.04s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 16.4142	Cost: 6.25s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 16.3899	Cost: 5.87s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 16.4788	Cost: 5.52s
Train Epoch: 325 	Average Loss: 16.4456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9012

Learning rate: 0.00019947921417617242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 16.7961	Cost: 19.24s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 16.4406	Cost: 6.06s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 16.4612	Cost: 6.06s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 16.4195	Cost: 6.10s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 16.4207	Cost: 5.74s
Train Epoch: 326 	Average Loss: 16.4161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8328

Learning rate: 0.0001994760072159072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 16.7711	Cost: 19.98s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 16.4075	Cost: 6.13s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 16.4706	Cost: 6.09s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 16.3502	Cost: 5.99s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 16.4182	Cost: 6.28s
Train Epoch: 327 	Average Loss: 16.3997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8660

Learning rate: 0.00019947279043775368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 16.8867	Cost: 19.99s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 16.3680	Cost: 6.06s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 16.4029	Cost: 5.81s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 16.3049	Cost: 5.82s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 16.3341	Cost: 6.12s
Train Epoch: 328 	Average Loss: 16.4027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8934

Learning rate: 0.00019946956384202932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 16.8182	Cost: 19.78s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 16.4524	Cost: 6.10s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 16.4046	Cost: 6.00s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 16.2374	Cost: 5.85s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 16.2819	Cost: 5.85s
Train Epoch: 329 	Average Loss: 16.4061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8493

Learning rate: 0.00019946632742905265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 16.7724	Cost: 20.54s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 16.3690	Cost: 5.94s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 16.4060	Cost: 5.97s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 16.3406	Cost: 5.82s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 16.4055	Cost: 5.86s
Train Epoch: 330 	Average Loss: 16.3929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8522

Learning rate: 0.000199463081199143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 16.8278	Cost: 21.28s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 16.2670	Cost: 5.89s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 16.4591	Cost: 6.51s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 16.4025	Cost: 5.81s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 16.3329	Cost: 5.95s
Train Epoch: 331 	Average Loss: 16.4091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8543

Learning rate: 0.0001994598251526208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 16.8017	Cost: 20.21s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 16.3959	Cost: 5.74s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 16.2590	Cost: 6.86s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 16.2392	Cost: 5.60s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 16.3799	Cost: 6.13s
Train Epoch: 332 	Average Loss: 16.3686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9232

Learning rate: 0.00019945655928980737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 16.8042	Cost: 20.01s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 16.4175	Cost: 6.04s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 16.2816	Cost: 6.07s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 16.2977	Cost: 5.90s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 16.2449	Cost: 5.71s
Train Epoch: 333 	Average Loss: 16.3782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8137

Learning rate: 0.0001994532836110251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 16.7862	Cost: 20.26s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 16.3707	Cost: 6.06s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 16.3885	Cost: 6.38s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 16.2964	Cost: 5.89s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 16.1886	Cost: 5.76s
Train Epoch: 334 	Average Loss: 16.3616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8439

Learning rate: 0.00019944999811659725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 16.6990	Cost: 20.71s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 16.3904	Cost: 5.75s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 16.2397	Cost: 6.46s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 16.3394	Cost: 5.62s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 16.3301	Cost: 5.62s
Train Epoch: 335 	Average Loss: 16.3597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8432

Learning rate: 0.00019944670280684805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 16.8668	Cost: 20.58s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 16.3171	Cost: 5.96s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 16.2441	Cost: 6.01s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 16.2353	Cost: 5.97s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 16.3969	Cost: 5.68s
Train Epoch: 336 	Average Loss: 16.3555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8852

Learning rate: 0.00019944339768210285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 16.7223	Cost: 19.96s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 16.3013	Cost: 6.03s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 16.2422	Cost: 6.05s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 16.2861	Cost: 5.95s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 16.3923	Cost: 5.70s
Train Epoch: 337 	Average Loss: 16.3562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8512

Learning rate: 0.0001994400827426877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 16.8570	Cost: 19.57s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 16.4141	Cost: 6.09s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 16.4094	Cost: 6.09s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 16.2492	Cost: 5.85s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 16.2958	Cost: 5.70s
Train Epoch: 338 	Average Loss: 16.3359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8055

Learning rate: 0.0001994367579889299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 16.6530	Cost: 19.69s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 16.3185	Cost: 6.02s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 16.4809	Cost: 6.03s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 16.2411	Cost: 5.83s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 16.3037	Cost: 5.67s
Train Epoch: 339 	Average Loss: 16.3425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9041

Learning rate: 0.0001994334234211575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 16.8499	Cost: 20.71s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 16.3449	Cost: 5.97s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 16.3558	Cost: 6.02s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 16.2798	Cost: 5.85s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 16.2495	Cost: 5.68s
Train Epoch: 340 	Average Loss: 16.3510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8280

Learning rate: 0.00019943007903969968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 16.8052	Cost: 21.26s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 16.3404	Cost: 5.91s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 16.2639	Cost: 6.25s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 16.2801	Cost: 5.84s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 16.3072	Cost: 5.89s
Train Epoch: 341 	Average Loss: 16.3324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8569

Learning rate: 0.00019942672484488645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 16.8534	Cost: 20.71s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 16.4113	Cost: 6.00s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 16.1639	Cost: 6.07s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 16.1751	Cost: 5.86s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 16.2335	Cost: 5.68s
Train Epoch: 342 	Average Loss: 16.3189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8763

Learning rate: 0.0001994233608370489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 16.8314	Cost: 21.90s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 16.2870	Cost: 5.98s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 16.1568	Cost: 6.15s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 16.2178	Cost: 5.98s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 16.3252	Cost: 5.76s
Train Epoch: 343 	Average Loss: 16.3196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9207

Learning rate: 0.00019941998701651908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 16.7988	Cost: 21.01s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 16.4200	Cost: 6.01s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 16.2494	Cost: 6.00s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 16.3234	Cost: 5.84s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 16.3246	Cost: 5.78s
Train Epoch: 344 	Average Loss: 16.3216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8531

Learning rate: 0.00019941660338362987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 16.8936	Cost: 22.39s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 16.3298	Cost: 5.97s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 16.2088	Cost: 6.03s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 16.2208	Cost: 5.81s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 16.1741	Cost: 6.32s
Train Epoch: 345 	Average Loss: 16.2900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8419

Learning rate: 0.0001994132099387153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 16.9468	Cost: 22.79s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 16.2561	Cost: 5.99s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 16.4057	Cost: 6.01s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 16.4134	Cost: 5.90s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 16.3123	Cost: 5.69s
Train Epoch: 346 	Average Loss: 16.3179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8545

Learning rate: 0.00019940980668211027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 16.8359	Cost: 22.66s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 16.2660	Cost: 6.46s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 16.1864	Cost: 6.03s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 16.2872	Cost: 5.99s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 16.3308	Cost: 5.68s
Train Epoch: 347 	Average Loss: 16.3147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8819

Learning rate: 0.00019940639361415064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 16.8992	Cost: 23.25s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 16.3397	Cost: 6.05s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 16.2286	Cost: 6.08s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 16.0827	Cost: 5.87s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 16.3724	Cost: 5.69s
Train Epoch: 348 	Average Loss: 16.2902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8755

Learning rate: 0.00019940297073517331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 16.7199	Cost: 21.56s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 16.3092	Cost: 6.34s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 16.2160	Cost: 6.13s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 16.1957	Cost: 5.84s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 16.2707	Cost: 5.71s
Train Epoch: 349 	Average Loss: 16.2871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9125

Learning rate: 0.00019939953804551608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 16.7629	Cost: 21.56s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 16.2738	Cost: 6.19s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 16.2611	Cost: 6.50s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 16.2047	Cost: 5.87s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 16.2499	Cost: 5.82s
Train Epoch: 350 	Average Loss: 16.2853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8586

Learning rate: 0.00019939609554551777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 16.9390	Cost: 19.09s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 16.2491	Cost: 6.35s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 16.2231	Cost: 6.23s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 16.1254	Cost: 5.78s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 16.2475	Cost: 5.49s
Train Epoch: 351 	Average Loss: 16.2610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8555

Learning rate: 0.0001993926432355181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 16.8677	Cost: 19.40s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 16.3068	Cost: 6.03s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 16.1428	Cost: 6.18s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 16.1623	Cost: 5.86s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 16.3229	Cost: 5.71s
Train Epoch: 352 	Average Loss: 16.2732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9459

Learning rate: 0.00019938918111585784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 16.8189	Cost: 20.21s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 16.2967	Cost: 5.94s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 16.1888	Cost: 6.36s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 16.1259	Cost: 6.02s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 16.2773	Cost: 6.80s
Train Epoch: 353 	Average Loss: 16.2516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9067

Learning rate: 0.00019938570918687863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 16.8031	Cost: 19.48s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 16.1746	Cost: 5.98s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 16.1902	Cost: 6.08s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 16.0676	Cost: 5.92s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 16.2611	Cost: 5.80s
Train Epoch: 354 	Average Loss: 16.2505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8422

Learning rate: 0.0001993822274489232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 16.8072	Cost: 20.02s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 16.2769	Cost: 6.01s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 16.1481	Cost: 5.98s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 16.1531	Cost: 5.83s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 16.2549	Cost: 5.73s
Train Epoch: 355 	Average Loss: 16.2863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9411

Learning rate: 0.00019937873590233516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 16.8148	Cost: 20.80s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 16.3722	Cost: 5.99s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 16.2338	Cost: 6.16s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 16.1780	Cost: 5.85s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 16.2278	Cost: 5.82s
Train Epoch: 356 	Average Loss: 16.2543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8603

Learning rate: 0.0001993752345474591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 16.8818	Cost: 19.89s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 16.1768	Cost: 5.97s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 16.1812	Cost: 5.99s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 16.1811	Cost: 5.80s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 16.1897	Cost: 5.68s
Train Epoch: 357 	Average Loss: 16.2506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8578

Learning rate: 0.0001993717233846406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 16.7295	Cost: 20.17s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 16.1887	Cost: 5.99s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 16.1588	Cost: 6.13s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 16.0766	Cost: 5.97s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 16.2513	Cost: 5.70s
Train Epoch: 358 	Average Loss: 16.2426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8623

Learning rate: 0.0001993682024142262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 16.6649	Cost: 18.97s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 16.1002	Cost: 6.07s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 16.1485	Cost: 6.25s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 16.1435	Cost: 5.87s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 16.3072	Cost: 5.69s
Train Epoch: 359 	Average Loss: 16.2359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8526

Learning rate: 0.00019936467163656337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 16.8612	Cost: 19.15s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 16.1596	Cost: 6.00s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 16.3543	Cost: 6.00s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 16.1831	Cost: 5.84s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 16.3645	Cost: 5.68s
Train Epoch: 360 	Average Loss: 16.2109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8592

Learning rate: 0.00019936113105200064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 16.7223	Cost: 20.50s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 16.1673	Cost: 6.09s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 16.2731	Cost: 5.81s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 16.1697	Cost: 5.66s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 16.3010	Cost: 5.50s
Train Epoch: 361 	Average Loss: 16.2238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8824

Learning rate: 0.00019935758066088742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 16.8515	Cost: 20.31s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 16.2099	Cost: 5.94s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 16.0923	Cost: 6.00s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 16.0952	Cost: 5.86s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 16.1872	Cost: 5.71s
Train Epoch: 362 	Average Loss: 16.2114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8838

Learning rate: 0.00019935402046357414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 16.8927	Cost: 20.90s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 16.2224	Cost: 5.94s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 16.1434	Cost: 6.04s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 16.2518	Cost: 5.87s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 16.1609	Cost: 5.72s
Train Epoch: 363 	Average Loss: 16.1905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8740

Learning rate: 0.00019935045046041218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 16.7930	Cost: 20.48s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 16.2174	Cost: 6.04s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 16.2308	Cost: 6.12s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 16.1619	Cost: 5.87s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 16.1467	Cost: 5.71s
Train Epoch: 364 	Average Loss: 16.2147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8440

Learning rate: 0.00019934687065175386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 16.9075	Cost: 20.85s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 16.2460	Cost: 5.96s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 16.2054	Cost: 5.97s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 16.0326	Cost: 5.88s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 16.1833	Cost: 5.71s
Train Epoch: 365 	Average Loss: 16.2150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8486

Learning rate: 0.00019934328103795248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 16.7715	Cost: 21.23s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 16.1639	Cost: 6.05s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 16.1055	Cost: 6.45s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 16.0152	Cost: 5.91s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 16.2339	Cost: 5.96s
Train Epoch: 366 	Average Loss: 16.1638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8654

Learning rate: 0.00019933968161936236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 16.7376	Cost: 22.22s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 16.1221	Cost: 5.97s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 16.1959	Cost: 6.20s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 16.1673	Cost: 5.95s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 16.0802	Cost: 5.80s
Train Epoch: 367 	Average Loss: 16.1917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8898

Learning rate: 0.00019933607239633875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 16.7205	Cost: 21.79s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 16.0626	Cost: 6.05s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 16.1360	Cost: 6.00s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 15.9928	Cost: 5.89s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 16.0875	Cost: 5.79s
Train Epoch: 368 	Average Loss: 16.1511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9272

Learning rate: 0.00019933245336923783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 16.6814	Cost: 22.17s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 16.1005	Cost: 6.02s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 16.0765	Cost: 6.44s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 16.1365	Cost: 5.98s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 16.1718	Cost: 5.84s
Train Epoch: 369 	Average Loss: 16.1667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8730

Learning rate: 0.0001993288245384168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 16.9334	Cost: 23.70s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 16.2590	Cost: 5.98s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 16.0598	Cost: 6.00s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 16.0495	Cost: 5.85s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 16.2674	Cost: 5.72s
Train Epoch: 370 	Average Loss: 16.1682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9387

Learning rate: 0.00019932518590423377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 16.9047	Cost: 22.58s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 16.1583	Cost: 5.97s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 16.0840	Cost: 6.03s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 16.1253	Cost: 5.84s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 16.2268	Cost: 5.70s
Train Epoch: 371 	Average Loss: 16.1625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8753

Learning rate: 0.00019932153746704794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 16.7501	Cost: 21.13s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 16.2291	Cost: 6.09s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 16.2008	Cost: 6.04s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 16.1163	Cost: 5.86s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 16.1239	Cost: 5.72s
Train Epoch: 372 	Average Loss: 16.1577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9282

Learning rate: 0.00019931787922721937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 16.7893	Cost: 22.04s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 16.2027	Cost: 6.40s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 16.0946	Cost: 6.06s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 16.0507	Cost: 5.89s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 16.0583	Cost: 5.72s
Train Epoch: 373 	Average Loss: 16.1406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8229

Learning rate: 0.00019931421118510906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 16.8798	Cost: 19.44s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 16.1354	Cost: 6.11s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 16.1550	Cost: 6.19s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 16.0782	Cost: 5.84s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 16.1861	Cost: 5.71s
Train Epoch: 374 	Average Loss: 16.1450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8451

Learning rate: 0.0001993105333410791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 17.0309	Cost: 20.03s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 16.1839	Cost: 6.16s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 16.0743	Cost: 6.32s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 16.1841	Cost: 5.91s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 16.0758	Cost: 5.73s
Train Epoch: 375 	Average Loss: 16.1308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8770

Learning rate: 0.00019930684569549248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 16.8657	Cost: 19.42s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 16.1560	Cost: 6.01s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 15.9564	Cost: 6.19s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 15.9712	Cost: 5.93s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 16.2168	Cost: 5.75s
Train Epoch: 376 	Average Loss: 16.1190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8557

Learning rate: 0.0001993031482487131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 16.9846	Cost: 18.66s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 16.0066	Cost: 6.00s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 16.0194	Cost: 6.10s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 15.9172	Cost: 6.04s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 16.0219	Cost: 5.90s
Train Epoch: 377 	Average Loss: 16.1149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8956

Learning rate: 0.0001992994410011059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 16.7257	Cost: 20.32s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 16.0209	Cost: 5.97s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 15.9793	Cost: 6.03s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 16.0142	Cost: 6.00s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 16.1542	Cost: 5.97s
Train Epoch: 378 	Average Loss: 16.1036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7969

Learning rate: 0.00019929572395303678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 16.8687	Cost: 20.62s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 16.0705	Cost: 6.01s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 16.0868	Cost: 5.99s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 16.0073	Cost: 5.85s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 16.0986	Cost: 5.87s
Train Epoch: 379 	Average Loss: 16.1097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8353

Learning rate: 0.0001992919971048726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 16.9930	Cost: 20.49s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 16.0065	Cost: 5.99s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 16.0801	Cost: 6.05s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 16.0644	Cost: 5.97s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 16.1685	Cost: 5.71s
Train Epoch: 380 	Average Loss: 16.1005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8641

Learning rate: 0.0001992882604569812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 16.8827	Cost: 19.82s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 16.1008	Cost: 5.97s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 15.9695	Cost: 5.97s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 16.0380	Cost: 5.81s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 16.1136	Cost: 5.71s
Train Epoch: 381 	Average Loss: 16.0971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9114

Learning rate: 0.00019928451400973133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 16.7912	Cost: 20.31s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 16.0002	Cost: 6.07s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 16.0431	Cost: 6.03s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 16.1350	Cost: 5.89s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 16.0194	Cost: 5.71s
Train Epoch: 382 	Average Loss: 16.0683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8792

Learning rate: 0.0001992807577634928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 16.7846	Cost: 20.69s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 16.0258	Cost: 5.94s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 16.0726	Cost: 6.11s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 15.9861	Cost: 5.84s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 16.2032	Cost: 5.87s
Train Epoch: 383 	Average Loss: 16.0774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8216

Learning rate: 0.00019927699171863632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 16.7423	Cost: 19.78s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 16.0886	Cost: 6.07s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 15.8745	Cost: 6.09s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 15.9926	Cost: 5.89s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 16.1189	Cost: 5.74s
Train Epoch: 384 	Average Loss: 16.0924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9244

Learning rate: 0.00019927321587553357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 16.9696	Cost: 19.95s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 16.0249	Cost: 6.04s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 15.9667	Cost: 6.07s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 15.8865	Cost: 5.85s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 15.9918	Cost: 5.68s
Train Epoch: 385 	Average Loss: 16.0708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9212

Learning rate: 0.00019926943023455717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 16.8228	Cost: 19.87s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 16.0488	Cost: 5.93s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 15.9104	Cost: 6.04s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 16.0044	Cost: 5.87s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 15.9485	Cost: 5.69s
Train Epoch: 386 	Average Loss: 16.0493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9214

Learning rate: 0.00019926563479608086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 16.8128	Cost: 20.75s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 16.0067	Cost: 6.29s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 16.0584	Cost: 6.10s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 16.1071	Cost: 5.86s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 16.0781	Cost: 5.70s
Train Epoch: 387 	Average Loss: 16.0480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9124

Learning rate: 0.00019926182956047912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 16.9907	Cost: 20.82s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 15.9820	Cost: 5.97s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 15.9523	Cost: 5.93s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 15.9035	Cost: 5.86s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 16.1543	Cost: 5.73s
Train Epoch: 388 	Average Loss: 16.0742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9169

Learning rate: 0.00019925801452812757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 16.8614	Cost: 20.64s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 16.0065	Cost: 6.02s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 15.9582	Cost: 6.08s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 15.9868	Cost: 5.93s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 16.0245	Cost: 5.72s
Train Epoch: 389 	Average Loss: 16.0496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9275

Learning rate: 0.00019925418969940278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 16.9310	Cost: 22.41s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 16.0430	Cost: 5.98s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 16.0251	Cost: 6.31s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 15.9453	Cost: 5.98s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 15.9738	Cost: 6.25s
Train Epoch: 390 	Average Loss: 16.0281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9193

Learning rate: 0.00019925035507468219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 16.8220	Cost: 21.77s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 15.9325	Cost: 5.96s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 16.0206	Cost: 6.25s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 15.9253	Cost: 5.94s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 15.9161	Cost: 5.72s
Train Epoch: 391 	Average Loss: 16.0096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8788

Learning rate: 0.00019924651065434423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 16.9210	Cost: 22.30s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 15.9293	Cost: 6.00s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 15.9761	Cost: 6.03s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 15.9346	Cost: 5.88s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 15.9865	Cost: 5.76s
Train Epoch: 392 	Average Loss: 16.0265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9209

Learning rate: 0.0001992426564387684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 16.9354	Cost: 22.88s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 16.0214	Cost: 5.99s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 15.9460	Cost: 6.42s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 15.9858	Cost: 5.86s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 16.0105	Cost: 5.87s
Train Epoch: 393 	Average Loss: 16.0183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8908

Learning rate: 0.00019923879242833502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 16.9103	Cost: 22.30s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 15.9295	Cost: 5.94s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 15.9917	Cost: 6.47s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 15.9291	Cost: 5.90s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 15.9194	Cost: 5.82s
Train Epoch: 394 	Average Loss: 16.0026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9260

Learning rate: 0.00019923491862342552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 16.7288	Cost: 21.05s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 15.9529	Cost: 6.10s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 15.8898	Cost: 6.02s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 15.8675	Cost: 5.84s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 15.8497	Cost: 5.72s
Train Epoch: 395 	Average Loss: 15.9830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8709

Learning rate: 0.0001992310350244222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 16.7780	Cost: 22.48s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 15.9723	Cost: 5.99s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 15.9566	Cost: 6.02s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 15.7741	Cost: 5.84s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 15.9515	Cost: 5.69s
Train Epoch: 396 	Average Loss: 15.9963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9133

Learning rate: 0.0001992271416317084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 16.8096	Cost: 23.93s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 16.0246	Cost: 5.97s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 15.8493	Cost: 6.13s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 15.8626	Cost: 5.84s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 16.0725	Cost: 5.68s
Train Epoch: 397 	Average Loss: 15.9836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9308

Learning rate: 0.0001992232384456683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 16.8528	Cost: 22.56s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 15.9605	Cost: 6.02s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 15.9031	Cost: 6.06s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 16.0368	Cost: 5.97s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 15.8496	Cost: 5.68s
Train Epoch: 398 	Average Loss: 15.9939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9277

Learning rate: 0.00019921932546668718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 17.0098	Cost: 22.15s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 15.9772	Cost: 6.02s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 15.8677	Cost: 6.06s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 15.8848	Cost: 5.89s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 15.9920	Cost: 5.70s
Train Epoch: 399 	Average Loss: 15.9750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9002

Learning rate: 0.00019921540269515121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 16.8430	Cost: 20.00s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 15.8943	Cost: 6.61s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 15.9359	Cost: 6.06s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 15.9296	Cost: 5.88s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 15.8874	Cost: 5.70s
Train Epoch: 400 	Average Loss: 15.9721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8897

Learning rate: 0.0001992114701314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 16.9371	Cost: 20.61s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 15.9467	Cost: 6.09s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 15.9347	Cost: 6.12s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 15.9181	Cost: 5.88s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 15.9561	Cost: 5.72s
Train Epoch: 401 	Average Loss: 15.9889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9364

Learning rate: 0.00019920752777596444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 16.8372	Cost: 19.00s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 15.9757	Cost: 6.12s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 15.9745	Cost: 7.00s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 15.8489	Cost: 5.86s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 15.9864	Cost: 5.69s
Train Epoch: 402 	Average Loss: 15.9605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9169

Learning rate: 0.00019920357562909082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 16.7167	Cost: 19.65s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 15.8778	Cost: 6.03s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 15.8727	Cost: 6.36s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 15.9335	Cost: 5.90s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 15.9874	Cost: 5.80s
Train Epoch: 403 	Average Loss: 15.9522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9586

Learning rate: 0.00019919961369121682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 16.9540	Cost: 18.03s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 16.0032	Cost: 6.06s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 15.9092	Cost: 6.14s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 15.8867	Cost: 6.10s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 15.9203	Cost: 6.14s
Train Epoch: 404 	Average Loss: 15.9724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9272

Learning rate: 0.00019919564196273348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 16.8818	Cost: 20.02s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 15.9091	Cost: 5.96s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 15.7967	Cost: 6.02s
Train Epoch: 405 [61440/90000 (68%)]	Loss: 15.8697	Cost: 5.88s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 16.0324	Cost: 5.73s
Train Epoch: 405 	Average Loss: 15.9468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9454

Learning rate: 0.00019919166044403278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 16.7462	Cost: 19.40s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 15.8580	Cost: 6.18s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 15.8096	Cost: 6.08s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 15.8377	Cost: 5.85s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 15.8150	Cost: 5.71s
Train Epoch: 406 	Average Loss: 15.9411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9520

Learning rate: 0.00019918766913550764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 16.9774	Cost: 19.14s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 15.9088	Cost: 6.09s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 15.8462	Cost: 6.07s
Train Epoch: 407 [61440/90000 (68%)]	Loss: 15.8104	Cost: 5.82s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 15.8244	Cost: 5.71s
Train Epoch: 407 	Average Loss: 15.9346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0154

Learning rate: 0.00019918366803755205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 16.8855	Cost: 19.80s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 15.7813	Cost: 6.06s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 15.9166	Cost: 6.26s
Train Epoch: 408 [61440/90000 (68%)]	Loss: 15.8220	Cost: 5.81s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 15.9540	Cost: 5.72s
Train Epoch: 408 	Average Loss: 15.9274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8906

Learning rate: 0.00019917965715056087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 16.8394	Cost: 20.44s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 15.8197	Cost: 6.11s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 15.8507	Cost: 6.23s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 15.8033	Cost: 5.65s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 15.8277	Cost: 5.66s
Train Epoch: 409 	Average Loss: 15.9232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9752

Learning rate: 0.00019917563647492995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 16.9917	Cost: 19.38s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 15.8265	Cost: 6.01s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 15.8109	Cost: 6.20s
Train Epoch: 410 [61440/90000 (68%)]	Loss: 15.8239	Cost: 5.88s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 15.9823	Cost: 5.69s
Train Epoch: 410 	Average Loss: 15.9166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9520

Learning rate: 0.00019917160601105614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 17.0228	Cost: 20.11s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 15.8919	Cost: 6.21s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 15.7932	Cost: 6.03s
Train Epoch: 411 [61440/90000 (68%)]	Loss: 15.8255	Cost: 5.85s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 15.9284	Cost: 5.71s
Train Epoch: 411 	Average Loss: 15.9166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9272

Learning rate: 0.0001991675657593372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 16.7424	Cost: 19.86s
Train Epoch: 412 [20480/90000 (23%)]	Loss: 15.9109	Cost: 6.06s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 15.7621	Cost: 6.15s
Train Epoch: 412 [61440/90000 (68%)]	Loss: 15.7172	Cost: 5.88s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 15.6841	Cost: 5.71s
Train Epoch: 412 	Average Loss: 15.8721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9180

Learning rate: 0.00019916351572017192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 17.0691	Cost: 20.24s
Train Epoch: 413 [20480/90000 (23%)]	Loss: 15.6833	Cost: 6.01s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 15.8371	Cost: 6.23s
Train Epoch: 413 [61440/90000 (68%)]	Loss: 15.7281	Cost: 5.98s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 15.8159	Cost: 5.71s
Train Epoch: 413 	Average Loss: 15.8807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9423

Learning rate: 0.00019915945589396003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 16.7284	Cost: 20.04s
Train Epoch: 414 [20480/90000 (23%)]	Loss: 15.8855	Cost: 6.04s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 15.6990	Cost: 6.24s
Train Epoch: 414 [61440/90000 (68%)]	Loss: 15.7800	Cost: 5.84s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 15.7988	Cost: 5.68s
Train Epoch: 414 	Average Loss: 15.8779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9627

Learning rate: 0.00019915538628110217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 16.9259	Cost: 20.21s
Train Epoch: 415 [20480/90000 (23%)]	Loss: 15.7749	Cost: 6.22s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 15.7566	Cost: 6.05s
Train Epoch: 415 [61440/90000 (68%)]	Loss: 15.7792	Cost: 5.87s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 15.7388	Cost: 5.70s
Train Epoch: 415 	Average Loss: 15.8732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8968

Learning rate: 0.00019915130688200001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 16.8377	Cost: 20.06s
Train Epoch: 416 [20480/90000 (23%)]	Loss: 15.8703	Cost: 6.07s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 15.9364	Cost: 6.05s
Train Epoch: 416 [61440/90000 (68%)]	Loss: 15.7841	Cost: 5.87s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 15.7900	Cost: 5.73s
Train Epoch: 416 	Average Loss: 15.8907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9849

Learning rate: 0.0001991472176970562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 16.9321	Cost: 20.03s
Train Epoch: 417 [20480/90000 (23%)]	Loss: 15.7797	Cost: 6.07s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 15.8021	Cost: 6.04s
Train Epoch: 417 [61440/90000 (68%)]	Loss: 15.7840	Cost: 5.83s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 15.8844	Cost: 5.71s
Train Epoch: 417 	Average Loss: 15.8824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9429

Learning rate: 0.00019914311872667434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 16.8844	Cost: 20.98s
Train Epoch: 418 [20480/90000 (23%)]	Loss: 15.8137	Cost: 5.93s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 15.7018	Cost: 6.58s
Train Epoch: 418 [61440/90000 (68%)]	Loss: 15.9244	Cost: 5.84s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 15.7823	Cost: 5.99s
Train Epoch: 418 	Average Loss: 15.8587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9711

Learning rate: 0.0001991390099712589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 17.0007	Cost: 20.19s
Train Epoch: 419 [20480/90000 (23%)]	Loss: 15.9305	Cost: 6.03s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 15.7095	Cost: 6.05s
Train Epoch: 419 [61440/90000 (68%)]	Loss: 15.8314	Cost: 5.85s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 15.7830	Cost: 5.71s
Train Epoch: 419 	Average Loss: 15.8617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9914

Learning rate: 0.00019913489143121547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 16.8637	Cost: 20.78s
Train Epoch: 420 [20480/90000 (23%)]	Loss: 15.7740	Cost: 5.97s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 15.6650	Cost: 6.42s
Train Epoch: 420 [61440/90000 (68%)]	Loss: 15.7231	Cost: 5.86s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 15.7857	Cost: 5.83s
Train Epoch: 420 	Average Loss: 15.8176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8759

Learning rate: 0.0001991307631069505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 16.9443	Cost: 20.41s
Train Epoch: 421 [20480/90000 (23%)]	Loss: 15.8363	Cost: 5.96s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 15.7964	Cost: 6.13s
Train Epoch: 421 [61440/90000 (68%)]	Loss: 15.7367	Cost: 5.86s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 15.7916	Cost: 5.69s
Train Epoch: 421 	Average Loss: 15.8295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9529

Learning rate: 0.0001991266249988715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 16.9930	Cost: 21.32s
Train Epoch: 422 [20480/90000 (23%)]	Loss: 15.7440	Cost: 6.02s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 15.7773	Cost: 6.14s
Train Epoch: 422 [61440/90000 (68%)]	Loss: 15.7187	Cost: 5.88s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 15.7840	Cost: 5.70s
Train Epoch: 422 	Average Loss: 15.8223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9866

Learning rate: 0.00019912247710738676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 16.7269	Cost: 20.67s
Train Epoch: 423 [20480/90000 (23%)]	Loss: 15.7583	Cost: 6.09s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 15.6289	Cost: 6.26s
Train Epoch: 423 [61440/90000 (68%)]	Loss: 15.7996	Cost: 6.02s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 15.8529	Cost: 5.73s
Train Epoch: 423 	Average Loss: 15.7983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9347

Learning rate: 0.0001991183194329058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 16.8477	Cost: 21.47s
Train Epoch: 424 [20480/90000 (23%)]	Loss: 15.8121	Cost: 6.31s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 15.7868	Cost: 6.65s
Train Epoch: 424 [61440/90000 (68%)]	Loss: 15.8052	Cost: 6.03s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 15.7345	Cost: 5.79s
Train Epoch: 424 	Average Loss: 15.8078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9727

Learning rate: 0.00019911415197583891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 17.0654	Cost: 21.56s
Train Epoch: 425 [20480/90000 (23%)]	Loss: 15.7715	Cost: 5.99s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 15.7722	Cost: 6.02s
Train Epoch: 425 [61440/90000 (68%)]	Loss: 15.6748	Cost: 5.91s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 15.9276	Cost: 5.79s
Train Epoch: 425 	Average Loss: 15.8303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0403

Learning rate: 0.00019910997473659734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 16.8110	Cost: 20.58s
Train Epoch: 426 [20480/90000 (23%)]	Loss: 15.8585	Cost: 6.11s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 15.7902	Cost: 6.06s
Train Epoch: 426 [61440/90000 (68%)]	Loss: 15.5998	Cost: 5.89s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 15.7801	Cost: 5.80s
Train Epoch: 426 	Average Loss: 15.7983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0009

Learning rate: 0.00019910578771559345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 16.9041	Cost: 21.09s
Train Epoch: 427 [20480/90000 (23%)]	Loss: 15.6220	Cost: 6.01s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 15.7870	Cost: 6.18s
Train Epoch: 427 [61440/90000 (68%)]	Loss: 15.7397	Cost: 5.83s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 15.7325	Cost: 5.81s
Train Epoch: 427 	Average Loss: 15.7930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0852

Learning rate: 0.00019910159091324043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 16.9188	Cost: 21.47s
Train Epoch: 428 [20480/90000 (23%)]	Loss: 15.7474	Cost: 6.05s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 15.7907	Cost: 6.06s
Train Epoch: 428 [61440/90000 (68%)]	Loss: 15.5131	Cost: 5.90s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 15.8476	Cost: 5.73s
Train Epoch: 428 	Average Loss: 15.7903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0446

Learning rate: 0.00019909738432995254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 16.9605	Cost: 22.50s
Train Epoch: 429 [20480/90000 (23%)]	Loss: 15.7501	Cost: 6.00s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 15.5547	Cost: 6.09s
Train Epoch: 429 [61440/90000 (68%)]	Loss: 15.5788	Cost: 5.90s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 15.7140	Cost: 5.69s
Train Epoch: 429 	Average Loss: 15.7659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9850

Learning rate: 0.00019909316796614494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 16.9337	Cost: 23.21s
Train Epoch: 430 [20480/90000 (23%)]	Loss: 15.6276	Cost: 6.20s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 15.6038	Cost: 6.06s
Train Epoch: 430 [61440/90000 (68%)]	Loss: 15.5873	Cost: 5.85s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 15.6219	Cost: 5.71s
Train Epoch: 430 	Average Loss: 15.7495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0585

Learning rate: 0.00019908894182223372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 16.8871	Cost: 22.90s
Train Epoch: 431 [20480/90000 (23%)]	Loss: 15.6617	Cost: 6.09s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 15.7877	Cost: 6.07s
Train Epoch: 431 [61440/90000 (68%)]	Loss: 15.6582	Cost: 5.90s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 15.7652	Cost: 5.70s
Train Epoch: 431 	Average Loss: 15.7752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0114

Learning rate: 0.00019908470589863605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 16.9262	Cost: 21.07s
Train Epoch: 432 [20480/90000 (23%)]	Loss: 15.5695	Cost: 6.60s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 15.7658	Cost: 6.15s
Train Epoch: 432 [61440/90000 (68%)]	Loss: 15.7384	Cost: 5.85s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 15.7408	Cost: 5.72s
Train Epoch: 432 	Average Loss: 15.7550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9248

Learning rate: 0.00019908046019576994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 16.9594	Cost: 20.28s
Train Epoch: 433 [20480/90000 (23%)]	Loss: 15.6480	Cost: 6.10s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 15.6521	Cost: 6.15s
Train Epoch: 433 [61440/90000 (68%)]	Loss: 15.6105	Cost: 5.89s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 15.8286	Cost: 5.75s
Train Epoch: 433 	Average Loss: 15.7673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0418

Learning rate: 0.00019907620471405445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 16.8381	Cost: 19.64s
Train Epoch: 434 [20480/90000 (23%)]	Loss: 15.6806	Cost: 6.18s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 15.6562	Cost: 6.13s
Train Epoch: 434 [61440/90000 (68%)]	Loss: 15.5148	Cost: 5.94s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 15.6693	Cost: 5.77s
Train Epoch: 434 	Average Loss: 15.7376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9887

Learning rate: 0.0001990719394539096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 16.9691	Cost: 19.81s
Train Epoch: 435 [20480/90000 (23%)]	Loss: 15.5729	Cost: 6.19s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 15.6551	Cost: 6.38s
Train Epoch: 435 [61440/90000 (68%)]	Loss: 15.5842	Cost: 6.01s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 15.7769	Cost: 5.71s
Train Epoch: 435 	Average Loss: 15.7414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0791

Learning rate: 0.0001990676644157563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 16.9546	Cost: 20.30s
Train Epoch: 436 [20480/90000 (23%)]	Loss: 15.6557	Cost: 6.21s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 15.6256	Cost: 6.30s
Train Epoch: 436 [61440/90000 (68%)]	Loss: 15.4395	Cost: 5.90s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 15.6633	Cost: 5.71s
Train Epoch: 436 	Average Loss: 15.7278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9967

Learning rate: 0.00019906337960001657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 17.0527	Cost: 20.28s
Train Epoch: 437 [20480/90000 (23%)]	Loss: 15.6871	Cost: 6.18s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 15.6035	Cost: 6.45s
Train Epoch: 437 [61440/90000 (68%)]	Loss: 15.4235	Cost: 5.84s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 15.7094	Cost: 5.75s
Train Epoch: 437 	Average Loss: 15.7253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0359

Learning rate: 0.0001990590850071132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 16.8675	Cost: 19.52s
Train Epoch: 438 [20480/90000 (23%)]	Loss: 15.5293	Cost: 6.01s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 15.5256	Cost: 6.09s
Train Epoch: 438 [61440/90000 (68%)]	Loss: 15.5115	Cost: 5.91s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 15.7907	Cost: 5.75s
Train Epoch: 438 	Average Loss: 15.7188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0227

Learning rate: 0.0001990547806374701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 16.9450	Cost: 19.93s
Train Epoch: 439 [20480/90000 (23%)]	Loss: 15.6885	Cost: 5.98s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 15.5742	Cost: 6.37s
Train Epoch: 439 [61440/90000 (68%)]	Loss: 15.6087	Cost: 5.89s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 15.6465	Cost: 5.74s
Train Epoch: 439 	Average Loss: 15.7121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0725

Learning rate: 0.00019905046649151213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 17.0755	Cost: 19.28s
Train Epoch: 440 [20480/90000 (23%)]	Loss: 15.5739	Cost: 6.02s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 15.6848	Cost: 6.06s
Train Epoch: 440 [61440/90000 (68%)]	Loss: 15.4826	Cost: 6.05s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 15.6421	Cost: 5.98s
Train Epoch: 440 	Average Loss: 15.7066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0331

Learning rate: 0.00019904614256966498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 16.8495	Cost: 19.17s
Train Epoch: 441 [20480/90000 (23%)]	Loss: 15.6418	Cost: 6.05s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 15.5382	Cost: 5.96s
Train Epoch: 441 [61440/90000 (68%)]	Loss: 15.4733	Cost: 5.96s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 15.6861	Cost: 6.01s
Train Epoch: 441 	Average Loss: 15.6759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0639

Learning rate: 0.00019904180887235552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 17.0776	Cost: 20.02s
Train Epoch: 442 [20480/90000 (23%)]	Loss: 15.4428	Cost: 6.21s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 15.5392	Cost: 6.06s
Train Epoch: 442 [61440/90000 (68%)]	Loss: 15.6751	Cost: 5.86s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 15.6907	Cost: 5.87s
Train Epoch: 442 	Average Loss: 15.7040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0329

Learning rate: 0.0001990374654000114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 16.8309	Cost: 20.08s
Train Epoch: 443 [20480/90000 (23%)]	Loss: 15.5861	Cost: 6.06s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 15.5024	Cost: 6.07s
Train Epoch: 443 [61440/90000 (68%)]	Loss: 15.5841	Cost: 5.89s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 15.5458	Cost: 5.79s
Train Epoch: 443 	Average Loss: 15.6578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0280

Learning rate: 0.0001990331121530613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 16.9491	Cost: 19.74s
Train Epoch: 444 [20480/90000 (23%)]	Loss: 15.5548	Cost: 6.26s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 15.6663	Cost: 6.17s
Train Epoch: 444 [61440/90000 (68%)]	Loss: 15.5403	Cost: 6.01s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 15.6006	Cost: 5.74s
Train Epoch: 444 	Average Loss: 15.6720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0480

Learning rate: 0.0001990287491319349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 16.9079	Cost: 19.85s
Train Epoch: 445 [20480/90000 (23%)]	Loss: 15.7874	Cost: 6.04s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 15.5379	Cost: 6.02s
Train Epoch: 445 [61440/90000 (68%)]	Loss: 15.4775	Cost: 5.84s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 15.4952	Cost: 5.69s
Train Epoch: 445 	Average Loss: 15.6727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0593

Learning rate: 0.00019902437633706276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 17.0581	Cost: 20.02s
Train Epoch: 446 [20480/90000 (23%)]	Loss: 15.5660	Cost: 6.07s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 15.5573	Cost: 6.29s
Train Epoch: 446 [61440/90000 (68%)]	Loss: 15.5308	Cost: 5.86s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 15.6173	Cost: 5.88s
Train Epoch: 446 	Average Loss: 15.6653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0804

Learning rate: 0.0001990199937688765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 16.8130	Cost: 20.80s
Train Epoch: 447 [20480/90000 (23%)]	Loss: 15.5902	Cost: 5.96s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 15.5189	Cost: 6.46s
Train Epoch: 447 [61440/90000 (68%)]	Loss: 15.5214	Cost: 5.82s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 15.5958	Cost: 5.89s
Train Epoch: 447 	Average Loss: 15.6223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0697

Learning rate: 0.00019901560142780868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 16.8098	Cost: 20.26s
Train Epoch: 448 [20480/90000 (23%)]	Loss: 15.5451	Cost: 6.00s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 15.4987	Cost: 6.25s
Train Epoch: 448 [61440/90000 (68%)]	Loss: 15.4397	Cost: 5.90s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 15.7806	Cost: 5.98s
Train Epoch: 448 	Average Loss: 15.6083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0643

Learning rate: 0.0001990111993142928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 17.1121	Cost: 20.47s
Train Epoch: 449 [20480/90000 (23%)]	Loss: 15.5519	Cost: 6.03s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 15.5716	Cost: 6.10s
Train Epoch: 449 [61440/90000 (68%)]	Loss: 15.4421	Cost: 5.84s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 15.5255	Cost: 5.80s
Train Epoch: 449 	Average Loss: 15.6517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0995

Learning rate: 0.0001990067874287633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 17.0946	Cost: 20.36s
Train Epoch: 450 [20480/90000 (23%)]	Loss: 15.5144	Cost: 6.10s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 15.4929	Cost: 6.12s
Train Epoch: 450 [61440/90000 (68%)]	Loss: 15.4121	Cost: 5.92s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 15.4327	Cost: 5.83s
Train Epoch: 450 	Average Loss: 15.6094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0937

Learning rate: 0.00019900236577165563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 16.9469	Cost: 20.30s
Train Epoch: 451 [20480/90000 (23%)]	Loss: 15.6999	Cost: 6.17s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 15.5319	Cost: 6.47s
Train Epoch: 451 [61440/90000 (68%)]	Loss: 15.3778	Cost: 5.89s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 15.6157	Cost: 5.84s
Train Epoch: 451 	Average Loss: 15.6159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0950

Learning rate: 0.00019899793434340619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 17.0253	Cost: 20.78s
Train Epoch: 452 [20480/90000 (23%)]	Loss: 15.4923	Cost: 6.14s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 15.5105	Cost: 6.15s
Train Epoch: 452 [61440/90000 (68%)]	Loss: 15.4846	Cost: 5.97s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 15.5006	Cost: 5.80s
Train Epoch: 452 	Average Loss: 15.6055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0304

Learning rate: 0.00019899349314445237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 17.0835	Cost: 21.83s
Train Epoch: 453 [20480/90000 (23%)]	Loss: 15.4736	Cost: 6.06s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 15.5612	Cost: 6.35s
Train Epoch: 453 [61440/90000 (68%)]	Loss: 15.3482	Cost: 5.94s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 15.5072	Cost: 5.80s
Train Epoch: 453 	Average Loss: 15.6023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1121

Learning rate: 0.00019898904217523244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 17.0370	Cost: 20.26s
Train Epoch: 454 [20480/90000 (23%)]	Loss: 15.5467	Cost: 6.14s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 15.5228	Cost: 6.11s
Train Epoch: 454 [61440/90000 (68%)]	Loss: 15.4281	Cost: 5.98s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 15.6904	Cost: 5.86s
Train Epoch: 454 	Average Loss: 15.5901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1182

Learning rate: 0.00019898458143618574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 17.0011	Cost: 20.66s
Train Epoch: 455 [20480/90000 (23%)]	Loss: 15.5206	Cost: 6.12s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 15.5469	Cost: 6.64s
Train Epoch: 455 [61440/90000 (68%)]	Loss: 15.4303	Cost: 6.16s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 15.3702	Cost: 5.79s
Train Epoch: 455 	Average Loss: 15.5751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0541

Learning rate: 0.0001989801109277525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 17.0332	Cost: 21.24s
Train Epoch: 456 [20480/90000 (23%)]	Loss: 15.5057	Cost: 6.06s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 15.4889	Cost: 6.19s
Train Epoch: 456 [61440/90000 (68%)]	Loss: 15.5692	Cost: 5.91s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 15.4824	Cost: 5.85s
Train Epoch: 456 	Average Loss: 15.5824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0824

Learning rate: 0.000198975630650374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 17.0397	Cost: 21.93s
Train Epoch: 457 [20480/90000 (23%)]	Loss: 15.4910	Cost: 6.06s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 15.5065	Cost: 6.15s
Train Epoch: 457 [61440/90000 (68%)]	Loss: 15.3041	Cost: 5.93s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 15.5546	Cost: 5.83s
Train Epoch: 457 	Average Loss: 15.5657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0885

Learning rate: 0.0001989711406044923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 17.1921	Cost: 21.00s
Train Epoch: 458 [20480/90000 (23%)]	Loss: 15.4314	Cost: 6.13s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 15.5035	Cost: 6.58s
Train Epoch: 458 [61440/90000 (68%)]	Loss: 15.4069	Cost: 5.85s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 15.4706	Cost: 5.88s
Train Epoch: 458 	Average Loss: 15.5731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0975

Learning rate: 0.0001989666407905507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 17.1331	Cost: 21.45s
Train Epoch: 459 [20480/90000 (23%)]	Loss: 15.4101	Cost: 6.14s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 15.3520	Cost: 6.15s
Train Epoch: 459 [61440/90000 (68%)]	Loss: 15.5115	Cost: 5.89s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 15.6037	Cost: 5.87s
Train Epoch: 459 	Average Loss: 15.5256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1267

Learning rate: 0.00019896213120899325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 17.0922	Cost: 22.07s
Train Epoch: 460 [20480/90000 (23%)]	Loss: 15.4209	Cost: 6.14s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 15.5255	Cost: 6.25s
Train Epoch: 460 [61440/90000 (68%)]	Loss: 15.4285	Cost: 5.93s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 15.4977	Cost: 6.03s
Train Epoch: 460 	Average Loss: 15.5463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0512

Learning rate: 0.00019895761186026497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 17.1467	Cost: 21.52s
Train Epoch: 461 [20480/90000 (23%)]	Loss: 15.5801	Cost: 6.06s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 15.3844	Cost: 6.45s
Train Epoch: 461 [61440/90000 (68%)]	Loss: 15.3681	Cost: 5.90s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 15.4407	Cost: 6.04s
Train Epoch: 461 	Average Loss: 15.5526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0779

Learning rate: 0.000198953082744812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 16.9789	Cost: 21.04s
Train Epoch: 462 [20480/90000 (23%)]	Loss: 15.4266	Cost: 6.09s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 15.4358	Cost: 6.62s
Train Epoch: 462 [61440/90000 (68%)]	Loss: 15.3736	Cost: 6.02s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 15.3321	Cost: 6.06s
Train Epoch: 462 	Average Loss: 15.5353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0940

Learning rate: 0.0001989485438630813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 16.9952	Cost: 21.01s
Train Epoch: 463 [20480/90000 (23%)]	Loss: 15.4918	Cost: 6.03s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 15.4743	Cost: 6.08s
Train Epoch: 463 [61440/90000 (68%)]	Loss: 15.3359	Cost: 5.90s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 15.3559	Cost: 5.78s
Train Epoch: 463 	Average Loss: 15.5155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1734

Learning rate: 0.00019894399521552084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 17.2270	Cost: 20.98s
Train Epoch: 464 [20480/90000 (23%)]	Loss: 15.4222	Cost: 6.14s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 15.3368	Cost: 6.63s
Train Epoch: 464 [61440/90000 (68%)]	Loss: 15.3702	Cost: 5.94s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 15.5390	Cost: 5.91s
Train Epoch: 464 	Average Loss: 15.5056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1313

Learning rate: 0.0001989394368025795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 17.2452	Cost: 20.13s
Train Epoch: 465 [20480/90000 (23%)]	Loss: 15.3865	Cost: 6.10s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 15.4937	Cost: 6.30s
Train Epoch: 465 [61440/90000 (68%)]	Loss: 15.3928	Cost: 5.94s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 15.4688	Cost: 5.82s
Train Epoch: 465 	Average Loss: 15.5074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1844

Learning rate: 0.0001989348686247073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 17.1073	Cost: 20.65s
Train Epoch: 466 [20480/90000 (23%)]	Loss: 15.4441	Cost: 6.13s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 15.3283	Cost: 6.50s
Train Epoch: 466 [61440/90000 (68%)]	Loss: 15.1958	Cost: 6.03s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 15.3183	Cost: 6.02s
Train Epoch: 466 	Average Loss: 15.4945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1923

Learning rate: 0.000198930290682355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 17.0633	Cost: 20.52s
Train Epoch: 467 [20480/90000 (23%)]	Loss: 15.4792	Cost: 6.14s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 15.5598	Cost: 6.45s
Train Epoch: 467 [61440/90000 (68%)]	Loss: 15.2027	Cost: 5.97s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 15.3515	Cost: 5.98s
Train Epoch: 467 	Average Loss: 15.4817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0737

Learning rate: 0.00019892570297597447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 17.0206	Cost: 22.32s
Train Epoch: 468 [20480/90000 (23%)]	Loss: 15.2337	Cost: 5.90s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 15.4861	Cost: 6.45s
Train Epoch: 468 [61440/90000 (68%)]	Loss: 15.3520	Cost: 5.93s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 15.4641	Cost: 6.19s
Train Epoch: 468 	Average Loss: 15.4684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1701

Learning rate: 0.00019892110550601846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 17.0150	Cost: 20.69s
Train Epoch: 469 [20480/90000 (23%)]	Loss: 15.2977	Cost: 6.20s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 15.4184	Cost: 6.26s
Train Epoch: 469 [61440/90000 (68%)]	Loss: 15.3306	Cost: 5.90s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 15.4074	Cost: 5.86s
Train Epoch: 469 	Average Loss: 15.4687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0992

Learning rate: 0.00019891649827294077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 17.1232	Cost: 20.89s
Train Epoch: 470 [20480/90000 (23%)]	Loss: 15.1926	Cost: 6.13s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 15.3566	Cost: 6.19s
Train Epoch: 470 [61440/90000 (68%)]	Loss: 15.1927	Cost: 5.92s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 15.4421	Cost: 5.80s
Train Epoch: 470 	Average Loss: 15.4498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1429

Learning rate: 0.00019891188127719607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 17.2343	Cost: 21.93s
Train Epoch: 471 [20480/90000 (23%)]	Loss: 15.4123	Cost: 5.98s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 15.2092	Cost: 6.46s
Train Epoch: 471 [61440/90000 (68%)]	Loss: 15.4288	Cost: 5.89s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 15.5026	Cost: 6.17s
Train Epoch: 471 	Average Loss: 15.4525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1913

Learning rate: 0.00019890725451924011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 17.0518	Cost: 21.09s
Train Epoch: 472 [20480/90000 (23%)]	Loss: 15.4495	Cost: 6.05s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 15.3766	Cost: 6.66s
Train Epoch: 472 [61440/90000 (68%)]	Loss: 15.2792	Cost: 5.93s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 15.2989	Cost: 6.05s
Train Epoch: 472 	Average Loss: 15.4455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1122

Learning rate: 0.00019890261799952944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 17.0944	Cost: 20.80s
Train Epoch: 473 [20480/90000 (23%)]	Loss: 15.3423	Cost: 6.04s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 15.2539	Cost: 6.13s
Train Epoch: 473 [61440/90000 (68%)]	Loss: 15.3020	Cost: 5.90s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 15.3402	Cost: 5.86s
Train Epoch: 473 	Average Loss: 15.4360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1971

Learning rate: 0.00019889797171852172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 17.2502	Cost: 22.74s
Train Epoch: 474 [20480/90000 (23%)]	Loss: 15.4498	Cost: 6.13s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 15.4917	Cost: 6.06s
Train Epoch: 474 [61440/90000 (68%)]	Loss: 15.1765	Cost: 5.96s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 15.2433	Cost: 5.91s
Train Epoch: 474 	Average Loss: 15.4449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2253

Learning rate: 0.0001988933156766755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 17.0719	Cost: 22.12s
Train Epoch: 475 [20480/90000 (23%)]	Loss: 15.3095	Cost: 6.15s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 15.4260	Cost: 6.24s
Train Epoch: 475 [61440/90000 (68%)]	Loss: 15.0669	Cost: 5.95s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 15.1481	Cost: 5.93s
Train Epoch: 475 	Average Loss: 15.3912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2261

Learning rate: 0.00019888864987445035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 17.1647	Cost: 22.67s
Train Epoch: 476 [20480/90000 (23%)]	Loss: 15.3560	Cost: 6.16s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 15.3639	Cost: 6.12s
Train Epoch: 476 [61440/90000 (68%)]	Loss: 15.2586	Cost: 5.87s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 15.2532	Cost: 5.84s
Train Epoch: 476 	Average Loss: 15.4364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2539

Learning rate: 0.00019888397431230674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 17.1647	Cost: 24.23s
Train Epoch: 477 [20480/90000 (23%)]	Loss: 15.4119	Cost: 6.15s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 15.3903	Cost: 6.85s
Train Epoch: 477 [61440/90000 (68%)]	Loss: 15.2323	Cost: 6.07s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 15.4615	Cost: 5.65s
Train Epoch: 477 	Average Loss: 15.4119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2225

Learning rate: 0.00019887928899070613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 17.0813	Cost: 23.85s
Train Epoch: 478 [20480/90000 (23%)]	Loss: 15.3144	Cost: 6.11s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 15.2501	Cost: 6.12s
Train Epoch: 478 [61440/90000 (68%)]	Loss: 15.1104	Cost: 5.98s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 15.4485	Cost: 5.79s
Train Epoch: 478 	Average Loss: 15.3838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2157

Learning rate: 0.00019887459391011093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 17.1219	Cost: 23.33s
Train Epoch: 479 [20480/90000 (23%)]	Loss: 15.2109	Cost: 6.33s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 15.2799	Cost: 6.16s
Train Epoch: 479 [61440/90000 (68%)]	Loss: 15.1535	Cost: 5.95s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 15.2588	Cost: 5.91s
Train Epoch: 479 	Average Loss: 15.3720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2655

Learning rate: 0.0001988698890709845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 17.1997	Cost: 23.76s
Train Epoch: 480 [20480/90000 (23%)]	Loss: 15.3210	Cost: 6.22s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 15.3604	Cost: 6.37s
Train Epoch: 480 [61440/90000 (68%)]	Loss: 15.1916	Cost: 5.93s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 15.1757	Cost: 6.03s
Train Epoch: 480 	Average Loss: 15.3858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1667

Learning rate: 0.0001988651744737913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 17.1357	Cost: 23.65s
Train Epoch: 481 [20480/90000 (23%)]	Loss: 15.2140	Cost: 6.05s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 15.1712	Cost: 6.17s
Train Epoch: 481 [61440/90000 (68%)]	Loss: 15.1693	Cost: 6.04s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 15.3640	Cost: 5.80s
Train Epoch: 481 	Average Loss: 15.3683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1959

Learning rate: 0.00019886045011899655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 17.1869	Cost: 21.25s
Train Epoch: 482 [20480/90000 (23%)]	Loss: 15.2422	Cost: 6.23s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 15.2608	Cost: 6.16s
Train Epoch: 482 [61440/90000 (68%)]	Loss: 15.2339	Cost: 5.99s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 15.4320	Cost: 6.02s
Train Epoch: 482 	Average Loss: 15.3655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2160

Learning rate: 0.00019885571600706652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 17.0549	Cost: 21.36s
Train Epoch: 483 [20480/90000 (23%)]	Loss: 15.3867	Cost: 6.19s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 15.4160	Cost: 6.61s
Train Epoch: 483 [61440/90000 (68%)]	Loss: 15.1362	Cost: 5.97s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 15.2507	Cost: 5.87s
Train Epoch: 483 	Average Loss: 15.3576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2159

Learning rate: 0.00019885097213846847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 17.1801	Cost: 20.75s
Train Epoch: 484 [20480/90000 (23%)]	Loss: 15.3908	Cost: 6.35s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 15.3139	Cost: 6.31s
Train Epoch: 484 [61440/90000 (68%)]	Loss: 15.1895	Cost: 5.93s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 15.3989	Cost: 5.88s
Train Epoch: 484 	Average Loss: 15.3825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2222

Learning rate: 0.00019884621851367065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 17.1056	Cost: 20.51s
Train Epoch: 485 [20480/90000 (23%)]	Loss: 15.2599	Cost: 6.11s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 15.3355	Cost: 6.22s
Train Epoch: 485 [61440/90000 (68%)]	Loss: 15.3043	Cost: 6.01s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 15.2799	Cost: 5.79s
Train Epoch: 485 	Average Loss: 15.3529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2692

Learning rate: 0.00019884145513314214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 17.0592	Cost: 20.58s
Train Epoch: 486 [20480/90000 (23%)]	Loss: 15.2076	Cost: 6.02s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 15.2505	Cost: 6.86s
Train Epoch: 486 [61440/90000 (68%)]	Loss: 15.0237	Cost: 5.97s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 15.2431	Cost: 6.03s
Train Epoch: 486 	Average Loss: 15.3211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2682

Learning rate: 0.00019883668199735307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 17.1869	Cost: 20.50s
Train Epoch: 487 [20480/90000 (23%)]	Loss: 15.3028	Cost: 6.06s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 15.1220	Cost: 6.08s
Train Epoch: 487 [61440/90000 (68%)]	Loss: 15.0814	Cost: 6.13s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 15.1948	Cost: 6.14s
Train Epoch: 487 	Average Loss: 15.3331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2062

Learning rate: 0.00019883189910677464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 17.1838	Cost: 20.55s
Train Epoch: 488 [20480/90000 (23%)]	Loss: 15.1942	Cost: 6.18s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 15.1323	Cost: 6.64s
Train Epoch: 488 [61440/90000 (68%)]	Loss: 15.1395	Cost: 6.13s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 15.3033	Cost: 6.85s
Train Epoch: 488 	Average Loss: 15.3082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2058

Learning rate: 0.00019882710646187875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 17.1342	Cost: 20.89s
Train Epoch: 489 [20480/90000 (23%)]	Loss: 15.1015	Cost: 5.97s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 15.1586	Cost: 6.16s
Train Epoch: 489 [61440/90000 (68%)]	Loss: 15.0888	Cost: 5.89s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 15.1092	Cost: 6.05s
Train Epoch: 489 	Average Loss: 15.2924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2075

Learning rate: 0.00019882230406313855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 17.1080	Cost: 20.40s
Train Epoch: 490 [20480/90000 (23%)]	Loss: 15.2842	Cost: 6.04s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 15.1619	Cost: 6.44s
Train Epoch: 490 [61440/90000 (68%)]	Loss: 15.1543	Cost: 5.85s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 15.2077	Cost: 5.78s
Train Epoch: 490 	Average Loss: 15.2986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2433

Learning rate: 0.00019881749191102795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 17.1520	Cost: 19.83s
Train Epoch: 491 [20480/90000 (23%)]	Loss: 15.2095	Cost: 6.04s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 15.1442	Cost: 6.17s
Train Epoch: 491 [61440/90000 (68%)]	Loss: 15.0061	Cost: 6.06s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 15.2371	Cost: 5.82s
Train Epoch: 491 	Average Loss: 15.2763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2900

Learning rate: 0.00019881267000602186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 17.2053	Cost: 20.41s
Train Epoch: 492 [20480/90000 (23%)]	Loss: 15.1336	Cost: 6.15s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 15.2652	Cost: 6.31s
Train Epoch: 492 [61440/90000 (68%)]	Loss: 15.0550	Cost: 5.91s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 15.1498	Cost: 5.80s
Train Epoch: 492 	Average Loss: 15.2887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2924

Learning rate: 0.00019880783834859626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 17.1182	Cost: 19.91s
Train Epoch: 493 [20480/90000 (23%)]	Loss: 15.2088	Cost: 6.08s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 15.2520	Cost: 6.10s
Train Epoch: 493 [61440/90000 (68%)]	Loss: 15.0066	Cost: 5.94s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 15.0864	Cost: 5.75s
Train Epoch: 493 	Average Loss: 15.2730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3001

Learning rate: 0.000198802996939228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 17.0511	Cost: 21.16s
Train Epoch: 494 [20480/90000 (23%)]	Loss: 15.1403	Cost: 6.05s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 15.0904	Cost: 6.15s
Train Epoch: 494 [61440/90000 (68%)]	Loss: 15.0955	Cost: 5.89s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 15.1061	Cost: 5.72s
Train Epoch: 494 	Average Loss: 15.2659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3166

Learning rate: 0.0001987981457783948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 17.3150	Cost: 20.17s
Train Epoch: 495 [20480/90000 (23%)]	Loss: 15.1570	Cost: 6.17s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 15.2460	Cost: 6.22s
Train Epoch: 495 [61440/90000 (68%)]	Loss: 15.0202	Cost: 5.93s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 15.1562	Cost: 5.73s
Train Epoch: 495 	Average Loss: 15.2601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2500

Learning rate: 0.00019879328486657562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 17.3595	Cost: 20.45s
Train Epoch: 496 [20480/90000 (23%)]	Loss: 15.1379	Cost: 6.30s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 15.0588	Cost: 6.13s
Train Epoch: 496 [61440/90000 (68%)]	Loss: 14.9037	Cost: 5.96s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 15.1075	Cost: 5.76s
Train Epoch: 496 	Average Loss: 15.2648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3211

Learning rate: 0.0001987884142042501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 17.2077	Cost: 20.67s
Train Epoch: 497 [20480/90000 (23%)]	Loss: 15.3267	Cost: 6.05s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 15.3438	Cost: 6.26s
Train Epoch: 497 [61440/90000 (68%)]	Loss: 15.1706	Cost: 5.89s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 15.3071	Cost: 5.76s
Train Epoch: 497 	Average Loss: 15.3259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2894

Learning rate: 0.00019878353379189899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 17.2970	Cost: 21.74s
Train Epoch: 498 [20480/90000 (23%)]	Loss: 15.1418	Cost: 6.10s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 15.2073	Cost: 6.21s
Train Epoch: 498 [61440/90000 (68%)]	Loss: 15.1241	Cost: 5.93s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 15.1627	Cost: 5.72s
Train Epoch: 498 	Average Loss: 15.2694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2768

Learning rate: 0.00019877864363000396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 17.1151	Cost: 21.99s
Train Epoch: 499 [20480/90000 (23%)]	Loss: 15.1095	Cost: 5.80s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 15.2083	Cost: 6.64s
Train Epoch: 499 [61440/90000 (68%)]	Loss: 15.0366	Cost: 6.09s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 15.0969	Cost: 5.79s
Train Epoch: 499 	Average Loss: 15.2512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3340

Learning rate: 0.00019877374371904765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 17.2835	Cost: 22.50s
Train Epoch: 500 [20480/90000 (23%)]	Loss: 15.0492	Cost: 6.13s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 15.1768	Cost: 6.28s
Train Epoch: 500 [61440/90000 (68%)]	Loss: 14.9377	Cost: 5.92s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 15.0943	Cost: 5.77s
Train Epoch: 500 	Average Loss: 15.2200
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3503

Learning rate: 0.00019876883405951367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: 17.3060	Cost: 20.75s
Train Epoch: 501 [20480/90000 (23%)]	Loss: 15.2038	Cost: 6.22s
Train Epoch: 501 [40960/90000 (45%)]	Loss: 15.1196	Cost: 6.11s
Train Epoch: 501 [61440/90000 (68%)]	Loss: 14.8458	Cost: 5.90s
Train Epoch: 501 [81920/90000 (91%)]	Loss: 15.0842	Cost: 5.78s
Train Epoch: 501 	Average Loss: 15.2080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2505

Learning rate: 0.00019876391465188656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: 17.1953	Cost: 22.25s
Train Epoch: 502 [20480/90000 (23%)]	Loss: 15.0587	Cost: 6.13s
Train Epoch: 502 [40960/90000 (45%)]	Loss: 15.1441	Cost: 6.17s
Train Epoch: 502 [61440/90000 (68%)]	Loss: 15.1205	Cost: 5.89s
Train Epoch: 502 [81920/90000 (91%)]	Loss: 15.2986	Cost: 5.75s
Train Epoch: 502 	Average Loss: 15.2493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3158

Learning rate: 0.00019875898549665186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: 17.1328	Cost: 26.32s
Train Epoch: 503 [20480/90000 (23%)]	Loss: 15.1210	Cost: 6.02s
Train Epoch: 503 [40960/90000 (45%)]	Loss: 14.9824	Cost: 6.07s
Train Epoch: 503 [61440/90000 (68%)]	Loss: 15.0782	Cost: 5.85s
Train Epoch: 503 [81920/90000 (91%)]	Loss: 15.0895	Cost: 5.78s
Train Epoch: 503 	Average Loss: 15.2005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3275

Learning rate: 0.0001987540465942961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: 17.1073	Cost: 24.06s
Train Epoch: 504 [20480/90000 (23%)]	Loss: 15.0639	Cost: 5.93s
Train Epoch: 504 [40960/90000 (45%)]	Loss: 15.1256	Cost: 6.55s
Train Epoch: 504 [61440/90000 (68%)]	Loss: 14.9252	Cost: 5.94s
Train Epoch: 504 [81920/90000 (91%)]	Loss: 15.2598	Cost: 5.82s
Train Epoch: 504 	Average Loss: 15.1807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3389

Learning rate: 0.00019874909794530664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: 17.3486	Cost: 24.33s
Train Epoch: 505 [20480/90000 (23%)]	Loss: 15.1254	Cost: 6.12s
Train Epoch: 505 [40960/90000 (45%)]	Loss: 14.9856	Cost: 6.05s
Train Epoch: 505 [61440/90000 (68%)]	Loss: 15.0462	Cost: 5.86s
Train Epoch: 505 [81920/90000 (91%)]	Loss: 15.2364	Cost: 5.70s
Train Epoch: 505 	Average Loss: 15.1935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3276

Learning rate: 0.00019874413955017195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: 17.2503	Cost: 23.61s
Train Epoch: 506 [20480/90000 (23%)]	Loss: 14.9690	Cost: 6.12s
Train Epoch: 506 [40960/90000 (45%)]	Loss: 15.1272	Cost: 6.62s
Train Epoch: 506 [61440/90000 (68%)]	Loss: 15.0268	Cost: 5.99s
Train Epoch: 506 [81920/90000 (91%)]	Loss: 15.0648	Cost: 5.99s
Train Epoch: 506 	Average Loss: 15.1778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3245

Learning rate: 0.00019873917140938142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: 17.2444	Cost: 22.47s
Train Epoch: 507 [20480/90000 (23%)]	Loss: 15.0403	Cost: 6.13s
Train Epoch: 507 [40960/90000 (45%)]	Loss: 14.9598	Cost: 6.24s
Train Epoch: 507 [61440/90000 (68%)]	Loss: 14.9548	Cost: 5.96s
Train Epoch: 507 [81920/90000 (91%)]	Loss: 15.1313	Cost: 5.90s
Train Epoch: 507 	Average Loss: 15.1590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3771

Learning rate: 0.00019873419352342536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: 17.2839	Cost: 22.94s
Train Epoch: 508 [20480/90000 (23%)]	Loss: 15.0332	Cost: 6.25s
Train Epoch: 508 [40960/90000 (45%)]	Loss: 14.9163	Cost: 6.28s
Train Epoch: 508 [61440/90000 (68%)]	Loss: 14.8575	Cost: 5.95s
Train Epoch: 508 [81920/90000 (91%)]	Loss: 15.0457	Cost: 5.91s
Train Epoch: 508 	Average Loss: 15.1331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3108

Learning rate: 0.00019872920589279508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: 17.1285	Cost: 20.51s
Train Epoch: 509 [20480/90000 (23%)]	Loss: 14.8863	Cost: 6.30s
Train Epoch: 509 [40960/90000 (45%)]	Loss: 15.1541	Cost: 6.46s
Train Epoch: 509 [61440/90000 (68%)]	Loss: 14.9799	Cost: 5.94s
Train Epoch: 509 [81920/90000 (91%)]	Loss: 14.9999	Cost: 6.11s
Train Epoch: 509 	Average Loss: 15.1264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4303

Learning rate: 0.0001987242085179828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: 17.2297	Cost: 20.72s
Train Epoch: 510 [20480/90000 (23%)]	Loss: 15.0972	Cost: 5.94s
Train Epoch: 510 [40960/90000 (45%)]	Loss: 14.9519	Cost: 6.77s
Train Epoch: 510 [61440/90000 (68%)]	Loss: 14.8431	Cost: 6.08s
Train Epoch: 510 [81920/90000 (91%)]	Loss: 14.9844	Cost: 5.77s
Train Epoch: 510 	Average Loss: 15.1372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3908

Learning rate: 0.00019871920139948181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: 17.3884	Cost: 20.45s
Train Epoch: 511 [20480/90000 (23%)]	Loss: 15.0394	Cost: 5.99s
Train Epoch: 511 [40960/90000 (45%)]	Loss: 15.0170	Cost: 6.34s
Train Epoch: 511 [61440/90000 (68%)]	Loss: 14.8188	Cost: 6.01s
Train Epoch: 511 [81920/90000 (91%)]	Loss: 15.0147	Cost: 5.85s
Train Epoch: 511 	Average Loss: 15.1304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3429

Learning rate: 0.00019871418453778627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: 17.2633	Cost: 20.27s
Train Epoch: 512 [20480/90000 (23%)]	Loss: 15.0206	Cost: 6.09s
Train Epoch: 512 [40960/90000 (45%)]	Loss: 15.0816	Cost: 6.25s
Train Epoch: 512 [61440/90000 (68%)]	Loss: 14.9241	Cost: 6.06s
Train Epoch: 512 [81920/90000 (91%)]	Loss: 14.8946	Cost: 6.06s
Train Epoch: 512 	Average Loss: 15.1350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3831

Learning rate: 0.00019870915793339126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: 17.3012	Cost: 20.84s
Train Epoch: 513 [20480/90000 (23%)]	Loss: 14.9616	Cost: 6.03s
Train Epoch: 513 [40960/90000 (45%)]	Loss: 14.8676	Cost: 6.29s
Train Epoch: 513 [61440/90000 (68%)]	Loss: 14.8763	Cost: 6.12s
Train Epoch: 513 [81920/90000 (91%)]	Loss: 15.0739	Cost: 6.61s
Train Epoch: 513 	Average Loss: 15.1152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3430

Learning rate: 0.00019870412158679292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: 17.2858	Cost: 21.14s
Train Epoch: 514 [20480/90000 (23%)]	Loss: 14.9089	Cost: 5.96s
Train Epoch: 514 [40960/90000 (45%)]	Loss: 14.8468	Cost: 6.06s
Train Epoch: 514 [61440/90000 (68%)]	Loss: 14.8127	Cost: 5.91s
Train Epoch: 514 [81920/90000 (91%)]	Loss: 15.0664	Cost: 6.01s
Train Epoch: 514 	Average Loss: 15.0737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4288

Learning rate: 0.00019869907549848836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: 17.3942	Cost: 21.66s
Train Epoch: 515 [20480/90000 (23%)]	Loss: 14.8671	Cost: 6.05s
Train Epoch: 515 [40960/90000 (45%)]	Loss: 14.9406	Cost: 6.72s
Train Epoch: 515 [61440/90000 (68%)]	Loss: 15.0162	Cost: 5.89s
Train Epoch: 515 [81920/90000 (91%)]	Loss: 14.9504	Cost: 6.09s
Train Epoch: 515 	Average Loss: 15.0810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4192

Learning rate: 0.0001986940196689756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: 17.2117	Cost: 20.85s
Train Epoch: 516 [20480/90000 (23%)]	Loss: 15.0020	Cost: 6.12s
Train Epoch: 516 [40960/90000 (45%)]	Loss: 14.9326	Cost: 6.12s
Train Epoch: 516 [61440/90000 (68%)]	Loss: 14.8131	Cost: 5.91s
Train Epoch: 516 [81920/90000 (91%)]	Loss: 15.0111	Cost: 5.74s
Train Epoch: 516 	Average Loss: 15.0678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4818

Learning rate: 0.00019868895409875357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: 17.4062	Cost: 20.50s
Train Epoch: 517 [20480/90000 (23%)]	Loss: 14.9717	Cost: 6.08s
Train Epoch: 517 [40960/90000 (45%)]	Loss: 14.9448	Cost: 6.27s
Train Epoch: 517 [61440/90000 (68%)]	Loss: 14.8755	Cost: 5.99s
Train Epoch: 517 [81920/90000 (91%)]	Loss: 15.1365	Cost: 5.73s
Train Epoch: 517 	Average Loss: 15.0723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3958

Learning rate: 0.00019868387878832229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: 17.4407	Cost: 20.40s
Train Epoch: 518 [20480/90000 (23%)]	Loss: 14.9955	Cost: 6.09s
Train Epoch: 518 [40960/90000 (45%)]	Loss: 15.0852	Cost: 6.17s
Train Epoch: 518 [61440/90000 (68%)]	Loss: 14.8096	Cost: 5.87s
Train Epoch: 518 [81920/90000 (91%)]	Loss: 15.0286	Cost: 5.76s
Train Epoch: 518 	Average Loss: 15.0924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4277

Learning rate: 0.00019867879373818264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: 17.2337	Cost: 19.91s
Train Epoch: 519 [20480/90000 (23%)]	Loss: 14.8239	Cost: 6.16s
Train Epoch: 519 [40960/90000 (45%)]	Loss: 15.0274	Cost: 6.13s
Train Epoch: 519 [61440/90000 (68%)]	Loss: 14.8163	Cost: 5.93s
Train Epoch: 519 [81920/90000 (91%)]	Loss: 14.9921	Cost: 5.82s
Train Epoch: 519 	Average Loss: 15.0674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3917

Learning rate: 0.00019867369894883648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: 17.5236	Cost: 19.99s
Train Epoch: 520 [20480/90000 (23%)]	Loss: 15.0065	Cost: 6.10s
Train Epoch: 520 [40960/90000 (45%)]	Loss: 14.9900	Cost: 6.14s
Train Epoch: 520 [61440/90000 (68%)]	Loss: 14.7586	Cost: 5.89s
Train Epoch: 520 [81920/90000 (91%)]	Loss: 14.8745	Cost: 5.77s
Train Epoch: 520 	Average Loss: 15.0518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4485

Learning rate: 0.0001986685944207867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: 17.4102	Cost: 21.07s
Train Epoch: 521 [20480/90000 (23%)]	Loss: 14.9190	Cost: 6.17s
Train Epoch: 521 [40960/90000 (45%)]	Loss: 14.9202	Cost: 6.10s
Train Epoch: 521 [61440/90000 (68%)]	Loss: 14.8306	Cost: 5.87s
Train Epoch: 521 [81920/90000 (91%)]	Loss: 14.9242	Cost: 5.74s
Train Epoch: 521 	Average Loss: 15.0647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4285

Learning rate: 0.00019866348015453705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 17.3831	Cost: 20.46s
Train Epoch: 522 [20480/90000 (23%)]	Loss: 14.7692	Cost: 6.21s
Train Epoch: 522 [40960/90000 (45%)]	Loss: 14.8916	Cost: 6.08s
Train Epoch: 522 [61440/90000 (68%)]	Loss: 14.9058	Cost: 5.87s
Train Epoch: 522 [81920/90000 (91%)]	Loss: 14.9514	Cost: 5.79s
Train Epoch: 522 	Average Loss: 15.0299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4180

Learning rate: 0.0001986583561505923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: 17.4628	Cost: 20.48s
Train Epoch: 523 [20480/90000 (23%)]	Loss: 14.9090	Cost: 6.04s
Train Epoch: 523 [40960/90000 (45%)]	Loss: 14.7975	Cost: 6.27s
Train Epoch: 523 [61440/90000 (68%)]	Loss: 14.7819	Cost: 5.90s
Train Epoch: 523 [81920/90000 (91%)]	Loss: 14.9057	Cost: 5.76s
Train Epoch: 523 	Average Loss: 15.0259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3781

Learning rate: 0.0001986532224094582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: 17.3236	Cost: 21.99s
Train Epoch: 524 [20480/90000 (23%)]	Loss: 14.9878	Cost: 6.14s
Train Epoch: 524 [40960/90000 (45%)]	Loss: 14.8501	Cost: 6.23s
Train Epoch: 524 [61440/90000 (68%)]	Loss: 14.7894	Cost: 6.03s
Train Epoch: 524 [81920/90000 (91%)]	Loss: 15.0027	Cost: 5.73s
Train Epoch: 524 	Average Loss: 15.0179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4125

Learning rate: 0.00019864807893164133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: 17.2300	Cost: 20.95s
Train Epoch: 525 [20480/90000 (23%)]	Loss: 14.8145	Cost: 6.08s
Train Epoch: 525 [40960/90000 (45%)]	Loss: 14.8902	Cost: 6.45s
Train Epoch: 525 [61440/90000 (68%)]	Loss: 14.7634	Cost: 5.93s
Train Epoch: 525 [81920/90000 (91%)]	Loss: 14.9589	Cost: 6.10s
Train Epoch: 525 	Average Loss: 15.0154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4376

Learning rate: 0.00019864292571764947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: 17.4091	Cost: 21.93s
Train Epoch: 526 [20480/90000 (23%)]	Loss: 14.8976	Cost: 6.11s
Train Epoch: 526 [40960/90000 (45%)]	Loss: 14.8834	Cost: 6.17s
Train Epoch: 526 [61440/90000 (68%)]	Loss: 14.8826	Cost: 5.99s
Train Epoch: 526 [81920/90000 (91%)]	Loss: 14.8130	Cost: 5.77s
Train Epoch: 526 	Average Loss: 15.0135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4993

Learning rate: 0.00019863776276799112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: 17.3967	Cost: 22.73s
Train Epoch: 527 [20480/90000 (23%)]	Loss: 14.8626	Cost: 6.17s
Train Epoch: 527 [40960/90000 (45%)]	Loss: 15.0116	Cost: 6.18s
Train Epoch: 527 [61440/90000 (68%)]	Loss: 14.5835	Cost: 5.93s
Train Epoch: 527 [81920/90000 (91%)]	Loss: 14.9943	Cost: 5.81s
Train Epoch: 527 	Average Loss: 15.0203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4339

Learning rate: 0.00019863259008317586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: 17.3317	Cost: 22.13s
Train Epoch: 528 [20480/90000 (23%)]	Loss: 14.8585	Cost: 6.01s
Train Epoch: 528 [40960/90000 (45%)]	Loss: 14.8242	Cost: 7.51s
Train Epoch: 528 [61440/90000 (68%)]	Loss: 14.8582	Cost: 6.10s
Train Epoch: 528 [81920/90000 (91%)]	Loss: 14.8687	Cost: 6.20s
Train Epoch: 528 	Average Loss: 14.9766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4781

Learning rate: 0.00019862740766371425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: 17.4201	Cost: 21.24s
Train Epoch: 529 [20480/90000 (23%)]	Loss: 14.7845	Cost: 6.12s
Train Epoch: 529 [40960/90000 (45%)]	Loss: 14.7745	Cost: 6.18s
Train Epoch: 529 [61440/90000 (68%)]	Loss: 14.6520	Cost: 5.95s
Train Epoch: 529 [81920/90000 (91%)]	Loss: 14.9376	Cost: 5.97s
Train Epoch: 529 	Average Loss: 14.9869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4370

Learning rate: 0.00019862221551011772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: 17.3943	Cost: 23.89s
Train Epoch: 530 [20480/90000 (23%)]	Loss: 14.8592	Cost: 6.10s
Train Epoch: 530 [40960/90000 (45%)]	Loss: 14.9568	Cost: 6.13s
Train Epoch: 530 [61440/90000 (68%)]	Loss: 14.7405	Cost: 5.99s
Train Epoch: 530 [81920/90000 (91%)]	Loss: 14.7999	Cost: 6.04s
Train Epoch: 530 	Average Loss: 14.9615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4439

Learning rate: 0.0001986170136228988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: 17.4453	Cost: 25.60s
Train Epoch: 531 [20480/90000 (23%)]	Loss: 14.8941	Cost: 5.93s
Train Epoch: 531 [40960/90000 (45%)]	Loss: 14.6895	Cost: 6.35s
Train Epoch: 531 [61440/90000 (68%)]	Loss: 14.6727	Cost: 5.98s
Train Epoch: 531 [81920/90000 (91%)]	Loss: 15.2818	Cost: 6.11s
Train Epoch: 531 	Average Loss: 15.0416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5749

Learning rate: 0.00019861180200257079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: 17.6150	Cost: 22.29s
Train Epoch: 532 [20480/90000 (23%)]	Loss: 15.2088	Cost: 6.13s
Train Epoch: 532 [40960/90000 (45%)]	Loss: 15.0017	Cost: 6.09s
Train Epoch: 532 [61440/90000 (68%)]	Loss: 14.9579	Cost: 6.00s
Train Epoch: 532 [81920/90000 (91%)]	Loss: 14.9174	Cost: 6.03s
Train Epoch: 532 	Average Loss: 15.2133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3537

Learning rate: 0.00019860658064964812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: 17.4235	Cost: 22.53s
Train Epoch: 533 [20480/90000 (23%)]	Loss: 14.9462	Cost: 6.08s
Train Epoch: 533 [40960/90000 (45%)]	Loss: 15.0978	Cost: 6.17s
Train Epoch: 533 [61440/90000 (68%)]	Loss: 14.7706	Cost: 5.84s
Train Epoch: 533 [81920/90000 (91%)]	Loss: 14.9975	Cost: 6.77s
Train Epoch: 533 	Average Loss: 15.0600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4320

Learning rate: 0.0001986013495646461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: 17.2373	Cost: 22.02s
Train Epoch: 534 [20480/90000 (23%)]	Loss: 14.8690	Cost: 6.06s
Train Epoch: 534 [40960/90000 (45%)]	Loss: 14.9499	Cost: 6.07s
Train Epoch: 534 [61440/90000 (68%)]	Loss: 14.9123	Cost: 5.92s
Train Epoch: 534 [81920/90000 (91%)]	Loss: 14.8738	Cost: 5.76s
Train Epoch: 534 	Average Loss: 15.0000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3921

Learning rate: 0.00019859610874808106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: 17.1160	Cost: 24.58s
Train Epoch: 535 [20480/90000 (23%)]	Loss: 14.8265	Cost: 6.11s
Train Epoch: 535 [40960/90000 (45%)]	Loss: 15.0173	Cost: 6.14s
Train Epoch: 535 [61440/90000 (68%)]	Loss: 14.6979	Cost: 6.03s
Train Epoch: 535 [81920/90000 (91%)]	Loss: 14.8675	Cost: 5.72s
Train Epoch: 535 	Average Loss: 14.9736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4297

Learning rate: 0.0001985908582004702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: 17.3447	Cost: 24.36s
Train Epoch: 536 [20480/90000 (23%)]	Loss: 14.8688	Cost: 6.06s
Train Epoch: 536 [40960/90000 (45%)]	Loss: 14.9161	Cost: 6.17s
Train Epoch: 536 [61440/90000 (68%)]	Loss: 14.6425	Cost: 5.92s
Train Epoch: 536 [81920/90000 (91%)]	Loss: 14.8643	Cost: 5.90s
Train Epoch: 536 	Average Loss: 14.9453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5161

Learning rate: 0.00019858559792233175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: 17.4434	Cost: 24.63s
Train Epoch: 537 [20480/90000 (23%)]	Loss: 14.8653	Cost: 6.24s
Train Epoch: 537 [40960/90000 (45%)]	Loss: 14.8484	Cost: 6.14s
Train Epoch: 537 [61440/90000 (68%)]	Loss: 14.6614	Cost: 5.89s
Train Epoch: 537 [81920/90000 (91%)]	Loss: 14.7348	Cost: 5.78s
Train Epoch: 537 	Average Loss: 14.9226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4775

Learning rate: 0.00019858032791418486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: 17.3650	Cost: 22.37s
Train Epoch: 538 [20480/90000 (23%)]	Loss: 14.7730	Cost: 6.13s
Train Epoch: 538 [40960/90000 (45%)]	Loss: 14.8354	Cost: 6.17s
Train Epoch: 538 [61440/90000 (68%)]	Loss: 14.7713	Cost: 6.04s
Train Epoch: 538 [81920/90000 (91%)]	Loss: 14.6340	Cost: 5.88s
Train Epoch: 538 	Average Loss: 14.9263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4759

Learning rate: 0.00019857504817654965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: 17.3873	Cost: 22.35s
Train Epoch: 539 [20480/90000 (23%)]	Loss: 14.8270	Cost: 6.17s
Train Epoch: 539 [40960/90000 (45%)]	Loss: 14.6951	Cost: 6.18s
Train Epoch: 539 [61440/90000 (68%)]	Loss: 14.7047	Cost: 6.06s
Train Epoch: 539 [81920/90000 (91%)]	Loss: 14.7502	Cost: 5.83s
Train Epoch: 539 	Average Loss: 14.9112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4259

Learning rate: 0.00019856975870994725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: 17.4528	Cost: 21.97s
Train Epoch: 540 [20480/90000 (23%)]	Loss: 14.6732	Cost: 6.24s
Train Epoch: 540 [40960/90000 (45%)]	Loss: 14.6767	Cost: 6.09s
Train Epoch: 540 [61440/90000 (68%)]	Loss: 14.8035	Cost: 5.92s
Train Epoch: 540 [81920/90000 (91%)]	Loss: 14.7744	Cost: 5.76s
Train Epoch: 540 	Average Loss: 14.8825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5278

Learning rate: 0.0001985644595148997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: 17.3631	Cost: 19.54s
Train Epoch: 541 [20480/90000 (23%)]	Loss: 14.8617	Cost: 6.95s
Train Epoch: 541 [40960/90000 (45%)]	Loss: 14.7666	Cost: 6.21s
Train Epoch: 541 [61440/90000 (68%)]	Loss: 14.7096	Cost: 5.98s
Train Epoch: 541 [81920/90000 (91%)]	Loss: 14.8659	Cost: 6.03s
Train Epoch: 541 	Average Loss: 14.8822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4945

Learning rate: 0.00019855915059192997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: 17.4711	Cost: 21.43s
Train Epoch: 542 [20480/90000 (23%)]	Loss: 14.8158	Cost: 6.50s
Train Epoch: 542 [40960/90000 (45%)]	Loss: 14.7888	Cost: 6.44s
Train Epoch: 542 [61440/90000 (68%)]	Loss: 14.5346	Cost: 5.89s
Train Epoch: 542 [81920/90000 (91%)]	Loss: 14.8434	Cost: 5.89s
Train Epoch: 542 	Average Loss: 14.8736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5637

Learning rate: 0.00019855383194156202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: 17.4327	Cost: 20.65s
Train Epoch: 543 [20480/90000 (23%)]	Loss: 14.6947	Cost: 6.09s
Train Epoch: 543 [40960/90000 (45%)]	Loss: 14.5798	Cost: 6.85s
Train Epoch: 543 [61440/90000 (68%)]	Loss: 14.6427	Cost: 5.98s
Train Epoch: 543 [81920/90000 (91%)]	Loss: 14.7136	Cost: 5.76s
Train Epoch: 543 	Average Loss: 14.8789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4819

Learning rate: 0.00019854850356432085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: 17.4471	Cost: 20.29s
Train Epoch: 544 [20480/90000 (23%)]	Loss: 14.7628	Cost: 6.09s
Train Epoch: 544 [40960/90000 (45%)]	Loss: 14.7715	Cost: 7.22s
Train Epoch: 544 [61440/90000 (68%)]	Loss: 14.5410	Cost: 5.95s
Train Epoch: 544 [81920/90000 (91%)]	Loss: 14.8097	Cost: 6.05s
Train Epoch: 544 	Average Loss: 14.8899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5201

Learning rate: 0.00019854316546073235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: 17.4768	Cost: 20.20s
Train Epoch: 545 [20480/90000 (23%)]	Loss: 14.8847	Cost: 6.01s
Train Epoch: 545 [40960/90000 (45%)]	Loss: 14.7664	Cost: 6.07s
Train Epoch: 545 [61440/90000 (68%)]	Loss: 14.4646	Cost: 6.06s
Train Epoch: 545 [81920/90000 (91%)]	Loss: 14.7299	Cost: 6.54s
Train Epoch: 545 	Average Loss: 14.8619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5238

Learning rate: 0.0001985378176313233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: 17.3774	Cost: 20.53s
Train Epoch: 546 [20480/90000 (23%)]	Loss: 14.7339	Cost: 6.02s
Train Epoch: 546 [40960/90000 (45%)]	Loss: 14.7621	Cost: 6.73s
Train Epoch: 546 [61440/90000 (68%)]	Loss: 14.6019	Cost: 5.99s
Train Epoch: 546 [81920/90000 (91%)]	Loss: 14.7322	Cost: 6.85s
Train Epoch: 546 	Average Loss: 14.8445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5612

Learning rate: 0.00019853246007662156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: 17.5163	Cost: 20.83s
Train Epoch: 547 [20480/90000 (23%)]	Loss: 14.5332	Cost: 6.01s
Train Epoch: 547 [40960/90000 (45%)]	Loss: 14.7557	Cost: 6.14s
Train Epoch: 547 [61440/90000 (68%)]	Loss: 14.4451	Cost: 5.91s
Train Epoch: 547 [81920/90000 (91%)]	Loss: 14.6650	Cost: 5.93s
Train Epoch: 547 	Average Loss: 14.8447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6066

Learning rate: 0.0001985270927971559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: 17.5790	Cost: 21.76s
Train Epoch: 548 [20480/90000 (23%)]	Loss: 14.7426	Cost: 6.02s
Train Epoch: 548 [40960/90000 (45%)]	Loss: 14.6800	Cost: 6.22s
Train Epoch: 548 [61440/90000 (68%)]	Loss: 14.5633	Cost: 5.89s
Train Epoch: 548 [81920/90000 (91%)]	Loss: 14.6822	Cost: 6.33s
Train Epoch: 548 	Average Loss: 14.8213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5318

Learning rate: 0.00019852171579345603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: 17.4526	Cost: 20.19s
Train Epoch: 549 [20480/90000 (23%)]	Loss: 14.6996	Cost: 5.85s
Train Epoch: 549 [40960/90000 (45%)]	Loss: 14.6638	Cost: 6.08s
Train Epoch: 549 [61440/90000 (68%)]	Loss: 14.5385	Cost: 5.98s
Train Epoch: 549 [81920/90000 (91%)]	Loss: 14.6494	Cost: 5.60s
Train Epoch: 549 	Average Loss: 14.8104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5516

Learning rate: 0.0001985163290660526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: 17.4882	Cost: 20.85s
Train Epoch: 550 [20480/90000 (23%)]	Loss: 14.6487	Cost: 6.26s
Train Epoch: 550 [40960/90000 (45%)]	Loss: 14.6277	Cost: 6.15s
Train Epoch: 550 [61440/90000 (68%)]	Loss: 14.6084	Cost: 6.00s
Train Epoch: 550 [81920/90000 (91%)]	Loss: 14.5962	Cost: 5.80s
Train Epoch: 550 	Average Loss: 14.8114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5688

Learning rate: 0.0001985109326154773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: 17.5916	Cost: 20.02s
Train Epoch: 551 [20480/90000 (23%)]	Loss: 14.7218	Cost: 6.18s
Train Epoch: 551 [40960/90000 (45%)]	Loss: 14.6196	Cost: 6.22s
Train Epoch: 551 [61440/90000 (68%)]	Loss: 14.6606	Cost: 5.89s
Train Epoch: 551 [81920/90000 (91%)]	Loss: 14.6459	Cost: 5.75s
Train Epoch: 551 	Average Loss: 14.8026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5265

Learning rate: 0.00019850552644226275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: 17.4650	Cost: 21.22s
Train Epoch: 552 [20480/90000 (23%)]	Loss: 14.6026	Cost: 6.10s
Train Epoch: 552 [40960/90000 (45%)]	Loss: 14.6939	Cost: 7.04s
Train Epoch: 552 [61440/90000 (68%)]	Loss: 14.6426	Cost: 5.92s
Train Epoch: 552 [81920/90000 (91%)]	Loss: 14.6038	Cost: 6.12s
Train Epoch: 552 	Average Loss: 14.8040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5232

Learning rate: 0.0001985001105469425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: 17.4323	Cost: 20.34s
Train Epoch: 553 [20480/90000 (23%)]	Loss: 14.6108	Cost: 6.13s
Train Epoch: 553 [40960/90000 (45%)]	Loss: 14.5749	Cost: 6.09s
Train Epoch: 553 [61440/90000 (68%)]	Loss: 14.5531	Cost: 5.88s
Train Epoch: 553 [81920/90000 (91%)]	Loss: 14.6455	Cost: 5.73s
Train Epoch: 553 	Average Loss: 14.8136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5981

Learning rate: 0.00019849468493005109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: 17.3777	Cost: 20.49s
Train Epoch: 554 [20480/90000 (23%)]	Loss: 14.5215	Cost: 6.18s
Train Epoch: 554 [40960/90000 (45%)]	Loss: 14.4917	Cost: 6.52s
Train Epoch: 554 [61440/90000 (68%)]	Loss: 14.5499	Cost: 5.93s
Train Epoch: 554 [81920/90000 (91%)]	Loss: 14.6691	Cost: 5.84s
Train Epoch: 554 	Average Loss: 14.7658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6080

Learning rate: 0.000198489249592124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: 17.5077	Cost: 21.23s
Train Epoch: 555 [20480/90000 (23%)]	Loss: 14.5355	Cost: 5.99s
Train Epoch: 555 [40960/90000 (45%)]	Loss: 14.4471	Cost: 6.29s
Train Epoch: 555 [61440/90000 (68%)]	Loss: 14.5542	Cost: 5.91s
Train Epoch: 555 [81920/90000 (91%)]	Loss: 14.6286	Cost: 5.78s
Train Epoch: 555 	Average Loss: 14.7541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5894

Learning rate: 0.00019848380453369767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: 17.7298	Cost: 20.35s
Train Epoch: 556 [20480/90000 (23%)]	Loss: 14.5419	Cost: 6.26s
Train Epoch: 556 [40960/90000 (45%)]	Loss: 14.6189	Cost: 6.19s
Train Epoch: 556 [61440/90000 (68%)]	Loss: 14.3026	Cost: 6.11s
Train Epoch: 556 [81920/90000 (91%)]	Loss: 14.6482	Cost: 5.75s
Train Epoch: 556 	Average Loss: 14.7513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5946

Learning rate: 0.00019847834975530955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: 17.3975	Cost: 20.48s
Train Epoch: 557 [20480/90000 (23%)]	Loss: 14.4656	Cost: 6.13s
Train Epoch: 557 [40960/90000 (45%)]	Loss: 14.6333	Cost: 6.19s
Train Epoch: 557 [61440/90000 (68%)]	Loss: 14.5583	Cost: 5.88s
Train Epoch: 557 [81920/90000 (91%)]	Loss: 14.6294	Cost: 5.70s
Train Epoch: 557 	Average Loss: 14.7173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5882

Learning rate: 0.00019847288525749797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: 17.4192	Cost: 21.28s
Train Epoch: 558 [20480/90000 (23%)]	Loss: 14.4858	Cost: 6.10s
Train Epoch: 558 [40960/90000 (45%)]	Loss: 14.4091	Cost: 6.14s
Train Epoch: 558 [61440/90000 (68%)]	Loss: 14.4745	Cost: 5.98s
Train Epoch: 558 [81920/90000 (91%)]	Loss: 14.5773	Cost: 5.81s
Train Epoch: 558 	Average Loss: 14.7293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6234

Learning rate: 0.0001984674110408022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: 17.5143	Cost: 22.16s
Train Epoch: 559 [20480/90000 (23%)]	Loss: 14.4874	Cost: 6.12s
Train Epoch: 559 [40960/90000 (45%)]	Loss: 14.5292	Cost: 6.27s
Train Epoch: 559 [61440/90000 (68%)]	Loss: 14.3376	Cost: 5.96s
Train Epoch: 559 [81920/90000 (91%)]	Loss: 14.5752	Cost: 5.85s
Train Epoch: 559 	Average Loss: 14.6988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6248

Learning rate: 0.0001984619271057626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: 17.5520	Cost: 21.87s
Train Epoch: 560 [20480/90000 (23%)]	Loss: 14.5415	Cost: 5.99s
Train Epoch: 560 [40960/90000 (45%)]	Loss: 14.5404	Cost: 6.09s
Train Epoch: 560 [61440/90000 (68%)]	Loss: 14.5312	Cost: 5.87s
Train Epoch: 560 [81920/90000 (91%)]	Loss: 14.5441	Cost: 5.73s
Train Epoch: 560 	Average Loss: 14.6987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6175

Learning rate: 0.0001984564334529204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: 17.4832	Cost: 23.07s
Train Epoch: 561 [20480/90000 (23%)]	Loss: 14.5546	Cost: 6.13s
Train Epoch: 561 [40960/90000 (45%)]	Loss: 14.5754	Cost: 6.34s
Train Epoch: 561 [61440/90000 (68%)]	Loss: 14.3253	Cost: 6.01s
Train Epoch: 561 [81920/90000 (91%)]	Loss: 14.5396	Cost: 5.80s
Train Epoch: 561 	Average Loss: 14.6920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6549

Learning rate: 0.0001984509300828178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: 17.4806	Cost: 24.32s
Train Epoch: 562 [20480/90000 (23%)]	Loss: 14.4102	Cost: 6.04s
Train Epoch: 562 [40960/90000 (45%)]	Loss: 14.5405	Cost: 6.07s
Train Epoch: 562 [61440/90000 (68%)]	Loss: 14.3858	Cost: 5.91s
Train Epoch: 562 [81920/90000 (91%)]	Loss: 14.5270	Cost: 5.77s
Train Epoch: 562 	Average Loss: 14.6793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6617

Learning rate: 0.00019844541699599793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: 17.4389	Cost: 26.14s
Train Epoch: 563 [20480/90000 (23%)]	Loss: 14.5199	Cost: 6.11s
Train Epoch: 563 [40960/90000 (45%)]	Loss: 14.3985	Cost: 6.66s
Train Epoch: 563 [61440/90000 (68%)]	Loss: 14.3723	Cost: 5.87s
Train Epoch: 563 [81920/90000 (91%)]	Loss: 14.4617	Cost: 6.15s
Train Epoch: 563 	Average Loss: 14.6535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6610

Learning rate: 0.00019843989419300492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: 17.7059	Cost: 23.39s
Train Epoch: 564 [20480/90000 (23%)]	Loss: 14.5011	Cost: 6.34s
Train Epoch: 564 [40960/90000 (45%)]	Loss: 14.2900	Cost: 6.62s
Train Epoch: 564 [61440/90000 (68%)]	Loss: 14.5478	Cost: 5.91s
Train Epoch: 564 [81920/90000 (91%)]	Loss: 14.4657	Cost: 5.81s
Train Epoch: 564 	Average Loss: 14.6700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6742

Learning rate: 0.00019843436167438387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: 17.6577	Cost: 21.15s
Train Epoch: 565 [20480/90000 (23%)]	Loss: 14.3682	Cost: 6.42s
Train Epoch: 565 [40960/90000 (45%)]	Loss: 14.4817	Cost: 6.58s
Train Epoch: 565 [61440/90000 (68%)]	Loss: 14.4529	Cost: 5.93s
Train Epoch: 565 [81920/90000 (91%)]	Loss: 14.5995	Cost: 5.84s
Train Epoch: 565 	Average Loss: 14.6840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6567

Learning rate: 0.00019842881944068082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: 17.5525	Cost: 21.10s
Train Epoch: 566 [20480/90000 (23%)]	Loss: 14.4699	Cost: 6.35s
Train Epoch: 566 [40960/90000 (45%)]	Loss: 14.4888	Cost: 6.65s
Train Epoch: 566 [61440/90000 (68%)]	Loss: 14.3567	Cost: 5.89s
Train Epoch: 566 [81920/90000 (91%)]	Loss: 14.5819	Cost: 5.88s
Train Epoch: 566 	Average Loss: 14.6848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7141

Learning rate: 0.00019842326749244275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: 17.5538	Cost: 20.09s
Train Epoch: 567 [20480/90000 (23%)]	Loss: 14.5603	Cost: 6.85s
Train Epoch: 567 [40960/90000 (45%)]	Loss: 14.5088	Cost: 6.86s
Train Epoch: 567 [61440/90000 (68%)]	Loss: 14.3722	Cost: 6.00s
Train Epoch: 567 [81920/90000 (91%)]	Loss: 14.4377	Cost: 5.83s
Train Epoch: 567 	Average Loss: 14.6700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6532

Learning rate: 0.00019841770583021762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: 17.5146	Cost: 21.01s
Train Epoch: 568 [20480/90000 (23%)]	Loss: 14.2214	Cost: 6.40s
Train Epoch: 568 [40960/90000 (45%)]	Loss: 14.5272	Cost: 6.56s
Train Epoch: 568 [61440/90000 (68%)]	Loss: 14.3990	Cost: 6.04s
Train Epoch: 568 [81920/90000 (91%)]	Loss: 14.5030	Cost: 5.83s
Train Epoch: 568 	Average Loss: 14.6536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6446

Learning rate: 0.00019841213445455434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: 17.6470	Cost: 20.28s
Train Epoch: 569 [20480/90000 (23%)]	Loss: 14.3355	Cost: 6.12s
Train Epoch: 569 [40960/90000 (45%)]	Loss: 14.5170	Cost: 6.26s
Train Epoch: 569 [61440/90000 (68%)]	Loss: 14.3764	Cost: 5.96s
Train Epoch: 569 [81920/90000 (91%)]	Loss: 14.4203	Cost: 5.77s
Train Epoch: 569 	Average Loss: 14.6469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7398

Learning rate: 0.00019840655336600282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: 17.6069	Cost: 19.98s
Train Epoch: 570 [20480/90000 (23%)]	Loss: 14.4615	Cost: 6.11s
Train Epoch: 570 [40960/90000 (45%)]	Loss: 14.4360	Cost: 6.29s
Train Epoch: 570 [61440/90000 (68%)]	Loss: 14.3425	Cost: 5.91s
Train Epoch: 570 [81920/90000 (91%)]	Loss: 14.4568	Cost: 5.84s
Train Epoch: 570 	Average Loss: 14.6341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7187

Learning rate: 0.00019840096256511382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: 17.6240	Cost: 20.82s
Train Epoch: 571 [20480/90000 (23%)]	Loss: 14.3581	Cost: 6.00s
Train Epoch: 571 [40960/90000 (45%)]	Loss: 14.4719	Cost: 6.26s
Train Epoch: 571 [61440/90000 (68%)]	Loss: 14.3526	Cost: 5.93s
Train Epoch: 571 [81920/90000 (91%)]	Loss: 14.6233	Cost: 5.96s
Train Epoch: 571 	Average Loss: 14.6339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7423

Learning rate: 0.0001983953620524392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: 17.5961	Cost: 20.73s
Train Epoch: 572 [20480/90000 (23%)]	Loss: 14.4889	Cost: 6.07s
Train Epoch: 572 [40960/90000 (45%)]	Loss: 14.4585	Cost: 6.71s
Train Epoch: 572 [61440/90000 (68%)]	Loss: 14.3742	Cost: 6.03s
Train Epoch: 572 [81920/90000 (91%)]	Loss: 14.4446	Cost: 6.18s
Train Epoch: 572 	Average Loss: 14.6187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6786

Learning rate: 0.00019838975182853166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: 17.5236	Cost: 20.51s
Train Epoch: 573 [20480/90000 (23%)]	Loss: 14.4634	Cost: 6.15s
Train Epoch: 573 [40960/90000 (45%)]	Loss: 14.4484	Cost: 6.37s
Train Epoch: 573 [61440/90000 (68%)]	Loss: 14.3550	Cost: 5.90s
Train Epoch: 573 [81920/90000 (91%)]	Loss: 14.4438	Cost: 5.68s
Train Epoch: 573 	Average Loss: 14.5990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6904

Learning rate: 0.0001983841318939449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: 17.7449	Cost: 19.84s
Train Epoch: 574 [20480/90000 (23%)]	Loss: 14.2752	Cost: 6.09s
Train Epoch: 574 [40960/90000 (45%)]	Loss: 14.3827	Cost: 6.71s
Train Epoch: 574 [61440/90000 (68%)]	Loss: 14.2216	Cost: 5.92s
Train Epoch: 574 [81920/90000 (91%)]	Loss: 14.3801	Cost: 5.77s
Train Epoch: 574 	Average Loss: 14.5678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7174

Learning rate: 0.00019837850224923363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: 17.6261	Cost: 20.62s
Train Epoch: 575 [20480/90000 (23%)]	Loss: 14.4441	Cost: 6.08s
Train Epoch: 575 [40960/90000 (45%)]	Loss: 14.3215	Cost: 6.14s
Train Epoch: 575 [61440/90000 (68%)]	Loss: 14.1724	Cost: 5.89s
Train Epoch: 575 [81920/90000 (91%)]	Loss: 14.4763	Cost: 5.77s
Train Epoch: 575 	Average Loss: 14.5846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7741

Learning rate: 0.00019837286289495345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: 17.6010	Cost: 20.59s
Train Epoch: 576 [20480/90000 (23%)]	Loss: 14.4112	Cost: 6.15s
Train Epoch: 576 [40960/90000 (45%)]	Loss: 14.3289	Cost: 6.53s
Train Epoch: 576 [61440/90000 (68%)]	Loss: 14.2631	Cost: 5.89s
Train Epoch: 576 [81920/90000 (91%)]	Loss: 14.4862	Cost: 6.05s
Train Epoch: 576 	Average Loss: 14.5665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7486

Learning rate: 0.00019836721383166095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: 17.7701	Cost: 20.52s
Train Epoch: 577 [20480/90000 (23%)]	Loss: 14.2849	Cost: 6.06s
Train Epoch: 577 [40960/90000 (45%)]	Loss: 14.3482	Cost: 6.20s
Train Epoch: 577 [61440/90000 (68%)]	Loss: 14.2131	Cost: 6.00s
Train Epoch: 577 [81920/90000 (91%)]	Loss: 14.4564	Cost: 5.73s
Train Epoch: 577 	Average Loss: 14.5419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7618

Learning rate: 0.00019836155505991362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: 17.5709	Cost: 21.83s
Train Epoch: 578 [20480/90000 (23%)]	Loss: 14.3218	Cost: 6.09s
Train Epoch: 578 [40960/90000 (45%)]	Loss: 14.2888	Cost: 6.30s
Train Epoch: 578 [61440/90000 (68%)]	Loss: 14.1861	Cost: 5.94s
Train Epoch: 578 [81920/90000 (91%)]	Loss: 14.2626	Cost: 5.86s
Train Epoch: 578 	Average Loss: 14.5329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7179

Learning rate: 0.00019835588658027008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: 17.6211	Cost: 20.12s
Train Epoch: 579 [20480/90000 (23%)]	Loss: 14.4626	Cost: 6.11s
Train Epoch: 579 [40960/90000 (45%)]	Loss: 14.3879	Cost: 6.13s
Train Epoch: 579 [61440/90000 (68%)]	Loss: 14.2801	Cost: 5.85s
Train Epoch: 579 [81920/90000 (91%)]	Loss: 14.3467	Cost: 5.70s
Train Epoch: 579 	Average Loss: 14.5482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7552

Learning rate: 0.00019835020839328965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: 17.7167	Cost: 21.40s
Train Epoch: 580 [20480/90000 (23%)]	Loss: 14.2291	Cost: 6.11s
Train Epoch: 580 [40960/90000 (45%)]	Loss: 14.2600	Cost: 6.08s
Train Epoch: 580 [61440/90000 (68%)]	Loss: 14.2998	Cost: 5.89s
Train Epoch: 580 [81920/90000 (91%)]	Loss: 14.4467	Cost: 5.75s
Train Epoch: 580 	Average Loss: 14.5453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7502

Learning rate: 0.0001983445204995328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: 17.7130	Cost: 22.18s
Train Epoch: 581 [20480/90000 (23%)]	Loss: 14.4514	Cost: 6.05s
Train Epoch: 581 [40960/90000 (45%)]	Loss: 14.2957	Cost: 6.11s
Train Epoch: 581 [61440/90000 (68%)]	Loss: 14.0558	Cost: 5.94s
Train Epoch: 581 [81920/90000 (91%)]	Loss: 14.2930	Cost: 5.63s
Train Epoch: 581 	Average Loss: 14.5606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7628

Learning rate: 0.00019833882289956094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: 17.4941	Cost: 22.90s
Train Epoch: 582 [20480/90000 (23%)]	Loss: 14.2522	Cost: 6.08s
Train Epoch: 582 [40960/90000 (45%)]	Loss: 14.4525	Cost: 6.12s
Train Epoch: 582 [61440/90000 (68%)]	Loss: 14.2510	Cost: 5.93s
Train Epoch: 582 [81920/90000 (91%)]	Loss: 14.1854	Cost: 5.72s
Train Epoch: 582 	Average Loss: 14.5045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8128

Learning rate: 0.00019833311559393636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: 17.6764	Cost: 21.55s
Train Epoch: 583 [20480/90000 (23%)]	Loss: 14.2326	Cost: 6.12s
Train Epoch: 583 [40960/90000 (45%)]	Loss: 14.2113	Cost: 6.09s
Train Epoch: 583 [61440/90000 (68%)]	Loss: 14.1739	Cost: 6.10s
Train Epoch: 583 [81920/90000 (91%)]	Loss: 14.2280	Cost: 5.83s
Train Epoch: 583 	Average Loss: 14.4897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7626

Learning rate: 0.00019832739858322235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: 17.6320	Cost: 22.04s
Train Epoch: 584 [20480/90000 (23%)]	Loss: 14.1909	Cost: 5.99s
Train Epoch: 584 [40960/90000 (45%)]	Loss: 14.1745	Cost: 6.59s
Train Epoch: 584 [61440/90000 (68%)]	Loss: 14.2228	Cost: 6.06s
Train Epoch: 584 [81920/90000 (91%)]	Loss: 14.2729	Cost: 6.57s
Train Epoch: 584 	Average Loss: 14.4687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8308

Learning rate: 0.00019832167186798315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: 17.7738	Cost: 21.84s
Train Epoch: 585 [20480/90000 (23%)]	Loss: 14.3612	Cost: 6.15s
Train Epoch: 585 [40960/90000 (45%)]	Loss: 14.2554	Cost: 6.20s
Train Epoch: 585 [61440/90000 (68%)]	Loss: 14.1174	Cost: 5.93s
Train Epoch: 585 [81920/90000 (91%)]	Loss: 14.2775	Cost: 5.99s
Train Epoch: 585 	Average Loss: 14.4556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8085

Learning rate: 0.000198315935448784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: 17.7812	Cost: 24.30s
Train Epoch: 586 [20480/90000 (23%)]	Loss: 14.2339	Cost: 6.12s
Train Epoch: 586 [40960/90000 (45%)]	Loss: 14.1993	Cost: 6.13s
Train Epoch: 586 [61440/90000 (68%)]	Loss: 14.2364	Cost: 5.93s
Train Epoch: 586 [81920/90000 (91%)]	Loss: 14.3222	Cost: 5.79s
Train Epoch: 586 	Average Loss: 14.4752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8103

Learning rate: 0.00019831018932619103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: 17.7988	Cost: 25.44s
Train Epoch: 587 [20480/90000 (23%)]	Loss: 14.2326	Cost: 6.08s
Train Epoch: 587 [40960/90000 (45%)]	Loss: 14.2681	Cost: 6.17s
Train Epoch: 587 [61440/90000 (68%)]	Loss: 14.1693	Cost: 5.83s
Train Epoch: 587 [81920/90000 (91%)]	Loss: 14.3248	Cost: 5.84s
Train Epoch: 587 	Average Loss: 14.4956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7734

Learning rate: 0.00019830443350077136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: 17.8348	Cost: 25.65s
Train Epoch: 588 [20480/90000 (23%)]	Loss: 14.2705	Cost: 6.01s
Train Epoch: 588 [40960/90000 (45%)]	Loss: 14.3033	Cost: 6.17s
Train Epoch: 588 [61440/90000 (68%)]	Loss: 14.1584	Cost: 5.92s
Train Epoch: 588 [81920/90000 (91%)]	Loss: 14.1417	Cost: 5.71s
Train Epoch: 588 	Average Loss: 14.4371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8373

Learning rate: 0.0001982986679730931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: 17.7689	Cost: 23.59s
Train Epoch: 589 [20480/90000 (23%)]	Loss: 14.2466	Cost: 6.34s
Train Epoch: 589 [40960/90000 (45%)]	Loss: 14.1527	Cost: 6.27s
Train Epoch: 589 [61440/90000 (68%)]	Loss: 14.1115	Cost: 5.93s
Train Epoch: 589 [81920/90000 (91%)]	Loss: 14.2097	Cost: 5.79s
Train Epoch: 589 	Average Loss: 14.4401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8213

Learning rate: 0.00019829289274372522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: 17.6471	Cost: 24.75s
Train Epoch: 590 [20480/90000 (23%)]	Loss: 14.2035	Cost: 6.12s
Train Epoch: 590 [40960/90000 (45%)]	Loss: 14.1162	Cost: 6.55s
Train Epoch: 590 [61440/90000 (68%)]	Loss: 14.2248	Cost: 6.00s
Train Epoch: 590 [81920/90000 (91%)]	Loss: 14.3129	Cost: 5.82s
Train Epoch: 590 	Average Loss: 14.4489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7966

Learning rate: 0.00019828710781323776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: 17.7815	Cost: 21.57s
Train Epoch: 591 [20480/90000 (23%)]	Loss: 14.2720	Cost: 6.13s
Train Epoch: 591 [40960/90000 (45%)]	Loss: 14.2729	Cost: 6.45s
Train Epoch: 591 [61440/90000 (68%)]	Loss: 14.0145	Cost: 5.91s
Train Epoch: 591 [81920/90000 (91%)]	Loss: 14.2202	Cost: 6.15s
Train Epoch: 591 	Average Loss: 14.4334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7635

Learning rate: 0.00019828131318220168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: 17.7836	Cost: 21.83s
Train Epoch: 592 [20480/90000 (23%)]	Loss: 14.0417	Cost: 6.78s
Train Epoch: 592 [40960/90000 (45%)]	Loss: 14.2209	Cost: 6.21s
Train Epoch: 592 [61440/90000 (68%)]	Loss: 14.1443	Cost: 5.90s
Train Epoch: 592 [81920/90000 (91%)]	Loss: 14.1871	Cost: 5.83s
Train Epoch: 592 	Average Loss: 14.4391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8672

Learning rate: 0.00019827550885118884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: 17.6735	Cost: 21.42s
Train Epoch: 593 [20480/90000 (23%)]	Loss: 14.2137	Cost: 6.20s
Train Epoch: 593 [40960/90000 (45%)]	Loss: 14.1320	Cost: 6.17s
Train Epoch: 593 [61440/90000 (68%)]	Loss: 14.2597	Cost: 5.91s
Train Epoch: 593 [81920/90000 (91%)]	Loss: 14.3746	Cost: 5.82s
Train Epoch: 593 	Average Loss: 14.4515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8147

Learning rate: 0.00019826969482077218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: 17.6702	Cost: 20.69s
Train Epoch: 594 [20480/90000 (23%)]	Loss: 14.1410	Cost: 6.20s
Train Epoch: 594 [40960/90000 (45%)]	Loss: 14.1485	Cost: 6.93s
Train Epoch: 594 [61440/90000 (68%)]	Loss: 14.2029	Cost: 5.89s
Train Epoch: 594 [81920/90000 (91%)]	Loss: 14.1837	Cost: 5.86s
Train Epoch: 594 	Average Loss: 14.4054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8450

Learning rate: 0.00019826387109152545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: 17.9258	Cost: 20.93s
Train Epoch: 595 [20480/90000 (23%)]	Loss: 14.2015	Cost: 5.99s
Train Epoch: 595 [40960/90000 (45%)]	Loss: 14.1850	Cost: 6.21s
Train Epoch: 595 [61440/90000 (68%)]	Loss: 14.0328	Cost: 5.90s
Train Epoch: 595 [81920/90000 (91%)]	Loss: 14.1268	Cost: 5.99s
Train Epoch: 595 	Average Loss: 14.3762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8630

Learning rate: 0.00019825803766402344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: 17.6865	Cost: 20.51s
Train Epoch: 596 [20480/90000 (23%)]	Loss: 14.2498	Cost: 6.14s
Train Epoch: 596 [40960/90000 (45%)]	Loss: 14.0545	Cost: 6.08s
Train Epoch: 596 [61440/90000 (68%)]	Loss: 13.9725	Cost: 6.25s
Train Epoch: 596 [81920/90000 (91%)]	Loss: 14.2180	Cost: 7.04s
Train Epoch: 596 	Average Loss: 14.3521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7775

Learning rate: 0.00019825219453884193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: 17.7195	Cost: 20.14s
Train Epoch: 597 [20480/90000 (23%)]	Loss: 14.1263	Cost: 6.00s
Train Epoch: 597 [40960/90000 (45%)]	Loss: 14.1782	Cost: 6.10s
Train Epoch: 597 [61440/90000 (68%)]	Loss: 14.0228	Cost: 6.19s
Train Epoch: 597 [81920/90000 (91%)]	Loss: 14.2142	Cost: 6.25s
Train Epoch: 597 	Average Loss: 14.3300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8638

Learning rate: 0.00019824634171655754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: 17.6893	Cost: 21.02s
Train Epoch: 598 [20480/90000 (23%)]	Loss: 14.2653	Cost: 6.06s
Train Epoch: 598 [40960/90000 (45%)]	Loss: 14.1621	Cost: 6.10s
Train Epoch: 598 [61440/90000 (68%)]	Loss: 14.1119	Cost: 5.92s
Train Epoch: 598 [81920/90000 (91%)]	Loss: 14.1469	Cost: 6.05s
Train Epoch: 598 	Average Loss: 14.3593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8726

Learning rate: 0.000198240479197748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: 17.7266	Cost: 20.76s
Train Epoch: 599 [20480/90000 (23%)]	Loss: 14.1951	Cost: 6.05s
Train Epoch: 599 [40960/90000 (45%)]	Loss: 14.1715	Cost: 6.09s
Train Epoch: 599 [61440/90000 (68%)]	Loss: 14.0134	Cost: 6.00s
Train Epoch: 599 [81920/90000 (91%)]	Loss: 14.1409	Cost: 5.77s
Train Epoch: 599 	Average Loss: 14.3365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8833

Learning rate: 0.00019823460698299188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: 17.7211	Cost: 20.59s
Train Epoch: 600 [20480/90000 (23%)]	Loss: 14.0858	Cost: 6.10s
Train Epoch: 600 [40960/90000 (45%)]	Loss: 14.1042	Cost: 6.11s
Train Epoch: 600 [61440/90000 (68%)]	Loss: 14.0410	Cost: 5.96s
Train Epoch: 600 [81920/90000 (91%)]	Loss: 14.2361	Cost: 5.76s
Train Epoch: 600 	Average Loss: 14.3184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8518

Learning rate: 0.00019822872507286872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: 17.8037	Cost: 20.39s
Train Epoch: 601 [20480/90000 (23%)]	Loss: 14.0958	Cost: 6.14s
Train Epoch: 601 [40960/90000 (45%)]	Loss: 14.0437	Cost: 6.17s
Train Epoch: 601 [61440/90000 (68%)]	Loss: 14.0473	Cost: 5.89s
Train Epoch: 601 [81920/90000 (91%)]	Loss: 13.9391	Cost: 5.83s
Train Epoch: 601 	Average Loss: 14.3290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8582

Learning rate: 0.00019822283346795905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: 17.8332	Cost: 20.73s
Train Epoch: 602 [20480/90000 (23%)]	Loss: 13.9769	Cost: 6.10s
Train Epoch: 602 [40960/90000 (45%)]	Loss: 14.0355	Cost: 6.29s
Train Epoch: 602 [61440/90000 (68%)]	Loss: 13.9529	Cost: 5.90s
Train Epoch: 602 [81920/90000 (91%)]	Loss: 14.1175	Cost: 5.86s
Train Epoch: 602 	Average Loss: 14.3084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8490

Learning rate: 0.0001982169321688444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: 17.8751	Cost: 20.60s
Train Epoch: 603 [20480/90000 (23%)]	Loss: 14.1545	Cost: 6.00s
Train Epoch: 603 [40960/90000 (45%)]	Loss: 14.1986	Cost: 6.68s
Train Epoch: 603 [61440/90000 (68%)]	Loss: 13.9771	Cost: 6.04s
Train Epoch: 603 [81920/90000 (91%)]	Loss: 14.0178	Cost: 5.79s
Train Epoch: 603 	Average Loss: 14.2906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9590

Learning rate: 0.00019821102117610715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: 17.9083	Cost: 20.64s
Train Epoch: 604 [20480/90000 (23%)]	Loss: 14.1769	Cost: 6.10s
Train Epoch: 604 [40960/90000 (45%)]	Loss: 14.0382	Cost: 6.55s
Train Epoch: 604 [61440/90000 (68%)]	Loss: 14.0124	Cost: 5.87s
Train Epoch: 604 [81920/90000 (91%)]	Loss: 14.0888	Cost: 5.80s
Train Epoch: 604 	Average Loss: 14.3189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9888

Learning rate: 0.00019820510049033073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: 17.9054	Cost: 20.32s
Train Epoch: 605 [20480/90000 (23%)]	Loss: 13.9800	Cost: 6.13s
Train Epoch: 605 [40960/90000 (45%)]	Loss: 14.0214	Cost: 6.26s
Train Epoch: 605 [61440/90000 (68%)]	Loss: 13.8896	Cost: 5.92s
Train Epoch: 605 [81920/90000 (91%)]	Loss: 14.1956	Cost: 6.01s
Train Epoch: 605 	Average Loss: 14.2778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9407

Learning rate: 0.0001981991701120995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: 17.8472	Cost: 20.64s
Train Epoch: 606 [20480/90000 (23%)]	Loss: 13.9741	Cost: 6.12s
Train Epoch: 606 [40960/90000 (45%)]	Loss: 14.0751	Cost: 6.22s
Train Epoch: 606 [61440/90000 (68%)]	Loss: 13.9187	Cost: 5.95s
Train Epoch: 606 [81920/90000 (91%)]	Loss: 14.0634	Cost: 5.77s
Train Epoch: 606 	Average Loss: 14.2580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9755

Learning rate: 0.00019819323004199868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: 17.8007	Cost: 20.63s
Train Epoch: 607 [20480/90000 (23%)]	Loss: 13.9611	Cost: 6.20s
Train Epoch: 607 [40960/90000 (45%)]	Loss: 13.9484	Cost: 6.10s
Train Epoch: 607 [61440/90000 (68%)]	Loss: 13.8972	Cost: 5.97s
Train Epoch: 607 [81920/90000 (91%)]	Loss: 14.0328	Cost: 5.80s
Train Epoch: 607 	Average Loss: 14.2448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9213

Learning rate: 0.0001981872802806146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: 18.1012	Cost: 21.07s
Train Epoch: 608 [20480/90000 (23%)]	Loss: 13.9839	Cost: 5.90s
Train Epoch: 608 [40960/90000 (45%)]	Loss: 13.9721	Cost: 6.32s
Train Epoch: 608 [61440/90000 (68%)]	Loss: 13.9609	Cost: 5.87s
Train Epoch: 608 [81920/90000 (91%)]	Loss: 14.1336	Cost: 5.79s
Train Epoch: 608 	Average Loss: 14.2583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9396

Learning rate: 0.0001981813208285345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: 18.0091	Cost: 21.19s
Train Epoch: 609 [20480/90000 (23%)]	Loss: 13.9652	Cost: 5.97s
Train Epoch: 609 [40960/90000 (45%)]	Loss: 13.9603	Cost: 6.29s
Train Epoch: 609 [61440/90000 (68%)]	Loss: 14.0362	Cost: 5.90s
Train Epoch: 609 [81920/90000 (91%)]	Loss: 14.0085	Cost: 5.77s
Train Epoch: 609 	Average Loss: 14.2451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0341

Learning rate: 0.00019817535168634647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: 17.9255	Cost: 22.43s
Train Epoch: 610 [20480/90000 (23%)]	Loss: 13.7951	Cost: 5.99s
Train Epoch: 610 [40960/90000 (45%)]	Loss: 13.9436	Cost: 6.22s
Train Epoch: 610 [61440/90000 (68%)]	Loss: 14.0275	Cost: 5.88s
Train Epoch: 610 [81920/90000 (91%)]	Loss: 13.9030	Cost: 6.10s
Train Epoch: 610 	Average Loss: 14.2045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9433

Learning rate: 0.0001981693728546397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: 17.9908	Cost: 22.65s
Train Epoch: 611 [20480/90000 (23%)]	Loss: 14.0522	Cost: 6.03s
Train Epoch: 611 [40960/90000 (45%)]	Loss: 13.7347	Cost: 6.25s
Train Epoch: 611 [61440/90000 (68%)]	Loss: 13.8042	Cost: 5.95s
Train Epoch: 611 [81920/90000 (91%)]	Loss: 13.9691	Cost: 5.80s
Train Epoch: 611 	Average Loss: 14.2064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9940

Learning rate: 0.00019816338433400427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: 18.1143	Cost: 24.33s
Train Epoch: 612 [20480/90000 (23%)]	Loss: 13.8307	Cost: 6.09s
Train Epoch: 612 [40960/90000 (45%)]	Loss: 13.8313	Cost: 6.10s
Train Epoch: 612 [61440/90000 (68%)]	Loss: 13.8170	Cost: 5.85s
Train Epoch: 612 [81920/90000 (91%)]	Loss: 14.0653	Cost: 5.84s
Train Epoch: 612 	Average Loss: 14.2156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0228

Learning rate: 0.00019815738612503125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: 17.8582	Cost: 22.97s
Train Epoch: 613 [20480/90000 (23%)]	Loss: 13.9736	Cost: 6.27s
Train Epoch: 613 [40960/90000 (45%)]	Loss: 13.8490	Cost: 6.10s
Train Epoch: 613 [61440/90000 (68%)]	Loss: 13.9431	Cost: 5.94s
Train Epoch: 613 [81920/90000 (91%)]	Loss: 14.0529	Cost: 6.26s
Train Epoch: 613 	Average Loss: 14.2149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9934

Learning rate: 0.00019815137822831258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: 18.1103	Cost: 23.75s
Train Epoch: 614 [20480/90000 (23%)]	Loss: 14.2671	Cost: 6.17s
Train Epoch: 614 [40960/90000 (45%)]	Loss: 14.2043	Cost: 6.19s
Train Epoch: 614 [61440/90000 (68%)]	Loss: 14.0012	Cost: 6.03s
Train Epoch: 614 [81920/90000 (91%)]	Loss: 14.1156	Cost: 5.76s
Train Epoch: 614 	Average Loss: 14.3169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0054

Learning rate: 0.00019814536064444125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: 17.9023	Cost: 22.43s
Train Epoch: 615 [20480/90000 (23%)]	Loss: 13.9447	Cost: 6.39s
Train Epoch: 615 [40960/90000 (45%)]	Loss: 13.9246	Cost: 6.06s
Train Epoch: 615 [61440/90000 (68%)]	Loss: 13.8865	Cost: 5.91s
Train Epoch: 615 [81920/90000 (91%)]	Loss: 13.8509	Cost: 5.78s
Train Epoch: 615 	Average Loss: 14.2367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9309

Learning rate: 0.00019813933337401116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: 17.8942	Cost: 23.09s
Train Epoch: 616 [20480/90000 (23%)]	Loss: 13.7965	Cost: 6.14s
Train Epoch: 616 [40960/90000 (45%)]	Loss: 13.9723	Cost: 6.77s
Train Epoch: 616 [61440/90000 (68%)]	Loss: 13.9337	Cost: 5.95s
Train Epoch: 616 [81920/90000 (91%)]	Loss: 14.0759	Cost: 5.78s
Train Epoch: 616 	Average Loss: 14.2759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9815

Learning rate: 0.0001981332964176172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: 17.7922	Cost: 23.26s
Train Epoch: 617 [20480/90000 (23%)]	Loss: 13.8384	Cost: 6.69s
Train Epoch: 617 [40960/90000 (45%)]	Loss: 14.0314	Cost: 6.31s
Train Epoch: 617 [61440/90000 (68%)]	Loss: 13.9678	Cost: 5.95s
Train Epoch: 617 [81920/90000 (91%)]	Loss: 13.9152	Cost: 5.74s
Train Epoch: 617 	Average Loss: 14.2403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9731

Learning rate: 0.00019812724977585515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: 17.8659	Cost: 23.21s
Train Epoch: 618 [20480/90000 (23%)]	Loss: 14.0245	Cost: 6.31s
Train Epoch: 618 [40960/90000 (45%)]	Loss: 13.9531	Cost: 6.72s
Train Epoch: 618 [61440/90000 (68%)]	Loss: 13.8264	Cost: 5.81s
Train Epoch: 618 [81920/90000 (91%)]	Loss: 14.1133	Cost: 6.31s
Train Epoch: 618 	Average Loss: 14.1985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9740

Learning rate: 0.00019812119344932182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: 17.9265	Cost: 21.69s
Train Epoch: 619 [20480/90000 (23%)]	Loss: 13.8231	Cost: 6.16s
Train Epoch: 619 [40960/90000 (45%)]	Loss: 13.9308	Cost: 6.20s
Train Epoch: 619 [61440/90000 (68%)]	Loss: 13.6832	Cost: 6.05s
Train Epoch: 619 [81920/90000 (91%)]	Loss: 13.8579	Cost: 5.77s
Train Epoch: 619 	Average Loss: 14.1373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0427

Learning rate: 0.00019811512743861495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: 18.0035	Cost: 21.50s
Train Epoch: 620 [20480/90000 (23%)]	Loss: 13.8663	Cost: 6.07s
Train Epoch: 620 [40960/90000 (45%)]	Loss: 13.9154	Cost: 6.29s
Train Epoch: 620 [61440/90000 (68%)]	Loss: 13.7067	Cost: 5.90s
Train Epoch: 620 [81920/90000 (91%)]	Loss: 13.8479	Cost: 5.84s
Train Epoch: 620 	Average Loss: 14.1274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0090

Learning rate: 0.00019810905174433323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: 17.9624	Cost: 20.51s
Train Epoch: 621 [20480/90000 (23%)]	Loss: 13.7722	Cost: 6.90s
Train Epoch: 621 [40960/90000 (45%)]	Loss: 13.8807	Cost: 6.29s
Train Epoch: 621 [61440/90000 (68%)]	Loss: 13.6785	Cost: 5.94s
Train Epoch: 621 [81920/90000 (91%)]	Loss: 13.8127	Cost: 6.08s
Train Epoch: 621 	Average Loss: 14.0807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0863

Learning rate: 0.0001981029663670763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: 17.8952	Cost: 20.72s
Train Epoch: 622 [20480/90000 (23%)]	Loss: 13.8895	Cost: 6.31s
Train Epoch: 622 [40960/90000 (45%)]	Loss: 13.8227	Cost: 6.55s
Train Epoch: 622 [61440/90000 (68%)]	Loss: 13.5744	Cost: 5.91s
Train Epoch: 622 [81920/90000 (91%)]	Loss: 13.7660	Cost: 6.25s
Train Epoch: 622 	Average Loss: 14.0778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0873

Learning rate: 0.00019809687130744477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: 17.8754	Cost: 21.39s
Train Epoch: 623 [20480/90000 (23%)]	Loss: 13.7991	Cost: 6.04s
Train Epoch: 623 [40960/90000 (45%)]	Loss: 13.8338	Cost: 6.46s
Train Epoch: 623 [61440/90000 (68%)]	Loss: 13.7273	Cost: 6.01s
Train Epoch: 623 [81920/90000 (91%)]	Loss: 13.9411	Cost: 5.87s
Train Epoch: 623 	Average Loss: 14.1176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0825

Learning rate: 0.00019809076656604016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: 18.0114	Cost: 19.90s
Train Epoch: 624 [20480/90000 (23%)]	Loss: 13.8776	Cost: 6.08s
Train Epoch: 624 [40960/90000 (45%)]	Loss: 13.9294	Cost: 6.34s
Train Epoch: 624 [61440/90000 (68%)]	Loss: 13.7109	Cost: 5.93s
Train Epoch: 624 [81920/90000 (91%)]	Loss: 14.0766	Cost: 5.83s
Train Epoch: 624 	Average Loss: 14.1053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0045

Learning rate: 0.00019808465214346508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: 17.8216	Cost: 20.31s
Train Epoch: 625 [20480/90000 (23%)]	Loss: 13.8123	Cost: 6.11s
Train Epoch: 625 [40960/90000 (45%)]	Loss: 13.7539	Cost: 6.35s
Train Epoch: 625 [61440/90000 (68%)]	Loss: 13.7255	Cost: 6.16s
Train Epoch: 625 [81920/90000 (91%)]	Loss: 13.8506	Cost: 5.86s
Train Epoch: 625 	Average Loss: 14.0760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0208

Learning rate: 0.00019807852804032286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: 18.0568	Cost: 20.85s
Train Epoch: 626 [20480/90000 (23%)]	Loss: 13.7370	Cost: 5.95s
Train Epoch: 626 [40960/90000 (45%)]	Loss: 13.6897	Cost: 6.60s
Train Epoch: 626 [61440/90000 (68%)]	Loss: 13.6044	Cost: 5.87s
Train Epoch: 626 [81920/90000 (91%)]	Loss: 13.8744	Cost: 5.85s
Train Epoch: 626 	Average Loss: 14.0537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1010

Learning rate: 0.00019807239425721806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: 18.0499	Cost: 20.50s
Train Epoch: 627 [20480/90000 (23%)]	Loss: 13.9739	Cost: 6.11s
Train Epoch: 627 [40960/90000 (45%)]	Loss: 13.9038	Cost: 6.38s
Train Epoch: 627 [61440/90000 (68%)]	Loss: 13.7443	Cost: 5.86s
Train Epoch: 627 [81920/90000 (91%)]	Loss: 13.7930	Cost: 6.21s
Train Epoch: 627 	Average Loss: 14.1256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9808

Learning rate: 0.00019806625079475595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: 18.0174	Cost: 19.66s
Train Epoch: 628 [20480/90000 (23%)]	Loss: 13.7582	Cost: 6.17s
Train Epoch: 628 [40960/90000 (45%)]	Loss: 13.8825	Cost: 6.14s
Train Epoch: 628 [61440/90000 (68%)]	Loss: 13.7456	Cost: 5.87s
Train Epoch: 628 [81920/90000 (91%)]	Loss: 13.8655	Cost: 5.63s
Train Epoch: 628 	Average Loss: 14.0761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0743

Learning rate: 0.00019806009765354292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: 17.9023	Cost: 20.16s
Train Epoch: 629 [20480/90000 (23%)]	Loss: 13.7360	Cost: 6.13s
Train Epoch: 629 [40960/90000 (45%)]	Loss: 13.6542	Cost: 6.61s
Train Epoch: 629 [61440/90000 (68%)]	Loss: 13.7675	Cost: 5.88s
Train Epoch: 629 [81920/90000 (91%)]	Loss: 13.7407	Cost: 5.88s
Train Epoch: 629 	Average Loss: 14.0262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0861

Learning rate: 0.00019805393483418628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: 17.9458	Cost: 20.52s
Train Epoch: 630 [20480/90000 (23%)]	Loss: 13.7119	Cost: 6.12s
Train Epoch: 630 [40960/90000 (45%)]	Loss: 13.7157	Cost: 6.17s
Train Epoch: 630 [61440/90000 (68%)]	Loss: 13.6544	Cost: 5.90s
Train Epoch: 630 [81920/90000 (91%)]	Loss: 13.7290	Cost: 5.81s
Train Epoch: 630 	Average Loss: 14.0178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0274

Learning rate: 0.00019804776233729425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: 17.9430	Cost: 20.79s
Train Epoch: 631 [20480/90000 (23%)]	Loss: 13.7904	Cost: 6.17s
Train Epoch: 631 [40960/90000 (45%)]	Loss: 13.9356	Cost: 6.05s
Train Epoch: 631 [61440/90000 (68%)]	Loss: 13.8525	Cost: 5.90s
Train Epoch: 631 [81920/90000 (91%)]	Loss: 13.8597	Cost: 5.79s
Train Epoch: 631 	Average Loss: 14.0468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1304

Learning rate: 0.00019804158016347603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: 18.0177	Cost: 20.55s
Train Epoch: 632 [20480/90000 (23%)]	Loss: 13.7237	Cost: 6.18s
Train Epoch: 632 [40960/90000 (45%)]	Loss: 13.7353	Cost: 6.48s
Train Epoch: 632 [61440/90000 (68%)]	Loss: 13.6722	Cost: 5.88s
Train Epoch: 632 [81920/90000 (91%)]	Loss: 13.6712	Cost: 5.76s
Train Epoch: 632 	Average Loss: 14.0019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1039

Learning rate: 0.0001980353883133418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: 18.0531	Cost: 20.75s
Train Epoch: 633 [20480/90000 (23%)]	Loss: 13.7595	Cost: 6.04s
Train Epoch: 633 [40960/90000 (45%)]	Loss: 13.5792	Cost: 6.07s
Train Epoch: 633 [61440/90000 (68%)]	Loss: 13.5152	Cost: 5.90s
Train Epoch: 633 [81920/90000 (91%)]	Loss: 13.8695	Cost: 5.79s
Train Epoch: 633 	Average Loss: 14.0095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2006

Learning rate: 0.0001980291867875026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: 18.0143	Cost: 21.93s
Train Epoch: 634 [20480/90000 (23%)]	Loss: 13.5858	Cost: 6.05s
Train Epoch: 634 [40960/90000 (45%)]	Loss: 13.7067	Cost: 6.75s
Train Epoch: 634 [61440/90000 (68%)]	Loss: 13.6112	Cost: 5.99s
Train Epoch: 634 [81920/90000 (91%)]	Loss: 13.7467	Cost: 6.07s
Train Epoch: 634 	Average Loss: 13.9780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1777

Learning rate: 0.00019802297558657058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: 18.1117	Cost: 20.74s
Train Epoch: 635 [20480/90000 (23%)]	Loss: 13.6932	Cost: 6.08s
Train Epoch: 635 [40960/90000 (45%)]	Loss: 13.5608	Cost: 6.57s
Train Epoch: 635 [61440/90000 (68%)]	Loss: 13.5606	Cost: 5.87s
Train Epoch: 635 [81920/90000 (91%)]	Loss: 13.7202	Cost: 6.00s
Train Epoch: 635 	Average Loss: 13.9715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1378

Learning rate: 0.00019801675471115872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: 17.9774	Cost: 20.56s
Train Epoch: 636 [20480/90000 (23%)]	Loss: 13.7502	Cost: 6.03s
Train Epoch: 636 [40960/90000 (45%)]	Loss: 13.6392	Cost: 6.05s
Train Epoch: 636 [61440/90000 (68%)]	Loss: 13.5886	Cost: 6.13s
Train Epoch: 636 [81920/90000 (91%)]	Loss: 13.5952	Cost: 5.77s
Train Epoch: 636 	Average Loss: 13.9636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1516

Learning rate: 0.000198010524161881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: 17.9930	Cost: 21.67s
Train Epoch: 637 [20480/90000 (23%)]	Loss: 13.6429	Cost: 6.04s
Train Epoch: 637 [40960/90000 (45%)]	Loss: 13.7691	Cost: 6.04s
Train Epoch: 637 [61440/90000 (68%)]	Loss: 13.7503	Cost: 5.89s
Train Epoch: 637 [81920/90000 (91%)]	Loss: 13.7907	Cost: 5.81s
Train Epoch: 637 	Average Loss: 13.9775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2269

Learning rate: 0.00019800428393935233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: 18.1495	Cost: 20.51s
Train Epoch: 638 [20480/90000 (23%)]	Loss: 13.5710	Cost: 6.10s
Train Epoch: 638 [40960/90000 (45%)]	Loss: 13.5865	Cost: 6.68s
Train Epoch: 638 [61440/90000 (68%)]	Loss: 13.6005	Cost: 5.93s
Train Epoch: 638 [81920/90000 (91%)]	Loss: 13.6910	Cost: 6.35s
Train Epoch: 638 	Average Loss: 13.9574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1938

Learning rate: 0.00019799803404418868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: 18.0561	Cost: 21.62s
Train Epoch: 639 [20480/90000 (23%)]	Loss: 13.6153	Cost: 6.01s
Train Epoch: 639 [40960/90000 (45%)]	Loss: 13.5365	Cost: 6.59s
Train Epoch: 639 [61440/90000 (68%)]	Loss: 13.4825	Cost: 5.90s
Train Epoch: 639 [81920/90000 (91%)]	Loss: 13.6685	Cost: 6.19s
Train Epoch: 639 	Average Loss: 13.9527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1419

Learning rate: 0.00019799177447700676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: 18.0158	Cost: 22.20s
Train Epoch: 640 [20480/90000 (23%)]	Loss: 13.5781	Cost: 6.08s
Train Epoch: 640 [40960/90000 (45%)]	Loss: 13.6410	Cost: 6.41s
Train Epoch: 640 [61440/90000 (68%)]	Loss: 13.4310	Cost: 5.85s
Train Epoch: 640 [81920/90000 (91%)]	Loss: 13.8711	Cost: 5.77s
Train Epoch: 640 	Average Loss: 13.9184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2475

Learning rate: 0.00019798550523842447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: 18.0523	Cost: 22.67s
Train Epoch: 641 [20480/90000 (23%)]	Loss: 13.5660	Cost: 6.23s
Train Epoch: 641 [40960/90000 (45%)]	Loss: 13.7921	Cost: 6.27s
Train Epoch: 641 [61440/90000 (68%)]	Loss: 13.6504	Cost: 5.91s
Train Epoch: 641 [81920/90000 (91%)]	Loss: 13.6997	Cost: 5.71s
Train Epoch: 641 	Average Loss: 13.9004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2524

Learning rate: 0.0001979792263290605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: 17.9824	Cost: 23.23s
Train Epoch: 642 [20480/90000 (23%)]	Loss: 13.6616	Cost: 6.12s
Train Epoch: 642 [40960/90000 (45%)]	Loss: 13.6430	Cost: 6.29s
Train Epoch: 642 [61440/90000 (68%)]	Loss: 13.4833	Cost: 5.92s
Train Epoch: 642 [81920/90000 (91%)]	Loss: 13.6669	Cost: 5.77s
Train Epoch: 642 	Average Loss: 13.9097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2043

Learning rate: 0.00019797293774953458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: 18.0614	Cost: 21.97s
Train Epoch: 643 [20480/90000 (23%)]	Loss: 13.4743	Cost: 6.03s
Train Epoch: 643 [40960/90000 (45%)]	Loss: 13.5053	Cost: 6.09s
Train Epoch: 643 [61440/90000 (68%)]	Loss: 13.3677	Cost: 5.95s
Train Epoch: 643 [81920/90000 (91%)]	Loss: 13.5874	Cost: 5.97s
Train Epoch: 643 	Average Loss: 13.8671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2940

Learning rate: 0.00019796663950046741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: 18.0693	Cost: 21.42s
Train Epoch: 644 [20480/90000 (23%)]	Loss: 13.6300	Cost: 6.37s
Train Epoch: 644 [40960/90000 (45%)]	Loss: 13.6008	Cost: 6.22s
Train Epoch: 644 [61440/90000 (68%)]	Loss: 13.5109	Cost: 5.95s
Train Epoch: 644 [81920/90000 (91%)]	Loss: 13.5735	Cost: 5.78s
Train Epoch: 644 	Average Loss: 13.8676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2772

Learning rate: 0.0001979603315824805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: 18.2030	Cost: 19.90s
Train Epoch: 645 [20480/90000 (23%)]	Loss: 13.6252	Cost: 6.39s
Train Epoch: 645 [40960/90000 (45%)]	Loss: 13.8284	Cost: 6.28s
Train Epoch: 645 [61440/90000 (68%)]	Loss: 13.5935	Cost: 5.92s
Train Epoch: 645 [81920/90000 (91%)]	Loss: 13.5901	Cost: 5.99s
Train Epoch: 645 	Average Loss: 13.8941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2638

Learning rate: 0.0001979540139961965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: 18.1936	Cost: 20.31s
Train Epoch: 646 [20480/90000 (23%)]	Loss: 13.6558	Cost: 6.05s
Train Epoch: 646 [40960/90000 (45%)]	Loss: 13.5605	Cost: 6.38s
Train Epoch: 646 [61440/90000 (68%)]	Loss: 13.6136	Cost: 5.92s
Train Epoch: 646 [81920/90000 (91%)]	Loss: 13.7161	Cost: 6.04s
Train Epoch: 646 	Average Loss: 13.8936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2986

Learning rate: 0.0001979476867422389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: 18.1695	Cost: 19.60s
Train Epoch: 647 [20480/90000 (23%)]	Loss: 13.5953	Cost: 6.02s
Train Epoch: 647 [40960/90000 (45%)]	Loss: 13.6275	Cost: 6.55s
Train Epoch: 647 [61440/90000 (68%)]	Loss: 13.5227	Cost: 6.21s
Train Epoch: 647 [81920/90000 (91%)]	Loss: 13.6887	Cost: 6.77s
Train Epoch: 647 	Average Loss: 13.8994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2667

Learning rate: 0.00019794134982123216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: 18.1100	Cost: 19.68s
Train Epoch: 648 [20480/90000 (23%)]	Loss: 13.4531	Cost: 6.09s
Train Epoch: 648 [40960/90000 (45%)]	Loss: 13.6378	Cost: 6.08s
Train Epoch: 648 [61440/90000 (68%)]	Loss: 13.6126	Cost: 5.90s
Train Epoch: 648 [81920/90000 (91%)]	Loss: 13.4847	Cost: 6.64s
Train Epoch: 648 	Average Loss: 13.8361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2025

Learning rate: 0.00019793500323380173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: 18.1718	Cost: 19.96s
Train Epoch: 649 [20480/90000 (23%)]	Loss: 13.7354	Cost: 6.14s
Train Epoch: 649 [40960/90000 (45%)]	Loss: 13.6825	Cost: 6.06s
Train Epoch: 649 [61440/90000 (68%)]	Loss: 13.5701	Cost: 6.02s
Train Epoch: 649 [81920/90000 (91%)]	Loss: 13.6751	Cost: 5.90s
Train Epoch: 649 	Average Loss: 13.9317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2753

Learning rate: 0.000197928646980574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: 18.2339	Cost: 20.75s
Train Epoch: 650 [20480/90000 (23%)]	Loss: 13.6003	Cost: 6.00s
Train Epoch: 650 [40960/90000 (45%)]	Loss: 13.4841	Cost: 6.19s
Train Epoch: 650 [61440/90000 (68%)]	Loss: 13.5277	Cost: 5.85s
Train Epoch: 650 [81920/90000 (91%)]	Loss: 13.5166	Cost: 5.71s
Train Epoch: 650 	Average Loss: 13.8556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2483

Learning rate: 0.00019792228106217628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: 18.2272	Cost: 19.98s
Train Epoch: 651 [20480/90000 (23%)]	Loss: 13.4620	Cost: 6.11s
Train Epoch: 651 [40960/90000 (45%)]	Loss: 13.5608	Cost: 6.32s
Train Epoch: 651 [61440/90000 (68%)]	Loss: 13.3283	Cost: 5.91s
Train Epoch: 651 [81920/90000 (91%)]	Loss: 13.6272	Cost: 5.82s
Train Epoch: 651 	Average Loss: 13.7817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2913

Learning rate: 0.00019791590547923692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: 18.0256	Cost: 20.34s
Train Epoch: 652 [20480/90000 (23%)]	Loss: 13.5890	Cost: 6.11s
Train Epoch: 652 [40960/90000 (45%)]	Loss: 13.4485	Cost: 6.11s
Train Epoch: 652 [61440/90000 (68%)]	Loss: 13.3272	Cost: 5.90s
Train Epoch: 652 [81920/90000 (91%)]	Loss: 13.5468	Cost: 5.83s
Train Epoch: 652 	Average Loss: 13.7710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3333

Learning rate: 0.00019790952023238508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: 18.4595	Cost: 20.93s
Train Epoch: 653 [20480/90000 (23%)]	Loss: 13.3151	Cost: 6.01s
Train Epoch: 653 [40960/90000 (45%)]	Loss: 13.5298	Cost: 6.64s
Train Epoch: 653 [61440/90000 (68%)]	Loss: 13.2634	Cost: 5.87s
Train Epoch: 653 [81920/90000 (91%)]	Loss: 13.4962	Cost: 5.71s
Train Epoch: 653 	Average Loss: 13.7884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3302

Learning rate: 0.000197903125322251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: 18.2508	Cost: 20.23s
Train Epoch: 654 [20480/90000 (23%)]	Loss: 13.4048	Cost: 6.08s
Train Epoch: 654 [40960/90000 (45%)]	Loss: 13.6517	Cost: 6.12s
Train Epoch: 654 [61440/90000 (68%)]	Loss: 13.3301	Cost: 5.88s
Train Epoch: 654 [81920/90000 (91%)]	Loss: 13.4703	Cost: 5.73s
Train Epoch: 654 	Average Loss: 13.7476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3140

Learning rate: 0.00019789672074946586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: 18.1018	Cost: 20.66s
Train Epoch: 655 [20480/90000 (23%)]	Loss: 13.4505	Cost: 6.08s
Train Epoch: 655 [40960/90000 (45%)]	Loss: 13.3705	Cost: 6.21s
Train Epoch: 655 [61440/90000 (68%)]	Loss: 13.3292	Cost: 5.88s
Train Epoch: 655 [81920/90000 (91%)]	Loss: 13.4772	Cost: 5.75s
Train Epoch: 655 	Average Loss: 13.7228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3137

Learning rate: 0.00019789030651466173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: 18.3562	Cost: 21.59s
Train Epoch: 656 [20480/90000 (23%)]	Loss: 13.2769	Cost: 6.10s
Train Epoch: 656 [40960/90000 (45%)]	Loss: 13.4543	Cost: 6.13s
Train Epoch: 656 [61440/90000 (68%)]	Loss: 13.2198	Cost: 5.81s
Train Epoch: 656 [81920/90000 (91%)]	Loss: 13.5018	Cost: 5.70s
Train Epoch: 656 	Average Loss: 13.7008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3911

Learning rate: 0.0001978838826184717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: 18.2051	Cost: 20.93s
Train Epoch: 657 [20480/90000 (23%)]	Loss: 13.5011	Cost: 6.30s
Train Epoch: 657 [40960/90000 (45%)]	Loss: 13.5086	Cost: 6.40s
Train Epoch: 657 [61440/90000 (68%)]	Loss: 13.3850	Cost: 5.88s
Train Epoch: 657 [81920/90000 (91%)]	Loss: 13.4928	Cost: 6.03s
Train Epoch: 657 	Average Loss: 13.7870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3686

Learning rate: 0.00019787744906152977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: 18.2350	Cost: 22.36s
Train Epoch: 658 [20480/90000 (23%)]	Loss: 13.3982	Cost: 6.09s
Train Epoch: 658 [40960/90000 (45%)]	Loss: 13.3252	Cost: 6.46s
Train Epoch: 658 [61440/90000 (68%)]	Loss: 13.3233	Cost: 6.06s
Train Epoch: 658 [81920/90000 (91%)]	Loss: 13.5935	Cost: 5.80s
Train Epoch: 658 	Average Loss: 13.7617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3129

Learning rate: 0.00019787100584447087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: 18.2909	Cost: 20.59s
Train Epoch: 659 [20480/90000 (23%)]	Loss: 13.3455	Cost: 6.14s
Train Epoch: 659 [40960/90000 (45%)]	Loss: 13.3296	Cost: 6.19s
Train Epoch: 659 [61440/90000 (68%)]	Loss: 13.2129	Cost: 5.99s
Train Epoch: 659 [81920/90000 (91%)]	Loss: 13.4127	Cost: 5.74s
Train Epoch: 659 	Average Loss: 13.6907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3843

Learning rate: 0.00019786455296793095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: 18.3737	Cost: 23.36s
Train Epoch: 660 [20480/90000 (23%)]	Loss: 13.3774	Cost: 6.05s
Train Epoch: 660 [40960/90000 (45%)]	Loss: 13.3635	Cost: 6.53s
Train Epoch: 660 [61440/90000 (68%)]	Loss: 13.2849	Cost: 5.87s
Train Epoch: 660 [81920/90000 (91%)]	Loss: 13.4091	Cost: 6.28s
Train Epoch: 660 	Average Loss: 13.6936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3679

Learning rate: 0.0001978580904325469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: 18.3134	Cost: 22.01s
Train Epoch: 661 [20480/90000 (23%)]	Loss: 13.2061	Cost: 6.23s
Train Epoch: 661 [40960/90000 (45%)]	Loss: 13.2944	Cost: 6.19s
Train Epoch: 661 [61440/90000 (68%)]	Loss: 13.1787	Cost: 5.82s
Train Epoch: 661 [81920/90000 (91%)]	Loss: 13.3178	Cost: 5.78s
Train Epoch: 661 	Average Loss: 13.6714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4450

Learning rate: 0.00019785161823895653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: 18.3103	Cost: 23.29s
Train Epoch: 662 [20480/90000 (23%)]	Loss: 13.3624	Cost: 5.98s
Train Epoch: 662 [40960/90000 (45%)]	Loss: 13.2125	Cost: 6.45s
Train Epoch: 662 [61440/90000 (68%)]	Loss: 13.2728	Cost: 5.84s
Train Epoch: 662 [81920/90000 (91%)]	Loss: 13.3254	Cost: 5.83s
Train Epoch: 662 	Average Loss: 13.6360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4264

Learning rate: 0.00019784513638779864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: 18.2244	Cost: 22.42s
Train Epoch: 663 [20480/90000 (23%)]	Loss: 13.2538	Cost: 6.10s
Train Epoch: 663 [40960/90000 (45%)]	Loss: 13.4050	Cost: 6.18s
Train Epoch: 663 [61440/90000 (68%)]	Loss: 13.1351	Cost: 5.85s
Train Epoch: 663 [81920/90000 (91%)]	Loss: 13.4000	Cost: 5.76s
Train Epoch: 663 	Average Loss: 13.6462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4136

Learning rate: 0.0001978386448797129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: 18.3828	Cost: 24.62s
Train Epoch: 664 [20480/90000 (23%)]	Loss: 13.4142	Cost: 6.11s
Train Epoch: 664 [40960/90000 (45%)]	Loss: 13.2572	Cost: 6.23s
Train Epoch: 664 [61440/90000 (68%)]	Loss: 13.1046	Cost: 5.92s
Train Epoch: 664 [81920/90000 (91%)]	Loss: 13.3731	Cost: 5.71s
Train Epoch: 664 	Average Loss: 13.6493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3827

Learning rate: 0.00019783214371534008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: 18.4153	Cost: 21.47s
Train Epoch: 665 [20480/90000 (23%)]	Loss: 13.4387	Cost: 6.17s
Train Epoch: 665 [40960/90000 (45%)]	Loss: 13.2819	Cost: 6.18s
Train Epoch: 665 [61440/90000 (68%)]	Loss: 13.2174	Cost: 5.96s
Train Epoch: 665 [81920/90000 (91%)]	Loss: 13.2038	Cost: 5.84s
Train Epoch: 665 	Average Loss: 13.6277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3752

Learning rate: 0.00019782563289532173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: 18.1666	Cost: 22.48s
Train Epoch: 666 [20480/90000 (23%)]	Loss: 13.2301	Cost: 6.68s
Train Epoch: 666 [40960/90000 (45%)]	Loss: 13.2209	Cost: 6.55s
Train Epoch: 666 [61440/90000 (68%)]	Loss: 13.2599	Cost: 6.00s
Train Epoch: 666 [81920/90000 (91%)]	Loss: 13.3185	Cost: 6.36s
Train Epoch: 666 	Average Loss: 13.6340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3720

Learning rate: 0.0001978191124203005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: 18.1311	Cost: 21.89s
Train Epoch: 667 [20480/90000 (23%)]	Loss: 13.2948	Cost: 7.12s
Train Epoch: 667 [40960/90000 (45%)]	Loss: 13.4181	Cost: 6.14s
Train Epoch: 667 [61440/90000 (68%)]	Loss: 13.1920	Cost: 5.92s
Train Epoch: 667 [81920/90000 (91%)]	Loss: 13.4774	Cost: 5.73s
Train Epoch: 667 	Average Loss: 13.6541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3951

Learning rate: 0.00019781258229091995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: 18.3930	Cost: 19.20s
Train Epoch: 668 [20480/90000 (23%)]	Loss: 13.2841	Cost: 7.05s
Train Epoch: 668 [40960/90000 (45%)]	Loss: 13.2091	Cost: 6.18s
Train Epoch: 668 [61440/90000 (68%)]	Loss: 13.3555	Cost: 6.06s
Train Epoch: 668 [81920/90000 (91%)]	Loss: 13.3717	Cost: 5.82s
Train Epoch: 668 	Average Loss: 13.6400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3976

Learning rate: 0.00019780604250782451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: 18.2395	Cost: 20.53s
Train Epoch: 669 [20480/90000 (23%)]	Loss: 13.2603	Cost: 6.11s
Train Epoch: 669 [40960/90000 (45%)]	Loss: 13.2518	Cost: 6.10s
Train Epoch: 669 [61440/90000 (68%)]	Loss: 13.1137	Cost: 6.10s
Train Epoch: 669 [81920/90000 (91%)]	Loss: 13.4950	Cost: 5.75s
Train Epoch: 669 	Average Loss: 13.6443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4114

Learning rate: 0.00019779949307165972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: 18.4910	Cost: 20.58s
Train Epoch: 670 [20480/90000 (23%)]	Loss: 13.2435	Cost: 6.01s
Train Epoch: 670 [40960/90000 (45%)]	Loss: 13.3643	Cost: 6.12s
Train Epoch: 670 [61440/90000 (68%)]	Loss: 13.2401	Cost: 5.93s
Train Epoch: 670 [81920/90000 (91%)]	Loss: 13.3110	Cost: 5.79s
Train Epoch: 670 	Average Loss: 13.6329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4679

Learning rate: 0.00019779293398307192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: 18.2231	Cost: 20.37s
Train Epoch: 671 [20480/90000 (23%)]	Loss: 13.4801	Cost: 6.14s
Train Epoch: 671 [40960/90000 (45%)]	Loss: 13.3656	Cost: 6.28s
Train Epoch: 671 [61440/90000 (68%)]	Loss: 13.2036	Cost: 5.90s
Train Epoch: 671 [81920/90000 (91%)]	Loss: 13.2045	Cost: 6.51s
Train Epoch: 671 	Average Loss: 13.5999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4721

Learning rate: 0.00019778636524270848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: 18.2414	Cost: 20.52s
Train Epoch: 672 [20480/90000 (23%)]	Loss: 13.2505	Cost: 6.10s
Train Epoch: 672 [40960/90000 (45%)]	Loss: 13.2572	Cost: 6.07s
Train Epoch: 672 [61440/90000 (68%)]	Loss: 13.0353	Cost: 5.88s
Train Epoch: 672 [81920/90000 (91%)]	Loss: 13.1904	Cost: 5.85s
Train Epoch: 672 	Average Loss: 13.5689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4385

Learning rate: 0.0001977797868512177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: 18.2690	Cost: 20.63s
Train Epoch: 673 [20480/90000 (23%)]	Loss: 13.1714	Cost: 6.05s
Train Epoch: 673 [40960/90000 (45%)]	Loss: 13.1582	Cost: 6.15s
Train Epoch: 673 [61440/90000 (68%)]	Loss: 13.1612	Cost: 5.87s
Train Epoch: 673 [81920/90000 (91%)]	Loss: 13.4099	Cost: 5.75s
Train Epoch: 673 	Average Loss: 13.5825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4944

Learning rate: 0.00019777319880924887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: 18.4299	Cost: 20.98s
Train Epoch: 674 [20480/90000 (23%)]	Loss: 13.1870	Cost: 6.16s
Train Epoch: 674 [40960/90000 (45%)]	Loss: 13.2803	Cost: 6.52s
Train Epoch: 674 [61440/90000 (68%)]	Loss: 13.1861	Cost: 5.90s
Train Epoch: 674 [81920/90000 (91%)]	Loss: 13.2158	Cost: 5.76s
Train Epoch: 674 	Average Loss: 13.5512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5073

Learning rate: 0.0001977666011174522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: 18.4131	Cost: 21.07s
Train Epoch: 675 [20480/90000 (23%)]	Loss: 13.1603	Cost: 6.04s
Train Epoch: 675 [40960/90000 (45%)]	Loss: 13.1124	Cost: 6.91s
Train Epoch: 675 [61440/90000 (68%)]	Loss: 13.2012	Cost: 5.87s
Train Epoch: 675 [81920/90000 (91%)]	Loss: 13.1955	Cost: 6.01s
Train Epoch: 675 	Average Loss: 13.5180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4750

Learning rate: 0.00019775999377647882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: 18.3581	Cost: 20.40s
Train Epoch: 676 [20480/90000 (23%)]	Loss: 13.2760	Cost: 6.04s
Train Epoch: 676 [40960/90000 (45%)]	Loss: 13.1714	Cost: 6.14s
Train Epoch: 676 [61440/90000 (68%)]	Loss: 13.2093	Cost: 5.91s
Train Epoch: 676 [81920/90000 (91%)]	Loss: 13.2463	Cost: 5.74s
Train Epoch: 676 	Average Loss: 13.5262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5529

Learning rate: 0.00019775337678698088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: 18.3743	Cost: 20.32s
Train Epoch: 677 [20480/90000 (23%)]	Loss: 13.1979	Cost: 6.07s
Train Epoch: 677 [40960/90000 (45%)]	Loss: 13.2461	Cost: 6.29s
Train Epoch: 677 [61440/90000 (68%)]	Loss: 13.0549	Cost: 5.91s
Train Epoch: 677 [81920/90000 (91%)]	Loss: 13.2108	Cost: 5.73s
Train Epoch: 677 	Average Loss: 13.5194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5187

Learning rate: 0.00019774675014961146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: 18.3852	Cost: 20.83s
Train Epoch: 678 [20480/90000 (23%)]	Loss: 13.2909	Cost: 6.25s
Train Epoch: 678 [40960/90000 (45%)]	Loss: 13.1467	Cost: 6.19s
Train Epoch: 678 [61440/90000 (68%)]	Loss: 13.1310	Cost: 5.86s
Train Epoch: 678 [81920/90000 (91%)]	Loss: 13.2567	Cost: 5.73s
Train Epoch: 678 	Average Loss: 13.5122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5265

Learning rate: 0.00019774011386502452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: 18.4627	Cost: 20.83s
Train Epoch: 679 [20480/90000 (23%)]	Loss: 13.1605	Cost: 6.09s
Train Epoch: 679 [40960/90000 (45%)]	Loss: 13.1061	Cost: 6.53s
Train Epoch: 679 [61440/90000 (68%)]	Loss: 12.9896	Cost: 5.93s
Train Epoch: 679 [81920/90000 (91%)]	Loss: 13.0271	Cost: 5.87s
Train Epoch: 679 	Average Loss: 13.4810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4947

Learning rate: 0.0001977334679338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: 18.4286	Cost: 20.26s
Train Epoch: 680 [20480/90000 (23%)]	Loss: 13.1037	Cost: 5.98s
Train Epoch: 680 [40960/90000 (45%)]	Loss: 13.1283	Cost: 6.13s
Train Epoch: 680 [61440/90000 (68%)]	Loss: 13.0590	Cost: 6.10s
Train Epoch: 680 [81920/90000 (91%)]	Loss: 13.4258	Cost: 5.74s
Train Epoch: 680 	Average Loss: 13.4879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5968

Learning rate: 0.0001977268123568191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: 18.7174	Cost: 21.01s
Train Epoch: 681 [20480/90000 (23%)]	Loss: 13.0325	Cost: 6.03s
Train Epoch: 681 [40960/90000 (45%)]	Loss: 13.0211	Cost: 6.08s
Train Epoch: 681 [61440/90000 (68%)]	Loss: 13.1158	Cost: 5.85s
Train Epoch: 681 [81920/90000 (91%)]	Loss: 13.1808	Cost: 5.75s
Train Epoch: 681 	Average Loss: 13.4630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5119

Learning rate: 0.00019772014713451342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: 18.6794	Cost: 21.10s
Train Epoch: 682 [20480/90000 (23%)]	Loss: 13.1914	Cost: 6.14s
Train Epoch: 682 [40960/90000 (45%)]	Loss: 13.1351	Cost: 6.07s
Train Epoch: 682 [61440/90000 (68%)]	Loss: 13.0217	Cost: 5.99s
Train Epoch: 682 [81920/90000 (91%)]	Loss: 13.2279	Cost: 6.33s
Train Epoch: 682 	Average Loss: 13.4463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5760

Learning rate: 0.00019771347226761588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: 18.4854	Cost: 23.43s
Train Epoch: 683 [20480/90000 (23%)]	Loss: 13.0515	Cost: 6.15s
Train Epoch: 683 [40960/90000 (45%)]	Loss: 13.0951	Cost: 6.18s
Train Epoch: 683 [61440/90000 (68%)]	Loss: 13.0554	Cost: 5.93s
Train Epoch: 683 [81920/90000 (91%)]	Loss: 13.2011	Cost: 5.76s
Train Epoch: 683 	Average Loss: 13.4478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5018

Learning rate: 0.00019770678775678525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: 18.3867	Cost: 23.48s
Train Epoch: 684 [20480/90000 (23%)]	Loss: 12.9198	Cost: 6.11s
Train Epoch: 684 [40960/90000 (45%)]	Loss: 13.0802	Cost: 6.12s
Train Epoch: 684 [61440/90000 (68%)]	Loss: 12.9032	Cost: 5.90s
Train Epoch: 684 [81920/90000 (91%)]	Loss: 13.2102	Cost: 5.83s
Train Epoch: 684 	Average Loss: 13.4036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6037

Learning rate: 0.00019770009360268128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: 18.2872	Cost: 23.01s
Train Epoch: 685 [20480/90000 (23%)]	Loss: 12.9376	Cost: 6.09s
Train Epoch: 685 [40960/90000 (45%)]	Loss: 13.0417	Cost: 6.62s
Train Epoch: 685 [61440/90000 (68%)]	Loss: 13.0025	Cost: 5.96s
Train Epoch: 685 [81920/90000 (91%)]	Loss: 13.1491	Cost: 5.70s
Train Epoch: 685 	Average Loss: 13.3878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6085

Learning rate: 0.00019769338980596464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: 18.5152	Cost: 25.62s
Train Epoch: 686 [20480/90000 (23%)]	Loss: 12.9810	Cost: 6.04s
Train Epoch: 686 [40960/90000 (45%)]	Loss: 13.2349	Cost: 6.07s
Train Epoch: 686 [61440/90000 (68%)]	Loss: 12.8794	Cost: 5.95s
Train Epoch: 686 [81920/90000 (91%)]	Loss: 13.0208	Cost: 5.71s
Train Epoch: 686 	Average Loss: 13.4057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6003

Learning rate: 0.00019768667636729697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: 18.4672	Cost: 24.73s
Train Epoch: 687 [20480/90000 (23%)]	Loss: 12.8550	Cost: 6.02s
Train Epoch: 687 [40960/90000 (45%)]	Loss: 13.0585	Cost: 6.24s
Train Epoch: 687 [61440/90000 (68%)]	Loss: 13.0009	Cost: 5.93s
Train Epoch: 687 [81920/90000 (91%)]	Loss: 13.1581	Cost: 5.79s
Train Epoch: 687 	Average Loss: 13.4115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5703

Learning rate: 0.0001976799532873409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: 18.5812	Cost: 21.51s
Train Epoch: 688 [20480/90000 (23%)]	Loss: 13.0412	Cost: 6.18s
Train Epoch: 688 [40960/90000 (45%)]	Loss: 13.0779	Cost: 6.12s
Train Epoch: 688 [61440/90000 (68%)]	Loss: 12.9474	Cost: 5.95s
Train Epoch: 688 [81920/90000 (91%)]	Loss: 13.1683	Cost: 5.80s
Train Epoch: 688 	Average Loss: 13.3970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5528

Learning rate: 0.00019767322056675991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: 18.5321	Cost: 22.18s
Train Epoch: 689 [20480/90000 (23%)]	Loss: 12.9415	Cost: 6.26s
Train Epoch: 689 [40960/90000 (45%)]	Loss: 13.0481	Cost: 6.22s
Train Epoch: 689 [61440/90000 (68%)]	Loss: 12.8697	Cost: 5.89s
Train Epoch: 689 [81920/90000 (91%)]	Loss: 13.1610	Cost: 5.73s
Train Epoch: 689 	Average Loss: 13.3522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6801

Learning rate: 0.00019766647820621853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: 18.5126	Cost: 20.53s
Train Epoch: 690 [20480/90000 (23%)]	Loss: 12.9930	Cost: 6.21s
Train Epoch: 690 [40960/90000 (45%)]	Loss: 13.0362	Cost: 6.26s
Train Epoch: 690 [61440/90000 (68%)]	Loss: 12.8460	Cost: 5.99s
Train Epoch: 690 [81920/90000 (91%)]	Loss: 12.9830	Cost: 5.80s
Train Epoch: 690 	Average Loss: 13.3666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6288

Learning rate: 0.0001976597262063822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: 18.4098	Cost: 20.89s
Train Epoch: 691 [20480/90000 (23%)]	Loss: 12.8932	Cost: 6.05s
Train Epoch: 691 [40960/90000 (45%)]	Loss: 12.9687	Cost: 6.51s
Train Epoch: 691 [61440/90000 (68%)]	Loss: 12.8930	Cost: 6.04s
Train Epoch: 691 [81920/90000 (91%)]	Loss: 13.1475	Cost: 5.78s
Train Epoch: 691 	Average Loss: 13.3188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6946

Learning rate: 0.00019765296456791733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: 18.7264	Cost: 20.09s
Train Epoch: 692 [20480/90000 (23%)]	Loss: 12.8361	Cost: 6.04s
Train Epoch: 692 [40960/90000 (45%)]	Loss: 12.9759	Cost: 6.04s
Train Epoch: 692 [61440/90000 (68%)]	Loss: 12.8518	Cost: 5.96s
Train Epoch: 692 [81920/90000 (91%)]	Loss: 13.0660	Cost: 5.90s
Train Epoch: 692 	Average Loss: 13.3158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7088

Learning rate: 0.00019764619329149126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: 18.6024	Cost: 21.06s
Train Epoch: 693 [20480/90000 (23%)]	Loss: 12.9276	Cost: 5.99s
Train Epoch: 693 [40960/90000 (45%)]	Loss: 12.9713	Cost: 6.47s
Train Epoch: 693 [61440/90000 (68%)]	Loss: 12.9395	Cost: 6.05s
Train Epoch: 693 [81920/90000 (91%)]	Loss: 13.0555	Cost: 6.42s
Train Epoch: 693 	Average Loss: 13.3159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6756

Learning rate: 0.00019763941237777225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: 18.5620	Cost: 20.16s
Train Epoch: 694 [20480/90000 (23%)]	Loss: 12.9244	Cost: 6.09s
Train Epoch: 694 [40960/90000 (45%)]	Loss: 12.9970	Cost: 6.18s
Train Epoch: 694 [61440/90000 (68%)]	Loss: 12.8338	Cost: 5.95s
Train Epoch: 694 [81920/90000 (91%)]	Loss: 13.0879	Cost: 5.88s
Train Epoch: 694 	Average Loss: 13.3075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6875

Learning rate: 0.0001976326218274296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: 18.6723	Cost: 20.18s
Train Epoch: 695 [20480/90000 (23%)]	Loss: 12.9815	Cost: 6.06s
Train Epoch: 695 [40960/90000 (45%)]	Loss: 13.0570	Cost: 6.02s
Train Epoch: 695 [61440/90000 (68%)]	Loss: 12.8157	Cost: 5.87s
Train Epoch: 695 [81920/90000 (91%)]	Loss: 13.0467	Cost: 5.85s
Train Epoch: 695 	Average Loss: 13.3114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7693

Learning rate: 0.00019762582164113346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: 18.5726	Cost: 20.30s
Train Epoch: 696 [20480/90000 (23%)]	Loss: 13.0519	Cost: 6.02s
Train Epoch: 696 [40960/90000 (45%)]	Loss: 13.0472	Cost: 6.08s
Train Epoch: 696 [61440/90000 (68%)]	Loss: 12.8194	Cost: 5.89s
Train Epoch: 696 [81920/90000 (91%)]	Loss: 12.9924	Cost: 5.74s
Train Epoch: 696 	Average Loss: 13.3457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7918

Learning rate: 0.00019761901181955505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: 18.5430	Cost: 20.18s
Train Epoch: 697 [20480/90000 (23%)]	Loss: 12.8980	Cost: 6.10s
Train Epoch: 697 [40960/90000 (45%)]	Loss: 12.9175	Cost: 6.01s
Train Epoch: 697 [61440/90000 (68%)]	Loss: 12.7821	Cost: 5.92s
Train Epoch: 697 [81920/90000 (91%)]	Loss: 12.8830	Cost: 5.76s
Train Epoch: 697 	Average Loss: 13.2397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7756

Learning rate: 0.0001976121923633664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: 18.8206	Cost: 19.82s
Train Epoch: 698 [20480/90000 (23%)]	Loss: 12.8819	Cost: 6.16s
Train Epoch: 698 [40960/90000 (45%)]	Loss: 12.8470	Cost: 6.68s
Train Epoch: 698 [61440/90000 (68%)]	Loss: 12.6833	Cost: 5.81s
Train Epoch: 698 [81920/90000 (91%)]	Loss: 12.9279	Cost: 5.73s
Train Epoch: 698 	Average Loss: 13.2554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7086

Learning rate: 0.0001976053632732406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: 18.4348	Cost: 20.00s
Train Epoch: 699 [20480/90000 (23%)]	Loss: 12.8712	Cost: 6.13s
Train Epoch: 699 [40960/90000 (45%)]	Loss: 12.7562	Cost: 6.18s
Train Epoch: 699 [61440/90000 (68%)]	Loss: 12.8223	Cost: 5.91s
Train Epoch: 699 [81920/90000 (91%)]	Loss: 12.9776	Cost: 5.71s
Train Epoch: 699 	Average Loss: 13.2343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6925

Learning rate: 0.00019759852454985166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: 18.5791	Cost: 20.64s
Train Epoch: 700 [20480/90000 (23%)]	Loss: 13.0882	Cost: 6.24s
Train Epoch: 700 [40960/90000 (45%)]	Loss: 13.0812	Cost: 6.10s
Train Epoch: 700 [61440/90000 (68%)]	Loss: 12.8198	Cost: 5.88s
Train Epoch: 700 [81920/90000 (91%)]	Loss: 13.1751	Cost: 5.77s
Train Epoch: 700 	Average Loss: 13.3531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6672

Learning rate: 0.0001975916761938745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: 18.6679	Cost: 20.73s
Train Epoch: 701 [20480/90000 (23%)]	Loss: 12.7966	Cost: 6.08s
Train Epoch: 701 [40960/90000 (45%)]	Loss: 12.8806	Cost: 6.56s
Train Epoch: 701 [61440/90000 (68%)]	Loss: 12.8375	Cost: 5.92s
Train Epoch: 701 [81920/90000 (91%)]	Loss: 12.9960	Cost: 5.92s
Train Epoch: 701 	Average Loss: 13.2686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7255

Learning rate: 0.00019758481820598506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: 18.6788	Cost: 19.53s
Train Epoch: 702 [20480/90000 (23%)]	Loss: 12.8399	Cost: 6.03s
Train Epoch: 702 [40960/90000 (45%)]	Loss: 12.9247	Cost: 6.08s
Train Epoch: 702 [61440/90000 (68%)]	Loss: 12.7638	Cost: 5.97s
Train Epoch: 702 [81920/90000 (91%)]	Loss: 12.8917	Cost: 5.74s
Train Epoch: 702 	Average Loss: 13.2502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7534

Learning rate: 0.0001975779505868602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: 18.4500	Cost: 21.45s
Train Epoch: 703 [20480/90000 (23%)]	Loss: 12.7737	Cost: 5.99s
Train Epoch: 703 [40960/90000 (45%)]	Loss: 12.8399	Cost: 6.22s
Train Epoch: 703 [61440/90000 (68%)]	Loss: 12.7232	Cost: 5.90s
Train Epoch: 703 [81920/90000 (91%)]	Loss: 12.9246	Cost: 5.73s
Train Epoch: 703 	Average Loss: 13.1887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7828

Learning rate: 0.0001975710733371777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: 18.6059	Cost: 20.39s
Train Epoch: 704 [20480/90000 (23%)]	Loss: 12.6671	Cost: 6.04s
Train Epoch: 704 [40960/90000 (45%)]	Loss: 12.7735	Cost: 6.33s
Train Epoch: 704 [61440/90000 (68%)]	Loss: 12.6868	Cost: 5.89s
Train Epoch: 704 [81920/90000 (91%)]	Loss: 12.8021	Cost: 6.14s
Train Epoch: 704 	Average Loss: 13.1534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7929

Learning rate: 0.00019756418645761634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: 18.5803	Cost: 22.46s
Train Epoch: 705 [20480/90000 (23%)]	Loss: 12.8925	Cost: 6.12s
Train Epoch: 705 [40960/90000 (45%)]	Loss: 12.6710	Cost: 6.72s
Train Epoch: 705 [61440/90000 (68%)]	Loss: 12.6061	Cost: 5.86s
Train Epoch: 705 [81920/90000 (91%)]	Loss: 13.0277	Cost: 6.09s
Train Epoch: 705 	Average Loss: 13.1942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8039

Learning rate: 0.0001975572899488558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: 18.6197	Cost: 23.79s
Train Epoch: 706 [20480/90000 (23%)]	Loss: 12.8093	Cost: 6.03s
Train Epoch: 706 [40960/90000 (45%)]	Loss: 12.8909	Cost: 6.18s
Train Epoch: 706 [61440/90000 (68%)]	Loss: 12.6194	Cost: 5.86s
Train Epoch: 706 [81920/90000 (91%)]	Loss: 13.0663	Cost: 5.76s
Train Epoch: 706 	Average Loss: 13.2767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6868

Learning rate: 0.0001975503838115768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: 18.6744	Cost: 26.63s
Train Epoch: 707 [20480/90000 (23%)]	Loss: 12.9560	Cost: 6.01s
Train Epoch: 707 [40960/90000 (45%)]	Loss: 12.9761	Cost: 6.59s
Train Epoch: 707 [61440/90000 (68%)]	Loss: 12.7385	Cost: 5.88s
Train Epoch: 707 [81920/90000 (91%)]	Loss: 13.0359	Cost: 5.86s
Train Epoch: 707 	Average Loss: 13.2884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6939

Learning rate: 0.00019754346804646088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: 18.4631	Cost: 21.50s
Train Epoch: 708 [20480/90000 (23%)]	Loss: 12.9660	Cost: 7.20s
Train Epoch: 708 [40960/90000 (45%)]	Loss: 12.8894	Cost: 6.16s
Train Epoch: 708 [61440/90000 (68%)]	Loss: 12.7530	Cost: 5.88s
Train Epoch: 708 [81920/90000 (91%)]	Loss: 12.9461	Cost: 5.71s
Train Epoch: 708 	Average Loss: 13.2467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7946

Learning rate: 0.00019753654265419063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: 18.5612	Cost: 21.99s
Train Epoch: 709 [20480/90000 (23%)]	Loss: 12.6660	Cost: 6.15s
Train Epoch: 709 [40960/90000 (45%)]	Loss: 12.5718	Cost: 6.57s
Train Epoch: 709 [61440/90000 (68%)]	Loss: 12.7458	Cost: 5.92s
Train Epoch: 709 [81920/90000 (91%)]	Loss: 12.8327	Cost: 6.18s
Train Epoch: 709 	Average Loss: 13.1652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8025

Learning rate: 0.00019752960763544955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: 18.4552	Cost: 20.84s
Train Epoch: 710 [20480/90000 (23%)]	Loss: 12.8627	Cost: 6.13s
Train Epoch: 710 [40960/90000 (45%)]	Loss: 12.8248	Cost: 6.23s
Train Epoch: 710 [61440/90000 (68%)]	Loss: 12.6198	Cost: 5.97s
Train Epoch: 710 [81920/90000 (91%)]	Loss: 12.8604	Cost: 5.71s
Train Epoch: 710 	Average Loss: 13.1459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7901

Learning rate: 0.0001975226629909221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: 18.7452	Cost: 22.43s
Train Epoch: 711 [20480/90000 (23%)]	Loss: 12.6580	Cost: 6.06s
Train Epoch: 711 [40960/90000 (45%)]	Loss: 12.7967	Cost: 6.09s
Train Epoch: 711 [61440/90000 (68%)]	Loss: 12.6535	Cost: 6.02s
Train Epoch: 711 [81920/90000 (91%)]	Loss: 12.8544	Cost: 5.85s
Train Epoch: 711 	Average Loss: 13.1088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7381

Learning rate: 0.00019751570872129367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: 18.4289	Cost: 20.09s
Train Epoch: 712 [20480/90000 (23%)]	Loss: 12.7208	Cost: 6.30s
Train Epoch: 712 [40960/90000 (45%)]	Loss: 12.7705	Cost: 6.15s
Train Epoch: 712 [61440/90000 (68%)]	Loss: 12.5074	Cost: 5.99s
Train Epoch: 712 [81920/90000 (91%)]	Loss: 12.8180	Cost: 5.79s
Train Epoch: 712 	Average Loss: 13.0829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8288

Learning rate: 0.00019750874482725065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: 18.8492	Cost: 20.90s
Train Epoch: 713 [20480/90000 (23%)]	Loss: 12.7602	Cost: 6.24s
Train Epoch: 713 [40960/90000 (45%)]	Loss: 12.7473	Cost: 6.31s
Train Epoch: 713 [61440/90000 (68%)]	Loss: 12.5504	Cost: 6.04s
Train Epoch: 713 [81920/90000 (91%)]	Loss: 12.8034	Cost: 5.72s
Train Epoch: 713 	Average Loss: 13.1317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8205

Learning rate: 0.00019750177130948036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: 18.6430	Cost: 20.66s
Train Epoch: 714 [20480/90000 (23%)]	Loss: 12.5973	Cost: 6.00s
Train Epoch: 714 [40960/90000 (45%)]	Loss: 12.7297	Cost: 6.08s
Train Epoch: 714 [61440/90000 (68%)]	Loss: 12.5416	Cost: 6.19s
Train Epoch: 714 [81920/90000 (91%)]	Loss: 12.9252	Cost: 6.86s
Train Epoch: 714 	Average Loss: 13.1040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7261

Learning rate: 0.00019749478816867102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: 18.8530	Cost: 20.56s
Train Epoch: 715 [20480/90000 (23%)]	Loss: 12.5656	Cost: 6.17s
Train Epoch: 715 [40960/90000 (45%)]	Loss: 12.5954	Cost: 6.13s
Train Epoch: 715 [61440/90000 (68%)]	Loss: 12.5652	Cost: 5.92s
Train Epoch: 715 [81920/90000 (91%)]	Loss: 12.7899	Cost: 6.24s
Train Epoch: 715 	Average Loss: 13.0715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8047

Learning rate: 0.0001974877954055119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: 18.6722	Cost: 20.30s
Train Epoch: 716 [20480/90000 (23%)]	Loss: 12.6527	Cost: 6.11s
Train Epoch: 716 [40960/90000 (45%)]	Loss: 12.6971	Cost: 6.10s
Train Epoch: 716 [61440/90000 (68%)]	Loss: 12.5014	Cost: 5.88s
Train Epoch: 716 [81920/90000 (91%)]	Loss: 12.6856	Cost: 5.76s
Train Epoch: 716 	Average Loss: 13.0415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8964

Learning rate: 0.00019748079302069307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: 18.7362	Cost: 20.19s
Train Epoch: 717 [20480/90000 (23%)]	Loss: 12.5581	Cost: 6.19s
Train Epoch: 717 [40960/90000 (45%)]	Loss: 12.6114	Cost: 6.11s
Train Epoch: 717 [61440/90000 (68%)]	Loss: 12.5970	Cost: 5.92s
Train Epoch: 717 [81920/90000 (91%)]	Loss: 12.7424	Cost: 5.68s
Train Epoch: 717 	Average Loss: 13.0155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8296

Learning rate: 0.00019747378101490567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: 18.7791	Cost: 19.71s
Train Epoch: 718 [20480/90000 (23%)]	Loss: 12.6008	Cost: 6.04s
Train Epoch: 718 [40960/90000 (45%)]	Loss: 12.7236	Cost: 6.21s
Train Epoch: 718 [61440/90000 (68%)]	Loss: 12.4910	Cost: 5.89s
Train Epoch: 718 [81920/90000 (91%)]	Loss: 12.6523	Cost: 5.73s
Train Epoch: 718 	Average Loss: 13.0632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8478

Learning rate: 0.00019746675938884178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: 18.7803	Cost: 20.91s
Train Epoch: 719 [20480/90000 (23%)]	Loss: 12.5230	Cost: 6.07s
Train Epoch: 719 [40960/90000 (45%)]	Loss: 12.7578	Cost: 6.14s
Train Epoch: 719 [61440/90000 (68%)]	Loss: 12.4472	Cost: 5.88s
Train Epoch: 719 [81920/90000 (91%)]	Loss: 12.7012	Cost: 5.72s
Train Epoch: 719 	Average Loss: 12.9871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8860

Learning rate: 0.0001974597281431944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: 18.7298	Cost: 20.54s
Train Epoch: 720 [20480/90000 (23%)]	Loss: 12.6425	Cost: 6.12s
Train Epoch: 720 [40960/90000 (45%)]	Loss: 12.7871	Cost: 6.12s
Train Epoch: 720 [61440/90000 (68%)]	Loss: 12.4491	Cost: 5.86s
Train Epoch: 720 [81920/90000 (91%)]	Loss: 12.7883	Cost: 5.74s
Train Epoch: 720 	Average Loss: 13.0356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9054

Learning rate: 0.0001974526872786575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: 18.6885	Cost: 20.40s
Train Epoch: 721 [20480/90000 (23%)]	Loss: 12.5569	Cost: 6.13s
Train Epoch: 721 [40960/90000 (45%)]	Loss: 12.6807	Cost: 6.21s
Train Epoch: 721 [61440/90000 (68%)]	Loss: 12.5034	Cost: 5.88s
Train Epoch: 721 [81920/90000 (91%)]	Loss: 12.6831	Cost: 5.71s
Train Epoch: 721 	Average Loss: 12.9837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8728

Learning rate: 0.00019744563679592594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: 18.6900	Cost: 20.52s
Train Epoch: 722 [20480/90000 (23%)]	Loss: 12.3882	Cost: 6.17s
Train Epoch: 722 [40960/90000 (45%)]	Loss: 12.5072	Cost: 6.23s
Train Epoch: 722 [61440/90000 (68%)]	Loss: 12.3574	Cost: 5.82s
Train Epoch: 722 [81920/90000 (91%)]	Loss: 12.5079	Cost: 5.76s
Train Epoch: 722 	Average Loss: 12.9531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8804

Learning rate: 0.0001974385766956956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: 18.7585	Cost: 20.56s
Train Epoch: 723 [20480/90000 (23%)]	Loss: 12.5841	Cost: 6.06s
Train Epoch: 723 [40960/90000 (45%)]	Loss: 12.6418	Cost: 6.47s
Train Epoch: 723 [61440/90000 (68%)]	Loss: 12.5479	Cost: 5.95s
Train Epoch: 723 [81920/90000 (91%)]	Loss: 12.6715	Cost: 5.78s
Train Epoch: 723 	Average Loss: 12.9464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9546

Learning rate: 0.0001974315069786633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: 18.9429	Cost: 21.23s
Train Epoch: 724 [20480/90000 (23%)]	Loss: 12.4722	Cost: 6.07s
Train Epoch: 724 [40960/90000 (45%)]	Loss: 12.6645	Cost: 6.04s
Train Epoch: 724 [61440/90000 (68%)]	Loss: 12.3666	Cost: 6.09s
Train Epoch: 724 [81920/90000 (91%)]	Loss: 12.6496	Cost: 5.83s
Train Epoch: 724 	Average Loss: 13.0211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9457

Learning rate: 0.00019742442764552676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: 18.9282	Cost: 21.43s
Train Epoch: 725 [20480/90000 (23%)]	Loss: 12.4295	Cost: 6.04s
Train Epoch: 725 [40960/90000 (45%)]	Loss: 12.7117	Cost: 6.11s
Train Epoch: 725 [61440/90000 (68%)]	Loss: 12.3504	Cost: 6.02s
Train Epoch: 725 [81920/90000 (91%)]	Loss: 12.6091	Cost: 5.74s
Train Epoch: 725 	Average Loss: 12.9880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9341

Learning rate: 0.0001974173386969847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: 18.9610	Cost: 22.05s
Train Epoch: 726 [20480/90000 (23%)]	Loss: 12.6090	Cost: 6.08s
Train Epoch: 726 [40960/90000 (45%)]	Loss: 12.6782	Cost: 6.10s
Train Epoch: 726 [61440/90000 (68%)]	Loss: 12.4330	Cost: 5.91s
Train Epoch: 726 [81920/90000 (91%)]	Loss: 12.5961	Cost: 6.01s
Train Epoch: 726 	Average Loss: 12.9876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9664

Learning rate: 0.00019741024013373678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: 18.7109	Cost: 21.90s
Train Epoch: 727 [20480/90000 (23%)]	Loss: 12.5373	Cost: 6.19s
Train Epoch: 727 [40960/90000 (45%)]	Loss: 12.5106	Cost: 6.07s
Train Epoch: 727 [61440/90000 (68%)]	Loss: 12.3572	Cost: 5.86s
Train Epoch: 727 [81920/90000 (91%)]	Loss: 12.6401	Cost: 5.77s
Train Epoch: 727 	Average Loss: 12.9540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9766

Learning rate: 0.00019740313195648358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: 18.7237	Cost: 26.11s
Train Epoch: 728 [20480/90000 (23%)]	Loss: 12.6153	Cost: 6.09s
Train Epoch: 728 [40960/90000 (45%)]	Loss: 12.6879	Cost: 6.15s
Train Epoch: 728 [61440/90000 (68%)]	Loss: 12.6032	Cost: 5.90s
Train Epoch: 728 [81920/90000 (91%)]	Loss: 12.6337	Cost: 5.70s
Train Epoch: 728 	Average Loss: 12.9932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0070

Learning rate: 0.00019739601416592667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: 18.9046	Cost: 22.99s
Train Epoch: 729 [20480/90000 (23%)]	Loss: 12.7228	Cost: 6.06s
Train Epoch: 729 [40960/90000 (45%)]	Loss: 12.6709	Cost: 6.15s
Train Epoch: 729 [61440/90000 (68%)]	Loss: 12.2578	Cost: 5.94s
Train Epoch: 729 [81920/90000 (91%)]	Loss: 12.6144	Cost: 5.72s
Train Epoch: 729 	Average Loss: 12.9838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9598

Learning rate: 0.00019738888676276855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: 18.7525	Cost: 21.30s
Train Epoch: 730 [20480/90000 (23%)]	Loss: 12.5563	Cost: 6.12s
Train Epoch: 730 [40960/90000 (45%)]	Loss: 12.5698	Cost: 6.39s
Train Epoch: 730 [61440/90000 (68%)]	Loss: 12.3449	Cost: 5.89s
Train Epoch: 730 [81920/90000 (91%)]	Loss: 12.5627	Cost: 5.79s
Train Epoch: 730 	Average Loss: 12.9163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9453

Learning rate: 0.00019738174974771262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: 19.0046	Cost: 21.48s
Train Epoch: 731 [20480/90000 (23%)]	Loss: 12.5730	Cost: 6.14s
Train Epoch: 731 [40960/90000 (45%)]	Loss: 12.7495	Cost: 6.15s
Train Epoch: 731 [61440/90000 (68%)]	Loss: 12.5554	Cost: 5.93s
Train Epoch: 731 [81920/90000 (91%)]	Loss: 12.5272	Cost: 5.80s
Train Epoch: 731 	Average Loss: 12.9758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0138

Learning rate: 0.00019737460312146333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: 18.7132	Cost: 21.07s
Train Epoch: 732 [20480/90000 (23%)]	Loss: 12.5255	Cost: 6.22s
Train Epoch: 732 [40960/90000 (45%)]	Loss: 12.5039	Cost: 6.33s
Train Epoch: 732 [61440/90000 (68%)]	Loss: 12.2808	Cost: 5.96s
Train Epoch: 732 [81920/90000 (91%)]	Loss: 12.6354	Cost: 5.86s
Train Epoch: 732 	Average Loss: 12.9328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9640

Learning rate: 0.000197367446884726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: 18.9153	Cost: 21.91s
Train Epoch: 733 [20480/90000 (23%)]	Loss: 12.4641	Cost: 6.35s
Train Epoch: 733 [40960/90000 (45%)]	Loss: 12.6341	Cost: 6.45s
Train Epoch: 733 [61440/90000 (68%)]	Loss: 12.4217	Cost: 5.94s
Train Epoch: 733 [81920/90000 (91%)]	Loss: 12.4645	Cost: 5.73s
Train Epoch: 733 	Average Loss: 12.8795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0245

Learning rate: 0.00019736028103820694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: 18.8856	Cost: 20.61s
Train Epoch: 734 [20480/90000 (23%)]	Loss: 12.3593	Cost: 5.99s
Train Epoch: 734 [40960/90000 (45%)]	Loss: 12.4787	Cost: 6.74s
Train Epoch: 734 [61440/90000 (68%)]	Loss: 12.3296	Cost: 6.06s
Train Epoch: 734 [81920/90000 (91%)]	Loss: 12.5268	Cost: 5.77s
Train Epoch: 734 	Average Loss: 12.8567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0308

Learning rate: 0.0001973531055826134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: 19.0969	Cost: 20.52s
Train Epoch: 735 [20480/90000 (23%)]	Loss: 12.4306	Cost: 6.16s
Train Epoch: 735 [40960/90000 (45%)]	Loss: 12.5311	Cost: 6.12s
Train Epoch: 735 [61440/90000 (68%)]	Loss: 12.3796	Cost: 6.32s
Train Epoch: 735 [81920/90000 (91%)]	Loss: 12.4240	Cost: 6.62s
Train Epoch: 735 	Average Loss: 12.8533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0496

Learning rate: 0.0001973459205186535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: 18.9800	Cost: 20.11s
Train Epoch: 736 [20480/90000 (23%)]	Loss: 12.7210	Cost: 6.06s
Train Epoch: 736 [40960/90000 (45%)]	Loss: 12.4972	Cost: 6.10s
Train Epoch: 736 [61440/90000 (68%)]	Loss: 12.2784	Cost: 6.07s
Train Epoch: 736 [81920/90000 (91%)]	Loss: 12.6283	Cost: 7.38s
Train Epoch: 736 	Average Loss: 12.8866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0358

Learning rate: 0.00019733872584703645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: 18.7293	Cost: 20.39s
Train Epoch: 737 [20480/90000 (23%)]	Loss: 12.5149	Cost: 5.98s
Train Epoch: 737 [40960/90000 (45%)]	Loss: 12.4475	Cost: 6.04s
Train Epoch: 737 [61440/90000 (68%)]	Loss: 12.3473	Cost: 5.95s
Train Epoch: 737 [81920/90000 (91%)]	Loss: 12.4819	Cost: 6.09s
Train Epoch: 737 	Average Loss: 12.8262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0907

Learning rate: 0.0001973315215684723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: 18.7912	Cost: 20.63s
Train Epoch: 738 [20480/90000 (23%)]	Loss: 12.3341	Cost: 6.02s
Train Epoch: 738 [40960/90000 (45%)]	Loss: 12.3883	Cost: 5.99s
Train Epoch: 738 [61440/90000 (68%)]	Loss: 12.2742	Cost: 5.92s
Train Epoch: 738 [81920/90000 (91%)]	Loss: 12.4582	Cost: 5.88s
Train Epoch: 738 	Average Loss: 12.7786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0156

Learning rate: 0.00019732430768367213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: 18.9737	Cost: 21.34s
Train Epoch: 739 [20480/90000 (23%)]	Loss: 12.2263	Cost: 6.05s
Train Epoch: 739 [40960/90000 (45%)]	Loss: 12.2851	Cost: 6.62s
Train Epoch: 739 [61440/90000 (68%)]	Loss: 12.2071	Cost: 5.85s
Train Epoch: 739 [81920/90000 (91%)]	Loss: 12.4707	Cost: 6.13s
Train Epoch: 739 	Average Loss: 12.8031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9944

Learning rate: 0.00019731708419334784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: 18.9887	Cost: 20.68s
Train Epoch: 740 [20480/90000 (23%)]	Loss: 12.5743	Cost: 6.13s
Train Epoch: 740 [40960/90000 (45%)]	Loss: 12.5888	Cost: 6.10s
Train Epoch: 740 [61440/90000 (68%)]	Loss: 12.2432	Cost: 5.81s
Train Epoch: 740 [81920/90000 (91%)]	Loss: 12.4680	Cost: 5.70s
Train Epoch: 740 	Average Loss: 12.9192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0925

Learning rate: 0.00019730985109821242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: 18.9472	Cost: 21.27s
Train Epoch: 741 [20480/90000 (23%)]	Loss: 12.3808	Cost: 5.99s
Train Epoch: 741 [40960/90000 (45%)]	Loss: 12.4813	Cost: 6.51s
Train Epoch: 741 [61440/90000 (68%)]	Loss: 12.1539	Cost: 5.86s
Train Epoch: 741 [81920/90000 (91%)]	Loss: 12.2949	Cost: 5.74s
Train Epoch: 741 	Average Loss: 12.7877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1125

Learning rate: 0.0001973026083989797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: 19.0126	Cost: 22.06s
Train Epoch: 742 [20480/90000 (23%)]	Loss: 12.3422	Cost: 6.10s
Train Epoch: 742 [40960/90000 (45%)]	Loss: 12.4601	Cost: 6.75s
Train Epoch: 742 [61440/90000 (68%)]	Loss: 12.1657	Cost: 5.83s
Train Epoch: 742 [81920/90000 (91%)]	Loss: 12.4497	Cost: 6.36s
Train Epoch: 742 	Average Loss: 12.8098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0635

Learning rate: 0.00019729535609636458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: 18.9398	Cost: 21.16s
Train Epoch: 743 [20480/90000 (23%)]	Loss: 12.3230	Cost: 6.10s
Train Epoch: 743 [40960/90000 (45%)]	Loss: 12.4375	Cost: 6.08s
Train Epoch: 743 [61440/90000 (68%)]	Loss: 12.2590	Cost: 5.88s
Train Epoch: 743 [81920/90000 (91%)]	Loss: 12.4363	Cost: 5.71s
Train Epoch: 743 	Average Loss: 12.7502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0189

Learning rate: 0.00019728809419108275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: 18.8562	Cost: 21.42s
Train Epoch: 744 [20480/90000 (23%)]	Loss: 12.3200	Cost: 6.18s
Train Epoch: 744 [40960/90000 (45%)]	Loss: 12.3397	Cost: 6.15s
Train Epoch: 744 [61440/90000 (68%)]	Loss: 12.1638	Cost: 5.87s
Train Epoch: 744 [81920/90000 (91%)]	Loss: 12.4212	Cost: 5.99s
Train Epoch: 744 	Average Loss: 12.7369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1086

Learning rate: 0.00019728082268385098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: 19.0026	Cost: 20.61s
Train Epoch: 745 [20480/90000 (23%)]	Loss: 12.3725	Cost: 6.16s
Train Epoch: 745 [40960/90000 (45%)]	Loss: 12.3183	Cost: 6.28s
Train Epoch: 745 [61440/90000 (68%)]	Loss: 12.2625	Cost: 5.90s
Train Epoch: 745 [81920/90000 (91%)]	Loss: 12.1985	Cost: 5.74s
Train Epoch: 745 	Average Loss: 12.7590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1420

Learning rate: 0.00019727354157538695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: 19.0568	Cost: 20.80s
Train Epoch: 746 [20480/90000 (23%)]	Loss: 12.2872	Cost: 6.01s
Train Epoch: 746 [40960/90000 (45%)]	Loss: 12.3026	Cost: 6.25s
Train Epoch: 746 [61440/90000 (68%)]	Loss: 12.1541	Cost: 6.04s
Train Epoch: 746 [81920/90000 (91%)]	Loss: 12.3108	Cost: 5.81s
Train Epoch: 746 	Average Loss: 12.7099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1714

Learning rate: 0.00019726625086640925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: 19.0073	Cost: 21.01s
Train Epoch: 747 [20480/90000 (23%)]	Loss: 12.1510	Cost: 6.00s
Train Epoch: 747 [40960/90000 (45%)]	Loss: 12.3823	Cost: 6.13s
Train Epoch: 747 [61440/90000 (68%)]	Loss: 12.2164	Cost: 5.94s
Train Epoch: 747 [81920/90000 (91%)]	Loss: 12.2481	Cost: 5.78s
Train Epoch: 747 	Average Loss: 12.7362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1106

Learning rate: 0.00019725895055763745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: 19.1143	Cost: 23.40s
Train Epoch: 748 [20480/90000 (23%)]	Loss: 12.1232	Cost: 6.02s
Train Epoch: 748 [40960/90000 (45%)]	Loss: 12.2386	Cost: 6.67s
Train Epoch: 748 [61440/90000 (68%)]	Loss: 11.8934	Cost: 5.93s
Train Epoch: 748 [81920/90000 (91%)]	Loss: 12.3240	Cost: 6.53s
Train Epoch: 748 	Average Loss: 12.6862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2037

Learning rate: 0.00019725164064979207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: 19.1112	Cost: 23.37s
Train Epoch: 749 [20480/90000 (23%)]	Loss: 12.1866	Cost: 5.96s
Train Epoch: 749 [40960/90000 (45%)]	Loss: 12.3606	Cost: 6.58s
Train Epoch: 749 [61440/90000 (68%)]	Loss: 12.0362	Cost: 5.91s
Train Epoch: 749 [81920/90000 (91%)]	Loss: 12.3520	Cost: 5.90s
Train Epoch: 749 	Average Loss: 12.6587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2004

Learning rate: 0.00019724432114359458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: 18.9662	Cost: 23.11s
Train Epoch: 750 [20480/90000 (23%)]	Loss: 12.3326	Cost: 5.97s
Train Epoch: 750 [40960/90000 (45%)]	Loss: 12.2337	Cost: 6.45s
Train Epoch: 750 [61440/90000 (68%)]	Loss: 11.9819	Cost: 5.91s
Train Epoch: 750 [81920/90000 (91%)]	Loss: 12.3983	Cost: 5.92s
Train Epoch: 750 	Average Loss: 12.6745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2077

Learning rate: 0.00019723699203976736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: 19.0416	Cost: 22.30s
Train Epoch: 751 [20480/90000 (23%)]	Loss: 12.1237	Cost: 6.12s
Train Epoch: 751 [40960/90000 (45%)]	Loss: 12.2022	Cost: 6.51s
Train Epoch: 751 [61440/90000 (68%)]	Loss: 12.0237	Cost: 5.91s
Train Epoch: 751 [81920/90000 (91%)]	Loss: 12.2685	Cost: 6.10s
Train Epoch: 751 	Average Loss: 12.6378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1748

Learning rate: 0.0001972296533390338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: 19.0866	Cost: 22.44s
Train Epoch: 752 [20480/90000 (23%)]	Loss: 12.2024	Cost: 6.05s
Train Epoch: 752 [40960/90000 (45%)]	Loss: 12.2266	Cost: 6.19s
Train Epoch: 752 [61440/90000 (68%)]	Loss: 12.1888	Cost: 5.92s
Train Epoch: 752 [81920/90000 (91%)]	Loss: 12.2564	Cost: 5.93s
Train Epoch: 752 	Average Loss: 12.6749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2048

Learning rate: 0.00019722230504211813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: 19.1199	Cost: 23.74s
Train Epoch: 753 [20480/90000 (23%)]	Loss: 12.2409	Cost: 6.17s
Train Epoch: 753 [40960/90000 (45%)]	Loss: 12.3061	Cost: 6.08s
Train Epoch: 753 [61440/90000 (68%)]	Loss: 12.0704	Cost: 5.90s
Train Epoch: 753 [81920/90000 (91%)]	Loss: 12.3772	Cost: 5.78s
Train Epoch: 753 	Average Loss: 12.6528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1261

Learning rate: 0.00019721494714974565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: 19.0312	Cost: 23.20s
Train Epoch: 754 [20480/90000 (23%)]	Loss: 12.2252	Cost: 6.08s
Train Epoch: 754 [40960/90000 (45%)]	Loss: 12.2165	Cost: 6.08s
Train Epoch: 754 [61440/90000 (68%)]	Loss: 12.0699	Cost: 5.97s
Train Epoch: 754 [81920/90000 (91%)]	Loss: 12.3800	Cost: 5.88s
Train Epoch: 754 	Average Loss: 12.6661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1541

Learning rate: 0.00019720757966264256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: 19.0835	Cost: 23.03s
Train Epoch: 755 [20480/90000 (23%)]	Loss: 12.0728	Cost: 6.08s
Train Epoch: 755 [40960/90000 (45%)]	Loss: 12.2296	Cost: 6.17s
Train Epoch: 755 [61440/90000 (68%)]	Loss: 12.0434	Cost: 5.90s
Train Epoch: 755 [81920/90000 (91%)]	Loss: 12.1199	Cost: 5.95s
Train Epoch: 755 	Average Loss: 12.6247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1789

Learning rate: 0.00019720020258153596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: 19.1218	Cost: 20.68s
Train Epoch: 756 [20480/90000 (23%)]	Loss: 12.1421	Cost: 6.12s
Train Epoch: 756 [40960/90000 (45%)]	Loss: 12.2197	Cost: 6.71s
Train Epoch: 756 [61440/90000 (68%)]	Loss: 11.9065	Cost: 6.03s
Train Epoch: 756 [81920/90000 (91%)]	Loss: 12.3065	Cost: 5.77s
Train Epoch: 756 	Average Loss: 12.5841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1902

Learning rate: 0.000197192815907154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: 19.2030	Cost: 20.87s
Train Epoch: 757 [20480/90000 (23%)]	Loss: 12.0895	Cost: 5.97s
Train Epoch: 757 [40960/90000 (45%)]	Loss: 12.3321	Cost: 6.87s
Train Epoch: 757 [61440/90000 (68%)]	Loss: 12.2236	Cost: 6.12s
Train Epoch: 757 [81920/90000 (91%)]	Loss: 12.2912	Cost: 5.94s
Train Epoch: 757 	Average Loss: 12.6698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1717

Learning rate: 0.00019718541964022568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: 18.9816	Cost: 20.42s
Train Epoch: 758 [20480/90000 (23%)]	Loss: 12.2628	Cost: 6.02s
Train Epoch: 758 [40960/90000 (45%)]	Loss: 12.1561	Cost: 6.66s
Train Epoch: 758 [61440/90000 (68%)]	Loss: 12.2974	Cost: 6.20s
Train Epoch: 758 [81920/90000 (91%)]	Loss: 12.2953	Cost: 5.82s
Train Epoch: 758 	Average Loss: 12.6942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1942

Learning rate: 0.00019717801378148098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: 19.0496	Cost: 20.86s
Train Epoch: 759 [20480/90000 (23%)]	Loss: 12.5319	Cost: 6.05s
Train Epoch: 759 [40960/90000 (45%)]	Loss: 12.5326	Cost: 6.11s
Train Epoch: 759 [61440/90000 (68%)]	Loss: 12.4201	Cost: 6.05s
Train Epoch: 759 [81920/90000 (91%)]	Loss: 12.5993	Cost: 6.57s
Train Epoch: 759 	Average Loss: 12.9153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1845

Learning rate: 0.0001971705983316508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: 19.0000	Cost: 20.35s
Train Epoch: 760 [20480/90000 (23%)]	Loss: 12.2748	Cost: 6.24s
Train Epoch: 760 [40960/90000 (45%)]	Loss: 12.2126	Cost: 6.21s
Train Epoch: 760 [61440/90000 (68%)]	Loss: 12.1239	Cost: 5.94s
Train Epoch: 760 [81920/90000 (91%)]	Loss: 12.1521	Cost: 5.99s
Train Epoch: 760 	Average Loss: 12.6561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2406

Learning rate: 0.0001971631732914671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: 19.0105	Cost: 20.86s
Train Epoch: 761 [20480/90000 (23%)]	Loss: 12.0435	Cost: 6.13s
Train Epoch: 761 [40960/90000 (45%)]	Loss: 12.1676	Cost: 6.22s
Train Epoch: 761 [61440/90000 (68%)]	Loss: 12.2064	Cost: 5.97s
Train Epoch: 761 [81920/90000 (91%)]	Loss: 12.3100	Cost: 5.94s
Train Epoch: 761 	Average Loss: 12.5924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2525

Learning rate: 0.00019715573866166262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: 19.1068	Cost: 20.00s
Train Epoch: 762 [20480/90000 (23%)]	Loss: 12.2372	Cost: 6.14s
Train Epoch: 762 [40960/90000 (45%)]	Loss: 11.9719	Cost: 6.13s
Train Epoch: 762 [61440/90000 (68%)]	Loss: 12.2400	Cost: 5.77s
Train Epoch: 762 [81920/90000 (91%)]	Loss: 12.1889	Cost: 5.58s
Train Epoch: 762 	Average Loss: 12.6301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2404

Learning rate: 0.0001971482944429712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: 19.0233	Cost: 20.05s
Train Epoch: 763 [20480/90000 (23%)]	Loss: 12.2423	Cost: 6.09s
Train Epoch: 763 [40960/90000 (45%)]	Loss: 12.1900	Cost: 6.19s
Train Epoch: 763 [61440/90000 (68%)]	Loss: 12.0326	Cost: 5.89s
Train Epoch: 763 [81920/90000 (91%)]	Loss: 12.2174	Cost: 6.18s
Train Epoch: 763 	Average Loss: 12.6110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2259

Learning rate: 0.00019714084063612747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: 19.0477	Cost: 19.70s
Train Epoch: 764 [20480/90000 (23%)]	Loss: 11.9702	Cost: 6.06s
Train Epoch: 764 [40960/90000 (45%)]	Loss: 12.2209	Cost: 6.13s
Train Epoch: 764 [61440/90000 (68%)]	Loss: 11.9599	Cost: 5.85s
Train Epoch: 764 [81920/90000 (91%)]	Loss: 12.1655	Cost: 5.76s
Train Epoch: 764 	Average Loss: 12.5755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2575

Learning rate: 0.00019713337724186716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: 19.1744	Cost: 20.67s
Train Epoch: 765 [20480/90000 (23%)]	Loss: 11.9734	Cost: 5.91s
Train Epoch: 765 [40960/90000 (45%)]	Loss: 12.1345	Cost: 6.10s
Train Epoch: 765 [61440/90000 (68%)]	Loss: 12.0088	Cost: 5.85s
Train Epoch: 765 [81920/90000 (91%)]	Loss: 12.1756	Cost: 5.68s
Train Epoch: 765 	Average Loss: 12.5463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2652

Learning rate: 0.00019712590426092686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: 19.0951	Cost: 20.75s
Train Epoch: 766 [20480/90000 (23%)]	Loss: 11.8414	Cost: 5.99s
Train Epoch: 766 [40960/90000 (45%)]	Loss: 11.9946	Cost: 6.29s
Train Epoch: 766 [61440/90000 (68%)]	Loss: 11.9827	Cost: 5.87s
Train Epoch: 766 [81920/90000 (91%)]	Loss: 11.9933	Cost: 6.06s
Train Epoch: 766 	Average Loss: 12.4781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2839

Learning rate: 0.0001971184216940441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: 19.1810	Cost: 20.37s
Train Epoch: 767 [20480/90000 (23%)]	Loss: 12.0252	Cost: 6.12s
Train Epoch: 767 [40960/90000 (45%)]	Loss: 12.2592	Cost: 6.26s
Train Epoch: 767 [61440/90000 (68%)]	Loss: 12.3948	Cost: 5.86s
Train Epoch: 767 [81920/90000 (91%)]	Loss: 12.4475	Cost: 5.69s
Train Epoch: 767 	Average Loss: 12.7148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2171

Learning rate: 0.0001971109295419574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: 18.9030	Cost: 20.77s
Train Epoch: 768 [20480/90000 (23%)]	Loss: 12.4481	Cost: 6.02s
Train Epoch: 768 [40960/90000 (45%)]	Loss: 12.2222	Cost: 6.44s
Train Epoch: 768 [61440/90000 (68%)]	Loss: 12.2335	Cost: 5.89s
Train Epoch: 768 [81920/90000 (91%)]	Loss: 12.4184	Cost: 5.86s
Train Epoch: 768 	Average Loss: 12.7388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1957

Learning rate: 0.0001971034278054062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: 19.2302	Cost: 20.06s
Train Epoch: 769 [20480/90000 (23%)]	Loss: 12.1394	Cost: 6.01s
Train Epoch: 769 [40960/90000 (45%)]	Loss: 12.0428	Cost: 6.39s
Train Epoch: 769 [61440/90000 (68%)]	Loss: 11.9383	Cost: 5.92s
Train Epoch: 769 [81920/90000 (91%)]	Loss: 12.0668	Cost: 5.68s
Train Epoch: 769 	Average Loss: 12.5270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2023

Learning rate: 0.00019709591648513092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: 19.1144	Cost: 21.16s
Train Epoch: 770 [20480/90000 (23%)]	Loss: 11.9101	Cost: 6.16s
Train Epoch: 770 [40960/90000 (45%)]	Loss: 12.0822	Cost: 6.09s
Train Epoch: 770 [61440/90000 (68%)]	Loss: 12.0885	Cost: 5.86s
Train Epoch: 770 [81920/90000 (91%)]	Loss: 12.1540	Cost: 5.73s
Train Epoch: 770 	Average Loss: 12.5047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2997

Learning rate: 0.00019708839558187284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: 19.2022	Cost: 21.59s
Train Epoch: 771 [20480/90000 (23%)]	Loss: 11.8374	Cost: 6.11s
Train Epoch: 771 [40960/90000 (45%)]	Loss: 12.1753	Cost: 6.06s
Train Epoch: 771 [61440/90000 (68%)]	Loss: 11.9118	Cost: 5.94s
Train Epoch: 771 [81920/90000 (91%)]	Loss: 12.0323	Cost: 5.79s
Train Epoch: 771 	Average Loss: 12.4392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2299

Learning rate: 0.0001970808650963743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: 18.9049	Cost: 23.51s
Train Epoch: 772 [20480/90000 (23%)]	Loss: 11.9091	Cost: 6.12s
Train Epoch: 772 [40960/90000 (45%)]	Loss: 11.9247	Cost: 6.30s
Train Epoch: 772 [61440/90000 (68%)]	Loss: 11.9870	Cost: 5.89s
Train Epoch: 772 [81920/90000 (91%)]	Loss: 12.0238	Cost: 5.89s
Train Epoch: 772 	Average Loss: 12.4033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2955

Learning rate: 0.00019707332502937847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: 19.2857	Cost: 23.61s
Train Epoch: 773 [20480/90000 (23%)]	Loss: 11.9407	Cost: 5.99s
Train Epoch: 773 [40960/90000 (45%)]	Loss: 12.0268	Cost: 6.13s
Train Epoch: 773 [61440/90000 (68%)]	Loss: 11.8346	Cost: 5.92s
Train Epoch: 773 [81920/90000 (91%)]	Loss: 12.0086	Cost: 5.76s
Train Epoch: 773 	Average Loss: 12.4334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3402

Learning rate: 0.00019706577538162957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: 19.2455	Cost: 21.95s
Train Epoch: 774 [20480/90000 (23%)]	Loss: 11.7952	Cost: 7.32s
Train Epoch: 774 [40960/90000 (45%)]	Loss: 11.8546	Cost: 6.75s
Train Epoch: 774 [61440/90000 (68%)]	Loss: 11.6619	Cost: 5.88s
Train Epoch: 774 [81920/90000 (91%)]	Loss: 11.9295	Cost: 5.57s
Train Epoch: 774 	Average Loss: 12.3787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3815

Learning rate: 0.00019705821615387272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: 19.1653	Cost: 22.14s
Train Epoch: 775 [20480/90000 (23%)]	Loss: 12.0213	Cost: 6.30s
Train Epoch: 775 [40960/90000 (45%)]	Loss: 11.8489	Cost: 6.14s
Train Epoch: 775 [61440/90000 (68%)]	Loss: 11.7830	Cost: 5.94s
Train Epoch: 775 [81920/90000 (91%)]	Loss: 11.9360	Cost: 6.04s
Train Epoch: 775 	Average Loss: 12.3915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3602

Learning rate: 0.000197050647346854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: 19.2104	Cost: 21.59s
Train Epoch: 776 [20480/90000 (23%)]	Loss: 12.0364	Cost: 6.16s
Train Epoch: 776 [40960/90000 (45%)]	Loss: 11.7405	Cost: 6.22s
Train Epoch: 776 [61440/90000 (68%)]	Loss: 11.9084	Cost: 6.04s
Train Epoch: 776 [81920/90000 (91%)]	Loss: 12.0231	Cost: 6.00s
Train Epoch: 776 	Average Loss: 12.4162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3511

Learning rate: 0.0001970430689613204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: 19.0665	Cost: 21.60s
Train Epoch: 777 [20480/90000 (23%)]	Loss: 11.8698	Cost: 6.49s
Train Epoch: 777 [40960/90000 (45%)]	Loss: 12.0102	Cost: 6.15s
Train Epoch: 777 [61440/90000 (68%)]	Loss: 11.8542	Cost: 5.99s
Train Epoch: 777 [81920/90000 (91%)]	Loss: 12.0324	Cost: 5.89s
Train Epoch: 777 	Average Loss: 12.3908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3906

Learning rate: 0.00019703548099801984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: 19.1804	Cost: 21.22s
Train Epoch: 778 [20480/90000 (23%)]	Loss: 11.9423	Cost: 6.13s
Train Epoch: 778 [40960/90000 (45%)]	Loss: 12.1306	Cost: 6.25s
Train Epoch: 778 [61440/90000 (68%)]	Loss: 11.7863	Cost: 6.00s
Train Epoch: 778 [81920/90000 (91%)]	Loss: 12.0537	Cost: 5.72s
Train Epoch: 778 	Average Loss: 12.3921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4000

Learning rate: 0.00019702788345770126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: 19.2096	Cost: 20.90s
Train Epoch: 779 [20480/90000 (23%)]	Loss: 11.6934	Cost: 6.11s
Train Epoch: 779 [40960/90000 (45%)]	Loss: 12.2619	Cost: 6.19s
Train Epoch: 779 [61440/90000 (68%)]	Loss: 12.0344	Cost: 6.20s
Train Epoch: 779 [81920/90000 (91%)]	Loss: 12.2137	Cost: 5.78s
Train Epoch: 779 	Average Loss: 12.4525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3959

Learning rate: 0.0001970202763411145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: 19.2528	Cost: 19.94s
Train Epoch: 780 [20480/90000 (23%)]	Loss: 11.9854	Cost: 6.04s
Train Epoch: 780 [40960/90000 (45%)]	Loss: 11.9762	Cost: 6.50s
Train Epoch: 780 [61440/90000 (68%)]	Loss: 11.9729	Cost: 5.97s
Train Epoch: 780 [81920/90000 (91%)]	Loss: 12.2503	Cost: 6.07s
Train Epoch: 780 	Average Loss: 12.5250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3494

Learning rate: 0.00019701265964901035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: 19.2265	Cost: 20.41s
Train Epoch: 781 [20480/90000 (23%)]	Loss: 11.9637	Cost: 6.14s
Train Epoch: 781 [40960/90000 (45%)]	Loss: 11.9919	Cost: 6.10s
Train Epoch: 781 [61440/90000 (68%)]	Loss: 11.8654	Cost: 6.15s
Train Epoch: 781 [81920/90000 (91%)]	Loss: 12.1231	Cost: 6.19s
Train Epoch: 781 	Average Loss: 12.5248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3714

Learning rate: 0.00019700503338214057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: 19.1881	Cost: 19.93s
Train Epoch: 782 [20480/90000 (23%)]	Loss: 11.9761	Cost: 6.05s
Train Epoch: 782 [40960/90000 (45%)]	Loss: 12.0985	Cost: 6.07s
Train Epoch: 782 [61440/90000 (68%)]	Loss: 11.7577	Cost: 5.86s
Train Epoch: 782 [81920/90000 (91%)]	Loss: 12.0775	Cost: 6.15s
Train Epoch: 782 	Average Loss: 12.4813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3583

Learning rate: 0.0001969973975412578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: 19.0543	Cost: 20.45s
Train Epoch: 783 [20480/90000 (23%)]	Loss: 11.7906	Cost: 6.06s
Train Epoch: 783 [40960/90000 (45%)]	Loss: 11.9031	Cost: 6.05s
Train Epoch: 783 [61440/90000 (68%)]	Loss: 11.8412	Cost: 5.91s
Train Epoch: 783 [81920/90000 (91%)]	Loss: 11.9116	Cost: 5.82s
Train Epoch: 783 	Average Loss: 12.3663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3601

Learning rate: 0.00019698975212711572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: 19.2601	Cost: 20.46s
Train Epoch: 784 [20480/90000 (23%)]	Loss: 12.0059	Cost: 6.01s
Train Epoch: 784 [40960/90000 (45%)]	Loss: 12.1102	Cost: 6.84s
Train Epoch: 784 [61440/90000 (68%)]	Loss: 11.8104	Cost: 5.84s
Train Epoch: 784 [81920/90000 (91%)]	Loss: 12.0410	Cost: 5.87s
Train Epoch: 784 	Average Loss: 12.4652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3361

Learning rate: 0.00019698209714046885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: 19.2432	Cost: 20.03s
Train Epoch: 785 [20480/90000 (23%)]	Loss: 11.9194	Cost: 6.08s
Train Epoch: 785 [40960/90000 (45%)]	Loss: 11.9317	Cost: 6.12s
Train Epoch: 785 [61440/90000 (68%)]	Loss: 11.8622	Cost: 5.85s
Train Epoch: 785 [81920/90000 (91%)]	Loss: 12.0452	Cost: 5.75s
Train Epoch: 785 	Average Loss: 12.4275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3529

Learning rate: 0.00019697443258207274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: 19.3037	Cost: 21.19s
Train Epoch: 786 [20480/90000 (23%)]	Loss: 11.9062	Cost: 5.98s
Train Epoch: 786 [40960/90000 (45%)]	Loss: 11.9501	Cost: 6.76s
Train Epoch: 786 [61440/90000 (68%)]	Loss: 11.8634	Cost: 5.85s
Train Epoch: 786 [81920/90000 (91%)]	Loss: 11.9291	Cost: 6.04s
Train Epoch: 786 	Average Loss: 12.4231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3787

Learning rate: 0.00019696675845268385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: 19.4251	Cost: 20.78s
Train Epoch: 787 [20480/90000 (23%)]	Loss: 11.8754	Cost: 6.21s
Train Epoch: 787 [40960/90000 (45%)]	Loss: 11.9614	Cost: 6.16s
Train Epoch: 787 [61440/90000 (68%)]	Loss: 11.6674	Cost: 5.95s
Train Epoch: 787 [81920/90000 (91%)]	Loss: 11.8422	Cost: 5.83s
Train Epoch: 787 	Average Loss: 12.3827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4590

Learning rate: 0.00019695907475305956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: 19.1875	Cost: 20.82s
Train Epoch: 788 [20480/90000 (23%)]	Loss: 11.8287	Cost: 6.09s
Train Epoch: 788 [40960/90000 (45%)]	Loss: 11.6949	Cost: 6.15s
Train Epoch: 788 [61440/90000 (68%)]	Loss: 11.7388	Cost: 5.93s
Train Epoch: 788 [81920/90000 (91%)]	Loss: 11.8061	Cost: 5.79s
Train Epoch: 788 	Average Loss: 12.3065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3753

Learning rate: 0.00019695138148395828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: 19.2173	Cost: 20.34s
Train Epoch: 789 [20480/90000 (23%)]	Loss: 11.7222	Cost: 6.12s
Train Epoch: 789 [40960/90000 (45%)]	Loss: 11.7895	Cost: 6.13s
Train Epoch: 789 [61440/90000 (68%)]	Loss: 11.8355	Cost: 5.92s
Train Epoch: 789 [81920/90000 (91%)]	Loss: 11.7389	Cost: 5.72s
Train Epoch: 789 	Average Loss: 12.2739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4336

Learning rate: 0.00019694367864613922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: 19.1425	Cost: 20.41s
Train Epoch: 790 [20480/90000 (23%)]	Loss: 11.7670	Cost: 6.14s
Train Epoch: 790 [40960/90000 (45%)]	Loss: 11.8209	Cost: 6.03s
Train Epoch: 790 [61440/90000 (68%)]	Loss: 11.6186	Cost: 5.95s
Train Epoch: 790 [81920/90000 (91%)]	Loss: 11.8766	Cost: 5.70s
Train Epoch: 790 	Average Loss: 12.2652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4178

Learning rate: 0.00019693596624036267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: 19.3444	Cost: 20.30s
Train Epoch: 791 [20480/90000 (23%)]	Loss: 11.6736	Cost: 6.21s
Train Epoch: 791 [40960/90000 (45%)]	Loss: 11.7139	Cost: 6.14s
Train Epoch: 791 [61440/90000 (68%)]	Loss: 11.7986	Cost: 5.82s
Train Epoch: 791 [81920/90000 (91%)]	Loss: 11.9607	Cost: 5.69s
Train Epoch: 791 	Average Loss: 12.2475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4996

Learning rate: 0.00019692824426738987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: 19.3749	Cost: 19.97s
Train Epoch: 792 [20480/90000 (23%)]	Loss: 11.9083	Cost: 5.99s
Train Epoch: 792 [40960/90000 (45%)]	Loss: 11.8581	Cost: 6.48s
Train Epoch: 792 [61440/90000 (68%)]	Loss: 12.0609	Cost: 5.88s
Train Epoch: 792 [81920/90000 (91%)]	Loss: 11.9966	Cost: 5.84s
Train Epoch: 792 	Average Loss: 12.4501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4080

Learning rate: 0.0001969205127279828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: 19.3583	Cost: 23.05s
Train Epoch: 793 [20480/90000 (23%)]	Loss: 11.9208	Cost: 5.84s
Train Epoch: 793 [40960/90000 (45%)]	Loss: 11.8203	Cost: 6.36s
Train Epoch: 793 [61440/90000 (68%)]	Loss: 11.8247	Cost: 6.10s
Train Epoch: 793 [81920/90000 (91%)]	Loss: 11.8341	Cost: 5.95s
Train Epoch: 793 	Average Loss: 12.3748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4520

Learning rate: 0.00019691277162290467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: 19.2686	Cost: 21.14s
Train Epoch: 794 [20480/90000 (23%)]	Loss: 11.4822	Cost: 6.10s
Train Epoch: 794 [40960/90000 (45%)]	Loss: 11.7803	Cost: 6.52s
Train Epoch: 794 [61440/90000 (68%)]	Loss: 11.8291	Cost: 5.92s
Train Epoch: 794 [81920/90000 (91%)]	Loss: 11.8606	Cost: 6.45s
Train Epoch: 794 	Average Loss: 12.2861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4266

Learning rate: 0.00019690502095291943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 795 [0/90000 (0%)]	Loss: 19.1322	Cost: 21.48s
Train Epoch: 795 [20480/90000 (23%)]	Loss: 11.7363	Cost: 6.02s
Train Epoch: 795 [40960/90000 (45%)]	Loss: 11.6744	Cost: 6.17s
Train Epoch: 795 [61440/90000 (68%)]	Loss: 11.6045	Cost: 5.89s
Train Epoch: 795 [81920/90000 (91%)]	Loss: 11.8081	Cost: 5.88s
Train Epoch: 795 	Average Loss: 12.2009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4031

Learning rate: 0.00019689726071879206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 796 [0/90000 (0%)]	Loss: 19.3587	Cost: 20.96s
Train Epoch: 796 [20480/90000 (23%)]	Loss: 11.6517	Cost: 6.01s
Train Epoch: 796 [40960/90000 (45%)]	Loss: 11.7544	Cost: 5.98s
Train Epoch: 796 [61440/90000 (68%)]	Loss: 11.5919	Cost: 5.79s
Train Epoch: 796 [81920/90000 (91%)]	Loss: 11.7547	Cost: 5.83s
Train Epoch: 796 	Average Loss: 12.1620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4618

Learning rate: 0.00019688949092128843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 797 [0/90000 (0%)]	Loss: 19.3171	Cost: 23.24s
Train Epoch: 797 [20480/90000 (23%)]	Loss: 11.4405	Cost: 6.10s
Train Epoch: 797 [40960/90000 (45%)]	Loss: 11.8620	Cost: 6.05s
Train Epoch: 797 [61440/90000 (68%)]	Loss: 11.5732	Cost: 5.93s
Train Epoch: 797 [81920/90000 (91%)]	Loss: 11.7532	Cost: 5.85s
Train Epoch: 797 	Average Loss: 12.1438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5777

Learning rate: 0.00019688171156117545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 798 [0/90000 (0%)]	Loss: 19.5108	Cost: 22.00s
Train Epoch: 798 [20480/90000 (23%)]	Loss: 11.5746	Cost: 6.05s
Train Epoch: 798 [40960/90000 (45%)]	Loss: 11.5742	Cost: 6.60s
Train Epoch: 798 [61440/90000 (68%)]	Loss: 11.5091	Cost: 5.91s
Train Epoch: 798 [81920/90000 (91%)]	Loss: 11.7087	Cost: 5.86s
Train Epoch: 798 	Average Loss: 12.1442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5396

Learning rate: 0.00019687392263922088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 799 [0/90000 (0%)]	Loss: 19.4366	Cost: 25.43s
Train Epoch: 799 [20480/90000 (23%)]	Loss: 11.5483	Cost: 6.06s
Train Epoch: 799 [40960/90000 (45%)]	Loss: 11.7706	Cost: 6.13s
Train Epoch: 799 [61440/90000 (68%)]	Loss: 11.5139	Cost: 5.91s
Train Epoch: 799 [81920/90000 (91%)]	Loss: 11.6802	Cost: 5.71s
Train Epoch: 799 	Average Loss: 12.1789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5062

Learning rate: 0.00019686612415619346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 800 [0/90000 (0%)]	Loss: 19.3649	Cost: 22.40s
Train Epoch: 800 [20480/90000 (23%)]	Loss: 11.7183	Cost: 6.19s
Train Epoch: 800 [40960/90000 (45%)]	Loss: 11.8138	Cost: 6.15s
Train Epoch: 800 [61440/90000 (68%)]	Loss: 11.4888	Cost: 5.93s
Train Epoch: 800 [81920/90000 (91%)]	Loss: 11.8346	Cost: 5.76s
Train Epoch: 800 	Average Loss: 12.2171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5067

Learning rate: 0.00019685831611286286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 801 [0/90000 (0%)]	Loss: 19.3463	Cost: 20.42s
Train Epoch: 801 [20480/90000 (23%)]	Loss: 11.7236	Cost: 6.30s
Train Epoch: 801 [40960/90000 (45%)]	Loss: 11.7597	Cost: 6.62s
Train Epoch: 801 [61440/90000 (68%)]	Loss: 11.4873	Cost: 6.14s
Train Epoch: 801 [81920/90000 (91%)]	Loss: 11.9625	Cost: 6.12s
Train Epoch: 801 	Average Loss: 12.2160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5080

Learning rate: 0.0001968504985099997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 802 [0/90000 (0%)]	Loss: 19.3484	Cost: 20.45s
Train Epoch: 802 [20480/90000 (23%)]	Loss: 11.9271	Cost: 6.57s
Train Epoch: 802 [40960/90000 (45%)]	Loss: 11.8160	Cost: 6.07s
Train Epoch: 802 [61440/90000 (68%)]	Loss: 11.5897	Cost: 5.96s
Train Epoch: 802 [81920/90000 (91%)]	Loss: 11.8880	Cost: 5.81s
Train Epoch: 802 	Average Loss: 12.2739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4874

Learning rate: 0.00019684267134837557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 803 [0/90000 (0%)]	Loss: 19.6066	Cost: 21.75s
Train Epoch: 803 [20480/90000 (23%)]	Loss: 11.6129	Cost: 6.23s
Train Epoch: 803 [40960/90000 (45%)]	Loss: 11.6508	Cost: 6.60s
Train Epoch: 803 [61440/90000 (68%)]	Loss: 11.5712	Cost: 5.91s
Train Epoch: 803 [81920/90000 (91%)]	Loss: 11.6272	Cost: 6.11s
Train Epoch: 803 	Average Loss: 12.1561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5331

Learning rate: 0.00019683483462876295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 804 [0/90000 (0%)]	Loss: 19.4423	Cost: 20.44s
Train Epoch: 804 [20480/90000 (23%)]	Loss: 11.5584	Cost: 6.23s
Train Epoch: 804 [40960/90000 (45%)]	Loss: 11.7121	Cost: 6.16s
Train Epoch: 804 [61440/90000 (68%)]	Loss: 11.5328	Cost: 5.96s
Train Epoch: 804 [81920/90000 (91%)]	Loss: 11.7116	Cost: 5.82s
Train Epoch: 804 	Average Loss: 12.0881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5845

Learning rate: 0.0001968269883519353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 805 [0/90000 (0%)]	Loss: 19.4591	Cost: 20.74s
Train Epoch: 805 [20480/90000 (23%)]	Loss: 11.5923	Cost: 6.14s
Train Epoch: 805 [40960/90000 (45%)]	Loss: 11.5427	Cost: 6.61s
Train Epoch: 805 [61440/90000 (68%)]	Loss: 11.5105	Cost: 5.93s
Train Epoch: 805 [81920/90000 (91%)]	Loss: 11.7140	Cost: 6.17s
Train Epoch: 805 	Average Loss: 12.1166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5541

Learning rate: 0.00019681913251866706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 806 [0/90000 (0%)]	Loss: 19.4708	Cost: 20.41s
Train Epoch: 806 [20480/90000 (23%)]	Loss: 11.5481	Cost: 6.04s
Train Epoch: 806 [40960/90000 (45%)]	Loss: 11.5098	Cost: 6.23s
Train Epoch: 806 [61440/90000 (68%)]	Loss: 11.3182	Cost: 5.88s
Train Epoch: 806 [81920/90000 (91%)]	Loss: 11.5410	Cost: 5.79s
Train Epoch: 806 	Average Loss: 12.0777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5942

Learning rate: 0.00019681126712973353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 807 [0/90000 (0%)]	Loss: 19.4140	Cost: 21.60s
Train Epoch: 807 [20480/90000 (23%)]	Loss: 11.4437	Cost: 6.09s
Train Epoch: 807 [40960/90000 (45%)]	Loss: 11.5927	Cost: 6.18s
Train Epoch: 807 [61440/90000 (68%)]	Loss: 11.3518	Cost: 6.03s
Train Epoch: 807 [81920/90000 (91%)]	Loss: 11.4754	Cost: 6.66s
Train Epoch: 807 	Average Loss: 11.9859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6448

Learning rate: 0.00019680339218591098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 808 [0/90000 (0%)]	Loss: 19.3775	Cost: 21.24s
Train Epoch: 808 [20480/90000 (23%)]	Loss: 11.3151	Cost: 6.11s
Train Epoch: 808 [40960/90000 (45%)]	Loss: 11.6369	Cost: 6.61s
Train Epoch: 808 [61440/90000 (68%)]	Loss: 11.3627	Cost: 5.93s
Train Epoch: 808 [81920/90000 (91%)]	Loss: 11.6125	Cost: 6.17s
Train Epoch: 808 	Average Loss: 12.0178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5553

Learning rate: 0.00019679550768797666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 809 [0/90000 (0%)]	Loss: 19.5006	Cost: 20.69s
Train Epoch: 809 [20480/90000 (23%)]	Loss: 11.4383	Cost: 6.01s
Train Epoch: 809 [40960/90000 (45%)]	Loss: 11.5152	Cost: 6.18s
Train Epoch: 809 [61440/90000 (68%)]	Loss: 11.3359	Cost: 5.89s
Train Epoch: 809 [81920/90000 (91%)]	Loss: 11.7439	Cost: 5.98s
Train Epoch: 809 	Average Loss: 11.9931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6089

Learning rate: 0.00019678761363670875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 810 [0/90000 (0%)]	Loss: 19.5339	Cost: 20.55s
Train Epoch: 810 [20480/90000 (23%)]	Loss: 11.4976	Cost: 6.07s
Train Epoch: 810 [40960/90000 (45%)]	Loss: 11.4450	Cost: 6.31s
Train Epoch: 810 [61440/90000 (68%)]	Loss: 11.3139	Cost: 5.90s
Train Epoch: 810 [81920/90000 (91%)]	Loss: 11.5343	Cost: 6.15s
Train Epoch: 810 	Average Loss: 12.0226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7281

Learning rate: 0.0001967797100328863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 811 [0/90000 (0%)]	Loss: 19.4070	Cost: 21.86s
Train Epoch: 811 [20480/90000 (23%)]	Loss: 11.5409	Cost: 5.95s
Train Epoch: 811 [40960/90000 (45%)]	Loss: 11.4528	Cost: 6.07s
Train Epoch: 811 [61440/90000 (68%)]	Loss: 11.3916	Cost: 5.88s
Train Epoch: 811 [81920/90000 (91%)]	Loss: 11.6101	Cost: 5.82s
Train Epoch: 811 	Average Loss: 11.9785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7139

Learning rate: 0.00019677179687728943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 812 [0/90000 (0%)]	Loss: 19.5057	Cost: 20.78s
Train Epoch: 812 [20480/90000 (23%)]	Loss: 11.2764	Cost: 6.12s
Train Epoch: 812 [40960/90000 (45%)]	Loss: 11.4597	Cost: 6.15s
Train Epoch: 812 [61440/90000 (68%)]	Loss: 11.3820	Cost: 6.08s
Train Epoch: 812 [81920/90000 (91%)]	Loss: 11.4961	Cost: 5.72s
Train Epoch: 812 	Average Loss: 11.9323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6359

Learning rate: 0.00019676387417069913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 813 [0/90000 (0%)]	Loss: 19.3453	Cost: 20.66s
Train Epoch: 813 [20480/90000 (23%)]	Loss: 11.4246	Cost: 5.98s
Train Epoch: 813 [40960/90000 (45%)]	Loss: 11.6395	Cost: 6.29s
Train Epoch: 813 [61440/90000 (68%)]	Loss: 11.2951	Cost: 5.90s
Train Epoch: 813 [81920/90000 (91%)]	Loss: 11.6894	Cost: 5.76s
Train Epoch: 813 	Average Loss: 12.0737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6774

Learning rate: 0.0001967559419138973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 814 [0/90000 (0%)]	Loss: 19.6258	Cost: 20.26s
Train Epoch: 814 [20480/90000 (23%)]	Loss: 11.3146	Cost: 6.19s
Train Epoch: 814 [40960/90000 (45%)]	Loss: 11.4863	Cost: 6.13s
Train Epoch: 814 [61440/90000 (68%)]	Loss: 11.2440	Cost: 5.86s
Train Epoch: 814 [81920/90000 (91%)]	Loss: 11.4761	Cost: 5.74s
Train Epoch: 814 	Average Loss: 11.9696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6655

Learning rate: 0.00019674800010766687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 815 [0/90000 (0%)]	Loss: 19.3855	Cost: 20.36s
Train Epoch: 815 [20480/90000 (23%)]	Loss: 11.3356	Cost: 6.10s
Train Epoch: 815 [40960/90000 (45%)]	Loss: 11.5369	Cost: 6.87s
Train Epoch: 815 [61440/90000 (68%)]	Loss: 11.1340	Cost: 5.90s
Train Epoch: 815 [81920/90000 (91%)]	Loss: 11.5141	Cost: 6.10s
Train Epoch: 815 	Average Loss: 11.9146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6952

Learning rate: 0.00019674004875279162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 816 [0/90000 (0%)]	Loss: 19.7173	Cost: 22.59s
Train Epoch: 816 [20480/90000 (23%)]	Loss: 11.4403	Cost: 6.00s
Train Epoch: 816 [40960/90000 (45%)]	Loss: 11.4997	Cost: 7.02s
Train Epoch: 816 [61440/90000 (68%)]	Loss: 11.1595	Cost: 5.89s
Train Epoch: 816 [81920/90000 (91%)]	Loss: 11.5371	Cost: 5.81s
Train Epoch: 816 	Average Loss: 11.9915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6891

Learning rate: 0.00019673208785005636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 817 [0/90000 (0%)]	Loss: 19.5894	Cost: 20.48s
Train Epoch: 817 [20480/90000 (23%)]	Loss: 11.5008	Cost: 6.13s
Train Epoch: 817 [40960/90000 (45%)]	Loss: 11.4654	Cost: 6.11s
Train Epoch: 817 [61440/90000 (68%)]	Loss: 11.2901	Cost: 5.93s
Train Epoch: 817 [81920/90000 (91%)]	Loss: 11.4973	Cost: 5.77s
Train Epoch: 817 	Average Loss: 11.9734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7008

Learning rate: 0.00019672411740024673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 818 [0/90000 (0%)]	Loss: 19.5701	Cost: 21.53s
Train Epoch: 818 [20480/90000 (23%)]	Loss: 11.4248	Cost: 6.20s
Train Epoch: 818 [40960/90000 (45%)]	Loss: 11.4418	Cost: 6.07s
Train Epoch: 818 [61440/90000 (68%)]	Loss: 11.3383	Cost: 5.89s
Train Epoch: 818 [81920/90000 (91%)]	Loss: 11.4355	Cost: 5.78s
Train Epoch: 818 	Average Loss: 11.9643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6219

Learning rate: 0.0001967161374041495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 819 [0/90000 (0%)]	Loss: 19.7554	Cost: 20.84s
Train Epoch: 819 [20480/90000 (23%)]	Loss: 11.3311	Cost: 6.24s
Train Epoch: 819 [40960/90000 (45%)]	Loss: 11.4107	Cost: 6.17s
Train Epoch: 819 [61440/90000 (68%)]	Loss: 11.0357	Cost: 5.99s
Train Epoch: 819 [81920/90000 (91%)]	Loss: 11.4706	Cost: 5.74s
Train Epoch: 819 	Average Loss: 11.8930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7479

Learning rate: 0.00019670814786255217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 820 [0/90000 (0%)]	Loss: 19.5651	Cost: 21.40s
Train Epoch: 820 [20480/90000 (23%)]	Loss: 11.3358	Cost: 6.02s
Train Epoch: 820 [40960/90000 (45%)]	Loss: 11.3606	Cost: 6.26s
Train Epoch: 820 [61440/90000 (68%)]	Loss: 11.3163	Cost: 5.87s
Train Epoch: 820 [81920/90000 (91%)]	Loss: 11.3651	Cost: 5.74s
Train Epoch: 820 	Average Loss: 11.8499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7820

Learning rate: 0.0001967001487762433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 821 [0/90000 (0%)]	Loss: 19.5979	Cost: 21.04s
Train Epoch: 821 [20480/90000 (23%)]	Loss: 11.3963	Cost: 6.14s
Train Epoch: 821 [40960/90000 (45%)]	Loss: 11.2950	Cost: 6.75s
Train Epoch: 821 [61440/90000 (68%)]	Loss: 11.2144	Cost: 6.04s
Train Epoch: 821 [81920/90000 (91%)]	Loss: 11.3943	Cost: 5.72s
Train Epoch: 821 	Average Loss: 11.8380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7732

Learning rate: 0.00019669214014601236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 822 [0/90000 (0%)]	Loss: 19.4942	Cost: 20.78s
Train Epoch: 822 [20480/90000 (23%)]	Loss: 11.1309	Cost: 6.13s
Train Epoch: 822 [40960/90000 (45%)]	Loss: 11.2490	Cost: 6.14s
Train Epoch: 822 [61440/90000 (68%)]	Loss: 11.1356	Cost: 5.92s
Train Epoch: 822 [81920/90000 (91%)]	Loss: 11.4338	Cost: 5.80s
Train Epoch: 822 	Average Loss: 11.8228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6910

Learning rate: 0.00019668412197264976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 823 [0/90000 (0%)]	Loss: 19.6598	Cost: 21.76s
Train Epoch: 823 [20480/90000 (23%)]	Loss: 11.4685	Cost: 6.10s
Train Epoch: 823 [40960/90000 (45%)]	Loss: 11.4690	Cost: 6.54s
Train Epoch: 823 [61440/90000 (68%)]	Loss: 11.2509	Cost: 5.91s
Train Epoch: 823 [81920/90000 (91%)]	Loss: 11.3101	Cost: 6.03s
Train Epoch: 823 	Average Loss: 11.8746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7138

Learning rate: 0.0001966760942569469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 824 [0/90000 (0%)]	Loss: 19.5117	Cost: 21.45s
Train Epoch: 824 [20480/90000 (23%)]	Loss: 11.2199	Cost: 6.05s
Train Epoch: 824 [40960/90000 (45%)]	Loss: 11.4970	Cost: 5.96s
Train Epoch: 824 [61440/90000 (68%)]	Loss: 11.2641	Cost: 6.10s
Train Epoch: 824 [81920/90000 (91%)]	Loss: 11.5138	Cost: 6.10s
Train Epoch: 824 	Average Loss: 11.9149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7589

Learning rate: 0.00019666805699969608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 825 [0/90000 (0%)]	Loss: 19.7091	Cost: 23.02s
Train Epoch: 825 [20480/90000 (23%)]	Loss: 11.3311	Cost: 6.15s
Train Epoch: 825 [40960/90000 (45%)]	Loss: 11.2747	Cost: 6.14s
Train Epoch: 825 [61440/90000 (68%)]	Loss: 10.9254	Cost: 5.94s
Train Epoch: 825 [81920/90000 (91%)]	Loss: 11.3008	Cost: 5.72s
Train Epoch: 825 	Average Loss: 11.8117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8221

Learning rate: 0.00019666001020169052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 826 [0/90000 (0%)]	Loss: 19.7498	Cost: 25.04s
Train Epoch: 826 [20480/90000 (23%)]	Loss: 11.1704	Cost: 6.06s
Train Epoch: 826 [40960/90000 (45%)]	Loss: 11.3700	Cost: 6.78s
Train Epoch: 826 [61440/90000 (68%)]	Loss: 11.1299	Cost: 5.96s
Train Epoch: 826 [81920/90000 (91%)]	Loss: 11.2392	Cost: 6.44s
Train Epoch: 826 	Average Loss: 11.7642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7796

Learning rate: 0.00019665195386372441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 827 [0/90000 (0%)]	Loss: 19.7461	Cost: 24.13s
Train Epoch: 827 [20480/90000 (23%)]	Loss: 11.2480	Cost: 6.14s
Train Epoch: 827 [40960/90000 (45%)]	Loss: 11.5827	Cost: 6.08s
Train Epoch: 827 [61440/90000 (68%)]	Loss: 11.1276	Cost: 5.89s
Train Epoch: 827 [81920/90000 (91%)]	Loss: 11.4838	Cost: 5.83s
Train Epoch: 827 	Average Loss: 11.9059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7513

Learning rate: 0.00019664388798659287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 828 [0/90000 (0%)]	Loss: 19.6740	Cost: 24.00s
Train Epoch: 828 [20480/90000 (23%)]	Loss: 11.2442	Cost: 6.09s
Train Epoch: 828 [40960/90000 (45%)]	Loss: 11.3420	Cost: 6.10s
Train Epoch: 828 [61440/90000 (68%)]	Loss: 10.9658	Cost: 5.94s
Train Epoch: 828 [81920/90000 (91%)]	Loss: 11.4494	Cost: 5.78s
Train Epoch: 828 	Average Loss: 11.7936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7916

Learning rate: 0.00019663581257109203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 829 [0/90000 (0%)]	Loss: 19.7015	Cost: 26.02s
Train Epoch: 829 [20480/90000 (23%)]	Loss: 11.2202	Cost: 6.05s
Train Epoch: 829 [40960/90000 (45%)]	Loss: 11.3770	Cost: 6.25s
Train Epoch: 829 [61440/90000 (68%)]	Loss: 11.0684	Cost: 5.84s
Train Epoch: 829 [81920/90000 (91%)]	Loss: 11.4907	Cost: 5.84s
Train Epoch: 829 	Average Loss: 11.8636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8181

Learning rate: 0.00019662772761801884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 830 [0/90000 (0%)]	Loss: 19.7252	Cost: 22.75s
Train Epoch: 830 [20480/90000 (23%)]	Loss: 11.1474	Cost: 6.05s
Train Epoch: 830 [40960/90000 (45%)]	Loss: 11.3311	Cost: 6.30s
Train Epoch: 830 [61440/90000 (68%)]	Loss: 11.0805	Cost: 5.99s
Train Epoch: 830 [81920/90000 (91%)]	Loss: 11.4299	Cost: 5.74s
Train Epoch: 830 	Average Loss: 11.8183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7438

Learning rate: 0.00019661963312817126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 831 [0/90000 (0%)]	Loss: 19.7835	Cost: 22.84s
Train Epoch: 831 [20480/90000 (23%)]	Loss: 11.1779	Cost: 6.60s
Train Epoch: 831 [40960/90000 (45%)]	Loss: 11.2319	Cost: 6.15s
Train Epoch: 831 [61440/90000 (68%)]	Loss: 11.0075	Cost: 5.91s
Train Epoch: 831 [81920/90000 (91%)]	Loss: 11.3574	Cost: 5.84s
Train Epoch: 831 	Average Loss: 11.7951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8269

Learning rate: 0.00019661152910234822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 832 [0/90000 (0%)]	Loss: 19.6414	Cost: 22.24s
Train Epoch: 832 [20480/90000 (23%)]	Loss: 11.1611	Cost: 6.22s
Train Epoch: 832 [40960/90000 (45%)]	Loss: 11.2103	Cost: 6.24s
Train Epoch: 832 [61440/90000 (68%)]	Loss: 10.9307	Cost: 5.95s
Train Epoch: 832 [81920/90000 (91%)]	Loss: 11.1805	Cost: 5.87s
Train Epoch: 832 	Average Loss: 11.7434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8161

Learning rate: 0.0001966034155413495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 833 [0/90000 (0%)]	Loss: 19.7195	Cost: 21.39s
Train Epoch: 833 [20480/90000 (23%)]	Loss: 11.0626	Cost: 6.46s
Train Epoch: 833 [40960/90000 (45%)]	Loss: 11.2934	Cost: 6.47s
Train Epoch: 833 [61440/90000 (68%)]	Loss: 10.9167	Cost: 5.90s
Train Epoch: 833 [81920/90000 (91%)]	Loss: 11.0716	Cost: 5.87s
Train Epoch: 833 	Average Loss: 11.6971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8556

Learning rate: 0.00019659529244597592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 834 [0/90000 (0%)]	Loss: 19.7094	Cost: 20.41s
Train Epoch: 834 [20480/90000 (23%)]	Loss: 11.1988	Cost: 6.15s
Train Epoch: 834 [40960/90000 (45%)]	Loss: 11.4697	Cost: 6.55s
Train Epoch: 834 [61440/90000 (68%)]	Loss: 11.0762	Cost: 5.90s
Train Epoch: 834 [81920/90000 (91%)]	Loss: 11.2746	Cost: 5.74s
Train Epoch: 834 	Average Loss: 11.8102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8385

Learning rate: 0.00019658715981702915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 835 [0/90000 (0%)]	Loss: 19.7359	Cost: 20.22s
Train Epoch: 835 [20480/90000 (23%)]	Loss: 11.1285	Cost: 6.17s
Train Epoch: 835 [40960/90000 (45%)]	Loss: 11.3933	Cost: 6.43s
Train Epoch: 835 [61440/90000 (68%)]	Loss: 10.8492	Cost: 5.95s
Train Epoch: 835 [81920/90000 (91%)]	Loss: 11.0917	Cost: 5.87s
Train Epoch: 835 	Average Loss: 11.7735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8681

Learning rate: 0.00019657901765531195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 836 [0/90000 (0%)]	Loss: 19.7198	Cost: 20.00s
Train Epoch: 836 [20480/90000 (23%)]	Loss: 11.1631	Cost: 6.14s
Train Epoch: 836 [40960/90000 (45%)]	Loss: 11.4569	Cost: 6.18s
Train Epoch: 836 [61440/90000 (68%)]	Loss: 11.0901	Cost: 6.00s
Train Epoch: 836 [81920/90000 (91%)]	Loss: 11.1527	Cost: 6.16s
Train Epoch: 836 	Average Loss: 11.7719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8649

Learning rate: 0.0001965708659616278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 837 [0/90000 (0%)]	Loss: 19.7114	Cost: 21.20s
Train Epoch: 837 [20480/90000 (23%)]	Loss: 11.1239	Cost: 6.03s
Train Epoch: 837 [40960/90000 (45%)]	Loss: 11.1339	Cost: 6.21s
Train Epoch: 837 [61440/90000 (68%)]	Loss: 10.9724	Cost: 5.95s
Train Epoch: 837 [81920/90000 (91%)]	Loss: 11.1975	Cost: 6.24s
Train Epoch: 837 	Average Loss: 11.7377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8934

Learning rate: 0.00019656270473678128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 838 [0/90000 (0%)]	Loss: 19.6401	Cost: 20.84s
Train Epoch: 838 [20480/90000 (23%)]	Loss: 11.2200	Cost: 6.13s
Train Epoch: 838 [40960/90000 (45%)]	Loss: 11.1882	Cost: 6.54s
Train Epoch: 838 [61440/90000 (68%)]	Loss: 11.0896	Cost: 5.89s
Train Epoch: 838 [81920/90000 (91%)]	Loss: 11.1923	Cost: 6.33s
Train Epoch: 838 	Average Loss: 11.7665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8562

Learning rate: 0.0001965545339815779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 839 [0/90000 (0%)]	Loss: 19.6279	Cost: 21.08s
Train Epoch: 839 [20480/90000 (23%)]	Loss: 10.9257	Cost: 5.94s
Train Epoch: 839 [40960/90000 (45%)]	Loss: 11.0907	Cost: 6.24s
Train Epoch: 839 [61440/90000 (68%)]	Loss: 10.9579	Cost: 6.05s
Train Epoch: 839 [81920/90000 (91%)]	Loss: 11.0486	Cost: 5.81s
Train Epoch: 839 	Average Loss: 11.6563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9061

Learning rate: 0.00019654635369682408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 840 [0/90000 (0%)]	Loss: 19.8002	Cost: 20.85s
Train Epoch: 840 [20480/90000 (23%)]	Loss: 11.0487	Cost: 6.04s
Train Epoch: 840 [40960/90000 (45%)]	Loss: 10.9863	Cost: 6.59s
Train Epoch: 840 [61440/90000 (68%)]	Loss: 10.8587	Cost: 5.97s
Train Epoch: 840 [81920/90000 (91%)]	Loss: 11.1334	Cost: 5.87s
Train Epoch: 840 	Average Loss: 11.6853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8993

Learning rate: 0.00019653816388332714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 841 [0/90000 (0%)]	Loss: 19.8373	Cost: 20.18s
Train Epoch: 841 [20480/90000 (23%)]	Loss: 11.0848	Cost: 6.16s
Train Epoch: 841 [40960/90000 (45%)]	Loss: 11.1535	Cost: 6.37s
Train Epoch: 841 [61440/90000 (68%)]	Loss: 10.9185	Cost: 5.90s
Train Epoch: 841 [81920/90000 (91%)]	Loss: 11.1272	Cost: 6.18s
Train Epoch: 841 	Average Loss: 11.6470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8890

Learning rate: 0.00019652996454189544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 842 [0/90000 (0%)]	Loss: 19.7587	Cost: 19.68s
Train Epoch: 842 [20480/90000 (23%)]	Loss: 11.0441	Cost: 6.04s
Train Epoch: 842 [40960/90000 (45%)]	Loss: 11.1508	Cost: 6.27s
Train Epoch: 842 [61440/90000 (68%)]	Loss: 11.0083	Cost: 6.01s
Train Epoch: 842 [81920/90000 (91%)]	Loss: 11.2322	Cost: 5.71s
Train Epoch: 842 	Average Loss: 11.6447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9328

Learning rate: 0.00019652175567333815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 843 [0/90000 (0%)]	Loss: 19.6341	Cost: 20.36s
Train Epoch: 843 [20480/90000 (23%)]	Loss: 11.0122	Cost: 6.05s
Train Epoch: 843 [40960/90000 (45%)]	Loss: 11.1843	Cost: 6.14s
Train Epoch: 843 [61440/90000 (68%)]	Loss: 11.0813	Cost: 5.87s
Train Epoch: 843 [81920/90000 (91%)]	Loss: 11.0287	Cost: 5.77s
Train Epoch: 843 	Average Loss: 11.6749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9297

Learning rate: 0.00019651353727846553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 844 [0/90000 (0%)]	Loss: 19.5686	Cost: 20.47s
Train Epoch: 844 [20480/90000 (23%)]	Loss: 11.0314	Cost: 6.15s
Train Epoch: 844 [40960/90000 (45%)]	Loss: 10.9571	Cost: 6.43s
Train Epoch: 844 [61440/90000 (68%)]	Loss: 10.7543	Cost: 5.88s
Train Epoch: 844 [81920/90000 (91%)]	Loss: 11.2085	Cost: 5.70s
Train Epoch: 844 	Average Loss: 11.5885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0751

Learning rate: 0.00019650530935808866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 845 [0/90000 (0%)]	Loss: 19.5847	Cost: 20.23s
Train Epoch: 845 [20480/90000 (23%)]	Loss: 10.7432	Cost: 6.12s
Train Epoch: 845 [40960/90000 (45%)]	Loss: 11.1487	Cost: 6.11s
Train Epoch: 845 [61440/90000 (68%)]	Loss: 10.9258	Cost: 5.98s
Train Epoch: 845 [81920/90000 (91%)]	Loss: 10.9932	Cost: 5.73s
Train Epoch: 845 	Average Loss: 11.5682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9163

Learning rate: 0.00019649707191301958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 846 [0/90000 (0%)]	Loss: 19.9980	Cost: 21.52s
Train Epoch: 846 [20480/90000 (23%)]	Loss: 10.8003	Cost: 6.04s
Train Epoch: 846 [40960/90000 (45%)]	Loss: 10.9596	Cost: 6.17s
Train Epoch: 846 [61440/90000 (68%)]	Loss: 10.7790	Cost: 5.86s
Train Epoch: 846 [81920/90000 (91%)]	Loss: 11.0981	Cost: 5.78s
Train Epoch: 846 	Average Loss: 11.5774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0180

Learning rate: 0.00019648882494407134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 847 [0/90000 (0%)]	Loss: 19.8058	Cost: 22.62s
Train Epoch: 847 [20480/90000 (23%)]	Loss: 10.7206	Cost: 6.07s
Train Epoch: 847 [40960/90000 (45%)]	Loss: 11.0290	Cost: 6.19s
Train Epoch: 847 [61440/90000 (68%)]	Loss: 10.7983	Cost: 5.87s
Train Epoch: 847 [81920/90000 (91%)]	Loss: 11.0577	Cost: 5.71s
Train Epoch: 847 	Average Loss: 11.5478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9833

Learning rate: 0.0001964805684520579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 848 [0/90000 (0%)]	Loss: 19.7844	Cost: 22.93s
Train Epoch: 848 [20480/90000 (23%)]	Loss: 10.8343	Cost: 6.07s
Train Epoch: 848 [40960/90000 (45%)]	Loss: 11.0222	Cost: 6.23s
Train Epoch: 848 [61440/90000 (68%)]	Loss: 10.9855	Cost: 6.09s
Train Epoch: 848 [81920/90000 (91%)]	Loss: 11.0502	Cost: 5.78s
Train Epoch: 848 	Average Loss: 11.5869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0032

Learning rate: 0.00019647230243779407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 849 [0/90000 (0%)]	Loss: 19.6644	Cost: 24.29s
Train Epoch: 849 [20480/90000 (23%)]	Loss: 11.0676	Cost: 6.09s
Train Epoch: 849 [40960/90000 (45%)]	Loss: 11.1183	Cost: 6.07s
Train Epoch: 849 [61440/90000 (68%)]	Loss: 10.7715	Cost: 5.96s
Train Epoch: 849 [81920/90000 (91%)]	Loss: 11.1755	Cost: 5.86s
Train Epoch: 849 	Average Loss: 11.6081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0335

Learning rate: 0.00019646402690209574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 850 [0/90000 (0%)]	Loss: 19.6905	Cost: 24.28s
Train Epoch: 850 [20480/90000 (23%)]	Loss: 10.8912	Cost: 5.91s
Train Epoch: 850 [40960/90000 (45%)]	Loss: 11.0183	Cost: 6.33s
Train Epoch: 850 [61440/90000 (68%)]	Loss: 10.8509	Cost: 5.95s
Train Epoch: 850 [81920/90000 (91%)]	Loss: 10.9634	Cost: 5.93s
Train Epoch: 850 	Average Loss: 11.4978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1268

Learning rate: 0.0001964557418457796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 851 [0/90000 (0%)]	Loss: 20.1950	Cost: 21.21s
Train Epoch: 851 [20480/90000 (23%)]	Loss: 10.8641	Cost: 6.02s
Train Epoch: 851 [40960/90000 (45%)]	Loss: 10.9464	Cost: 6.35s
Train Epoch: 851 [61440/90000 (68%)]	Loss: 10.8907	Cost: 5.95s
Train Epoch: 851 [81920/90000 (91%)]	Loss: 10.9281	Cost: 6.47s
Train Epoch: 851 	Average Loss: 11.5314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9452

Learning rate: 0.0001964474472696634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 852 [0/90000 (0%)]	Loss: 19.9080	Cost: 23.13s
Train Epoch: 852 [20480/90000 (23%)]	Loss: 10.8678	Cost: 6.18s
Train Epoch: 852 [40960/90000 (45%)]	Loss: 11.0370	Cost: 6.02s
Train Epoch: 852 [61440/90000 (68%)]	Loss: 10.9533	Cost: 5.99s
Train Epoch: 852 [81920/90000 (91%)]	Loss: 11.0538	Cost: 5.82s
Train Epoch: 852 	Average Loss: 11.5311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0287

Learning rate: 0.00019643914317456578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 853 [0/90000 (0%)]	Loss: 19.8188	Cost: 23.87s
Train Epoch: 853 [20480/90000 (23%)]	Loss: 10.7459	Cost: 6.01s
Train Epoch: 853 [40960/90000 (45%)]	Loss: 10.9594	Cost: 6.22s
Train Epoch: 853 [61440/90000 (68%)]	Loss: 10.8493	Cost: 5.87s
Train Epoch: 853 [81920/90000 (91%)]	Loss: 10.9988	Cost: 5.77s
Train Epoch: 853 	Average Loss: 11.5046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0318

Learning rate: 0.00019643082956130633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 854 [0/90000 (0%)]	Loss: 19.9073	Cost: 23.91s
Train Epoch: 854 [20480/90000 (23%)]	Loss: 10.9238	Cost: 6.14s
Train Epoch: 854 [40960/90000 (45%)]	Loss: 10.9588	Cost: 6.15s
Train Epoch: 854 [61440/90000 (68%)]	Loss: 10.8440	Cost: 5.92s
Train Epoch: 854 [81920/90000 (91%)]	Loss: 11.3328	Cost: 5.80s
Train Epoch: 854 	Average Loss: 11.6097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0464

Learning rate: 0.00019642250643070558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 855 [0/90000 (0%)]	Loss: 19.6771	Cost: 26.26s
Train Epoch: 855 [20480/90000 (23%)]	Loss: 11.2342	Cost: 6.02s
Train Epoch: 855 [40960/90000 (45%)]	Loss: 11.1495	Cost: 6.76s
Train Epoch: 855 [61440/90000 (68%)]	Loss: 11.0761	Cost: 5.90s
Train Epoch: 855 [81920/90000 (91%)]	Loss: 11.3022	Cost: 5.97s
Train Epoch: 855 	Average Loss: 11.7431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0104

Learning rate: 0.00019641417378358494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 856 [0/90000 (0%)]	Loss: 19.7395	Cost: 23.83s
Train Epoch: 856 [20480/90000 (23%)]	Loss: 10.9365	Cost: 6.15s
Train Epoch: 856 [40960/90000 (45%)]	Loss: 11.1833	Cost: 6.53s
Train Epoch: 856 [61440/90000 (68%)]	Loss: 10.8459	Cost: 5.89s
Train Epoch: 856 [81920/90000 (91%)]	Loss: 11.0985	Cost: 5.76s
Train Epoch: 856 	Average Loss: 11.5754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0542

Learning rate: 0.00019640583162076685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 857 [0/90000 (0%)]	Loss: 20.0168	Cost: 22.92s
Train Epoch: 857 [20480/90000 (23%)]	Loss: 10.6450	Cost: 6.32s
Train Epoch: 857 [40960/90000 (45%)]	Loss: 10.8866	Cost: 6.48s
Train Epoch: 857 [61440/90000 (68%)]	Loss: 10.7255	Cost: 5.97s
Train Epoch: 857 [81920/90000 (91%)]	Loss: 10.9562	Cost: 5.96s
Train Epoch: 857 	Average Loss: 11.4731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0123

Learning rate: 0.00019639747994307463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 858 [0/90000 (0%)]	Loss: 19.9725	Cost: 22.86s
Train Epoch: 858 [20480/90000 (23%)]	Loss: 10.9385	Cost: 6.10s
Train Epoch: 858 [40960/90000 (45%)]	Loss: 11.1176	Cost: 6.13s
Train Epoch: 858 [61440/90000 (68%)]	Loss: 11.0155	Cost: 5.97s
Train Epoch: 858 [81920/90000 (91%)]	Loss: 10.9803	Cost: 5.86s
Train Epoch: 858 	Average Loss: 11.5581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0846

Learning rate: 0.0001963891187513326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 859 [0/90000 (0%)]	Loss: 19.7582	Cost: 21.48s
Train Epoch: 859 [20480/90000 (23%)]	Loss: 10.8343	Cost: 6.12s
Train Epoch: 859 [40960/90000 (45%)]	Loss: 11.0918	Cost: 6.35s
Train Epoch: 859 [61440/90000 (68%)]	Loss: 10.8946	Cost: 5.85s
Train Epoch: 859 [81920/90000 (91%)]	Loss: 10.8846	Cost: 5.77s
Train Epoch: 859 	Average Loss: 11.5053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0727

Learning rate: 0.0001963807480463659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 860 [0/90000 (0%)]	Loss: 19.7928	Cost: 21.78s
Train Epoch: 860 [20480/90000 (23%)]	Loss: 10.9097	Cost: 5.91s
Train Epoch: 860 [40960/90000 (45%)]	Loss: 11.0785	Cost: 6.29s
Train Epoch: 860 [61440/90000 (68%)]	Loss: 10.7856	Cost: 5.92s
Train Epoch: 860 [81920/90000 (91%)]	Loss: 11.0384	Cost: 6.02s
Train Epoch: 860 	Average Loss: 11.5801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0803

Learning rate: 0.00019637236782900076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 861 [0/90000 (0%)]	Loss: 19.9201	Cost: 21.02s
Train Epoch: 861 [20480/90000 (23%)]	Loss: 10.8469	Cost: 6.26s
Train Epoch: 861 [40960/90000 (45%)]	Loss: 10.9090	Cost: 6.44s
Train Epoch: 861 [61440/90000 (68%)]	Loss: 10.8193	Cost: 5.88s
Train Epoch: 861 [81920/90000 (91%)]	Loss: 10.8315	Cost: 5.56s
Train Epoch: 861 	Average Loss: 11.4781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0538

Learning rate: 0.0001963639781000642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 862 [0/90000 (0%)]	Loss: 19.8237	Cost: 20.57s
Train Epoch: 862 [20480/90000 (23%)]	Loss: 10.8136	Cost: 6.13s
Train Epoch: 862 [40960/90000 (45%)]	Loss: 10.9500	Cost: 6.57s
Train Epoch: 862 [61440/90000 (68%)]	Loss: 10.6609	Cost: 5.99s
Train Epoch: 862 [81920/90000 (91%)]	Loss: 10.9055	Cost: 5.73s
Train Epoch: 862 	Average Loss: 11.4487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0547

Learning rate: 0.00019635557886038432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 863 [0/90000 (0%)]	Loss: 19.8582	Cost: 20.65s
Train Epoch: 863 [20480/90000 (23%)]	Loss: 10.9549	Cost: 6.07s
Train Epoch: 863 [40960/90000 (45%)]	Loss: 11.2135	Cost: 6.09s
Train Epoch: 863 [61440/90000 (68%)]	Loss: 10.9408	Cost: 6.12s
Train Epoch: 863 [81920/90000 (91%)]	Loss: 10.9214	Cost: 6.17s
Train Epoch: 863 	Average Loss: 11.5594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1298

Learning rate: 0.00019634717011079007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 864 [0/90000 (0%)]	Loss: 19.8191	Cost: 21.35s
Train Epoch: 864 [20480/90000 (23%)]	Loss: 11.0373	Cost: 6.09s
Train Epoch: 864 [40960/90000 (45%)]	Loss: 11.0769	Cost: 6.69s
Train Epoch: 864 [61440/90000 (68%)]	Loss: 10.9004	Cost: 5.95s
Train Epoch: 864 [81920/90000 (91%)]	Loss: 10.9273	Cost: 6.74s
Train Epoch: 864 	Average Loss: 11.5349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0611

Learning rate: 0.00019633875185211136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 865 [0/90000 (0%)]	Loss: 19.8611	Cost: 20.28s
Train Epoch: 865 [20480/90000 (23%)]	Loss: 10.8741	Cost: 6.10s
Train Epoch: 865 [40960/90000 (45%)]	Loss: 11.0106	Cost: 6.03s
Train Epoch: 865 [61440/90000 (68%)]	Loss: 10.7438	Cost: 5.95s
Train Epoch: 865 [81920/90000 (91%)]	Loss: 11.0625	Cost: 5.88s
Train Epoch: 865 	Average Loss: 11.4720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0242

Learning rate: 0.00019633032408517903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 866 [0/90000 (0%)]	Loss: 19.7343	Cost: 20.34s
Train Epoch: 866 [20480/90000 (23%)]	Loss: 11.0611	Cost: 6.12s
Train Epoch: 866 [40960/90000 (45%)]	Loss: 10.8368	Cost: 6.19s
Train Epoch: 866 [61440/90000 (68%)]	Loss: 10.5759	Cost: 6.02s
Train Epoch: 866 [81920/90000 (91%)]	Loss: 10.7846	Cost: 5.75s
Train Epoch: 866 	Average Loss: 11.3988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1087

Learning rate: 0.00019632188681082487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 867 [0/90000 (0%)]	Loss: 19.9929	Cost: 20.30s
Train Epoch: 867 [20480/90000 (23%)]	Loss: 10.6510	Cost: 6.12s
Train Epoch: 867 [40960/90000 (45%)]	Loss: 10.8600	Cost: 6.06s
Train Epoch: 867 [61440/90000 (68%)]	Loss: 11.1460	Cost: 5.85s
Train Epoch: 867 [81920/90000 (91%)]	Loss: 11.1740	Cost: 5.77s
Train Epoch: 867 	Average Loss: 11.5967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1109

Learning rate: 0.00019631344002988158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 868 [0/90000 (0%)]	Loss: 20.1070	Cost: 21.20s
Train Epoch: 868 [20480/90000 (23%)]	Loss: 10.9749	Cost: 6.03s
Train Epoch: 868 [40960/90000 (45%)]	Loss: 11.0221	Cost: 6.49s
Train Epoch: 868 [61440/90000 (68%)]	Loss: 10.7958	Cost: 5.83s
Train Epoch: 868 [81920/90000 (91%)]	Loss: 11.0215	Cost: 6.10s
Train Epoch: 868 	Average Loss: 11.5895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1068

Learning rate: 0.00019630498374318287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 869 [0/90000 (0%)]	Loss: 19.8662	Cost: 21.07s
Train Epoch: 869 [20480/90000 (23%)]	Loss: 10.8539	Cost: 6.06s
Train Epoch: 869 [40960/90000 (45%)]	Loss: 10.9214	Cost: 6.76s
Train Epoch: 869 [61440/90000 (68%)]	Loss: 10.7047	Cost: 5.99s
Train Epoch: 869 [81920/90000 (91%)]	Loss: 10.7805	Cost: 5.96s
Train Epoch: 869 	Average Loss: 11.4433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0849

Learning rate: 0.00019629651795156333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 870 [0/90000 (0%)]	Loss: 19.7690	Cost: 21.03s
Train Epoch: 870 [20480/90000 (23%)]	Loss: 10.5846	Cost: 5.99s
Train Epoch: 870 [40960/90000 (45%)]	Loss: 10.7621	Cost: 6.73s
Train Epoch: 870 [61440/90000 (68%)]	Loss: 10.6187	Cost: 5.93s
Train Epoch: 870 [81920/90000 (91%)]	Loss: 10.7258	Cost: 5.78s
Train Epoch: 870 	Average Loss: 11.3275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1186

Learning rate: 0.00019628804265585853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 871 [0/90000 (0%)]	Loss: 19.8433	Cost: 21.68s
Train Epoch: 871 [20480/90000 (23%)]	Loss: 10.5848	Cost: 6.12s
Train Epoch: 871 [40960/90000 (45%)]	Loss: 10.7344	Cost: 6.07s
Train Epoch: 871 [61440/90000 (68%)]	Loss: 10.6944	Cost: 5.87s
Train Epoch: 871 [81920/90000 (91%)]	Loss: 10.7178	Cost: 5.82s
Train Epoch: 871 	Average Loss: 11.3345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0980

Learning rate: 0.00019627955785690487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 872 [0/90000 (0%)]	Loss: 19.9330	Cost: 21.06s
Train Epoch: 872 [20480/90000 (23%)]	Loss: 10.6135	Cost: 6.05s
Train Epoch: 872 [40960/90000 (45%)]	Loss: 10.7276	Cost: 6.26s
Train Epoch: 872 [61440/90000 (68%)]	Loss: 10.5278	Cost: 5.92s
Train Epoch: 872 [81920/90000 (91%)]	Loss: 10.6282	Cost: 5.75s
Train Epoch: 872 	Average Loss: 11.3032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0631

Learning rate: 0.00019627106355553982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 873 [0/90000 (0%)]	Loss: 19.8273	Cost: 21.95s
Train Epoch: 873 [20480/90000 (23%)]	Loss: 10.5869	Cost: 6.03s
Train Epoch: 873 [40960/90000 (45%)]	Loss: 10.6377	Cost: 6.21s
Train Epoch: 873 [61440/90000 (68%)]	Loss: 10.6358	Cost: 5.88s
Train Epoch: 873 [81920/90000 (91%)]	Loss: 10.7946	Cost: 5.80s
Train Epoch: 873 	Average Loss: 11.3224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1749

Learning rate: 0.00019626255975260172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 874 [0/90000 (0%)]	Loss: 19.9543	Cost: 20.27s
Train Epoch: 874 [20480/90000 (23%)]	Loss: 10.5849	Cost: 6.01s
Train Epoch: 874 [40960/90000 (45%)]	Loss: 10.8206	Cost: 6.21s
Train Epoch: 874 [61440/90000 (68%)]	Loss: 10.5885	Cost: 5.90s
Train Epoch: 874 [81920/90000 (91%)]	Loss: 10.8695	Cost: 5.69s
Train Epoch: 874 	Average Loss: 11.3169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0999

Learning rate: 0.00019625404644892983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 875 [0/90000 (0%)]	Loss: 19.8834	Cost: 20.81s
Train Epoch: 875 [20480/90000 (23%)]	Loss: 10.6886	Cost: 6.08s
Train Epoch: 875 [40960/90000 (45%)]	Loss: 10.5698	Cost: 6.36s
Train Epoch: 875 [61440/90000 (68%)]	Loss: 10.5350	Cost: 6.01s
Train Epoch: 875 [81920/90000 (91%)]	Loss: 10.6398	Cost: 5.77s
Train Epoch: 875 	Average Loss: 11.2387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1746

Learning rate: 0.00019624552364536446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 876 [0/90000 (0%)]	Loss: 19.9063	Cost: 23.10s
Train Epoch: 876 [20480/90000 (23%)]	Loss: 10.8350	Cost: 6.13s
Train Epoch: 876 [40960/90000 (45%)]	Loss: 11.0361	Cost: 6.56s
Train Epoch: 876 [61440/90000 (68%)]	Loss: 10.6219	Cost: 5.98s
Train Epoch: 876 [81920/90000 (91%)]	Loss: 10.7582	Cost: 6.19s
Train Epoch: 876 	Average Loss: 11.4422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1540

Learning rate: 0.00019623699134274674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 877 [0/90000 (0%)]	Loss: 20.0171	Cost: 22.40s
Train Epoch: 877 [20480/90000 (23%)]	Loss: 10.8439	Cost: 6.06s
Train Epoch: 877 [40960/90000 (45%)]	Loss: 11.2282	Cost: 6.18s
Train Epoch: 877 [61440/90000 (68%)]	Loss: 10.9872	Cost: 6.02s
Train Epoch: 877 [81920/90000 (91%)]	Loss: 11.4000	Cost: 5.77s
Train Epoch: 877 	Average Loss: 11.6412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0965

Learning rate: 0.00019622844954191875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 878 [0/90000 (0%)]	Loss: 20.0112	Cost: 24.23s
Train Epoch: 878 [20480/90000 (23%)]	Loss: 10.9817	Cost: 6.01s
Train Epoch: 878 [40960/90000 (45%)]	Loss: 11.0185	Cost: 6.18s
Train Epoch: 878 [61440/90000 (68%)]	Loss: 10.8554	Cost: 5.87s
Train Epoch: 878 [81920/90000 (91%)]	Loss: 11.1796	Cost: 6.46s
Train Epoch: 878 	Average Loss: 11.6312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0431

Learning rate: 0.00019621989824372354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 879 [0/90000 (0%)]	Loss: 19.7888	Cost: 25.49s
Train Epoch: 879 [20480/90000 (23%)]	Loss: 10.8841	Cost: 6.06s
Train Epoch: 879 [40960/90000 (45%)]	Loss: 10.8242	Cost: 6.23s
Train Epoch: 879 [61440/90000 (68%)]	Loss: 10.9059	Cost: 5.85s
Train Epoch: 879 [81920/90000 (91%)]	Loss: 11.0366	Cost: 5.80s
Train Epoch: 879 	Average Loss: 11.5293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0875

Learning rate: 0.0001962113374490051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 880 [0/90000 (0%)]	Loss: 19.8928	Cost: 24.11s
Train Epoch: 880 [20480/90000 (23%)]	Loss: 10.7867	Cost: 6.21s
Train Epoch: 880 [40960/90000 (45%)]	Loss: 10.7512	Cost: 6.61s
Train Epoch: 880 [61440/90000 (68%)]	Loss: 10.8819	Cost: 5.86s
Train Epoch: 880 [81920/90000 (91%)]	Loss: 10.8872	Cost: 5.99s
Train Epoch: 880 	Average Loss: 11.4930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1829

Learning rate: 0.00019620276715860832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 881 [0/90000 (0%)]	Loss: 20.0529	Cost: 24.43s
Train Epoch: 881 [20480/90000 (23%)]	Loss: 10.4792	Cost: 6.12s
Train Epoch: 881 [40960/90000 (45%)]	Loss: 10.7912	Cost: 6.71s
Train Epoch: 881 [61440/90000 (68%)]	Loss: 10.5849	Cost: 6.01s
Train Epoch: 881 [81920/90000 (91%)]	Loss: 10.7291	Cost: 5.81s
Train Epoch: 881 	Average Loss: 11.3241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2020

Learning rate: 0.0001961941873733791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 882 [0/90000 (0%)]	Loss: 20.1347	Cost: 24.36s
Train Epoch: 882 [20480/90000 (23%)]	Loss: 10.8071	Cost: 6.05s
Train Epoch: 882 [40960/90000 (45%)]	Loss: 10.8634	Cost: 6.18s
Train Epoch: 882 [61440/90000 (68%)]	Loss: 10.5454	Cost: 6.05s
Train Epoch: 882 [81920/90000 (91%)]	Loss: 10.7814	Cost: 5.65s
Train Epoch: 882 	Average Loss: 11.3398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1484

Learning rate: 0.0001961855980941642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 883 [0/90000 (0%)]	Loss: 20.0252	Cost: 22.65s
Train Epoch: 883 [20480/90000 (23%)]	Loss: 10.7897	Cost: 6.77s
Train Epoch: 883 [40960/90000 (45%)]	Loss: 10.8397	Cost: 6.74s
Train Epoch: 883 [61440/90000 (68%)]	Loss: 10.5303	Cost: 5.93s
Train Epoch: 883 [81920/90000 (91%)]	Loss: 10.8630	Cost: 5.89s
Train Epoch: 883 	Average Loss: 11.3614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1567

Learning rate: 0.0001961769993218114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 884 [0/90000 (0%)]	Loss: 19.9304	Cost: 21.79s
Train Epoch: 884 [20480/90000 (23%)]	Loss: 10.6949	Cost: 6.40s
Train Epoch: 884 [40960/90000 (45%)]	Loss: 10.6519	Cost: 6.47s
Train Epoch: 884 [61440/90000 (68%)]	Loss: 10.3910	Cost: 6.06s
Train Epoch: 884 [81920/90000 (91%)]	Loss: 10.6946	Cost: 6.12s
Train Epoch: 884 	Average Loss: 11.2216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2258

Learning rate: 0.00019616839105716927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 885 [0/90000 (0%)]	Loss: 19.9540	Cost: 20.91s
Train Epoch: 885 [20480/90000 (23%)]	Loss: 10.1769	Cost: 6.71s
Train Epoch: 885 [40960/90000 (45%)]	Loss: 10.7173	Cost: 6.56s
Train Epoch: 885 [61440/90000 (68%)]	Loss: 10.3658	Cost: 5.91s
Train Epoch: 885 [81920/90000 (91%)]	Loss: 10.6678	Cost: 6.16s
Train Epoch: 885 	Average Loss: 11.1348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2441

Learning rate: 0.00019615977330108747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 886 [0/90000 (0%)]	Loss: 20.1169	Cost: 20.34s
Train Epoch: 886 [20480/90000 (23%)]	Loss: 10.5558	Cost: 6.18s
Train Epoch: 886 [40960/90000 (45%)]	Loss: 10.8815	Cost: 6.12s
Train Epoch: 886 [61440/90000 (68%)]	Loss: 10.7649	Cost: 5.99s
Train Epoch: 886 [81920/90000 (91%)]	Loss: 10.7478	Cost: 5.83s
Train Epoch: 886 	Average Loss: 11.3314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1788

Learning rate: 0.00019615114605441654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 887 [0/90000 (0%)]	Loss: 19.9903	Cost: 20.25s
Train Epoch: 887 [20480/90000 (23%)]	Loss: 10.6006	Cost: 6.08s
Train Epoch: 887 [40960/90000 (45%)]	Loss: 10.6716	Cost: 6.46s
Train Epoch: 887 [61440/90000 (68%)]	Loss: 10.3559	Cost: 6.02s
Train Epoch: 887 [81920/90000 (91%)]	Loss: 10.5575	Cost: 6.09s
Train Epoch: 887 	Average Loss: 11.2243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1381

Learning rate: 0.00019614250931800791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 888 [0/90000 (0%)]	Loss: 20.1818	Cost: 20.80s
Train Epoch: 888 [20480/90000 (23%)]	Loss: 10.3734	Cost: 5.97s
Train Epoch: 888 [40960/90000 (45%)]	Loss: 10.4945	Cost: 6.30s
Train Epoch: 888 [61440/90000 (68%)]	Loss: 10.5993	Cost: 5.99s
Train Epoch: 888 [81920/90000 (91%)]	Loss: 10.5719	Cost: 6.55s
Train Epoch: 888 	Average Loss: 11.1335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2984

Learning rate: 0.00019613386309271408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 889 [0/90000 (0%)]	Loss: 19.8766	Cost: 21.14s
Train Epoch: 889 [20480/90000 (23%)]	Loss: 10.5931	Cost: 5.98s
Train Epoch: 889 [40960/90000 (45%)]	Loss: 10.6825	Cost: 6.62s
Train Epoch: 889 [61440/90000 (68%)]	Loss: 10.4618	Cost: 5.77s
Train Epoch: 889 [81920/90000 (91%)]	Loss: 10.7464	Cost: 6.64s
Train Epoch: 889 	Average Loss: 11.2181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2616

Learning rate: 0.0001961252073793883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 890 [0/90000 (0%)]	Loss: 20.0574	Cost: 21.66s
Train Epoch: 890 [20480/90000 (23%)]	Loss: 10.6149	Cost: 5.98s
Train Epoch: 890 [40960/90000 (45%)]	Loss: 10.7882	Cost: 6.26s
Train Epoch: 890 [61440/90000 (68%)]	Loss: 10.5714	Cost: 5.82s
Train Epoch: 890 [81920/90000 (91%)]	Loss: 10.7296	Cost: 5.92s
Train Epoch: 890 	Average Loss: 11.2459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3768

Learning rate: 0.00019611654217888494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 891 [0/90000 (0%)]	Loss: 19.9976	Cost: 20.55s
Train Epoch: 891 [20480/90000 (23%)]	Loss: 10.4917	Cost: 6.11s
Train Epoch: 891 [40960/90000 (45%)]	Loss: 10.5064	Cost: 6.29s
Train Epoch: 891 [61440/90000 (68%)]	Loss: 10.5104	Cost: 5.84s
Train Epoch: 891 [81920/90000 (91%)]	Loss: 10.6698	Cost: 5.75s
Train Epoch: 891 	Average Loss: 11.1731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2825

Learning rate: 0.00019610786749205917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 892 [0/90000 (0%)]	Loss: 20.0038	Cost: 20.89s
Train Epoch: 892 [20480/90000 (23%)]	Loss: 10.6020	Cost: 6.04s
Train Epoch: 892 [40960/90000 (45%)]	Loss: 10.7547	Cost: 6.66s
Train Epoch: 892 [61440/90000 (68%)]	Loss: 10.4209	Cost: 5.89s
Train Epoch: 892 [81920/90000 (91%)]	Loss: 10.4717	Cost: 6.06s
Train Epoch: 892 	Average Loss: 11.2102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2608

Learning rate: 0.00019609918331976714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 893 [0/90000 (0%)]	Loss: 20.2064	Cost: 19.81s
Train Epoch: 893 [20480/90000 (23%)]	Loss: 10.4462	Cost: 6.11s
Train Epoch: 893 [40960/90000 (45%)]	Loss: 10.4899	Cost: 6.87s
Train Epoch: 893 [61440/90000 (68%)]	Loss: 10.3113	Cost: 5.96s
Train Epoch: 893 [81920/90000 (91%)]	Loss: 10.4699	Cost: 5.74s
Train Epoch: 893 	Average Loss: 11.0813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3151

Learning rate: 0.00019609048966286597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 894 [0/90000 (0%)]	Loss: 20.2320	Cost: 20.19s
Train Epoch: 894 [20480/90000 (23%)]	Loss: 10.4083	Cost: 6.29s
Train Epoch: 894 [40960/90000 (45%)]	Loss: 10.4316	Cost: 6.11s
Train Epoch: 894 [61440/90000 (68%)]	Loss: 10.2691	Cost: 5.96s
Train Epoch: 894 [81920/90000 (91%)]	Loss: 10.6408	Cost: 5.79s
Train Epoch: 894 	Average Loss: 11.0459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3649

Learning rate: 0.0001960817865222137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 895 [0/90000 (0%)]	Loss: 20.1420	Cost: 20.13s
Train Epoch: 895 [20480/90000 (23%)]	Loss: 10.4394	Cost: 6.24s
Train Epoch: 895 [40960/90000 (45%)]	Loss: 10.6355	Cost: 6.08s
Train Epoch: 895 [61440/90000 (68%)]	Loss: 10.4174	Cost: 5.85s
Train Epoch: 895 [81920/90000 (91%)]	Loss: 10.7317	Cost: 5.76s
Train Epoch: 895 	Average Loss: 11.1692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3452

Learning rate: 0.00019607307389866925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 896 [0/90000 (0%)]	Loss: 20.2977	Cost: 20.76s
Train Epoch: 896 [20480/90000 (23%)]	Loss: 10.3952	Cost: 6.25s
Train Epoch: 896 [40960/90000 (45%)]	Loss: 10.7666	Cost: 6.17s
Train Epoch: 896 [61440/90000 (68%)]	Loss: 10.3970	Cost: 5.89s
Train Epoch: 896 [81920/90000 (91%)]	Loss: 10.3954	Cost: 5.72s
Train Epoch: 896 	Average Loss: 11.1450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2174

Learning rate: 0.00019606435179309254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 897 [0/90000 (0%)]	Loss: 20.0946	Cost: 21.78s
Train Epoch: 897 [20480/90000 (23%)]	Loss: 10.2437	Cost: 6.10s
Train Epoch: 897 [40960/90000 (45%)]	Loss: 10.4978	Cost: 6.39s
Train Epoch: 897 [61440/90000 (68%)]	Loss: 10.2055	Cost: 5.85s
Train Epoch: 897 [81920/90000 (91%)]	Loss: 10.5294	Cost: 6.13s
Train Epoch: 897 	Average Loss: 11.0596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4300

Learning rate: 0.00019605562020634444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 898 [0/90000 (0%)]	Loss: 20.0404	Cost: 21.55s
Train Epoch: 898 [20480/90000 (23%)]	Loss: 10.3973	Cost: 6.05s
Train Epoch: 898 [40960/90000 (45%)]	Loss: 10.4808	Cost: 6.23s
Train Epoch: 898 [61440/90000 (68%)]	Loss: 10.2921	Cost: 5.91s
Train Epoch: 898 [81920/90000 (91%)]	Loss: 10.2997	Cost: 5.78s
Train Epoch: 898 	Average Loss: 11.0652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3156

Learning rate: 0.0001960468791392867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 899 [0/90000 (0%)]	Loss: 20.2396	Cost: 21.62s
Train Epoch: 899 [20480/90000 (23%)]	Loss: 10.3363	Cost: 5.96s
Train Epoch: 899 [40960/90000 (45%)]	Loss: 10.4307	Cost: 6.51s
Train Epoch: 899 [61440/90000 (68%)]	Loss: 10.1914	Cost: 5.89s
Train Epoch: 899 [81920/90000 (91%)]	Loss: 10.5008	Cost: 6.06s
Train Epoch: 899 	Average Loss: 11.0113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3376

Learning rate: 0.000196038128592782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 900 [0/90000 (0%)]	Loss: 20.0270	Cost: 22.94s
Train Epoch: 900 [20480/90000 (23%)]	Loss: 10.2021	Cost: 5.96s
Train Epoch: 900 [40960/90000 (45%)]	Loss: 10.3374	Cost: 7.08s
Train Epoch: 900 [61440/90000 (68%)]	Loss: 10.2430	Cost: 5.91s
Train Epoch: 900 [81920/90000 (91%)]	Loss: 10.2651	Cost: 5.72s
Train Epoch: 900 	Average Loss: 10.9730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3610

Learning rate: 0.00019602936856769404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 901 [0/90000 (0%)]	Loss: 20.2148	Cost: 20.86s
Train Epoch: 901 [20480/90000 (23%)]	Loss: 10.2153	Cost: 6.04s
Train Epoch: 901 [40960/90000 (45%)]	Loss: 10.2890	Cost: 6.19s
Train Epoch: 901 [61440/90000 (68%)]	Loss: 10.1461	Cost: 5.92s
Train Epoch: 901 [81920/90000 (91%)]	Loss: 10.4153	Cost: 5.81s
Train Epoch: 901 	Average Loss: 10.9520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3817

Learning rate: 0.0001960205990648874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 902 [0/90000 (0%)]	Loss: 20.1193	Cost: 22.57s
Train Epoch: 902 [20480/90000 (23%)]	Loss: 10.1216	Cost: 6.17s
Train Epoch: 902 [40960/90000 (45%)]	Loss: 10.2831	Cost: 6.07s
Train Epoch: 902 [61440/90000 (68%)]	Loss: 10.1355	Cost: 6.17s
Train Epoch: 902 [81920/90000 (91%)]	Loss: 10.3248	Cost: 5.90s
Train Epoch: 902 	Average Loss: 10.9545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4850

Learning rate: 0.0001960118200852275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 903 [0/90000 (0%)]	Loss: 20.1446	Cost: 21.44s
Train Epoch: 903 [20480/90000 (23%)]	Loss: 10.3198	Cost: 6.16s
Train Epoch: 903 [40960/90000 (45%)]	Loss: 10.2103	Cost: 6.08s
Train Epoch: 903 [61440/90000 (68%)]	Loss: 10.2349	Cost: 5.96s
Train Epoch: 903 [81920/90000 (91%)]	Loss: 10.5041	Cost: 5.79s
Train Epoch: 903 	Average Loss: 10.9673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4182

Learning rate: 0.00019600303162958089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 904 [0/90000 (0%)]	Loss: 20.0472	Cost: 23.92s
Train Epoch: 904 [20480/90000 (23%)]	Loss: 10.2361	Cost: 6.00s
Train Epoch: 904 [40960/90000 (45%)]	Loss: 10.3447	Cost: 6.07s
Train Epoch: 904 [61440/90000 (68%)]	Loss: 10.0970	Cost: 5.96s
Train Epoch: 904 [81920/90000 (91%)]	Loss: 10.1604	Cost: 5.85s
Train Epoch: 904 	Average Loss: 10.9200
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5028

Learning rate: 0.00019599423369881492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 905 [0/90000 (0%)]	Loss: 20.2930	Cost: 23.16s
Train Epoch: 905 [20480/90000 (23%)]	Loss: 10.1120	Cost: 6.02s
Train Epoch: 905 [40960/90000 (45%)]	Loss: 10.3143	Cost: 6.11s
Train Epoch: 905 [61440/90000 (68%)]	Loss: 10.1610	Cost: 5.92s
Train Epoch: 905 [81920/90000 (91%)]	Loss: 10.1852	Cost: 5.81s
Train Epoch: 905 	Average Loss: 10.8482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4903

Learning rate: 0.0001959854262937979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 906 [0/90000 (0%)]	Loss: 20.5415	Cost: 22.63s
Train Epoch: 906 [20480/90000 (23%)]	Loss: 10.2782	Cost: 6.31s
Train Epoch: 906 [40960/90000 (45%)]	Loss: 10.4261	Cost: 5.94s
Train Epoch: 906 [61440/90000 (68%)]	Loss: 10.2287	Cost: 5.93s
Train Epoch: 906 [81920/90000 (91%)]	Loss: 10.3221	Cost: 5.80s
Train Epoch: 906 	Average Loss: 10.9546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4879

Learning rate: 0.0001959766094153991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 907 [0/90000 (0%)]	Loss: 20.0402	Cost: 24.44s
Train Epoch: 907 [20480/90000 (23%)]	Loss: 10.2344	Cost: 6.03s
Train Epoch: 907 [40960/90000 (45%)]	Loss: 10.1169	Cost: 6.43s
Train Epoch: 907 [61440/90000 (68%)]	Loss: 10.0060	Cost: 5.89s
Train Epoch: 907 [81920/90000 (91%)]	Loss: 10.2952	Cost: 6.12s
Train Epoch: 907 	Average Loss: 10.8688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5189

Learning rate: 0.00019596778306448873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 908 [0/90000 (0%)]	Loss: 20.2951	Cost: 24.70s
Train Epoch: 908 [20480/90000 (23%)]	Loss: 10.3088	Cost: 6.01s
Train Epoch: 908 [40960/90000 (45%)]	Loss: 10.3376	Cost: 6.37s
Train Epoch: 908 [61440/90000 (68%)]	Loss: 10.1856	Cost: 5.87s
Train Epoch: 908 [81920/90000 (91%)]	Loss: 10.2634	Cost: 5.71s
Train Epoch: 908 	Average Loss: 10.8976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5172

Learning rate: 0.0001959589472419379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 909 [0/90000 (0%)]	Loss: 20.3625	Cost: 22.46s
Train Epoch: 909 [20480/90000 (23%)]	Loss: 10.3367	Cost: 6.12s
Train Epoch: 909 [40960/90000 (45%)]	Loss: 10.1969	Cost: 6.23s
Train Epoch: 909 [61440/90000 (68%)]	Loss: 9.9993	Cost: 5.92s
Train Epoch: 909 [81920/90000 (91%)]	Loss: 10.2514	Cost: 5.86s
Train Epoch: 909 	Average Loss: 10.8868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4963

Learning rate: 0.00019595010194861865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 910 [0/90000 (0%)]	Loss: 20.2769	Cost: 21.71s
Train Epoch: 910 [20480/90000 (23%)]	Loss: 10.1917	Cost: 7.01s
Train Epoch: 910 [40960/90000 (45%)]	Loss: 10.3481	Cost: 6.33s
Train Epoch: 910 [61440/90000 (68%)]	Loss: 10.0680	Cost: 5.94s
Train Epoch: 910 [81920/90000 (91%)]	Loss: 10.1432	Cost: 5.88s
Train Epoch: 910 	Average Loss: 10.8877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4880

Learning rate: 0.00019594124718540402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 911 [0/90000 (0%)]	Loss: 20.3664	Cost: 20.30s
Train Epoch: 911 [20480/90000 (23%)]	Loss: 9.9989	Cost: 6.48s
Train Epoch: 911 [40960/90000 (45%)]	Loss: 10.2281	Cost: 6.45s
Train Epoch: 911 [61440/90000 (68%)]	Loss: 9.9565	Cost: 6.12s
Train Epoch: 911 [81920/90000 (91%)]	Loss: 10.2245	Cost: 5.82s
Train Epoch: 911 	Average Loss: 10.7508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4989

Learning rate: 0.00019593238295316788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 912 [0/90000 (0%)]	Loss: 20.2566	Cost: 20.06s
Train Epoch: 912 [20480/90000 (23%)]	Loss: 10.1188	Cost: 6.34s
Train Epoch: 912 [40960/90000 (45%)]	Loss: 10.1622	Cost: 6.31s
Train Epoch: 912 [61440/90000 (68%)]	Loss: 9.9660	Cost: 5.92s
Train Epoch: 912 [81920/90000 (91%)]	Loss: 10.1214	Cost: 5.80s
Train Epoch: 912 	Average Loss: 10.7802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5824

Learning rate: 0.00019592350925278515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 913 [0/90000 (0%)]	Loss: 20.2129	Cost: 20.30s
Train Epoch: 913 [20480/90000 (23%)]	Loss: 10.0745	Cost: 6.00s
Train Epoch: 913 [40960/90000 (45%)]	Loss: 10.2177	Cost: 6.60s
Train Epoch: 913 [61440/90000 (68%)]	Loss: 10.0431	Cost: 6.00s
Train Epoch: 913 [81920/90000 (91%)]	Loss: 10.2567	Cost: 5.78s
Train Epoch: 913 	Average Loss: 10.8273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5400

Learning rate: 0.0001959146260851316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 914 [0/90000 (0%)]	Loss: 20.3440	Cost: 20.90s
Train Epoch: 914 [20480/90000 (23%)]	Loss: 10.0042	Cost: 6.04s
Train Epoch: 914 [40960/90000 (45%)]	Loss: 10.3065	Cost: 6.18s
Train Epoch: 914 [61440/90000 (68%)]	Loss: 10.0240	Cost: 6.06s
Train Epoch: 914 [81920/90000 (91%)]	Loss: 10.1206	Cost: 5.76s
Train Epoch: 914 	Average Loss: 10.7785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5638

Learning rate: 0.00019590573345108395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 915 [0/90000 (0%)]	Loss: 20.2875	Cost: 20.55s
Train Epoch: 915 [20480/90000 (23%)]	Loss: 10.2183	Cost: 6.19s
Train Epoch: 915 [40960/90000 (45%)]	Loss: 9.9499	Cost: 5.99s
Train Epoch: 915 [61440/90000 (68%)]	Loss: 9.9467	Cost: 5.95s
Train Epoch: 915 [81920/90000 (91%)]	Loss: 10.1926	Cost: 6.07s
Train Epoch: 915 	Average Loss: 10.8163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5430

Learning rate: 0.00019589683135151992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 916 [0/90000 (0%)]	Loss: 20.4215	Cost: 21.10s
Train Epoch: 916 [20480/90000 (23%)]	Loss: 10.1583	Cost: 6.13s
Train Epoch: 916 [40960/90000 (45%)]	Loss: 10.2475	Cost: 6.15s
Train Epoch: 916 [61440/90000 (68%)]	Loss: 9.9741	Cost: 5.88s
Train Epoch: 916 [81920/90000 (91%)]	Loss: 10.1065	Cost: 5.97s
Train Epoch: 916 	Average Loss: 10.8113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5911

Learning rate: 0.00019588791978731806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 917 [0/90000 (0%)]	Loss: 20.5764	Cost: 20.23s
Train Epoch: 917 [20480/90000 (23%)]	Loss: 10.2464	Cost: 5.92s
Train Epoch: 917 [40960/90000 (45%)]	Loss: 10.2858	Cost: 6.73s
Train Epoch: 917 [61440/90000 (68%)]	Loss: 9.9482	Cost: 5.85s
Train Epoch: 917 [81920/90000 (91%)]	Loss: 10.2655	Cost: 6.19s
Train Epoch: 917 	Average Loss: 10.8367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5108

Learning rate: 0.00019587899875935793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 918 [0/90000 (0%)]	Loss: 20.2340	Cost: 20.20s
Train Epoch: 918 [20480/90000 (23%)]	Loss: 9.9924	Cost: 6.24s
Train Epoch: 918 [40960/90000 (45%)]	Loss: 10.3049	Cost: 6.05s
Train Epoch: 918 [61440/90000 (68%)]	Loss: 10.0058	Cost: 6.01s
Train Epoch: 918 [81920/90000 (91%)]	Loss: 10.0472	Cost: 5.79s
Train Epoch: 918 	Average Loss: 10.8008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5771

Learning rate: 0.00019587006826851997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 919 [0/90000 (0%)]	Loss: 20.1849	Cost: 21.03s
Train Epoch: 919 [20480/90000 (23%)]	Loss: 9.9985	Cost: 6.00s
Train Epoch: 919 [40960/90000 (45%)]	Loss: 10.0038	Cost: 6.57s
Train Epoch: 919 [61440/90000 (68%)]	Loss: 9.8926	Cost: 5.89s
Train Epoch: 919 [81920/90000 (91%)]	Loss: 10.0399	Cost: 5.65s
Train Epoch: 919 	Average Loss: 10.6929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6197

Learning rate: 0.00019586112831568563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 920 [0/90000 (0%)]	Loss: 20.2653	Cost: 20.29s
Train Epoch: 920 [20480/90000 (23%)]	Loss: 9.9622	Cost: 6.14s
Train Epoch: 920 [40960/90000 (45%)]	Loss: 10.0577	Cost: 5.99s
Train Epoch: 920 [61440/90000 (68%)]	Loss: 9.9141	Cost: 5.87s
Train Epoch: 920 [81920/90000 (91%)]	Loss: 10.3272	Cost: 5.68s
Train Epoch: 920 	Average Loss: 10.7203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6439

Learning rate: 0.00019585217890173725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 921 [0/90000 (0%)]	Loss: 20.4479	Cost: 20.69s
Train Epoch: 921 [20480/90000 (23%)]	Loss: 10.1357	Cost: 6.09s
Train Epoch: 921 [40960/90000 (45%)]	Loss: 10.2027	Cost: 6.14s
Train Epoch: 921 [61440/90000 (68%)]	Loss: 10.1384	Cost: 5.90s
Train Epoch: 921 [81920/90000 (91%)]	Loss: 10.3303	Cost: 5.73s
Train Epoch: 921 	Average Loss: 10.8758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6280

Learning rate: 0.0001958432200275581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 922 [0/90000 (0%)]	Loss: 20.4630	Cost: 19.22s
Train Epoch: 922 [20480/90000 (23%)]	Loss: 10.2536	Cost: 6.23s
Train Epoch: 922 [40960/90000 (45%)]	Loss: 10.3135	Cost: 6.07s
Train Epoch: 922 [61440/90000 (68%)]	Loss: 10.0698	Cost: 5.90s
Train Epoch: 922 [81920/90000 (91%)]	Loss: 10.2508	Cost: 5.71s
Train Epoch: 922 	Average Loss: 10.8751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6735

Learning rate: 0.00019583425169403235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 923 [0/90000 (0%)]	Loss: 20.4802	Cost: 20.13s
Train Epoch: 923 [20480/90000 (23%)]	Loss: 9.9693	Cost: 6.03s
Train Epoch: 923 [40960/90000 (45%)]	Loss: 9.9954	Cost: 6.03s
Train Epoch: 923 [61440/90000 (68%)]	Loss: 9.8637	Cost: 5.90s
Train Epoch: 923 [81920/90000 (91%)]	Loss: 9.9106	Cost: 5.81s
Train Epoch: 923 	Average Loss: 10.7140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5927

Learning rate: 0.00019582527390204514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 924 [0/90000 (0%)]	Loss: 20.3898	Cost: 20.15s
Train Epoch: 924 [20480/90000 (23%)]	Loss: 9.7734	Cost: 6.09s
Train Epoch: 924 [40960/90000 (45%)]	Loss: 9.9558	Cost: 6.13s
Train Epoch: 924 [61440/90000 (68%)]	Loss: 9.8359	Cost: 5.95s
Train Epoch: 924 [81920/90000 (91%)]	Loss: 9.9358	Cost: 5.73s
Train Epoch: 924 	Average Loss: 10.6247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6368

Learning rate: 0.00019581628665248256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 925 [0/90000 (0%)]	Loss: 20.4206	Cost: 21.50s
Train Epoch: 925 [20480/90000 (23%)]	Loss: 9.8495	Cost: 6.04s
Train Epoch: 925 [40960/90000 (45%)]	Loss: 10.1134	Cost: 6.27s
Train Epoch: 925 [61440/90000 (68%)]	Loss: 9.8003	Cost: 5.96s
Train Epoch: 925 [81920/90000 (91%)]	Loss: 9.9394	Cost: 5.71s
Train Epoch: 925 	Average Loss: 10.6440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6564

Learning rate: 0.00019580728994623165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 926 [0/90000 (0%)]	Loss: 20.3817	Cost: 21.65s
Train Epoch: 926 [20480/90000 (23%)]	Loss: 9.8388	Cost: 6.35s
Train Epoch: 926 [40960/90000 (45%)]	Loss: 9.9950	Cost: 6.11s
Train Epoch: 926 [61440/90000 (68%)]	Loss: 9.8462	Cost: 5.97s
Train Epoch: 926 [81920/90000 (91%)]	Loss: 9.8942	Cost: 5.77s
Train Epoch: 926 	Average Loss: 10.6132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6064

Learning rate: 0.00019579828378418028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 927 [0/90000 (0%)]	Loss: 20.5093	Cost: 22.14s
Train Epoch: 927 [20480/90000 (23%)]	Loss: 9.8845	Cost: 6.16s
Train Epoch: 927 [40960/90000 (45%)]	Loss: 9.9483	Cost: 6.16s
Train Epoch: 927 [61440/90000 (68%)]	Loss: 9.7848	Cost: 5.87s
Train Epoch: 927 [81920/90000 (91%)]	Loss: 9.9255	Cost: 5.96s
Train Epoch: 927 	Average Loss: 10.6035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6989

Learning rate: 0.00019578926816721736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 928 [0/90000 (0%)]	Loss: 20.7673	Cost: 24.19s
Train Epoch: 928 [20480/90000 (23%)]	Loss: 9.8433	Cost: 6.05s
Train Epoch: 928 [40960/90000 (45%)]	Loss: 9.9536	Cost: 6.24s
Train Epoch: 928 [61440/90000 (68%)]	Loss: 9.9616	Cost: 5.93s
Train Epoch: 928 [81920/90000 (91%)]	Loss: 10.1508	Cost: 5.83s
Train Epoch: 928 	Average Loss: 10.6651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6979

Learning rate: 0.00019578024309623268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 929 [0/90000 (0%)]	Loss: 20.5028	Cost: 23.95s
Train Epoch: 929 [20480/90000 (23%)]	Loss: 10.1332	Cost: 6.11s
Train Epoch: 929 [40960/90000 (45%)]	Loss: 10.1730	Cost: 6.09s
Train Epoch: 929 [61440/90000 (68%)]	Loss: 9.8176	Cost: 6.07s
Train Epoch: 929 [81920/90000 (91%)]	Loss: 10.0629	Cost: 5.73s
Train Epoch: 929 	Average Loss: 10.7726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6260

Learning rate: 0.00019577120857211698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 930 [0/90000 (0%)]	Loss: 20.3446	Cost: 24.79s
Train Epoch: 930 [20480/90000 (23%)]	Loss: 9.8890	Cost: 6.03s
Train Epoch: 930 [40960/90000 (45%)]	Loss: 10.0199	Cost: 6.07s
Train Epoch: 930 [61440/90000 (68%)]	Loss: 9.7258	Cost: 5.96s
Train Epoch: 930 [81920/90000 (91%)]	Loss: 10.0768	Cost: 5.74s
Train Epoch: 930 	Average Loss: 10.6650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6997

Learning rate: 0.00019576216459576195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 931 [0/90000 (0%)]	Loss: 20.5172	Cost: 23.07s
Train Epoch: 931 [20480/90000 (23%)]	Loss: 9.8652	Cost: 6.48s
Train Epoch: 931 [40960/90000 (45%)]	Loss: 9.7860	Cost: 6.88s
Train Epoch: 931 [61440/90000 (68%)]	Loss: 9.8062	Cost: 5.91s
Train Epoch: 931 [81920/90000 (91%)]	Loss: 9.8242	Cost: 5.76s
Train Epoch: 931 	Average Loss: 10.5898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7175

Learning rate: 0.0001957531111680602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 932 [0/90000 (0%)]	Loss: 20.5965	Cost: 22.82s
Train Epoch: 932 [20480/90000 (23%)]	Loss: 9.6340	Cost: 6.35s
Train Epoch: 932 [40960/90000 (45%)]	Loss: 9.9799	Cost: 6.59s
Train Epoch: 932 [61440/90000 (68%)]	Loss: 9.6546	Cost: 5.94s
Train Epoch: 932 [81920/90000 (91%)]	Loss: 9.7643	Cost: 5.74s
Train Epoch: 932 	Average Loss: 10.5512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7357

Learning rate: 0.00019574404828990522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 933 [0/90000 (0%)]	Loss: 20.4479	Cost: 20.86s
Train Epoch: 933 [20480/90000 (23%)]	Loss: 9.8117	Cost: 7.31s
Train Epoch: 933 [40960/90000 (45%)]	Loss: 9.9092	Cost: 6.47s
Train Epoch: 933 [61440/90000 (68%)]	Loss: 9.5016	Cost: 5.88s
Train Epoch: 933 [81920/90000 (91%)]	Loss: 10.0426	Cost: 5.80s
Train Epoch: 933 	Average Loss: 10.5461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6881

Learning rate: 0.00019573497596219155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 934 [0/90000 (0%)]	Loss: 20.4736	Cost: 20.96s
Train Epoch: 934 [20480/90000 (23%)]	Loss: 9.7973	Cost: 6.27s
Train Epoch: 934 [40960/90000 (45%)]	Loss: 9.8819	Cost: 6.25s
Train Epoch: 934 [61440/90000 (68%)]	Loss: 9.8107	Cost: 6.03s
Train Epoch: 934 [81920/90000 (91%)]	Loss: 10.1032	Cost: 5.87s
Train Epoch: 934 	Average Loss: 10.5836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7707

Learning rate: 0.00019572589418581453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 935 [0/90000 (0%)]	Loss: 20.2886	Cost: 20.22s
Train Epoch: 935 [20480/90000 (23%)]	Loss: 9.7926	Cost: 6.28s
Train Epoch: 935 [40960/90000 (45%)]	Loss: 9.8684	Cost: 6.16s
Train Epoch: 935 [61440/90000 (68%)]	Loss: 9.6763	Cost: 5.97s
Train Epoch: 935 [81920/90000 (91%)]	Loss: 9.9754	Cost: 6.01s
Train Epoch: 935 	Average Loss: 10.5640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7213

Learning rate: 0.00019571680296167054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 936 [0/90000 (0%)]	Loss: 20.6064	Cost: 21.10s
Train Epoch: 936 [20480/90000 (23%)]	Loss: 9.6858	Cost: 6.01s
Train Epoch: 936 [40960/90000 (45%)]	Loss: 9.8760	Cost: 6.20s
Train Epoch: 936 [61440/90000 (68%)]	Loss: 9.5657	Cost: 5.95s
Train Epoch: 936 [81920/90000 (91%)]	Loss: 9.8121	Cost: 5.81s
Train Epoch: 936 	Average Loss: 10.5205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6857

Learning rate: 0.00019570770229065682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 937 [0/90000 (0%)]	Loss: 20.5111	Cost: 20.70s
Train Epoch: 937 [20480/90000 (23%)]	Loss: 9.5810	Cost: 6.12s
Train Epoch: 937 [40960/90000 (45%)]	Loss: 9.8275	Cost: 6.59s
Train Epoch: 937 [61440/90000 (68%)]	Loss: 9.5948	Cost: 5.90s
Train Epoch: 937 [81920/90000 (91%)]	Loss: 9.8542	Cost: 7.06s
Train Epoch: 937 	Average Loss: 10.5470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8283

Learning rate: 0.0001956985921736716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 938 [0/90000 (0%)]	Loss: 20.6304	Cost: 20.62s
Train Epoch: 938 [20480/90000 (23%)]	Loss: 9.7151	Cost: 5.98s
Train Epoch: 938 [40960/90000 (45%)]	Loss: 9.8700	Cost: 6.20s
Train Epoch: 938 [61440/90000 (68%)]	Loss: 9.5061	Cost: 6.10s
Train Epoch: 938 [81920/90000 (91%)]	Loss: 9.9787	Cost: 5.93s
Train Epoch: 938 	Average Loss: 10.5299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7215

Learning rate: 0.00019568947261161396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 939 [0/90000 (0%)]	Loss: 20.6828	Cost: 21.40s
Train Epoch: 939 [20480/90000 (23%)]	Loss: 9.6936	Cost: 5.99s
Train Epoch: 939 [40960/90000 (45%)]	Loss: 9.9068	Cost: 6.14s
Train Epoch: 939 [61440/90000 (68%)]	Loss: 9.6325	Cost: 5.94s
Train Epoch: 939 [81920/90000 (91%)]	Loss: 9.8950	Cost: 5.91s
Train Epoch: 939 	Average Loss: 10.5801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7326

Learning rate: 0.00019568034360538402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 940 [0/90000 (0%)]	Loss: 20.5969	Cost: 20.87s
Train Epoch: 940 [20480/90000 (23%)]	Loss: 9.7733	Cost: 6.08s
Train Epoch: 940 [40960/90000 (45%)]	Loss: 9.9348	Cost: 6.10s
Train Epoch: 940 [61440/90000 (68%)]	Loss: 9.8195	Cost: 5.93s
Train Epoch: 940 [81920/90000 (91%)]	Loss: 9.9851	Cost: 5.85s
Train Epoch: 940 	Average Loss: 10.6669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8052

Learning rate: 0.00019567120515588275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 941 [0/90000 (0%)]	Loss: 20.6239	Cost: 21.45s
Train Epoch: 941 [20480/90000 (23%)]	Loss: 10.1034	Cost: 6.04s
Train Epoch: 941 [40960/90000 (45%)]	Loss: 10.0856	Cost: 6.33s
Train Epoch: 941 [61440/90000 (68%)]	Loss: 9.6721	Cost: 5.85s
Train Epoch: 941 [81920/90000 (91%)]	Loss: 10.0829	Cost: 5.79s
Train Epoch: 941 	Average Loss: 10.7811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7206

Learning rate: 0.0001956620572640121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 942 [0/90000 (0%)]	Loss: 20.4136	Cost: 21.26s
Train Epoch: 942 [20480/90000 (23%)]	Loss: 9.8748	Cost: 6.05s
Train Epoch: 942 [40960/90000 (45%)]	Loss: 10.1171	Cost: 6.19s
Train Epoch: 942 [61440/90000 (68%)]	Loss: 9.9576	Cost: 5.98s
Train Epoch: 942 [81920/90000 (91%)]	Loss: 9.9778	Cost: 5.79s
Train Epoch: 942 	Average Loss: 10.6634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6932

Learning rate: 0.0001956528999306749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 943 [0/90000 (0%)]	Loss: 20.4330	Cost: 21.68s
Train Epoch: 943 [20480/90000 (23%)]	Loss: 9.5312	Cost: 5.95s
Train Epoch: 943 [40960/90000 (45%)]	Loss: 9.7108	Cost: 6.00s
Train Epoch: 943 [61440/90000 (68%)]	Loss: 9.6721	Cost: 5.83s
Train Epoch: 943 [81920/90000 (91%)]	Loss: 9.8898	Cost: 5.70s
Train Epoch: 943 	Average Loss: 10.5140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7570

Learning rate: 0.00019564373315677494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 944 [0/90000 (0%)]	Loss: 20.4756	Cost: 21.15s
Train Epoch: 944 [20480/90000 (23%)]	Loss: 9.9791	Cost: 6.16s
Train Epoch: 944 [40960/90000 (45%)]	Loss: 9.9662	Cost: 6.57s
Train Epoch: 944 [61440/90000 (68%)]	Loss: 9.7077	Cost: 5.84s
Train Epoch: 944 [81920/90000 (91%)]	Loss: 9.8993	Cost: 6.18s
Train Epoch: 944 	Average Loss: 10.5769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7429

Learning rate: 0.00019563455694321697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 945 [0/90000 (0%)]	Loss: 20.5890	Cost: 20.83s
Train Epoch: 945 [20480/90000 (23%)]	Loss: 9.8338	Cost: 6.08s
Train Epoch: 945 [40960/90000 (45%)]	Loss: 9.8002	Cost: 6.26s
Train Epoch: 945 [61440/90000 (68%)]	Loss: 9.6611	Cost: 5.93s
Train Epoch: 945 [81920/90000 (91%)]	Loss: 9.7617	Cost: 5.82s
Train Epoch: 945 	Average Loss: 10.4821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7303

Learning rate: 0.00019562537129090663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 946 [0/90000 (0%)]	Loss: 20.5464	Cost: 20.44s
Train Epoch: 946 [20480/90000 (23%)]	Loss: 9.5118	Cost: 6.10s
Train Epoch: 946 [40960/90000 (45%)]	Loss: 9.6817	Cost: 6.89s
Train Epoch: 946 [61440/90000 (68%)]	Loss: 9.5327	Cost: 5.82s
Train Epoch: 946 [81920/90000 (91%)]	Loss: 9.7929	Cost: 5.74s
Train Epoch: 946 	Average Loss: 10.4166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7859

Learning rate: 0.00019561617620075054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 947 [0/90000 (0%)]	Loss: 20.5069	Cost: 21.13s
Train Epoch: 947 [20480/90000 (23%)]	Loss: 9.8364	Cost: 6.09s
Train Epoch: 947 [40960/90000 (45%)]	Loss: 9.9415	Cost: 6.12s
Train Epoch: 947 [61440/90000 (68%)]	Loss: 9.7808	Cost: 5.96s
Train Epoch: 947 [81920/90000 (91%)]	Loss: 9.7676	Cost: 5.73s
Train Epoch: 947 	Average Loss: 10.5793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7697

Learning rate: 0.00019560697167365617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 948 [0/90000 (0%)]	Loss: 20.4592	Cost: 20.52s
Train Epoch: 948 [20480/90000 (23%)]	Loss: 9.7452	Cost: 6.12s
Train Epoch: 948 [40960/90000 (45%)]	Loss: 9.8521	Cost: 6.92s
Train Epoch: 948 [61440/90000 (68%)]	Loss: 9.5004	Cost: 5.82s
Train Epoch: 948 [81920/90000 (91%)]	Loss: 9.6714	Cost: 5.96s
Train Epoch: 948 	Average Loss: 10.4415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7908

Learning rate: 0.00019559775771053198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 949 [0/90000 (0%)]	Loss: 20.4345	Cost: 20.95s
Train Epoch: 949 [20480/90000 (23%)]	Loss: 9.6434	Cost: 6.09s
Train Epoch: 949 [40960/90000 (45%)]	Loss: 9.9212	Cost: 6.26s
Train Epoch: 949 [61440/90000 (68%)]	Loss: 9.5163	Cost: 6.07s
Train Epoch: 949 [81920/90000 (91%)]	Loss: 9.7116	Cost: 5.77s
Train Epoch: 949 	Average Loss: 10.4324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8409

Learning rate: 0.0001955885343122874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 950 [0/90000 (0%)]	Loss: 20.5987	Cost: 20.21s
Train Epoch: 950 [20480/90000 (23%)]	Loss: 9.7230	Cost: 6.04s
Train Epoch: 950 [40960/90000 (45%)]	Loss: 9.6078	Cost: 6.33s
Train Epoch: 950 [61440/90000 (68%)]	Loss: 9.6285	Cost: 5.91s
Train Epoch: 950 [81920/90000 (91%)]	Loss: 9.7323	Cost: 5.75s
Train Epoch: 950 	Average Loss: 10.3971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8663

Learning rate: 0.0001955793014798327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 951 [0/90000 (0%)]	Loss: 20.6292	Cost: 21.34s
Train Epoch: 951 [20480/90000 (23%)]	Loss: 9.6318	Cost: 6.03s
Train Epoch: 951 [40960/90000 (45%)]	Loss: 9.8965	Cost: 6.35s
Train Epoch: 951 [61440/90000 (68%)]	Loss: 9.7577	Cost: 5.87s
Train Epoch: 951 [81920/90000 (91%)]	Loss: 9.8612	Cost: 6.24s
Train Epoch: 951 	Average Loss: 10.5439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8573

Learning rate: 0.00019557005921407914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 952 [0/90000 (0%)]	Loss: 20.6061	Cost: 21.34s
Train Epoch: 952 [20480/90000 (23%)]	Loss: 9.7699	Cost: 6.02s
Train Epoch: 952 [40960/90000 (45%)]	Loss: 9.7913	Cost: 6.36s
Train Epoch: 952 [61440/90000 (68%)]	Loss: 9.7980	Cost: 5.86s
Train Epoch: 952 [81920/90000 (91%)]	Loss: 9.7539	Cost: 5.76s
Train Epoch: 952 	Average Loss: 10.4541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7994

Learning rate: 0.0001955608075159389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 953 [0/90000 (0%)]	Loss: 20.4951	Cost: 21.89s
Train Epoch: 953 [20480/90000 (23%)]	Loss: 9.7868	Cost: 6.08s
Train Epoch: 953 [40960/90000 (45%)]	Loss: 9.7924	Cost: 6.14s
Train Epoch: 953 [61440/90000 (68%)]	Loss: 9.7057	Cost: 5.87s
Train Epoch: 953 [81920/90000 (91%)]	Loss: 9.7484	Cost: 5.86s
Train Epoch: 953 	Average Loss: 10.4872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8844

Learning rate: 0.00019555154638632502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 954 [0/90000 (0%)]	Loss: 20.7711	Cost: 23.38s
Train Epoch: 954 [20480/90000 (23%)]	Loss: 9.8645	Cost: 6.10s
Train Epoch: 954 [40960/90000 (45%)]	Loss: 9.7966	Cost: 6.26s
Train Epoch: 954 [61440/90000 (68%)]	Loss: 9.5884	Cost: 5.87s
Train Epoch: 954 [81920/90000 (91%)]	Loss: 9.6631	Cost: 5.83s
Train Epoch: 954 	Average Loss: 10.4232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7933

Learning rate: 0.00019554227582615162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 955 [0/90000 (0%)]	Loss: 20.6777	Cost: 24.94s
Train Epoch: 955 [20480/90000 (23%)]	Loss: 9.5353	Cost: 6.12s
Train Epoch: 955 [40960/90000 (45%)]	Loss: 9.7981	Cost: 6.14s
Train Epoch: 955 [61440/90000 (68%)]	Loss: 9.4896	Cost: 5.90s
Train Epoch: 955 [81920/90000 (91%)]	Loss: 9.6990	Cost: 5.76s
Train Epoch: 955 	Average Loss: 10.3885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8289

Learning rate: 0.00019553299583633364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 956 [0/90000 (0%)]	Loss: 20.4673	Cost: 24.08s
Train Epoch: 956 [20480/90000 (23%)]	Loss: 9.6141	Cost: 6.26s
Train Epoch: 956 [40960/90000 (45%)]	Loss: 9.6606	Cost: 6.30s
Train Epoch: 956 [61440/90000 (68%)]	Loss: 9.7372	Cost: 5.89s
Train Epoch: 956 [81920/90000 (91%)]	Loss: 9.6197	Cost: 5.76s
Train Epoch: 956 	Average Loss: 10.3769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8343

Learning rate: 0.00019552370641778697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 957 [0/90000 (0%)]	Loss: 20.6752	Cost: 22.72s
Train Epoch: 957 [20480/90000 (23%)]	Loss: 9.8268	Cost: 6.85s
Train Epoch: 957 [40960/90000 (45%)]	Loss: 9.6990	Cost: 6.28s
Train Epoch: 957 [61440/90000 (68%)]	Loss: 9.4859	Cost: 5.95s
Train Epoch: 957 [81920/90000 (91%)]	Loss: 9.7407	Cost: 5.79s
Train Epoch: 957 	Average Loss: 10.3532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8223

Learning rate: 0.00019551440757142847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 958 [0/90000 (0%)]	Loss: 20.8044	Cost: 22.24s
Train Epoch: 958 [20480/90000 (23%)]	Loss: 9.4875	Cost: 6.94s
Train Epoch: 958 [40960/90000 (45%)]	Loss: 9.4784	Cost: 6.33s
Train Epoch: 958 [61440/90000 (68%)]	Loss: 9.3107	Cost: 5.98s
Train Epoch: 958 [81920/90000 (91%)]	Loss: 9.6420	Cost: 5.84s
Train Epoch: 958 	Average Loss: 10.2805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9209

Learning rate: 0.00019550509929817583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 959 [0/90000 (0%)]	Loss: 20.7809	Cost: 22.23s
Train Epoch: 959 [20480/90000 (23%)]	Loss: 9.4325	Cost: 6.30s
Train Epoch: 959 [40960/90000 (45%)]	Loss: 9.6410	Cost: 6.56s
Train Epoch: 959 [61440/90000 (68%)]	Loss: 9.5600	Cost: 6.00s
Train Epoch: 959 [81920/90000 (91%)]	Loss: 9.7957	Cost: 5.78s
Train Epoch: 959 	Average Loss: 10.3668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9167

Learning rate: 0.00019549578159894782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 960 [0/90000 (0%)]	Loss: 20.6779	Cost: 21.07s
Train Epoch: 960 [20480/90000 (23%)]	Loss: 9.5267	Cost: 6.30s
Train Epoch: 960 [40960/90000 (45%)]	Loss: 9.4890	Cost: 6.99s
Train Epoch: 960 [61440/90000 (68%)]	Loss: 9.2888	Cost: 6.04s
Train Epoch: 960 [81920/90000 (91%)]	Loss: 9.6352	Cost: 5.99s
Train Epoch: 960 	Average Loss: 10.2760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9141

Learning rate: 0.00019548645447466402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 961 [0/90000 (0%)]	Loss: 20.7427	Cost: 20.56s
Train Epoch: 961 [20480/90000 (23%)]	Loss: 9.5719	Cost: 6.78s
Train Epoch: 961 [40960/90000 (45%)]	Loss: 9.3221	Cost: 6.17s
Train Epoch: 961 [61440/90000 (68%)]	Loss: 9.4361	Cost: 5.88s
Train Epoch: 961 [81920/90000 (91%)]	Loss: 9.4157	Cost: 5.75s
Train Epoch: 961 	Average Loss: 10.2481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9118

Learning rate: 0.00019547711792624497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 962 [0/90000 (0%)]	Loss: 20.7896	Cost: 20.50s
Train Epoch: 962 [20480/90000 (23%)]	Loss: 9.4624	Cost: 6.15s
Train Epoch: 962 [40960/90000 (45%)]	Loss: 9.5079	Cost: 6.26s
Train Epoch: 962 [61440/90000 (68%)]	Loss: 9.2924	Cost: 5.80s
Train Epoch: 962 [81920/90000 (91%)]	Loss: 9.6929	Cost: 5.88s
Train Epoch: 962 	Average Loss: 10.2392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0097

Learning rate: 0.00019546777195461216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 963 [0/90000 (0%)]	Loss: 20.6631	Cost: 19.72s
Train Epoch: 963 [20480/90000 (23%)]	Loss: 9.6225	Cost: 6.13s
Train Epoch: 963 [40960/90000 (45%)]	Loss: 9.5041	Cost: 6.12s
Train Epoch: 963 [61440/90000 (68%)]	Loss: 9.3886	Cost: 6.16s
Train Epoch: 963 [81920/90000 (91%)]	Loss: 9.5513	Cost: 6.11s
Train Epoch: 963 	Average Loss: 10.2466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8955

Learning rate: 0.00019545841656068801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 964 [0/90000 (0%)]	Loss: 20.7378	Cost: 20.43s
Train Epoch: 964 [20480/90000 (23%)]	Loss: 9.3370	Cost: 5.99s
Train Epoch: 964 [40960/90000 (45%)]	Loss: 9.5961	Cost: 6.34s
Train Epoch: 964 [61440/90000 (68%)]	Loss: 9.3693	Cost: 6.02s
Train Epoch: 964 [81920/90000 (91%)]	Loss: 9.7086	Cost: 6.08s
Train Epoch: 964 	Average Loss: 10.2614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8558

Learning rate: 0.00019544905174539588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 965 [0/90000 (0%)]	Loss: 20.8777	Cost: 22.16s
Train Epoch: 965 [20480/90000 (23%)]	Loss: 9.7805	Cost: 5.81s
Train Epoch: 965 [40960/90000 (45%)]	Loss: 9.7881	Cost: 6.04s
Train Epoch: 965 [61440/90000 (68%)]	Loss: 9.4765	Cost: 5.94s
Train Epoch: 965 [81920/90000 (91%)]	Loss: 9.7541	Cost: 6.20s
Train Epoch: 965 	Average Loss: 10.4727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8873

Learning rate: 0.00019543967750965997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 966 [0/90000 (0%)]	Loss: 20.6933	Cost: 20.66s
Train Epoch: 966 [20480/90000 (23%)]	Loss: 9.7464	Cost: 6.07s
Train Epoch: 966 [40960/90000 (45%)]	Loss: 9.7955	Cost: 6.33s
Train Epoch: 966 [61440/90000 (68%)]	Loss: 9.6887	Cost: 5.88s
Train Epoch: 966 [81920/90000 (91%)]	Loss: 9.6380	Cost: 5.81s
Train Epoch: 966 	Average Loss: 10.4587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9124

Learning rate: 0.00019543029385440556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 967 [0/90000 (0%)]	Loss: 20.6521	Cost: 21.32s
Train Epoch: 967 [20480/90000 (23%)]	Loss: 9.5518	Cost: 6.05s
Train Epoch: 967 [40960/90000 (45%)]	Loss: 9.5107	Cost: 6.05s
Train Epoch: 967 [61440/90000 (68%)]	Loss: 9.3369	Cost: 5.67s
Train Epoch: 967 [81920/90000 (91%)]	Loss: 9.7175	Cost: 6.04s
Train Epoch: 967 	Average Loss: 10.3068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9211

Learning rate: 0.00019542090078055873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 968 [0/90000 (0%)]	Loss: 20.8965	Cost: 20.61s
Train Epoch: 968 [20480/90000 (23%)]	Loss: 9.5028	Cost: 6.07s
Train Epoch: 968 [40960/90000 (45%)]	Loss: 9.5874	Cost: 6.50s
Train Epoch: 968 [61440/90000 (68%)]	Loss: 9.5484	Cost: 5.87s
Train Epoch: 968 [81920/90000 (91%)]	Loss: 9.6493	Cost: 6.08s
Train Epoch: 968 	Average Loss: 10.3363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8862

Learning rate: 0.00019541149828904657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 969 [0/90000 (0%)]	Loss: 20.9094	Cost: 21.51s
Train Epoch: 969 [20480/90000 (23%)]	Loss: 9.5392	Cost: 5.95s
Train Epoch: 969 [40960/90000 (45%)]	Loss: 9.6859	Cost: 6.56s
Train Epoch: 969 [61440/90000 (68%)]	Loss: 9.3796	Cost: 5.89s
Train Epoch: 969 [81920/90000 (91%)]	Loss: 9.7113	Cost: 5.94s
Train Epoch: 969 	Average Loss: 10.3197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9734

Learning rate: 0.00019540208638079703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 970 [0/90000 (0%)]	Loss: 20.8672	Cost: 20.56s
Train Epoch: 970 [20480/90000 (23%)]	Loss: 9.6842	Cost: 6.08s
Train Epoch: 970 [40960/90000 (45%)]	Loss: 9.7681	Cost: 6.26s
Train Epoch: 970 [61440/90000 (68%)]	Loss: 9.6366	Cost: 6.03s
Train Epoch: 970 [81920/90000 (91%)]	Loss: 9.6261	Cost: 5.70s
Train Epoch: 970 	Average Loss: 10.3661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9792

Learning rate: 0.00019539266505673905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 971 [0/90000 (0%)]	Loss: 20.6745	Cost: 19.99s
Train Epoch: 971 [20480/90000 (23%)]	Loss: 9.6363	Cost: 6.08s
Train Epoch: 971 [40960/90000 (45%)]	Loss: 9.7980	Cost: 7.30s
Train Epoch: 971 [61440/90000 (68%)]	Loss: 9.7061	Cost: 5.93s
Train Epoch: 971 [81920/90000 (91%)]	Loss: 9.6403	Cost: 5.82s
Train Epoch: 971 	Average Loss: 10.3369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9745

Learning rate: 0.0001953832343178025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 972 [0/90000 (0%)]	Loss: 20.7910	Cost: 20.35s
Train Epoch: 972 [20480/90000 (23%)]	Loss: 9.6195	Cost: 6.11s
Train Epoch: 972 [40960/90000 (45%)]	Loss: 9.6410	Cost: 6.59s
Train Epoch: 972 [61440/90000 (68%)]	Loss: 9.6272	Cost: 5.86s
Train Epoch: 972 [81920/90000 (91%)]	Loss: 9.5377	Cost: 5.77s
Train Epoch: 972 	Average Loss: 10.3160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9502

Learning rate: 0.00019537379416491811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 973 [0/90000 (0%)]	Loss: 20.6681	Cost: 20.88s
Train Epoch: 973 [20480/90000 (23%)]	Loss: 9.2888	Cost: 6.32s
Train Epoch: 973 [40960/90000 (45%)]	Loss: 9.2901	Cost: 6.12s
Train Epoch: 973 [61440/90000 (68%)]	Loss: 9.2922	Cost: 5.94s
Train Epoch: 973 [81920/90000 (91%)]	Loss: 9.3949	Cost: 5.81s
Train Epoch: 973 	Average Loss: 10.1484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9417

Learning rate: 0.00019536434459901765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 974 [0/90000 (0%)]	Loss: 20.7487	Cost: 20.46s
Train Epoch: 974 [20480/90000 (23%)]	Loss: 9.2855	Cost: 6.10s
Train Epoch: 974 [40960/90000 (45%)]	Loss: 9.4248	Cost: 6.16s
Train Epoch: 974 [61440/90000 (68%)]	Loss: 9.2032	Cost: 5.89s
Train Epoch: 974 [81920/90000 (91%)]	Loss: 9.3493	Cost: 5.75s
Train Epoch: 974 	Average Loss: 10.0894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0431

Learning rate: 0.0001953548856210337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 975 [0/90000 (0%)]	Loss: 20.7087	Cost: 20.65s
Train Epoch: 975 [20480/90000 (23%)]	Loss: 9.3109	Cost: 6.15s
Train Epoch: 975 [40960/90000 (45%)]	Loss: 9.3502	Cost: 6.12s
Train Epoch: 975 [61440/90000 (68%)]	Loss: 9.1942	Cost: 5.92s
Train Epoch: 975 [81920/90000 (91%)]	Loss: 9.3323	Cost: 5.79s
Train Epoch: 975 	Average Loss: 10.0799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0022

Learning rate: 0.00019534541723189978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 976 [0/90000 (0%)]	Loss: 20.5830	Cost: 21.04s
Train Epoch: 976 [20480/90000 (23%)]	Loss: 9.2437	Cost: 6.04s
Train Epoch: 976 [40960/90000 (45%)]	Loss: 9.2823	Cost: 6.77s
Train Epoch: 976 [61440/90000 (68%)]	Loss: 9.1437	Cost: 5.89s
Train Epoch: 976 [81920/90000 (91%)]	Loss: 9.5187	Cost: 5.75s
Train Epoch: 976 	Average Loss: 10.0753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0991

Learning rate: 0.00019533593943255054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 977 [0/90000 (0%)]	Loss: 20.8870	Cost: 19.92s
Train Epoch: 977 [20480/90000 (23%)]	Loss: 9.2886	Cost: 6.06s
Train Epoch: 977 [40960/90000 (45%)]	Loss: 9.2391	Cost: 6.15s
Train Epoch: 977 [61440/90000 (68%)]	Loss: 8.9964	Cost: 5.92s
Train Epoch: 977 [81920/90000 (91%)]	Loss: 9.4872	Cost: 5.73s
Train Epoch: 977 	Average Loss: 10.1226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0908

Learning rate: 0.00019532645222392127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 978 [0/90000 (0%)]	Loss: 20.9723	Cost: 21.42s
Train Epoch: 978 [20480/90000 (23%)]	Loss: 9.3401	Cost: 5.99s
Train Epoch: 978 [40960/90000 (45%)]	Loss: 9.4914	Cost: 6.19s
Train Epoch: 978 [61440/90000 (68%)]	Loss: 9.1903	Cost: 5.93s
Train Epoch: 978 [81920/90000 (91%)]	Loss: 9.4569	Cost: 5.71s
Train Epoch: 978 	Average Loss: 10.1867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0165

Learning rate: 0.00019531695560694832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 979 [0/90000 (0%)]	Loss: 20.9156	Cost: 21.95s
Train Epoch: 979 [20480/90000 (23%)]	Loss: 9.2354	Cost: 6.17s
Train Epoch: 979 [40960/90000 (45%)]	Loss: 9.4638	Cost: 6.28s
Train Epoch: 979 [61440/90000 (68%)]	Loss: 9.2485	Cost: 5.99s
Train Epoch: 979 [81920/90000 (91%)]	Loss: 9.5036	Cost: 5.86s
Train Epoch: 979 	Average Loss: 10.1558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0718

Learning rate: 0.00019530744958256901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 980 [0/90000 (0%)]	Loss: 20.9074	Cost: 22.51s
Train Epoch: 980 [20480/90000 (23%)]	Loss: 9.4877	Cost: 6.27s
Train Epoch: 980 [40960/90000 (45%)]	Loss: 9.5158	Cost: 6.11s
Train Epoch: 980 [61440/90000 (68%)]	Loss: 9.3252	Cost: 5.88s
Train Epoch: 980 [81920/90000 (91%)]	Loss: 9.4757	Cost: 5.78s
Train Epoch: 980 	Average Loss: 10.1780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0366

Learning rate: 0.00019529793415172156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 981 [0/90000 (0%)]	Loss: 20.7853	Cost: 24.06s
Train Epoch: 981 [20480/90000 (23%)]	Loss: 9.2174	Cost: 6.15s
Train Epoch: 981 [40960/90000 (45%)]	Loss: 9.2998	Cost: 6.32s
Train Epoch: 981 [61440/90000 (68%)]	Loss: 9.0469	Cost: 5.87s
Train Epoch: 981 [81920/90000 (91%)]	Loss: 9.2670	Cost: 5.63s
Train Epoch: 981 	Average Loss: 10.0606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9635

Learning rate: 0.00019528840931534505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 982 [0/90000 (0%)]	Loss: 20.9021	Cost: 24.36s
Train Epoch: 982 [20480/90000 (23%)]	Loss: 9.2618	Cost: 6.32s
Train Epoch: 982 [40960/90000 (45%)]	Loss: 9.3350	Cost: 6.90s
Train Epoch: 982 [61440/90000 (68%)]	Loss: 9.1594	Cost: 6.04s
Train Epoch: 982 [81920/90000 (91%)]	Loss: 9.4046	Cost: 5.83s
Train Epoch: 982 	Average Loss: 10.0980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0597

Learning rate: 0.0001952788750743796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 983 [0/90000 (0%)]	Loss: 20.8630	Cost: 21.46s
Train Epoch: 983 [20480/90000 (23%)]	Loss: 9.2445	Cost: 6.58s
Train Epoch: 983 [40960/90000 (45%)]	Loss: 9.4183	Cost: 6.27s
Train Epoch: 983 [61440/90000 (68%)]	Loss: 9.1243	Cost: 5.92s
Train Epoch: 983 [81920/90000 (91%)]	Loss: 9.5285	Cost: 5.78s
Train Epoch: 983 	Average Loss: 10.0835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0991

Learning rate: 0.0001952693314297662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 984 [0/90000 (0%)]	Loss: 20.7529	Cost: 20.75s
Train Epoch: 984 [20480/90000 (23%)]	Loss: 9.3983	Cost: 6.51s
Train Epoch: 984 [40960/90000 (45%)]	Loss: 9.5515	Cost: 6.72s
Train Epoch: 984 [61440/90000 (68%)]	Loss: 9.2235	Cost: 5.95s
Train Epoch: 984 [81920/90000 (91%)]	Loss: 9.6789	Cost: 6.30s
Train Epoch: 984 	Average Loss: 10.2615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0685

Learning rate: 0.00019525977838244672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 985 [0/90000 (0%)]	Loss: 21.0622	Cost: 21.26s
Train Epoch: 985 [20480/90000 (23%)]	Loss: 9.3935	Cost: 6.21s
Train Epoch: 985 [40960/90000 (45%)]	Loss: 9.3712	Cost: 6.20s
Train Epoch: 985 [61440/90000 (68%)]	Loss: 9.1616	Cost: 5.93s
Train Epoch: 985 [81920/90000 (91%)]	Loss: 9.3024	Cost: 5.75s
Train Epoch: 985 	Average Loss: 10.0718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0983

Learning rate: 0.00019525021593336405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 986 [0/90000 (0%)]	Loss: 20.8958	Cost: 20.00s
Train Epoch: 986 [20480/90000 (23%)]	Loss: 9.0656	Cost: 6.28s
Train Epoch: 986 [40960/90000 (45%)]	Loss: 9.3166	Cost: 6.28s
Train Epoch: 986 [61440/90000 (68%)]	Loss: 9.0214	Cost: 6.10s
Train Epoch: 986 [81920/90000 (91%)]	Loss: 9.3795	Cost: 5.84s
Train Epoch: 986 	Average Loss: 10.0756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1484

Learning rate: 0.00019524064408346195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 987 [0/90000 (0%)]	Loss: 20.8801	Cost: 20.76s
Train Epoch: 987 [20480/90000 (23%)]	Loss: 9.2138	Cost: 6.04s
Train Epoch: 987 [40960/90000 (45%)]	Loss: 9.2330	Cost: 6.48s
Train Epoch: 987 [61440/90000 (68%)]	Loss: 9.1061	Cost: 5.92s
Train Epoch: 987 [81920/90000 (91%)]	Loss: 9.2672	Cost: 6.38s
Train Epoch: 987 	Average Loss: 10.0086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1266

Learning rate: 0.00019523106283368514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 988 [0/90000 (0%)]	Loss: 20.7038	Cost: 19.95s
Train Epoch: 988 [20480/90000 (23%)]	Loss: 9.2312	Cost: 6.06s
Train Epoch: 988 [40960/90000 (45%)]	Loss: 9.2378	Cost: 6.33s
Train Epoch: 988 [61440/90000 (68%)]	Loss: 9.0868	Cost: 5.99s
Train Epoch: 988 [81920/90000 (91%)]	Loss: 9.3991	Cost: 5.89s
Train Epoch: 988 	Average Loss: 10.0333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1331

Learning rate: 0.00019522147218497925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 989 [0/90000 (0%)]	Loss: 20.7123	Cost: 20.09s
Train Epoch: 989 [20480/90000 (23%)]	Loss: 9.2074	Cost: 6.13s
Train Epoch: 989 [40960/90000 (45%)]	Loss: 9.3238	Cost: 6.14s
Train Epoch: 989 [61440/90000 (68%)]	Loss: 9.2430	Cost: 5.97s
Train Epoch: 989 [81920/90000 (91%)]	Loss: 9.4824	Cost: 6.16s
Train Epoch: 989 	Average Loss: 10.0967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1118

Learning rate: 0.0001952118721382908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 990 [0/90000 (0%)]	Loss: 21.0768	Cost: 20.91s
Train Epoch: 990 [20480/90000 (23%)]	Loss: 9.2158	Cost: 6.08s
Train Epoch: 990 [40960/90000 (45%)]	Loss: 9.0776	Cost: 6.20s
Train Epoch: 990 [61440/90000 (68%)]	Loss: 8.8802	Cost: 5.89s
Train Epoch: 990 [81920/90000 (91%)]	Loss: 9.1973	Cost: 6.04s
Train Epoch: 990 	Average Loss: 9.9894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0472

Learning rate: 0.0001952022626945673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 991 [0/90000 (0%)]	Loss: 20.9306	Cost: 20.60s
Train Epoch: 991 [20480/90000 (23%)]	Loss: 9.1683	Cost: 6.04s
Train Epoch: 991 [40960/90000 (45%)]	Loss: 9.2444	Cost: 6.14s
Train Epoch: 991 [61440/90000 (68%)]	Loss: 9.1694	Cost: 6.00s
Train Epoch: 991 [81920/90000 (91%)]	Loss: 9.4353	Cost: 5.88s
Train Epoch: 991 	Average Loss: 10.0494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1588

Learning rate: 0.00019519264385475717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 992 [0/90000 (0%)]	Loss: 21.0051	Cost: 20.24s
Train Epoch: 992 [20480/90000 (23%)]	Loss: 9.3687	Cost: 6.16s
Train Epoch: 992 [40960/90000 (45%)]	Loss: 9.3284	Cost: 6.05s
Train Epoch: 992 [61440/90000 (68%)]	Loss: 9.1088	Cost: 5.95s
Train Epoch: 992 [81920/90000 (91%)]	Loss: 9.3737	Cost: 5.77s
Train Epoch: 992 	Average Loss: 9.9823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1493

Learning rate: 0.00019518301561980976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 993 [0/90000 (0%)]	Loss: 21.0685	Cost: 20.86s
Train Epoch: 993 [20480/90000 (23%)]	Loss: 9.2521	Cost: 6.07s
Train Epoch: 993 [40960/90000 (45%)]	Loss: 9.1050	Cost: 6.12s
Train Epoch: 993 [61440/90000 (68%)]	Loss: 9.0213	Cost: 6.05s
Train Epoch: 993 [81920/90000 (91%)]	Loss: 9.3192	Cost: 5.84s
Train Epoch: 993 	Average Loss: 9.9097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2077

Learning rate: 0.00019517337799067536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 994 [0/90000 (0%)]	Loss: 20.8788	Cost: 20.43s
Train Epoch: 994 [20480/90000 (23%)]	Loss: 9.1391	Cost: 6.08s
Train Epoch: 994 [40960/90000 (45%)]	Loss: 9.3627	Cost: 6.30s
Train Epoch: 994 [61440/90000 (68%)]	Loss: 9.3811	Cost: 5.70s
Train Epoch: 994 [81920/90000 (91%)]	Loss: 9.4433	Cost: 5.70s
Train Epoch: 994 	Average Loss: 10.0043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1859

Learning rate: 0.00019516373096830513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 995 [0/90000 (0%)]	Loss: 20.9385	Cost: 20.72s
Train Epoch: 995 [20480/90000 (23%)]	Loss: 9.2017	Cost: 6.24s
Train Epoch: 995 [40960/90000 (45%)]	Loss: 9.2318	Cost: 6.09s
Train Epoch: 995 [61440/90000 (68%)]	Loss: 9.1344	Cost: 5.88s
Train Epoch: 995 [81920/90000 (91%)]	Loss: 9.3505	Cost: 5.79s
Train Epoch: 995 	Average Loss: 9.9812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1379

Learning rate: 0.00019515407455365116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 996 [0/90000 (0%)]	Loss: 20.8391	Cost: 20.25s
Train Epoch: 996 [20480/90000 (23%)]	Loss: 9.0783	Cost: 6.16s
Train Epoch: 996 [40960/90000 (45%)]	Loss: 9.0480	Cost: 6.17s
Train Epoch: 996 [61440/90000 (68%)]	Loss: 9.0929	Cost: 5.91s
Train Epoch: 996 [81920/90000 (91%)]	Loss: 9.0140	Cost: 5.75s
Train Epoch: 996 	Average Loss: 9.9251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1617

Learning rate: 0.00019514440874766656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 997 [0/90000 (0%)]	Loss: 20.6132	Cost: 20.32s
Train Epoch: 997 [20480/90000 (23%)]	Loss: 9.1575	Cost: 6.09s
Train Epoch: 997 [40960/90000 (45%)]	Loss: 9.2789	Cost: 6.16s
Train Epoch: 997 [61440/90000 (68%)]	Loss: 9.2507	Cost: 5.88s
Train Epoch: 997 [81920/90000 (91%)]	Loss: 9.3029	Cost: 5.72s
Train Epoch: 997 	Average Loss: 9.9763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1589

Learning rate: 0.00019513473355130528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 998 [0/90000 (0%)]	Loss: 20.7954	Cost: 21.12s
Train Epoch: 998 [20480/90000 (23%)]	Loss: 8.8241	Cost: 6.02s
Train Epoch: 998 [40960/90000 (45%)]	Loss: 9.0370	Cost: 6.77s
Train Epoch: 998 [61440/90000 (68%)]	Loss: 9.1003	Cost: 5.85s
Train Epoch: 998 [81920/90000 (91%)]	Loss: 9.3545	Cost: 6.07s
Train Epoch: 998 	Average Loss: 9.9311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1203

Learning rate: 0.00019512504896552222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 999 [0/90000 (0%)]	Loss: 20.8149	Cost: 22.38s
Train Epoch: 999 [20480/90000 (23%)]	Loss: 9.0527	Cost: 6.11s
Train Epoch: 999 [40960/90000 (45%)]	Loss: 9.1324	Cost: 6.42s
Train Epoch: 999 [61440/90000 (68%)]	Loss: 9.1721	Cost: 5.92s
Train Epoch: 999 [81920/90000 (91%)]	Loss: 9.1131	Cost: 5.98s
Train Epoch: 999 	Average Loss: 9.9072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1882

Learning rate: 0.00019511535499127324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1000 [0/90000 (0%)]	Loss: 21.1164	Cost: 21.52s
Train Epoch: 1000 [20480/90000 (23%)]	Loss: 9.1054	Cost: 6.09s
Train Epoch: 1000 [40960/90000 (45%)]	Loss: 9.4664	Cost: 6.50s
Train Epoch: 1000 [61440/90000 (68%)]	Loss: 9.2404	Cost: 5.91s
Train Epoch: 1000 [81920/90000 (91%)]	Loss: 9.4293	Cost: 5.79s
Train Epoch: 1000 	Average Loss: 10.0737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1725

Learning rate: 0.00019510565162951505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1001 [0/90000 (0%)]	Loss: 21.0071	Cost: 23.33s
Train Epoch: 1001 [20480/90000 (23%)]	Loss: 9.2579	Cost: 6.00s
Train Epoch: 1001 [40960/90000 (45%)]	Loss: 9.1328	Cost: 6.28s
Train Epoch: 1001 [61440/90000 (68%)]	Loss: 9.1315	Cost: 5.99s
Train Epoch: 1001 [81920/90000 (91%)]	Loss: 9.2564	Cost: 5.79s
Train Epoch: 1001 	Average Loss: 10.0574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1292

Learning rate: 0.00019509593888120534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1002 [0/90000 (0%)]	Loss: 20.8481	Cost: 22.73s
Train Epoch: 1002 [20480/90000 (23%)]	Loss: 9.2583	Cost: 6.06s
Train Epoch: 1002 [40960/90000 (45%)]	Loss: 9.1709	Cost: 6.12s
Train Epoch: 1002 [61440/90000 (68%)]	Loss: 8.8847	Cost: 5.89s
Train Epoch: 1002 [81920/90000 (91%)]	Loss: 9.1137	Cost: 6.09s
Train Epoch: 1002 	Average Loss: 9.9422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1492

Learning rate: 0.00019508621674730277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1003 [0/90000 (0%)]	Loss: 21.1255	Cost: 24.59s
Train Epoch: 1003 [20480/90000 (23%)]	Loss: 9.1335	Cost: 6.13s
Train Epoch: 1003 [40960/90000 (45%)]	Loss: 9.0663	Cost: 6.04s
Train Epoch: 1003 [61440/90000 (68%)]	Loss: 8.9640	Cost: 5.87s
Train Epoch: 1003 [81920/90000 (91%)]	Loss: 9.1327	Cost: 5.76s
Train Epoch: 1003 	Average Loss: 9.8617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1776

Learning rate: 0.00019507648522876684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1004 [0/90000 (0%)]	Loss: 21.0180	Cost: 24.83s
Train Epoch: 1004 [20480/90000 (23%)]	Loss: 8.8665	Cost: 6.15s
Train Epoch: 1004 [40960/90000 (45%)]	Loss: 9.2060	Cost: 6.23s
Train Epoch: 1004 [61440/90000 (68%)]	Loss: 8.7918	Cost: 6.04s
Train Epoch: 1004 [81920/90000 (91%)]	Loss: 9.0525	Cost: 5.78s
Train Epoch: 1004 	Average Loss: 9.8075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1860

Learning rate: 0.00019506674432655802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1005 [0/90000 (0%)]	Loss: 20.8651	Cost: 23.29s
Train Epoch: 1005 [20480/90000 (23%)]	Loss: 8.9548	Cost: 6.59s
Train Epoch: 1005 [40960/90000 (45%)]	Loss: 9.1004	Cost: 6.20s
Train Epoch: 1005 [61440/90000 (68%)]	Loss: 8.7401	Cost: 5.92s
Train Epoch: 1005 [81920/90000 (91%)]	Loss: 8.9869	Cost: 5.75s
Train Epoch: 1005 	Average Loss: 9.7999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2490

Learning rate: 0.0001950569940416377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1006 [0/90000 (0%)]	Loss: 21.1649	Cost: 23.16s
Train Epoch: 1006 [20480/90000 (23%)]	Loss: 8.8510	Cost: 6.41s
Train Epoch: 1006 [40960/90000 (45%)]	Loss: 8.9211	Cost: 6.40s
Train Epoch: 1006 [61440/90000 (68%)]	Loss: 8.7917	Cost: 5.93s
Train Epoch: 1006 [81920/90000 (91%)]	Loss: 9.0079	Cost: 6.29s
Train Epoch: 1006 	Average Loss: 9.8071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2405

Learning rate: 0.00019504723437496817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1007 [0/90000 (0%)]	Loss: 21.0974	Cost: 22.76s
Train Epoch: 1007 [20480/90000 (23%)]	Loss: 9.2101	Cost: 6.98s
Train Epoch: 1007 [40960/90000 (45%)]	Loss: 9.1785	Cost: 6.66s
Train Epoch: 1007 [61440/90000 (68%)]	Loss: 9.1043	Cost: 5.89s
Train Epoch: 1007 [81920/90000 (91%)]	Loss: 9.3344	Cost: 5.74s
Train Epoch: 1007 	Average Loss: 9.9692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3647

Learning rate: 0.0001950374653275127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1008 [0/90000 (0%)]	Loss: 20.9070	Cost: 20.37s
Train Epoch: 1008 [20480/90000 (23%)]	Loss: 8.9506	Cost: 6.77s
Train Epoch: 1008 [40960/90000 (45%)]	Loss: 9.1301	Cost: 6.72s
Train Epoch: 1008 [61440/90000 (68%)]	Loss: 8.8407	Cost: 6.01s
Train Epoch: 1008 [81920/90000 (91%)]	Loss: 8.9479	Cost: 6.31s
Train Epoch: 1008 	Average Loss: 9.8107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2783

Learning rate: 0.00019502768690023544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1009 [0/90000 (0%)]	Loss: 20.8946	Cost: 21.89s
Train Epoch: 1009 [20480/90000 (23%)]	Loss: 8.9836	Cost: 6.22s
Train Epoch: 1009 [40960/90000 (45%)]	Loss: 9.0452	Cost: 6.34s
Train Epoch: 1009 [61440/90000 (68%)]	Loss: 8.8740	Cost: 5.95s
Train Epoch: 1009 [81920/90000 (91%)]	Loss: 9.1460	Cost: 6.22s
Train Epoch: 1009 	Average Loss: 9.8054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2641

Learning rate: 0.0001950178990941015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1010 [0/90000 (0%)]	Loss: 21.1267	Cost: 21.13s
Train Epoch: 1010 [20480/90000 (23%)]	Loss: 9.0354	Cost: 6.51s
Train Epoch: 1010 [40960/90000 (45%)]	Loss: 8.9115	Cost: 6.25s
Train Epoch: 1010 [61440/90000 (68%)]	Loss: 8.8806	Cost: 5.99s
Train Epoch: 1010 [81920/90000 (91%)]	Loss: 8.9526	Cost: 5.75s
Train Epoch: 1010 	Average Loss: 9.7906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2552

Learning rate: 0.00019500810191007685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1011 [0/90000 (0%)]	Loss: 21.0969	Cost: 20.22s
Train Epoch: 1011 [20480/90000 (23%)]	Loss: 9.0765	Cost: 6.81s
Train Epoch: 1011 [40960/90000 (45%)]	Loss: 9.1477	Cost: 6.11s
Train Epoch: 1011 [61440/90000 (68%)]	Loss: 9.1110	Cost: 6.03s
Train Epoch: 1011 [81920/90000 (91%)]	Loss: 9.2580	Cost: 5.78s
Train Epoch: 1011 	Average Loss: 9.9213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2295

Learning rate: 0.0001949982953491285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1012 [0/90000 (0%)]	Loss: 21.1777	Cost: 20.49s
Train Epoch: 1012 [20480/90000 (23%)]	Loss: 8.9942	Cost: 6.23s
Train Epoch: 1012 [40960/90000 (45%)]	Loss: 9.2698	Cost: 6.13s
Train Epoch: 1012 [61440/90000 (68%)]	Loss: 8.9406	Cost: 6.00s
Train Epoch: 1012 [81920/90000 (91%)]	Loss: 8.9277	Cost: 5.88s
Train Epoch: 1012 	Average Loss: 9.9014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2780

Learning rate: 0.0001949884794122243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1013 [0/90000 (0%)]	Loss: 21.1266	Cost: 21.11s
Train Epoch: 1013 [20480/90000 (23%)]	Loss: 8.9056	Cost: 6.02s
Train Epoch: 1013 [40960/90000 (45%)]	Loss: 9.0296	Cost: 6.15s
Train Epoch: 1013 [61440/90000 (68%)]	Loss: 8.9794	Cost: 6.05s
Train Epoch: 1013 [81920/90000 (91%)]	Loss: 8.9518	Cost: 5.93s
Train Epoch: 1013 	Average Loss: 9.8677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3207

Learning rate: 0.000194978654100333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1014 [0/90000 (0%)]	Loss: 21.0032	Cost: 21.18s
Train Epoch: 1014 [20480/90000 (23%)]	Loss: 8.7587	Cost: 6.04s
Train Epoch: 1014 [40960/90000 (45%)]	Loss: 9.0587	Cost: 6.08s
Train Epoch: 1014 [61440/90000 (68%)]	Loss: 9.0418	Cost: 6.09s
Train Epoch: 1014 [81920/90000 (91%)]	Loss: 9.1759	Cost: 5.85s
Train Epoch: 1014 	Average Loss: 9.8864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2750

Learning rate: 0.00019496881941442437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1015 [0/90000 (0%)]	Loss: 20.9760	Cost: 20.53s
Train Epoch: 1015 [20480/90000 (23%)]	Loss: 9.2818	Cost: 6.02s
Train Epoch: 1015 [40960/90000 (45%)]	Loss: 9.2770	Cost: 6.30s
Train Epoch: 1015 [61440/90000 (68%)]	Loss: 9.1769	Cost: 5.99s
Train Epoch: 1015 [81920/90000 (91%)]	Loss: 9.0518	Cost: 5.93s
Train Epoch: 1015 	Average Loss: 10.0313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2995

Learning rate: 0.00019495897535546904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1016 [0/90000 (0%)]	Loss: 20.9309	Cost: 21.05s
Train Epoch: 1016 [20480/90000 (23%)]	Loss: 8.9149	Cost: 6.14s
Train Epoch: 1016 [40960/90000 (45%)]	Loss: 9.0706	Cost: 6.17s
Train Epoch: 1016 [61440/90000 (68%)]	Loss: 8.8667	Cost: 5.88s
Train Epoch: 1016 [81920/90000 (91%)]	Loss: 8.8299	Cost: 5.98s
Train Epoch: 1016 	Average Loss: 9.7808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2713

Learning rate: 0.00019494912192443854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1017 [0/90000 (0%)]	Loss: 21.0437	Cost: 19.86s
Train Epoch: 1017 [20480/90000 (23%)]	Loss: 9.0052	Cost: 6.08s
Train Epoch: 1017 [40960/90000 (45%)]	Loss: 8.8214	Cost: 6.35s
Train Epoch: 1017 [61440/90000 (68%)]	Loss: 8.6213	Cost: 5.86s
Train Epoch: 1017 [81920/90000 (91%)]	Loss: 9.0663	Cost: 6.11s
Train Epoch: 1017 	Average Loss: 9.7240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2227

Learning rate: 0.00019493925912230544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1018 [0/90000 (0%)]	Loss: 21.0727	Cost: 21.27s
Train Epoch: 1018 [20480/90000 (23%)]	Loss: 8.9760	Cost: 6.19s
Train Epoch: 1018 [40960/90000 (45%)]	Loss: 9.0593	Cost: 6.42s
Train Epoch: 1018 [61440/90000 (68%)]	Loss: 9.0267	Cost: 5.87s
Train Epoch: 1018 [81920/90000 (91%)]	Loss: 8.9532	Cost: 5.74s
Train Epoch: 1018 	Average Loss: 9.8392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2818

Learning rate: 0.00019492938695004312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1019 [0/90000 (0%)]	Loss: 20.9070	Cost: 21.14s
Train Epoch: 1019 [20480/90000 (23%)]	Loss: 8.9142	Cost: 6.02s
Train Epoch: 1019 [40960/90000 (45%)]	Loss: 8.9259	Cost: 6.21s
Train Epoch: 1019 [61440/90000 (68%)]	Loss: 8.6633	Cost: 5.91s
Train Epoch: 1019 [81920/90000 (91%)]	Loss: 9.0747	Cost: 5.82s
Train Epoch: 1019 	Average Loss: 9.7401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2997

Learning rate: 0.00019491950540862592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1020 [0/90000 (0%)]	Loss: 21.1285	Cost: 21.15s
Train Epoch: 1020 [20480/90000 (23%)]	Loss: 8.9110	Cost: 6.18s
Train Epoch: 1020 [40960/90000 (45%)]	Loss: 8.8527	Cost: 6.17s
Train Epoch: 1020 [61440/90000 (68%)]	Loss: 8.6420	Cost: 5.88s
Train Epoch: 1020 [81920/90000 (91%)]	Loss: 8.8308	Cost: 5.75s
Train Epoch: 1020 	Average Loss: 9.6567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3097

Learning rate: 0.0001949096144990291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1021 [0/90000 (0%)]	Loss: 21.4618	Cost: 20.06s
Train Epoch: 1021 [20480/90000 (23%)]	Loss: 8.8474	Cost: 6.20s
Train Epoch: 1021 [40960/90000 (45%)]	Loss: 8.7277	Cost: 6.18s
Train Epoch: 1021 [61440/90000 (68%)]	Loss: 8.8325	Cost: 5.95s
Train Epoch: 1021 [81920/90000 (91%)]	Loss: 8.6845	Cost: 5.78s
Train Epoch: 1021 	Average Loss: 9.6594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3563

Learning rate: 0.0001948997142222289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1022 [0/90000 (0%)]	Loss: 20.9942	Cost: 20.95s
Train Epoch: 1022 [20480/90000 (23%)]	Loss: 8.8485	Cost: 6.18s
Train Epoch: 1022 [40960/90000 (45%)]	Loss: 8.9517	Cost: 6.31s
Train Epoch: 1022 [61440/90000 (68%)]	Loss: 8.7437	Cost: 5.87s
Train Epoch: 1022 [81920/90000 (91%)]	Loss: 8.9270	Cost: 5.75s
Train Epoch: 1022 	Average Loss: 9.6526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3880

Learning rate: 0.00019488980457920237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1023 [0/90000 (0%)]	Loss: 21.1231	Cost: 21.06s
Train Epoch: 1023 [20480/90000 (23%)]	Loss: 8.9419	Cost: 6.16s
Train Epoch: 1023 [40960/90000 (45%)]	Loss: 8.6778	Cost: 6.33s
Train Epoch: 1023 [61440/90000 (68%)]	Loss: 8.6469	Cost: 5.87s
Train Epoch: 1023 [81920/90000 (91%)]	Loss: 8.8580	Cost: 5.73s
Train Epoch: 1023 	Average Loss: 9.6311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3843

Learning rate: 0.00019487988557092759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1024 [0/90000 (0%)]	Loss: 21.2612	Cost: 20.82s
Train Epoch: 1024 [20480/90000 (23%)]	Loss: 8.8714	Cost: 6.12s
Train Epoch: 1024 [40960/90000 (45%)]	Loss: 8.8413	Cost: 6.28s
Train Epoch: 1024 [61440/90000 (68%)]	Loss: 8.7431	Cost: 6.00s
Train Epoch: 1024 [81920/90000 (91%)]	Loss: 8.7652	Cost: 5.68s
Train Epoch: 1024 	Average Loss: 9.6023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3979

Learning rate: 0.00019486995719838354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1025 [0/90000 (0%)]	Loss: 21.3976	Cost: 21.29s
Train Epoch: 1025 [20480/90000 (23%)]	Loss: 8.8729	Cost: 6.11s
Train Epoch: 1025 [40960/90000 (45%)]	Loss: 8.8981	Cost: 6.09s
Train Epoch: 1025 [61440/90000 (68%)]	Loss: 8.8507	Cost: 5.95s
Train Epoch: 1025 [81920/90000 (91%)]	Loss: 8.9752	Cost: 5.75s
Train Epoch: 1025 	Average Loss: 9.7839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3974

Learning rate: 0.00019486001946255008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1026 [0/90000 (0%)]	Loss: 21.1616	Cost: 22.75s
Train Epoch: 1026 [20480/90000 (23%)]	Loss: 8.7302	Cost: 6.06s
Train Epoch: 1026 [40960/90000 (45%)]	Loss: 8.9044	Cost: 6.39s
Train Epoch: 1026 [61440/90000 (68%)]	Loss: 8.7847	Cost: 6.10s
Train Epoch: 1026 [81920/90000 (91%)]	Loss: 8.9369	Cost: 5.81s
Train Epoch: 1026 	Average Loss: 9.7159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4530

Learning rate: 0.00019485007236440808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1027 [0/90000 (0%)]	Loss: 21.3462	Cost: 21.72s
Train Epoch: 1027 [20480/90000 (23%)]	Loss: 9.2101	Cost: 6.09s
Train Epoch: 1027 [40960/90000 (45%)]	Loss: 9.0072	Cost: 6.08s
Train Epoch: 1027 [61440/90000 (68%)]	Loss: 8.7861	Cost: 5.85s
Train Epoch: 1027 [81920/90000 (91%)]	Loss: 9.0192	Cost: 5.79s
Train Epoch: 1027 	Average Loss: 9.8133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3763

Learning rate: 0.00019484011590493924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1028 [0/90000 (0%)]	Loss: 21.2738	Cost: 24.93s
Train Epoch: 1028 [20480/90000 (23%)]	Loss: 8.8982	Cost: 6.08s
Train Epoch: 1028 [40960/90000 (45%)]	Loss: 9.0990	Cost: 6.10s
Train Epoch: 1028 [61440/90000 (68%)]	Loss: 8.7877	Cost: 6.01s
Train Epoch: 1028 [81920/90000 (91%)]	Loss: 8.8512	Cost: 5.82s
Train Epoch: 1028 	Average Loss: 9.6959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4390

Learning rate: 0.0001948301500851262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1029 [0/90000 (0%)]	Loss: 21.1403	Cost: 22.13s
Train Epoch: 1029 [20480/90000 (23%)]	Loss: 8.9335	Cost: 5.93s
Train Epoch: 1029 [40960/90000 (45%)]	Loss: 8.9175	Cost: 6.67s
Train Epoch: 1029 [61440/90000 (68%)]	Loss: 8.8086	Cost: 5.88s
Train Epoch: 1029 [81920/90000 (91%)]	Loss: 8.9306	Cost: 5.91s
Train Epoch: 1029 	Average Loss: 9.6690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3802

Learning rate: 0.00019482017490595255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1030 [0/90000 (0%)]	Loss: 21.0981	Cost: 23.53s
Train Epoch: 1030 [20480/90000 (23%)]	Loss: 8.9455	Cost: 5.98s
Train Epoch: 1030 [40960/90000 (45%)]	Loss: 8.8463	Cost: 6.41s
Train Epoch: 1030 [61440/90000 (68%)]	Loss: 8.6781	Cost: 5.90s
Train Epoch: 1030 [81920/90000 (91%)]	Loss: 8.8011	Cost: 5.92s
Train Epoch: 1030 	Average Loss: 9.6316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4126

Learning rate: 0.00019481019036840283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1031 [0/90000 (0%)]	Loss: 21.2353	Cost: 20.35s
Train Epoch: 1031 [20480/90000 (23%)]	Loss: 8.6239	Cost: 6.11s
Train Epoch: 1031 [40960/90000 (45%)]	Loss: 8.8883	Cost: 6.14s
Train Epoch: 1031 [61440/90000 (68%)]	Loss: 8.7612	Cost: 5.96s
Train Epoch: 1031 [81920/90000 (91%)]	Loss: 8.8984	Cost: 5.83s
Train Epoch: 1031 	Average Loss: 9.6491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4277

Learning rate: 0.0001948001964734625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1032 [0/90000 (0%)]	Loss: 21.1821	Cost: 24.29s
Train Epoch: 1032 [20480/90000 (23%)]	Loss: 8.8753	Cost: 6.08s
Train Epoch: 1032 [40960/90000 (45%)]	Loss: 9.2215	Cost: 6.07s
Train Epoch: 1032 [61440/90000 (68%)]	Loss: 8.8276	Cost: 5.89s
Train Epoch: 1032 [81920/90000 (91%)]	Loss: 9.0546	Cost: 5.83s
Train Epoch: 1032 	Average Loss: 9.8068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4241

Learning rate: 0.00019479019322211785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1033 [0/90000 (0%)]	Loss: 21.1547	Cost: 23.76s
Train Epoch: 1033 [20480/90000 (23%)]	Loss: 8.8774	Cost: 6.04s
Train Epoch: 1033 [40960/90000 (45%)]	Loss: 8.9187	Cost: 6.10s
Train Epoch: 1033 [61440/90000 (68%)]	Loss: 8.7763	Cost: 5.96s
Train Epoch: 1033 [81920/90000 (91%)]	Loss: 9.1151	Cost: 5.81s
Train Epoch: 1033 	Average Loss: 9.7316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3997

Learning rate: 0.00019478018061535622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1034 [0/90000 (0%)]	Loss: 21.1600	Cost: 24.44s
Train Epoch: 1034 [20480/90000 (23%)]	Loss: 8.8612	Cost: 6.30s
Train Epoch: 1034 [40960/90000 (45%)]	Loss: 8.9958	Cost: 6.12s
Train Epoch: 1034 [61440/90000 (68%)]	Loss: 8.8092	Cost: 6.00s
Train Epoch: 1034 [81920/90000 (91%)]	Loss: 8.9999	Cost: 5.98s
Train Epoch: 1034 	Average Loss: 9.8150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4683

Learning rate: 0.0001947701586541658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1035 [0/90000 (0%)]	Loss: 20.8756	Cost: 23.00s
Train Epoch: 1035 [20480/90000 (23%)]	Loss: 8.7032	Cost: 6.15s
Train Epoch: 1035 [40960/90000 (45%)]	Loss: 8.8241	Cost: 6.53s
Train Epoch: 1035 [61440/90000 (68%)]	Loss: 8.7641	Cost: 5.88s
Train Epoch: 1035 [81920/90000 (91%)]	Loss: 8.9740	Cost: 5.70s
Train Epoch: 1035 	Average Loss: 9.7077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4334

Learning rate: 0.00019476012733953566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1036 [0/90000 (0%)]	Loss: 21.1093	Cost: 21.99s
Train Epoch: 1036 [20480/90000 (23%)]	Loss: 8.8397	Cost: 6.69s
Train Epoch: 1036 [40960/90000 (45%)]	Loss: 8.9489	Cost: 6.04s
Train Epoch: 1036 [61440/90000 (68%)]	Loss: 8.8474	Cost: 5.95s
Train Epoch: 1036 [81920/90000 (91%)]	Loss: 8.8751	Cost: 5.71s
Train Epoch: 1036 	Average Loss: 9.6198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4490

Learning rate: 0.0001947500866724559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1037 [0/90000 (0%)]	Loss: 20.9321	Cost: 20.30s
Train Epoch: 1037 [20480/90000 (23%)]	Loss: 8.8181	Cost: 6.21s
Train Epoch: 1037 [40960/90000 (45%)]	Loss: 8.8206	Cost: 6.63s
Train Epoch: 1037 [61440/90000 (68%)]	Loss: 8.6910	Cost: 6.09s
Train Epoch: 1037 [81920/90000 (91%)]	Loss: 8.8325	Cost: 5.82s
Train Epoch: 1037 	Average Loss: 9.6129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3936

Learning rate: 0.00019474003665391753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1038 [0/90000 (0%)]	Loss: 21.1610	Cost: 19.56s
Train Epoch: 1038 [20480/90000 (23%)]	Loss: 8.7565	Cost: 6.23s
Train Epoch: 1038 [40960/90000 (45%)]	Loss: 8.9806	Cost: 6.56s
Train Epoch: 1038 [61440/90000 (68%)]	Loss: 8.6124	Cost: 6.03s
Train Epoch: 1038 [81920/90000 (91%)]	Loss: 8.7901	Cost: 5.82s
Train Epoch: 1038 	Average Loss: 9.5808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3633

Learning rate: 0.0001947299772849124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1039 [0/90000 (0%)]	Loss: 21.1377	Cost: 19.60s
Train Epoch: 1039 [20480/90000 (23%)]	Loss: 8.7251	Cost: 6.07s
Train Epoch: 1039 [40960/90000 (45%)]	Loss: 8.8128	Cost: 6.35s
Train Epoch: 1039 [61440/90000 (68%)]	Loss: 8.6215	Cost: 6.05s
Train Epoch: 1039 [81920/90000 (91%)]	Loss: 8.8430	Cost: 6.26s
Train Epoch: 1039 	Average Loss: 9.4886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4168

Learning rate: 0.00019471990856643334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1040 [0/90000 (0%)]	Loss: 21.1272	Cost: 20.60s
Train Epoch: 1040 [20480/90000 (23%)]	Loss: 8.5599	Cost: 5.99s
Train Epoch: 1040 [40960/90000 (45%)]	Loss: 8.6303	Cost: 7.25s
Train Epoch: 1040 [61440/90000 (68%)]	Loss: 8.4869	Cost: 5.90s
Train Epoch: 1040 [81920/90000 (91%)]	Loss: 8.6983	Cost: 6.07s
Train Epoch: 1040 	Average Loss: 9.5097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5274

Learning rate: 0.0001947098304994741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1041 [0/90000 (0%)]	Loss: 21.2284	Cost: 20.23s
Train Epoch: 1041 [20480/90000 (23%)]	Loss: 8.6472	Cost: 6.05s
Train Epoch: 1041 [40960/90000 (45%)]	Loss: 8.5312	Cost: 6.28s
Train Epoch: 1041 [61440/90000 (68%)]	Loss: 8.2690	Cost: 5.87s
Train Epoch: 1041 [81920/90000 (91%)]	Loss: 8.6261	Cost: 5.91s
Train Epoch: 1041 	Average Loss: 9.3997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4360

Learning rate: 0.0001946997430850293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1042 [0/90000 (0%)]	Loss: 21.2755	Cost: 21.37s
Train Epoch: 1042 [20480/90000 (23%)]	Loss: 8.4888	Cost: 6.14s
Train Epoch: 1042 [40960/90000 (45%)]	Loss: 8.5488	Cost: 6.16s
Train Epoch: 1042 [61440/90000 (68%)]	Loss: 8.2585	Cost: 5.89s
Train Epoch: 1042 [81920/90000 (91%)]	Loss: 8.6955	Cost: 5.83s
Train Epoch: 1042 	Average Loss: 9.3998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4750

Learning rate: 0.0001946896463240946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1043 [0/90000 (0%)]	Loss: 21.2282	Cost: 21.03s
Train Epoch: 1043 [20480/90000 (23%)]	Loss: 8.5472	Cost: 5.99s
Train Epoch: 1043 [40960/90000 (45%)]	Loss: 8.7308	Cost: 6.00s
Train Epoch: 1043 [61440/90000 (68%)]	Loss: 8.5264	Cost: 5.88s
Train Epoch: 1043 [81920/90000 (91%)]	Loss: 8.7028	Cost: 5.73s
Train Epoch: 1043 	Average Loss: 9.4168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3946

Learning rate: 0.00019467954021766648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1044 [0/90000 (0%)]	Loss: 21.2093	Cost: 19.95s
Train Epoch: 1044 [20480/90000 (23%)]	Loss: 8.5665	Cost: 6.17s
Train Epoch: 1044 [40960/90000 (45%)]	Loss: 8.7610	Cost: 6.07s
Train Epoch: 1044 [61440/90000 (68%)]	Loss: 8.5655	Cost: 5.98s
Train Epoch: 1044 [81920/90000 (91%)]	Loss: 8.7762	Cost: 5.76s
Train Epoch: 1044 	Average Loss: 9.5212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6037

Learning rate: 0.00019466942476674236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1045 [0/90000 (0%)]	Loss: 21.0021	Cost: 21.77s
Train Epoch: 1045 [20480/90000 (23%)]	Loss: 8.6107	Cost: 6.01s
Train Epoch: 1045 [40960/90000 (45%)]	Loss: 8.8145	Cost: 6.22s
Train Epoch: 1045 [61440/90000 (68%)]	Loss: 8.4183	Cost: 5.88s
Train Epoch: 1045 [81920/90000 (91%)]	Loss: 8.5736	Cost: 5.79s
Train Epoch: 1045 	Average Loss: 9.4624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5426

Learning rate: 0.00019465929997232058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1046 [0/90000 (0%)]	Loss: 21.3972	Cost: 22.04s
Train Epoch: 1046 [20480/90000 (23%)]	Loss: 8.2444	Cost: 6.07s
Train Epoch: 1046 [40960/90000 (45%)]	Loss: 8.4818	Cost: 6.14s
Train Epoch: 1046 [61440/90000 (68%)]	Loss: 8.4054	Cost: 5.87s
Train Epoch: 1046 [81920/90000 (91%)]	Loss: 8.7823	Cost: 5.85s
Train Epoch: 1046 	Average Loss: 9.3691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4991

Learning rate: 0.00019464916583540045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1047 [0/90000 (0%)]	Loss: 21.3211	Cost: 21.21s
Train Epoch: 1047 [20480/90000 (23%)]	Loss: 8.5347	Cost: 6.02s
Train Epoch: 1047 [40960/90000 (45%)]	Loss: 8.5109	Cost: 6.24s
Train Epoch: 1047 [61440/90000 (68%)]	Loss: 8.4103	Cost: 5.91s
Train Epoch: 1047 [81920/90000 (91%)]	Loss: 8.5933	Cost: 5.73s
Train Epoch: 1047 	Average Loss: 9.4241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6169

Learning rate: 0.00019463902235698218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1048 [0/90000 (0%)]	Loss: 21.2890	Cost: 22.46s
Train Epoch: 1048 [20480/90000 (23%)]	Loss: 8.3996	Cost: 6.05s
Train Epoch: 1048 [40960/90000 (45%)]	Loss: 8.6245	Cost: 6.27s
Train Epoch: 1048 [61440/90000 (68%)]	Loss: 8.3972	Cost: 6.22s
Train Epoch: 1048 [81920/90000 (91%)]	Loss: 8.6515	Cost: 5.79s
Train Epoch: 1048 	Average Loss: 9.4114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5354

Learning rate: 0.00019462886953806687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1049 [0/90000 (0%)]	Loss: 21.2269	Cost: 21.79s
Train Epoch: 1049 [20480/90000 (23%)]	Loss: 8.4524	Cost: 6.17s
Train Epoch: 1049 [40960/90000 (45%)]	Loss: 8.4523	Cost: 6.23s
Train Epoch: 1049 [61440/90000 (68%)]	Loss: 8.3270	Cost: 5.88s
Train Epoch: 1049 [81920/90000 (91%)]	Loss: 8.4270	Cost: 5.80s
Train Epoch: 1049 	Average Loss: 9.3133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6754

Learning rate: 0.00019461870737965656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1050 [0/90000 (0%)]	Loss: 21.5403	Cost: 21.06s
Train Epoch: 1050 [20480/90000 (23%)]	Loss: 8.3246	Cost: 6.03s
Train Epoch: 1050 [40960/90000 (45%)]	Loss: 8.6386	Cost: 6.34s
Train Epoch: 1050 [61440/90000 (68%)]	Loss: 8.3342	Cost: 5.88s
Train Epoch: 1050 [81920/90000 (91%)]	Loss: 8.4611	Cost: 5.78s
Train Epoch: 1050 	Average Loss: 9.3275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5802

Learning rate: 0.00019460853588275422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1051 [0/90000 (0%)]	Loss: 21.2520	Cost: 19.95s
Train Epoch: 1051 [20480/90000 (23%)]	Loss: 8.4701	Cost: 6.24s
Train Epoch: 1051 [40960/90000 (45%)]	Loss: 8.6628	Cost: 6.32s
Train Epoch: 1051 [61440/90000 (68%)]	Loss: 8.3100	Cost: 5.96s
Train Epoch: 1051 [81920/90000 (91%)]	Loss: 8.3947	Cost: 5.84s
Train Epoch: 1051 	Average Loss: 9.3769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4836

Learning rate: 0.00019459835504836374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1052 [0/90000 (0%)]	Loss: 21.1418	Cost: 22.65s
Train Epoch: 1052 [20480/90000 (23%)]	Loss: 8.3038	Cost: 6.10s
Train Epoch: 1052 [40960/90000 (45%)]	Loss: 8.5435	Cost: 6.12s
Train Epoch: 1052 [61440/90000 (68%)]	Loss: 8.3452	Cost: 6.07s
Train Epoch: 1052 [81920/90000 (91%)]	Loss: 8.4710	Cost: 6.22s
Train Epoch: 1052 	Average Loss: 9.2990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6120

Learning rate: 0.0001945881648774899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1053 [0/90000 (0%)]	Loss: 21.3795	Cost: 22.82s
Train Epoch: 1053 [20480/90000 (23%)]	Loss: 8.5174	Cost: 6.00s
Train Epoch: 1053 [40960/90000 (45%)]	Loss: 8.5517	Cost: 6.11s
Train Epoch: 1053 [61440/90000 (68%)]	Loss: 8.2768	Cost: 5.88s
Train Epoch: 1053 [81920/90000 (91%)]	Loss: 8.4771	Cost: 5.73s
Train Epoch: 1053 	Average Loss: 9.3210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5786

Learning rate: 0.00019457796537113845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1054 [0/90000 (0%)]	Loss: 21.2013	Cost: 23.79s
Train Epoch: 1054 [20480/90000 (23%)]	Loss: 8.5669	Cost: 6.02s
Train Epoch: 1054 [40960/90000 (45%)]	Loss: 8.5640	Cost: 6.07s
Train Epoch: 1054 [61440/90000 (68%)]	Loss: 8.5493	Cost: 5.84s
Train Epoch: 1054 [81920/90000 (91%)]	Loss: 8.4624	Cost: 5.76s
Train Epoch: 1054 	Average Loss: 9.3539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5436

Learning rate: 0.00019456775653031605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1055 [0/90000 (0%)]	Loss: 21.4289	Cost: 24.48s
Train Epoch: 1055 [20480/90000 (23%)]	Loss: 8.4131	Cost: 6.16s
Train Epoch: 1055 [40960/90000 (45%)]	Loss: 8.3505	Cost: 6.38s
Train Epoch: 1055 [61440/90000 (68%)]	Loss: 8.3121	Cost: 5.87s
Train Epoch: 1055 [81920/90000 (91%)]	Loss: 8.5746	Cost: 5.84s
Train Epoch: 1055 	Average Loss: 9.3481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6356

Learning rate: 0.0001945575383560303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1056 [0/90000 (0%)]	Loss: 21.0780	Cost: 23.68s
Train Epoch: 1056 [20480/90000 (23%)]	Loss: 8.3980	Cost: 6.10s
Train Epoch: 1056 [40960/90000 (45%)]	Loss: 8.5609	Cost: 6.34s
Train Epoch: 1056 [61440/90000 (68%)]	Loss: 8.3332	Cost: 5.85s
Train Epoch: 1056 [81920/90000 (91%)]	Loss: 8.5673	Cost: 5.77s
Train Epoch: 1056 	Average Loss: 9.3638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5980

Learning rate: 0.00019454731084928963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1057 [0/90000 (0%)]	Loss: 21.4549	Cost: 26.00s
Train Epoch: 1057 [20480/90000 (23%)]	Loss: 8.4718	Cost: 5.95s
Train Epoch: 1057 [40960/90000 (45%)]	Loss: 8.4198	Cost: 6.41s
Train Epoch: 1057 [61440/90000 (68%)]	Loss: 8.5428	Cost: 5.92s
Train Epoch: 1057 [81920/90000 (91%)]	Loss: 8.5888	Cost: 5.65s
Train Epoch: 1057 	Average Loss: 9.4398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5930

Learning rate: 0.0001945370740111035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1058 [0/90000 (0%)]	Loss: 21.2730	Cost: 22.58s
Train Epoch: 1058 [20480/90000 (23%)]	Loss: 8.3171	Cost: 6.76s
Train Epoch: 1058 [40960/90000 (45%)]	Loss: 8.4574	Cost: 6.11s
Train Epoch: 1058 [61440/90000 (68%)]	Loss: 8.2405	Cost: 6.03s
Train Epoch: 1058 [81920/90000 (91%)]	Loss: 8.3552	Cost: 5.78s
Train Epoch: 1058 	Average Loss: 9.2647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6122

Learning rate: 0.00019452682784248221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1059 [0/90000 (0%)]	Loss: 21.2797	Cost: 22.81s
Train Epoch: 1059 [20480/90000 (23%)]	Loss: 8.2655	Cost: 6.63s
Train Epoch: 1059 [40960/90000 (45%)]	Loss: 8.3718	Cost: 6.36s
Train Epoch: 1059 [61440/90000 (68%)]	Loss: 8.3058	Cost: 5.99s
Train Epoch: 1059 [81920/90000 (91%)]	Loss: 8.1901	Cost: 5.77s
Train Epoch: 1059 	Average Loss: 9.1464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6527

Learning rate: 0.00019451657234443705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1060 [0/90000 (0%)]	Loss: 21.4068	Cost: 20.87s
Train Epoch: 1060 [20480/90000 (23%)]	Loss: 8.0855	Cost: 6.20s
Train Epoch: 1060 [40960/90000 (45%)]	Loss: 8.2364	Cost: 6.10s
Train Epoch: 1060 [61440/90000 (68%)]	Loss: 8.1724	Cost: 5.95s
Train Epoch: 1060 [81920/90000 (91%)]	Loss: 8.3246	Cost: 5.81s
Train Epoch: 1060 	Average Loss: 9.1798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6468

Learning rate: 0.00019450630751798018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1061 [0/90000 (0%)]	Loss: 21.5043	Cost: 19.65s
Train Epoch: 1061 [20480/90000 (23%)]	Loss: 8.5035	Cost: 6.19s
Train Epoch: 1061 [40960/90000 (45%)]	Loss: 8.5538	Cost: 6.66s
Train Epoch: 1061 [61440/90000 (68%)]	Loss: 8.4034	Cost: 6.04s
Train Epoch: 1061 [81920/90000 (91%)]	Loss: 8.4594	Cost: 6.10s
Train Epoch: 1061 	Average Loss: 9.3411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6752

Learning rate: 0.0001944960333641247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1062 [0/90000 (0%)]	Loss: 21.1835	Cost: 20.34s
Train Epoch: 1062 [20480/90000 (23%)]	Loss: 8.4245	Cost: 6.08s
Train Epoch: 1062 [40960/90000 (45%)]	Loss: 8.5368	Cost: 7.13s
Train Epoch: 1062 [61440/90000 (68%)]	Loss: 8.2617	Cost: 5.93s
Train Epoch: 1062 [81920/90000 (91%)]	Loss: 8.2898	Cost: 5.81s
Train Epoch: 1062 	Average Loss: 9.2944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7685

Learning rate: 0.0001944857498838846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1063 [0/90000 (0%)]	Loss: 21.1893	Cost: 19.62s
Train Epoch: 1063 [20480/90000 (23%)]	Loss: 8.3184	Cost: 6.09s
Train Epoch: 1063 [40960/90000 (45%)]	Loss: 8.4382	Cost: 6.39s
Train Epoch: 1063 [61440/90000 (68%)]	Loss: 8.2530	Cost: 6.04s
Train Epoch: 1063 [81920/90000 (91%)]	Loss: 8.5550	Cost: 6.04s
Train Epoch: 1063 	Average Loss: 9.2543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6768

Learning rate: 0.00019447545707827488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1064 [0/90000 (0%)]	Loss: 21.4475	Cost: 20.93s
Train Epoch: 1064 [20480/90000 (23%)]	Loss: 8.4654	Cost: 6.08s
Train Epoch: 1064 [40960/90000 (45%)]	Loss: 8.4489	Cost: 6.22s
Train Epoch: 1064 [61440/90000 (68%)]	Loss: 8.3564	Cost: 5.96s
Train Epoch: 1064 [81920/90000 (91%)]	Loss: 8.3358	Cost: 6.14s
Train Epoch: 1064 	Average Loss: 9.2789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6360

Learning rate: 0.00019446515494831135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1065 [0/90000 (0%)]	Loss: 21.7260	Cost: 20.92s
Train Epoch: 1065 [20480/90000 (23%)]	Loss: 8.3761	Cost: 6.05s
Train Epoch: 1065 [40960/90000 (45%)]	Loss: 8.4487	Cost: 6.13s
Train Epoch: 1065 [61440/90000 (68%)]	Loss: 8.3251	Cost: 6.02s
Train Epoch: 1065 [81920/90000 (91%)]	Loss: 8.4510	Cost: 5.84s
Train Epoch: 1065 	Average Loss: 9.3319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6542

Learning rate: 0.00019445484349501084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1066 [0/90000 (0%)]	Loss: 21.5552	Cost: 21.04s
Train Epoch: 1066 [20480/90000 (23%)]	Loss: 8.4025	Cost: 6.02s
Train Epoch: 1066 [40960/90000 (45%)]	Loss: 8.5139	Cost: 6.27s
Train Epoch: 1066 [61440/90000 (68%)]	Loss: 8.2205	Cost: 5.87s
Train Epoch: 1066 [81920/90000 (91%)]	Loss: 8.5092	Cost: 5.96s
Train Epoch: 1066 	Average Loss: 9.3073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7330

Learning rate: 0.00019444452271939096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1067 [0/90000 (0%)]	Loss: 21.5580	Cost: 20.65s
Train Epoch: 1067 [20480/90000 (23%)]	Loss: 8.3988	Cost: 6.03s
Train Epoch: 1067 [40960/90000 (45%)]	Loss: 8.1609	Cost: 6.13s
Train Epoch: 1067 [61440/90000 (68%)]	Loss: 8.1827	Cost: 5.82s
Train Epoch: 1067 [81920/90000 (91%)]	Loss: 8.1142	Cost: 5.72s
Train Epoch: 1067 	Average Loss: 9.1447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7618

Learning rate: 0.0001944341926224704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1068 [0/90000 (0%)]	Loss: 21.4788	Cost: 21.59s
Train Epoch: 1068 [20480/90000 (23%)]	Loss: 8.2537	Cost: 6.01s
Train Epoch: 1068 [40960/90000 (45%)]	Loss: 8.1419	Cost: 6.07s
Train Epoch: 1068 [61440/90000 (68%)]	Loss: 8.0026	Cost: 5.86s
Train Epoch: 1068 [81920/90000 (91%)]	Loss: 8.2164	Cost: 5.83s
Train Epoch: 1068 	Average Loss: 9.0730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7779

Learning rate: 0.00019442385320526872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1069 [0/90000 (0%)]	Loss: 21.3267	Cost: 19.84s
Train Epoch: 1069 [20480/90000 (23%)]	Loss: 8.1516	Cost: 6.18s
Train Epoch: 1069 [40960/90000 (45%)]	Loss: 8.0909	Cost: 6.05s
Train Epoch: 1069 [61440/90000 (68%)]	Loss: 8.0388	Cost: 5.90s
Train Epoch: 1069 [81920/90000 (91%)]	Loss: 8.1684	Cost: 5.70s
Train Epoch: 1069 	Average Loss: 9.0676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7713

Learning rate: 0.00019441350446880632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1070 [0/90000 (0%)]	Loss: 21.4449	Cost: 20.19s
Train Epoch: 1070 [20480/90000 (23%)]	Loss: 8.0644	Cost: 6.06s
Train Epoch: 1070 [40960/90000 (45%)]	Loss: 8.5573	Cost: 6.62s
Train Epoch: 1070 [61440/90000 (68%)]	Loss: 8.3932	Cost: 5.95s
Train Epoch: 1070 [81920/90000 (91%)]	Loss: 8.3852	Cost: 5.92s
Train Epoch: 1070 	Average Loss: 9.2143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6532

Learning rate: 0.00019440314641410464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1071 [0/90000 (0%)]	Loss: 21.4158	Cost: 21.96s
Train Epoch: 1071 [20480/90000 (23%)]	Loss: 8.4176	Cost: 5.99s
Train Epoch: 1071 [40960/90000 (45%)]	Loss: 8.6560	Cost: 6.71s
Train Epoch: 1071 [61440/90000 (68%)]	Loss: 8.3138	Cost: 5.78s
Train Epoch: 1071 [81920/90000 (91%)]	Loss: 8.2704	Cost: 5.52s
Train Epoch: 1071 	Average Loss: 9.3089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6801

Learning rate: 0.0001943927790421859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1072 [0/90000 (0%)]	Loss: 21.4902	Cost: 20.93s
Train Epoch: 1072 [20480/90000 (23%)]	Loss: 8.4122	Cost: 6.03s
Train Epoch: 1072 [40960/90000 (45%)]	Loss: 8.3202	Cost: 6.06s
Train Epoch: 1072 [61440/90000 (68%)]	Loss: 8.2421	Cost: 5.86s
Train Epoch: 1072 [81920/90000 (91%)]	Loss: 8.3949	Cost: 5.74s
Train Epoch: 1072 	Average Loss: 9.2001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6949

Learning rate: 0.00019438240235407337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1073 [0/90000 (0%)]	Loss: 21.3825	Cost: 21.10s
Train Epoch: 1073 [20480/90000 (23%)]	Loss: 8.1293	Cost: 5.97s
Train Epoch: 1073 [40960/90000 (45%)]	Loss: 8.2827	Cost: 6.19s
Train Epoch: 1073 [61440/90000 (68%)]	Loss: 8.0790	Cost: 5.85s
Train Epoch: 1073 [81920/90000 (91%)]	Loss: 8.2991	Cost: 5.71s
Train Epoch: 1073 	Average Loss: 9.1136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7918

Learning rate: 0.0001943720163507912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1074 [0/90000 (0%)]	Loss: 21.4493	Cost: 22.02s
Train Epoch: 1074 [20480/90000 (23%)]	Loss: 8.2215	Cost: 5.97s
Train Epoch: 1074 [40960/90000 (45%)]	Loss: 8.1954	Cost: 6.60s
Train Epoch: 1074 [61440/90000 (68%)]	Loss: 8.0481	Cost: 5.84s
Train Epoch: 1074 [81920/90000 (91%)]	Loss: 8.1469	Cost: 5.97s
Train Epoch: 1074 	Average Loss: 9.1077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7911

Learning rate: 0.0001943616210333644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1075 [0/90000 (0%)]	Loss: 21.5098	Cost: 20.60s
Train Epoch: 1075 [20480/90000 (23%)]	Loss: 8.1880	Cost: 5.93s
Train Epoch: 1075 [40960/90000 (45%)]	Loss: 8.1053	Cost: 6.36s
Train Epoch: 1075 [61440/90000 (68%)]	Loss: 7.9052	Cost: 5.88s
Train Epoch: 1075 [81920/90000 (91%)]	Loss: 8.1163	Cost: 5.66s
Train Epoch: 1075 	Average Loss: 9.0390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7400

Learning rate: 0.000194351216402819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1076 [0/90000 (0%)]	Loss: 21.5062	Cost: 22.80s
Train Epoch: 1076 [20480/90000 (23%)]	Loss: 7.9906	Cost: 5.98s
Train Epoch: 1076 [40960/90000 (45%)]	Loss: 8.2786	Cost: 6.08s
Train Epoch: 1076 [61440/90000 (68%)]	Loss: 7.9768	Cost: 5.93s
Train Epoch: 1076 [81920/90000 (91%)]	Loss: 8.0972	Cost: 5.75s
Train Epoch: 1076 	Average Loss: 9.0274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8377

Learning rate: 0.00019434080246018187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1077 [0/90000 (0%)]	Loss: 21.4898	Cost: 20.87s
Train Epoch: 1077 [20480/90000 (23%)]	Loss: 8.1361	Cost: 6.03s
Train Epoch: 1077 [40960/90000 (45%)]	Loss: 8.1283	Cost: 6.05s
Train Epoch: 1077 [61440/90000 (68%)]	Loss: 7.8105	Cost: 5.70s
Train Epoch: 1077 [81920/90000 (91%)]	Loss: 7.9885	Cost: 5.82s
Train Epoch: 1077 	Average Loss: 9.0130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8684

Learning rate: 0.00019433037920648082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1078 [0/90000 (0%)]	Loss: 21.5941	Cost: 23.52s
Train Epoch: 1078 [20480/90000 (23%)]	Loss: 8.1548	Cost: 6.05s
Train Epoch: 1078 [40960/90000 (45%)]	Loss: 8.1973	Cost: 6.03s
Train Epoch: 1078 [61440/90000 (68%)]	Loss: 8.0755	Cost: 5.86s
Train Epoch: 1078 [81920/90000 (91%)]	Loss: 8.4095	Cost: 5.75s
Train Epoch: 1078 	Average Loss: 9.1157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7730

Learning rate: 0.0001943199466427446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1079 [0/90000 (0%)]	Loss: 21.6916	Cost: 24.67s
Train Epoch: 1079 [20480/90000 (23%)]	Loss: 8.3958	Cost: 6.03s
Train Epoch: 1079 [40960/90000 (45%)]	Loss: 8.2950	Cost: 6.76s
Train Epoch: 1079 [61440/90000 (68%)]	Loss: 8.1379	Cost: 5.89s
Train Epoch: 1079 [81920/90000 (91%)]	Loss: 8.0410	Cost: 5.90s
Train Epoch: 1079 	Average Loss: 9.1755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7238

Learning rate: 0.0001943095047700028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1080 [0/90000 (0%)]	Loss: 21.6415	Cost: 23.57s
Train Epoch: 1080 [20480/90000 (23%)]	Loss: 8.0617	Cost: 5.96s
Train Epoch: 1080 [40960/90000 (45%)]	Loss: 8.2010	Cost: 6.65s
Train Epoch: 1080 [61440/90000 (68%)]	Loss: 7.9261	Cost: 5.86s
Train Epoch: 1080 [81920/90000 (91%)]	Loss: 8.0455	Cost: 5.85s
Train Epoch: 1080 	Average Loss: 9.0214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6766

Learning rate: 0.00019429905358928608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1081 [0/90000 (0%)]	Loss: 21.6382	Cost: 21.92s
Train Epoch: 1081 [20480/90000 (23%)]	Loss: 8.0021	Cost: 6.32s
Train Epoch: 1081 [40960/90000 (45%)]	Loss: 8.0759	Cost: 6.53s
Train Epoch: 1081 [61440/90000 (68%)]	Loss: 7.9037	Cost: 6.01s
Train Epoch: 1081 [81920/90000 (91%)]	Loss: 8.1937	Cost: 5.74s
Train Epoch: 1081 	Average Loss: 8.9955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8709

Learning rate: 0.0001942885931016259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1082 [0/90000 (0%)]	Loss: 21.7267	Cost: 21.56s
Train Epoch: 1082 [20480/90000 (23%)]	Loss: 7.9097	Cost: 7.03s
Train Epoch: 1082 [40960/90000 (45%)]	Loss: 7.8607	Cost: 6.09s
Train Epoch: 1082 [61440/90000 (68%)]	Loss: 7.9827	Cost: 5.96s
Train Epoch: 1082 [81920/90000 (91%)]	Loss: 8.1887	Cost: 5.82s
Train Epoch: 1082 	Average Loss: 8.9078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9076

Learning rate: 0.00019427812330805462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1083 [0/90000 (0%)]	Loss: 21.6202	Cost: 21.04s
Train Epoch: 1083 [20480/90000 (23%)]	Loss: 7.9544	Cost: 6.68s
Train Epoch: 1083 [40960/90000 (45%)]	Loss: 8.2037	Cost: 6.35s
Train Epoch: 1083 [61440/90000 (68%)]	Loss: 8.0314	Cost: 5.91s
Train Epoch: 1083 [81920/90000 (91%)]	Loss: 8.0444	Cost: 5.85s
Train Epoch: 1083 	Average Loss: 8.9697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9143

Learning rate: 0.00019426764420960564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1084 [0/90000 (0%)]	Loss: 21.4813	Cost: 20.19s
Train Epoch: 1084 [20480/90000 (23%)]	Loss: 7.9990	Cost: 6.32s
Train Epoch: 1084 [40960/90000 (45%)]	Loss: 8.2840	Cost: 6.47s
Train Epoch: 1084 [61440/90000 (68%)]	Loss: 8.0695	Cost: 5.89s
Train Epoch: 1084 [81920/90000 (91%)]	Loss: 7.7503	Cost: 5.91s
Train Epoch: 1084 	Average Loss: 8.9557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9029

Learning rate: 0.00019425715580731318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1085 [0/90000 (0%)]	Loss: 21.7153	Cost: 20.00s
Train Epoch: 1085 [20480/90000 (23%)]	Loss: 7.9578	Cost: 6.29s
Train Epoch: 1085 [40960/90000 (45%)]	Loss: 8.0374	Cost: 6.94s
Train Epoch: 1085 [61440/90000 (68%)]	Loss: 8.0738	Cost: 5.92s
Train Epoch: 1085 [81920/90000 (91%)]	Loss: 8.0515	Cost: 6.03s
Train Epoch: 1085 	Average Loss: 8.9649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8673

Learning rate: 0.00019424665810221242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1086 [0/90000 (0%)]	Loss: 21.8017	Cost: 20.03s
Train Epoch: 1086 [20480/90000 (23%)]	Loss: 7.9979	Cost: 6.04s
Train Epoch: 1086 [40960/90000 (45%)]	Loss: 8.1193	Cost: 6.49s
Train Epoch: 1086 [61440/90000 (68%)]	Loss: 7.8850	Cost: 5.88s
Train Epoch: 1086 [81920/90000 (91%)]	Loss: 8.0080	Cost: 5.73s
Train Epoch: 1086 	Average Loss: 9.0107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8942

Learning rate: 0.00019423615109533942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1087 [0/90000 (0%)]	Loss: 21.7436	Cost: 20.76s
Train Epoch: 1087 [20480/90000 (23%)]	Loss: 7.9482	Cost: 6.01s
Train Epoch: 1087 [40960/90000 (45%)]	Loss: 8.1203	Cost: 6.03s
Train Epoch: 1087 [61440/90000 (68%)]	Loss: 7.7294	Cost: 5.98s
Train Epoch: 1087 [81920/90000 (91%)]	Loss: 8.0006	Cost: 6.43s
Train Epoch: 1087 	Average Loss: 8.9126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9229

Learning rate: 0.00019422563478773116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1088 [0/90000 (0%)]	Loss: 21.6357	Cost: 20.50s
Train Epoch: 1088 [20480/90000 (23%)]	Loss: 7.9515	Cost: 5.94s
Train Epoch: 1088 [40960/90000 (45%)]	Loss: 7.9104	Cost: 6.15s
Train Epoch: 1088 [61440/90000 (68%)]	Loss: 7.8202	Cost: 5.86s
Train Epoch: 1088 [81920/90000 (91%)]	Loss: 7.8363	Cost: 6.01s
Train Epoch: 1088 	Average Loss: 8.8212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9193

Learning rate: 0.00019421510918042557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1089 [0/90000 (0%)]	Loss: 21.6526	Cost: 20.81s
Train Epoch: 1089 [20480/90000 (23%)]	Loss: 7.9202	Cost: 6.05s
Train Epoch: 1089 [40960/90000 (45%)]	Loss: 8.0310	Cost: 6.68s
Train Epoch: 1089 [61440/90000 (68%)]	Loss: 7.8348	Cost: 5.90s
Train Epoch: 1089 [81920/90000 (91%)]	Loss: 8.0438	Cost: 6.17s
Train Epoch: 1089 	Average Loss: 8.9281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8872

Learning rate: 0.0001942045742744615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1090 [0/90000 (0%)]	Loss: 21.5332	Cost: 20.60s
Train Epoch: 1090 [20480/90000 (23%)]	Loss: 7.9604	Cost: 5.99s
Train Epoch: 1090 [40960/90000 (45%)]	Loss: 7.9970	Cost: 6.72s
Train Epoch: 1090 [61440/90000 (68%)]	Loss: 7.9088	Cost: 6.05s
Train Epoch: 1090 [81920/90000 (91%)]	Loss: 8.2212	Cost: 5.93s
Train Epoch: 1090 	Average Loss: 8.9081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9732

Learning rate: 0.0001941940300708787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1091 [0/90000 (0%)]	Loss: 21.4742	Cost: 21.39s
Train Epoch: 1091 [20480/90000 (23%)]	Loss: 7.8921	Cost: 5.96s
Train Epoch: 1091 [40960/90000 (45%)]	Loss: 8.0815	Cost: 6.57s
Train Epoch: 1091 [61440/90000 (68%)]	Loss: 7.9482	Cost: 5.85s
Train Epoch: 1091 [81920/90000 (91%)]	Loss: 8.4275	Cost: 5.88s
Train Epoch: 1091 	Average Loss: 8.9925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8448

Learning rate: 0.00019418347657071785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1092 [0/90000 (0%)]	Loss: 21.5997	Cost: 20.43s
Train Epoch: 1092 [20480/90000 (23%)]	Loss: 8.4233	Cost: 6.19s
Train Epoch: 1092 [40960/90000 (45%)]	Loss: 8.3864	Cost: 6.20s
Train Epoch: 1092 [61440/90000 (68%)]	Loss: 8.0056	Cost: 5.99s
Train Epoch: 1092 [81920/90000 (91%)]	Loss: 8.5248	Cost: 6.24s
Train Epoch: 1092 	Average Loss: 9.1634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8637

Learning rate: 0.0001941729137750205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1093 [0/90000 (0%)]	Loss: 21.4623	Cost: 20.80s
Train Epoch: 1093 [20480/90000 (23%)]	Loss: 8.1270	Cost: 6.09s
Train Epoch: 1093 [40960/90000 (45%)]	Loss: 7.9803	Cost: 6.16s
Train Epoch: 1093 [61440/90000 (68%)]	Loss: 7.9478	Cost: 5.87s
Train Epoch: 1093 [81920/90000 (91%)]	Loss: 7.9016	Cost: 5.82s
Train Epoch: 1093 	Average Loss: 9.0386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9152

Learning rate: 0.0001941623416848292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1094 [0/90000 (0%)]	Loss: 21.4556	Cost: 21.01s
Train Epoch: 1094 [20480/90000 (23%)]	Loss: 7.8824	Cost: 6.17s
Train Epoch: 1094 [40960/90000 (45%)]	Loss: 8.0278	Cost: 6.44s
Train Epoch: 1094 [61440/90000 (68%)]	Loss: 7.9937	Cost: 5.87s
Train Epoch: 1094 [81920/90000 (91%)]	Loss: 8.0160	Cost: 5.74s
Train Epoch: 1094 	Average Loss: 8.9649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8876

Learning rate: 0.00019415176030118734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1095 [0/90000 (0%)]	Loss: 21.7081	Cost: 20.63s
Train Epoch: 1095 [20480/90000 (23%)]	Loss: 8.1284	Cost: 6.07s
Train Epoch: 1095 [40960/90000 (45%)]	Loss: 8.0772	Cost: 6.68s
Train Epoch: 1095 [61440/90000 (68%)]	Loss: 7.9723	Cost: 5.93s
Train Epoch: 1095 [81920/90000 (91%)]	Loss: 8.0370	Cost: 5.82s
Train Epoch: 1095 	Average Loss: 8.9810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8847

Learning rate: 0.00019414116962513932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1096 [0/90000 (0%)]	Loss: 21.6036	Cost: 21.47s
Train Epoch: 1096 [20480/90000 (23%)]	Loss: 8.1398	Cost: 6.18s
Train Epoch: 1096 [40960/90000 (45%)]	Loss: 8.1694	Cost: 6.34s
Train Epoch: 1096 [61440/90000 (68%)]	Loss: 7.8725	Cost: 5.94s
Train Epoch: 1096 [81920/90000 (91%)]	Loss: 8.0373	Cost: 5.86s
Train Epoch: 1096 	Average Loss: 9.0358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8880

Learning rate: 0.00019413056965773032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1097 [0/90000 (0%)]	Loss: 21.5117	Cost: 20.48s
Train Epoch: 1097 [20480/90000 (23%)]	Loss: 7.9862	Cost: 6.03s
Train Epoch: 1097 [40960/90000 (45%)]	Loss: 7.9670	Cost: 6.22s
Train Epoch: 1097 [61440/90000 (68%)]	Loss: 7.7012	Cost: 5.99s
Train Epoch: 1097 [81920/90000 (91%)]	Loss: 7.8919	Cost: 5.83s
Train Epoch: 1097 	Average Loss: 8.8762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9441

Learning rate: 0.00019411996040000657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1098 [0/90000 (0%)]	Loss: 21.4744	Cost: 19.52s
Train Epoch: 1098 [20480/90000 (23%)]	Loss: 7.8843	Cost: 6.19s
Train Epoch: 1098 [40960/90000 (45%)]	Loss: 7.8979	Cost: 6.06s
Train Epoch: 1098 [61440/90000 (68%)]	Loss: 7.8917	Cost: 5.92s
Train Epoch: 1098 [81920/90000 (91%)]	Loss: 7.9481	Cost: 5.86s
Train Epoch: 1098 	Average Loss: 8.8604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8821

Learning rate: 0.00019410934185301514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1099 [0/90000 (0%)]	Loss: 21.8959	Cost: 21.99s
Train Epoch: 1099 [20480/90000 (23%)]	Loss: 8.1675	Cost: 6.01s
Train Epoch: 1099 [40960/90000 (45%)]	Loss: 8.0360	Cost: 6.53s
Train Epoch: 1099 [61440/90000 (68%)]	Loss: 7.7832	Cost: 5.91s
Train Epoch: 1099 [81920/90000 (91%)]	Loss: 8.0829	Cost: 6.20s
Train Epoch: 1099 	Average Loss: 9.0105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8746

Learning rate: 0.00019409871401780405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1100 [0/90000 (0%)]	Loss: 21.6469	Cost: 20.54s
Train Epoch: 1100 [20480/90000 (23%)]	Loss: 7.9518	Cost: 6.15s
Train Epoch: 1100 [40960/90000 (45%)]	Loss: 8.3014	Cost: 6.67s
Train Epoch: 1100 [61440/90000 (68%)]	Loss: 8.1584	Cost: 5.91s
Train Epoch: 1100 [81920/90000 (91%)]	Loss: 8.1600	Cost: 5.91s
Train Epoch: 1100 	Average Loss: 9.1042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8270

Learning rate: 0.0001940880768954222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1101 [0/90000 (0%)]	Loss: 21.9356	Cost: 20.02s
Train Epoch: 1101 [20480/90000 (23%)]	Loss: 7.8857	Cost: 6.17s
Train Epoch: 1101 [40960/90000 (45%)]	Loss: 8.1547	Cost: 6.21s
Train Epoch: 1101 [61440/90000 (68%)]	Loss: 7.9331	Cost: 6.05s
Train Epoch: 1101 [81920/90000 (91%)]	Loss: 8.0989	Cost: 5.78s
Train Epoch: 1101 	Average Loss: 8.9810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8986

Learning rate: 0.00019407743048691943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1102 [0/90000 (0%)]	Loss: 21.5834	Cost: 21.40s
Train Epoch: 1102 [20480/90000 (23%)]	Loss: 7.7918	Cost: 6.06s
Train Epoch: 1102 [40960/90000 (45%)]	Loss: 8.0084	Cost: 6.17s
Train Epoch: 1102 [61440/90000 (68%)]	Loss: 7.8372	Cost: 5.91s
Train Epoch: 1102 [81920/90000 (91%)]	Loss: 7.8110	Cost: 5.84s
Train Epoch: 1102 	Average Loss: 8.8480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9522

Learning rate: 0.00019406677479334654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1103 [0/90000 (0%)]	Loss: 21.8240	Cost: 21.61s
Train Epoch: 1103 [20480/90000 (23%)]	Loss: 7.8805	Cost: 6.02s
Train Epoch: 1103 [40960/90000 (45%)]	Loss: 7.8806	Cost: 6.17s
Train Epoch: 1103 [61440/90000 (68%)]	Loss: 7.8244	Cost: 5.94s
Train Epoch: 1103 [81920/90000 (91%)]	Loss: 7.8017	Cost: 6.11s
Train Epoch: 1103 	Average Loss: 8.8208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9131

Learning rate: 0.0001940561098157552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1104 [0/90000 (0%)]	Loss: 21.6244	Cost: 21.68s
Train Epoch: 1104 [20480/90000 (23%)]	Loss: 7.6543	Cost: 6.00s
Train Epoch: 1104 [40960/90000 (45%)]	Loss: 8.0425	Cost: 6.81s
Train Epoch: 1104 [61440/90000 (68%)]	Loss: 7.7270	Cost: 5.79s
Train Epoch: 1104 [81920/90000 (91%)]	Loss: 7.8112	Cost: 6.08s
Train Epoch: 1104 	Average Loss: 8.7843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9089

Learning rate: 0.00019404543555519795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1105 [0/90000 (0%)]	Loss: 21.5548	Cost: 20.76s
Train Epoch: 1105 [20480/90000 (23%)]	Loss: 7.9108	Cost: 6.06s
Train Epoch: 1105 [40960/90000 (45%)]	Loss: 7.9427	Cost: 6.28s
Train Epoch: 1105 [61440/90000 (68%)]	Loss: 7.4713	Cost: 5.91s
Train Epoch: 1105 [81920/90000 (91%)]	Loss: 7.9059	Cost: 5.90s
Train Epoch: 1105 	Average Loss: 8.7595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9825

Learning rate: 0.00019403475201272834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1106 [0/90000 (0%)]	Loss: 21.8994	Cost: 22.40s
Train Epoch: 1106 [20480/90000 (23%)]	Loss: 7.6783	Cost: 6.02s
Train Epoch: 1106 [40960/90000 (45%)]	Loss: 7.7865	Cost: 6.40s
Train Epoch: 1106 [61440/90000 (68%)]	Loss: 7.7838	Cost: 5.88s
Train Epoch: 1106 [81920/90000 (91%)]	Loss: 7.9031	Cost: 6.04s
Train Epoch: 1106 	Average Loss: 8.7845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9565

Learning rate: 0.00019402405918940077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1107 [0/90000 (0%)]	Loss: 21.6033	Cost: 21.00s
Train Epoch: 1107 [20480/90000 (23%)]	Loss: 7.8322	Cost: 6.16s
Train Epoch: 1107 [40960/90000 (45%)]	Loss: 8.0026	Cost: 6.04s
Train Epoch: 1107 [61440/90000 (68%)]	Loss: 7.8625	Cost: 5.95s
Train Epoch: 1107 [81920/90000 (91%)]	Loss: 7.7604	Cost: 5.82s
Train Epoch: 1107 	Average Loss: 8.8082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0282

Learning rate: 0.00019401335708627064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1108 [0/90000 (0%)]	Loss: 21.6240	Cost: 25.08s
Train Epoch: 1108 [20480/90000 (23%)]	Loss: 7.8497	Cost: 5.97s
Train Epoch: 1108 [40960/90000 (45%)]	Loss: 7.9357	Cost: 6.06s
Train Epoch: 1108 [61440/90000 (68%)]	Loss: 8.1049	Cost: 5.90s
Train Epoch: 1108 [81920/90000 (91%)]	Loss: 8.0087	Cost: 5.79s
Train Epoch: 1108 	Average Loss: 8.8433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9801

Learning rate: 0.00019400264570439412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1109 [0/90000 (0%)]	Loss: 21.6031	Cost: 23.58s
Train Epoch: 1109 [20480/90000 (23%)]	Loss: 7.8594	Cost: 6.05s
Train Epoch: 1109 [40960/90000 (45%)]	Loss: 8.0409	Cost: 6.20s
Train Epoch: 1109 [61440/90000 (68%)]	Loss: 7.8175	Cost: 5.92s
Train Epoch: 1109 [81920/90000 (91%)]	Loss: 7.9024	Cost: 5.78s
Train Epoch: 1109 	Average Loss: 8.8043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9829

Learning rate: 0.0001939919250448284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1110 [0/90000 (0%)]	Loss: 21.4811	Cost: 23.19s
Train Epoch: 1110 [20480/90000 (23%)]	Loss: 7.6171	Cost: 6.03s
Train Epoch: 1110 [40960/90000 (45%)]	Loss: 7.8037	Cost: 6.06s
Train Epoch: 1110 [61440/90000 (68%)]	Loss: 7.5766	Cost: 5.97s
Train Epoch: 1110 [81920/90000 (91%)]	Loss: 7.8800	Cost: 5.69s
Train Epoch: 1110 	Average Loss: 8.7009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0615

Learning rate: 0.00019398119510863161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1111 [0/90000 (0%)]	Loss: 21.6445	Cost: 22.34s
Train Epoch: 1111 [20480/90000 (23%)]	Loss: 7.8207	Cost: 6.24s
Train Epoch: 1111 [40960/90000 (45%)]	Loss: 7.9240	Cost: 6.64s
Train Epoch: 1111 [61440/90000 (68%)]	Loss: 7.7126	Cost: 5.93s
Train Epoch: 1111 [81920/90000 (91%)]	Loss: 7.6522	Cost: 5.99s
Train Epoch: 1111 	Average Loss: 8.7643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9816

Learning rate: 0.00019397045589686273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1112 [0/90000 (0%)]	Loss: 21.4935	Cost: 22.29s
Train Epoch: 1112 [20480/90000 (23%)]	Loss: 7.5808	Cost: 6.71s
Train Epoch: 1112 [40960/90000 (45%)]	Loss: 7.7790	Cost: 6.83s
Train Epoch: 1112 [61440/90000 (68%)]	Loss: 7.5627	Cost: 6.07s
Train Epoch: 1112 [81920/90000 (91%)]	Loss: 7.6759	Cost: 6.09s
Train Epoch: 1112 	Average Loss: 8.6421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0387

Learning rate: 0.00019395970741058167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1113 [0/90000 (0%)]	Loss: 21.8627	Cost: 20.92s
Train Epoch: 1113 [20480/90000 (23%)]	Loss: 7.7270	Cost: 6.20s
Train Epoch: 1113 [40960/90000 (45%)]	Loss: 7.7283	Cost: 6.45s
Train Epoch: 1113 [61440/90000 (68%)]	Loss: 7.5185	Cost: 5.99s
Train Epoch: 1113 [81920/90000 (91%)]	Loss: 7.6422	Cost: 5.95s
Train Epoch: 1113 	Average Loss: 8.5968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0848

Learning rate: 0.00019394894965084927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1114 [0/90000 (0%)]	Loss: 21.8066	Cost: 20.50s
Train Epoch: 1114 [20480/90000 (23%)]	Loss: 7.7689	Cost: 6.27s
Train Epoch: 1114 [40960/90000 (45%)]	Loss: 7.9575	Cost: 7.11s
Train Epoch: 1114 [61440/90000 (68%)]	Loss: 7.8806	Cost: 5.97s
Train Epoch: 1114 [81920/90000 (91%)]	Loss: 7.8282	Cost: 6.61s
Train Epoch: 1114 	Average Loss: 8.7662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0565

Learning rate: 0.00019393818261872732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1115 [0/90000 (0%)]	Loss: 21.8827	Cost: 20.25s
Train Epoch: 1115 [20480/90000 (23%)]	Loss: 7.8019	Cost: 6.18s
Train Epoch: 1115 [40960/90000 (45%)]	Loss: 7.8791	Cost: 6.21s
Train Epoch: 1115 [61440/90000 (68%)]	Loss: 7.7291	Cost: 5.98s
Train Epoch: 1115 [81920/90000 (91%)]	Loss: 7.8036	Cost: 5.79s
Train Epoch: 1115 	Average Loss: 8.7042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1223

Learning rate: 0.0001939274063152784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1116 [0/90000 (0%)]	Loss: 21.8980	Cost: 20.08s
Train Epoch: 1116 [20480/90000 (23%)]	Loss: 7.4643	Cost: 5.96s
Train Epoch: 1116 [40960/90000 (45%)]	Loss: 7.6558	Cost: 6.98s
Train Epoch: 1116 [61440/90000 (68%)]	Loss: 7.5915	Cost: 5.91s
Train Epoch: 1116 [81920/90000 (91%)]	Loss: 7.7119	Cost: 5.85s
Train Epoch: 1116 	Average Loss: 8.6205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0661

Learning rate: 0.00019391662074156612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1117 [0/90000 (0%)]	Loss: 21.7163	Cost: 20.65s
Train Epoch: 1117 [20480/90000 (23%)]	Loss: 7.5118	Cost: 6.12s
Train Epoch: 1117 [40960/90000 (45%)]	Loss: 7.7634	Cost: 6.40s
Train Epoch: 1117 [61440/90000 (68%)]	Loss: 7.7773	Cost: 6.06s
Train Epoch: 1117 [81920/90000 (91%)]	Loss: 7.8437	Cost: 7.40s
Train Epoch: 1117 	Average Loss: 8.6610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1446

Learning rate: 0.00019390582589865496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1118 [0/90000 (0%)]	Loss: 21.8460	Cost: 20.68s
Train Epoch: 1118 [20480/90000 (23%)]	Loss: 7.9252	Cost: 6.09s
Train Epoch: 1118 [40960/90000 (45%)]	Loss: 7.9275	Cost: 6.35s
Train Epoch: 1118 [61440/90000 (68%)]	Loss: 7.8651	Cost: 5.95s
Train Epoch: 1118 [81920/90000 (91%)]	Loss: 8.1337	Cost: 7.30s
Train Epoch: 1118 	Average Loss: 8.8823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0557

Learning rate: 0.0001938950217876104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1119 [0/90000 (0%)]	Loss: 21.7913	Cost: 21.24s
Train Epoch: 1119 [20480/90000 (23%)]	Loss: 7.6604	Cost: 5.98s
Train Epoch: 1119 [40960/90000 (45%)]	Loss: 7.8388	Cost: 6.24s
Train Epoch: 1119 [61440/90000 (68%)]	Loss: 7.7228	Cost: 6.04s
Train Epoch: 1119 [81920/90000 (91%)]	Loss: 7.8070	Cost: 5.94s
Train Epoch: 1119 	Average Loss: 8.7776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0744

Learning rate: 0.00019388420840949869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1120 [0/90000 (0%)]	Loss: 21.5850	Cost: 21.08s
Train Epoch: 1120 [20480/90000 (23%)]	Loss: 7.7164	Cost: 5.99s
Train Epoch: 1120 [40960/90000 (45%)]	Loss: 7.8562	Cost: 6.08s
Train Epoch: 1120 [61440/90000 (68%)]	Loss: 7.5648	Cost: 5.75s
Train Epoch: 1120 [81920/90000 (91%)]	Loss: 7.5705	Cost: 5.94s
Train Epoch: 1120 	Average Loss: 8.6851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1529

Learning rate: 0.00019387338576538711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1121 [0/90000 (0%)]	Loss: 21.9540	Cost: 21.05s
Train Epoch: 1121 [20480/90000 (23%)]	Loss: 7.5934	Cost: 6.09s
Train Epoch: 1121 [40960/90000 (45%)]	Loss: 7.6842	Cost: 6.47s
Train Epoch: 1121 [61440/90000 (68%)]	Loss: 7.7861	Cost: 5.86s
Train Epoch: 1121 [81920/90000 (91%)]	Loss: 7.7058	Cost: 6.01s
Train Epoch: 1121 	Average Loss: 8.6567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1531

Learning rate: 0.00019386255385634376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1122 [0/90000 (0%)]	Loss: 21.6085	Cost: 20.69s
Train Epoch: 1122 [20480/90000 (23%)]	Loss: 7.6561	Cost: 6.14s
Train Epoch: 1122 [40960/90000 (45%)]	Loss: 7.8313	Cost: 6.54s
Train Epoch: 1122 [61440/90000 (68%)]	Loss: 7.6864	Cost: 5.78s
Train Epoch: 1122 [81920/90000 (91%)]	Loss: 7.4877	Cost: 6.71s
Train Epoch: 1122 	Average Loss: 8.5912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0519

Learning rate: 0.00019385171268343775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1123 [0/90000 (0%)]	Loss: 21.6642	Cost: 20.83s
Train Epoch: 1123 [20480/90000 (23%)]	Loss: 7.7164	Cost: 6.05s
Train Epoch: 1123 [40960/90000 (45%)]	Loss: 7.5913	Cost: 6.55s
Train Epoch: 1123 [61440/90000 (68%)]	Loss: 7.7660	Cost: 6.05s
Train Epoch: 1123 [81920/90000 (91%)]	Loss: 7.9750	Cost: 5.75s
Train Epoch: 1123 	Average Loss: 8.7142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1042

Learning rate: 0.00019384086224773903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1124 [0/90000 (0%)]	Loss: 21.8274	Cost: 20.55s
Train Epoch: 1124 [20480/90000 (23%)]	Loss: 7.6775	Cost: 6.12s
Train Epoch: 1124 [40960/90000 (45%)]	Loss: 7.8942	Cost: 6.14s
Train Epoch: 1124 [61440/90000 (68%)]	Loss: 7.6580	Cost: 5.88s
Train Epoch: 1124 [81920/90000 (91%)]	Loss: 7.7505	Cost: 5.76s
Train Epoch: 1124 	Average Loss: 8.7358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1232

Learning rate: 0.00019383000255031852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1125 [0/90000 (0%)]	Loss: 21.7060	Cost: 20.19s
Train Epoch: 1125 [20480/90000 (23%)]	Loss: 7.5206	Cost: 6.06s
Train Epoch: 1125 [40960/90000 (45%)]	Loss: 7.4806	Cost: 6.66s
Train Epoch: 1125 [61440/90000 (68%)]	Loss: 7.7017	Cost: 5.84s
Train Epoch: 1125 [81920/90000 (91%)]	Loss: 7.5236	Cost: 6.18s
Train Epoch: 1125 	Average Loss: 8.5497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1100

Learning rate: 0.00019381913359224807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1126 [0/90000 (0%)]	Loss: 21.7592	Cost: 21.41s
Train Epoch: 1126 [20480/90000 (23%)]	Loss: 7.4466	Cost: 6.24s
Train Epoch: 1126 [40960/90000 (45%)]	Loss: 7.5476	Cost: 6.37s
Train Epoch: 1126 [61440/90000 (68%)]	Loss: 7.4720	Cost: 5.89s
Train Epoch: 1126 [81920/90000 (91%)]	Loss: 7.5472	Cost: 5.94s
Train Epoch: 1126 	Average Loss: 8.5316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0839

Learning rate: 0.00019380825537460033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1127 [0/90000 (0%)]	Loss: 21.7989	Cost: 21.36s
Train Epoch: 1127 [20480/90000 (23%)]	Loss: 7.6634	Cost: 6.03s
Train Epoch: 1127 [40960/90000 (45%)]	Loss: 7.7802	Cost: 6.29s
Train Epoch: 1127 [61440/90000 (68%)]	Loss: 7.7509	Cost: 5.90s
Train Epoch: 1127 [81920/90000 (91%)]	Loss: 7.6986	Cost: 5.67s
Train Epoch: 1127 	Average Loss: 8.5748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2094

Learning rate: 0.00019379736789844898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1128 [0/90000 (0%)]	Loss: 21.7615	Cost: 20.93s
Train Epoch: 1128 [20480/90000 (23%)]	Loss: 7.6568	Cost: 6.11s
Train Epoch: 1128 [40960/90000 (45%)]	Loss: 7.7998	Cost: 6.49s
Train Epoch: 1128 [61440/90000 (68%)]	Loss: 7.7078	Cost: 5.87s
Train Epoch: 1128 [81920/90000 (91%)]	Loss: 7.9191	Cost: 5.75s
Train Epoch: 1128 	Average Loss: 8.7142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1207

Learning rate: 0.00019378647116486856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1129 [0/90000 (0%)]	Loss: 21.7385	Cost: 21.52s
Train Epoch: 1129 [20480/90000 (23%)]	Loss: 7.6734	Cost: 5.96s
Train Epoch: 1129 [40960/90000 (45%)]	Loss: 7.6780	Cost: 6.73s
Train Epoch: 1129 [61440/90000 (68%)]	Loss: 7.5082	Cost: 5.89s
Train Epoch: 1129 [81920/90000 (91%)]	Loss: 7.6533	Cost: 5.99s
Train Epoch: 1129 	Average Loss: 8.6259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1057

Learning rate: 0.0001937755651749345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1130 [0/90000 (0%)]	Loss: 22.0976	Cost: 20.14s
Train Epoch: 1130 [20480/90000 (23%)]	Loss: 7.4885	Cost: 6.01s
Train Epoch: 1130 [40960/90000 (45%)]	Loss: 7.6092	Cost: 6.08s
Train Epoch: 1130 [61440/90000 (68%)]	Loss: 7.5131	Cost: 5.89s
Train Epoch: 1130 [81920/90000 (91%)]	Loss: 7.6311	Cost: 5.79s
Train Epoch: 1130 	Average Loss: 8.5242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1823

Learning rate: 0.0001937646499297232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1131 [0/90000 (0%)]	Loss: 21.8068	Cost: 20.51s
Train Epoch: 1131 [20480/90000 (23%)]	Loss: 7.3295	Cost: 6.02s
Train Epoch: 1131 [40960/90000 (45%)]	Loss: 7.5357	Cost: 6.07s
Train Epoch: 1131 [61440/90000 (68%)]	Loss: 7.2753	Cost: 5.88s
Train Epoch: 1131 [81920/90000 (91%)]	Loss: 7.5109	Cost: 5.79s
Train Epoch: 1131 	Average Loss: 8.4392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1810

Learning rate: 0.000193753725430312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1132 [0/90000 (0%)]	Loss: 21.8948	Cost: 21.60s
Train Epoch: 1132 [20480/90000 (23%)]	Loss: 7.5105	Cost: 6.09s
Train Epoch: 1132 [40960/90000 (45%)]	Loss: 7.4632	Cost: 6.76s
Train Epoch: 1132 [61440/90000 (68%)]	Loss: 7.4725	Cost: 5.89s
Train Epoch: 1132 [81920/90000 (91%)]	Loss: 7.4438	Cost: 6.18s
Train Epoch: 1132 	Average Loss: 8.4164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1820

Learning rate: 0.00019374279167777905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1133 [0/90000 (0%)]	Loss: 21.9853	Cost: 20.77s
Train Epoch: 1133 [20480/90000 (23%)]	Loss: 7.6076	Cost: 6.02s
Train Epoch: 1133 [40960/90000 (45%)]	Loss: 7.4883	Cost: 6.31s
Train Epoch: 1133 [61440/90000 (68%)]	Loss: 7.3163	Cost: 5.97s
Train Epoch: 1133 [81920/90000 (91%)]	Loss: 7.5082	Cost: 6.12s
Train Epoch: 1133 	Average Loss: 8.4304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2083

Learning rate: 0.00019373184867320348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1134 [0/90000 (0%)]	Loss: 21.8786	Cost: 21.71s
Train Epoch: 1134 [20480/90000 (23%)]	Loss: 7.5803	Cost: 6.24s
Train Epoch: 1134 [40960/90000 (45%)]	Loss: 7.4225	Cost: 6.92s
Train Epoch: 1134 [61440/90000 (68%)]	Loss: 7.4828	Cost: 6.03s
Train Epoch: 1134 [81920/90000 (91%)]	Loss: 7.5547	Cost: 6.54s
Train Epoch: 1134 	Average Loss: 8.4656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2658

Learning rate: 0.00019372089641766534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1135 [0/90000 (0%)]	Loss: 21.8868	Cost: 24.66s
Train Epoch: 1135 [20480/90000 (23%)]	Loss: 7.6936	Cost: 5.94s
Train Epoch: 1135 [40960/90000 (45%)]	Loss: 7.5197	Cost: 6.27s
Train Epoch: 1135 [61440/90000 (68%)]	Loss: 7.3953	Cost: 5.94s
Train Epoch: 1135 [81920/90000 (91%)]	Loss: 7.3881	Cost: 5.79s
Train Epoch: 1135 	Average Loss: 8.5302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2743

Learning rate: 0.00019370993491224555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1136 [0/90000 (0%)]	Loss: 21.9613	Cost: 24.15s
Train Epoch: 1136 [20480/90000 (23%)]	Loss: 7.3999	Cost: 6.07s
Train Epoch: 1136 [40960/90000 (45%)]	Loss: 7.5199	Cost: 6.73s
Train Epoch: 1136 [61440/90000 (68%)]	Loss: 7.5215	Cost: 5.90s
Train Epoch: 1136 [81920/90000 (91%)]	Loss: 7.3397	Cost: 6.09s
Train Epoch: 1136 	Average Loss: 8.4377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2326

Learning rate: 0.00019369896415802597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1137 [0/90000 (0%)]	Loss: 21.9680	Cost: 24.39s
Train Epoch: 1137 [20480/90000 (23%)]	Loss: 7.4876	Cost: 6.16s
Train Epoch: 1137 [40960/90000 (45%)]	Loss: 7.3626	Cost: 6.21s
Train Epoch: 1137 [61440/90000 (68%)]	Loss: 7.3634	Cost: 5.88s
Train Epoch: 1137 [81920/90000 (91%)]	Loss: 7.3618	Cost: 5.82s
Train Epoch: 1137 	Average Loss: 8.4048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3085

Learning rate: 0.0001936879841560894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1138 [0/90000 (0%)]	Loss: 21.8505	Cost: 23.78s
Train Epoch: 1138 [20480/90000 (23%)]	Loss: 7.3844	Cost: 6.06s
Train Epoch: 1138 [40960/90000 (45%)]	Loss: 7.5809	Cost: 6.15s
Train Epoch: 1138 [61440/90000 (68%)]	Loss: 7.4803	Cost: 5.88s
Train Epoch: 1138 [81920/90000 (91%)]	Loss: 7.4774	Cost: 5.72s
Train Epoch: 1138 	Average Loss: 8.5123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2736

Learning rate: 0.00019367699490751948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1139 [0/90000 (0%)]	Loss: 21.8773	Cost: 23.82s
Train Epoch: 1139 [20480/90000 (23%)]	Loss: 7.4982	Cost: 6.08s
Train Epoch: 1139 [40960/90000 (45%)]	Loss: 7.3937	Cost: 6.42s
Train Epoch: 1139 [61440/90000 (68%)]	Loss: 7.2880	Cost: 5.93s
Train Epoch: 1139 [81920/90000 (91%)]	Loss: 7.5873	Cost: 5.79s
Train Epoch: 1139 	Average Loss: 8.4542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2158

Learning rate: 0.0001936659964134008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1140 [0/90000 (0%)]	Loss: 21.8749	Cost: 23.58s
Train Epoch: 1140 [20480/90000 (23%)]	Loss: 7.4581	Cost: 6.17s
Train Epoch: 1140 [40960/90000 (45%)]	Loss: 7.4982	Cost: 6.54s
Train Epoch: 1140 [61440/90000 (68%)]	Loss: 7.5265	Cost: 5.94s
Train Epoch: 1140 [81920/90000 (91%)]	Loss: 7.5957	Cost: 5.81s
Train Epoch: 1140 	Average Loss: 8.4537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3435

Learning rate: 0.0001936549886748189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1141 [0/90000 (0%)]	Loss: 21.6923	Cost: 21.27s
Train Epoch: 1141 [20480/90000 (23%)]	Loss: 7.4695	Cost: 6.17s
Train Epoch: 1141 [40960/90000 (45%)]	Loss: 7.5358	Cost: 6.16s
Train Epoch: 1141 [61440/90000 (68%)]	Loss: 7.4153	Cost: 5.98s
Train Epoch: 1141 [81920/90000 (91%)]	Loss: 7.6046	Cost: 6.14s
Train Epoch: 1141 	Average Loss: 8.4699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2636

Learning rate: 0.00019364397169286022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1142 [0/90000 (0%)]	Loss: 21.9565	Cost: 21.78s
Train Epoch: 1142 [20480/90000 (23%)]	Loss: 7.4030	Cost: 6.19s
Train Epoch: 1142 [40960/90000 (45%)]	Loss: 7.1919	Cost: 6.46s
Train Epoch: 1142 [61440/90000 (68%)]	Loss: 7.2725	Cost: 5.97s
Train Epoch: 1142 [81920/90000 (91%)]	Loss: 7.2484	Cost: 5.82s
Train Epoch: 1142 	Average Loss: 8.3631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3243

Learning rate: 0.00019363294546861204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1143 [0/90000 (0%)]	Loss: 22.1489	Cost: 21.00s
Train Epoch: 1143 [20480/90000 (23%)]	Loss: 7.4034	Cost: 6.28s
Train Epoch: 1143 [40960/90000 (45%)]	Loss: 7.4660	Cost: 6.20s
Train Epoch: 1143 [61440/90000 (68%)]	Loss: 7.3420	Cost: 6.00s
Train Epoch: 1143 [81920/90000 (91%)]	Loss: 7.3718	Cost: 5.84s
Train Epoch: 1143 	Average Loss: 8.4873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2657

Learning rate: 0.00019362191000316264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1144 [0/90000 (0%)]	Loss: 21.8782	Cost: 20.45s
Train Epoch: 1144 [20480/90000 (23%)]	Loss: 7.4643	Cost: 6.14s
Train Epoch: 1144 [40960/90000 (45%)]	Loss: 7.3565	Cost: 6.77s
Train Epoch: 1144 [61440/90000 (68%)]	Loss: 7.3747	Cost: 6.00s
Train Epoch: 1144 [81920/90000 (91%)]	Loss: 7.2890	Cost: 6.31s
Train Epoch: 1144 	Average Loss: 8.4181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3153

Learning rate: 0.0001936108652976012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1145 [0/90000 (0%)]	Loss: 21.8307	Cost: 20.59s
Train Epoch: 1145 [20480/90000 (23%)]	Loss: 7.8654	Cost: 5.94s
Train Epoch: 1145 [40960/90000 (45%)]	Loss: 7.7305	Cost: 6.72s
Train Epoch: 1145 [61440/90000 (68%)]	Loss: 7.7726	Cost: 6.09s
Train Epoch: 1145 [81920/90000 (91%)]	Loss: 7.8825	Cost: 6.00s
Train Epoch: 1145 	Average Loss: 8.7117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2542

Learning rate: 0.0001935998113530177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1146 [0/90000 (0%)]	Loss: 21.9572	Cost: 20.43s
Train Epoch: 1146 [20480/90000 (23%)]	Loss: 7.7788	Cost: 6.04s
Train Epoch: 1146 [40960/90000 (45%)]	Loss: 7.6524	Cost: 6.50s
Train Epoch: 1146 [61440/90000 (68%)]	Loss: 7.5019	Cost: 6.22s
Train Epoch: 1146 [81920/90000 (91%)]	Loss: 7.5820	Cost: 6.72s
Train Epoch: 1146 	Average Loss: 8.6050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2471

Learning rate: 0.0001935887481705032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1147 [0/90000 (0%)]	Loss: 21.9435	Cost: 19.85s
Train Epoch: 1147 [20480/90000 (23%)]	Loss: 7.4576	Cost: 6.06s
Train Epoch: 1147 [40960/90000 (45%)]	Loss: 7.4130	Cost: 6.06s
Train Epoch: 1147 [61440/90000 (68%)]	Loss: 7.4094	Cost: 5.93s
Train Epoch: 1147 [81920/90000 (91%)]	Loss: 7.3710	Cost: 6.64s
Train Epoch: 1147 	Average Loss: 8.4506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3365

Learning rate: 0.00019357767575114954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1148 [0/90000 (0%)]	Loss: 21.8997	Cost: 21.10s
Train Epoch: 1148 [20480/90000 (23%)]	Loss: 7.4637	Cost: 5.97s
Train Epoch: 1148 [40960/90000 (45%)]	Loss: 7.4466	Cost: 6.10s
Train Epoch: 1148 [61440/90000 (68%)]	Loss: 7.4629	Cost: 5.91s
Train Epoch: 1148 [81920/90000 (91%)]	Loss: 7.3777	Cost: 5.87s
Train Epoch: 1148 	Average Loss: 8.4355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3087

Learning rate: 0.0001935665940960496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1149 [0/90000 (0%)]	Loss: 22.1162	Cost: 19.99s
Train Epoch: 1149 [20480/90000 (23%)]	Loss: 7.3941	Cost: 6.25s
Train Epoch: 1149 [40960/90000 (45%)]	Loss: 7.8489	Cost: 5.99s
Train Epoch: 1149 [61440/90000 (68%)]	Loss: 7.7915	Cost: 5.90s
Train Epoch: 1149 [81920/90000 (91%)]	Loss: 7.7134	Cost: 5.85s
Train Epoch: 1149 	Average Loss: 8.5358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2881

Learning rate: 0.000193555503206297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1150 [0/90000 (0%)]	Loss: 22.0509	Cost: 20.57s
Train Epoch: 1150 [20480/90000 (23%)]	Loss: 7.8056	Cost: 6.10s
Train Epoch: 1150 [40960/90000 (45%)]	Loss: 7.6795	Cost: 6.13s
Train Epoch: 1150 [61440/90000 (68%)]	Loss: 7.5240	Cost: 5.86s
Train Epoch: 1150 [81920/90000 (91%)]	Loss: 7.5917	Cost: 5.76s
Train Epoch: 1150 	Average Loss: 8.5737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3198

Learning rate: 0.00019354440308298645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1151 [0/90000 (0%)]	Loss: 21.8714	Cost: 20.36s
Train Epoch: 1151 [20480/90000 (23%)]	Loss: 8.0097	Cost: 6.11s
Train Epoch: 1151 [40960/90000 (45%)]	Loss: 7.8880	Cost: 6.22s
Train Epoch: 1151 [61440/90000 (68%)]	Loss: 7.6519	Cost: 5.86s
Train Epoch: 1151 [81920/90000 (91%)]	Loss: 7.5977	Cost: 5.76s
Train Epoch: 1151 	Average Loss: 8.7708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1604

Learning rate: 0.00019353329372721341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1152 [0/90000 (0%)]	Loss: 21.8857	Cost: 20.78s
Train Epoch: 1152 [20480/90000 (23%)]	Loss: 7.5188	Cost: 6.09s
Train Epoch: 1152 [40960/90000 (45%)]	Loss: 7.4192	Cost: 6.10s
Train Epoch: 1152 [61440/90000 (68%)]	Loss: 7.1762	Cost: 5.92s
Train Epoch: 1152 [81920/90000 (91%)]	Loss: 7.3717	Cost: 5.72s
Train Epoch: 1152 	Average Loss: 8.4418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3308

Learning rate: 0.0001935221751400744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1153 [0/90000 (0%)]	Loss: 21.8174	Cost: 19.83s
Train Epoch: 1153 [20480/90000 (23%)]	Loss: 7.4961	Cost: 6.13s
Train Epoch: 1153 [40960/90000 (45%)]	Loss: 7.3635	Cost: 6.55s
Train Epoch: 1153 [61440/90000 (68%)]	Loss: 7.1528	Cost: 5.94s
Train Epoch: 1153 [81920/90000 (91%)]	Loss: 7.1798	Cost: 5.81s
Train Epoch: 1153 	Average Loss: 8.3667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2653

Learning rate: 0.00019351104732266675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1154 [0/90000 (0%)]	Loss: 22.0358	Cost: 21.08s
Train Epoch: 1154 [20480/90000 (23%)]	Loss: 7.3885	Cost: 6.17s
Train Epoch: 1154 [40960/90000 (45%)]	Loss: 7.2537	Cost: 6.53s
Train Epoch: 1154 [61440/90000 (68%)]	Loss: 7.0359	Cost: 5.84s
Train Epoch: 1154 [81920/90000 (91%)]	Loss: 7.1310	Cost: 5.99s
Train Epoch: 1154 	Average Loss: 8.2420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3537

Learning rate: 0.00019349991027608872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1155 [0/90000 (0%)]	Loss: 22.2290	Cost: 20.47s
Train Epoch: 1155 [20480/90000 (23%)]	Loss: 7.1900	Cost: 6.09s
Train Epoch: 1155 [40960/90000 (45%)]	Loss: 7.2201	Cost: 6.17s
Train Epoch: 1155 [61440/90000 (68%)]	Loss: 6.9214	Cost: 5.92s
Train Epoch: 1155 [81920/90000 (91%)]	Loss: 7.3259	Cost: 5.84s
Train Epoch: 1155 	Average Loss: 8.1999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3296

Learning rate: 0.0001934887640014395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1156 [0/90000 (0%)]	Loss: 22.0632	Cost: 21.46s
Train Epoch: 1156 [20480/90000 (23%)]	Loss: 7.3188	Cost: 6.03s
Train Epoch: 1156 [40960/90000 (45%)]	Loss: 7.3485	Cost: 6.27s
Train Epoch: 1156 [61440/90000 (68%)]	Loss: 7.1384	Cost: 5.86s
Train Epoch: 1156 [81920/90000 (91%)]	Loss: 7.3143	Cost: 5.76s
Train Epoch: 1156 	Average Loss: 8.3175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4089

Learning rate: 0.00019347760849981922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1157 [0/90000 (0%)]	Loss: 21.9136	Cost: 20.89s
Train Epoch: 1157 [20480/90000 (23%)]	Loss: 7.3094	Cost: 6.11s
Train Epoch: 1157 [40960/90000 (45%)]	Loss: 7.2866	Cost: 6.33s
Train Epoch: 1157 [61440/90000 (68%)]	Loss: 7.3421	Cost: 5.89s
Train Epoch: 1157 [81920/90000 (91%)]	Loss: 7.3570	Cost: 5.79s
Train Epoch: 1157 	Average Loss: 8.2933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4608

Learning rate: 0.00019346644377232883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1158 [0/90000 (0%)]	Loss: 21.7367	Cost: 22.27s
Train Epoch: 1158 [20480/90000 (23%)]	Loss: 7.3011	Cost: 6.05s
Train Epoch: 1158 [40960/90000 (45%)]	Loss: 7.3567	Cost: 6.08s
Train Epoch: 1158 [61440/90000 (68%)]	Loss: 7.3170	Cost: 6.07s
Train Epoch: 1158 [81920/90000 (91%)]	Loss: 7.4808	Cost: 5.75s
Train Epoch: 1158 	Average Loss: 8.3923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4092

Learning rate: 0.0001934552698200703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1159 [0/90000 (0%)]	Loss: 22.1732	Cost: 20.44s
Train Epoch: 1159 [20480/90000 (23%)]	Loss: 7.4073	Cost: 6.12s
Train Epoch: 1159 [40960/90000 (45%)]	Loss: 7.3409	Cost: 6.13s
Train Epoch: 1159 [61440/90000 (68%)]	Loss: 7.2358	Cost: 5.88s
Train Epoch: 1159 [81920/90000 (91%)]	Loss: 7.1991	Cost: 5.78s
Train Epoch: 1159 	Average Loss: 8.3123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4688

Learning rate: 0.0001934440866441464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1160 [0/90000 (0%)]	Loss: 21.8568	Cost: 22.02s
Train Epoch: 1160 [20480/90000 (23%)]	Loss: 7.3672	Cost: 5.99s
Train Epoch: 1160 [40960/90000 (45%)]	Loss: 7.4072	Cost: 6.61s
Train Epoch: 1160 [61440/90000 (68%)]	Loss: 7.0874	Cost: 5.89s
Train Epoch: 1160 [81920/90000 (91%)]	Loss: 7.1726	Cost: 6.10s
Train Epoch: 1160 	Average Loss: 8.2198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3650

Learning rate: 0.0001934328942456609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1161 [0/90000 (0%)]	Loss: 22.2071	Cost: 20.33s
Train Epoch: 1161 [20480/90000 (23%)]	Loss: 7.2582	Cost: 6.18s
Train Epoch: 1161 [40960/90000 (45%)]	Loss: 7.0441	Cost: 6.59s
Train Epoch: 1161 [61440/90000 (68%)]	Loss: 7.1418	Cost: 5.94s
Train Epoch: 1161 [81920/90000 (91%)]	Loss: 7.1590	Cost: 5.85s
Train Epoch: 1161 	Average Loss: 8.1800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4894

Learning rate: 0.0001934216926257184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1162 [0/90000 (0%)]	Loss: 22.2263	Cost: 20.88s
Train Epoch: 1162 [20480/90000 (23%)]	Loss: 7.0006	Cost: 6.10s
Train Epoch: 1162 [40960/90000 (45%)]	Loss: 7.1800	Cost: 6.50s
Train Epoch: 1162 [61440/90000 (68%)]	Loss: 7.0701	Cost: 5.90s
Train Epoch: 1162 [81920/90000 (91%)]	Loss: 7.0880	Cost: 5.82s
Train Epoch: 1162 	Average Loss: 8.1664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4010

Learning rate: 0.0001934104817854245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1163 [0/90000 (0%)]	Loss: 22.2088	Cost: 21.15s
Train Epoch: 1163 [20480/90000 (23%)]	Loss: 7.3124	Cost: 6.04s
Train Epoch: 1163 [40960/90000 (45%)]	Loss: 7.3981	Cost: 6.18s
Train Epoch: 1163 [61440/90000 (68%)]	Loss: 7.3251	Cost: 5.90s
Train Epoch: 1163 [81920/90000 (91%)]	Loss: 7.1717	Cost: 5.82s
Train Epoch: 1163 	Average Loss: 8.2707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4244

Learning rate: 0.00019339926172588564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1164 [0/90000 (0%)]	Loss: 22.2583	Cost: 21.91s
Train Epoch: 1164 [20480/90000 (23%)]	Loss: 7.0094	Cost: 6.02s
Train Epoch: 1164 [40960/90000 (45%)]	Loss: 7.2762	Cost: 6.58s
Train Epoch: 1164 [61440/90000 (68%)]	Loss: 6.9038	Cost: 5.91s
Train Epoch: 1164 [81920/90000 (91%)]	Loss: 7.3374	Cost: 6.04s
Train Epoch: 1164 	Average Loss: 8.2076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4548

Learning rate: 0.00019338803244820925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1165 [0/90000 (0%)]	Loss: 22.0207	Cost: 22.03s
Train Epoch: 1165 [20480/90000 (23%)]	Loss: 7.2246	Cost: 6.12s
Train Epoch: 1165 [40960/90000 (45%)]	Loss: 7.2110	Cost: 6.06s
Train Epoch: 1165 [61440/90000 (68%)]	Loss: 7.3388	Cost: 6.02s
Train Epoch: 1165 [81920/90000 (91%)]	Loss: 7.2973	Cost: 5.85s
Train Epoch: 1165 	Average Loss: 8.2911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3723

Learning rate: 0.00019337679395350357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1166 [0/90000 (0%)]	Loss: 21.9704	Cost: 25.89s
Train Epoch: 1166 [20480/90000 (23%)]	Loss: 7.3829	Cost: 6.05s
Train Epoch: 1166 [40960/90000 (45%)]	Loss: 7.2652	Cost: 6.10s
Train Epoch: 1166 [61440/90000 (68%)]	Loss: 7.1385	Cost: 5.92s
Train Epoch: 1166 [81920/90000 (91%)]	Loss: 7.3773	Cost: 5.88s
Train Epoch: 1166 	Average Loss: 8.3180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4785

Learning rate: 0.00019336554624287778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1167 [0/90000 (0%)]	Loss: 22.2485	Cost: 23.19s
Train Epoch: 1167 [20480/90000 (23%)]	Loss: 7.0933	Cost: 6.07s
Train Epoch: 1167 [40960/90000 (45%)]	Loss: 7.3268	Cost: 6.15s
Train Epoch: 1167 [61440/90000 (68%)]	Loss: 7.7088	Cost: 6.10s
Train Epoch: 1167 [81920/90000 (91%)]	Loss: 7.5666	Cost: 5.76s
Train Epoch: 1167 	Average Loss: 8.4276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3499

Learning rate: 0.00019335428931744204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1168 [0/90000 (0%)]	Loss: 22.1217	Cost: 23.71s
Train Epoch: 1168 [20480/90000 (23%)]	Loss: 7.4637	Cost: 6.05s
Train Epoch: 1168 [40960/90000 (45%)]	Loss: 7.6058	Cost: 6.73s
Train Epoch: 1168 [61440/90000 (68%)]	Loss: 7.3343	Cost: 5.87s
Train Epoch: 1168 [81920/90000 (91%)]	Loss: 7.2687	Cost: 5.95s
Train Epoch: 1168 	Average Loss: 8.4648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3682

Learning rate: 0.0001933430231783073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1169 [0/90000 (0%)]	Loss: 22.0915	Cost: 22.99s
Train Epoch: 1169 [20480/90000 (23%)]	Loss: 7.2550	Cost: 7.04s
Train Epoch: 1169 [40960/90000 (45%)]	Loss: 7.2453	Cost: 6.34s
Train Epoch: 1169 [61440/90000 (68%)]	Loss: 6.8923	Cost: 5.86s
Train Epoch: 1169 [81920/90000 (91%)]	Loss: 7.2832	Cost: 5.92s
Train Epoch: 1169 	Average Loss: 8.2245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4225

Learning rate: 0.00019333174782658552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1170 [0/90000 (0%)]	Loss: 22.1195	Cost: 23.56s
Train Epoch: 1170 [20480/90000 (23%)]	Loss: 6.9406	Cost: 6.05s
Train Epoch: 1170 [40960/90000 (45%)]	Loss: 7.1906	Cost: 6.17s
Train Epoch: 1170 [61440/90000 (68%)]	Loss: 6.9658	Cost: 5.96s
Train Epoch: 1170 [81920/90000 (91%)]	Loss: 6.9520	Cost: 5.82s
Train Epoch: 1170 	Average Loss: 8.1169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4110

Learning rate: 0.0001933204632633895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1171 [0/90000 (0%)]	Loss: 22.4678	Cost: 21.63s
Train Epoch: 1171 [20480/90000 (23%)]	Loss: 7.1507	Cost: 6.18s
Train Epoch: 1171 [40960/90000 (45%)]	Loss: 7.0184	Cost: 6.63s
Train Epoch: 1171 [61440/90000 (68%)]	Loss: 6.9276	Cost: 5.89s
Train Epoch: 1171 [81920/90000 (91%)]	Loss: 6.8354	Cost: 6.49s
Train Epoch: 1171 	Average Loss: 8.0430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4458

Learning rate: 0.00019330916948983305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1172 [0/90000 (0%)]	Loss: 22.1438	Cost: 21.23s
Train Epoch: 1172 [20480/90000 (23%)]	Loss: 7.0027	Cost: 6.16s
Train Epoch: 1172 [40960/90000 (45%)]	Loss: 7.0883	Cost: 6.41s
Train Epoch: 1172 [61440/90000 (68%)]	Loss: 6.9458	Cost: 5.93s
Train Epoch: 1172 [81920/90000 (91%)]	Loss: 7.0107	Cost: 5.90s
Train Epoch: 1172 	Average Loss: 8.0183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5123

Learning rate: 0.00019329786650703075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1173 [0/90000 (0%)]	Loss: 22.2591	Cost: 21.05s
Train Epoch: 1173 [20480/90000 (23%)]	Loss: 7.1136	Cost: 6.17s
Train Epoch: 1173 [40960/90000 (45%)]	Loss: 7.1435	Cost: 6.63s
Train Epoch: 1173 [61440/90000 (68%)]	Loss: 6.9129	Cost: 6.03s
Train Epoch: 1173 [81920/90000 (91%)]	Loss: 7.0008	Cost: 5.82s
Train Epoch: 1173 	Average Loss: 8.0920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4832

Learning rate: 0.00019328655431609818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1174 [0/90000 (0%)]	Loss: 22.2231	Cost: 21.43s
Train Epoch: 1174 [20480/90000 (23%)]	Loss: 6.8598	Cost: 6.06s
Train Epoch: 1174 [40960/90000 (45%)]	Loss: 7.0473	Cost: 6.45s
Train Epoch: 1174 [61440/90000 (68%)]	Loss: 6.8767	Cost: 5.83s
Train Epoch: 1174 [81920/90000 (91%)]	Loss: 6.9676	Cost: 6.14s
Train Epoch: 1174 	Average Loss: 8.0266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5850

Learning rate: 0.00019327523291815183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1175 [0/90000 (0%)]	Loss: 22.1949	Cost: 20.14s
Train Epoch: 1175 [20480/90000 (23%)]	Loss: 6.8526	Cost: 6.06s
Train Epoch: 1175 [40960/90000 (45%)]	Loss: 7.1449	Cost: 7.06s
Train Epoch: 1175 [61440/90000 (68%)]	Loss: 7.0274	Cost: 5.85s
Train Epoch: 1175 [81920/90000 (91%)]	Loss: 7.0876	Cost: 6.51s
Train Epoch: 1175 	Average Loss: 8.1131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4383

Learning rate: 0.00019326390231430904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1176 [0/90000 (0%)]	Loss: 22.2388	Cost: 20.94s
Train Epoch: 1176 [20480/90000 (23%)]	Loss: 6.9870	Cost: 6.00s
Train Epoch: 1176 [40960/90000 (45%)]	Loss: 7.0202	Cost: 6.48s
Train Epoch: 1176 [61440/90000 (68%)]	Loss: 6.9128	Cost: 6.05s
Train Epoch: 1176 [81920/90000 (91%)]	Loss: 7.0398	Cost: 6.33s
Train Epoch: 1176 	Average Loss: 8.0422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5214

Learning rate: 0.00019325256250568812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1177 [0/90000 (0%)]	Loss: 22.2286	Cost: 19.95s
Train Epoch: 1177 [20480/90000 (23%)]	Loss: 6.8454	Cost: 6.02s
Train Epoch: 1177 [40960/90000 (45%)]	Loss: 7.0016	Cost: 6.05s
Train Epoch: 1177 [61440/90000 (68%)]	Loss: 6.9581	Cost: 6.01s
Train Epoch: 1177 [81920/90000 (91%)]	Loss: 7.0464	Cost: 6.15s
Train Epoch: 1177 	Average Loss: 8.0296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5012

Learning rate: 0.00019324121349340828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1178 [0/90000 (0%)]	Loss: 22.3310	Cost: 21.49s
Train Epoch: 1178 [20480/90000 (23%)]	Loss: 7.0254	Cost: 6.05s
Train Epoch: 1178 [40960/90000 (45%)]	Loss: 7.3311	Cost: 6.14s
Train Epoch: 1178 [61440/90000 (68%)]	Loss: 7.1511	Cost: 6.05s
Train Epoch: 1178 [81920/90000 (91%)]	Loss: 7.4177	Cost: 5.84s
Train Epoch: 1178 	Average Loss: 8.2341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5425

Learning rate: 0.0001932298552785896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1179 [0/90000 (0%)]	Loss: 22.5258	Cost: 20.29s
Train Epoch: 1179 [20480/90000 (23%)]	Loss: 7.2089	Cost: 6.00s
Train Epoch: 1179 [40960/90000 (45%)]	Loss: 7.3026	Cost: 6.25s
Train Epoch: 1179 [61440/90000 (68%)]	Loss: 7.0142	Cost: 5.92s
Train Epoch: 1179 [81920/90000 (91%)]	Loss: 7.1791	Cost: 5.77s
Train Epoch: 1179 	Average Loss: 8.2368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5586

Learning rate: 0.00019321848786235313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1180 [0/90000 (0%)]	Loss: 22.3805	Cost: 20.15s
Train Epoch: 1180 [20480/90000 (23%)]	Loss: 6.8809	Cost: 6.18s
Train Epoch: 1180 [40960/90000 (45%)]	Loss: 6.9823	Cost: 6.53s
Train Epoch: 1180 [61440/90000 (68%)]	Loss: 6.7359	Cost: 5.89s
Train Epoch: 1180 [81920/90000 (91%)]	Loss: 6.9620	Cost: 6.36s
Train Epoch: 1180 	Average Loss: 8.0120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5678

Learning rate: 0.0001932071112458207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1181 [0/90000 (0%)]	Loss: 22.0477	Cost: 20.24s
Train Epoch: 1181 [20480/90000 (23%)]	Loss: 7.0476	Cost: 6.14s
Train Epoch: 1181 [40960/90000 (45%)]	Loss: 7.0975	Cost: 6.19s
Train Epoch: 1181 [61440/90000 (68%)]	Loss: 6.8750	Cost: 5.96s
Train Epoch: 1181 [81920/90000 (91%)]	Loss: 7.0543	Cost: 5.67s
Train Epoch: 1181 	Average Loss: 8.0244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4623

Learning rate: 0.00019319572543011524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1182 [0/90000 (0%)]	Loss: 22.1480	Cost: 20.65s
Train Epoch: 1182 [20480/90000 (23%)]	Loss: 6.7190	Cost: 6.17s
Train Epoch: 1182 [40960/90000 (45%)]	Loss: 6.7419	Cost: 6.15s
Train Epoch: 1182 [61440/90000 (68%)]	Loss: 6.5234	Cost: 5.92s
Train Epoch: 1182 [81920/90000 (91%)]	Loss: 6.9839	Cost: 5.76s
Train Epoch: 1182 	Average Loss: 7.9125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6620

Learning rate: 0.0001931843304163604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1183 [0/90000 (0%)]	Loss: 22.1239	Cost: 20.11s
Train Epoch: 1183 [20480/90000 (23%)]	Loss: 6.7599	Cost: 6.06s
Train Epoch: 1183 [40960/90000 (45%)]	Loss: 6.8648	Cost: 6.32s
Train Epoch: 1183 [61440/90000 (68%)]	Loss: 6.6985	Cost: 5.88s
Train Epoch: 1183 [81920/90000 (91%)]	Loss: 6.9529	Cost: 5.78s
Train Epoch: 1183 	Average Loss: 7.8914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5905

Learning rate: 0.0001931729262056809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1184 [0/90000 (0%)]	Loss: 21.9597	Cost: 21.10s
Train Epoch: 1184 [20480/90000 (23%)]	Loss: 6.8842	Cost: 6.04s
Train Epoch: 1184 [40960/90000 (45%)]	Loss: 7.0336	Cost: 6.59s
Train Epoch: 1184 [61440/90000 (68%)]	Loss: 6.7804	Cost: 5.88s
Train Epoch: 1184 [81920/90000 (91%)]	Loss: 6.9653	Cost: 5.95s
Train Epoch: 1184 	Average Loss: 7.9587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6214

Learning rate: 0.0001931615127992022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1185 [0/90000 (0%)]	Loss: 22.1854	Cost: 20.28s
Train Epoch: 1185 [20480/90000 (23%)]	Loss: 6.8621	Cost: 6.00s
Train Epoch: 1185 [40960/90000 (45%)]	Loss: 7.0513	Cost: 6.17s
Train Epoch: 1185 [61440/90000 (68%)]	Loss: 6.9146	Cost: 5.97s
Train Epoch: 1185 [81920/90000 (91%)]	Loss: 7.2287	Cost: 5.79s
Train Epoch: 1185 	Average Loss: 8.0585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5970

Learning rate: 0.00019315009019805086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1186 [0/90000 (0%)]	Loss: 22.4952	Cost: 20.38s
Train Epoch: 1186 [20480/90000 (23%)]	Loss: 7.0065	Cost: 6.12s
Train Epoch: 1186 [40960/90000 (45%)]	Loss: 7.2593	Cost: 6.72s
Train Epoch: 1186 [61440/90000 (68%)]	Loss: 7.0578	Cost: 5.89s
Train Epoch: 1186 [81920/90000 (91%)]	Loss: 7.0799	Cost: 5.74s
Train Epoch: 1186 	Average Loss: 8.2142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5459

Learning rate: 0.00019313865840335417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1187 [0/90000 (0%)]	Loss: 22.1688	Cost: 22.51s
Train Epoch: 1187 [20480/90000 (23%)]	Loss: 7.1968	Cost: 5.99s
Train Epoch: 1187 [40960/90000 (45%)]	Loss: 7.1933	Cost: 6.04s
Train Epoch: 1187 [61440/90000 (68%)]	Loss: 6.9857	Cost: 5.92s
Train Epoch: 1187 [81920/90000 (91%)]	Loss: 7.3071	Cost: 5.73s
Train Epoch: 1187 	Average Loss: 8.1882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5479

Learning rate: 0.00019312721741624044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1188 [0/90000 (0%)]	Loss: 22.3091	Cost: 20.52s
Train Epoch: 1188 [20480/90000 (23%)]	Loss: 7.1557	Cost: 6.23s
Train Epoch: 1188 [40960/90000 (45%)]	Loss: 7.2027	Cost: 6.08s
Train Epoch: 1188 [61440/90000 (68%)]	Loss: 6.9662	Cost: 5.74s
Train Epoch: 1188 [81920/90000 (91%)]	Loss: 7.0499	Cost: 5.78s
Train Epoch: 1188 	Average Loss: 8.1968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5754

Learning rate: 0.00019311576723783885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1189 [0/90000 (0%)]	Loss: 22.3376	Cost: 20.59s
Train Epoch: 1189 [20480/90000 (23%)]	Loss: 6.9130	Cost: 6.13s
Train Epoch: 1189 [40960/90000 (45%)]	Loss: 7.2048	Cost: 6.22s
Train Epoch: 1189 [61440/90000 (68%)]	Loss: 6.7109	Cost: 6.10s
Train Epoch: 1189 [81920/90000 (91%)]	Loss: 7.0519	Cost: 5.76s
Train Epoch: 1189 	Average Loss: 8.0048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5078

Learning rate: 0.00019310430786927943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1190 [0/90000 (0%)]	Loss: 22.2679	Cost: 21.84s
Train Epoch: 1190 [20480/90000 (23%)]	Loss: 6.9690	Cost: 6.02s
Train Epoch: 1190 [40960/90000 (45%)]	Loss: 7.0127	Cost: 6.17s
Train Epoch: 1190 [61440/90000 (68%)]	Loss: 6.8539	Cost: 5.87s
Train Epoch: 1190 [81920/90000 (91%)]	Loss: 6.9547	Cost: 5.79s
Train Epoch: 1190 	Average Loss: 7.9710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5777

Learning rate: 0.0001930928393116932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1191 [0/90000 (0%)]	Loss: 22.3788	Cost: 21.28s
Train Epoch: 1191 [20480/90000 (23%)]	Loss: 6.8624	Cost: 6.24s
Train Epoch: 1191 [40960/90000 (45%)]	Loss: 7.0016	Cost: 6.15s
Train Epoch: 1191 [61440/90000 (68%)]	Loss: 6.8456	Cost: 5.96s
Train Epoch: 1191 [81920/90000 (91%)]	Loss: 6.8575	Cost: 5.77s
Train Epoch: 1191 	Average Loss: 7.9881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6824

Learning rate: 0.00019308136156621214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1192 [0/90000 (0%)]	Loss: 22.1604	Cost: 22.00s
Train Epoch: 1192 [20480/90000 (23%)]	Loss: 6.6678	Cost: 5.98s
Train Epoch: 1192 [40960/90000 (45%)]	Loss: 6.9993	Cost: 7.03s
Train Epoch: 1192 [61440/90000 (68%)]	Loss: 6.9424	Cost: 5.91s
Train Epoch: 1192 [81920/90000 (91%)]	Loss: 6.9042	Cost: 6.11s
Train Epoch: 1192 	Average Loss: 7.9707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5392

Learning rate: 0.00019306987463396896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1193 [0/90000 (0%)]	Loss: 22.0060	Cost: 20.67s
Train Epoch: 1193 [20480/90000 (23%)]	Loss: 7.0365	Cost: 6.06s
Train Epoch: 1193 [40960/90000 (45%)]	Loss: 6.9909	Cost: 6.70s
Train Epoch: 1193 [61440/90000 (68%)]	Loss: 6.9468	Cost: 5.87s
Train Epoch: 1193 [81920/90000 (91%)]	Loss: 6.8956	Cost: 6.20s
Train Epoch: 1193 	Average Loss: 7.9653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5896

Learning rate: 0.00019305837851609745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1194 [0/90000 (0%)]	Loss: 22.2738	Cost: 20.96s
Train Epoch: 1194 [20480/90000 (23%)]	Loss: 6.9226	Cost: 6.03s
Train Epoch: 1194 [40960/90000 (45%)]	Loss: 6.9892	Cost: 6.74s
Train Epoch: 1194 [61440/90000 (68%)]	Loss: 6.6658	Cost: 5.88s
Train Epoch: 1194 [81920/90000 (91%)]	Loss: 6.7453	Cost: 5.97s
Train Epoch: 1194 	Average Loss: 7.9119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6476

Learning rate: 0.00019304687321373217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1195 [0/90000 (0%)]	Loss: 22.2966	Cost: 20.58s
Train Epoch: 1195 [20480/90000 (23%)]	Loss: 6.9020	Cost: 6.06s
Train Epoch: 1195 [40960/90000 (45%)]	Loss: 6.7156	Cost: 6.13s
Train Epoch: 1195 [61440/90000 (68%)]	Loss: 6.7492	Cost: 6.03s
Train Epoch: 1195 [81920/90000 (91%)]	Loss: 6.9154	Cost: 5.77s
Train Epoch: 1195 	Average Loss: 7.8715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6472

Learning rate: 0.00019303535872800865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1196 [0/90000 (0%)]	Loss: 22.2564	Cost: 22.32s
Train Epoch: 1196 [20480/90000 (23%)]	Loss: 6.9367	Cost: 6.01s
Train Epoch: 1196 [40960/90000 (45%)]	Loss: 7.0662	Cost: 6.32s
Train Epoch: 1196 [61440/90000 (68%)]	Loss: 6.6482	Cost: 5.95s
Train Epoch: 1196 [81920/90000 (91%)]	Loss: 7.1548	Cost: 5.79s
Train Epoch: 1196 	Average Loss: 7.9691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6317

Learning rate: 0.00019302383506006335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1197 [0/90000 (0%)]	Loss: 22.3974	Cost: 22.56s
Train Epoch: 1197 [20480/90000 (23%)]	Loss: 6.8893	Cost: 5.94s
Train Epoch: 1197 [40960/90000 (45%)]	Loss: 7.1271	Cost: 6.11s
Train Epoch: 1197 [61440/90000 (68%)]	Loss: 6.9889	Cost: 5.98s
Train Epoch: 1197 [81920/90000 (91%)]	Loss: 6.9326	Cost: 5.82s
Train Epoch: 1197 	Average Loss: 8.0469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5964

Learning rate: 0.00019301230221103362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1198 [0/90000 (0%)]	Loss: 22.1969	Cost: 22.57s
Train Epoch: 1198 [20480/90000 (23%)]	Loss: 6.7947	Cost: 5.99s
Train Epoch: 1198 [40960/90000 (45%)]	Loss: 6.9596	Cost: 6.71s
Train Epoch: 1198 [61440/90000 (68%)]	Loss: 6.5785	Cost: 5.91s
Train Epoch: 1198 [81920/90000 (91%)]	Loss: 6.7770	Cost: 6.33s
Train Epoch: 1198 	Average Loss: 7.8759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6699

Learning rate: 0.0001930007601820577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1199 [0/90000 (0%)]	Loss: 22.4589	Cost: 20.96s
Train Epoch: 1199 [20480/90000 (23%)]	Loss: 6.8177	Cost: 6.17s
Train Epoch: 1199 [40960/90000 (45%)]	Loss: 6.9186	Cost: 6.06s
Train Epoch: 1199 [61440/90000 (68%)]	Loss: 6.7472	Cost: 5.95s
Train Epoch: 1199 [81920/90000 (91%)]	Loss: 6.7520	Cost: 6.05s
Train Epoch: 1199 	Average Loss: 7.8304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6413

Learning rate: 0.00019298920897427473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1200 [0/90000 (0%)]	Loss: 22.4054	Cost: 24.70s
Train Epoch: 1200 [20480/90000 (23%)]	Loss: 6.5936	Cost: 5.94s
Train Epoch: 1200 [40960/90000 (45%)]	Loss: 6.8766	Cost: 6.24s
Train Epoch: 1200 [61440/90000 (68%)]	Loss: 6.7366	Cost: 6.06s
Train Epoch: 1200 [81920/90000 (91%)]	Loss: 6.7869	Cost: 5.86s
Train Epoch: 1200 	Average Loss: 7.7796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6177

Learning rate: 0.00019297764858882476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1201 [0/90000 (0%)]	Loss: 22.2304	Cost: 22.46s
Train Epoch: 1201 [20480/90000 (23%)]	Loss: 6.7476	Cost: 6.09s
Train Epoch: 1201 [40960/90000 (45%)]	Loss: 6.9508	Cost: 6.14s
Train Epoch: 1201 [61440/90000 (68%)]	Loss: 6.9674	Cost: 5.91s
Train Epoch: 1201 [81920/90000 (91%)]	Loss: 6.9560	Cost: 5.84s
Train Epoch: 1201 	Average Loss: 7.9180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5840

Learning rate: 0.0001929660790268488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1202 [0/90000 (0%)]	Loss: 22.4679	Cost: 26.68s
Train Epoch: 1202 [20480/90000 (23%)]	Loss: 6.9723	Cost: 6.14s
Train Epoch: 1202 [40960/90000 (45%)]	Loss: 7.2102	Cost: 6.04s
Train Epoch: 1202 [61440/90000 (68%)]	Loss: 7.0563	Cost: 5.86s
Train Epoch: 1202 [81920/90000 (91%)]	Loss: 7.0946	Cost: 5.89s
Train Epoch: 1202 	Average Loss: 8.0555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6696

Learning rate: 0.00019295450028948867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1203 [0/90000 (0%)]	Loss: 22.3038	Cost: 23.89s
Train Epoch: 1203 [20480/90000 (23%)]	Loss: 7.0664	Cost: 6.06s
Train Epoch: 1203 [40960/90000 (45%)]	Loss: 6.9879	Cost: 6.72s
Train Epoch: 1203 [61440/90000 (68%)]	Loss: 6.7749	Cost: 5.95s
Train Epoch: 1203 [81920/90000 (91%)]	Loss: 7.1055	Cost: 5.87s
Train Epoch: 1203 	Average Loss: 7.9610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6255

Learning rate: 0.00019294291237788717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1204 [0/90000 (0%)]	Loss: 22.1982	Cost: 23.54s
Train Epoch: 1204 [20480/90000 (23%)]	Loss: 6.9792	Cost: 6.16s
Train Epoch: 1204 [40960/90000 (45%)]	Loss: 7.1679	Cost: 6.46s
Train Epoch: 1204 [61440/90000 (68%)]	Loss: 7.0215	Cost: 5.85s
Train Epoch: 1204 [81920/90000 (91%)]	Loss: 7.1271	Cost: 5.92s
Train Epoch: 1204 	Average Loss: 8.0302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5886

Learning rate: 0.00019293131529318796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1205 [0/90000 (0%)]	Loss: 22.1529	Cost: 24.37s
Train Epoch: 1205 [20480/90000 (23%)]	Loss: 7.0468	Cost: 6.07s
Train Epoch: 1205 [40960/90000 (45%)]	Loss: 7.1886	Cost: 6.20s
Train Epoch: 1205 [61440/90000 (68%)]	Loss: 6.8071	Cost: 5.91s
Train Epoch: 1205 [81920/90000 (91%)]	Loss: 7.1766	Cost: 5.71s
Train Epoch: 1205 	Average Loss: 8.1023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6340

Learning rate: 0.00019291970903653568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1206 [0/90000 (0%)]	Loss: 22.2667	Cost: 23.49s
Train Epoch: 1206 [20480/90000 (23%)]	Loss: 6.9844	Cost: 6.53s
Train Epoch: 1206 [40960/90000 (45%)]	Loss: 7.3817	Cost: 6.50s
Train Epoch: 1206 [61440/90000 (68%)]	Loss: 7.0578	Cost: 5.93s
Train Epoch: 1206 [81920/90000 (91%)]	Loss: 6.9936	Cost: 6.27s
Train Epoch: 1206 	Average Loss: 8.1226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4709

Learning rate: 0.00019290809360907572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1207 [0/90000 (0%)]	Loss: 22.2314	Cost: 22.59s
Train Epoch: 1207 [20480/90000 (23%)]	Loss: 6.7559	Cost: 5.93s
Train Epoch: 1207 [40960/90000 (45%)]	Loss: 6.8866	Cost: 6.53s
Train Epoch: 1207 [61440/90000 (68%)]	Loss: 6.7783	Cost: 5.98s
Train Epoch: 1207 [81920/90000 (91%)]	Loss: 6.8960	Cost: 6.01s
Train Epoch: 1207 	Average Loss: 7.9076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5744

Learning rate: 0.0001928964690119546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1208 [0/90000 (0%)]	Loss: 22.1866	Cost: 21.33s
Train Epoch: 1208 [20480/90000 (23%)]	Loss: 6.8510	Cost: 7.40s
Train Epoch: 1208 [40960/90000 (45%)]	Loss: 6.8243	Cost: 6.26s
Train Epoch: 1208 [61440/90000 (68%)]	Loss: 6.8127	Cost: 5.97s
Train Epoch: 1208 [81920/90000 (91%)]	Loss: 6.8697	Cost: 6.11s
Train Epoch: 1208 	Average Loss: 7.8654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4935

Learning rate: 0.00019288483524631953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1209 [0/90000 (0%)]	Loss: 22.1956	Cost: 21.72s
Train Epoch: 1209 [20480/90000 (23%)]	Loss: 6.8374	Cost: 6.40s
Train Epoch: 1209 [40960/90000 (45%)]	Loss: 6.9443	Cost: 6.21s
Train Epoch: 1209 [61440/90000 (68%)]	Loss: 6.8748	Cost: 5.91s
Train Epoch: 1209 [81920/90000 (91%)]	Loss: 6.8629	Cost: 5.80s
Train Epoch: 1209 	Average Loss: 7.9326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5886

Learning rate: 0.00019287319231331873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1210 [0/90000 (0%)]	Loss: 22.3124	Cost: 20.78s
Train Epoch: 1210 [20480/90000 (23%)]	Loss: 6.6509	Cost: 6.11s
Train Epoch: 1210 [40960/90000 (45%)]	Loss: 6.7465	Cost: 6.15s
Train Epoch: 1210 [61440/90000 (68%)]	Loss: 6.5219	Cost: 5.97s
Train Epoch: 1210 [81920/90000 (91%)]	Loss: 6.6061	Cost: 5.82s
Train Epoch: 1210 	Average Loss: 7.7638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6065

Learning rate: 0.00019286154021410135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1211 [0/90000 (0%)]	Loss: 22.2640	Cost: 20.59s
Train Epoch: 1211 [20480/90000 (23%)]	Loss: 6.6714	Cost: 6.73s
Train Epoch: 1211 [40960/90000 (45%)]	Loss: 6.5429	Cost: 6.62s
Train Epoch: 1211 [61440/90000 (68%)]	Loss: 6.5488	Cost: 6.14s
Train Epoch: 1211 [81920/90000 (91%)]	Loss: 6.4775	Cost: 5.84s
Train Epoch: 1211 	Average Loss: 7.6696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6643

Learning rate: 0.0001928498789498174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1212 [0/90000 (0%)]	Loss: 22.0955	Cost: 21.62s
Train Epoch: 1212 [20480/90000 (23%)]	Loss: 6.5502	Cost: 6.18s
Train Epoch: 1212 [40960/90000 (45%)]	Loss: 6.7040	Cost: 6.23s
Train Epoch: 1212 [61440/90000 (68%)]	Loss: 6.5255	Cost: 6.06s
Train Epoch: 1212 [81920/90000 (91%)]	Loss: 6.7793	Cost: 6.07s
Train Epoch: 1212 	Average Loss: 7.6959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6658

Learning rate: 0.00019283820852161778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1213 [0/90000 (0%)]	Loss: 22.1970	Cost: 21.21s
Train Epoch: 1213 [20480/90000 (23%)]	Loss: 6.4952	Cost: 6.10s
Train Epoch: 1213 [40960/90000 (45%)]	Loss: 6.6324	Cost: 6.83s
Train Epoch: 1213 [61440/90000 (68%)]	Loss: 6.4370	Cost: 5.93s
Train Epoch: 1213 [81920/90000 (91%)]	Loss: 6.4745	Cost: 5.88s
Train Epoch: 1213 	Average Loss: 7.7124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6281

Learning rate: 0.00019282652893065432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1214 [0/90000 (0%)]	Loss: 22.2919	Cost: 20.62s
Train Epoch: 1214 [20480/90000 (23%)]	Loss: 6.7839	Cost: 6.00s
Train Epoch: 1214 [40960/90000 (45%)]	Loss: 7.1670	Cost: 6.28s
Train Epoch: 1214 [61440/90000 (68%)]	Loss: 7.1758	Cost: 5.98s
Train Epoch: 1214 [81920/90000 (91%)]	Loss: 7.0079	Cost: 5.96s
Train Epoch: 1214 	Average Loss: 8.0177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6386

Learning rate: 0.00019281484017807975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1215 [0/90000 (0%)]	Loss: 22.2242	Cost: 20.47s
Train Epoch: 1215 [20480/90000 (23%)]	Loss: 7.0987	Cost: 6.02s
Train Epoch: 1215 [40960/90000 (45%)]	Loss: 6.9581	Cost: 6.35s
Train Epoch: 1215 [61440/90000 (68%)]	Loss: 6.7037	Cost: 5.99s
Train Epoch: 1215 [81920/90000 (91%)]	Loss: 6.9421	Cost: 6.58s
Train Epoch: 1215 	Average Loss: 7.9814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5941

Learning rate: 0.00019280314226504771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1216 [0/90000 (0%)]	Loss: 22.3062	Cost: 20.78s
Train Epoch: 1216 [20480/90000 (23%)]	Loss: 6.7983	Cost: 6.07s
Train Epoch: 1216 [40960/90000 (45%)]	Loss: 6.8778	Cost: 5.97s
Train Epoch: 1216 [61440/90000 (68%)]	Loss: 6.5799	Cost: 5.94s
Train Epoch: 1216 [81920/90000 (91%)]	Loss: 6.6904	Cost: 5.92s
Train Epoch: 1216 	Average Loss: 7.8416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5771

Learning rate: 0.00019279143519271272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1217 [0/90000 (0%)]	Loss: 22.2483	Cost: 20.40s
Train Epoch: 1217 [20480/90000 (23%)]	Loss: 6.5924	Cost: 6.00s
Train Epoch: 1217 [40960/90000 (45%)]	Loss: 6.7018	Cost: 6.08s
Train Epoch: 1217 [61440/90000 (68%)]	Loss: 6.5941	Cost: 5.85s
Train Epoch: 1217 [81920/90000 (91%)]	Loss: 6.7211	Cost: 5.98s
Train Epoch: 1217 	Average Loss: 7.7331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6808

Learning rate: 0.00019277971896223024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1218 [0/90000 (0%)]	Loss: 22.3603	Cost: 20.37s
Train Epoch: 1218 [20480/90000 (23%)]	Loss: 6.6229	Cost: 6.04s
Train Epoch: 1218 [40960/90000 (45%)]	Loss: 6.5997	Cost: 6.65s
Train Epoch: 1218 [61440/90000 (68%)]	Loss: 6.5166	Cost: 5.85s
Train Epoch: 1218 [81920/90000 (91%)]	Loss: 6.5694	Cost: 6.16s
Train Epoch: 1218 	Average Loss: 7.6205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6799

Learning rate: 0.00019276799357475661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1219 [0/90000 (0%)]	Loss: 22.3205	Cost: 20.96s
Train Epoch: 1219 [20480/90000 (23%)]	Loss: 6.5377	Cost: 6.12s
Train Epoch: 1219 [40960/90000 (45%)]	Loss: 6.4521	Cost: 6.05s
Train Epoch: 1219 [61440/90000 (68%)]	Loss: 6.3262	Cost: 5.77s
Train Epoch: 1219 [81920/90000 (91%)]	Loss: 6.3243	Cost: 5.81s
Train Epoch: 1219 	Average Loss: 7.6040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7508

Learning rate: 0.00019275625903144908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1220 [0/90000 (0%)]	Loss: 22.4139	Cost: 21.33s
Train Epoch: 1220 [20480/90000 (23%)]	Loss: 6.5600	Cost: 6.06s
Train Epoch: 1220 [40960/90000 (45%)]	Loss: 6.6951	Cost: 6.88s
Train Epoch: 1220 [61440/90000 (68%)]	Loss: 6.3999	Cost: 5.94s
Train Epoch: 1220 [81920/90000 (91%)]	Loss: 6.5089	Cost: 5.82s
Train Epoch: 1220 	Average Loss: 7.5735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7381

Learning rate: 0.0001927445153334658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1221 [0/90000 (0%)]	Loss: 22.4883	Cost: 21.31s
Train Epoch: 1221 [20480/90000 (23%)]	Loss: 6.3873	Cost: 5.95s
Train Epoch: 1221 [40960/90000 (45%)]	Loss: 6.6471	Cost: 6.58s
Train Epoch: 1221 [61440/90000 (68%)]	Loss: 6.2026	Cost: 5.83s
Train Epoch: 1221 [81920/90000 (91%)]	Loss: 6.5063	Cost: 6.13s
Train Epoch: 1221 	Average Loss: 7.5023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8113

Learning rate: 0.00019273276248196581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1222 [0/90000 (0%)]	Loss: 22.4760	Cost: 20.55s
Train Epoch: 1222 [20480/90000 (23%)]	Loss: 6.7256	Cost: 6.00s
Train Epoch: 1222 [40960/90000 (45%)]	Loss: 6.4911	Cost: 6.24s
Train Epoch: 1222 [61440/90000 (68%)]	Loss: 6.4788	Cost: 6.14s
Train Epoch: 1222 [81920/90000 (91%)]	Loss: 6.4461	Cost: 5.76s
Train Epoch: 1222 	Average Loss: 7.5998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8598

Learning rate: 0.0001927210004781091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1223 [0/90000 (0%)]	Loss: 22.5198	Cost: 20.48s
Train Epoch: 1223 [20480/90000 (23%)]	Loss: 6.4974	Cost: 6.01s
Train Epoch: 1223 [40960/90000 (45%)]	Loss: 6.7149	Cost: 6.40s
Train Epoch: 1223 [61440/90000 (68%)]	Loss: 6.2806	Cost: 5.92s
Train Epoch: 1223 [81920/90000 (91%)]	Loss: 6.6405	Cost: 5.78s
Train Epoch: 1223 	Average Loss: 7.5864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8547

Learning rate: 0.0001927092293230565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1224 [0/90000 (0%)]	Loss: 22.5959	Cost: 19.95s
Train Epoch: 1224 [20480/90000 (23%)]	Loss: 6.6811	Cost: 6.11s
Train Epoch: 1224 [40960/90000 (45%)]	Loss: 6.5960	Cost: 6.93s
Train Epoch: 1224 [61440/90000 (68%)]	Loss: 6.2483	Cost: 5.91s
Train Epoch: 1224 [81920/90000 (91%)]	Loss: 6.5120	Cost: 5.84s
Train Epoch: 1224 	Average Loss: 7.7040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7510

Learning rate: 0.00019269744901796983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1225 [0/90000 (0%)]	Loss: 22.3281	Cost: 20.71s
Train Epoch: 1225 [20480/90000 (23%)]	Loss: 6.5094	Cost: 6.15s
Train Epoch: 1225 [40960/90000 (45%)]	Loss: 6.5814	Cost: 6.56s
Train Epoch: 1225 [61440/90000 (68%)]	Loss: 6.3919	Cost: 5.89s
Train Epoch: 1225 [81920/90000 (91%)]	Loss: 6.3131	Cost: 5.78s
Train Epoch: 1225 	Average Loss: 7.5521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8233

Learning rate: 0.0001926856595640117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1226 [0/90000 (0%)]	Loss: 22.3791	Cost: 20.84s
Train Epoch: 1226 [20480/90000 (23%)]	Loss: 6.4249	Cost: 6.06s
Train Epoch: 1226 [40960/90000 (45%)]	Loss: 6.4049	Cost: 6.59s
Train Epoch: 1226 [61440/90000 (68%)]	Loss: 6.2930	Cost: 5.87s
Train Epoch: 1226 [81920/90000 (91%)]	Loss: 6.4412	Cost: 5.89s
Train Epoch: 1226 	Average Loss: 7.4969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9508

Learning rate: 0.00019267386096234575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1227 [0/90000 (0%)]	Loss: 22.3197	Cost: 20.16s
Train Epoch: 1227 [20480/90000 (23%)]	Loss: 6.4988	Cost: 5.99s
Train Epoch: 1227 [40960/90000 (45%)]	Loss: 6.5908	Cost: 6.12s
Train Epoch: 1227 [61440/90000 (68%)]	Loss: 6.3438	Cost: 5.88s
Train Epoch: 1227 [81920/90000 (91%)]	Loss: 6.5560	Cost: 5.79s
Train Epoch: 1227 	Average Loss: 7.5532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9221

Learning rate: 0.0001926620532141364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1228 [0/90000 (0%)]	Loss: 22.6180	Cost: 20.62s
Train Epoch: 1228 [20480/90000 (23%)]	Loss: 6.2869	Cost: 6.10s
Train Epoch: 1228 [40960/90000 (45%)]	Loss: 6.5774	Cost: 6.08s
Train Epoch: 1228 [61440/90000 (68%)]	Loss: 6.2367	Cost: 5.93s
Train Epoch: 1228 [81920/90000 (91%)]	Loss: 6.4482	Cost: 5.77s
Train Epoch: 1228 	Average Loss: 7.5614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8417

Learning rate: 0.00019265023632054903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1229 [0/90000 (0%)]	Loss: 22.5158	Cost: 20.98s
Train Epoch: 1229 [20480/90000 (23%)]	Loss: 6.4155	Cost: 6.04s
Train Epoch: 1229 [40960/90000 (45%)]	Loss: 6.5293	Cost: 6.28s
Train Epoch: 1229 [61440/90000 (68%)]	Loss: 6.3408	Cost: 5.95s
Train Epoch: 1229 [81920/90000 (91%)]	Loss: 6.2900	Cost: 5.87s
Train Epoch: 1229 	Average Loss: 7.4956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8577

Learning rate: 0.00019263841028274996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1230 [0/90000 (0%)]	Loss: 22.7032	Cost: 21.09s
Train Epoch: 1230 [20480/90000 (23%)]	Loss: 6.4112	Cost: 6.06s
Train Epoch: 1230 [40960/90000 (45%)]	Loss: 6.4932	Cost: 6.18s
Train Epoch: 1230 [61440/90000 (68%)]	Loss: 6.2672	Cost: 6.04s
Train Epoch: 1230 [81920/90000 (91%)]	Loss: 6.4085	Cost: 5.81s
Train Epoch: 1230 	Average Loss: 7.5511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8259

Learning rate: 0.0001926265751019063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1231 [0/90000 (0%)]	Loss: 22.4752	Cost: 23.59s
Train Epoch: 1231 [20480/90000 (23%)]	Loss: 6.4525	Cost: 6.05s
Train Epoch: 1231 [40960/90000 (45%)]	Loss: 6.4540	Cost: 6.13s
Train Epoch: 1231 [61440/90000 (68%)]	Loss: 6.2342	Cost: 6.01s
Train Epoch: 1231 [81920/90000 (91%)]	Loss: 6.2719	Cost: 5.84s
Train Epoch: 1231 	Average Loss: 7.5362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8681

Learning rate: 0.00019261473077918618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1232 [0/90000 (0%)]	Loss: 22.5166	Cost: 20.82s
Train Epoch: 1232 [20480/90000 (23%)]	Loss: 6.3076	Cost: 6.05s
Train Epoch: 1232 [40960/90000 (45%)]	Loss: 6.4503	Cost: 6.35s
Train Epoch: 1232 [61440/90000 (68%)]	Loss: 6.0868	Cost: 5.94s
Train Epoch: 1232 [81920/90000 (91%)]	Loss: 6.2608	Cost: 6.28s
Train Epoch: 1232 	Average Loss: 7.4372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0299

Learning rate: 0.00019260287731575864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1233 [0/90000 (0%)]	Loss: 22.5173	Cost: 23.32s
Train Epoch: 1233 [20480/90000 (23%)]	Loss: 6.3068	Cost: 6.02s
Train Epoch: 1233 [40960/90000 (45%)]	Loss: 6.2933	Cost: 6.23s
Train Epoch: 1233 [61440/90000 (68%)]	Loss: 6.2906	Cost: 6.14s
Train Epoch: 1233 [81920/90000 (91%)]	Loss: 6.1397	Cost: 5.85s
Train Epoch: 1233 	Average Loss: 7.4365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9212

Learning rate: 0.0001925910147127935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1234 [0/90000 (0%)]	Loss: 22.4020	Cost: 22.96s
Train Epoch: 1234 [20480/90000 (23%)]	Loss: 6.3732	Cost: 6.11s
Train Epoch: 1234 [40960/90000 (45%)]	Loss: 6.5019	Cost: 6.09s
Train Epoch: 1234 [61440/90000 (68%)]	Loss: 6.3768	Cost: 5.92s
Train Epoch: 1234 [81920/90000 (91%)]	Loss: 6.4795	Cost: 5.91s
Train Epoch: 1234 	Average Loss: 7.5180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8478

Learning rate: 0.00019257914297146156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1235 [0/90000 (0%)]	Loss: 22.5584	Cost: 23.28s
Train Epoch: 1235 [20480/90000 (23%)]	Loss: 6.4554	Cost: 6.11s
Train Epoch: 1235 [40960/90000 (45%)]	Loss: 6.7040	Cost: 6.32s
Train Epoch: 1235 [61440/90000 (68%)]	Loss: 6.4358	Cost: 5.95s
Train Epoch: 1235 [81920/90000 (91%)]	Loss: 6.5350	Cost: 5.94s
Train Epoch: 1235 	Average Loss: 7.6257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8938

Learning rate: 0.00019256726209293456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1236 [0/90000 (0%)]	Loss: 22.5314	Cost: 21.74s
Train Epoch: 1236 [20480/90000 (23%)]	Loss: 6.5562	Cost: 6.05s
Train Epoch: 1236 [40960/90000 (45%)]	Loss: 6.5513	Cost: 6.62s
Train Epoch: 1236 [61440/90000 (68%)]	Loss: 6.2882	Cost: 5.95s
Train Epoch: 1236 [81920/90000 (91%)]	Loss: 6.3688	Cost: 5.82s
Train Epoch: 1236 	Average Loss: 7.6057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8610

Learning rate: 0.00019255537207838502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1237 [0/90000 (0%)]	Loss: 22.2522	Cost: 23.96s
Train Epoch: 1237 [20480/90000 (23%)]	Loss: 6.4026	Cost: 6.10s
Train Epoch: 1237 [40960/90000 (45%)]	Loss: 6.4925	Cost: 6.40s
Train Epoch: 1237 [61440/90000 (68%)]	Loss: 6.1417	Cost: 5.85s
Train Epoch: 1237 [81920/90000 (91%)]	Loss: 6.2517	Cost: 6.05s
Train Epoch: 1237 	Average Loss: 7.5018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8937

Learning rate: 0.0001925434729289865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1238 [0/90000 (0%)]	Loss: 22.4512	Cost: 24.28s
Train Epoch: 1238 [20480/90000 (23%)]	Loss: 6.3619	Cost: 6.12s
Train Epoch: 1238 [40960/90000 (45%)]	Loss: 6.5672	Cost: 6.25s
Train Epoch: 1238 [61440/90000 (68%)]	Loss: 6.3868	Cost: 5.89s
Train Epoch: 1238 [81920/90000 (91%)]	Loss: 6.3563	Cost: 6.22s
Train Epoch: 1238 	Average Loss: 7.4624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9190

Learning rate: 0.00019253156464591338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1239 [0/90000 (0%)]	Loss: 22.6516	Cost: 25.31s
Train Epoch: 1239 [20480/90000 (23%)]	Loss: 6.3209	Cost: 5.97s
Train Epoch: 1239 [40960/90000 (45%)]	Loss: 6.5545	Cost: 6.26s
Train Epoch: 1239 [61440/90000 (68%)]	Loss: 6.2804	Cost: 5.88s
Train Epoch: 1239 [81920/90000 (91%)]	Loss: 6.2544	Cost: 5.85s
Train Epoch: 1239 	Average Loss: 7.4453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8170

Learning rate: 0.00019251964723034095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1240 [0/90000 (0%)]	Loss: 22.3834	Cost: 22.04s
Train Epoch: 1240 [20480/90000 (23%)]	Loss: 6.2787	Cost: 6.06s
Train Epoch: 1240 [40960/90000 (45%)]	Loss: 6.4003	Cost: 6.10s
Train Epoch: 1240 [61440/90000 (68%)]	Loss: 6.2030	Cost: 5.98s
Train Epoch: 1240 [81920/90000 (91%)]	Loss: 6.3240	Cost: 5.71s
Train Epoch: 1240 	Average Loss: 7.4541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9231

Learning rate: 0.00019250772068344542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1241 [0/90000 (0%)]	Loss: 22.5201	Cost: 24.97s
Train Epoch: 1241 [20480/90000 (23%)]	Loss: 6.2603	Cost: 6.05s
Train Epoch: 1241 [40960/90000 (45%)]	Loss: 6.5930	Cost: 6.08s
Train Epoch: 1241 [61440/90000 (68%)]	Loss: 6.3633	Cost: 5.90s
Train Epoch: 1241 [81920/90000 (91%)]	Loss: 6.3482	Cost: 5.83s
Train Epoch: 1241 	Average Loss: 7.4873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9148

Learning rate: 0.0001924957850064039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1242 [0/90000 (0%)]	Loss: 22.5007	Cost: 25.54s
Train Epoch: 1242 [20480/90000 (23%)]	Loss: 6.2768	Cost: 6.16s
Train Epoch: 1242 [40960/90000 (45%)]	Loss: 6.3929	Cost: 6.13s
Train Epoch: 1242 [61440/90000 (68%)]	Loss: 6.2372	Cost: 5.92s
Train Epoch: 1242 [81920/90000 (91%)]	Loss: 6.2653	Cost: 5.76s
Train Epoch: 1242 	Average Loss: 7.4075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9645

Learning rate: 0.0001924838402003944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1243 [0/90000 (0%)]	Loss: 22.5134	Cost: 24.21s
Train Epoch: 1243 [20480/90000 (23%)]	Loss: 6.2388	Cost: 6.31s
Train Epoch: 1243 [40960/90000 (45%)]	Loss: 6.4527	Cost: 6.15s
Train Epoch: 1243 [61440/90000 (68%)]	Loss: 6.3506	Cost: 5.96s
Train Epoch: 1243 [81920/90000 (91%)]	Loss: 6.5383	Cost: 5.80s
Train Epoch: 1243 	Average Loss: 7.4873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9343

Learning rate: 0.0001924718862665958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1244 [0/90000 (0%)]	Loss: 22.6877	Cost: 25.09s
Train Epoch: 1244 [20480/90000 (23%)]	Loss: 6.5664	Cost: 6.08s
Train Epoch: 1244 [40960/90000 (45%)]	Loss: 6.6102	Cost: 6.79s
Train Epoch: 1244 [61440/90000 (68%)]	Loss: 6.4543	Cost: 6.07s
Train Epoch: 1244 [81920/90000 (91%)]	Loss: 6.4300	Cost: 5.72s
Train Epoch: 1244 	Average Loss: 7.6355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8933

Learning rate: 0.0001924599232061879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1245 [0/90000 (0%)]	Loss: 22.4846	Cost: 22.41s
Train Epoch: 1245 [20480/90000 (23%)]	Loss: 6.2760	Cost: 6.33s
Train Epoch: 1245 [40960/90000 (45%)]	Loss: 6.5501	Cost: 6.38s
Train Epoch: 1245 [61440/90000 (68%)]	Loss: 6.1890	Cost: 5.93s
Train Epoch: 1245 [81920/90000 (91%)]	Loss: 6.5836	Cost: 5.80s
Train Epoch: 1245 	Average Loss: 7.5533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8791

Learning rate: 0.00019244795102035147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1246 [0/90000 (0%)]	Loss: 22.5878	Cost: 21.86s
Train Epoch: 1246 [20480/90000 (23%)]	Loss: 6.7400	Cost: 6.65s
Train Epoch: 1246 [40960/90000 (45%)]	Loss: 6.8654	Cost: 6.21s
Train Epoch: 1246 [61440/90000 (68%)]	Loss: 6.3822	Cost: 6.10s
Train Epoch: 1246 [81920/90000 (91%)]	Loss: 6.3463	Cost: 5.91s
Train Epoch: 1246 	Average Loss: 7.7145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8552

Learning rate: 0.00019243596971026803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1247 [0/90000 (0%)]	Loss: 22.5547	Cost: 21.02s
Train Epoch: 1247 [20480/90000 (23%)]	Loss: 6.5336	Cost: 6.49s
Train Epoch: 1247 [40960/90000 (45%)]	Loss: 6.7305	Cost: 6.77s
Train Epoch: 1247 [61440/90000 (68%)]	Loss: 6.5856	Cost: 5.94s
Train Epoch: 1247 [81920/90000 (91%)]	Loss: 6.5026	Cost: 6.17s
Train Epoch: 1247 	Average Loss: 7.6635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8704

Learning rate: 0.00019242397927712014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1248 [0/90000 (0%)]	Loss: 22.5581	Cost: 22.94s
Train Epoch: 1248 [20480/90000 (23%)]	Loss: 6.2648	Cost: 6.08s
Train Epoch: 1248 [40960/90000 (45%)]	Loss: 6.2940	Cost: 6.46s
Train Epoch: 1248 [61440/90000 (68%)]	Loss: 6.2313	Cost: 5.95s
Train Epoch: 1248 [81920/90000 (91%)]	Loss: 6.5543	Cost: 5.92s
Train Epoch: 1248 	Average Loss: 7.4761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8331

Learning rate: 0.00019241197972209119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1249 [0/90000 (0%)]	Loss: 22.4920	Cost: 21.02s
Train Epoch: 1249 [20480/90000 (23%)]	Loss: 6.1692	Cost: 6.08s
Train Epoch: 1249 [40960/90000 (45%)]	Loss: 6.3586	Cost: 6.28s
Train Epoch: 1249 [61440/90000 (68%)]	Loss: 6.1410	Cost: 5.97s
Train Epoch: 1249 [81920/90000 (91%)]	Loss: 6.3800	Cost: 6.02s
Train Epoch: 1249 	Average Loss: 7.4353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9810

Learning rate: 0.0001923999710463655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1250 [0/90000 (0%)]	Loss: 22.6853	Cost: 19.47s
Train Epoch: 1250 [20480/90000 (23%)]	Loss: 6.3246	Cost: 6.89s
Train Epoch: 1250 [40960/90000 (45%)]	Loss: 6.0510	Cost: 6.49s
Train Epoch: 1250 [61440/90000 (68%)]	Loss: 6.0266	Cost: 6.00s
Train Epoch: 1250 [81920/90000 (91%)]	Loss: 6.0462	Cost: 5.85s
Train Epoch: 1250 	Average Loss: 7.2957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0202

Learning rate: 0.0001923879532511283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1251 [0/90000 (0%)]	Loss: 22.4927	Cost: 20.62s
Train Epoch: 1251 [20480/90000 (23%)]	Loss: 6.2969	Cost: 6.25s
Train Epoch: 1251 [40960/90000 (45%)]	Loss: 6.2886	Cost: 6.32s
Train Epoch: 1251 [61440/90000 (68%)]	Loss: 5.9686	Cost: 5.93s
Train Epoch: 1251 [81920/90000 (91%)]	Loss: 6.1521	Cost: 5.94s
Train Epoch: 1251 	Average Loss: 7.2562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0257

Learning rate: 0.00019237592633756566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1252 [0/90000 (0%)]	Loss: 22.9260	Cost: 20.63s
Train Epoch: 1252 [20480/90000 (23%)]	Loss: 5.9880	Cost: 6.05s
Train Epoch: 1252 [40960/90000 (45%)]	Loss: 6.2218	Cost: 6.84s
Train Epoch: 1252 [61440/90000 (68%)]	Loss: 5.9618	Cost: 5.90s
Train Epoch: 1252 [81920/90000 (91%)]	Loss: 6.1125	Cost: 6.08s
Train Epoch: 1252 	Average Loss: 7.2830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0071

Learning rate: 0.00019236389030686458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1253 [0/90000 (0%)]	Loss: 22.8276	Cost: 19.62s
Train Epoch: 1253 [20480/90000 (23%)]	Loss: 6.0829	Cost: 6.21s
Train Epoch: 1253 [40960/90000 (45%)]	Loss: 6.0729	Cost: 6.38s
Train Epoch: 1253 [61440/90000 (68%)]	Loss: 6.0251	Cost: 6.09s
Train Epoch: 1253 [81920/90000 (91%)]	Loss: 6.1582	Cost: 5.81s
Train Epoch: 1253 	Average Loss: 7.2560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9964

Learning rate: 0.000192351845160213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1254 [0/90000 (0%)]	Loss: 22.6216	Cost: 19.88s
Train Epoch: 1254 [20480/90000 (23%)]	Loss: 6.0159	Cost: 6.09s
Train Epoch: 1254 [40960/90000 (45%)]	Loss: 6.0872	Cost: 6.55s
Train Epoch: 1254 [61440/90000 (68%)]	Loss: 5.9175	Cost: 6.01s
Train Epoch: 1254 [81920/90000 (91%)]	Loss: 5.9765	Cost: 6.32s
Train Epoch: 1254 	Average Loss: 7.1665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0205

Learning rate: 0.00019233979089879974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1255 [0/90000 (0%)]	Loss: 22.7126	Cost: 20.66s
Train Epoch: 1255 [20480/90000 (23%)]	Loss: 6.0138	Cost: 6.13s
Train Epoch: 1255 [40960/90000 (45%)]	Loss: 6.2186	Cost: 6.15s
Train Epoch: 1255 [61440/90000 (68%)]	Loss: 5.7690	Cost: 6.01s
Train Epoch: 1255 [81920/90000 (91%)]	Loss: 6.2225	Cost: 5.86s
Train Epoch: 1255 	Average Loss: 7.2490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0238

Learning rate: 0.00019232772752381447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1256 [0/90000 (0%)]	Loss: 22.7027	Cost: 20.78s
Train Epoch: 1256 [20480/90000 (23%)]	Loss: 6.2113	Cost: 6.01s
Train Epoch: 1256 [40960/90000 (45%)]	Loss: 6.1505	Cost: 6.66s
Train Epoch: 1256 [61440/90000 (68%)]	Loss: 6.1134	Cost: 6.01s
Train Epoch: 1256 [81920/90000 (91%)]	Loss: 6.3096	Cost: 6.19s
Train Epoch: 1256 	Average Loss: 7.3014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0689

Learning rate: 0.00019231565503644783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1257 [0/90000 (0%)]	Loss: 22.8369	Cost: 21.32s
Train Epoch: 1257 [20480/90000 (23%)]	Loss: 6.1485	Cost: 6.10s
Train Epoch: 1257 [40960/90000 (45%)]	Loss: 6.2391	Cost: 6.19s
Train Epoch: 1257 [61440/90000 (68%)]	Loss: 5.6650	Cost: 5.87s
Train Epoch: 1257 [81920/90000 (91%)]	Loss: 5.9171	Cost: 6.05s
Train Epoch: 1257 	Average Loss: 7.1903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1652

Learning rate: 0.0001923035734378913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1258 [0/90000 (0%)]	Loss: 22.8641	Cost: 21.69s
Train Epoch: 1258 [20480/90000 (23%)]	Loss: 6.2060	Cost: 6.10s
Train Epoch: 1258 [40960/90000 (45%)]	Loss: 6.2598	Cost: 6.88s
Train Epoch: 1258 [61440/90000 (68%)]	Loss: 6.0545	Cost: 5.83s
Train Epoch: 1258 [81920/90000 (91%)]	Loss: 6.2731	Cost: 5.96s
Train Epoch: 1258 	Average Loss: 7.2702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0483

Learning rate: 0.00019229148272933733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1259 [0/90000 (0%)]	Loss: 22.8307	Cost: 20.47s
Train Epoch: 1259 [20480/90000 (23%)]	Loss: 6.1865	Cost: 6.08s
Train Epoch: 1259 [40960/90000 (45%)]	Loss: 6.2070	Cost: 6.11s
Train Epoch: 1259 [61440/90000 (68%)]	Loss: 5.9123	Cost: 5.89s
Train Epoch: 1259 [81920/90000 (91%)]	Loss: 5.9867	Cost: 5.90s
Train Epoch: 1259 	Average Loss: 7.2646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9998

Learning rate: 0.00019227938291197918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1260 [0/90000 (0%)]	Loss: 22.5018	Cost: 21.33s
Train Epoch: 1260 [20480/90000 (23%)]	Loss: 6.1079	Cost: 6.13s
Train Epoch: 1260 [40960/90000 (45%)]	Loss: 6.2075	Cost: 6.02s
Train Epoch: 1260 [61440/90000 (68%)]	Loss: 5.8679	Cost: 5.87s
Train Epoch: 1260 [81920/90000 (91%)]	Loss: 6.0185	Cost: 5.89s
Train Epoch: 1260 	Average Loss: 7.1997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0208

Learning rate: 0.00019226727398701107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1261 [0/90000 (0%)]	Loss: 22.5534	Cost: 20.69s
Train Epoch: 1261 [20480/90000 (23%)]	Loss: 5.9023	Cost: 6.08s
Train Epoch: 1261 [40960/90000 (45%)]	Loss: 6.1254	Cost: 6.12s
Train Epoch: 1261 [61440/90000 (68%)]	Loss: 6.0779	Cost: 6.05s
Train Epoch: 1261 [81920/90000 (91%)]	Loss: 6.1359	Cost: 5.83s
Train Epoch: 1261 	Average Loss: 7.1995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1013

Learning rate: 0.00019225515595562809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1262 [0/90000 (0%)]	Loss: 22.7095	Cost: 21.47s
Train Epoch: 1262 [20480/90000 (23%)]	Loss: 5.9914	Cost: 6.04s
Train Epoch: 1262 [40960/90000 (45%)]	Loss: 6.1147	Cost: 6.16s
Train Epoch: 1262 [61440/90000 (68%)]	Loss: 5.8783	Cost: 5.91s
Train Epoch: 1262 [81920/90000 (91%)]	Loss: 5.9595	Cost: 6.06s
Train Epoch: 1262 	Average Loss: 7.1741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0544

Learning rate: 0.00019224302881902622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1263 [0/90000 (0%)]	Loss: 22.5325	Cost: 20.89s
Train Epoch: 1263 [20480/90000 (23%)]	Loss: 5.9545	Cost: 6.17s
Train Epoch: 1263 [40960/90000 (45%)]	Loss: 6.0307	Cost: 6.11s
Train Epoch: 1263 [61440/90000 (68%)]	Loss: 5.9995	Cost: 6.01s
Train Epoch: 1263 [81920/90000 (91%)]	Loss: 6.1654	Cost: 5.81s
Train Epoch: 1263 	Average Loss: 7.2351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1267

Learning rate: 0.00019223089257840243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1264 [0/90000 (0%)]	Loss: 22.5332	Cost: 21.02s
Train Epoch: 1264 [20480/90000 (23%)]	Loss: 6.0819	Cost: 6.10s
Train Epoch: 1264 [40960/90000 (45%)]	Loss: 6.0809	Cost: 6.10s
Train Epoch: 1264 [61440/90000 (68%)]	Loss: 5.9136	Cost: 6.01s
Train Epoch: 1264 [81920/90000 (91%)]	Loss: 5.9341	Cost: 5.72s
Train Epoch: 1264 	Average Loss: 7.2002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1482

Learning rate: 0.0001922187472349545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1265 [0/90000 (0%)]	Loss: 22.6916	Cost: 19.79s
Train Epoch: 1265 [20480/90000 (23%)]	Loss: 5.9538	Cost: 6.29s
Train Epoch: 1265 [40960/90000 (45%)]	Loss: 5.9016	Cost: 6.62s
Train Epoch: 1265 [61440/90000 (68%)]	Loss: 5.7603	Cost: 5.89s
Train Epoch: 1265 [81920/90000 (91%)]	Loss: 5.9039	Cost: 6.60s
Train Epoch: 1265 	Average Loss: 7.1371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1656

Learning rate: 0.0001922065927898811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1266 [0/90000 (0%)]	Loss: 22.6855	Cost: 21.04s
Train Epoch: 1266 [20480/90000 (23%)]	Loss: 5.9686	Cost: 6.12s
Train Epoch: 1266 [40960/90000 (45%)]	Loss: 6.0733	Cost: 6.27s
Train Epoch: 1266 [61440/90000 (68%)]	Loss: 6.1351	Cost: 5.97s
Train Epoch: 1266 [81920/90000 (91%)]	Loss: 6.2567	Cost: 6.01s
Train Epoch: 1266 	Average Loss: 7.2894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0926

Learning rate: 0.0001921944292443818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1267 [0/90000 (0%)]	Loss: 22.8651	Cost: 21.30s
Train Epoch: 1267 [20480/90000 (23%)]	Loss: 6.2027	Cost: 6.05s
Train Epoch: 1267 [40960/90000 (45%)]	Loss: 6.4281	Cost: 6.58s
Train Epoch: 1267 [61440/90000 (68%)]	Loss: 6.1669	Cost: 5.85s
Train Epoch: 1267 [81920/90000 (91%)]	Loss: 6.3739	Cost: 6.37s
Train Epoch: 1267 	Average Loss: 7.4797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0798

Learning rate: 0.00019218225659965716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1268 [0/90000 (0%)]	Loss: 22.6888	Cost: 20.36s
Train Epoch: 1268 [20480/90000 (23%)]	Loss: 6.1409	Cost: 6.04s
Train Epoch: 1268 [40960/90000 (45%)]	Loss: 6.2571	Cost: 6.25s
Train Epoch: 1268 [61440/90000 (68%)]	Loss: 6.0404	Cost: 5.93s
Train Epoch: 1268 [81920/90000 (91%)]	Loss: 6.1864	Cost: 5.82s
Train Epoch: 1268 	Average Loss: 7.3360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0024

Learning rate: 0.00019217007485690854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1269 [0/90000 (0%)]	Loss: 22.6604	Cost: 20.60s
Train Epoch: 1269 [20480/90000 (23%)]	Loss: 6.0303	Cost: 6.18s
Train Epoch: 1269 [40960/90000 (45%)]	Loss: 6.1784	Cost: 6.10s
Train Epoch: 1269 [61440/90000 (68%)]	Loss: 6.0261	Cost: 5.91s
Train Epoch: 1269 [81920/90000 (91%)]	Loss: 6.1870	Cost: 5.82s
Train Epoch: 1269 	Average Loss: 7.2205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0829

Learning rate: 0.00019215788401733824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1270 [0/90000 (0%)]	Loss: 22.7411	Cost: 20.17s
Train Epoch: 1270 [20480/90000 (23%)]	Loss: 6.0627	Cost: 6.15s
Train Epoch: 1270 [40960/90000 (45%)]	Loss: 6.3323	Cost: 6.08s
Train Epoch: 1270 [61440/90000 (68%)]	Loss: 6.2311	Cost: 5.90s
Train Epoch: 1270 [81920/90000 (91%)]	Loss: 6.4031	Cost: 5.76s
Train Epoch: 1270 	Average Loss: 7.2971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0464

Learning rate: 0.00019214568408214942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1271 [0/90000 (0%)]	Loss: 22.8058	Cost: 21.27s
Train Epoch: 1271 [20480/90000 (23%)]	Loss: 6.1596	Cost: 6.05s
Train Epoch: 1271 [40960/90000 (45%)]	Loss: 6.2863	Cost: 6.46s
Train Epoch: 1271 [61440/90000 (68%)]	Loss: 6.0898	Cost: 5.91s
Train Epoch: 1271 [81920/90000 (91%)]	Loss: 6.1979	Cost: 6.31s
Train Epoch: 1271 	Average Loss: 7.2382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1555

Learning rate: 0.00019213347505254617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1272 [0/90000 (0%)]	Loss: 22.8578	Cost: 20.36s
Train Epoch: 1272 [20480/90000 (23%)]	Loss: 6.0343	Cost: 6.01s
Train Epoch: 1272 [40960/90000 (45%)]	Loss: 6.2235	Cost: 6.69s
Train Epoch: 1272 [61440/90000 (68%)]	Loss: 5.8369	Cost: 5.91s
Train Epoch: 1272 [81920/90000 (91%)]	Loss: 6.0313	Cost: 6.06s
Train Epoch: 1272 	Average Loss: 7.1656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1517

Learning rate: 0.0001921212569297335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1273 [0/90000 (0%)]	Loss: 22.8100	Cost: 20.71s
Train Epoch: 1273 [20480/90000 (23%)]	Loss: 6.0574	Cost: 6.13s
Train Epoch: 1273 [40960/90000 (45%)]	Loss: 6.1220	Cost: 6.41s
Train Epoch: 1273 [61440/90000 (68%)]	Loss: 5.9891	Cost: 5.91s
Train Epoch: 1273 [81920/90000 (91%)]	Loss: 5.9636	Cost: 5.76s
Train Epoch: 1273 	Average Loss: 7.1532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1459

Learning rate: 0.00019210902971491728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1274 [0/90000 (0%)]	Loss: 22.5597	Cost: 21.62s
Train Epoch: 1274 [20480/90000 (23%)]	Loss: 5.9677	Cost: 6.19s
Train Epoch: 1274 [40960/90000 (45%)]	Loss: 5.9501	Cost: 6.08s
Train Epoch: 1274 [61440/90000 (68%)]	Loss: 5.7586	Cost: 5.89s
Train Epoch: 1274 [81920/90000 (91%)]	Loss: 5.9132	Cost: 5.82s
Train Epoch: 1274 	Average Loss: 7.0835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1161

Learning rate: 0.0001920967934093043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1275 [0/90000 (0%)]	Loss: 22.5787	Cost: 21.02s
Train Epoch: 1275 [20480/90000 (23%)]	Loss: 6.0919	Cost: 6.06s
Train Epoch: 1275 [40960/90000 (45%)]	Loss: 6.0950	Cost: 6.13s
Train Epoch: 1275 [61440/90000 (68%)]	Loss: 5.8284	Cost: 6.02s
Train Epoch: 1275 [81920/90000 (91%)]	Loss: 5.8874	Cost: 5.77s
Train Epoch: 1275 	Average Loss: 7.1021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0907

Learning rate: 0.00019208454801410222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1276 [0/90000 (0%)]	Loss: 22.7288	Cost: 21.95s
Train Epoch: 1276 [20480/90000 (23%)]	Loss: 5.8002	Cost: 6.07s
Train Epoch: 1276 [40960/90000 (45%)]	Loss: 5.7898	Cost: 6.25s
Train Epoch: 1276 [61440/90000 (68%)]	Loss: 5.8314	Cost: 5.79s
Train Epoch: 1276 [81920/90000 (91%)]	Loss: 5.8978	Cost: 6.52s
Train Epoch: 1276 	Average Loss: 7.0362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0867

Learning rate: 0.00019207229353051958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1277 [0/90000 (0%)]	Loss: 22.7243	Cost: 21.11s
Train Epoch: 1277 [20480/90000 (23%)]	Loss: 6.1729	Cost: 6.02s
Train Epoch: 1277 [40960/90000 (45%)]	Loss: 6.1582	Cost: 6.55s
Train Epoch: 1277 [61440/90000 (68%)]	Loss: 5.9919	Cost: 5.97s
Train Epoch: 1277 [81920/90000 (91%)]	Loss: 5.9536	Cost: 6.08s
Train Epoch: 1277 	Average Loss: 7.1350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2118

Learning rate: 0.00019206002995976587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1278 [0/90000 (0%)]	Loss: 22.6412	Cost: 20.08s
Train Epoch: 1278 [20480/90000 (23%)]	Loss: 6.0010	Cost: 6.18s
Train Epoch: 1278 [40960/90000 (45%)]	Loss: 6.0131	Cost: 6.11s
Train Epoch: 1278 [61440/90000 (68%)]	Loss: 5.7382	Cost: 5.96s
Train Epoch: 1278 [81920/90000 (91%)]	Loss: 5.9370	Cost: 5.79s
Train Epoch: 1278 	Average Loss: 7.0717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2136

Learning rate: 0.00019204775730305153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1279 [0/90000 (0%)]	Loss: 22.8242	Cost: 20.37s
Train Epoch: 1279 [20480/90000 (23%)]	Loss: 5.7754	Cost: 6.11s
Train Epoch: 1279 [40960/90000 (45%)]	Loss: 5.9757	Cost: 6.19s
Train Epoch: 1279 [61440/90000 (68%)]	Loss: 5.8060	Cost: 5.98s
Train Epoch: 1279 [81920/90000 (91%)]	Loss: 5.8232	Cost: 5.75s
Train Epoch: 1279 	Average Loss: 7.0511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1724

Learning rate: 0.00019203547556158768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1280 [0/90000 (0%)]	Loss: 22.6291	Cost: 19.95s
Train Epoch: 1280 [20480/90000 (23%)]	Loss: 5.8778	Cost: 6.11s
Train Epoch: 1280 [40960/90000 (45%)]	Loss: 5.9302	Cost: 6.04s
Train Epoch: 1280 [61440/90000 (68%)]	Loss: 5.7893	Cost: 5.95s
Train Epoch: 1280 [81920/90000 (91%)]	Loss: 5.7275	Cost: 5.81s
Train Epoch: 1280 	Average Loss: 7.0015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1328

Learning rate: 0.0001920231847365866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1281 [0/90000 (0%)]	Loss: 22.6930	Cost: 21.25s
Train Epoch: 1281 [20480/90000 (23%)]	Loss: 5.7218	Cost: 6.18s
Train Epoch: 1281 [40960/90000 (45%)]	Loss: 5.8682	Cost: 6.11s
Train Epoch: 1281 [61440/90000 (68%)]	Loss: 5.5014	Cost: 5.96s
Train Epoch: 1281 [81920/90000 (91%)]	Loss: 5.8019	Cost: 5.78s
Train Epoch: 1281 	Average Loss: 6.9661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1921

Learning rate: 0.00019201088482926132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1282 [0/90000 (0%)]	Loss: 22.9883	Cost: 19.79s
Train Epoch: 1282 [20480/90000 (23%)]	Loss: 5.8919	Cost: 6.21s
Train Epoch: 1282 [40960/90000 (45%)]	Loss: 5.8670	Cost: 6.15s
Train Epoch: 1282 [61440/90000 (68%)]	Loss: 5.6987	Cost: 5.91s
Train Epoch: 1282 [81920/90000 (91%)]	Loss: 5.8666	Cost: 5.83s
Train Epoch: 1282 	Average Loss: 6.9855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2133

Learning rate: 0.00019199857584082573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1283 [0/90000 (0%)]	Loss: 22.8418	Cost: 20.31s
Train Epoch: 1283 [20480/90000 (23%)]	Loss: 5.5349	Cost: 6.16s
Train Epoch: 1283 [40960/90000 (45%)]	Loss: 5.9409	Cost: 6.20s
Train Epoch: 1283 [61440/90000 (68%)]	Loss: 5.4904	Cost: 5.95s
Train Epoch: 1283 [81920/90000 (91%)]	Loss: 5.9418	Cost: 5.81s
Train Epoch: 1283 	Average Loss: 6.9556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3368

Learning rate: 0.00019198625777249478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1284 [0/90000 (0%)]	Loss: 22.8797	Cost: 21.70s
Train Epoch: 1284 [20480/90000 (23%)]	Loss: 5.7188	Cost: 6.05s
Train Epoch: 1284 [40960/90000 (45%)]	Loss: 5.8714	Cost: 6.68s
Train Epoch: 1284 [61440/90000 (68%)]	Loss: 5.6548	Cost: 5.90s
Train Epoch: 1284 [81920/90000 (91%)]	Loss: 5.7632	Cost: 5.84s
Train Epoch: 1284 	Average Loss: 6.9504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2258

Learning rate: 0.00019197393062548413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1285 [0/90000 (0%)]	Loss: 22.9364	Cost: 20.66s
Train Epoch: 1285 [20480/90000 (23%)]	Loss: 5.8137	Cost: 6.15s
Train Epoch: 1285 [40960/90000 (45%)]	Loss: 5.6986	Cost: 6.18s
Train Epoch: 1285 [61440/90000 (68%)]	Loss: 5.5031	Cost: 5.88s
Train Epoch: 1285 [81920/90000 (91%)]	Loss: 5.7007	Cost: 5.79s
Train Epoch: 1285 	Average Loss: 6.9345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3500

Learning rate: 0.00019196159440101047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1286 [0/90000 (0%)]	Loss: 22.7553	Cost: 22.45s
Train Epoch: 1286 [20480/90000 (23%)]	Loss: 5.7518	Cost: 6.07s
Train Epoch: 1286 [40960/90000 (45%)]	Loss: 6.0967	Cost: 6.76s
Train Epoch: 1286 [61440/90000 (68%)]	Loss: 5.6879	Cost: 6.04s
Train Epoch: 1286 [81920/90000 (91%)]	Loss: 5.8556	Cost: 5.80s
Train Epoch: 1286 	Average Loss: 7.0370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2188

Learning rate: 0.0001919492491002913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1287 [0/90000 (0%)]	Loss: 22.8160	Cost: 21.19s
Train Epoch: 1287 [20480/90000 (23%)]	Loss: 5.7745	Cost: 6.08s
Train Epoch: 1287 [40960/90000 (45%)]	Loss: 6.0452	Cost: 6.12s
Train Epoch: 1287 [61440/90000 (68%)]	Loss: 5.7118	Cost: 5.91s
Train Epoch: 1287 [81920/90000 (91%)]	Loss: 5.6077	Cost: 5.84s
Train Epoch: 1287 	Average Loss: 6.9929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2870

Learning rate: 0.00019193689472454505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1288 [0/90000 (0%)]	Loss: 22.7062	Cost: 20.21s
Train Epoch: 1288 [20480/90000 (23%)]	Loss: 5.8155	Cost: 6.05s
Train Epoch: 1288 [40960/90000 (45%)]	Loss: 5.8561	Cost: 6.23s
Train Epoch: 1288 [61440/90000 (68%)]	Loss: 5.8584	Cost: 5.89s
Train Epoch: 1288 [81920/90000 (91%)]	Loss: 5.7044	Cost: 5.94s
Train Epoch: 1288 	Average Loss: 6.9773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2816

Learning rate: 0.0001919245312749911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1289 [0/90000 (0%)]	Loss: 22.7861	Cost: 20.15s
Train Epoch: 1289 [20480/90000 (23%)]	Loss: 5.5688	Cost: 6.09s
Train Epoch: 1289 [40960/90000 (45%)]	Loss: 5.7876	Cost: 6.17s
Train Epoch: 1289 [61440/90000 (68%)]	Loss: 5.7401	Cost: 5.90s
Train Epoch: 1289 [81920/90000 (91%)]	Loss: 5.9832	Cost: 5.88s
Train Epoch: 1289 	Average Loss: 6.9263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2731

Learning rate: 0.00019191215875284963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1290 [0/90000 (0%)]	Loss: 22.8080	Cost: 22.26s
Train Epoch: 1290 [20480/90000 (23%)]	Loss: 5.7669	Cost: 6.06s
Train Epoch: 1290 [40960/90000 (45%)]	Loss: 5.9400	Cost: 6.20s
Train Epoch: 1290 [61440/90000 (68%)]	Loss: 5.5565	Cost: 5.98s
Train Epoch: 1290 [81920/90000 (91%)]	Loss: 5.7219	Cost: 5.80s
Train Epoch: 1290 	Average Loss: 6.9342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2752

Learning rate: 0.00019189977715934172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1291 [0/90000 (0%)]	Loss: 22.7291	Cost: 21.88s
Train Epoch: 1291 [20480/90000 (23%)]	Loss: 5.6404	Cost: 6.10s
Train Epoch: 1291 [40960/90000 (45%)]	Loss: 5.7797	Cost: 6.23s
Train Epoch: 1291 [61440/90000 (68%)]	Loss: 5.6419	Cost: 5.95s
Train Epoch: 1291 [81920/90000 (91%)]	Loss: 5.6276	Cost: 5.78s
Train Epoch: 1291 	Average Loss: 6.8726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2692

Learning rate: 0.0001918873864956895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1292 [0/90000 (0%)]	Loss: 22.9280	Cost: 21.65s
Train Epoch: 1292 [20480/90000 (23%)]	Loss: 5.7839	Cost: 6.26s
Train Epoch: 1292 [40960/90000 (45%)]	Loss: 5.8152	Cost: 6.29s
Train Epoch: 1292 [61440/90000 (68%)]	Loss: 5.7118	Cost: 5.93s
Train Epoch: 1292 [81920/90000 (91%)]	Loss: 5.6217	Cost: 5.86s
Train Epoch: 1292 	Average Loss: 6.9120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3253

Learning rate: 0.00019187498676311577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1293 [0/90000 (0%)]	Loss: 22.6574	Cost: 21.20s
Train Epoch: 1293 [20480/90000 (23%)]	Loss: 5.6637	Cost: 6.06s
Train Epoch: 1293 [40960/90000 (45%)]	Loss: 5.8612	Cost: 6.81s
Train Epoch: 1293 [61440/90000 (68%)]	Loss: 5.7178	Cost: 5.97s
Train Epoch: 1293 [81920/90000 (91%)]	Loss: 5.7371	Cost: 6.24s
Train Epoch: 1293 	Average Loss: 6.8431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2675

Learning rate: 0.0001918625779628444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1294 [0/90000 (0%)]	Loss: 22.8883	Cost: 21.90s
Train Epoch: 1294 [20480/90000 (23%)]	Loss: 5.4694	Cost: 6.15s
Train Epoch: 1294 [40960/90000 (45%)]	Loss: 5.8400	Cost: 6.10s
Train Epoch: 1294 [61440/90000 (68%)]	Loss: 5.7174	Cost: 5.95s
Train Epoch: 1294 [81920/90000 (91%)]	Loss: 5.8498	Cost: 5.82s
Train Epoch: 1294 	Average Loss: 6.8932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2949

Learning rate: 0.00019185016009610006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1295 [0/90000 (0%)]	Loss: 22.9910	Cost: 21.38s
Train Epoch: 1295 [20480/90000 (23%)]	Loss: 5.9246	Cost: 6.11s
Train Epoch: 1295 [40960/90000 (45%)]	Loss: 6.0362	Cost: 6.15s
Train Epoch: 1295 [61440/90000 (68%)]	Loss: 5.8663	Cost: 6.06s
Train Epoch: 1295 [81920/90000 (91%)]	Loss: 5.7188	Cost: 5.81s
Train Epoch: 1295 	Average Loss: 7.0351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3734

Learning rate: 0.00019183773316410835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1296 [0/90000 (0%)]	Loss: 23.1674	Cost: 22.27s
Train Epoch: 1296 [20480/90000 (23%)]	Loss: 5.5397	Cost: 6.23s
Train Epoch: 1296 [40960/90000 (45%)]	Loss: 6.1136	Cost: 6.10s
Train Epoch: 1296 [61440/90000 (68%)]	Loss: 5.7949	Cost: 5.90s
Train Epoch: 1296 [81920/90000 (91%)]	Loss: 5.9591	Cost: 5.80s
Train Epoch: 1296 	Average Loss: 7.0694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3496

Learning rate: 0.00019182529716809578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1297 [0/90000 (0%)]	Loss: 22.7220	Cost: 22.43s
Train Epoch: 1297 [20480/90000 (23%)]	Loss: 5.7601	Cost: 6.12s
Train Epoch: 1297 [40960/90000 (45%)]	Loss: 5.8783	Cost: 6.26s
Train Epoch: 1297 [61440/90000 (68%)]	Loss: 5.7674	Cost: 6.10s
Train Epoch: 1297 [81920/90000 (91%)]	Loss: 5.8726	Cost: 5.75s
Train Epoch: 1297 	Average Loss: 7.0108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3488

Learning rate: 0.0001918128521092897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1298 [0/90000 (0%)]	Loss: 22.8206	Cost: 24.29s
Train Epoch: 1298 [20480/90000 (23%)]	Loss: 5.6502	Cost: 6.22s
Train Epoch: 1298 [40960/90000 (45%)]	Loss: 5.8399	Cost: 6.08s
Train Epoch: 1298 [61440/90000 (68%)]	Loss: 5.5716	Cost: 5.87s
Train Epoch: 1298 [81920/90000 (91%)]	Loss: 5.7278	Cost: 5.81s
Train Epoch: 1298 	Average Loss: 6.9706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3405

Learning rate: 0.0001918003979889184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1299 [0/90000 (0%)]	Loss: 22.7718	Cost: 24.53s
Train Epoch: 1299 [20480/90000 (23%)]	Loss: 5.7150	Cost: 6.15s
Train Epoch: 1299 [40960/90000 (45%)]	Loss: 5.7568	Cost: 6.12s
Train Epoch: 1299 [61440/90000 (68%)]	Loss: 5.4815	Cost: 5.90s
Train Epoch: 1299 [81920/90000 (91%)]	Loss: 5.6501	Cost: 6.02s
Train Epoch: 1299 	Average Loss: 6.8325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3746

Learning rate: 0.00019178793480821105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1300 [0/90000 (0%)]	Loss: 22.9730	Cost: 23.37s
Train Epoch: 1300 [20480/90000 (23%)]	Loss: 5.3530	Cost: 6.09s
Train Epoch: 1300 [40960/90000 (45%)]	Loss: 5.7149	Cost: 6.15s
Train Epoch: 1300 [61440/90000 (68%)]	Loss: 5.4232	Cost: 5.96s
Train Epoch: 1300 [81920/90000 (91%)]	Loss: 5.6382	Cost: 5.79s
Train Epoch: 1300 	Average Loss: 6.8038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3375

Learning rate: 0.00019177546256839772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1301 [0/90000 (0%)]	Loss: 22.9741	Cost: 24.93s
Train Epoch: 1301 [20480/90000 (23%)]	Loss: 5.4204	Cost: 6.12s
Train Epoch: 1301 [40960/90000 (45%)]	Loss: 5.7693	Cost: 6.44s
Train Epoch: 1301 [61440/90000 (68%)]	Loss: 5.5286	Cost: 5.94s
Train Epoch: 1301 [81920/90000 (91%)]	Loss: 5.6442	Cost: 6.17s
Train Epoch: 1301 	Average Loss: 6.8055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3844

Learning rate: 0.00019176298127070938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1302 [0/90000 (0%)]	Loss: 23.0876	Cost: 24.88s
Train Epoch: 1302 [20480/90000 (23%)]	Loss: 5.3627	Cost: 6.07s
Train Epoch: 1302 [40960/90000 (45%)]	Loss: 5.6599	Cost: 6.29s
Train Epoch: 1302 [61440/90000 (68%)]	Loss: 5.3922	Cost: 5.89s
Train Epoch: 1302 [81920/90000 (91%)]	Loss: 5.8044	Cost: 5.84s
Train Epoch: 1302 	Average Loss: 6.8000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3098

Learning rate: 0.00019175049091637786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1303 [0/90000 (0%)]	Loss: 23.1069	Cost: 23.10s
Train Epoch: 1303 [20480/90000 (23%)]	Loss: 5.4756	Cost: 6.16s
Train Epoch: 1303 [40960/90000 (45%)]	Loss: 5.7596	Cost: 6.18s
Train Epoch: 1303 [61440/90000 (68%)]	Loss: 5.4898	Cost: 5.97s
Train Epoch: 1303 [81920/90000 (91%)]	Loss: 5.6797	Cost: 5.83s
Train Epoch: 1303 	Average Loss: 6.8768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3785

Learning rate: 0.00019173799150663595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1304 [0/90000 (0%)]	Loss: 22.9334	Cost: 25.10s
Train Epoch: 1304 [20480/90000 (23%)]	Loss: 5.5640	Cost: 6.13s
Train Epoch: 1304 [40960/90000 (45%)]	Loss: 5.4685	Cost: 6.41s
Train Epoch: 1304 [61440/90000 (68%)]	Loss: 5.4538	Cost: 6.03s
Train Epoch: 1304 [81920/90000 (91%)]	Loss: 5.7063	Cost: 5.81s
Train Epoch: 1304 	Average Loss: 6.7828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3755

Learning rate: 0.00019172548304271725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1305 [0/90000 (0%)]	Loss: 22.5480	Cost: 21.98s
Train Epoch: 1305 [20480/90000 (23%)]	Loss: 5.6150	Cost: 6.10s
Train Epoch: 1305 [40960/90000 (45%)]	Loss: 5.6437	Cost: 6.15s
Train Epoch: 1305 [61440/90000 (68%)]	Loss: 5.5892	Cost: 5.94s
Train Epoch: 1305 [81920/90000 (91%)]	Loss: 5.7041	Cost: 5.80s
Train Epoch: 1305 	Average Loss: 6.8787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4075

Learning rate: 0.00019171296552585629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1306 [0/90000 (0%)]	Loss: 22.9622	Cost: 25.97s
Train Epoch: 1306 [20480/90000 (23%)]	Loss: 5.6335	Cost: 6.07s
Train Epoch: 1306 [40960/90000 (45%)]	Loss: 5.9079	Cost: 6.13s
Train Epoch: 1306 [61440/90000 (68%)]	Loss: 5.5880	Cost: 5.94s
Train Epoch: 1306 [81920/90000 (91%)]	Loss: 5.9396	Cost: 5.89s
Train Epoch: 1306 	Average Loss: 6.9326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3711

Learning rate: 0.00019170043895728857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1307 [0/90000 (0%)]	Loss: 22.9995	Cost: 22.64s
Train Epoch: 1307 [20480/90000 (23%)]	Loss: 5.5729	Cost: 7.18s
Train Epoch: 1307 [40960/90000 (45%)]	Loss: 5.8168	Cost: 6.32s
Train Epoch: 1307 [61440/90000 (68%)]	Loss: 5.7485	Cost: 6.00s
Train Epoch: 1307 [81920/90000 (91%)]	Loss: 5.8901	Cost: 5.93s
Train Epoch: 1307 	Average Loss: 6.8910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3902

Learning rate: 0.00019168790333825032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1308 [0/90000 (0%)]	Loss: 23.0070	Cost: 22.12s
Train Epoch: 1308 [20480/90000 (23%)]	Loss: 5.6444	Cost: 6.20s
Train Epoch: 1308 [40960/90000 (45%)]	Loss: 5.7205	Cost: 6.34s
Train Epoch: 1308 [61440/90000 (68%)]	Loss: 5.5843	Cost: 6.08s
Train Epoch: 1308 [81920/90000 (91%)]	Loss: 5.6647	Cost: 6.01s
Train Epoch: 1308 	Average Loss: 6.8538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4368

Learning rate: 0.00019167535866997882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1309 [0/90000 (0%)]	Loss: 23.1086	Cost: 21.24s
Train Epoch: 1309 [20480/90000 (23%)]	Loss: 5.5471	Cost: 8.33s
Train Epoch: 1309 [40960/90000 (45%)]	Loss: 5.6720	Cost: 6.16s
Train Epoch: 1309 [61440/90000 (68%)]	Loss: 5.4781	Cost: 5.99s
Train Epoch: 1309 [81920/90000 (91%)]	Loss: 5.4947	Cost: 5.79s
Train Epoch: 1309 	Average Loss: 6.7418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2757

Learning rate: 0.0001916628049537122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1310 [0/90000 (0%)]	Loss: 22.7795	Cost: 21.48s
Train Epoch: 1310 [20480/90000 (23%)]	Loss: 5.4821	Cost: 6.55s
Train Epoch: 1310 [40960/90000 (45%)]	Loss: 5.7256	Cost: 6.69s
Train Epoch: 1310 [61440/90000 (68%)]	Loss: 5.3532	Cost: 5.99s
Train Epoch: 1310 [81920/90000 (91%)]	Loss: 5.5639	Cost: 6.47s
Train Epoch: 1310 	Average Loss: 6.7155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4396

Learning rate: 0.00019165024219068937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1311 [0/90000 (0%)]	Loss: 22.8737	Cost: 20.84s
Train Epoch: 1311 [20480/90000 (23%)]	Loss: 5.3776	Cost: 6.30s
Train Epoch: 1311 [40960/90000 (45%)]	Loss: 5.5862	Cost: 6.28s
Train Epoch: 1311 [61440/90000 (68%)]	Loss: 5.3578	Cost: 5.95s
Train Epoch: 1311 [81920/90000 (91%)]	Loss: 5.4941	Cost: 6.02s
Train Epoch: 1311 	Average Loss: 6.6652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3515

Learning rate: 0.0001916376703821503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1312 [0/90000 (0%)]	Loss: 23.2510	Cost: 21.96s
Train Epoch: 1312 [20480/90000 (23%)]	Loss: 5.3081	Cost: 6.45s
Train Epoch: 1312 [40960/90000 (45%)]	Loss: 5.4501	Cost: 6.19s
Train Epoch: 1312 [61440/90000 (68%)]	Loss: 5.3223	Cost: 5.96s
Train Epoch: 1312 [81920/90000 (91%)]	Loss: 5.5265	Cost: 5.82s
Train Epoch: 1312 	Average Loss: 6.6091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3952

Learning rate: 0.00019162508952933575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1313 [0/90000 (0%)]	Loss: 23.0768	Cost: 19.85s
Train Epoch: 1313 [20480/90000 (23%)]	Loss: 5.5547	Cost: 7.06s
Train Epoch: 1313 [40960/90000 (45%)]	Loss: 5.6250	Cost: 6.20s
Train Epoch: 1313 [61440/90000 (68%)]	Loss: 5.4113	Cost: 6.01s
Train Epoch: 1313 [81920/90000 (91%)]	Loss: 5.6748	Cost: 5.88s
Train Epoch: 1313 	Average Loss: 6.7123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4990

Learning rate: 0.0001916124996334874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1314 [0/90000 (0%)]	Loss: 23.1572	Cost: 20.54s
Train Epoch: 1314 [20480/90000 (23%)]	Loss: 5.3388	Cost: 6.21s
Train Epoch: 1314 [40960/90000 (45%)]	Loss: 5.7953	Cost: 6.09s
Train Epoch: 1314 [61440/90000 (68%)]	Loss: 5.3591	Cost: 5.94s
Train Epoch: 1314 [81920/90000 (91%)]	Loss: 5.5917	Cost: 5.94s
Train Epoch: 1314 	Average Loss: 6.6734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5039

Learning rate: 0.00019159990069584783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1315 [0/90000 (0%)]	Loss: 22.7368	Cost: 19.85s
Train Epoch: 1315 [20480/90000 (23%)]	Loss: 5.4407	Cost: 6.10s
Train Epoch: 1315 [40960/90000 (45%)]	Loss: 5.8931	Cost: 6.77s
Train Epoch: 1315 [61440/90000 (68%)]	Loss: 5.7520	Cost: 5.98s
Train Epoch: 1315 [81920/90000 (91%)]	Loss: 5.8223	Cost: 6.15s
Train Epoch: 1315 	Average Loss: 6.8657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4478

Learning rate: 0.0001915872927176605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1316 [0/90000 (0%)]	Loss: 22.7630	Cost: 20.45s
Train Epoch: 1316 [20480/90000 (23%)]	Loss: 5.7853	Cost: 6.09s
Train Epoch: 1316 [40960/90000 (45%)]	Loss: 5.6946	Cost: 6.34s
Train Epoch: 1316 [61440/90000 (68%)]	Loss: 5.3319	Cost: 6.03s
Train Epoch: 1316 [81920/90000 (91%)]	Loss: 5.6174	Cost: 5.97s
Train Epoch: 1316 	Average Loss: 6.8429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3795

Learning rate: 0.0001915746757001698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1317 [0/90000 (0%)]	Loss: 23.1829	Cost: 20.76s
Train Epoch: 1317 [20480/90000 (23%)]	Loss: 5.4747	Cost: 6.02s
Train Epoch: 1317 [40960/90000 (45%)]	Loss: 5.6174	Cost: 6.20s
Train Epoch: 1317 [61440/90000 (68%)]	Loss: 5.5702	Cost: 6.09s
Train Epoch: 1317 [81920/90000 (91%)]	Loss: 5.2969	Cost: 6.05s
Train Epoch: 1317 	Average Loss: 6.7052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3822

Learning rate: 0.00019156204964462093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1318 [0/90000 (0%)]	Loss: 23.1552	Cost: 19.93s
Train Epoch: 1318 [20480/90000 (23%)]	Loss: 5.4717	Cost: 6.12s
Train Epoch: 1318 [40960/90000 (45%)]	Loss: 5.5962	Cost: 6.12s
Train Epoch: 1318 [61440/90000 (68%)]	Loss: 5.4543	Cost: 6.00s
Train Epoch: 1318 [81920/90000 (91%)]	Loss: 5.4794	Cost: 5.97s
Train Epoch: 1318 	Average Loss: 6.6637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3504

Learning rate: 0.00019154941455226007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1319 [0/90000 (0%)]	Loss: 22.8634	Cost: 22.06s
Train Epoch: 1319 [20480/90000 (23%)]	Loss: 5.2627	Cost: 6.02s
Train Epoch: 1319 [40960/90000 (45%)]	Loss: 5.3093	Cost: 6.14s
Train Epoch: 1319 [61440/90000 (68%)]	Loss: 5.2762	Cost: 6.10s
Train Epoch: 1319 [81920/90000 (91%)]	Loss: 5.2621	Cost: 5.93s
Train Epoch: 1319 	Average Loss: 6.5278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5298

Learning rate: 0.00019153677042433424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1320 [0/90000 (0%)]	Loss: 22.9996	Cost: 20.26s
Train Epoch: 1320 [20480/90000 (23%)]	Loss: 5.1535	Cost: 6.03s
Train Epoch: 1320 [40960/90000 (45%)]	Loss: 5.3061	Cost: 6.26s
Train Epoch: 1320 [61440/90000 (68%)]	Loss: 5.0955	Cost: 5.90s
Train Epoch: 1320 [81920/90000 (91%)]	Loss: 5.3087	Cost: 5.97s
Train Epoch: 1320 	Average Loss: 6.5098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5141

Learning rate: 0.00019152411726209133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1321 [0/90000 (0%)]	Loss: 23.0492	Cost: 20.61s
Train Epoch: 1321 [20480/90000 (23%)]	Loss: 5.4084	Cost: 6.03s
Train Epoch: 1321 [40960/90000 (45%)]	Loss: 5.5879	Cost: 6.12s
Train Epoch: 1321 [61440/90000 (68%)]	Loss: 5.4116	Cost: 5.93s
Train Epoch: 1321 [81920/90000 (91%)]	Loss: 5.4865	Cost: 5.93s
Train Epoch: 1321 	Average Loss: 6.6705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5009

Learning rate: 0.00019151145506678021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1322 [0/90000 (0%)]	Loss: 23.0212	Cost: 21.24s
Train Epoch: 1322 [20480/90000 (23%)]	Loss: 5.4818	Cost: 6.12s
Train Epoch: 1322 [40960/90000 (45%)]	Loss: 5.5664	Cost: 6.74s
Train Epoch: 1322 [61440/90000 (68%)]	Loss: 5.2435	Cost: 5.88s
Train Epoch: 1322 [81920/90000 (91%)]	Loss: 5.5638	Cost: 6.22s
Train Epoch: 1322 	Average Loss: 6.6868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4272

Learning rate: 0.00019149878383965054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1323 [0/90000 (0%)]	Loss: 23.0347	Cost: 19.85s
Train Epoch: 1323 [20480/90000 (23%)]	Loss: 5.7395	Cost: 6.08s
Train Epoch: 1323 [40960/90000 (45%)]	Loss: 5.7296	Cost: 6.09s
Train Epoch: 1323 [61440/90000 (68%)]	Loss: 5.4116	Cost: 5.92s
Train Epoch: 1323 [81920/90000 (91%)]	Loss: 5.6010	Cost: 5.79s
Train Epoch: 1323 	Average Loss: 6.8634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3551

Learning rate: 0.00019148610358195298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1324 [0/90000 (0%)]	Loss: 22.9008	Cost: 21.61s
Train Epoch: 1324 [20480/90000 (23%)]	Loss: 5.4487	Cost: 6.11s
Train Epoch: 1324 [40960/90000 (45%)]	Loss: 5.2800	Cost: 6.21s
Train Epoch: 1324 [61440/90000 (68%)]	Loss: 5.3062	Cost: 5.85s
Train Epoch: 1324 [81920/90000 (91%)]	Loss: 5.3397	Cost: 5.71s
Train Epoch: 1324 	Average Loss: 6.6606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4851

Learning rate: 0.00019147341429493896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1325 [0/90000 (0%)]	Loss: 23.1939	Cost: 19.67s
Train Epoch: 1325 [20480/90000 (23%)]	Loss: 5.1935	Cost: 6.16s
Train Epoch: 1325 [40960/90000 (45%)]	Loss: 5.4707	Cost: 6.44s
Train Epoch: 1325 [61440/90000 (68%)]	Loss: 5.3234	Cost: 5.93s
Train Epoch: 1325 [81920/90000 (91%)]	Loss: 5.4763	Cost: 5.83s
Train Epoch: 1325 	Average Loss: 6.6165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4799

Learning rate: 0.00019146071597986092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1326 [0/90000 (0%)]	Loss: 22.8559	Cost: 20.55s
Train Epoch: 1326 [20480/90000 (23%)]	Loss: 5.2564	Cost: 6.06s
Train Epoch: 1326 [40960/90000 (45%)]	Loss: 5.4810	Cost: 6.08s
Train Epoch: 1326 [61440/90000 (68%)]	Loss: 5.2719	Cost: 5.87s
Train Epoch: 1326 [81920/90000 (91%)]	Loss: 5.4345	Cost: 5.85s
Train Epoch: 1326 	Average Loss: 6.6484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4926

Learning rate: 0.00019144800863797208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1327 [0/90000 (0%)]	Loss: 23.2402	Cost: 20.30s
Train Epoch: 1327 [20480/90000 (23%)]	Loss: 5.1408	Cost: 6.08s
Train Epoch: 1327 [40960/90000 (45%)]	Loss: 5.4527	Cost: 6.81s
Train Epoch: 1327 [61440/90000 (68%)]	Loss: 5.2126	Cost: 5.93s
Train Epoch: 1327 [81920/90000 (91%)]	Loss: 5.3037	Cost: 5.90s
Train Epoch: 1327 	Average Loss: 6.5795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4756

Learning rate: 0.00019143529227052663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1328 [0/90000 (0%)]	Loss: 22.9072	Cost: 20.76s
Train Epoch: 1328 [20480/90000 (23%)]	Loss: 5.4325	Cost: 6.07s
Train Epoch: 1328 [40960/90000 (45%)]	Loss: 5.5946	Cost: 6.10s
Train Epoch: 1328 [61440/90000 (68%)]	Loss: 5.3677	Cost: 5.92s
Train Epoch: 1328 [81920/90000 (91%)]	Loss: 5.4022	Cost: 5.77s
Train Epoch: 1328 	Average Loss: 6.6884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4741

Learning rate: 0.00019142256687877963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1329 [0/90000 (0%)]	Loss: 22.9391	Cost: 20.99s
Train Epoch: 1329 [20480/90000 (23%)]	Loss: 5.3849	Cost: 6.03s
Train Epoch: 1329 [40960/90000 (45%)]	Loss: 5.7484	Cost: 6.33s
Train Epoch: 1329 [61440/90000 (68%)]	Loss: 5.2562	Cost: 5.91s
Train Epoch: 1329 [81920/90000 (91%)]	Loss: 5.4974	Cost: 5.83s
Train Epoch: 1329 	Average Loss: 6.6955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4510

Learning rate: 0.00019140983246398704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1330 [0/90000 (0%)]	Loss: 22.9509	Cost: 21.11s
Train Epoch: 1330 [20480/90000 (23%)]	Loss: 5.3717	Cost: 6.10s
Train Epoch: 1330 [40960/90000 (45%)]	Loss: 5.4390	Cost: 6.29s
Train Epoch: 1330 [61440/90000 (68%)]	Loss: 5.1212	Cost: 6.05s
Train Epoch: 1330 [81920/90000 (91%)]	Loss: 5.3550	Cost: 5.86s
Train Epoch: 1330 	Average Loss: 6.6578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4732

Learning rate: 0.00019139708902740564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1331 [0/90000 (0%)]	Loss: 23.0313	Cost: 20.55s
Train Epoch: 1331 [20480/90000 (23%)]	Loss: 5.2575	Cost: 6.10s
Train Epoch: 1331 [40960/90000 (45%)]	Loss: 5.4321	Cost: 6.08s
Train Epoch: 1331 [61440/90000 (68%)]	Loss: 5.0825	Cost: 5.91s
Train Epoch: 1331 [81920/90000 (91%)]	Loss: 5.2919	Cost: 5.85s
Train Epoch: 1331 	Average Loss: 6.5576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4655

Learning rate: 0.00019138433657029324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1332 [0/90000 (0%)]	Loss: 23.0210	Cost: 20.85s
Train Epoch: 1332 [20480/90000 (23%)]	Loss: 5.4366	Cost: 6.12s
Train Epoch: 1332 [40960/90000 (45%)]	Loss: 5.5531	Cost: 6.88s
Train Epoch: 1332 [61440/90000 (68%)]	Loss: 5.4891	Cost: 5.92s
Train Epoch: 1332 [81920/90000 (91%)]	Loss: 5.7723	Cost: 6.43s
Train Epoch: 1332 	Average Loss: 6.7029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4533

Learning rate: 0.0001913715750939084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1333 [0/90000 (0%)]	Loss: 23.1606	Cost: 21.32s
Train Epoch: 1333 [20480/90000 (23%)]	Loss: 5.7190	Cost: 6.04s
Train Epoch: 1333 [40960/90000 (45%)]	Loss: 5.9040	Cost: 6.14s
Train Epoch: 1333 [61440/90000 (68%)]	Loss: 5.4537	Cost: 5.98s
Train Epoch: 1333 [81920/90000 (91%)]	Loss: 5.6011	Cost: 5.85s
Train Epoch: 1333 	Average Loss: 6.8740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4272

Learning rate: 0.00019135880459951061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1334 [0/90000 (0%)]	Loss: 23.1781	Cost: 20.39s
Train Epoch: 1334 [20480/90000 (23%)]	Loss: 6.1697	Cost: 6.12s
Train Epoch: 1334 [40960/90000 (45%)]	Loss: 6.2598	Cost: 6.09s
Train Epoch: 1334 [61440/90000 (68%)]	Loss: 6.0382	Cost: 5.86s
Train Epoch: 1334 [81920/90000 (91%)]	Loss: 5.8807	Cost: 6.01s
Train Epoch: 1334 	Average Loss: 7.2424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4119

Learning rate: 0.00019134602508836032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1335 [0/90000 (0%)]	Loss: 23.0141	Cost: 21.06s
Train Epoch: 1335 [20480/90000 (23%)]	Loss: 5.8257	Cost: 6.14s
Train Epoch: 1335 [40960/90000 (45%)]	Loss: 5.9128	Cost: 6.11s
Train Epoch: 1335 [61440/90000 (68%)]	Loss: 5.8001	Cost: 5.93s
Train Epoch: 1335 [81920/90000 (91%)]	Loss: 5.7856	Cost: 5.82s
Train Epoch: 1335 	Average Loss: 7.0467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4139

Learning rate: 0.00019133323656171877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1336 [0/90000 (0%)]	Loss: 22.9052	Cost: 22.75s
Train Epoch: 1336 [20480/90000 (23%)]	Loss: 5.4681	Cost: 6.01s
Train Epoch: 1336 [40960/90000 (45%)]	Loss: 5.5969	Cost: 6.60s
Train Epoch: 1336 [61440/90000 (68%)]	Loss: 5.1461	Cost: 5.95s
Train Epoch: 1336 [81920/90000 (91%)]	Loss: 5.3710	Cost: 6.19s
Train Epoch: 1336 	Average Loss: 6.6767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3848

Learning rate: 0.0001913204390208482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1337 [0/90000 (0%)]	Loss: 22.9359	Cost: 20.46s
Train Epoch: 1337 [20480/90000 (23%)]	Loss: 5.3685	Cost: 6.03s
Train Epoch: 1337 [40960/90000 (45%)]	Loss: 5.2723	Cost: 6.68s
Train Epoch: 1337 [61440/90000 (68%)]	Loss: 5.2612	Cost: 5.89s
Train Epoch: 1337 [81920/90000 (91%)]	Loss: 5.5895	Cost: 6.19s
Train Epoch: 1337 	Average Loss: 6.5356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4072

Learning rate: 0.0001913076324670116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1338 [0/90000 (0%)]	Loss: 23.0542	Cost: 22.49s
Train Epoch: 1338 [20480/90000 (23%)]	Loss: 5.3946	Cost: 6.01s
Train Epoch: 1338 [40960/90000 (45%)]	Loss: 5.2784	Cost: 6.20s
Train Epoch: 1338 [61440/90000 (68%)]	Loss: 5.0917	Cost: 5.94s
Train Epoch: 1338 [81920/90000 (91%)]	Loss: 5.5544	Cost: 5.97s
Train Epoch: 1338 	Average Loss: 6.5575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5133

Learning rate: 0.00019129481690147293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1339 [0/90000 (0%)]	Loss: 23.1713	Cost: 23.20s
Train Epoch: 1339 [20480/90000 (23%)]	Loss: 5.1992	Cost: 5.95s
Train Epoch: 1339 [40960/90000 (45%)]	Loss: 5.2884	Cost: 6.14s
Train Epoch: 1339 [61440/90000 (68%)]	Loss: 4.9810	Cost: 5.92s
Train Epoch: 1339 [81920/90000 (91%)]	Loss: 5.1875	Cost: 6.11s
Train Epoch: 1339 	Average Loss: 6.4857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5110

Learning rate: 0.0001912819923254971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1340 [0/90000 (0%)]	Loss: 23.0916	Cost: 21.48s
Train Epoch: 1340 [20480/90000 (23%)]	Loss: 5.1180	Cost: 6.14s
Train Epoch: 1340 [40960/90000 (45%)]	Loss: 5.4580	Cost: 6.06s
Train Epoch: 1340 [61440/90000 (68%)]	Loss: 5.1888	Cost: 6.03s
Train Epoch: 1340 [81920/90000 (91%)]	Loss: 5.5909	Cost: 5.97s
Train Epoch: 1340 	Average Loss: 6.5628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5498

Learning rate: 0.00019126915874034982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1341 [0/90000 (0%)]	Loss: 23.1000	Cost: 22.85s
Train Epoch: 1341 [20480/90000 (23%)]	Loss: 5.2998	Cost: 6.06s
Train Epoch: 1341 [40960/90000 (45%)]	Loss: 5.4849	Cost: 6.20s
Train Epoch: 1341 [61440/90000 (68%)]	Loss: 6.0398	Cost: 6.11s
Train Epoch: 1341 [81920/90000 (91%)]	Loss: 6.0767	Cost: 5.90s
Train Epoch: 1341 	Average Loss: 6.8905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4680

Learning rate: 0.00019125631614729769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1342 [0/90000 (0%)]	Loss: 23.0268	Cost: 25.33s
Train Epoch: 1342 [20480/90000 (23%)]	Loss: 5.6547	Cost: 6.05s
Train Epoch: 1342 [40960/90000 (45%)]	Loss: 5.6783	Cost: 6.13s
Train Epoch: 1342 [61440/90000 (68%)]	Loss: 5.3440	Cost: 6.03s
Train Epoch: 1342 [81920/90000 (91%)]	Loss: 5.4845	Cost: 6.20s
Train Epoch: 1342 	Average Loss: 6.8737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5393

Learning rate: 0.00019124346454760824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1343 [0/90000 (0%)]	Loss: 23.0941	Cost: 22.25s
Train Epoch: 1343 [20480/90000 (23%)]	Loss: 5.2636	Cost: 6.09s
Train Epoch: 1343 [40960/90000 (45%)]	Loss: 5.5823	Cost: 6.75s
Train Epoch: 1343 [61440/90000 (68%)]	Loss: 5.3277	Cost: 5.99s
Train Epoch: 1343 [81920/90000 (91%)]	Loss: 5.5154	Cost: 6.53s
Train Epoch: 1343 	Average Loss: 6.6936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4533

Learning rate: 0.00019123060394254988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1344 [0/90000 (0%)]	Loss: 22.9363	Cost: 24.35s
Train Epoch: 1344 [20480/90000 (23%)]	Loss: 5.3582	Cost: 6.06s
Train Epoch: 1344 [40960/90000 (45%)]	Loss: 5.6196	Cost: 6.24s
Train Epoch: 1344 [61440/90000 (68%)]	Loss: 5.1216	Cost: 5.89s
Train Epoch: 1344 [81920/90000 (91%)]	Loss: 5.1008	Cost: 6.07s
Train Epoch: 1344 	Average Loss: 6.5588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4738

Learning rate: 0.00019121773433339187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1345 [0/90000 (0%)]	Loss: 23.1889	Cost: 24.85s
Train Epoch: 1345 [20480/90000 (23%)]	Loss: 5.0772	Cost: 6.01s
Train Epoch: 1345 [40960/90000 (45%)]	Loss: 5.2383	Cost: 6.44s
Train Epoch: 1345 [61440/90000 (68%)]	Loss: 4.9631	Cost: 6.05s
Train Epoch: 1345 [81920/90000 (91%)]	Loss: 5.1261	Cost: 5.94s
Train Epoch: 1345 	Average Loss: 6.4291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5828

Learning rate: 0.00019120485572140446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1346 [0/90000 (0%)]	Loss: 22.9275	Cost: 22.03s
Train Epoch: 1346 [20480/90000 (23%)]	Loss: 5.2521	Cost: 6.23s
Train Epoch: 1346 [40960/90000 (45%)]	Loss: 5.2782	Cost: 6.13s
Train Epoch: 1346 [61440/90000 (68%)]	Loss: 5.1262	Cost: 5.93s
Train Epoch: 1346 [81920/90000 (91%)]	Loss: 5.2127	Cost: 5.89s
Train Epoch: 1346 	Average Loss: 6.5096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4738

Learning rate: 0.00019119196810785867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1347 [0/90000 (0%)]	Loss: 23.0931	Cost: 21.87s
Train Epoch: 1347 [20480/90000 (23%)]	Loss: 5.0662	Cost: 6.23s
Train Epoch: 1347 [40960/90000 (45%)]	Loss: 5.2731	Cost: 6.14s
Train Epoch: 1347 [61440/90000 (68%)]	Loss: 5.2868	Cost: 5.95s
Train Epoch: 1347 [81920/90000 (91%)]	Loss: 5.4289	Cost: 5.82s
Train Epoch: 1347 	Average Loss: 6.5094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6134

Learning rate: 0.0001911790714940264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1348 [0/90000 (0%)]	Loss: 23.2710	Cost: 22.65s
Train Epoch: 1348 [20480/90000 (23%)]	Loss: 5.2588	Cost: 6.05s
Train Epoch: 1348 [40960/90000 (45%)]	Loss: 5.4187	Cost: 6.12s
Train Epoch: 1348 [61440/90000 (68%)]	Loss: 5.1573	Cost: 5.89s
Train Epoch: 1348 [81920/90000 (91%)]	Loss: 5.3640	Cost: 5.81s
Train Epoch: 1348 	Average Loss: 6.5455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5312

Learning rate: 0.0001911661658811806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1349 [0/90000 (0%)]	Loss: 23.1433	Cost: 25.80s
Train Epoch: 1349 [20480/90000 (23%)]	Loss: 5.1507	Cost: 6.09s
Train Epoch: 1349 [40960/90000 (45%)]	Loss: 5.4983	Cost: 6.45s
Train Epoch: 1349 [61440/90000 (68%)]	Loss: 5.2883	Cost: 5.91s
Train Epoch: 1349 [81920/90000 (91%)]	Loss: 5.3190	Cost: 5.80s
Train Epoch: 1349 	Average Loss: 6.5084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4576

Learning rate: 0.00019115325127059494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1350 [0/90000 (0%)]	Loss: 23.1060	Cost: 26.11s
Train Epoch: 1350 [20480/90000 (23%)]	Loss: 4.9984	Cost: 6.10s
Train Epoch: 1350 [40960/90000 (45%)]	Loss: 5.0618	Cost: 6.08s
Train Epoch: 1350 [61440/90000 (68%)]	Loss: 5.0277	Cost: 5.87s
Train Epoch: 1350 [81920/90000 (91%)]	Loss: 4.9691	Cost: 5.76s
Train Epoch: 1350 	Average Loss: 6.3140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6010

Learning rate: 0.00019114032766354405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1351 [0/90000 (0%)]	Loss: 23.0863	Cost: 24.68s
Train Epoch: 1351 [20480/90000 (23%)]	Loss: 4.8522	Cost: 6.06s
Train Epoch: 1351 [40960/90000 (45%)]	Loss: 5.1806	Cost: 6.44s
Train Epoch: 1351 [61440/90000 (68%)]	Loss: 4.9736	Cost: 6.00s
Train Epoch: 1351 [81920/90000 (91%)]	Loss: 5.2547	Cost: 5.84s
Train Epoch: 1351 	Average Loss: 6.3257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6172

Learning rate: 0.00019112739506130344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1352 [0/90000 (0%)]	Loss: 23.2502	Cost: 24.27s
Train Epoch: 1352 [20480/90000 (23%)]	Loss: 4.9362	Cost: 6.01s
Train Epoch: 1352 [40960/90000 (45%)]	Loss: 5.3102	Cost: 6.57s
Train Epoch: 1352 [61440/90000 (68%)]	Loss: 5.1104	Cost: 6.04s
Train Epoch: 1352 [81920/90000 (91%)]	Loss: 5.2937	Cost: 5.99s
Train Epoch: 1352 	Average Loss: 6.4003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6445

Learning rate: 0.0001911144534651495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1353 [0/90000 (0%)]	Loss: 23.2179	Cost: 25.51s
Train Epoch: 1353 [20480/90000 (23%)]	Loss: 4.9297	Cost: 6.16s
Train Epoch: 1353 [40960/90000 (45%)]	Loss: 5.2969	Cost: 6.10s
Train Epoch: 1353 [61440/90000 (68%)]	Loss: 4.8600	Cost: 5.88s
Train Epoch: 1353 [81920/90000 (91%)]	Loss: 5.1669	Cost: 5.84s
Train Epoch: 1353 	Average Loss: 6.3678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6194

Learning rate: 0.00019110150287635953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1354 [0/90000 (0%)]	Loss: 23.1557	Cost: 23.54s
Train Epoch: 1354 [20480/90000 (23%)]	Loss: 5.1447	Cost: 6.12s
Train Epoch: 1354 [40960/90000 (45%)]	Loss: 5.3460	Cost: 6.84s
Train Epoch: 1354 [61440/90000 (68%)]	Loss: 5.1648	Cost: 5.90s
Train Epoch: 1354 [81920/90000 (91%)]	Loss: 5.3845	Cost: 6.09s
Train Epoch: 1354 	Average Loss: 6.4105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5737

Learning rate: 0.00019108854329621171
