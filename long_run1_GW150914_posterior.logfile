Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=100000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.0, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_posterior_prior/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=0, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
Loading load_all_bilby_samples...
Loading load_all_event_strain...
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 100000 epochs
Starting timer
Learning rate: 0.0002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.3362	Cost: 21.79s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.8246	Cost: 6.65s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 20.9664	Cost: 6.26s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 20.6036	Cost: 5.82s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.1899	Cost: 5.72s
Train Epoch: 1 	Average Loss: 21.3124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1354

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999995065198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 19.9881	Cost: 22.97s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 19.8822	Cost: 5.99s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.5762	Cost: 6.86s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 19.0465	Cost: 5.82s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 18.6288	Cost: 5.64s
Train Epoch: 2 	Average Loss: 19.3368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6354

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999998026079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 18.6640	Cost: 50.91s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 18.4627	Cost: 7.47s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.2538	Cost: 14.44s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 17.6202	Cost: 6.81s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 17.5113	Cost: 12.97s
Train Epoch: 3 	Average Loss: 17.9492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6037

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999995558678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 17.3750	Cost: 41.97s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 17.3651	Cost: 8.30s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 17.0372	Cost: 17.25s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 16.8059	Cost: 7.39s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 16.6351	Cost: 15.90s
Train Epoch: 4 	Average Loss: 16.9617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7892

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999921043165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 16.6076	Cost: 36.14s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 16.7442	Cost: 6.81s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 16.4672	Cost: 13.10s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 16.1684	Cost: 6.57s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 16.0715	Cost: 11.99s
Train Epoch: 5 	Average Loss: 16.3326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2011

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999876629945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 16.1185	Cost: 35.32s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 16.0802	Cost: 6.77s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 15.8492	Cost: 11.93s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 15.9234	Cost: 8.34s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 15.6606	Cost: 14.98s
Train Epoch: 6 	Average Loss: 15.8095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8557

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999822347122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 15.6398	Cost: 26.44s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 15.5609	Cost: 6.28s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 15.6911	Cost: 8.17s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 15.3342	Cost: 5.87s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 15.2009	Cost: 6.58s
Train Epoch: 7 	Average Loss: 15.4084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3052

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999758194695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 15.0766	Cost: 30.95s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 15.3076	Cost: 6.44s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 15.2015	Cost: 12.23s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 15.0639	Cost: 6.22s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 14.8665	Cost: 11.94s
Train Epoch: 8 	Average Loss: 15.0473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8519

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999684172664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 14.9189	Cost: 22.26s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 14.8190	Cost: 6.19s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 14.7363	Cost: 8.48s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 14.6699	Cost: 5.72s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 14.6727	Cost: 6.20s
Train Epoch: 9 	Average Loss: 14.7393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7490

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999600281025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 14.5631	Cost: 22.45s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 14.5942	Cost: 6.06s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 14.4472	Cost: 8.54s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 14.3649	Cost: 6.36s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 14.1778	Cost: 11.74s
Train Epoch: 10 	Average Loss: 14.3910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4016

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999506519785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 14.4126	Cost: 24.71s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 14.3929	Cost: 6.01s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 14.0830	Cost: 7.76s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 13.9917	Cost: 5.95s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 14.0603	Cost: 7.30s
Train Epoch: 11 	Average Loss: 14.1144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1122

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999402888941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 14.0689	Cost: 23.15s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 14.0620	Cost: 6.01s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 13.8420	Cost: 7.99s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 13.8403	Cost: 6.48s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 13.9160	Cost: 10.25s
Train Epoch: 12 	Average Loss: 13.8537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7943

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999289388494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 13.6078	Cost: 25.80s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 13.8404	Cost: 5.96s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 13.6884	Cost: 6.62s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 13.7250	Cost: 5.92s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 13.5664	Cost: 7.15s
Train Epoch: 13 	Average Loss: 13.5615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4344

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999916601844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 13.5610	Cost: 22.72s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 13.5547	Cost: 6.02s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 13.4606	Cost: 6.72s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 13.4742	Cost: 6.13s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 13.5063	Cost: 6.37s
Train Epoch: 14 	Average Loss: 13.3810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3616

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999032778784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 13.3992	Cost: 27.10s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 13.4927	Cost: 6.34s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 13.2676	Cost: 8.57s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 13.0883	Cost: 5.66s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 13.0603	Cost: 5.96s
Train Epoch: 15 	Average Loss: 13.2121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2427

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998889669524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 13.1845	Cost: 26.32s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 13.3276	Cost: 6.09s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 13.1691	Cost: 8.06s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 12.8697	Cost: 5.86s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 12.8193	Cost: 7.60s
Train Epoch: 16 	Average Loss: 12.9935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1048

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999873669066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 12.9040	Cost: 24.99s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 13.0600	Cost: 6.27s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 12.9693	Cost: 10.45s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 12.6170	Cost: 5.85s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 12.7626	Cost: 6.56s
Train Epoch: 17 	Average Loss: 12.8214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8480

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998573842195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 12.6806	Cost: 25.32s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 12.8896	Cost: 6.13s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 12.6407	Cost: 6.88s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 12.5617	Cost: 6.00s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 12.5260	Cost: 6.74s
Train Epoch: 18 	Average Loss: 12.6198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5675

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998401124124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 12.5389	Cost: 22.16s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 12.7621	Cost: 6.00s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 12.6379	Cost: 6.90s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 12.5418	Cost: 6.40s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 12.3884	Cost: 9.84s
Train Epoch: 19 	Average Loss: 12.4895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5928

Learning rate: 0.00019999998218536453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 12.5077	Cost: 28.06s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 12.7054	Cost: 6.27s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 12.4035	Cost: 9.68s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 12.1845	Cost: 5.81s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 12.2821	Cost: 5.61s
Train Epoch: 20 	Average Loss: 12.3437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4077

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998026079178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 12.3982	Cost: 23.26s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 12.3962	Cost: 6.01s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 12.2213	Cost: 6.92s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 12.1597	Cost: 5.80s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 12.2319	Cost: 5.81s
Train Epoch: 21 	Average Loss: 12.2267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3247

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999978237523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 12.1275	Cost: 22.99s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 12.3838	Cost: 6.22s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 12.2597	Cost: 10.76s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 11.9049	Cost: 6.15s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 12.1325	Cost: 10.60s
Train Epoch: 22 	Average Loss: 12.0897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3825

Learning rate: 0.00019999997611555822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 12.2336	Cost: 23.32s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 12.1366	Cost: 6.01s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 11.9531	Cost: 7.21s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 12.0991	Cost: 6.01s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 11.8641	Cost: 6.81s
Train Epoch: 23 	Average Loss: 11.9470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0164

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999997389489742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 11.8755	Cost: 22.58s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 12.0586	Cost: 6.89s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 11.6920	Cost: 11.25s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 11.6851	Cost: 6.25s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 11.7319	Cost: 11.16s
Train Epoch: 24 	Average Loss: 11.8055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7853

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999997157554058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 11.7151	Cost: 23.36s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 11.8575	Cost: 6.12s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 11.7760	Cost: 7.46s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 11.5660	Cost: 5.81s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 11.8781	Cost: 6.37s
Train Epoch: 25 	Average Loss: 11.6783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6791

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996915748774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 11.5584	Cost: 32.68s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 11.6795	Cost: 6.58s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 11.7710	Cost: 14.16s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 11.5217	Cost: 6.26s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 11.5408	Cost: 11.29s
Train Epoch: 26 	Average Loss: 11.5823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5832

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996664073888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 11.4382	Cost: 23.51s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 11.7986	Cost: 6.02s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 11.3748	Cost: 7.45s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 11.4683	Cost: 5.98s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 11.4772	Cost: 6.84s
Train Epoch: 27 	Average Loss: 11.4854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6306

Learning rate: 0.00019999996402529402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 11.6462	Cost: 22.28s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 11.5092	Cost: 6.08s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 11.5677	Cost: 7.82s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 11.3013	Cost: 6.44s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 11.3229	Cost: 11.32s
Train Epoch: 28 	Average Loss: 11.4065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4821

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996131115315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 11.4182	Cost: 30.08s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 11.2794	Cost: 6.73s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 11.3392	Cost: 10.62s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 11.1280	Cost: 6.10s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 11.1915	Cost: 11.27s
Train Epoch: 29 	Average Loss: 11.2516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4635

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999995849831625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 11.3173	Cost: 22.38s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 11.3623	Cost: 6.03s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 11.2124	Cost: 6.65s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 11.2528	Cost: 6.15s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 11.1240	Cost: 7.96s
Train Epoch: 30 	Average Loss: 11.2074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2395

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999995558678336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 11.0901	Cost: 27.38s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 11.3463	Cost: 6.18s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 11.3598	Cost: 9.30s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 11.0987	Cost: 5.90s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 11.1216	Cost: 6.36s
Train Epoch: 31 	Average Loss: 11.1474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1612

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999525765545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 11.1893	Cost: 23.18s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 11.0821	Cost: 6.03s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 10.9710	Cost: 7.06s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 10.9290	Cost: 5.78s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 10.9042	Cost: 6.14s
Train Epoch: 32 	Average Loss: 11.0373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0239

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999494676296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 11.0805	Cost: 25.13s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 11.0900	Cost: 6.27s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 10.9550	Cost: 10.30s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 10.9319	Cost: 6.01s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 10.8216	Cost: 8.63s
Train Epoch: 33 	Average Loss: 10.9360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9396

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999994626000874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 10.9257	Cost: 23.38s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 10.9818	Cost: 6.01s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 11.1288	Cost: 6.64s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 10.7033	Cost: 6.01s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 10.8907	Cost: 5.85s
Train Epoch: 34 	Average Loss: 10.8994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9294

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999994295369188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 10.6785	Cost: 27.55s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 10.9000	Cost: 6.34s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 10.7929	Cost: 8.98s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 10.7026	Cost: 5.81s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 10.8666	Cost: 6.01s
Train Epoch: 35 	Average Loss: 10.7750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8768

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999939548679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 10.7753	Cost: 24.50s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 10.9776	Cost: 6.17s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 10.6631	Cost: 7.88s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 10.7420	Cost: 6.07s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 10.6043	Cost: 5.77s
Train Epoch: 36 	Average Loss: 10.7237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0057

Learning rate: 0.00019999993604497015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 10.8247	Cost: 30.49s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 10.8572	Cost: 6.46s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 10.7041	Cost: 10.45s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 10.7204	Cost: 5.85s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 10.4586	Cost: 5.67s
Train Epoch: 37 	Average Loss: 10.6461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6980

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999993244256535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 10.6294	Cost: 22.54s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 10.8250	Cost: 6.01s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 10.7672	Cost: 6.53s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 10.5142	Cost: 6.04s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 10.5062	Cost: 7.56s
Train Epoch: 38 	Average Loss: 10.5692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7163

Learning rate: 0.00019999992874146456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 10.7761	Cost: 25.61s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 10.7352	Cost: 6.46s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 10.4798	Cost: 10.47s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 10.4074	Cost: 5.86s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 10.4440	Cost: 7.03s
Train Epoch: 39 	Average Loss: 10.4837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5539

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999249416678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 10.4470	Cost: 22.54s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 10.5513	Cost: 6.15s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 10.5381	Cost: 8.08s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 10.3928	Cost: 5.80s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 10.4235	Cost: 6.09s
Train Epoch: 40 	Average Loss: 10.4586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5221

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999992104317507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 10.4569	Cost: 24.18s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 10.5907	Cost: 6.26s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 10.4144	Cost: 10.61s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 10.3420	Cost: 6.12s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 10.3156	Cost: 9.20s
Train Epoch: 41 	Average Loss: 10.4060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5112

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999991704598637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 10.4123	Cost: 26.18s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 10.4962	Cost: 6.27s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 10.5021	Cost: 7.39s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 10.1495	Cost: 5.93s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 10.1673	Cost: 6.62s
Train Epoch: 42 	Average Loss: 10.3291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3751

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999991295010171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 10.3905	Cost: 29.94s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 10.6213	Cost: 6.57s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 10.1819	Cost: 10.63s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 10.2817	Cost: 5.81s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 10.1517	Cost: 5.68s
Train Epoch: 43 	Average Loss: 10.3035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4043

Learning rate: 0.00019999990875552108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 10.3860	Cost: 23.87s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 10.2506	Cost: 6.06s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 10.3247	Cost: 7.33s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 10.1374	Cost: 6.17s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 10.2491	Cost: 6.07s
Train Epoch: 44 	Average Loss: 10.2217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3893

Learning rate: 0.00019999990446224451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 10.4008	Cost: 22.35s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 10.2341	Cost: 6.44s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 10.1986	Cost: 10.31s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 10.1770	Cost: 6.28s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 10.0590	Cost: 10.99s
Train Epoch: 45 	Average Loss: 10.2011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1861

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999900070272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 10.0146	Cost: 22.96s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 10.2013	Cost: 5.99s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 10.0743	Cost: 8.52s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 10.0344	Cost: 5.73s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 10.1818	Cost: 6.42s
Train Epoch: 46 	Average Loss: 10.1192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3325

Learning rate: 0.00019999989557960353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 10.0944	Cost: 25.28s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 10.2768	Cost: 6.10s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 10.0746	Cost: 8.36s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 9.8685	Cost: 6.24s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 10.0785	Cost: 12.57s
Train Epoch: 47 	Average Loss: 10.0686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0702

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998909902391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 10.2031	Cost: 23.75s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 10.1219	Cost: 6.04s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 10.0365	Cost: 7.85s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 9.9506	Cost: 5.96s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 10.0690	Cost: 7.59s
Train Epoch: 48 	Average Loss: 10.0288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1385

Learning rate: 0.00019999988630217875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 10.1454	Cost: 22.95s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 10.3598	Cost: 6.06s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 9.9970	Cost: 7.60s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 9.9357	Cost: 5.73s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 10.0145	Cost: 5.76s
Train Epoch: 49 	Average Loss: 10.0182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0915

Learning rate: 0.00019999988151542247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 9.9323	Cost: 25.33s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 10.2739	Cost: 6.33s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 10.1650	Cost: 10.79s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 9.9318	Cost: 5.93s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 9.8850	Cost: 7.64s
Train Epoch: 50 	Average Loss: 9.9862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9827

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999987662997027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 9.8998	Cost: 22.16s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 9.9720	Cost: 6.12s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 9.9627	Cost: 7.22s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 9.7838	Cost: 5.96s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 9.8047	Cost: 5.85s
Train Epoch: 51 	Average Loss: 9.8850
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9203

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999987164582216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 9.8963	Cost: 26.65s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 9.9294	Cost: 6.13s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 9.8919	Cost: 8.72s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 9.8334	Cost: 5.87s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 9.8543	Cost: 6.21s
Train Epoch: 52 	Average Loss: 9.8707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9585

Learning rate: 0.0001999998665629781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 9.6944	Cost: 23.09s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 9.9732	Cost: 6.01s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 9.8112	Cost: 7.03s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 9.7874	Cost: 5.95s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 9.8502	Cost: 8.14s
Train Epoch: 53 	Average Loss: 9.8305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9443

Learning rate: 0.00019999986138143815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 9.8073	Cost: 25.75s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 9.7779	Cost: 6.18s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 9.8386	Cost: 10.43s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 9.8540	Cost: 5.91s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 9.8366	Cost: 6.76s
Train Epoch: 54 	Average Loss: 9.8000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8983

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999985610120227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 9.9798	Cost: 23.20s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 9.9175	Cost: 6.04s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 9.8294	Cost: 7.50s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 9.6728	Cost: 5.71s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 9.6249	Cost: 6.79s
Train Epoch: 55 	Average Loss: 9.7609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8075

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998507222705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 9.7010	Cost: 24.44s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 9.8915	Cost: 5.99s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 9.7300	Cost: 7.18s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 9.7323	Cost: 6.00s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 9.6904	Cost: 6.59s
Train Epoch: 56 	Average Loss: 9.7360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8109

Learning rate: 0.00019999984524464283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 9.9244	Cost: 24.96s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 9.8597	Cost: 6.16s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 9.7682	Cost: 8.32s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 9.5675	Cost: 5.94s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 9.5519	Cost: 5.74s
Train Epoch: 57 	Average Loss: 9.7053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7719

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998396683193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 9.7018	Cost: 28.77s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 9.8362	Cost: 6.57s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 9.7029	Cost: 10.78s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 9.6549	Cost: 6.21s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 9.6069	Cost: 6.01s
Train Epoch: 58 	Average Loss: 9.6556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8107

Learning rate: 0.00019999983399329984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 9.7436	Cost: 23.39s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 9.7352	Cost: 6.03s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 9.7451	Cost: 7.52s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 9.4527	Cost: 6.01s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 9.3657	Cost: 5.80s
Train Epoch: 59 	Average Loss: 9.5924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5938

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999982821958452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 9.6051	Cost: 28.23s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 9.6722	Cost: 6.32s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 9.4923	Cost: 8.08s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 9.4158	Cost: 5.87s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 9.5038	Cost: 5.80s
Train Epoch: 60 	Average Loss: 9.5348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5719

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999982234717332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 9.5465	Cost: 22.94s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 9.6910	Cost: 6.80s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 9.6021	Cost: 13.74s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 9.5428	Cost: 7.99s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 9.4938	Cost: 10.41s
Train Epoch: 61 	Average Loss: 9.5415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6985

Learning rate: 0.00019999981637606627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 9.5623	Cost: 27.05s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 9.6603	Cost: 6.15s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 9.4800	Cost: 7.03s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 9.4364	Cost: 6.01s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 9.3721	Cost: 7.20s
Train Epoch: 62 	Average Loss: 9.4870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6386

Learning rate: 0.00019999981030626333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 9.5290	Cost: 23.05s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 9.6712	Cost: 6.54s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 9.5509	Cost: 11.31s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 9.3879	Cost: 7.41s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 9.2622	Cost: 13.43s
Train Epoch: 63 	Average Loss: 9.4641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5299

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999980413776456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 9.5130	Cost: 26.41s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 9.5625	Cost: 6.14s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 9.4984	Cost: 6.44s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 9.2813	Cost: 6.03s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 9.2855	Cost: 7.79s
Train Epoch: 64 	Average Loss: 9.4335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5169

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999979787056995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 9.5762	Cost: 22.17s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 9.4973	Cost: 5.99s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 9.5320	Cost: 6.78s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 9.4023	Cost: 6.22s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 9.4016	Cost: 10.40s
Train Epoch: 65 	Average Loss: 9.4212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5587

Learning rate: 0.00019999979150467947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 9.6666	Cost: 26.29s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 9.4966	Cost: 6.52s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 9.3247	Cost: 10.01s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 9.2177	Cost: 5.94s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 9.2918	Cost: 6.42s
Train Epoch: 66 	Average Loss: 9.3475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4455

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999978504009312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 9.5752	Cost: 24.64s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 9.4326	Cost: 6.44s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 9.3516	Cost: 10.73s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 9.1765	Cost: 6.12s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 9.3602	Cost: 8.88s
Train Epoch: 67 	Average Loss: 9.3411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5764

Learning rate: 0.00019999977847681098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 9.5760	Cost: 26.61s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 9.4020	Cost: 6.15s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 9.3585	Cost: 10.01s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 9.2326	Cost: 5.67s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 9.2723	Cost: 5.87s
Train Epoch: 68 	Average Loss: 9.3410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4013

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999977181483299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 9.3839	Cost: 23.30s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 9.4416	Cost: 5.98s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 9.2634	Cost: 6.39s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 9.2563	Cost: 5.88s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 9.1703	Cost: 5.86s
Train Epoch: 69 	Average Loss: 9.2503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3521

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997650541592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 9.2304	Cost: 26.42s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 9.3120	Cost: 6.01s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 9.1703	Cost: 6.37s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 9.0952	Cost: 5.96s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 9.2241	Cost: 7.24s
Train Epoch: 70 	Average Loss: 9.2531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5007

Learning rate: 0.0001999997581947896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 9.4690	Cost: 22.47s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 9.3048	Cost: 6.11s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 9.2279	Cost: 6.40s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 9.0531	Cost: 6.62s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 9.0168	Cost: 9.40s
Train Epoch: 71 	Average Loss: 9.2183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3196

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997512367242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 9.2894	Cost: 23.96s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 9.2845	Cost: 6.14s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 9.3100	Cost: 8.21s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 9.1730	Cost: 5.85s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 9.1181	Cost: 6.38s
Train Epoch: 72 	Average Loss: 9.2290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3681

Learning rate: 0.000199999744179963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 9.3794	Cost: 24.31s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 9.2351	Cost: 6.41s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 9.1081	Cost: 10.08s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 9.2162	Cost: 6.24s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 9.0699	Cost: 11.43s
Train Epoch: 73 	Average Loss: 9.1590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2472

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999737024506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 9.3076	Cost: 23.28s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 9.2282	Cost: 6.00s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 9.2757	Cost: 7.60s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 9.0062	Cost: 5.73s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 9.0178	Cost: 6.07s
Train Epoch: 74 	Average Loss: 9.1763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3281

Learning rate: 0.00019999972977035322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 9.2228	Cost: 30.39s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 9.1889	Cost: 6.45s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 9.2014	Cost: 10.15s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 9.0047	Cost: 6.12s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 9.0048	Cost: 5.81s
Train Epoch: 75 	Average Loss: 9.1414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2758

Learning rate: 0.00019999972241750466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 9.1468	Cost: 24.14s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 9.3058	Cost: 6.10s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 9.0670	Cost: 7.78s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 9.0321	Cost: 6.20s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 9.1572	Cost: 7.82s
Train Epoch: 76 	Average Loss: 9.1304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2578

Learning rate: 0.0001999997149659603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 9.2515	Cost: 26.61s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 9.1270	Cost: 6.24s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 9.1206	Cost: 10.00s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 9.0013	Cost: 5.85s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 9.1591	Cost: 6.20s
Train Epoch: 77 	Average Loss: 9.1000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1505

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997074157202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 9.1242	Cost: 23.43s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 9.2056	Cost: 6.05s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 9.0175	Cost: 8.71s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 8.9565	Cost: 6.15s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 9.0665	Cost: 6.02s
Train Epoch: 78 	Average Loss: 9.0603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1398

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999969976678433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 9.1266	Cost: 24.95s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 9.1438	Cost: 6.28s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 8.9957	Cost: 10.42s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 8.9160	Cost: 6.04s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 8.9451	Cost: 8.06s
Train Epoch: 79 	Average Loss: 9.0033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1123

Saving model as e79_model.pt & e79_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999969201915272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 9.1166	Cost: 23.47s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 9.0017	Cost: 6.25s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 8.9757	Cost: 7.10s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 9.0451	Cost: 6.23s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 8.8268	Cost: 10.28s
Train Epoch: 80 	Average Loss: 8.9682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1302

Learning rate: 0.00019999968417282538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 9.0383	Cost: 23.51s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 9.0211	Cost: 6.22s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 9.0064	Cost: 10.45s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 8.9153	Cost: 6.14s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 9.1174	Cost: 10.24s
Train Epoch: 81 	Average Loss: 8.9975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0790

Saving model as e81_model.pt & e81_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999996762278023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 9.1371	Cost: 24.12s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 9.0221	Cost: 5.97s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 8.8262	Cost: 7.32s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 8.8735	Cost: 5.74s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 8.8349	Cost: 5.95s
Train Epoch: 82 	Average Loss: 8.9443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0496

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999996681840835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 9.1499	Cost: 28.20s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 9.0378	Cost: 6.14s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 9.0826	Cost: 10.48s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 8.9194	Cost: 5.82s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 8.7895	Cost: 5.68s
Train Epoch: 83 	Average Loss: 8.9258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9859

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999966004166902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 8.9853	Cost: 22.57s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 9.0233	Cost: 6.02s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 8.9695	Cost: 7.58s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 8.7606	Cost: 6.25s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 8.7242	Cost: 9.92s
Train Epoch: 84 	Average Loss: 8.8948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0385

Learning rate: 0.0001999996518005588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 9.0706	Cost: 27.89s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 9.0341	Cost: 6.06s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 8.8933	Cost: 7.28s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 8.7725	Cost: 6.05s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 8.7632	Cost: 8.26s
Train Epoch: 85 	Average Loss: 8.8959
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0822

Learning rate: 0.00019999964346075288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 8.9123	Cost: 22.75s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 8.9664	Cost: 6.07s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 8.8572	Cost: 7.94s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 8.6729	Cost: 6.42s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 8.8657	Cost: 9.15s
Train Epoch: 86 	Average Loss: 8.8681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9435

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999963502225128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 9.0465	Cost: 25.85s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 8.8874	Cost: 5.98s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 8.7935	Cost: 6.57s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 8.7097	Cost: 5.98s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 8.7382	Cost: 8.33s
Train Epoch: 87 	Average Loss: 8.8524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1000

Learning rate: 0.00019999962648505396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 8.9884	Cost: 23.55s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 8.8946	Cost: 5.99s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 8.8399	Cost: 6.98s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 8.7756	Cost: 5.75s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 8.7394	Cost: 6.05s
Train Epoch: 88 	Average Loss: 8.7905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9068

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999617849161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 8.8564	Cost: 25.62s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 8.9348	Cost: 5.95s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 8.7406	Cost: 6.68s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 8.7812	Cost: 5.96s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 8.7427	Cost: 7.76s
Train Epoch: 89 	Average Loss: 8.8037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9494

Learning rate: 0.00019999960911457236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 8.8353	Cost: 26.09s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 8.9791	Cost: 6.01s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 8.8355	Cost: 6.89s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 8.5887	Cost: 6.10s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 8.8056	Cost: 9.83s
Train Epoch: 90 	Average Loss: 8.7680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9113

Learning rate: 0.00019999960028128805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 8.9166	Cost: 26.73s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 8.8760	Cost: 6.23s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 8.7976	Cost: 9.74s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 8.5730	Cost: 5.97s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 8.6746	Cost: 6.06s
Train Epoch: 91 	Average Loss: 8.7348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8600

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999959134930808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 8.7748	Cost: 22.30s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 8.7814	Cost: 6.18s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 8.7080	Cost: 8.57s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 8.6262	Cost: 6.39s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 8.6425	Cost: 11.41s
Train Epoch: 92 	Average Loss: 8.7341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9457

Learning rate: 0.0001999995823186325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 8.8794	Cost: 25.25s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 8.8069	Cost: 5.99s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 8.7409	Cost: 7.11s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 8.6828	Cost: 6.01s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 8.7430	Cost: 7.32s
Train Epoch: 93 	Average Loss: 8.7053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9394

Learning rate: 0.00019999957318926127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 8.8856	Cost: 22.66s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 8.7345	Cost: 6.32s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 8.6075	Cost: 8.72s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 8.6233	Cost: 6.33s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 8.5337	Cost: 11.37s
Train Epoch: 94 	Average Loss: 8.6700
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8495

Saving model as e94_model.pt & e94_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999956396119442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 8.7778	Cost: 27.27s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 8.8217	Cost: 6.04s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 8.7235	Cost: 8.39s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 8.6308	Cost: 6.05s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 8.7652	Cost: 7.39s
Train Epoch: 95 	Average Loss: 8.6765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8706

Learning rate: 0.00019999955463443194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 8.7536	Cost: 22.84s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 8.7430	Cost: 5.96s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 8.6802	Cost: 7.07s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 8.7327	Cost: 6.24s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 8.5864	Cost: 10.69s
Train Epoch: 96 	Average Loss: 8.6281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8376

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999954520897388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 8.7261	Cost: 24.42s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 8.6900	Cost: 5.99s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 8.7652	Cost: 7.69s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 8.4759	Cost: 5.95s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 8.4871	Cost: 6.50s
Train Epoch: 97 	Average Loss: 8.6287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7573

Saving model as e97_model.pt & e97_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999953568482025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 8.7663	Cost: 22.68s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 8.6814	Cost: 6.02s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 8.5064	Cost: 6.89s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 8.4586	Cost: 6.21s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 8.4525	Cost: 10.77s
Train Epoch: 98 	Average Loss: 8.5656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7158

Saving model as e98_model.pt & e98_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999526061971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 8.6477	Cost: 24.36s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 8.6986	Cost: 6.15s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 8.6394	Cost: 9.10s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 8.3831	Cost: 5.94s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 8.6920	Cost: 6.48s
Train Epoch: 99 	Average Loss: 8.5930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7288

Learning rate: 0.00019999951634042617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 8.6817	Cost: 22.70s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 8.6759	Cost: 6.27s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 8.5560	Cost: 10.36s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 8.5728	Cost: 6.20s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 8.5155	Cost: 11.07s
Train Epoch: 100 	Average Loss: 8.5634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7924

Learning rate: 0.00019999950652018581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 8.8483	Cost: 23.60s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 8.7374	Cost: 6.22s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 8.5025	Cost: 9.23s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 8.5431	Cost: 5.84s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 8.4170	Cost: 6.31s
Train Epoch: 101 	Average Loss: 8.5643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8499

Learning rate: 0.00019999949660124986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 8.7976	Cost: 22.27s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 8.6704	Cost: 6.02s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 8.5294	Cost: 7.64s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 8.3978	Cost: 6.01s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 8.5202	Cost: 8.27s
Train Epoch: 102 	Average Loss: 8.5441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6775

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999948658361836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 8.6709	Cost: 25.51s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 8.5695	Cost: 6.02s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 8.3682	Cost: 7.46s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 8.5427	Cost: 6.00s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 8.4089	Cost: 8.51s
Train Epoch: 103 	Average Loss: 8.4795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6778

Learning rate: 0.00019999947646729134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 8.5823	Cost: 22.65s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 8.6080	Cost: 5.96s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 8.5373	Cost: 7.35s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 8.4349	Cost: 6.10s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 8.4082	Cost: 8.39s
Train Epoch: 104 	Average Loss: 8.4649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6103

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999946625226878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 8.6462	Cost: 26.90s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 8.5066	Cost: 6.17s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 8.4981	Cost: 7.70s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 8.3355	Cost: 5.77s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 8.4004	Cost: 7.08s
Train Epoch: 105 	Average Loss: 8.4696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7643

Learning rate: 0.00019999945593855072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 8.7139	Cost: 23.52s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 8.4908	Cost: 6.83s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 8.5341	Cost: 10.93s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 8.4833	Cost: 6.25s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 8.3407	Cost: 12.87s
Train Epoch: 106 	Average Loss: 8.4593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5756

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999944552613714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 8.6616	Cost: 31.15s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 8.5013	Cost: 17.40s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 8.3757	Cost: 17.41s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 8.2385	Cost: 17.72s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 8.3145	Cost: 18.50s
Train Epoch: 107 	Average Loss: 8.4177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5845

Learning rate: 0.00019999943501502806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 8.6512	Cost: 22.75s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 8.6328	Cost: 17.63s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 8.4183	Cost: 17.77s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 8.3082	Cost: 17.85s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 8.2777	Cost: 17.77s
Train Epoch: 108 	Average Loss: 8.4187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5555

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999994244052235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 8.3527	Cost: 24.05s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 8.4902	Cost: 17.56s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 8.4679	Cost: 17.15s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 8.2702	Cost: 17.86s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 8.2692	Cost: 17.72s
Train Epoch: 109 	Average Loss: 8.3539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5365

Saving model as e109_model.pt & e109_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999941369672346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 8.5571	Cost: 24.81s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 8.5382	Cost: 18.25s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 8.4879	Cost: 18.12s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 8.2542	Cost: 17.98s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 8.3215	Cost: 17.49s
Train Epoch: 110 	Average Loss: 8.3760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5797

Learning rate: 0.00019999940288952794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 8.5025	Cost: 25.07s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 8.4091	Cost: 17.83s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 8.6243	Cost: 17.20s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 8.2872	Cost: 17.61s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 8.3523	Cost: 17.48s
Train Epoch: 111 	Average Loss: 8.3709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5695

Learning rate: 0.000199999391983637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 8.5349	Cost: 27.60s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 8.4567	Cost: 17.44s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 8.2561	Cost: 17.48s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 8.2641	Cost: 17.22s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 8.3353	Cost: 17.14s
Train Epoch: 112 	Average Loss: 8.3351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5240

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999993809790506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 8.5906	Cost: 23.05s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 8.4638	Cost: 17.57s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 8.2646	Cost: 17.27s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 8.2986	Cost: 17.43s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 8.3448	Cost: 17.74s
Train Epoch: 113 	Average Loss: 8.3363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5365

Learning rate: 0.00019999936987576873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 8.5365	Cost: 22.64s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 8.3138	Cost: 6.17s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 8.2907	Cost: 8.30s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 8.2511	Cost: 5.82s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 8.2256	Cost: 6.03s
Train Epoch: 114 	Average Loss: 8.2797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4021

Saving model as e114_model.pt & e114_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999935867379148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 8.4525	Cost: 30.49s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 8.3824	Cost: 6.11s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 8.1801	Cost: 8.60s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 8.1263	Cost: 5.84s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 8.2255	Cost: 5.86s
Train Epoch: 115 	Average Loss: 8.2825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4809

Learning rate: 0.00019999934737311882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 8.6023	Cost: 26.66s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 8.2726	Cost: 6.54s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 8.3938	Cost: 11.94s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 8.1652	Cost: 6.91s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 8.4156	Cost: 12.63s
Train Epoch: 116 	Average Loss: 8.2867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4985

Learning rate: 0.00019999933597375074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 8.4725	Cost: 27.91s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 8.2964	Cost: 6.21s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 8.2597	Cost: 10.23s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 8.2146	Cost: 5.72s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 8.0865	Cost: 6.17s
Train Epoch: 117 	Average Loss: 8.2422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4337

Learning rate: 0.0001999993244756873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 8.4797	Cost: 23.38s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 8.3094	Cost: 6.24s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 8.1681	Cost: 10.16s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 8.0584	Cost: 6.24s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 8.0606	Cost: 11.26s
Train Epoch: 118 	Average Loss: 8.2035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3765

Saving model as e118_model.pt & e118_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999931287892846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 8.3915	Cost: 24.69s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 8.2484	Cost: 6.01s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 8.2617	Cost: 8.23s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 8.0476	Cost: 5.95s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 8.2981	Cost: 6.78s
Train Epoch: 119 	Average Loss: 8.2119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3979

Learning rate: 0.00019999930118347426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 8.4191	Cost: 22.01s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 8.2439	Cost: 6.16s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 8.1950	Cost: 8.92s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 8.0943	Cost: 6.20s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 8.1652	Cost: 11.24s
Train Epoch: 120 	Average Loss: 8.1893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4518

Learning rate: 0.0001999992893893247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 8.4913	Cost: 26.24s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 8.1743	Cost: 6.01s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 8.3104	Cost: 8.01s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 8.0342	Cost: 6.05s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 8.0073	Cost: 9.69s
Train Epoch: 121 	Average Loss: 8.1724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4050

Learning rate: 0.0001999992774964798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 8.4173	Cost: 22.31s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 8.2691	Cost: 6.01s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 8.1881	Cost: 6.82s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 7.9440	Cost: 6.02s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 8.0174	Cost: 7.98s
Train Epoch: 122 	Average Loss: 8.1219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3779

Learning rate: 0.00019999926550493962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 8.2577	Cost: 30.12s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 8.2704	Cost: 6.30s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 8.2366	Cost: 9.84s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 7.9933	Cost: 5.92s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 8.0039	Cost: 6.55s
Train Epoch: 123 	Average Loss: 8.1363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3787

Learning rate: 0.00019999925341470404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 8.3319	Cost: 23.73s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 8.2183	Cost: 6.02s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 8.1147	Cost: 7.51s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 7.9615	Cost: 5.77s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 7.9959	Cost: 6.29s
Train Epoch: 124 	Average Loss: 8.1167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3781

Learning rate: 0.0001999992412257732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 8.3137	Cost: 28.31s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 8.2219	Cost: 7.91s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 7.9575	Cost: 10.89s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 7.8580	Cost: 5.94s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 8.0304	Cost: 8.68s
Train Epoch: 125 	Average Loss: 8.0619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3720

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999922893814705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 8.5309	Cost: 23.02s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 8.2009	Cost: 6.13s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 8.1435	Cost: 8.17s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 8.0491	Cost: 5.98s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 7.9110	Cost: 5.72s
Train Epoch: 126 	Average Loss: 8.0965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3089

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999921655182562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 8.1217	Cost: 25.41s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 8.0635	Cost: 6.19s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 7.9924	Cost: 10.93s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 7.8843	Cost: 6.02s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 8.0272	Cost: 7.18s
Train Epoch: 127 	Average Loss: 8.0400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2593

Saving model as e127_model.pt & e127_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999992040668089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 8.1817	Cost: 23.51s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 8.1934	Cost: 6.00s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 7.9934	Cost: 7.05s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 7.8493	Cost: 5.79s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 7.9032	Cost: 5.74s
Train Epoch: 128 	Average Loss: 8.0256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2582

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999919148309698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 8.3513	Cost: 25.63s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 8.0645	Cost: 6.27s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 8.1340	Cost: 10.73s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 7.8774	Cost: 5.85s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 7.9187	Cost: 7.16s
Train Epoch: 129 	Average Loss: 8.0257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1997

Saving model as e129_model.pt & e129_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999917880068977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 8.2602	Cost: 23.65s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 8.1042	Cost: 6.00s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 7.9890	Cost: 7.64s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 7.8202	Cost: 5.65s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 7.9977	Cost: 6.19s
Train Epoch: 130 	Average Loss: 7.9882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2494

Learning rate: 0.00019999916601958734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 8.1339	Cost: 26.66s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 8.0729	Cost: 6.41s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 7.9526	Cost: 10.08s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 7.7441	Cost: 5.78s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 8.0146	Cost: 6.89s
Train Epoch: 131 	Average Loss: 7.9412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2814

Learning rate: 0.00019999915313978966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 8.1207	Cost: 23.50s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 8.0091	Cost: 6.05s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 7.8737	Cost: 7.93s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 7.7671	Cost: 6.07s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 7.9000	Cost: 6.12s
Train Epoch: 132 	Average Loss: 7.9357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3197

Learning rate: 0.00019999914016129682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 8.2301	Cost: 27.43s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 7.9038	Cost: 6.47s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 7.8833	Cost: 10.03s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 7.8185	Cost: 5.81s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 7.8349	Cost: 5.73s
Train Epoch: 133 	Average Loss: 7.9477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2544

Learning rate: 0.00019999912708410875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 8.1231	Cost: 23.77s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 8.0388	Cost: 6.32s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 7.9109	Cost: 7.59s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 7.7733	Cost: 5.92s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 7.7753	Cost: 6.02s
Train Epoch: 134 	Average Loss: 7.9000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2373

Learning rate: 0.00019999911390822548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 8.1672	Cost: 23.21s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 7.9378	Cost: 16.91s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 7.7993	Cost: 17.01s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 7.8141	Cost: 16.80s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 8.0089	Cost: 16.82s
Train Epoch: 135 	Average Loss: 7.9076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2432

Learning rate: 0.00019999910063364705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 8.2274	Cost: 25.06s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 8.0519	Cost: 16.69s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 7.8108	Cost: 16.42s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 7.8227	Cost: 16.43s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 7.8789	Cost: 16.45s
Train Epoch: 136 	Average Loss: 7.8879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2043

Learning rate: 0.00019999908726037348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 8.1444	Cost: 25.41s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 7.8314	Cost: 16.50s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 7.8678	Cost: 16.38s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 7.7273	Cost: 16.94s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 7.7820	Cost: 17.11s
Train Epoch: 137 	Average Loss: 7.8627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1553

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999907378840477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 8.0987	Cost: 24.99s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 7.8961	Cost: 16.72s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 7.8907	Cost: 16.78s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 7.7160	Cost: 16.96s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 7.7593	Cost: 17.45s
Train Epoch: 138 	Average Loss: 7.8459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1874

Learning rate: 0.00019999906021774094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 8.1042	Cost: 28.01s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 7.8988	Cost: 17.17s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 7.9435	Cost: 16.83s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 7.6521	Cost: 17.21s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 7.6102	Cost: 17.60s
Train Epoch: 139 	Average Loss: 7.8166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0924

Saving model as e139_model.pt & e139_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999904654838195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 7.9839	Cost: 24.36s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 7.8409	Cost: 16.67s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 7.7995	Cost: 16.52s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 7.6316	Cost: 17.16s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 7.7282	Cost: 17.43s
Train Epoch: 140 	Average Loss: 7.7933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0217

Saving model as e140_model.pt & e140_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999990327803279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 8.0509	Cost: 24.35s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 7.8155	Cost: 16.92s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 7.8533	Cost: 16.94s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 7.5693	Cost: 16.49s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 7.6752	Cost: 16.75s
Train Epoch: 141 	Average Loss: 7.7522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0695

Learning rate: 0.00019999901891357876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 8.0305	Cost: 23.21s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 7.8798	Cost: 16.97s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 7.8367	Cost: 16.67s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 7.6514	Cost: 16.92s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 7.6886	Cost: 16.96s
Train Epoch: 142 	Average Loss: 7.7757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0906

Learning rate: 0.0001999990049481345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 7.9202	Cost: 23.52s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 7.8356	Cost: 6.18s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 7.7563	Cost: 8.21s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 7.6661	Cost: 5.80s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 7.7030	Cost: 6.35s
Train Epoch: 143 	Average Loss: 7.7378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1001

Learning rate: 0.00019999899088399522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 7.9881	Cost: 23.00s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 7.8679	Cost: 16.53s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 7.6833	Cost: 16.52s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 7.4934	Cost: 17.28s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 7.6746	Cost: 16.78s
Train Epoch: 144 	Average Loss: 7.6938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0989

Learning rate: 0.0001999989767211609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 8.0458	Cost: 23.75s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 7.6912	Cost: 16.89s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 7.5728	Cost: 17.19s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 7.5573	Cost: 17.41s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 7.5304	Cost: 17.14s
Train Epoch: 145 	Average Loss: 7.6948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0576

Learning rate: 0.00019999896245963153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 7.9777	Cost: 24.01s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 7.6604	Cost: 16.73s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 7.7661	Cost: 16.41s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 7.6207	Cost: 16.92s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 7.5052	Cost: 17.13s
Train Epoch: 146 	Average Loss: 7.6851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0254

Learning rate: 0.00019999894809940715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 8.0845	Cost: 23.44s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 7.5885	Cost: 17.03s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 7.7496	Cost: 16.61s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 7.5189	Cost: 16.77s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 7.4753	Cost: 16.64s
Train Epoch: 147 	Average Loss: 7.6608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0153

Saving model as e147_model.pt & e147_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999893364048776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 7.9807	Cost: 26.88s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 7.6605	Cost: 16.87s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 7.6635	Cost: 16.43s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 7.4635	Cost: 16.52s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 7.6728	Cost: 15.77s
Train Epoch: 148 	Average Loss: 7.6431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9832

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999891908287334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 7.8716	Cost: 23.23s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 7.5888	Cost: 16.81s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 7.6247	Cost: 16.64s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 7.3731	Cost: 16.70s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 7.5184	Cost: 16.70s
Train Epoch: 149 	Average Loss: 7.5857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9297

Saving model as e149_model.pt & e149_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999890442656397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 7.9178	Cost: 23.58s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 7.6597	Cost: 16.89s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 7.7037	Cost: 16.96s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 7.5252	Cost: 17.00s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 7.4204	Cost: 16.83s
Train Epoch: 150 	Average Loss: 7.6124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9728

Learning rate: 0.00019999888967155965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 7.7914	Cost: 26.89s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 7.6325	Cost: 16.85s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 7.5146	Cost: 16.31s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 7.3689	Cost: 16.25s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 7.5553	Cost: 16.70s
Train Epoch: 151 	Average Loss: 7.5634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9827

Learning rate: 0.00019999887481786036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 7.8350	Cost: 22.29s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 7.5722	Cost: 6.18s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 7.6168	Cost: 9.01s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 7.3505	Cost: 5.83s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 7.3717	Cost: 5.68s
Train Epoch: 152 	Average Loss: 7.5515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8962

Saving model as e152_model.pt & e152_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999885986546616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 7.9028	Cost: 26.46s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 7.5951	Cost: 6.25s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 7.5365	Cost: 11.17s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 7.3113	Cost: 5.75s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 7.4366	Cost: 5.85s
Train Epoch: 153 	Average Loss: 7.4979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9464

Learning rate: 0.00019999884481437704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 7.9028	Cost: 23.47s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 7.5285	Cost: 6.05s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 7.5075	Cost: 7.90s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 7.3913	Cost: 6.13s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 7.4318	Cost: 5.91s
Train Epoch: 154 	Average Loss: 7.5241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8646

Saving model as e154_model.pt & e154_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998829664593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 7.7523	Cost: 26.81s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 7.5481	Cost: 6.12s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 7.5398	Cost: 8.88s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 7.3690	Cost: 5.96s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 7.4878	Cost: 6.20s
Train Epoch: 155 	Average Loss: 7.5167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8930

Learning rate: 0.00019999881441611406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 7.7930	Cost: 23.56s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 7.4310	Cost: 8.28s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 7.5041	Cost: 14.05s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 7.3087	Cost: 6.90s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 7.3897	Cost: 10.80s
Train Epoch: 156 	Average Loss: 7.4877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8276

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999879906894028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 7.8069	Cost: 30.72s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 7.4763	Cost: 6.49s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 7.2898	Cost: 10.51s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 7.2802	Cost: 5.75s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 7.3701	Cost: 6.33s
Train Epoch: 157 	Average Loss: 7.4671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8376

Learning rate: 0.00019999878362307163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 7.7985	Cost: 22.10s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 7.3437	Cost: 6.39s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 7.4957	Cost: 9.27s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 7.2245	Cost: 6.32s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 7.3320	Cost: 11.04s
Train Epoch: 158 	Average Loss: 7.4374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8565

Learning rate: 0.0001999987680785081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 7.7524	Cost: 23.58s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 7.4074	Cost: 6.04s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 7.5532	Cost: 8.22s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 7.1523	Cost: 5.86s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 7.4662	Cost: 6.52s
Train Epoch: 159 	Average Loss: 7.4230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7786

Saving model as e159_model.pt & e159_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999875243524977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 7.7085	Cost: 24.49s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 7.5034	Cost: 6.38s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 7.3426	Cost: 10.71s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 7.1964	Cost: 6.10s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 7.2728	Cost: 8.17s
Train Epoch: 160 	Average Loss: 7.3793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9029

Learning rate: 0.00019999873669329665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 7.8916	Cost: 23.73s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 7.4526	Cost: 6.72s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 7.2923	Cost: 11.12s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 7.1531	Cost: 6.14s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 7.2652	Cost: 9.23s
Train Epoch: 161 	Average Loss: 7.3580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7472

Saving model as e161_model.pt & e161_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999987208526487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 7.6024	Cost: 22.63s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 7.3763	Cost: 6.11s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 7.3909	Cost: 8.58s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 7.1732	Cost: 5.71s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 7.2102	Cost: 6.02s
Train Epoch: 162 	Average Loss: 7.3108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7906

Learning rate: 0.000199998704913306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 7.7765	Cost: 26.96s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 7.3890	Cost: 6.53s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 7.2877	Cost: 10.68s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 7.1714	Cost: 5.93s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 7.2120	Cost: 7.28s
Train Epoch: 163 	Average Loss: 7.2874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7202

Saving model as e163_model.pt & e163_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999868887526852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 7.7256	Cost: 22.57s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 7.3592	Cost: 5.97s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 7.2903	Cost: 7.54s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 7.0320	Cost: 5.71s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 7.1236	Cost: 6.78s
Train Epoch: 164 	Average Loss: 7.2872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7367

Learning rate: 0.0001999986727385363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 7.7650	Cost: 28.27s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 7.3306	Cost: 6.62s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 7.2644	Cost: 11.25s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 7.0916	Cost: 6.04s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 7.1208	Cost: 7.63s
Train Epoch: 165 	Average Loss: 7.2845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6787

Saving model as e165_model.pt & e165_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999986565031093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 7.6255	Cost: 22.67s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 7.2540	Cost: 6.14s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 7.3226	Cost: 7.26s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 7.0403	Cost: 5.77s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 6.9763	Cost: 7.74s
Train Epoch: 166 	Average Loss: 7.2311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6785

Saving model as e166_model.pt & e166_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999864016898762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 7.6693	Cost: 25.86s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 7.3665	Cost: 6.03s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 7.2569	Cost: 8.15s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 6.8974	Cost: 5.86s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 7.0930	Cost: 7.71s
Train Epoch: 167 	Average Loss: 7.2108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7221

Learning rate: 0.00019999862373617122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 7.5644	Cost: 22.46s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 7.2129	Cost: 6.03s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 7.1697	Cost: 7.05s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 6.9998	Cost: 6.34s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 7.0117	Cost: 14.64s
Train Epoch: 168 	Average Loss: 7.1833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6616

Saving model as e168_model.pt & e168_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999860720466015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 7.7855	Cost: 23.29s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 7.1349	Cost: 6.06s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 7.1603	Cost: 7.28s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 7.1136	Cost: 5.80s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 7.0036	Cost: 7.39s
Train Epoch: 169 	Average Loss: 7.2108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7024

Learning rate: 0.0001999985905744544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 7.7036	Cost: 26.05s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 7.2006	Cost: 6.34s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 7.1371	Cost: 10.42s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 7.0138	Cost: 6.02s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 7.1084	Cost: 8.18s
Train Epoch: 170 	Average Loss: 7.1747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6099

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998573845554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 7.5421	Cost: 23.69s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 7.2050	Cost: 6.13s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 7.1923	Cost: 7.65s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 7.0683	Cost: 6.14s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 7.0902	Cost: 6.00s
Train Epoch: 171 	Average Loss: 7.1439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7034

Learning rate: 0.00019999855701795897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 7.5933	Cost: 28.07s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 7.2634	Cost: 6.20s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 7.0797	Cost: 8.10s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 6.9527	Cost: 5.83s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 6.8954	Cost: 7.04s
Train Epoch: 172 	Average Loss: 7.1048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6385

Learning rate: 0.00019999854009166934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 7.5226	Cost: 22.80s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 7.1289	Cost: 6.05s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 7.1372	Cost: 7.49s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 6.9168	Cost: 6.30s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 6.8974	Cost: 8.68s
Train Epoch: 173 	Average Loss: 7.0726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5734

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999852306668508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 7.6021	Cost: 23.56s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 7.0968	Cost: 6.13s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 7.0501	Cost: 9.36s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 6.8849	Cost: 5.74s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 6.8465	Cost: 6.41s
Train Epoch: 174 	Average Loss: 7.0501
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5815

Learning rate: 0.00019999850594300622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 7.6165	Cost: 22.87s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 7.0171	Cost: 6.73s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 6.9607	Cost: 11.58s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 6.8579	Cost: 6.29s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 6.9556	Cost: 11.56s
Train Epoch: 175 	Average Loss: 7.0290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6332

Learning rate: 0.00019999848872063282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 7.3877	Cost: 25.14s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 7.0115	Cost: 6.10s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 6.9935	Cost: 8.71s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 6.8005	Cost: 5.81s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 6.8629	Cost: 5.82s
Train Epoch: 176 	Average Loss: 7.0035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5176

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999847139956484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 7.4459	Cost: 22.71s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 6.9702	Cost: 6.29s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 6.9842	Cost: 10.99s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 6.6697	Cost: 6.17s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 6.8849	Cost: 11.10s
Train Epoch: 177 	Average Loss: 6.9719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5817

Learning rate: 0.00019999845397980232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 7.5712	Cost: 26.94s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 7.1341	Cost: 6.05s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 6.9705	Cost: 8.33s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 6.6687	Cost: 5.97s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 6.8078	Cost: 7.05s
Train Epoch: 178 	Average Loss: 6.9774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4985

Saving model as e178_model.pt & e178_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999843646134532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 7.2676	Cost: 24.58s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 6.8705	Cost: 6.17s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 6.8962	Cost: 10.77s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 6.6961	Cost: 6.07s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 6.8847	Cost: 8.22s
Train Epoch: 179 	Average Loss: 6.9082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4727

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999841884419376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 7.4208	Cost: 23.13s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 6.9429	Cost: 6.08s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 6.8205	Cost: 7.93s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 6.7561	Cost: 5.80s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 6.7387	Cost: 6.12s
Train Epoch: 180 	Average Loss: 6.9135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4272

Saving model as e180_model.pt & e180_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999840112834775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 7.5005	Cost: 27.34s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 6.8699	Cost: 6.20s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 6.9204	Cost: 9.72s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 6.7678	Cost: 5.73s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 6.7042	Cost: 6.12s
Train Epoch: 181 	Average Loss: 6.9043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4679

Learning rate: 0.00019999838331380727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 7.3772	Cost: 24.21s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 6.8649	Cost: 6.19s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 6.8037	Cost: 8.56s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 6.7384	Cost: 5.83s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 6.7489	Cost: 8.04s
Train Epoch: 182 	Average Loss: 6.8537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4096

Saving model as e182_model.pt & e182_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999836540057235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 7.3336	Cost: 26.91s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 6.9769	Cost: 6.07s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 6.8731	Cost: 6.97s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 6.6296	Cost: 5.90s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 6.8335	Cost: 6.41s
Train Epoch: 183 	Average Loss: 6.8231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4241

Learning rate: 0.000199998347388643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 7.4402	Cost: 23.94s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 6.8037	Cost: 6.09s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 6.7513	Cost: 6.83s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 6.7191	Cost: 5.85s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 6.6766	Cost: 5.72s
Train Epoch: 184 	Average Loss: 6.8039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3939

Saving model as e184_model.pt & e184_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999832927801924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 7.4200	Cost: 29.71s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 6.8311	Cost: 6.82s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 6.7367	Cost: 11.01s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 6.5591	Cost: 5.78s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 6.9156	Cost: 7.53s
Train Epoch: 185 	Average Loss: 6.8233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4991

Learning rate: 0.00019999831106870108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 7.4531	Cost: 24.52s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 6.8594	Cost: 6.42s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 6.6520	Cost: 7.11s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 6.5873	Cost: 6.11s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 6.6223	Cost: 8.81s
Train Epoch: 186 	Average Loss: 6.7997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3618

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999829276068855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 7.4481	Cost: 38.54s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 6.6984	Cost: 6.03s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 6.7897	Cost: 8.26s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 6.5867	Cost: 5.92s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 6.5749	Cost: 8.00s
Train Epoch: 187 	Average Loss: 6.7731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3619

Learning rate: 0.00019999827435398168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 7.2636	Cost: 24.43s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 6.7163	Cost: 6.09s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 6.7521	Cost: 8.10s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 6.5206	Cost: 6.34s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 6.5635	Cost: 12.63s
Train Epoch: 188 	Average Loss: 6.7219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4476

Learning rate: 0.00019999825584858045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 7.3792	Cost: 24.43s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 6.6936	Cost: 6.10s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 6.7237	Cost: 8.42s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 6.4700	Cost: 5.81s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 6.4984	Cost: 6.26s
Train Epoch: 189 	Average Loss: 6.7091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3261

Saving model as e189_model.pt & e189_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999823724448486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 7.2351	Cost: 28.66s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 6.6460	Cost: 6.89s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 6.6052	Cost: 10.97s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 6.3560	Cost: 5.96s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 6.6608	Cost: 6.53s
Train Epoch: 190 	Average Loss: 6.6614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3036

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998218541695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 7.2893	Cost: 22.54s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 6.6482	Cost: 6.04s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 6.6005	Cost: 7.00s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 6.4906	Cost: 5.96s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 6.4968	Cost: 7.73s
Train Epoch: 191 	Average Loss: 6.6346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3515

Learning rate: 0.00019999819974021087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 7.2765	Cost: 26.40s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 6.6610	Cost: 6.01s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 6.6692	Cost: 8.02s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 6.3901	Cost: 5.94s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 6.5028	Cost: 8.61s
Train Epoch: 192 	Average Loss: 6.6210
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2718

Saving model as e192_model.pt & e192_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999818084003246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 7.2686	Cost: 22.31s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 6.5440	Cost: 6.47s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 6.4947	Cost: 10.59s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 6.4110	Cost: 6.13s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 6.4922	Cost: 11.05s
Train Epoch: 193 	Average Loss: 6.5660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3344

Learning rate: 0.00019999816184115978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 7.0981	Cost: 23.21s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 6.5286	Cost: 6.24s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 6.5251	Cost: 8.50s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 6.3222	Cost: 6.03s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 6.2768	Cost: 5.77s
Train Epoch: 194 	Average Loss: 6.5363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2977

Learning rate: 0.00019999814274359288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 7.3010	Cost: 25.83s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 6.6160	Cost: 6.66s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 6.5369	Cost: 11.51s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 6.3448	Cost: 6.23s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 6.4152	Cost: 8.80s
Train Epoch: 195 	Average Loss: 6.5403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1472

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999812354733177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 7.2351	Cost: 22.29s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 6.5140	Cost: 5.99s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 6.3545	Cost: 6.96s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 6.4097	Cost: 6.02s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 6.4476	Cost: 9.08s
Train Epoch: 196 	Average Loss: 6.5014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1693

Learning rate: 0.00019999810425237646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 7.2673	Cost: 23.47s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 6.5067	Cost: 6.17s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 6.3300	Cost: 8.51s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 6.1953	Cost: 6.05s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 6.2179	Cost: 6.39s
Train Epoch: 197 	Average Loss: 6.4776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1331

Saving model as e197_model.pt & e197_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999808485872698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 7.0992	Cost: 27.56s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 6.4980	Cost: 6.51s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 6.7230	Cost: 10.74s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 6.3493	Cost: 5.99s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 6.3934	Cost: 6.48s
Train Epoch: 198 	Average Loss: 6.5269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2156

Learning rate: 0.00019999806536638337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 7.2421	Cost: 24.36s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 6.3333	Cost: 6.62s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 6.4579	Cost: 10.23s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 6.1869	Cost: 6.22s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 6.3375	Cost: 11.32s
Train Epoch: 199 	Average Loss: 6.4597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1228

Saving model as e199_model.pt & e199_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999804577534562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 7.0586	Cost: 26.25s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 6.4262	Cost: 6.10s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 6.2974	Cost: 8.07s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 6.1173	Cost: 5.95s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 6.2339	Cost: 7.37s
Train Epoch: 200 	Average Loss: 6.3933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1425

Learning rate: 0.00019999802608561374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 7.0472	Cost: 22.42s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 6.4419	Cost: 6.44s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 6.2927	Cost: 9.23s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 6.2452	Cost: 6.25s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 6.2962	Cost: 11.75s
Train Epoch: 201 	Average Loss: 6.3950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1700

Learning rate: 0.00019999800629718777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 6.9716	Cost: 25.29s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 6.3277	Cost: 6.02s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 6.3802	Cost: 7.55s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 6.1326	Cost: 6.09s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 6.2474	Cost: 10.12s
Train Epoch: 202 	Average Loss: 6.3999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0744

Saving model as e202_model.pt & e202_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999798641006774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 7.1901	Cost: 23.00s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 6.2406	Cost: 6.80s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 6.2914	Cost: 10.76s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 6.2033	Cost: 6.17s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 6.1834	Cost: 11.47s
Train Epoch: 203 	Average Loss: 6.3207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0560

Saving model as e203_model.pt & e203_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999796642425366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 6.9718	Cost: 23.42s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 6.2788	Cost: 6.11s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 6.1466	Cost: 7.73s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 6.1146	Cost: 5.90s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 6.1319	Cost: 6.10s
Train Epoch: 204 	Average Loss: 6.3061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0293

Saving model as e204_model.pt & e204_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999794633974552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 6.9869	Cost: 23.29s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 6.3659	Cost: 6.10s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 6.2445	Cost: 8.43s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 6.0482	Cost: 6.03s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 6.0697	Cost: 6.05s
Train Epoch: 205 	Average Loss: 6.2628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9253

Saving model as e205_model.pt & e205_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999792615654335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 6.9212	Cost: 27.33s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 6.2247	Cost: 6.26s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 6.0925	Cost: 9.91s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 5.9996	Cost: 5.90s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 6.0635	Cost: 5.75s
Train Epoch: 206 	Average Loss: 6.2504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1051

Learning rate: 0.00019999790587464718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 6.9899	Cost: 23.85s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 6.2632	Cost: 6.09s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 6.1028	Cost: 7.79s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 5.8960	Cost: 6.08s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 6.0888	Cost: 6.26s
Train Epoch: 207 	Average Loss: 6.2077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9844

Learning rate: 0.00019999788549405706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 7.0669	Cost: 25.31s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 6.0854	Cost: 6.84s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 6.0532	Cost: 11.57s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 5.9499	Cost: 6.20s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 6.0578	Cost: 10.45s
Train Epoch: 208 	Average Loss: 6.2029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9989

Learning rate: 0.00019999786501477296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 6.8835	Cost: 23.25s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 6.2168	Cost: 6.24s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 6.1197	Cost: 7.93s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 5.9645	Cost: 5.77s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 5.9621	Cost: 5.68s
Train Epoch: 209 	Average Loss: 6.1671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9592

Learning rate: 0.00019999784443679492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 6.9887	Cost: 24.10s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 6.1059	Cost: 6.21s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 6.0383	Cost: 10.70s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 5.9125	Cost: 6.12s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 5.9479	Cost: 10.04s
Train Epoch: 210 	Average Loss: 6.1353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9835

Learning rate: 0.000199997823760123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 6.9214	Cost: 22.74s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 6.0912	Cost: 6.23s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 6.0677	Cost: 8.69s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 5.9624	Cost: 5.80s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 5.9308	Cost: 5.87s
Train Epoch: 211 	Average Loss: 6.1444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8817

Saving model as e211_model.pt & e211_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999780298475715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 6.9097	Cost: 26.53s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 6.0739	Cost: 6.16s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 6.0404	Cost: 8.49s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 5.8439	Cost: 5.77s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 5.9471	Cost: 6.25s
Train Epoch: 212 	Average Loss: 6.1030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9131

Learning rate: 0.00019999778211069746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 6.7076	Cost: 23.63s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 6.0909	Cost: 6.03s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 5.9663	Cost: 8.04s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 5.8472	Cost: 5.91s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 5.9017	Cost: 5.82s
Train Epoch: 213 	Average Loss: 6.0352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8556

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999977611379439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 6.7950	Cost: 27.87s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 6.0146	Cost: 6.10s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 5.8912	Cost: 8.04s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 5.7532	Cost: 5.99s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 5.9088	Cost: 8.87s
Train Epoch: 214 	Average Loss: 6.0200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9511

Learning rate: 0.00019999774006649652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 6.7580	Cost: 24.28s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 6.1086	Cost: 6.18s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 5.8267	Cost: 11.55s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 5.8805	Cost: 6.27s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 5.8667	Cost: 13.34s
Train Epoch: 215 	Average Loss: 6.0051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8623

Learning rate: 0.00019999771889635528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 6.8836	Cost: 27.71s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 6.0218	Cost: 6.13s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 5.9012	Cost: 8.63s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 5.8195	Cost: 5.94s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 6.0128	Cost: 8.96s
Train Epoch: 216 	Average Loss: 6.0301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0165

Learning rate: 0.00019999769762752028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 6.9933	Cost: 22.97s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 6.0823	Cost: 6.03s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 5.8705	Cost: 7.28s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 5.7312	Cost: 5.81s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 5.7245	Cost: 6.10s
Train Epoch: 217 	Average Loss: 6.0292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8401

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999767625999152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 6.7350	Cost: 23.72s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 5.8802	Cost: 6.03s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 5.9429	Cost: 7.11s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 5.7814	Cost: 6.09s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 5.7175	Cost: 10.59s
Train Epoch: 218 	Average Loss: 5.9514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8924

Learning rate: 0.00019999765479376897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 6.7964	Cost: 22.32s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 6.0215	Cost: 6.04s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 5.9619	Cost: 7.90s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 5.8100	Cost: 6.28s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 5.8105	Cost: 10.29s
Train Epoch: 219 	Average Loss: 5.9991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8841

Learning rate: 0.00019999763322885272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 6.7828	Cost: 26.68s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 5.9885	Cost: 6.22s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 5.8835	Cost: 10.06s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 5.5976	Cost: 5.69s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 5.6216	Cost: 5.73s
Train Epoch: 220 	Average Loss: 5.8877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7378

Saving model as e220_model.pt & e220_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999761156524275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 6.6502	Cost: 25.40s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 5.8351	Cost: 6.01s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 5.8215	Cost: 8.40s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 5.4384	Cost: 5.70s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 5.6796	Cost: 6.14s
Train Epoch: 221 	Average Loss: 5.8350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7923

Learning rate: 0.0001999975898029391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 6.7006	Cost: 36.82s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 5.8388	Cost: 10.36s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 5.7259	Cost: 11.42s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 5.6703	Cost: 6.47s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 5.5849	Cost: 10.98s
Train Epoch: 222 	Average Loss: 5.8285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7690

Learning rate: 0.00019999756794194176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 6.7025	Cost: 22.75s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 5.7039	Cost: 6.10s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 5.6401	Cost: 8.00s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 5.4908	Cost: 5.88s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 5.7074	Cost: 5.71s
Train Epoch: 223 	Average Loss: 5.7562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6885

Saving model as e223_model.pt & e223_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999975459822508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 6.6515	Cost: 36.91s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 5.7757	Cost: 6.14s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 5.7132	Cost: 9.94s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 5.6276	Cost: 6.21s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 5.5711	Cost: 8.06s
Train Epoch: 224 	Average Loss: 5.7629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6345

Saving model as e224_model.pt & e224_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999975239238662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 6.6785	Cost: 26.11s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 5.6183	Cost: 7.00s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 5.6220	Cost: 10.40s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 5.4765	Cost: 5.91s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 5.6109	Cost: 7.82s
Train Epoch: 225 	Average Loss: 5.7197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6705

Learning rate: 0.000199997501766788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 6.6952	Cost: 23.94s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 5.6915	Cost: 6.16s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 5.6588	Cost: 7.37s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 5.4198	Cost: 5.90s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 5.5364	Cost: 5.85s
Train Epoch: 226 	Average Loss: 5.6660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6737

Learning rate: 0.00019999747951101625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 6.6665	Cost: 28.79s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 5.7446	Cost: 6.35s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 5.5915	Cost: 8.67s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 5.3940	Cost: 5.94s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 5.5061	Cost: 5.85s
Train Epoch: 227 	Average Loss: 5.6768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6535

Learning rate: 0.0001999974571565509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 6.7333	Cost: 24.13s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 5.5705	Cost: 6.02s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 5.4907	Cost: 7.71s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 5.2968	Cost: 5.87s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 5.5914	Cost: 5.95s
Train Epoch: 228 	Average Loss: 5.6524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5736

Saving model as e228_model.pt & e228_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999743470339206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 6.5281	Cost: 29.01s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 5.6739	Cost: 6.68s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 5.5475	Cost: 11.10s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 5.3526	Cost: 6.17s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 5.2989	Cost: 5.75s
Train Epoch: 229 	Average Loss: 5.5972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6132

Learning rate: 0.0001999974121515397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 6.4994	Cost: 23.99s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 5.4800	Cost: 6.13s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 5.3849	Cost: 7.87s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 5.3876	Cost: 5.96s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 5.4141	Cost: 5.71s
Train Epoch: 230 	Average Loss: 5.5513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5189

Saving model as e230_model.pt & e230_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999738950099387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 6.6014	Cost: 26.61s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 5.5273	Cost: 6.04s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 5.4580	Cost: 7.20s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 5.2922	Cost: 6.04s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 5.2883	Cost: 7.13s
Train Epoch: 231 	Average Loss: 5.5385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5562

Learning rate: 0.00019999736675175452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 6.3546	Cost: 22.45s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 5.5842	Cost: 5.99s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 5.3309	Cost: 6.89s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 5.4422	Cost: 6.37s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 5.2919	Cost: 10.41s
Train Epoch: 232 	Average Loss: 5.5488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6179

Learning rate: 0.00019999734390382178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 6.4377	Cost: 26.43s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 5.5105	Cost: 6.06s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 5.4941	Cost: 8.04s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 5.3378	Cost: 5.99s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 5.4861	Cost: 7.12s
Train Epoch: 233 	Average Loss: 5.5351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4814

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999732095719557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 6.2602	Cost: 24.51s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 5.3361	Cost: 6.93s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 5.4210	Cost: 11.76s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 5.3014	Cost: 6.19s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 5.2439	Cost: 10.48s
Train Epoch: 234 	Average Loss: 5.4636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4970

Learning rate: 0.00019999729791187596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 6.4208	Cost: 22.24s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 5.4516	Cost: 6.06s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 5.4032	Cost: 8.38s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 5.1265	Cost: 5.82s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 5.2300	Cost: 6.16s
Train Epoch: 235 	Average Loss: 5.4163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4750

Saving model as e235_model.pt & e235_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199997274767863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 6.4626	Cost: 22.72s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 5.3276	Cost: 6.29s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 5.2979	Cost: 11.13s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 5.1444	Cost: 6.15s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 5.0814	Cost: 10.78s
Train Epoch: 236 	Average Loss: 5.4036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3957

Saving model as e236_model.pt & e236_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999972515251567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 6.3585	Cost: 21.82s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 5.3010	Cost: 6.10s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 5.2955	Cost: 8.82s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 5.1908	Cost: 6.03s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 5.1816	Cost: 8.56s
Train Epoch: 237 	Average Loss: 5.3568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4313

Learning rate: 0.00019999722818375706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 6.2710	Cost: 23.26s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 5.3884	Cost: 9.60s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 5.2163	Cost: 18.22s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 5.0405	Cost: 6.78s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 5.2283	Cost: 12.79s
Train Epoch: 238 	Average Loss: 5.3641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3925

Saving model as e238_model.pt & e238_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999720474366407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 6.2178	Cost: 26.59s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 5.2610	Cost: 6.05s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 5.2329	Cost: 8.17s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 5.0719	Cost: 5.90s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 5.0750	Cost: 7.97s
Train Epoch: 239 	Average Loss: 5.2940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4587

Learning rate: 0.00019999718120487783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 6.3575	Cost: 32.44s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 5.3645	Cost: 8.31s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 5.3250	Cost: 13.67s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 5.1260	Cost: 6.23s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 5.2170	Cost: 11.01s
Train Epoch: 240 	Average Loss: 5.3540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4006

Learning rate: 0.00019999715756739835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 6.2898	Cost: 23.80s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 5.2717	Cost: 6.02s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 5.1436	Cost: 7.43s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 4.9594	Cost: 5.71s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 5.1434	Cost: 5.81s
Train Epoch: 241 	Average Loss: 5.2645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4282

Learning rate: 0.00019999713383122558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 6.3167	Cost: 26.63s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 5.0578	Cost: 6.19s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 5.1262	Cost: 10.29s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 5.1427	Cost: 5.83s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 5.3502	Cost: 5.74s
Train Epoch: 242 	Average Loss: 5.2628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4954

Learning rate: 0.0001999971099963596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 6.7686	Cost: 24.39s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 5.3742	Cost: 6.01s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 5.3965	Cost: 8.02s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 5.1634	Cost: 5.69s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 5.2695	Cost: 6.22s
Train Epoch: 243 	Average Loss: 5.4364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4141

Learning rate: 0.00019999708606280046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 6.2414	Cost: 23.81s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 5.2431	Cost: 6.41s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 5.2475	Cost: 10.26s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 4.8228	Cost: 6.12s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 5.0352	Cost: 9.76s
Train Epoch: 244 	Average Loss: 5.2265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2908

Saving model as e244_model.pt & e244_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999706203054814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 6.1157	Cost: 23.01s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 5.1359	Cost: 6.20s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 5.1033	Cost: 10.25s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 4.9421	Cost: 5.73s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 4.8981	Cost: 7.14s
Train Epoch: 245 	Average Loss: 5.1657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2950

Learning rate: 0.00019999703789960266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 6.0906	Cost: 24.23s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 5.0531	Cost: 7.64s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 4.9824	Cost: 13.67s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 4.7985	Cost: 6.90s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 4.9678	Cost: 10.87s
Train Epoch: 246 	Average Loss: 5.1181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2579

Saving model as e246_model.pt & e246_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999701366996408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 6.1959	Cost: 23.45s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 4.9842	Cost: 6.14s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 4.8802	Cost: 8.93s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 4.6666	Cost: 6.36s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 4.8859	Cost: 11.77s
Train Epoch: 247 	Average Loss: 5.0381
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1553

Saving model as e247_model.pt & e247_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999969893416324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 5.9316	Cost: 23.20s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 4.9200	Cost: 6.02s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 4.9624	Cost: 7.84s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 4.7896	Cost: 5.71s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 4.8496	Cost: 6.33s
Train Epoch: 248 	Average Loss: 5.0502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1483

Saving model as e248_model.pt & e248_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999696491460766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 6.0125	Cost: 26.79s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 5.0619	Cost: 6.19s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 4.8247	Cost: 7.10s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 4.8771	Cost: 5.89s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 4.9517	Cost: 6.66s
Train Epoch: 249 	Average Loss: 5.0131
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1894

Learning rate: 0.00019999694038888986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 6.0932	Cost: 24.44s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 5.0014	Cost: 6.17s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 4.9000	Cost: 8.87s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 4.7464	Cost: 5.96s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 4.8914	Cost: 6.23s
Train Epoch: 250 	Average Loss: 5.0105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1744

Learning rate: 0.00019999691576447903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 6.1377	Cost: 25.95s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 4.9497	Cost: 6.33s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 4.8814	Cost: 12.34s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 4.7525	Cost: 6.31s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 4.7671	Cost: 10.50s
Train Epoch: 251 	Average Loss: 4.9687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1180

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999968910413752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 6.1188	Cost: 26.65s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 5.0291	Cost: 6.15s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 4.7425	Cost: 11.04s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 4.6712	Cost: 6.65s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 4.8391	Cost: 13.41s
Train Epoch: 252 	Average Loss: 4.9764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1584

Learning rate: 0.0001999968662195784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 6.0526	Cost: 27.13s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 4.8786	Cost: 6.10s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 4.7535	Cost: 8.62s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 4.7719	Cost: 6.08s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 4.8589	Cost: 6.87s
Train Epoch: 253 	Average Loss: 5.0030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1041

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999684129908864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 6.2630	Cost: 22.64s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 4.9055	Cost: 6.05s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 4.8342	Cost: 7.47s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 4.6673	Cost: 5.74s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 4.7480	Cost: 6.44s
Train Epoch: 254 	Average Loss: 4.9599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0766

Saving model as e254_model.pt & e254_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999681627990595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 6.1176	Cost: 27.12s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 4.8857	Cost: 6.24s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 4.8991	Cost: 10.86s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 4.7573	Cost: 5.82s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 4.8802	Cost: 6.04s
Train Epoch: 255 	Average Loss: 4.9680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1494

Learning rate: 0.00019999679116203034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 6.1654	Cost: 24.70s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 4.8675	Cost: 6.12s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 4.8068	Cost: 8.92s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 4.5441	Cost: 5.80s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 4.8195	Cost: 7.71s
Train Epoch: 256 	Average Loss: 4.9450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0352

Saving model as e256_model.pt & e256_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999967659454619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 5.9388	Cost: 27.01s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 4.7129	Cost: 6.04s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 4.7038	Cost: 8.08s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 4.5946	Cost: 6.03s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 4.5933	Cost: 8.24s
Train Epoch: 257 	Average Loss: 4.8242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0421

Learning rate: 0.00019999674063020056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 5.9573	Cost: 22.88s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 4.8068	Cost: 6.02s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 4.5767	Cost: 9.27s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 4.6917	Cost: 6.16s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 4.5472	Cost: 11.99s
Train Epoch: 258 	Average Loss: 4.7944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0343

Saving model as e258_model.pt & e258_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999671521624642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 5.9489	Cost: 24.94s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 4.7209	Cost: 6.07s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 4.6269	Cost: 8.99s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 4.4338	Cost: 5.65s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 4.6004	Cost: 6.02s
Train Epoch: 259 	Average Loss: 4.7084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9478

Saving model as e259_model.pt & e259_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999966897035995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 5.7439	Cost: 24.91s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 4.6327	Cost: 6.33s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 4.4946	Cost: 10.74s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 4.4297	Cost: 5.91s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 4.5103	Cost: 7.48s
Train Epoch: 260 	Average Loss: 4.6279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0082

Learning rate: 0.00019999666409225978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 5.7702	Cost: 26.39s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 4.4819	Cost: 6.09s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 4.5237	Cost: 7.86s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 4.4335	Cost: 6.01s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 4.4150	Cost: 6.52s
Train Epoch: 261 	Average Loss: 4.6325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9223

Saving model as e261_model.pt & e261_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999663838222732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 5.6575	Cost: 26.41s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 4.5361	Cost: 6.13s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 4.4685	Cost: 8.69s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 4.2963	Cost: 5.96s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 4.3473	Cost: 6.64s
Train Epoch: 262 	Average Loss: 4.6014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9098

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999661257350212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 5.7853	Cost: 22.81s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 4.6390	Cost: 6.25s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 4.3670	Cost: 8.91s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 4.3252	Cost: 6.25s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 4.3916	Cost: 11.51s
Train Epoch: 263 	Average Loss: 4.5729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8770

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999658666608423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 5.8117	Cost: 23.74s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 4.3986	Cost: 6.22s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 4.3736	Cost: 7.67s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 4.2593	Cost: 6.13s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 4.3000	Cost: 6.12s
Train Epoch: 264 	Average Loss: 4.5798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8886

Learning rate: 0.00019999656065997363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 5.6822	Cost: 26.14s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 4.5708	Cost: 6.25s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 4.5183	Cost: 10.51s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 4.4002	Cost: 5.91s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 4.3402	Cost: 7.05s
Train Epoch: 265 	Average Loss: 4.5922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8917

Learning rate: 0.00019999653455517042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 5.6603	Cost: 23.64s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 4.4609	Cost: 6.14s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 4.3636	Cost: 8.00s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 4.2788	Cost: 6.16s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 4.2775	Cost: 11.33s
Train Epoch: 266 	Average Loss: 4.5268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8126

Saving model as e266_model.pt & e266_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999650835167456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 5.7638	Cost: 33.35s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 4.3595	Cost: 8.55s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 4.3486	Cost: 9.47s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 4.3008	Cost: 5.90s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 4.2675	Cost: 6.29s
Train Epoch: 267 	Average Loss: 4.4515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8069

Saving model as e267_model.pt & e267_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999648204948613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 5.3827	Cost: 23.99s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 4.3778	Cost: 6.04s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 4.2923	Cost: 8.94s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 4.1558	Cost: 6.14s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 4.2863	Cost: 10.81s
Train Epoch: 268 	Average Loss: 4.4286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6924

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999964556486051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 5.5620	Cost: 23.70s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 4.3384	Cost: 6.10s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 4.1208	Cost: 8.58s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 4.2772	Cost: 5.74s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 4.3542	Cost: 6.05s
Train Epoch: 269 	Average Loss: 4.3992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7332

Learning rate: 0.00019999642914903155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 5.6116	Cost: 22.42s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 4.2392	Cost: 6.68s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 4.3009	Cost: 10.37s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 4.1688	Cost: 6.20s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 4.0819	Cost: 11.05s
Train Epoch: 270 	Average Loss: 4.4071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7239

Learning rate: 0.00019999640255076545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 5.6495	Cost: 25.07s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 4.2785	Cost: 6.07s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 4.2717	Cost: 8.11s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 5.6892	Cost: 5.90s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 5.4282	Cost: 6.21s
Train Epoch: 271 	Average Loss: 4.9813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6870

Learning rate: 0.0001999963758538069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 6.5030	Cost: 27.94s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 5.2006	Cost: 6.38s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 4.7743	Cost: 12.81s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 4.6938	Cost: 6.66s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 4.4806	Cost: 10.76s
Train Epoch: 272 	Average Loss: 5.0050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0368

Learning rate: 0.00019999634905815583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 5.9347	Cost: 26.12s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 4.6139	Cost: 5.99s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 4.2889	Cost: 7.54s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 4.2730	Cost: 6.06s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 4.3524	Cost: 8.47s
Train Epoch: 273 	Average Loss: 4.5065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7999

Learning rate: 0.00019999632216381234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 5.5455	Cost: 22.72s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 4.3808	Cost: 6.06s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 4.1379	Cost: 6.59s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 4.0971	Cost: 5.85s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 4.2276	Cost: 5.77s
Train Epoch: 274 	Average Loss: 4.4248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8048

Learning rate: 0.00019999629517077644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 5.7850	Cost: 26.91s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 4.2403	Cost: 6.35s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 4.4844	Cost: 10.50s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 4.4066	Cost: 5.94s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 4.4104	Cost: 6.59s
Train Epoch: 275 	Average Loss: 4.5361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9565

Learning rate: 0.00019999626807904816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 5.7372	Cost: 24.23s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 4.4335	Cost: 6.18s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 4.3963	Cost: 8.44s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 4.1311	Cost: 5.86s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 3.9958	Cost: 8.13s
Train Epoch: 276 	Average Loss: 4.4428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6698

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999962408886275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 5.5203	Cost: 26.49s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 4.2709	Cost: 6.04s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 4.2096	Cost: 7.08s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 3.9696	Cost: 5.82s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 3.9575	Cost: 7.94s
Train Epoch: 277 	Average Loss: 4.2546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6262

Saving model as e277_model.pt & e277_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999621359951451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 5.5056	Cost: 22.14s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 4.2186	Cost: 6.08s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 4.1025	Cost: 9.52s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 3.9579	Cost: 7.50s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 4.1290	Cost: 15.17s
Train Epoch: 278 	Average Loss: 4.2565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6517

Learning rate: 0.00019999618621170925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 5.5084	Cost: 26.03s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 4.2151	Cost: 6.01s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 4.0634	Cost: 7.16s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 4.1028	Cost: 5.96s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 4.0534	Cost: 7.76s
Train Epoch: 279 	Average Loss: 4.2402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5995

Saving model as e279_model.pt & e279_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999615872521166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 5.6020	Cost: 22.79s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 4.0813	Cost: 6.20s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 3.9580	Cost: 8.88s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 3.7384	Cost: 6.32s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 3.9253	Cost: 11.62s
Train Epoch: 280 	Average Loss: 4.1460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5347

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999613114002183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 5.5435	Cost: 23.40s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 4.0292	Cost: 6.30s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 4.0473	Cost: 10.73s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 3.8062	Cost: 6.16s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 3.8300	Cost: 11.38s
Train Epoch: 281 	Average Loss: 4.1137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5005

Saving model as e281_model.pt & e281_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999961034561398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 5.4221	Cost: 25.91s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 4.1241	Cost: 5.97s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 4.0050	Cost: 7.87s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 3.8961	Cost: 6.00s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 3.8700	Cost: 8.19s
Train Epoch: 282 	Average Loss: 4.1468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5802

Learning rate: 0.0001999960756735655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 5.4510	Cost: 22.71s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 3.9370	Cost: 6.01s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 3.8908	Cost: 7.93s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 3.6887	Cost: 5.73s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 3.7409	Cost: 7.04s
Train Epoch: 283 	Average Loss: 4.0259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4290

Saving model as e283_model.pt & e283_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999960477922991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 5.5520	Cost: 27.29s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 3.8833	Cost: 6.18s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 3.9293	Cost: 9.80s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 3.9299	Cost: 6.10s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 3.8478	Cost: 5.69s
Train Epoch: 284 	Average Loss: 4.0517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5441

Learning rate: 0.00019999601981234054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 5.6043	Cost: 23.38s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 3.8918	Cost: 6.15s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 3.8406	Cost: 9.61s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 3.7473	Cost: 5.78s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 3.7892	Cost: 7.47s
Train Epoch: 285 	Average Loss: 4.0014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4593

Learning rate: 0.00019999599173368987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 5.4277	Cost: 25.46s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 4.0474	Cost: 7.85s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 3.8047	Cost: 13.66s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 3.6102	Cost: 6.78s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 3.7327	Cost: 10.36s
Train Epoch: 286 	Average Loss: 3.9716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4221

Saving model as e286_model.pt & e286_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999596355634708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 5.5778	Cost: 25.49s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 3.8128	Cost: 6.05s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 3.7929	Cost: 7.06s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 3.5440	Cost: 5.96s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 3.7317	Cost: 9.72s
Train Epoch: 287 	Average Loss: 3.9392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5433

Learning rate: 0.00019999593528031228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 5.4954	Cost: 27.31s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 4.0258	Cost: 6.23s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 4.0118	Cost: 8.50s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 3.7848	Cost: 5.97s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 3.9171	Cost: 6.59s
Train Epoch: 288 	Average Loss: 4.0961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5737

Learning rate: 0.0001999959069055854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 5.3025	Cost: 22.57s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 4.0597	Cost: 6.09s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 3.9001	Cost: 6.85s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 3.6475	Cost: 6.51s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 3.7009	Cost: 9.06s
Train Epoch: 289 	Average Loss: 3.9620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3571

Saving model as e289_model.pt & e289_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999587843216654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 5.0311	Cost: 28.01s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 3.6057	Cost: 5.98s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 3.7153	Cost: 7.65s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 3.5621	Cost: 6.01s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 3.4532	Cost: 10.42s
Train Epoch: 290 	Average Loss: 3.7921
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3958

Learning rate: 0.00019999584986005571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 5.3115	Cost: 22.79s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 3.6750	Cost: 6.01s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 3.6702	Cost: 7.01s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 3.5214	Cost: 6.50s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 3.4092	Cost: 10.31s
Train Epoch: 291 	Average Loss: 3.7903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2312

Saving model as e291_model.pt & e291_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999582118925292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 5.1860	Cost: 31.53s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 3.5392	Cost: 6.15s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 3.5220	Cost: 11.04s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 3.3974	Cost: 6.04s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 3.3399	Cost: 7.89s
Train Epoch: 292 	Average Loss: 3.6857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2635

Learning rate: 0.00019999579241975824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 5.1074	Cost: 22.83s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 3.6847	Cost: 6.26s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 3.5753	Cost: 11.05s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 3.3861	Cost: 6.12s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 3.5847	Cost: 10.89s
Train Epoch: 293 	Average Loss: 3.7231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3051

Learning rate: 0.00019999576355157165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 5.2809	Cost: 23.53s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 3.5482	Cost: 6.01s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 3.5100	Cost: 6.76s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 3.2746	Cost: 5.89s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 3.3927	Cost: 6.16s
Train Epoch: 294 	Average Loss: 3.6243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2957

Learning rate: 0.0001999957345846932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 5.3277	Cost: 32.13s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 3.4335	Cost: 10.21s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 3.5625	Cost: 13.78s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 3.2851	Cost: 6.41s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 3.6102	Cost: 10.02s
Train Epoch: 295 	Average Loss: 3.6453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3457

Learning rate: 0.0001999957055191229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 5.0815	Cost: 24.20s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 3.5927	Cost: 6.04s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 3.9864	Cost: 7.46s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 3.6364	Cost: 5.74s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 3.6994	Cost: 5.87s
Train Epoch: 296 	Average Loss: 3.8692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4529

Learning rate: 0.0001999956763548608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 5.4629	Cost: 27.24s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 3.9016	Cost: 6.48s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 3.6557	Cost: 10.97s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 3.3450	Cost: 5.78s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 3.2937	Cost: 6.79s
Train Epoch: 297 	Average Loss: 3.7486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2415

Learning rate: 0.00019999564709190693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 5.1849	Cost: 23.37s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 3.6546	Cost: 6.02s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 3.4640	Cost: 7.80s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 3.2623	Cost: 5.85s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 3.4371	Cost: 6.02s
Train Epoch: 298 	Average Loss: 3.6198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2630

Learning rate: 0.00019999561773026132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 5.0725	Cost: 27.63s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 3.4564	Cost: 6.18s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 3.3584	Cost: 8.42s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 3.2769	Cost: 5.83s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 3.2273	Cost: 6.20s
Train Epoch: 299 	Average Loss: 3.5526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2050

Saving model as e299_model.pt & e299_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999558826992397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 5.0239	Cost: 22.38s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 3.3090	Cost: 6.04s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 3.2190	Cost: 7.66s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 3.3692	Cost: 5.82s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 3.2704	Cost: 8.93s
Train Epoch: 300 	Average Loss: 3.5014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1912

Saving model as e300_model.pt & e300_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999555871089494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 5.2380	Cost: 30.21s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 3.3193	Cost: 6.22s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 3.2386	Cost: 8.78s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 3.2897	Cost: 5.78s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 3.2297	Cost: 6.78s
Train Epoch: 301 	Average Loss: 3.4812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1070

Saving model as e301_model.pt & e301_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999552905317427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 5.0336	Cost: 27.40s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 3.3086	Cost: 6.17s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 3.1638	Cost: 7.08s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 3.0158	Cost: 5.99s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 3.2073	Cost: 7.70s
Train Epoch: 302 	Average Loss: 3.4028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0714

Saving model as e302_model.pt & e302_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999549929676196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 5.0037	Cost: 24.06s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 3.2683	Cost: 6.16s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 3.2508	Cost: 10.91s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 3.1321	Cost: 6.12s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 3.0912	Cost: 9.46s
Train Epoch: 303 	Average Loss: 3.3435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9422

Saving model as e303_model.pt & e303_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999546944165803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 4.8428	Cost: 23.16s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 3.1915	Cost: 6.12s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 3.1314	Cost: 8.04s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 3.0097	Cost: 5.69s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 3.1965	Cost: 5.93s
Train Epoch: 304 	Average Loss: 3.2717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9357

Saving model as e304_model.pt & e304_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999543948786254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 5.0633	Cost: 28.82s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 3.1699	Cost: 8.15s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 3.2694	Cost: 11.31s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 3.1785	Cost: 6.34s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 3.2106	Cost: 10.13s
Train Epoch: 305 	Average Loss: 3.3786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0919

Learning rate: 0.0001999954094353755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 5.2062	Cost: 22.99s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 3.2177	Cost: 6.21s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 3.2296	Cost: 8.56s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 3.4559	Cost: 5.86s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 3.3838	Cost: 6.46s
Train Epoch: 306 	Average Loss: 3.5223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2035

Learning rate: 0.00019999537928419694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 5.3465	Cost: 22.49s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 3.3784	Cost: 6.04s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 3.2368	Cost: 8.33s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 3.2174	Cost: 6.62s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 3.3227	Cost: 11.58s
Train Epoch: 307 	Average Loss: 3.5051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1928

Learning rate: 0.00019999534903432692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 4.7295	Cost: 23.47s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 3.3695	Cost: 6.12s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 3.0428	Cost: 8.71s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 2.8261	Cost: 6.18s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 3.0675	Cost: 6.14s
Train Epoch: 308 	Average Loss: 3.3274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9810

Learning rate: 0.00019999531868576542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 4.8942	Cost: 22.95s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 3.0221	Cost: 6.41s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 3.2315	Cost: 10.56s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 2.8969	Cost: 6.40s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 2.9484	Cost: 11.59s
Train Epoch: 309 	Average Loss: 3.2174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9192

Saving model as e309_model.pt & e309_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999528823851252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 5.0507	Cost: 23.94s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 3.3635	Cost: 6.18s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 3.0629	Cost: 7.90s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 2.9439	Cost: 5.85s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 2.9466	Cost: 5.89s
Train Epoch: 310 	Average Loss: 3.2287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9402

Learning rate: 0.00019999525769256822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 4.6814	Cost: 46.19s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 2.9163	Cost: 6.34s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 3.0360	Cost: 9.36s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 2.8082	Cost: 5.73s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 2.8771	Cost: 5.68s
Train Epoch: 311 	Average Loss: 3.1239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8722

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999522704793255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 4.6109	Cost: 23.16s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 3.0040	Cost: 6.06s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 2.9026	Cost: 9.12s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 2.8202	Cost: 6.15s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 2.8611	Cost: 8.51s
Train Epoch: 312 	Average Loss: 3.0956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8865

Learning rate: 0.00019999519630460553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 4.8036	Cost: 26.79s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 3.0035	Cost: 6.51s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 2.7680	Cost: 10.77s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 2.7379	Cost: 6.21s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 2.7984	Cost: 11.80s
Train Epoch: 313 	Average Loss: 3.0464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8778

Learning rate: 0.00019999516546258725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 4.7564	Cost: 22.81s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 2.9557	Cost: 6.00s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 2.8236	Cost: 8.05s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 2.8743	Cost: 6.26s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 2.7262	Cost: 10.36s
Train Epoch: 314 	Average Loss: 3.0879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8022

Saving model as e314_model.pt & e314_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999513452187764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 4.5763	Cost: 22.77s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 3.0212	Cost: 6.10s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 3.0832	Cost: 7.65s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 2.8167	Cost: 5.85s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 2.7680	Cost: 6.35s
Train Epoch: 315 	Average Loss: 3.1032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7505

Saving model as e315_model.pt & e315_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999951034824768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 4.8443	Cost: 45.23s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 2.7760	Cost: 7.71s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 2.6838	Cost: 11.24s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 2.5735	Cost: 5.83s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 2.7091	Cost: 6.83s
Train Epoch: 316 	Average Loss: 2.9742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7774

Learning rate: 0.00019999507234438478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 4.9024	Cost: 23.71s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 2.8300	Cost: 6.02s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 2.9648	Cost: 7.60s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 2.6735	Cost: 5.87s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 2.5967	Cost: 6.44s
Train Epoch: 317 	Average Loss: 2.9781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6849

Saving model as e317_model.pt & e317_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999504110760157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 4.5715	Cost: 26.97s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 2.8999	Cost: 6.14s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 3.0223	Cost: 7.64s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 2.8335	Cost: 5.81s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 2.6662	Cost: 6.63s
Train Epoch: 318 	Average Loss: 2.9775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7476

Learning rate: 0.0001999950097721272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 4.8826	Cost: 25.61s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 2.8529	Cost: 6.12s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 2.7640	Cost: 7.62s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 2.6004	Cost: 6.02s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 2.6275	Cost: 5.65s
Train Epoch: 319 	Average Loss: 2.9088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6665

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999497833796175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 4.4216	Cost: 27.40s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 2.8374	Cost: 5.99s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 2.5472	Cost: 7.82s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 2.5846	Cost: 5.98s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 2.6457	Cost: 7.88s
Train Epoch: 320 	Average Loss: 2.8510
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6652

Saving model as e320_model.pt & e320_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999494680510515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 4.5307	Cost: 22.25s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 2.6997	Cost: 6.33s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 2.5620	Cost: 10.85s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 2.5127	Cost: 7.03s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 2.4143	Cost: 12.10s
Train Epoch: 321 	Average Loss: 2.8105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5999

Saving model as e321_model.pt & e321_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999491517355754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 4.6971	Cost: 26.56s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 2.6871	Cost: 6.06s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 2.6238	Cost: 8.92s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 2.5919	Cost: 5.84s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 2.6578	Cost: 7.71s
Train Epoch: 322 	Average Loss: 2.8514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6506

Learning rate: 0.00019999488344331888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 4.7808	Cost: 39.37s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 2.8087	Cost: 7.76s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 2.7822	Cost: 11.98s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 2.3864	Cost: 6.20s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 2.4054	Cost: 10.52s
Train Epoch: 323 	Average Loss: 2.8030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6432

Learning rate: 0.00019999485161438922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 4.2342	Cost: 23.03s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 2.6518	Cost: 6.03s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 2.6256	Cost: 7.86s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 2.4239	Cost: 6.09s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 2.4873	Cost: 8.09s
Train Epoch: 324 	Average Loss: 2.7647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5757

Saving model as e324_model.pt & e324_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999948196867686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 4.5531	Cost: 26.12s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 2.5828	Cost: 6.10s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 2.5520	Cost: 6.65s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 2.3567	Cost: 6.05s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 2.4317	Cost: 7.93s
Train Epoch: 325 	Average Loss: 2.7308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6315

Learning rate: 0.00019999478766045706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 4.5142	Cost: 22.90s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 2.4222	Cost: 6.33s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 2.5123	Cost: 10.25s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 2.5056	Cost: 6.31s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 2.4652	Cost: 11.58s
Train Epoch: 326 	Average Loss: 2.7380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6807

Learning rate: 0.00019999475553545462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 4.5535	Cost: 26.68s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 2.7435	Cost: 6.28s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 2.5054	Cost: 7.91s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 2.4210	Cost: 5.84s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 2.2866	Cost: 6.41s
Train Epoch: 327 	Average Loss: 2.7893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4490

Saving model as e327_model.pt & e327_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999947233117613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 4.3848	Cost: 22.81s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 2.5542	Cost: 5.99s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 2.3474	Cost: 7.52s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 2.4916	Cost: 6.10s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 2.5633	Cost: 9.77s
Train Epoch: 328 	Average Loss: 2.6877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5381

Learning rate: 0.00019999469098937715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 4.3821	Cost: 25.92s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 2.4770	Cost: 6.03s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 2.3921	Cost: 7.29s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 2.2381	Cost: 5.97s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 2.1887	Cost: 8.09s
Train Epoch: 329 	Average Loss: 2.6209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3990

Saving model as e329_model.pt & e329_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999465856830218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 4.5310	Cost: 23.02s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 2.3284	Cost: 6.72s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 2.3257	Cost: 11.06s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 2.3735	Cost: 6.19s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 2.2752	Cost: 11.24s
Train Epoch: 330 	Average Loss: 2.5628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5309

Learning rate: 0.00019999462604853647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 4.5023	Cost: 23.16s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 2.5788	Cost: 6.16s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 2.3567	Cost: 9.39s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 2.2990	Cost: 5.95s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 2.2578	Cost: 7.72s
Train Epoch: 331 	Average Loss: 2.5722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4226

Learning rate: 0.00019999459343008003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 4.3120	Cost: 22.55s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 2.5343	Cost: 6.18s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 2.2793	Cost: 11.69s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 2.2800	Cost: 7.28s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 2.3370	Cost: 11.75s
Train Epoch: 332 	Average Loss: 2.5394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3724

Saving model as e332_model.pt & e332_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999456071293284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 4.3783	Cost: 27.38s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 2.3325	Cost: 6.19s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 2.1199	Cost: 9.62s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 2.1135	Cost: 5.68s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 2.1573	Cost: 6.39s
Train Epoch: 333 	Average Loss: 2.4448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3201

Saving model as e333_model.pt & e333_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999452789709498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 4.1070	Cost: 26.66s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 2.2018	Cost: 6.16s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 2.1884	Cost: 6.77s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 2.1240	Cost: 6.00s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 1.9964	Cost: 7.62s
Train Epoch: 334 	Average Loss: 2.3836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3904

Learning rate: 0.0001999944949825665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 4.5905	Cost: 22.20s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 2.3406	Cost: 6.05s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 2.2221	Cost: 7.95s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 2.2049	Cost: 6.23s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 2.2531	Cost: 11.63s
Train Epoch: 335 	Average Loss: 2.4941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3989

Learning rate: 0.0001999944619693474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 4.1471	Cost: 29.03s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 2.4520	Cost: 6.19s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 2.3660	Cost: 8.52s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 2.1532	Cost: 5.79s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 2.0765	Cost: 6.26s
Train Epoch: 336 	Average Loss: 2.4798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2779

Saving model as e336_model.pt & e336_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999442885743776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 4.2710	Cost: 23.17s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 2.2286	Cost: 6.05s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 2.1620	Cost: 8.70s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 2.0495	Cost: 5.88s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 2.1656	Cost: 8.16s
Train Epoch: 337 	Average Loss: 2.3319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2938

Learning rate: 0.00019999439564683753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 4.2800	Cost: 26.86s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 2.1841	Cost: 6.09s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 2.1153	Cost: 7.17s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 2.0180	Cost: 6.15s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 2.0114	Cost: 7.79s
Train Epoch: 338 	Average Loss: 2.2797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2946

Learning rate: 0.0001999943623375468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 4.0323	Cost: 24.90s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 2.1337	Cost: 6.27s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 2.0914	Cost: 9.04s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 2.0188	Cost: 5.92s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 1.9220	Cost: 6.00s
Train Epoch: 339 	Average Loss: 2.2908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2460

Saving model as e339_model.pt & e339_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999943289295656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 4.0959	Cost: 24.38s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 1.9551	Cost: 6.08s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 2.1042	Cost: 8.11s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 1.9924	Cost: 6.01s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 1.8931	Cost: 7.21s
Train Epoch: 340 	Average Loss: 2.2339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2660

Learning rate: 0.00019999429542289394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 4.2347	Cost: 25.74s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 2.1027	Cost: 6.36s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 2.1392	Cost: 11.70s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 2.0448	Cost: 6.12s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 1.8700	Cost: 9.58s
Train Epoch: 341 	Average Loss: 2.2714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1998

Saving model as e341_model.pt & e341_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999426181753187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 4.0145	Cost: 22.60s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 1.9675	Cost: 6.46s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 1.9368	Cost: 10.37s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 2.0128	Cost: 6.22s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 1.9694	Cost: 11.28s
Train Epoch: 342 	Average Loss: 2.1965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2009

Learning rate: 0.0001999942281134794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 4.2862	Cost: 24.84s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 2.0238	Cost: 6.19s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 2.0381	Cost: 8.51s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 1.8621	Cost: 6.07s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 1.8925	Cost: 6.07s
Train Epoch: 343 	Average Loss: 2.1569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1751

Saving model as e343_model.pt & e343_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999941943107366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 4.0702	Cost: 25.37s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 2.1390	Cost: 6.37s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 1.8595	Cost: 10.96s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 1.9996	Cost: 6.03s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 1.8587	Cost: 8.06s
Train Epoch: 344 	Average Loss: 2.1670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1974

Learning rate: 0.00019999416040930349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 4.4980	Cost: 23.79s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 2.1683	Cost: 6.02s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 2.0378	Cost: 8.14s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 1.8652	Cost: 6.01s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 1.8130	Cost: 5.94s
Train Epoch: 345 	Average Loss: 2.2123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2729

Learning rate: 0.0001999941264091801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 4.2455	Cost: 23.27s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 1.9707	Cost: 6.42s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 2.0456	Cost: 11.58s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 2.1226	Cost: 6.16s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 2.0451	Cost: 11.59s
Train Epoch: 346 	Average Loss: 2.2859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1634

Saving model as e346_model.pt & e346_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999409231036646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 4.0239	Cost: 24.21s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 2.1426	Cost: 6.04s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 2.1350	Cost: 8.69s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 1.9487	Cost: 6.26s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 1.9067	Cost: 11.66s
Train Epoch: 347 	Average Loss: 2.2357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1491

Saving model as e347_model.pt & e347_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999940581128626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 4.1763	Cost: 33.61s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 1.9678	Cost: 7.81s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 1.9429	Cost: 9.70s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 1.9547	Cost: 5.87s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 1.7719	Cost: 6.34s
Train Epoch: 348 	Average Loss: 2.1433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1103

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999402381666855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 4.0110	Cost: 23.75s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 1.9940	Cost: 6.08s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 2.0678	Cost: 8.14s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 1.8974	Cost: 5.81s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 1.7419	Cost: 6.10s
Train Epoch: 349 	Average Loss: 2.1495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1261

Learning rate: 0.0001999939894217844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 4.2323	Cost: 32.16s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 1.9692	Cost: 9.55s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 1.7936	Cost: 12.30s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 1.7151	Cost: 6.25s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 1.5758	Cost: 9.95s
Train Epoch: 350 	Average Loss: 2.0162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0346

Saving model as e350_model.pt & e350_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999939549282101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 3.5570	Cost: 22.65s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 1.8496	Cost: 6.03s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 1.6148	Cost: 8.01s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 1.5777	Cost: 5.87s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 1.5467	Cost: 7.74s
Train Epoch: 351 	Average Loss: 1.8931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9431

Saving model as e351_model.pt & e351_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999392033594573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 3.9042	Cost: 24.15s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 1.8505	Cost: 6.30s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 1.8399	Cost: 8.35s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 1.7162	Cost: 5.99s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 1.6824	Cost: 5.95s
Train Epoch: 352 	Average Loss: 1.9673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9872

Learning rate: 0.0001999938856449913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 3.8918	Cost: 22.39s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 1.7710	Cost: 6.85s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 1.6182	Cost: 11.43s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 1.6594	Cost: 6.30s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 1.6169	Cost: 11.43s
Train Epoch: 353 	Average Loss: 1.9491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0009

Learning rate: 0.00019999385085534688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 4.0103	Cost: 25.47s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 1.8094	Cost: 6.10s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 1.9989	Cost: 8.17s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 1.9030	Cost: 5.73s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 1.6591	Cost: 6.25s
Train Epoch: 354 	Average Loss: 2.1018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0664

Learning rate: 0.00019999381596701247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 3.7835	Cost: 28.66s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 1.8068	Cost: 7.55s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 1.6780	Cost: 12.36s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 1.5801	Cost: 6.88s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 1.5811	Cost: 10.66s
Train Epoch: 355 	Average Loss: 1.8467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9333

Saving model as e355_model.pt & e355_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999378097998813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 3.7861	Cost: 26.12s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 1.6903	Cost: 6.19s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 1.6083	Cost: 8.68s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 1.5844	Cost: 5.89s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 1.3916	Cost: 7.13s
Train Epoch: 356 	Average Loss: 1.8006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8482

Saving model as e356_model.pt & e356_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999374589427387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 3.6004	Cost: 26.64s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 1.5988	Cost: 6.18s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 1.5650	Cost: 8.65s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 1.3604	Cost: 5.75s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 1.4141	Cost: 6.87s
Train Epoch: 357 	Average Loss: 1.7550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8374

Saving model as e357_model.pt & e357_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999371070986973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 3.8208	Cost: 22.28s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 1.6575	Cost: 6.81s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 1.5217	Cost: 10.28s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 1.4216	Cost: 6.15s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 1.6101	Cost: 11.12s
Train Epoch: 358 	Average Loss: 1.7466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0310

Learning rate: 0.00019999367542677577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 3.9612	Cost: 24.26s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 1.8604	Cost: 6.02s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 1.8677	Cost: 8.44s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 1.6770	Cost: 5.89s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 1.4205	Cost: 6.55s
Train Epoch: 359 	Average Loss: 1.9504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8292

Saving model as e359_model.pt & e359_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999364004499203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 3.7293	Cost: 23.33s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 1.6209	Cost: 6.32s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 1.3360	Cost: 10.86s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 1.3528	Cost: 6.14s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 1.0930	Cost: 10.40s
Train Epoch: 360 	Average Loss: 1.6612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7399

Saving model as e360_model.pt & e360_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999936045645185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 3.7087	Cost: 24.02s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 1.5662	Cost: 5.98s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 1.3969	Cost: 7.91s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 1.3190	Cost: 5.68s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 1.3757	Cost: 6.51s
Train Epoch: 361 	Average Loss: 1.6292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7879

Learning rate: 0.00019999356898535523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 3.8010	Cost: 26.24s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 1.5661	Cost: 6.49s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 1.3220	Cost: 11.05s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 1.2588	Cost: 6.31s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 1.1408	Cost: 9.26s
Train Epoch: 362 	Average Loss: 1.5828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7344

Saving model as e362_model.pt & e362_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999935333075023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 3.7153	Cost: 23.69s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 1.3663	Cost: 6.02s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 1.3858	Cost: 8.06s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 1.5107	Cost: 5.73s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 1.3870	Cost: 5.97s
Train Epoch: 363 	Average Loss: 1.6663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8927

Learning rate: 0.0001999934975309597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 3.6582	Cost: 25.00s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 1.7854	Cost: 6.26s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 1.4783	Cost: 11.84s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 1.6380	Cost: 5.98s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 1.4918	Cost: 7.65s
Train Epoch: 364 	Average Loss: 1.7885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9058

Learning rate: 0.00019999346165572743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 3.5146	Cost: 23.70s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 1.5552	Cost: 6.09s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 1.3378	Cost: 7.75s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 1.1050	Cost: 5.90s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 1.1272	Cost: 5.74s
Train Epoch: 365 	Average Loss: 1.5443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6670

Saving model as e365_model.pt & e365_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999342568180562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 3.5036	Cost: 24.29s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 1.2791	Cost: 6.06s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 1.1605	Cost: 9.37s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 1.0709	Cost: 6.05s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 1.1073	Cost: 6.21s
Train Epoch: 366 	Average Loss: 1.4111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6892

Learning rate: 0.00019999338960919423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 3.8414	Cost: 22.04s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 1.1763	Cost: 6.35s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 1.1345	Cost: 9.28s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 1.0238	Cost: 6.31s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 1.1947	Cost: 11.23s
Train Epoch: 367 	Average Loss: 1.4394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7319

Learning rate: 0.0001999933534378933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 3.4279	Cost: 25.10s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 1.5529	Cost: 6.08s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 1.1480	Cost: 7.58s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 1.1703	Cost: 5.99s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 1.2944	Cost: 7.22s
Train Epoch: 368 	Average Loss: 1.5230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8760

Learning rate: 0.00019999331716790292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 3.8149	Cost: 22.18s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 1.6145	Cost: 5.99s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 1.3467	Cost: 7.78s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 1.1874	Cost: 6.46s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 0.9301	Cost: 10.71s
Train Epoch: 369 	Average Loss: 1.5556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6445

Saving model as e369_model.pt & e369_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999328079922307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 3.4815	Cost: 24.52s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 1.3399	Cost: 6.33s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 1.1949	Cost: 11.55s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 1.6320	Cost: 6.20s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 1.4331	Cost: 8.95s
Train Epoch: 370 	Average Loss: 1.6266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9169

Learning rate: 0.00019999324433185383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 3.6709	Cost: 22.40s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 1.3996	Cost: 6.92s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 1.2787	Cost: 10.83s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 1.2340	Cost: 6.34s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 1.0755	Cost: 11.75s
Train Epoch: 371 	Average Loss: 1.5109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6443

Saving model as e371_model.pt & e371_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999932077657952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 3.7017	Cost: 19.70s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 1.2716	Cost: 5.87s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 1.0583	Cost: 10.38s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 1.0513	Cost: 5.99s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 1.0466	Cost: 6.57s
Train Epoch: 372 	Average Loss: 1.3648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5302

Saving model as e372_model.pt & e372_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999317110104724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 3.5826	Cost: 24.85s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 1.3573	Cost: 9.40s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 1.3251	Cost: 13.74s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 1.0513	Cost: 7.42s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 0.8030	Cost: 11.15s
Train Epoch: 373 	Average Loss: 1.3485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4896

Saving model as e373_model.pt & e373_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999313433760997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 3.4013	Cost: 26.61s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 1.1601	Cost: 6.22s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 1.0603	Cost: 8.70s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 0.9314	Cost: 5.89s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 0.6989	Cost: 7.91s
Train Epoch: 374 	Average Loss: 1.2428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4248

Saving model as e374_model.pt & e374_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999309747548342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 3.3220	Cost: 26.28s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 0.9329	Cost: 6.04s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 0.9920	Cost: 6.60s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 0.9093	Cost: 6.02s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 0.9250	Cost: 8.02s
Train Epoch: 375 	Average Loss: 1.1902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4663

Learning rate: 0.00019999306051466764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 3.3737	Cost: 26.64s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 1.0235	Cost: 6.27s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 1.0051	Cost: 11.74s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 0.6855	Cost: 6.69s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 0.6803	Cost: 13.19s
Train Epoch: 376 	Average Loss: 1.1372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4648

Learning rate: 0.0001999930234551627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 3.3999	Cost: 26.76s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 1.0786	Cost: 6.13s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 0.9297	Cost: 8.43s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 0.6249	Cost: 5.76s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 0.7486	Cost: 7.33s
Train Epoch: 377 	Average Loss: 1.1227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4249

Learning rate: 0.00019999298629696857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 3.4273	Cost: 26.44s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 1.0559	Cost: 6.19s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 0.8591	Cost: 11.05s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 0.7998	Cost: 6.30s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 0.8905	Cost: 12.46s
Train Epoch: 378 	Average Loss: 1.1414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5176

Learning rate: 0.00019999294904008533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 3.3673	Cost: 26.73s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 1.1097	Cost: 5.99s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 1.1066	Cost: 7.71s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 0.8158	Cost: 6.10s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 0.9291	Cost: 8.48s
Train Epoch: 379 	Average Loss: 1.2466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5496

Learning rate: 0.000199992911684513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 3.1952	Cost: 22.50s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 1.1944	Cost: 6.07s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 0.8579	Cost: 7.65s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 0.6868	Cost: 6.46s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 0.5257	Cost: 9.67s
Train Epoch: 380 	Average Loss: 1.1146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3121

Saving model as e380_model.pt & e380_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999928742302516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 2.8973	Cost: 25.26s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 0.9322	Cost: 6.02s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 0.7087	Cost: 8.79s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 0.6905	Cost: 6.03s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 0.6860	Cost: 7.06s
Train Epoch: 381 	Average Loss: 0.9994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2907

Saving model as e381_model.pt & e381_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999283667730122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 3.2763	Cost: 24.94s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 1.1030	Cost: 7.41s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 1.0057	Cost: 10.75s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 0.8228	Cost: 6.29s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 0.5908	Cost: 12.37s
Train Epoch: 382 	Average Loss: 1.1045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3013

Learning rate: 0.00019999279902566184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 3.2238	Cost: 23.91s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 0.9303	Cost: 6.19s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 0.7596	Cost: 8.87s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 0.6746	Cost: 6.09s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 0.8195	Cost: 6.26s
Train Epoch: 383 	Average Loss: 1.0206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4009

Learning rate: 0.0001999927612753335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 3.3678	Cost: 32.29s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 0.9468	Cost: 11.74s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 0.6420	Cost: 11.93s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 0.5011	Cost: 6.82s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 0.5424	Cost: 10.16s
Train Epoch: 384 	Average Loss: 0.9440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2126

Saving model as e384_model.pt & e384_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999272342631632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 3.3153	Cost: 24.52s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 0.6534	Cost: 6.03s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 0.6271	Cost: 10.61s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 0.5570	Cost: 6.48s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 0.4583	Cost: 11.20s
Train Epoch: 385 	Average Loss: 0.8344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2593

Learning rate: 0.00019999268547861025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 3.1593	Cost: 25.01s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 0.9270	Cost: 6.84s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 0.5450	Cost: 11.74s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 0.5543	Cost: 6.22s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 0.5764	Cost: 11.27s
Train Epoch: 386 	Average Loss: 0.9248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2443

Learning rate: 0.00019999264743221536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 3.4563	Cost: 24.36s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 0.5838	Cost: 6.91s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 0.6500	Cost: 10.59s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 0.4298	Cost: 6.27s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 0.4324	Cost: 11.00s
Train Epoch: 387 	Average Loss: 0.8255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1487

Saving model as e387_model.pt & e387_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999260928713167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 3.0810	Cost: 23.74s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 0.6233	Cost: 6.03s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 0.5991	Cost: 8.61s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 0.3814	Cost: 5.85s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 0.3179	Cost: 8.05s
Train Epoch: 388 	Average Loss: 0.7904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2215

Learning rate: 0.00019999257104335924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 3.0457	Cost: 29.27s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 0.6370	Cost: 6.51s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 0.6252	Cost: 8.88s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 0.5949	Cost: 5.94s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 0.5159	Cost: 8.12s
Train Epoch: 389 	Average Loss: 0.8413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1975

Learning rate: 0.00019999253270089811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 3.0007	Cost: 29.87s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 0.6534	Cost: 8.65s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 0.3723	Cost: 12.64s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 0.3971	Cost: 6.83s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 0.3822	Cost: 13.84s
Train Epoch: 390 	Average Loss: 0.7789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1279

Saving model as e390_model.pt & e390_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999924942597483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 3.2710	Cost: 22.49s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 0.8794	Cost: 6.24s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 0.7581	Cost: 9.73s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 0.6254	Cost: 6.09s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 0.3486	Cost: 8.09s
Train Epoch: 391 	Average Loss: 0.8735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2933

Learning rate: 0.00019999245571990988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 3.2849	Cost: 25.66s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 1.1470	Cost: 9.29s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 0.7557	Cost: 16.03s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 0.6060	Cost: 7.85s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 0.5290	Cost: 10.93s
Train Epoch: 392 	Average Loss: 1.0423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1437

Learning rate: 0.00019999241708138285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 3.2893	Cost: 24.91s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 0.7989	Cost: 6.15s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 0.4928	Cost: 8.34s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 0.3404	Cost: 6.13s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 0.5480	Cost: 6.79s
Train Epoch: 393 	Average Loss: 0.8243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1683

Learning rate: 0.00019999237834416724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 3.1905	Cost: 23.36s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 0.7855	Cost: 6.07s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 0.4896	Cost: 9.36s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 0.2957	Cost: 6.29s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 0.2198	Cost: 11.26s
Train Epoch: 394 	Average Loss: 0.7082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0468

Saving model as e394_model.pt & e394_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999923395082631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 3.0835	Cost: 27.30s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 0.5392	Cost: 6.32s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 0.5746	Cost: 9.61s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 0.3301	Cost: 6.16s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 0.1671	Cost: 9.09s
Train Epoch: 395 	Average Loss: 0.6656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0226

Saving model as e395_model.pt & e395_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999923005736705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 3.2032	Cost: 30.57s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 0.2865	Cost: 5.90s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 0.3116	Cost: 8.21s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 0.2332	Cost: 6.15s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 0.0967	Cost: 7.90s
Train Epoch: 396 	Average Loss: 0.5415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9326

Saving model as e396_model.pt & e396_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999226154038944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 2.7403	Cost: 28.27s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 0.4313	Cost: 7.26s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 0.4969	Cost: 10.72s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 0.3975	Cost: 6.11s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 0.2064	Cost: 8.24s
Train Epoch: 397 	Average Loss: 0.6192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9965

Learning rate: 0.00019999222240841996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 3.0465	Cost: 24.87s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 0.5008	Cost: 6.12s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 0.2513	Cost: 8.37s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 0.1763	Cost: 5.82s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -0.0504	Cost: 6.81s
Train Epoch: 398 	Average Loss: 0.4586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8866

Saving model as e398_model.pt & e398_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999218317776212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 2.9479	Cost: 32.98s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 0.3063	Cost: 6.73s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 0.2825	Cost: 11.13s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 0.2463	Cost: 6.12s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 0.2224	Cost: 6.26s
Train Epoch: 399 	Average Loss: 0.5083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0880

Learning rate: 0.00019999214384841597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 2.9458	Cost: 24.16s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 0.5296	Cost: 6.27s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 0.2637	Cost: 9.75s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 0.2438	Cost: 6.06s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 0.1770	Cost: 6.70s
Train Epoch: 400 	Average Loss: 0.5519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9254

Learning rate: 0.00019999210442038154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 2.7267	Cost: 37.39s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 0.3089	Cost: 8.43s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 0.1817	Cost: 12.13s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 0.0242	Cost: 6.50s
Train Epoch: 401 [81920/90000 (91%)]	Loss: -0.0024	Cost: 10.07s
Train Epoch: 401 	Average Loss: 0.3891
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8381

Saving model as e401_model.pt & e401_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999206489365883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 3.0251	Cost: 24.09s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 0.1831	Cost: 7.22s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 0.0438	Cost: 10.70s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 0.1909	Cost: 6.33s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 0.2047	Cost: 10.89s
Train Epoch: 402 	Average Loss: 0.4248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9537

Learning rate: 0.0001999920252682479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 2.5568	Cost: 23.47s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 0.3987	Cost: 6.65s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 0.0434	Cost: 11.55s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 0.0635	Cost: 6.12s
Train Epoch: 403 [81920/90000 (91%)]	Loss: -0.0166	Cost: 11.30s
Train Epoch: 403 	Average Loss: 0.4392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7627

Saving model as e403_model.pt & e403_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999198554414882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 2.4752	Cost: 30.93s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 0.1760	Cost: 6.10s
Train Epoch: 404 [40960/90000 (45%)]	Loss: -0.1664	Cost: 8.44s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 0.0482	Cost: 6.01s
Train Epoch: 404 [81920/90000 (91%)]	Loss: -0.1827	Cost: 10.85s
Train Epoch: 404 	Average Loss: 0.2820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7724

Learning rate: 0.0001999919457213616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 2.4957	Cost: 23.48s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 0.2710	Cost: 6.14s
Train Epoch: 405 [40960/90000 (45%)]	Loss: -0.0397	Cost: 9.78s
Train Epoch: 405 [61440/90000 (68%)]	Loss: -0.1371	Cost: 9.04s
Train Epoch: 405 [81920/90000 (91%)]	Loss: -0.0344	Cost: 15.08s
Train Epoch: 405 	Average Loss: 0.3347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8434

Learning rate: 0.00019999190579988627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 2.7382	Cost: 26.70s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 0.2077	Cost: 6.03s
Train Epoch: 406 [40960/90000 (45%)]	Loss: -0.0764	Cost: 8.94s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 0.0016	Cost: 6.06s
Train Epoch: 406 [81920/90000 (91%)]	Loss: -0.2428	Cost: 7.48s
Train Epoch: 406 	Average Loss: 0.2864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7137

Saving model as e406_model.pt & e406_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999918657797229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 2.5476	Cost: 22.16s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 0.2253	Cost: 7.01s
Train Epoch: 407 [40960/90000 (45%)]	Loss: -0.0636	Cost: 10.34s
Train Epoch: 407 [61440/90000 (68%)]	Loss: -0.1946	Cost: 6.23s
Train Epoch: 407 [81920/90000 (91%)]	Loss: -0.1912	Cost: 11.50s
Train Epoch: 407 	Average Loss: 0.2195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7897

Learning rate: 0.00019999182566087152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 3.0885	Cost: 27.57s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 0.1057	Cost: 6.30s
Train Epoch: 408 [40960/90000 (45%)]	Loss: -0.1174	Cost: 10.11s
Train Epoch: 408 [61440/90000 (68%)]	Loss: -0.2136	Cost: 5.91s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 0.1508	Cost: 10.01s
Train Epoch: 408 	Average Loss: 0.3446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1083

Learning rate: 0.00019999178544333215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 3.0532	Cost: 32.13s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 0.3536	Cost: 10.65s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 0.4648	Cost: 11.31s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 0.4534	Cost: 6.85s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 0.4235	Cost: 10.60s
Train Epoch: 409 	Average Loss: 0.6819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0245

Learning rate: 0.00019999174512710485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 3.1471	Cost: 24.23s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 0.5648	Cost: 6.21s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 0.2070	Cost: 8.31s
Train Epoch: 410 [61440/90000 (68%)]	Loss: -0.0031	Cost: 6.12s
Train Epoch: 410 [81920/90000 (91%)]	Loss: -0.1512	Cost: 6.32s
Train Epoch: 410 	Average Loss: 0.4083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7417

Learning rate: 0.00019999170471218965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 2.7394	Cost: 30.97s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 0.0594	Cost: 7.12s
Train Epoch: 411 [40960/90000 (45%)]	Loss: -0.1970	Cost: 11.37s
Train Epoch: 411 [61440/90000 (68%)]	Loss: -0.2525	Cost: 6.20s
Train Epoch: 411 [81920/90000 (91%)]	Loss: -0.3102	Cost: 6.53s
Train Epoch: 411 	Average Loss: 0.1322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6450

Saving model as e411_model.pt & e411_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999916641985866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 2.7393	Cost: 26.38s
Train Epoch: 412 [20480/90000 (23%)]	Loss: -0.0896	Cost: 6.16s
Train Epoch: 412 [40960/90000 (45%)]	Loss: -0.1237	Cost: 8.05s
Train Epoch: 412 [61440/90000 (68%)]	Loss: -0.2457	Cost: 6.34s
Train Epoch: 412 [81920/90000 (91%)]	Loss: -0.3205	Cost: 6.14s
Train Epoch: 412 	Average Loss: 0.0706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6954

Learning rate: 0.00019999162358629572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 2.1798	Cost: 28.37s
Train Epoch: 413 [20480/90000 (23%)]	Loss: -0.1249	Cost: 6.78s
Train Epoch: 413 [40960/90000 (45%)]	Loss: -0.2385	Cost: 9.44s
Train Epoch: 413 [61440/90000 (68%)]	Loss: -0.2553	Cost: 6.05s
Train Epoch: 413 [81920/90000 (91%)]	Loss: -0.3329	Cost: 6.64s
Train Epoch: 413 	Average Loss: 0.0455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6722

Learning rate: 0.0001999915828753171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 2.4670	Cost: 26.05s
Train Epoch: 414 [20480/90000 (23%)]	Loss: -0.0167	Cost: 6.27s
Train Epoch: 414 [40960/90000 (45%)]	Loss: -0.1041	Cost: 9.21s
Train Epoch: 414 [61440/90000 (68%)]	Loss: -0.2313	Cost: 5.86s
Train Epoch: 414 [81920/90000 (91%)]	Loss: -0.0981	Cost: 7.06s
Train Epoch: 414 	Average Loss: 0.0910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6577

Learning rate: 0.0001999915420656507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 3.1181	Cost: 37.16s
Train Epoch: 415 [20480/90000 (23%)]	Loss: -0.0482	Cost: 18.40s
Train Epoch: 415 [40960/90000 (45%)]	Loss: -0.2301	Cost: 17.10s
Train Epoch: 415 [61440/90000 (68%)]	Loss: -0.2615	Cost: 17.04s
Train Epoch: 415 [81920/90000 (91%)]	Loss: -0.4666	Cost: 18.00s
Train Epoch: 415 	Average Loss: 0.0519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5316

Saving model as e415_model.pt & e415_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999915011572966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 2.5028	Cost: 25.59s
Train Epoch: 416 [20480/90000 (23%)]	Loss: -0.1319	Cost: 6.07s
Train Epoch: 416 [40960/90000 (45%)]	Loss: -0.1690	Cost: 8.51s
Train Epoch: 416 [61440/90000 (68%)]	Loss: -0.0962	Cost: 5.88s
Train Epoch: 416 [81920/90000 (91%)]	Loss: -0.2530	Cost: 6.64s
Train Epoch: 416 	Average Loss: 0.0445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6615

Learning rate: 0.0001999914601502549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 2.3481	Cost: 22.27s
Train Epoch: 417 [20480/90000 (23%)]	Loss: -0.0408	Cost: 6.55s
Train Epoch: 417 [40960/90000 (45%)]	Loss: -0.2671	Cost: 10.33s
Train Epoch: 417 [61440/90000 (68%)]	Loss: -0.3866	Cost: 6.40s
Train Epoch: 417 [81920/90000 (91%)]	Loss: -0.4276	Cost: 11.69s
Train Epoch: 417 	Average Loss: 0.0820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5807

Learning rate: 0.00019999141904452554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 2.3289	Cost: 24.96s
Train Epoch: 418 [20480/90000 (23%)]	Loss: -0.3126	Cost: 6.13s
Train Epoch: 418 [40960/90000 (45%)]	Loss: -0.4565	Cost: 8.35s
Train Epoch: 418 [61440/90000 (68%)]	Loss: -0.3124	Cost: 6.16s
Train Epoch: 418 [81920/90000 (91%)]	Loss: -0.4590	Cost: 5.84s
Train Epoch: 418 	Average Loss: -0.0877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4280

Saving model as e418_model.pt & e418_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999913778401086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 2.2591	Cost: 26.47s
Train Epoch: 419 [20480/90000 (23%)]	Loss: -0.1241	Cost: 6.84s
Train Epoch: 419 [40960/90000 (45%)]	Loss: -0.3719	Cost: 11.30s
Train Epoch: 419 [61440/90000 (68%)]	Loss: -0.7704	Cost: 6.21s
Train Epoch: 419 [81920/90000 (91%)]	Loss: -0.5693	Cost: 8.62s
Train Epoch: 419 	Average Loss: -0.1415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3881

Saving model as e419_model.pt & e419_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999133653700416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 2.1611	Cost: 23.31s
Train Epoch: 420 [20480/90000 (23%)]	Loss: -0.2681	Cost: 6.03s
Train Epoch: 420 [40960/90000 (45%)]	Loss: -0.5706	Cost: 7.49s
Train Epoch: 420 [61440/90000 (68%)]	Loss: -0.5040	Cost: 5.77s
Train Epoch: 420 [81920/90000 (91%)]	Loss: -0.3827	Cost: 5.81s
Train Epoch: 420 	Average Loss: -0.1584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4221

Learning rate: 0.0001999912951352122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 2.4828	Cost: 25.79s
Train Epoch: 421 [20480/90000 (23%)]	Loss: -0.3498	Cost: 6.26s
Train Epoch: 421 [40960/90000 (45%)]	Loss: -0.4937	Cost: 11.21s
Train Epoch: 421 [61440/90000 (68%)]	Loss: -0.6355	Cost: 5.88s
Train Epoch: 421 [81920/90000 (91%)]	Loss: -0.3973	Cost: 6.83s
Train Epoch: 421 	Average Loss: -0.1192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6570

Learning rate: 0.0001999912536347328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 2.5218	Cost: 25.91s
Train Epoch: 422 [20480/90000 (23%)]	Loss: -0.2802	Cost: 6.33s
Train Epoch: 422 [40960/90000 (45%)]	Loss: -0.3071	Cost: 11.23s
Train Epoch: 422 [61440/90000 (68%)]	Loss: -0.4739	Cost: 6.10s
Train Epoch: 422 [81920/90000 (91%)]	Loss: -0.6239	Cost: 8.35s
Train Epoch: 422 	Average Loss: -0.1029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5777

Learning rate: 0.00019999121203556597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 2.5543	Cost: 25.04s
Train Epoch: 423 [20480/90000 (23%)]	Loss: -0.3628	Cost: 5.92s
Train Epoch: 423 [40960/90000 (45%)]	Loss: -0.6394	Cost: 9.06s
Train Epoch: 423 [61440/90000 (68%)]	Loss: -0.5750	Cost: 6.21s
Train Epoch: 423 [81920/90000 (91%)]	Loss: -0.7074	Cost: 11.91s
Train Epoch: 423 	Average Loss: -0.2250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3526

Saving model as e423_model.pt & e423_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999911703377118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 2.0439	Cost: 43.49s
Train Epoch: 424 [20480/90000 (23%)]	Loss: -0.4905	Cost: 6.08s
Train Epoch: 424 [40960/90000 (45%)]	Loss: -0.7641	Cost: 9.34s
Train Epoch: 424 [61440/90000 (68%)]	Loss: -0.6273	Cost: 5.90s
Train Epoch: 424 [81920/90000 (91%)]	Loss: -0.7045	Cost: 5.83s
Train Epoch: 424 	Average Loss: -0.3748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3511

Saving model as e424_model.pt & e424_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999112854117028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 2.2428	Cost: 22.59s
Train Epoch: 425 [20480/90000 (23%)]	Loss: -0.3835	Cost: 6.43s
Train Epoch: 425 [40960/90000 (45%)]	Loss: -0.5181	Cost: 10.88s
Train Epoch: 425 [61440/90000 (68%)]	Loss: -0.6163	Cost: 6.32s
Train Epoch: 425 [81920/90000 (91%)]	Loss: -0.8412	Cost: 11.32s
Train Epoch: 425 	Average Loss: -0.3201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4097

Learning rate: 0.00019999108664594148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 2.4289	Cost: 24.14s
Train Epoch: 426 [20480/90000 (23%)]	Loss: -0.1241	Cost: 6.12s
Train Epoch: 426 [40960/90000 (45%)]	Loss: -0.2892	Cost: 9.18s
Train Epoch: 426 [61440/90000 (68%)]	Loss: -0.3891	Cost: 5.85s
Train Epoch: 426 [81920/90000 (91%)]	Loss: -0.7222	Cost: 6.48s
Train Epoch: 426 	Average Loss: -0.1628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4853

Learning rate: 0.0001999910446520254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 2.4231	Cost: 22.95s
Train Epoch: 427 [20480/90000 (23%)]	Loss: -0.2285	Cost: 6.11s
Train Epoch: 427 [40960/90000 (45%)]	Loss: -0.4141	Cost: 10.20s
Train Epoch: 427 [61440/90000 (68%)]	Loss: -0.6991	Cost: 6.20s
Train Epoch: 427 [81920/90000 (91%)]	Loss: -0.8240	Cost: 11.93s
Train Epoch: 427 	Average Loss: -0.1717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3397

Saving model as e427_model.pt & e427_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999100255942216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 2.5094	Cost: 24.43s
Train Epoch: 428 [20480/90000 (23%)]	Loss: -0.3946	Cost: 6.08s
Train Epoch: 428 [40960/90000 (45%)]	Loss: -0.6592	Cost: 8.67s
Train Epoch: 428 [61440/90000 (68%)]	Loss: -0.8115	Cost: 5.87s
Train Epoch: 428 [81920/90000 (91%)]	Loss: -0.6458	Cost: 5.67s
Train Epoch: 428 	Average Loss: -0.3189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3420

Learning rate: 0.00019999096036813171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 2.3477	Cost: 26.06s
Train Epoch: 429 [20480/90000 (23%)]	Loss: -0.2248	Cost: 7.93s
Train Epoch: 429 [40960/90000 (45%)]	Loss: -0.4208	Cost: 15.17s
Train Epoch: 429 [61440/90000 (68%)]	Loss: -0.6928	Cost: 7.12s
Train Epoch: 429 [81920/90000 (91%)]	Loss: -0.8344	Cost: 10.11s
Train Epoch: 429 	Average Loss: -0.2338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1771

Saving model as e429_model.pt & e429_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999909180781542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 2.3337	Cost: 26.25s
Train Epoch: 430 [20480/90000 (23%)]	Loss: -0.5069	Cost: 6.03s
Train Epoch: 430 [40960/90000 (45%)]	Loss: -0.7584	Cost: 8.03s
Train Epoch: 430 [61440/90000 (68%)]	Loss: -0.8308	Cost: 6.28s
Train Epoch: 430 [81920/90000 (91%)]	Loss: -0.7679	Cost: 9.73s
Train Epoch: 430 	Average Loss: -0.4135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3392

Learning rate: 0.00019999087568948958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 2.4769	Cost: 26.72s
Train Epoch: 431 [20480/90000 (23%)]	Loss: -0.5686	Cost: 6.02s
Train Epoch: 431 [40960/90000 (45%)]	Loss: -0.7877	Cost: 7.63s
Train Epoch: 431 [61440/90000 (68%)]	Loss: -1.0957	Cost: 5.88s
Train Epoch: 431 [81920/90000 (91%)]	Loss: -0.9742	Cost: 7.94s
Train Epoch: 431 	Average Loss: -0.4613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2360

Learning rate: 0.0001999908332021379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 2.2235	Cost: 22.92s
Train Epoch: 432 [20480/90000 (23%)]	Loss: -0.6357	Cost: 6.00s
Train Epoch: 432 [40960/90000 (45%)]	Loss: -0.7935	Cost: 7.73s
Train Epoch: 432 [61440/90000 (68%)]	Loss: -1.0141	Cost: 6.08s
Train Epoch: 432 [81920/90000 (91%)]	Loss: -1.0111	Cost: 6.54s
Train Epoch: 432 	Average Loss: -0.5075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1848

Learning rate: 0.00019999079061609924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 2.0377	Cost: 25.55s
Train Epoch: 433 [20480/90000 (23%)]	Loss: -0.7983	Cost: 6.33s
Train Epoch: 433 [40960/90000 (45%)]	Loss: -0.8162	Cost: 10.43s
Train Epoch: 433 [61440/90000 (68%)]	Loss: -0.9013	Cost: 6.02s
Train Epoch: 433 [81920/90000 (91%)]	Loss: -0.8952	Cost: 6.34s
Train Epoch: 433 	Average Loss: -0.5504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1046

Saving model as e433_model.pt & e433_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999074793137364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 2.3187	Cost: 23.24s
Train Epoch: 434 [20480/90000 (23%)]	Loss: -0.8344	Cost: 6.00s
Train Epoch: 434 [40960/90000 (45%)]	Loss: -1.0151	Cost: 7.72s
Train Epoch: 434 [61440/90000 (68%)]	Loss: -1.0352	Cost: 5.75s
Train Epoch: 434 [81920/90000 (91%)]	Loss: -1.0195	Cost: 6.50s
Train Epoch: 434 	Average Loss: -0.6262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1859

Learning rate: 0.00019999070514796111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 2.3119	Cost: 28.87s
Train Epoch: 435 [20480/90000 (23%)]	Loss: -0.7285	Cost: 6.23s
Train Epoch: 435 [40960/90000 (45%)]	Loss: -0.9444	Cost: 10.29s
Train Epoch: 435 [61440/90000 (68%)]	Loss: -0.7898	Cost: 5.78s
Train Epoch: 435 [81920/90000 (91%)]	Loss: -1.0936	Cost: 6.35s
Train Epoch: 435 	Average Loss: -0.5873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2570

Learning rate: 0.00019999066226586174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 2.1503	Cost: 23.76s
Train Epoch: 436 [20480/90000 (23%)]	Loss: -0.7913	Cost: 6.56s
Train Epoch: 436 [40960/90000 (45%)]	Loss: -0.9276	Cost: 11.03s
Train Epoch: 436 [61440/90000 (68%)]	Loss: -0.8482	Cost: 6.38s
Train Epoch: 436 [81920/90000 (91%)]	Loss: -0.6271	Cost: 9.27s
Train Epoch: 436 	Average Loss: -0.4770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4151

Learning rate: 0.00019999061928507552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 2.6711	Cost: 26.86s
Train Epoch: 437 [20480/90000 (23%)]	Loss: -0.4702	Cost: 6.20s
Train Epoch: 437 [40960/90000 (45%)]	Loss: -0.7632	Cost: 10.56s
Train Epoch: 437 [61440/90000 (68%)]	Loss: -0.9491	Cost: 5.67s
Train Epoch: 437 [81920/90000 (91%)]	Loss: -1.0185	Cost: 6.19s
Train Epoch: 437 	Average Loss: -0.4372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1390

Learning rate: 0.0001999905762056025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 1.9190	Cost: 22.94s
Train Epoch: 438 [20480/90000 (23%)]	Loss: -0.5821	Cost: 6.17s
Train Epoch: 438 [40960/90000 (45%)]	Loss: -0.7072	Cost: 8.27s
Train Epoch: 438 [61440/90000 (68%)]	Loss: 0.0807	Cost: 6.09s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 0.5594	Cost: 5.82s
Train Epoch: 438 	Average Loss: -0.0870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2108

Learning rate: 0.00019999053302744273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 3.1930	Cost: 22.48s
Train Epoch: 439 [20480/90000 (23%)]	Loss: 0.2624	Cost: 6.15s
Train Epoch: 439 [40960/90000 (45%)]	Loss: -0.3661	Cost: 9.11s
Train Epoch: 439 [61440/90000 (68%)]	Loss: -0.4327	Cost: 6.25s
Train Epoch: 439 [81920/90000 (91%)]	Loss: -0.5656	Cost: 11.72s
Train Epoch: 439 	Average Loss: 0.0613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5476

Learning rate: 0.00019999048975059627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 2.7885	Cost: 31.86s
Train Epoch: 440 [20480/90000 (23%)]	Loss: -0.5686	Cost: 6.79s
Train Epoch: 440 [40960/90000 (45%)]	Loss: -0.7262	Cost: 10.98s
Train Epoch: 440 [61440/90000 (68%)]	Loss: -0.9031	Cost: 5.83s
Train Epoch: 440 [81920/90000 (91%)]	Loss: -0.7818	Cost: 5.87s
Train Epoch: 440 	Average Loss: -0.3665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2094

Learning rate: 0.00019999044637506315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 1.9835	Cost: 22.32s
Train Epoch: 441 [20480/90000 (23%)]	Loss: -0.7157	Cost: 7.05s
Train Epoch: 441 [40960/90000 (45%)]	Loss: -0.8907	Cost: 10.32s
Train Epoch: 441 [61440/90000 (68%)]	Loss: -1.0046	Cost: 6.24s
Train Epoch: 441 [81920/90000 (91%)]	Loss: -1.0804	Cost: 11.19s
Train Epoch: 441 	Average Loss: -0.6340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0384

Saving model as e441_model.pt & e441_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999904029008434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 2.1651	Cost: 23.54s
Train Epoch: 442 [20480/90000 (23%)]	Loss: -0.8470	Cost: 6.17s
Train Epoch: 442 [40960/90000 (45%)]	Loss: -1.0294	Cost: 10.86s
Train Epoch: 442 [61440/90000 (68%)]	Loss: -1.0991	Cost: 6.17s
Train Epoch: 442 [81920/90000 (91%)]	Loss: -0.9536	Cost: 11.52s
Train Epoch: 442 	Average Loss: -0.6920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1689

Learning rate: 0.0001999903593279371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 1.8910	Cost: 26.74s
Train Epoch: 443 [20480/90000 (23%)]	Loss: -0.7110	Cost: 6.12s
Train Epoch: 443 [40960/90000 (45%)]	Loss: -1.0339	Cost: 10.10s
Train Epoch: 443 [61440/90000 (68%)]	Loss: -0.9857	Cost: 6.13s
Train Epoch: 443 [81920/90000 (91%)]	Loss: -1.3117	Cost: 6.11s
Train Epoch: 443 	Average Loss: -0.6613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9589

Saving model as e443_model.pt & e443_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999031565634426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 1.7718	Cost: 22.58s
Train Epoch: 444 [20480/90000 (23%)]	Loss: -1.1177	Cost: 6.17s
Train Epoch: 444 [40960/90000 (45%)]	Loss: -1.2023	Cost: 7.99s
Train Epoch: 444 [61440/90000 (68%)]	Loss: -1.3373	Cost: 6.20s
Train Epoch: 444 [81920/90000 (91%)]	Loss: -1.4949	Cost: 11.09s
Train Epoch: 444 	Average Loss: -0.8905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9926

Learning rate: 0.00019999027188606495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 1.5751	Cost: 42.08s
Train Epoch: 445 [20480/90000 (23%)]	Loss: -1.0582	Cost: 6.26s
Train Epoch: 445 [40960/90000 (45%)]	Loss: -1.1574	Cost: 9.00s
Train Epoch: 445 [61440/90000 (68%)]	Loss: -1.2498	Cost: 5.72s
Train Epoch: 445 [81920/90000 (91%)]	Loss: -1.3815	Cost: 5.89s
Train Epoch: 445 	Average Loss: -0.9531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8127

Saving model as e445_model.pt & e445_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999902280170992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 1.9285	Cost: 32.26s
Train Epoch: 446 [20480/90000 (23%)]	Loss: -0.8812	Cost: 6.26s
Train Epoch: 446 [40960/90000 (45%)]	Loss: -1.2622	Cost: 10.69s
Train Epoch: 446 [61440/90000 (68%)]	Loss: -1.2542	Cost: 11.62s
Train Epoch: 446 [81920/90000 (91%)]	Loss: -1.3221	Cost: 19.29s
Train Epoch: 446 	Average Loss: -0.8749
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9068

Learning rate: 0.00019999018404944703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 1.9512	Cost: 55.55s
Train Epoch: 447 [20480/90000 (23%)]	Loss: -0.9066	Cost: 7.48s
Train Epoch: 447 [40960/90000 (45%)]	Loss: -1.2783	Cost: 18.56s
Train Epoch: 447 [61440/90000 (68%)]	Loss: -1.2949	Cost: 9.09s
Train Epoch: 447 [81920/90000 (91%)]	Loss: -1.4738	Cost: 21.43s
Train Epoch: 447 	Average Loss: -0.9486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0123

Learning rate: 0.0001999901399831085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 1.6854	Cost: 25.88s
Train Epoch: 448 [20480/90000 (23%)]	Loss: -1.2496	Cost: 6.15s
Train Epoch: 448 [40960/90000 (45%)]	Loss: -1.2569	Cost: 8.34s
Train Epoch: 448 [61440/90000 (68%)]	Loss: -1.4526	Cost: 6.33s
Train Epoch: 448 [81920/90000 (91%)]	Loss: -1.4543	Cost: 10.60s
Train Epoch: 448 	Average Loss: -0.9857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8954

Learning rate: 0.00019999009581808368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 1.9566	Cost: 28.68s
Train Epoch: 449 [20480/90000 (23%)]	Loss: -1.1927	Cost: 6.78s
Train Epoch: 449 [40960/90000 (45%)]	Loss: -1.2469	Cost: 11.36s
Train Epoch: 449 [61440/90000 (68%)]	Loss: -1.3015	Cost: 5.93s
Train Epoch: 449 [81920/90000 (91%)]	Loss: -1.4289	Cost: 6.92s
Train Epoch: 449 	Average Loss: -0.9648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9006

Learning rate: 0.00019999005155437258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 1.8989	Cost: 25.85s
Train Epoch: 450 [20480/90000 (23%)]	Loss: -1.1307	Cost: 12.78s
Train Epoch: 450 [40960/90000 (45%)]	Loss: -1.3084	Cost: 15.98s
Train Epoch: 450 [61440/90000 (68%)]	Loss: -1.3767	Cost: 5.91s
Train Epoch: 450 [81920/90000 (91%)]	Loss: -1.4359	Cost: 16.69s
Train Epoch: 450 	Average Loss: -0.9888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7887

Saving model as e450_model.pt & e450_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999000719197527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 1.9939	Cost: 83.34s
Train Epoch: 451 [20480/90000 (23%)]	Loss: -1.2708	Cost: 10.51s
Train Epoch: 451 [40960/90000 (45%)]	Loss: -1.3958	Cost: 19.96s
Train Epoch: 451 [61440/90000 (68%)]	Loss: -1.4863	Cost: 11.44s
Train Epoch: 451 [81920/90000 (91%)]	Loss: -1.5259	Cost: 23.82s
Train Epoch: 451 	Average Loss: -1.0704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6825

Saving model as e451_model.pt & e451_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998996273089178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 1.0644	Cost: 30.97s
Train Epoch: 452 [20480/90000 (23%)]	Loss: -1.1836	Cost: 6.03s
Train Epoch: 452 [40960/90000 (45%)]	Loss: -1.3498	Cost: 8.28s
Train Epoch: 452 [61440/90000 (68%)]	Loss: -1.4266	Cost: 6.15s
Train Epoch: 452 [81920/90000 (91%)]	Loss: -1.4421	Cost: 8.59s
Train Epoch: 452 	Average Loss: -1.0906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8409

Learning rate: 0.00019998991817112214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 1.8742	Cost: 28.27s
Train Epoch: 453 [20480/90000 (23%)]	Loss: -1.1687	Cost: 7.51s
Train Epoch: 453 [40960/90000 (45%)]	Loss: -1.3613	Cost: 10.54s
Train Epoch: 453 [61440/90000 (68%)]	Loss: -1.4288	Cost: 7.46s
Train Epoch: 453 [81920/90000 (91%)]	Loss: -1.6128	Cost: 32.77s
Train Epoch: 453 	Average Loss: -1.0485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7455

Learning rate: 0.00019998987351266641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 1.6323	Cost: 112.34s
Train Epoch: 454 [20480/90000 (23%)]	Loss: -1.2895	Cost: 16.39s
Train Epoch: 454 [40960/90000 (45%)]	Loss: -1.4165	Cost: 30.99s
Train Epoch: 454 [61440/90000 (68%)]	Loss: -1.4606	Cost: 16.58s
Train Epoch: 454 [81920/90000 (91%)]	Loss: -1.5681	Cost: 32.82s
Train Epoch: 454 	Average Loss: -1.1224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6673

Saving model as e454_model.pt & e454_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998982875552463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 1.6120	Cost: 66.17s
Train Epoch: 455 [20480/90000 (23%)]	Loss: -1.3966	Cost: 20.67s
Train Epoch: 455 [40960/90000 (45%)]	Loss: -1.4444	Cost: 24.34s
Train Epoch: 455 [61440/90000 (68%)]	Loss: -1.4094	Cost: 22.36s
Train Epoch: 455 [81920/90000 (91%)]	Loss: -1.6384	Cost: 27.45s
Train Epoch: 455 	Average Loss: -1.1854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6730

Learning rate: 0.00019998978389969684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 1.6488	Cost: 119.35s
Train Epoch: 456 [20480/90000 (23%)]	Loss: -1.4805	Cost: 11.21s
Train Epoch: 456 [40960/90000 (45%)]	Loss: -1.5903	Cost: 24.54s
Train Epoch: 456 [61440/90000 (68%)]	Loss: -1.6391	Cost: 12.97s
Train Epoch: 456 [81920/90000 (91%)]	Loss: -1.7110	Cost: 21.20s
Train Epoch: 456 	Average Loss: -1.2413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5717

Saving model as e456_model.pt & e456_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999897389451831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 1.3098	Cost: 96.32s
Train Epoch: 457 [20480/90000 (23%)]	Loss: -1.3954	Cost: 12.78s
Train Epoch: 457 [40960/90000 (45%)]	Loss: -1.3043	Cost: 18.83s
Train Epoch: 457 [61440/90000 (68%)]	Loss: -0.7383	Cost: 9.06s
Train Epoch: 457 [81920/90000 (91%)]	Loss: -1.1976	Cost: 28.38s
Train Epoch: 457 	Average Loss: -0.8444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0223

Learning rate: 0.00019998969389198342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 1.7033	Cost: 96.41s
Train Epoch: 458 [20480/90000 (23%)]	Loss: -1.0764	Cost: 13.46s
Train Epoch: 458 [40960/90000 (45%)]	Loss: -1.4919	Cost: 29.95s
Train Epoch: 458 [61440/90000 (68%)]	Loss: -1.6650	Cost: 15.40s
Train Epoch: 458 [81920/90000 (91%)]	Loss: -1.8453	Cost: 28.68s
Train Epoch: 458 	Average Loss: -1.0923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6311

Learning rate: 0.00019998964874009788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 1.4097	Cost: 96.76s
Train Epoch: 459 [20480/90000 (23%)]	Loss: -1.3446	Cost: 11.74s
Train Epoch: 459 [40960/90000 (45%)]	Loss: -1.5401	Cost: 24.87s
Train Epoch: 459 [61440/90000 (68%)]	Loss: -1.7045	Cost: 12.54s
Train Epoch: 459 [81920/90000 (91%)]	Loss: -1.6568	Cost: 26.23s
Train Epoch: 459 	Average Loss: -1.2707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6428

Learning rate: 0.00019998960348952653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 1.4569	Cost: 84.31s
Train Epoch: 460 [20480/90000 (23%)]	Loss: -0.9582	Cost: 12.85s
Train Epoch: 460 [40960/90000 (45%)]	Loss: -1.3317	Cost: 31.76s
Train Epoch: 460 [61440/90000 (68%)]	Loss: -1.5272	Cost: 13.54s
Train Epoch: 460 [81920/90000 (91%)]	Loss: -1.6804	Cost: 24.94s
Train Epoch: 460 	Average Loss: -1.0498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6637

Learning rate: 0.00019998955814026938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 1.4386	Cost: 101.17s
Train Epoch: 461 [20480/90000 (23%)]	Loss: -1.3158	Cost: 14.50s
Train Epoch: 461 [40960/90000 (45%)]	Loss: -1.3261	Cost: 18.72s
Train Epoch: 461 [61440/90000 (68%)]	Loss: -1.4267	Cost: 10.67s
Train Epoch: 461 [81920/90000 (91%)]	Loss: -1.5880	Cost: 26.74s
Train Epoch: 461 	Average Loss: -1.1492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6351

Learning rate: 0.0001999895126923265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 1.4694	Cost: 91.01s
Train Epoch: 462 [20480/90000 (23%)]	Loss: -1.3140	Cost: 5.96s
Train Epoch: 462 [40960/90000 (45%)]	Loss: -1.3715	Cost: 8.48s
Train Epoch: 462 [61440/90000 (68%)]	Loss: -1.7160	Cost: 6.12s
Train Epoch: 462 [81920/90000 (91%)]	Loss: -1.8138	Cost: 6.91s
Train Epoch: 462 	Average Loss: -1.2233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5344

Saving model as e462_model.pt & e462_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998946714569794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 1.4025	Cost: 23.86s
Train Epoch: 463 [20480/90000 (23%)]	Loss: -1.4817	Cost: 6.67s
Train Epoch: 463 [40960/90000 (45%)]	Loss: -1.5063	Cost: 12.58s
Train Epoch: 463 [61440/90000 (68%)]	Loss: -1.6212	Cost: 7.29s
Train Epoch: 463 [81920/90000 (91%)]	Loss: -1.7290	Cost: 11.68s
Train Epoch: 463 	Average Loss: -1.2674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5685

Learning rate: 0.0001999894215003837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 1.3988	Cost: 23.42s
Train Epoch: 464 [20480/90000 (23%)]	Loss: -1.5004	Cost: 6.00s
Train Epoch: 464 [40960/90000 (45%)]	Loss: -1.5425	Cost: 8.29s
Train Epoch: 464 [61440/90000 (68%)]	Loss: -1.7293	Cost: 5.68s
Train Epoch: 464 [81920/90000 (91%)]	Loss: -1.8873	Cost: 5.85s
Train Epoch: 464 	Average Loss: -1.3282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5121

Saving model as e464_model.pt & e464_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998937575638385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 1.5374	Cost: 27.22s
Train Epoch: 465 [20480/90000 (23%)]	Loss: -1.3015	Cost: 6.13s
Train Epoch: 465 [40960/90000 (45%)]	Loss: -1.5697	Cost: 8.67s
Train Epoch: 465 [61440/90000 (68%)]	Loss: -1.8261	Cost: 5.81s
Train Epoch: 465 [81920/90000 (91%)]	Loss: -1.9300	Cost: 7.99s
Train Epoch: 465 	Average Loss: -1.3676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4097

Saving model as e465_model.pt & e465_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999893299136985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 1.4137	Cost: 27.93s
Train Epoch: 466 [20480/90000 (23%)]	Loss: -1.5427	Cost: 9.86s
Train Epoch: 466 [40960/90000 (45%)]	Loss: -1.8194	Cost: 10.13s
Train Epoch: 466 [61440/90000 (68%)]	Loss: -2.0030	Cost: 6.85s
Train Epoch: 466 [81920/90000 (91%)]	Loss: -1.9656	Cost: 12.97s
Train Epoch: 466 	Average Loss: -1.4779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4812

Learning rate: 0.00019998928397232759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 1.6164	Cost: 27.87s
Train Epoch: 467 [20480/90000 (23%)]	Loss: -1.4961	Cost: 6.02s
Train Epoch: 467 [40960/90000 (45%)]	Loss: -1.7175	Cost: 7.73s
Train Epoch: 467 [61440/90000 (68%)]	Loss: -1.7544	Cost: 6.11s
Train Epoch: 467 [81920/90000 (91%)]	Loss: -1.8369	Cost: 6.75s
Train Epoch: 467 	Average Loss: -1.3995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5315

Learning rate: 0.00019998923793227122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 1.6256	Cost: 22.94s
Train Epoch: 468 [20480/90000 (23%)]	Loss: -1.6214	Cost: 6.01s
Train Epoch: 468 [40960/90000 (45%)]	Loss: -1.7907	Cost: 7.70s
Train Epoch: 468 [61440/90000 (68%)]	Loss: -1.9513	Cost: 6.07s
Train Epoch: 468 [81920/90000 (91%)]	Loss: -1.8643	Cost: 9.36s
Train Epoch: 468 	Average Loss: -1.4692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6178

Learning rate: 0.0001999891917935294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 1.5973	Cost: 26.19s
Train Epoch: 469 [20480/90000 (23%)]	Loss: -1.6339	Cost: 6.09s
Train Epoch: 469 [40960/90000 (45%)]	Loss: -1.8329	Cost: 8.81s
Train Epoch: 469 [61440/90000 (68%)]	Loss: -1.7353	Cost: 6.08s
Train Epoch: 469 [81920/90000 (91%)]	Loss: -1.9153	Cost: 6.45s
Train Epoch: 469 	Average Loss: -1.4690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5959

Learning rate: 0.00019998914555610225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 1.5416	Cost: 25.20s
Train Epoch: 470 [20480/90000 (23%)]	Loss: -1.5280	Cost: 6.32s
Train Epoch: 470 [40960/90000 (45%)]	Loss: -1.7691	Cost: 10.35s
Train Epoch: 470 [61440/90000 (68%)]	Loss: -1.7572	Cost: 6.48s
Train Epoch: 470 [81920/90000 (91%)]	Loss: -2.0494	Cost: 12.58s
Train Epoch: 470 	Average Loss: -1.4464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4545

Learning rate: 0.00019998909921998975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 1.0467	Cost: 22.98s
Train Epoch: 471 [20480/90000 (23%)]	Loss: -1.7967	Cost: 6.41s
Train Epoch: 471 [40960/90000 (45%)]	Loss: -2.0016	Cost: 8.07s
Train Epoch: 471 [61440/90000 (68%)]	Loss: -1.8987	Cost: 6.17s
Train Epoch: 471 [81920/90000 (91%)]	Loss: -2.0896	Cost: 9.06s
Train Epoch: 471 	Average Loss: -1.6084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3434

Saving model as e471_model.pt & e471_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998905278519196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 1.3574	Cost: 29.61s
Train Epoch: 472 [20480/90000 (23%)]	Loss: -1.7260	Cost: 9.92s
Train Epoch: 472 [40960/90000 (45%)]	Loss: -1.7084	Cost: 9.06s
Train Epoch: 472 [61440/90000 (68%)]	Loss: -1.8413	Cost: 6.46s
Train Epoch: 472 [81920/90000 (91%)]	Loss: -1.8142	Cost: 12.05s
Train Epoch: 472 	Average Loss: -1.4824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5949

Learning rate: 0.00019998900625170892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 1.5377	Cost: 24.34s
Train Epoch: 473 [20480/90000 (23%)]	Loss: -1.6412	Cost: 6.28s
Train Epoch: 473 [40960/90000 (45%)]	Loss: -1.8193	Cost: 8.19s
Train Epoch: 473 [61440/90000 (68%)]	Loss: -1.9241	Cost: 5.96s
Train Epoch: 473 [81920/90000 (91%)]	Loss: -2.0975	Cost: 6.61s
Train Epoch: 473 	Average Loss: -1.5199
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3447

Learning rate: 0.0001999889596195407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 1.0502	Cost: 25.94s
Train Epoch: 474 [20480/90000 (23%)]	Loss: -1.9065	Cost: 8.72s
Train Epoch: 474 [40960/90000 (45%)]	Loss: -1.9618	Cost: 12.81s
Train Epoch: 474 [61440/90000 (68%)]	Loss: -2.0098	Cost: 6.78s
Train Epoch: 474 [81920/90000 (91%)]	Loss: -2.0165	Cost: 14.17s
Train Epoch: 474 	Average Loss: -1.6254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3622

Learning rate: 0.00019998891288868732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 1.7627	Cost: 25.51s
Train Epoch: 475 [20480/90000 (23%)]	Loss: -1.6296	Cost: 6.14s
Train Epoch: 475 [40960/90000 (45%)]	Loss: -1.7560	Cost: 6.89s
Train Epoch: 475 [61440/90000 (68%)]	Loss: -1.8531	Cost: 6.05s
Train Epoch: 475 [81920/90000 (91%)]	Loss: -2.0956	Cost: 7.64s
Train Epoch: 475 	Average Loss: -1.4920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3149

Saving model as e475_model.pt & e475_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998886605914883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 1.3896	Cost: 22.90s
Train Epoch: 476 [20480/90000 (23%)]	Loss: -1.8934	Cost: 6.40s
Train Epoch: 476 [40960/90000 (45%)]	Loss: -2.1004	Cost: 9.43s
Train Epoch: 476 [61440/90000 (68%)]	Loss: -2.0700	Cost: 6.73s
Train Epoch: 476 [81920/90000 (91%)]	Loss: -2.3237	Cost: 13.36s
Train Epoch: 476 	Average Loss: -1.7232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2854

Saving model as e476_model.pt & e476_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998881913092532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 1.0999	Cost: 27.94s
Train Epoch: 477 [20480/90000 (23%)]	Loss: -1.9433	Cost: 6.34s
Train Epoch: 477 [40960/90000 (45%)]	Loss: -2.0532	Cost: 10.02s
Train Epoch: 477 [61440/90000 (68%)]	Loss: -2.1212	Cost: 5.87s
Train Epoch: 477 [81920/90000 (91%)]	Loss: -2.0135	Cost: 6.27s
Train Epoch: 477 	Average Loss: -1.7335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4458

Learning rate: 0.00019998877210401677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 1.0616	Cost: 27.44s
Train Epoch: 478 [20480/90000 (23%)]	Loss: -1.5875	Cost: 6.12s
Train Epoch: 478 [40960/90000 (45%)]	Loss: -1.8983	Cost: 10.31s
Train Epoch: 478 [61440/90000 (68%)]	Loss: -2.2081	Cost: 5.69s
Train Epoch: 478 [81920/90000 (91%)]	Loss: -2.3642	Cost: 5.87s
Train Epoch: 478 	Average Loss: -1.6752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3039

Learning rate: 0.00019998872497842328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 1.3224	Cost: 22.74s
Train Epoch: 479 [20480/90000 (23%)]	Loss: -2.0845	Cost: 6.07s
Train Epoch: 479 [40960/90000 (45%)]	Loss: -1.9600	Cost: 7.32s
Train Epoch: 479 [61440/90000 (68%)]	Loss: -1.9759	Cost: 5.82s
Train Epoch: 479 [81920/90000 (91%)]	Loss: -2.3402	Cost: 8.65s
Train Epoch: 479 	Average Loss: -1.7670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2247

Saving model as e479_model.pt & e479_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998867775414486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 1.3431	Cost: 26.48s
Train Epoch: 480 [20480/90000 (23%)]	Loss: -1.6562	Cost: 6.08s
Train Epoch: 480 [40960/90000 (45%)]	Loss: -1.8696	Cost: 7.93s
Train Epoch: 480 [61440/90000 (68%)]	Loss: -1.9188	Cost: 5.85s
Train Epoch: 480 [81920/90000 (91%)]	Loss: -2.0802	Cost: 6.10s
Train Epoch: 480 	Average Loss: -1.5076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3009

Learning rate: 0.00019998863043118158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 1.1109	Cost: 23.12s
Train Epoch: 481 [20480/90000 (23%)]	Loss: -1.7937	Cost: 6.06s
Train Epoch: 481 [40960/90000 (45%)]	Loss: -2.0616	Cost: 7.86s
Train Epoch: 481 [61440/90000 (68%)]	Loss: -2.3087	Cost: 5.87s
Train Epoch: 481 [81920/90000 (91%)]	Loss: -2.2498	Cost: 5.63s
Train Epoch: 481 	Average Loss: -1.7893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1638

Saving model as e481_model.pt & e481_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998858300953348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 1.1986	Cost: 27.04s
Train Epoch: 482 [20480/90000 (23%)]	Loss: -2.0876	Cost: 6.20s
Train Epoch: 482 [40960/90000 (45%)]	Loss: -2.3085	Cost: 10.92s
Train Epoch: 482 [61440/90000 (68%)]	Loss: -2.3460	Cost: 5.87s
Train Epoch: 482 [81920/90000 (91%)]	Loss: -2.3918	Cost: 5.97s
Train Epoch: 482 	Average Loss: -1.8824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0699

Saving model as e482_model.pt & e482_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999885354892006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 1.0815	Cost: 22.34s
Train Epoch: 483 [20480/90000 (23%)]	Loss: -2.2205	Cost: 6.06s
Train Epoch: 483 [40960/90000 (45%)]	Loss: -2.3828	Cost: 8.15s
Train Epoch: 483 [61440/90000 (68%)]	Loss: -2.4330	Cost: 6.43s
Train Epoch: 483 [81920/90000 (91%)]	Loss: -2.3980	Cost: 11.16s
Train Epoch: 483 	Average Loss: -2.0285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0276

Saving model as e483_model.pt & e483_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199988487870183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 0.9447	Cost: 23.03s
Train Epoch: 484 [20480/90000 (23%)]	Loss: -2.1418	Cost: 6.11s
Train Epoch: 484 [40960/90000 (45%)]	Loss: -2.2385	Cost: 8.69s
Train Epoch: 484 [61440/90000 (68%)]	Loss: -2.1898	Cost: 6.30s
Train Epoch: 484 [81920/90000 (91%)]	Loss: -2.3194	Cost: 10.12s
Train Epoch: 484 	Average Loss: -1.9478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0927

Learning rate: 0.00019998844015248072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 1.3265	Cost: 23.15s
Train Epoch: 485 [20480/90000 (23%)]	Loss: -2.0198	Cost: 6.17s
Train Epoch: 485 [40960/90000 (45%)]	Loss: -2.0413	Cost: 11.59s
Train Epoch: 485 [61440/90000 (68%)]	Loss: -2.4219	Cost: 6.10s
Train Epoch: 485 [81920/90000 (91%)]	Loss: -2.5992	Cost: 10.69s
Train Epoch: 485 	Average Loss: -1.9382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0355

Learning rate: 0.0001999883923360938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 1.5224	Cost: 24.51s
Train Epoch: 486 [20480/90000 (23%)]	Loss: -2.2364	Cost: 6.00s
Train Epoch: 486 [40960/90000 (45%)]	Loss: -2.3900	Cost: 7.86s
Train Epoch: 486 [61440/90000 (68%)]	Loss: -2.4261	Cost: 5.91s
Train Epoch: 486 [81920/90000 (91%)]	Loss: -2.5063	Cost: 7.30s
Train Epoch: 486 	Average Loss: -2.0275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9090

Saving model as e486_model.pt & e486_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998834442102228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 0.9420	Cost: 22.67s
Train Epoch: 487 [20480/90000 (23%)]	Loss: -2.2344	Cost: 6.45s
Train Epoch: 487 [40960/90000 (45%)]	Loss: -2.4698	Cost: 11.18s
Train Epoch: 487 [61440/90000 (68%)]	Loss: -2.3890	Cost: 6.23s
Train Epoch: 487 [81920/90000 (91%)]	Loss: -2.3575	Cost: 11.80s
Train Epoch: 487 	Average Loss: -1.9735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0585

Learning rate: 0.00019998829640726623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 0.9159	Cost: 25.40s
Train Epoch: 488 [20480/90000 (23%)]	Loss: -2.1784	Cost: 6.16s
Train Epoch: 488 [40960/90000 (45%)]	Loss: -2.3114	Cost: 8.99s
Train Epoch: 488 [61440/90000 (68%)]	Loss: -2.3406	Cost: 5.80s
Train Epoch: 488 [81920/90000 (91%)]	Loss: -2.5897	Cost: 6.59s
Train Epoch: 488 	Average Loss: -2.0094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1255

Learning rate: 0.00019998824829482568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 1.2359	Cost: 24.67s
Train Epoch: 489 [20480/90000 (23%)]	Loss: -2.1657	Cost: 6.40s
Train Epoch: 489 [40960/90000 (45%)]	Loss: -2.2922	Cost: 11.53s
Train Epoch: 489 [61440/90000 (68%)]	Loss: -2.2689	Cost: 6.14s
Train Epoch: 489 [81920/90000 (91%)]	Loss: -2.6223	Cost: 11.20s
Train Epoch: 489 	Average Loss: -1.9450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9920

Learning rate: 0.0001999882000837007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 1.2304	Cost: 23.52s
Train Epoch: 490 [20480/90000 (23%)]	Loss: -2.2642	Cost: 6.09s
Train Epoch: 490 [40960/90000 (45%)]	Loss: -2.3676	Cost: 8.29s
Train Epoch: 490 [61440/90000 (68%)]	Loss: -2.6180	Cost: 6.18s
Train Epoch: 490 [81920/90000 (91%)]	Loss: -2.6231	Cost: 11.27s
Train Epoch: 490 	Average Loss: -2.1098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9728

Learning rate: 0.0001999881517738913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 0.8066	Cost: 26.93s
Train Epoch: 491 [20480/90000 (23%)]	Loss: -2.2418	Cost: 6.77s
Train Epoch: 491 [40960/90000 (45%)]	Loss: -2.5586	Cost: 10.26s
Train Epoch: 491 [61440/90000 (68%)]	Loss: -2.5851	Cost: 6.01s
Train Epoch: 491 [81920/90000 (91%)]	Loss: -2.5476	Cost: 6.30s
Train Epoch: 491 	Average Loss: -2.1309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9440

Learning rate: 0.00019998810336539752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 0.9105	Cost: 22.61s
Train Epoch: 492 [20480/90000 (23%)]	Loss: -2.3458	Cost: 6.05s
Train Epoch: 492 [40960/90000 (45%)]	Loss: -2.3772	Cost: 8.42s
Train Epoch: 492 [61440/90000 (68%)]	Loss: -2.5420	Cost: 5.76s
Train Epoch: 492 [81920/90000 (91%)]	Loss: -2.6775	Cost: 5.62s
Train Epoch: 492 	Average Loss: -2.1684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0880

Learning rate: 0.00019998805485821946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 1.3011	Cost: 23.20s
Train Epoch: 493 [20480/90000 (23%)]	Loss: -2.2588	Cost: 6.07s
Train Epoch: 493 [40960/90000 (45%)]	Loss: -2.4308	Cost: 7.72s
Train Epoch: 493 [61440/90000 (68%)]	Loss: -2.6787	Cost: 6.32s
Train Epoch: 493 [81920/90000 (91%)]	Loss: -2.7883	Cost: 10.51s
Train Epoch: 493 	Average Loss: -2.1615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8662

Saving model as e493_model.pt & e493_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998800625235718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 0.6924	Cost: 23.21s
Train Epoch: 494 [20480/90000 (23%)]	Loss: -2.5465	Cost: 6.12s
Train Epoch: 494 [40960/90000 (45%)]	Loss: -2.6097	Cost: 8.24s
Train Epoch: 494 [61440/90000 (68%)]	Loss: -2.8233	Cost: 6.07s
Train Epoch: 494 [81920/90000 (91%)]	Loss: -2.6561	Cost: 6.08s
Train Epoch: 494 	Average Loss: -2.2975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9451

Learning rate: 0.00019998795754781068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 1.0716	Cost: 28.37s
Train Epoch: 495 [20480/90000 (23%)]	Loss: -2.3668	Cost: 6.48s
Train Epoch: 495 [40960/90000 (45%)]	Loss: -2.7637	Cost: 11.00s
Train Epoch: 495 [61440/90000 (68%)]	Loss: -2.6881	Cost: 5.90s
Train Epoch: 495 [81920/90000 (91%)]	Loss: -2.7101	Cost: 6.92s
Train Epoch: 495 	Average Loss: -2.2477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9033

Learning rate: 0.00019998790874458001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 0.8155	Cost: 23.43s
Train Epoch: 496 [20480/90000 (23%)]	Loss: -2.3082	Cost: 6.05s
Train Epoch: 496 [40960/90000 (45%)]	Loss: -2.6560	Cost: 7.10s
Train Epoch: 496 [61440/90000 (68%)]	Loss: -2.6283	Cost: 6.00s
Train Epoch: 496 [81920/90000 (91%)]	Loss: -2.8290	Cost: 6.13s
Train Epoch: 496 	Average Loss: -2.2138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8756

Learning rate: 0.00019998785984266522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 0.5216	Cost: 28.13s
Train Epoch: 497 [20480/90000 (23%)]	Loss: -2.5121	Cost: 6.29s
Train Epoch: 497 [40960/90000 (45%)]	Loss: -2.5501	Cost: 10.25s
Train Epoch: 497 [61440/90000 (68%)]	Loss: -2.5053	Cost: 5.70s
Train Epoch: 497 [81920/90000 (91%)]	Loss: -2.7752	Cost: 6.23s
Train Epoch: 497 	Average Loss: -2.2180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8899

Learning rate: 0.0001999878108420664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 0.6195	Cost: 24.90s
Train Epoch: 498 [20480/90000 (23%)]	Loss: -2.4591	Cost: 6.06s
Train Epoch: 498 [40960/90000 (45%)]	Loss: -2.4640	Cost: 9.24s
Train Epoch: 498 [61440/90000 (68%)]	Loss: -2.6271	Cost: 5.77s
Train Epoch: 498 [81920/90000 (91%)]	Loss: -2.6325	Cost: 8.25s
Train Epoch: 498 	Average Loss: -2.2485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9277

Learning rate: 0.0001999877617427835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 0.4848	Cost: 25.64s
Train Epoch: 499 [20480/90000 (23%)]	Loss: -2.4387	Cost: 6.17s
Train Epoch: 499 [40960/90000 (45%)]	Loss: -2.5472	Cost: 8.81s
Train Epoch: 499 [61440/90000 (68%)]	Loss: -2.7507	Cost: 5.91s
Train Epoch: 499 [81920/90000 (91%)]	Loss: -2.7481	Cost: 7.73s
Train Epoch: 499 	Average Loss: -2.3143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7055

Saving model as e499_model.pt & e499_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998771254481668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 0.5462	Cost: 23.10s
Train Epoch: 500 [20480/90000 (23%)]	Loss: -2.5368	Cost: 6.06s
Train Epoch: 500 [40960/90000 (45%)]	Loss: -2.9393	Cost: 6.82s
Train Epoch: 500 [61440/90000 (68%)]	Loss: -2.8623	Cost: 6.67s
Train Epoch: 500 [81920/90000 (91%)]	Loss: -2.9736	Cost: 9.93s
Train Epoch: 500 	Average Loss: -2.5469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6035

Saving model as e500_model.pt & e500_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998766324816594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: 0.9712	Cost: 24.33s
Train Epoch: 501 [20480/90000 (23%)]	Loss: -2.6446	Cost: 6.06s
Train Epoch: 501 [40960/90000 (45%)]	Loss: -2.7439	Cost: 9.33s
Train Epoch: 501 [61440/90000 (68%)]	Loss: -2.8397	Cost: 6.21s
Train Epoch: 501 [81920/90000 (91%)]	Loss: -2.8100	Cost: 6.72s
Train Epoch: 501 	Average Loss: -2.3826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6670

Learning rate: 0.00019998761385283135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: 0.3746	Cost: 22.63s
Train Epoch: 502 [20480/90000 (23%)]	Loss: -2.5932	Cost: 6.98s
Train Epoch: 502 [40960/90000 (45%)]	Loss: -2.7784	Cost: 11.03s
Train Epoch: 502 [61440/90000 (68%)]	Loss: -2.7014	Cost: 6.31s
Train Epoch: 502 [81920/90000 (91%)]	Loss: -2.6292	Cost: 11.79s
Train Epoch: 502 	Average Loss: -2.3271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0063

Learning rate: 0.00019998756435881293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: 0.7853	Cost: 23.25s
Train Epoch: 503 [20480/90000 (23%)]	Loss: -2.4531	Cost: 6.12s
Train Epoch: 503 [40960/90000 (45%)]	Loss: -2.4299	Cost: 8.76s
Train Epoch: 503 [61440/90000 (68%)]	Loss: -2.7035	Cost: 6.01s
Train Epoch: 503 [81920/90000 (91%)]	Loss: -2.7456	Cost: 6.22s
Train Epoch: 503 	Average Loss: -2.2326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7558

Learning rate: 0.00019998751476611075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: 1.0965	Cost: 25.84s
Train Epoch: 504 [20480/90000 (23%)]	Loss: -2.6142	Cost: 6.45s
Train Epoch: 504 [40960/90000 (45%)]	Loss: -2.8765	Cost: 10.89s
Train Epoch: 504 [61440/90000 (68%)]	Loss: -2.8762	Cost: 6.41s
Train Epoch: 504 [81920/90000 (91%)]	Loss: -3.0233	Cost: 9.17s
Train Epoch: 504 	Average Loss: -2.4763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6264

Learning rate: 0.00019998746507472485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: 0.4837	Cost: 30.19s
Train Epoch: 505 [20480/90000 (23%)]	Loss: -2.6930	Cost: 6.32s
Train Epoch: 505 [40960/90000 (45%)]	Loss: -2.8020	Cost: 9.85s
Train Epoch: 505 [61440/90000 (68%)]	Loss: -2.9338	Cost: 6.06s
Train Epoch: 505 [81920/90000 (91%)]	Loss: -3.1764	Cost: 8.56s
Train Epoch: 505 	Average Loss: -2.4938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6270

Learning rate: 0.00019998741528465526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: 1.3009	Cost: 29.07s
Train Epoch: 506 [20480/90000 (23%)]	Loss: -2.6731	Cost: 6.67s
Train Epoch: 506 [40960/90000 (45%)]	Loss: -2.9043	Cost: 11.06s
Train Epoch: 506 [61440/90000 (68%)]	Loss: -2.8531	Cost: 5.93s
Train Epoch: 506 [81920/90000 (91%)]	Loss: -3.0936	Cost: 6.82s
Train Epoch: 506 	Average Loss: -2.5009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6339

Learning rate: 0.00019998736539590206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: 0.4546	Cost: 26.10s
Train Epoch: 507 [20480/90000 (23%)]	Loss: -2.6863	Cost: 6.18s
Train Epoch: 507 [40960/90000 (45%)]	Loss: -3.0115	Cost: 9.67s
Train Epoch: 507 [61440/90000 (68%)]	Loss: -2.9861	Cost: 5.95s
Train Epoch: 507 [81920/90000 (91%)]	Loss: -3.3298	Cost: 8.56s
Train Epoch: 507 	Average Loss: -2.5913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5454

Saving model as e507_model.pt & e507_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998731540846526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: 0.7761	Cost: 24.14s
Train Epoch: 508 [20480/90000 (23%)]	Loss: -2.8653	Cost: 6.05s
Train Epoch: 508 [40960/90000 (45%)]	Loss: -3.1889	Cost: 8.83s
Train Epoch: 508 [61440/90000 (68%)]	Loss: -3.0638	Cost: 5.96s
Train Epoch: 508 [81920/90000 (91%)]	Loss: -2.7875	Cost: 6.60s
Train Epoch: 508 	Average Loss: -2.5894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7905

Learning rate: 0.00019998726532234495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: 0.9794	Cost: 24.93s
Train Epoch: 509 [20480/90000 (23%)]	Loss: -2.5345	Cost: 6.73s
Train Epoch: 509 [40960/90000 (45%)]	Loss: -2.9978	Cost: 10.90s
Train Epoch: 509 [61440/90000 (68%)]	Loss: -2.9387	Cost: 6.18s
Train Epoch: 509 [81920/90000 (91%)]	Loss: -3.1609	Cost: 11.12s
Train Epoch: 509 	Average Loss: -2.5370
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6408

Learning rate: 0.00019998721513754116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: 0.9352	Cost: 24.14s
Train Epoch: 510 [20480/90000 (23%)]	Loss: -2.6890	Cost: 7.40s
Train Epoch: 510 [40960/90000 (45%)]	Loss: -2.6429	Cost: 12.14s
Train Epoch: 510 [61440/90000 (68%)]	Loss: -2.8262	Cost: 6.07s
Train Epoch: 510 [81920/90000 (91%)]	Loss: -3.0404	Cost: 10.72s
Train Epoch: 510 	Average Loss: -2.4337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5811

Learning rate: 0.00019998716485405393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: 1.0612	Cost: 26.20s
Train Epoch: 511 [20480/90000 (23%)]	Loss: -2.7801	Cost: 6.33s
Train Epoch: 511 [40960/90000 (45%)]	Loss: -3.0183	Cost: 12.64s
Train Epoch: 511 [61440/90000 (68%)]	Loss: -3.1421	Cost: 5.89s
Train Epoch: 511 [81920/90000 (91%)]	Loss: -3.1718	Cost: 7.79s
Train Epoch: 511 	Average Loss: -2.6137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4968

Saving model as e511_model.pt & e511_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998711447188336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: 0.3840	Cost: 32.82s
Train Epoch: 512 [20480/90000 (23%)]	Loss: -2.9279	Cost: 6.20s
Train Epoch: 512 [40960/90000 (45%)]	Loss: -3.0570	Cost: 9.65s
Train Epoch: 512 [61440/90000 (68%)]	Loss: -3.1048	Cost: 8.29s
Train Epoch: 512 [81920/90000 (91%)]	Loss: -3.2917	Cost: 27.70s
Train Epoch: 512 	Average Loss: -2.7562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3862

Saving model as e512_model.pt & e512_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998706399102943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: 0.0603	Cost: 25.29s
Train Epoch: 513 [20480/90000 (23%)]	Loss: -2.9113	Cost: 6.52s
Train Epoch: 513 [40960/90000 (45%)]	Loss: -3.1218	Cost: 11.59s
Train Epoch: 513 [61440/90000 (68%)]	Loss: -3.2654	Cost: 6.01s
Train Epoch: 513 [81920/90000 (91%)]	Loss: -3.0739	Cost: 8.83s
Train Epoch: 513 	Average Loss: -2.7148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5377

Learning rate: 0.00019998701341149226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: 0.2413	Cost: 26.73s
Train Epoch: 514 [20480/90000 (23%)]	Loss: -2.8299	Cost: 6.09s
Train Epoch: 514 [40960/90000 (45%)]	Loss: -3.0699	Cost: 9.74s
Train Epoch: 514 [61440/90000 (68%)]	Loss: -3.2485	Cost: 6.28s
Train Epoch: 514 [81920/90000 (91%)]	Loss: -3.1320	Cost: 12.78s
Train Epoch: 514 	Average Loss: -2.7209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7074

Learning rate: 0.00019998696273327185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: 0.8672	Cost: 24.20s
Train Epoch: 515 [20480/90000 (23%)]	Loss: -2.7512	Cost: 6.04s
Train Epoch: 515 [40960/90000 (45%)]	Loss: -3.0355	Cost: 11.21s
Train Epoch: 515 [61440/90000 (68%)]	Loss: -3.2821	Cost: 6.27s
Train Epoch: 515 [81920/90000 (91%)]	Loss: -3.1256	Cost: 16.97s
Train Epoch: 515 	Average Loss: -2.6299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4858

Learning rate: 0.00019998691195636826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: 0.6838	Cost: 28.31s
Train Epoch: 516 [20480/90000 (23%)]	Loss: -3.0420	Cost: 6.20s
Train Epoch: 516 [40960/90000 (45%)]	Loss: -2.7368	Cost: 10.43s
Train Epoch: 516 [61440/90000 (68%)]	Loss: -2.8632	Cost: 5.86s
Train Epoch: 516 [81920/90000 (91%)]	Loss: -3.2154	Cost: 6.78s
Train Epoch: 516 	Average Loss: -2.6419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5362

Learning rate: 0.00019998686108078153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: 0.3912	Cost: 49.23s
Train Epoch: 517 [20480/90000 (23%)]	Loss: -2.9531	Cost: 17.95s
Train Epoch: 517 [40960/90000 (45%)]	Loss: -3.1468	Cost: 34.28s
Train Epoch: 517 [61440/90000 (68%)]	Loss: -3.2582	Cost: 14.63s
Train Epoch: 517 [81920/90000 (91%)]	Loss: -3.3805	Cost: 30.91s
Train Epoch: 517 	Average Loss: -2.7862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5116

Learning rate: 0.00019998681010651175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: 0.1882	Cost: 44.27s
Train Epoch: 518 [20480/90000 (23%)]	Loss: -3.0273	Cost: 8.57s
Train Epoch: 518 [40960/90000 (45%)]	Loss: -3.2355	Cost: 11.73s
Train Epoch: 518 [61440/90000 (68%)]	Loss: -3.3730	Cost: 6.47s
Train Epoch: 518 [81920/90000 (91%)]	Loss: -3.4060	Cost: 11.96s
Train Epoch: 518 	Average Loss: -2.8892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2739

Saving model as e518_model.pt & e518_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999867590335589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: 0.6722	Cost: 24.15s
Train Epoch: 519 [20480/90000 (23%)]	Loss: -3.2190	Cost: 6.23s
Train Epoch: 519 [40960/90000 (45%)]	Loss: -3.4196	Cost: 8.15s
Train Epoch: 519 [61440/90000 (68%)]	Loss: -3.2429	Cost: 5.89s
Train Epoch: 519 [81920/90000 (91%)]	Loss: -3.4640	Cost: 7.33s
Train Epoch: 519 	Average Loss: -2.9178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3196

Learning rate: 0.00019998670786192314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: 0.5165	Cost: 89.67s
Train Epoch: 520 [20480/90000 (23%)]	Loss: -3.0863	Cost: 10.90s
Train Epoch: 520 [40960/90000 (45%)]	Loss: -3.2100	Cost: 28.60s
Train Epoch: 520 [61440/90000 (68%)]	Loss: -3.3606	Cost: 19.28s
Train Epoch: 520 [81920/90000 (91%)]	Loss: -3.4788	Cost: 21.33s
Train Epoch: 520 	Average Loss: -2.9123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4532

Learning rate: 0.00019998665659160442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: 0.4193	Cost: 24.69s
Train Epoch: 521 [20480/90000 (23%)]	Loss: -3.0080	Cost: 6.23s
Train Epoch: 521 [40960/90000 (45%)]	Loss: -3.2505	Cost: 8.17s
Train Epoch: 521 [61440/90000 (68%)]	Loss: -3.4608	Cost: 6.30s
Train Epoch: 521 [81920/90000 (91%)]	Loss: -3.6634	Cost: 10.98s
Train Epoch: 521 	Average Loss: -2.9539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2493

Saving model as e521_model.pt & e521_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998660522260283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 0.4127	Cost: 31.56s
Train Epoch: 522 [20480/90000 (23%)]	Loss: -3.1102	Cost: 6.71s
Train Epoch: 522 [40960/90000 (45%)]	Loss: -3.1840	Cost: 10.87s
Train Epoch: 522 [61440/90000 (68%)]	Loss: -3.3300	Cost: 5.91s
Train Epoch: 522 [81920/90000 (91%)]	Loss: -3.6176	Cost: 6.78s
Train Epoch: 522 	Average Loss: -2.9549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2237

Saving model as e522_model.pt & e522_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998655375491842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: 0.1111	Cost: 30.35s
Train Epoch: 523 [20480/90000 (23%)]	Loss: -3.2623	Cost: 6.55s
Train Epoch: 523 [40960/90000 (45%)]	Loss: -3.5733	Cost: 9.80s
Train Epoch: 523 [61440/90000 (68%)]	Loss: -3.5577	Cost: 6.22s
Train Epoch: 523 [81920/90000 (91%)]	Loss: -3.6018	Cost: 9.42s
Train Epoch: 523 	Average Loss: -3.1347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2535

Learning rate: 0.00019998650218855122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: 0.5956	Cost: 25.43s
Train Epoch: 524 [20480/90000 (23%)]	Loss: -3.1232	Cost: 9.59s
Train Epoch: 524 [40960/90000 (45%)]	Loss: -3.2821	Cost: 12.57s
Train Epoch: 524 [61440/90000 (68%)]	Loss: -3.3217	Cost: 8.05s
Train Epoch: 524 [81920/90000 (91%)]	Loss: -3.5144	Cost: 9.50s
Train Epoch: 524 	Average Loss: -2.9601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3474

Learning rate: 0.00019998645052350132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: 0.6259	Cost: 47.42s
Train Epoch: 525 [20480/90000 (23%)]	Loss: -2.9666	Cost: 10.00s
Train Epoch: 525 [40960/90000 (45%)]	Loss: -3.3040	Cost: 18.48s
Train Epoch: 525 [61440/90000 (68%)]	Loss: -3.4532	Cost: 9.08s
Train Epoch: 525 [81920/90000 (91%)]	Loss: -3.5963	Cost: 16.19s
Train Epoch: 525 	Average Loss: -2.9450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1345

Saving model as e525_model.pt & e525_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998639875976873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: 0.4165	Cost: 90.56s
Train Epoch: 526 [20480/90000 (23%)]	Loss: -3.2885	Cost: 13.27s
Train Epoch: 526 [40960/90000 (45%)]	Loss: -3.4745	Cost: 37.33s
Train Epoch: 526 [61440/90000 (68%)]	Loss: -3.2592	Cost: 11.82s
Train Epoch: 526 [81920/90000 (91%)]	Loss: -3.4396	Cost: 37.30s
Train Epoch: 526 	Average Loss: -2.9675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3192

Learning rate: 0.0001999863468973535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: 0.7684	Cost: 71.55s
Train Epoch: 527 [20480/90000 (23%)]	Loss: -3.0374	Cost: 11.22s
Train Epoch: 527 [40960/90000 (45%)]	Loss: -3.4593	Cost: 22.66s
Train Epoch: 527 [61440/90000 (68%)]	Loss: -3.3864	Cost: 10.73s
Train Epoch: 527 [81920/90000 (91%)]	Loss: -3.5882	Cost: 25.16s
Train Epoch: 527 	Average Loss: -3.0040
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2790

Learning rate: 0.00019998629493625576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: -0.3047	Cost: 71.99s
Train Epoch: 528 [20480/90000 (23%)]	Loss: -3.1596	Cost: 11.51s
Train Epoch: 528 [40960/90000 (45%)]	Loss: -3.3475	Cost: 26.26s
Train Epoch: 528 [61440/90000 (68%)]	Loss: -3.5898	Cost: 12.04s
Train Epoch: 528 [81920/90000 (91%)]	Loss: -3.5245	Cost: 22.59s
Train Epoch: 528 	Average Loss: -3.0296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3135

Learning rate: 0.00019998624287647545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: 0.3157	Cost: 84.55s
Train Epoch: 529 [20480/90000 (23%)]	Loss: -3.3083	Cost: 11.25s
Train Epoch: 529 [40960/90000 (45%)]	Loss: -3.3764	Cost: 19.88s
Train Epoch: 529 [61440/90000 (68%)]	Loss: -3.5340	Cost: 11.18s
Train Epoch: 529 [81920/90000 (91%)]	Loss: -3.5899	Cost: 24.03s
Train Epoch: 529 	Average Loss: -3.0631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1576

Learning rate: 0.0001999861907180127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: 0.3897	Cost: 83.03s
Train Epoch: 530 [20480/90000 (23%)]	Loss: -3.2828	Cost: 9.54s
Train Epoch: 530 [40960/90000 (45%)]	Loss: -3.1974	Cost: 20.06s
Train Epoch: 530 [61440/90000 (68%)]	Loss: -3.4209	Cost: 10.22s
Train Epoch: 530 [81920/90000 (91%)]	Loss: -3.5891	Cost: 26.49s
Train Epoch: 530 	Average Loss: -3.0215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2879

Learning rate: 0.0001999861384608675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: 0.4780	Cost: 79.90s
Train Epoch: 531 [20480/90000 (23%)]	Loss: -3.3345	Cost: 10.82s
Train Epoch: 531 [40960/90000 (45%)]	Loss: -3.5101	Cost: 21.74s
Train Epoch: 531 [61440/90000 (68%)]	Loss: -3.3641	Cost: 10.47s
Train Epoch: 531 [81920/90000 (91%)]	Loss: -3.7255	Cost: 23.35s
Train Epoch: 531 	Average Loss: -3.0760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1985

Learning rate: 0.00019998608610503996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: 0.2435	Cost: 69.94s
Train Epoch: 532 [20480/90000 (23%)]	Loss: -3.4730	Cost: 10.98s
Train Epoch: 532 [40960/90000 (45%)]	Loss: -3.5927	Cost: 23.14s
Train Epoch: 532 [61440/90000 (68%)]	Loss: -3.5944	Cost: 11.94s
Train Epoch: 532 [81920/90000 (91%)]	Loss: -3.8434	Cost: 26.06s
Train Epoch: 532 	Average Loss: -3.2372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0939

Saving model as e532_model.pt & e532_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998603365053012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: -0.4275	Cost: 91.72s
Train Epoch: 533 [20480/90000 (23%)]	Loss: -3.2170	Cost: 12.52s
Train Epoch: 533 [40960/90000 (45%)]	Loss: -3.7567	Cost: 31.69s
Train Epoch: 533 [61440/90000 (68%)]	Loss: -3.6871	Cost: 11.79s
Train Epoch: 533 [81920/90000 (91%)]	Loss: -3.7859	Cost: 26.12s
Train Epoch: 533 	Average Loss: -3.2119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0027

Saving model as e533_model.pt & e533_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998598109733802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: 0.2976	Cost: 94.39s
Train Epoch: 534 [20480/90000 (23%)]	Loss: -3.5704	Cost: 10.60s
Train Epoch: 534 [40960/90000 (45%)]	Loss: -3.7704	Cost: 19.43s
Train Epoch: 534 [61440/90000 (68%)]	Loss: -3.6939	Cost: 12.69s
Train Epoch: 534 [81920/90000 (91%)]	Loss: -3.8999	Cost: 22.96s
Train Epoch: 534 	Average Loss: -3.3541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0912

Learning rate: 0.0001999859284454637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: -0.2024	Cost: 91.75s
Train Epoch: 535 [20480/90000 (23%)]	Loss: -3.5250	Cost: 10.52s
Train Epoch: 535 [40960/90000 (45%)]	Loss: -3.6972	Cost: 21.04s
Train Epoch: 535 [61440/90000 (68%)]	Loss: -3.8071	Cost: 10.84s
Train Epoch: 535 [81920/90000 (91%)]	Loss: -3.9442	Cost: 23.05s
Train Epoch: 535 	Average Loss: -3.3446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0634

Learning rate: 0.00019998587569490723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: 0.3304	Cost: 79.97s
Train Epoch: 536 [20480/90000 (23%)]	Loss: -3.6792	Cost: 13.18s
Train Epoch: 536 [40960/90000 (45%)]	Loss: -3.6836	Cost: 21.46s
Train Epoch: 536 [61440/90000 (68%)]	Loss: -3.8121	Cost: 10.48s
Train Epoch: 536 [81920/90000 (91%)]	Loss: -3.7440	Cost: 26.97s
Train Epoch: 536 	Average Loss: -3.3403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1241

Learning rate: 0.00019998582284566865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: -0.0907	Cost: 86.28s
Train Epoch: 537 [20480/90000 (23%)]	Loss: -3.5210	Cost: 11.17s
Train Epoch: 537 [40960/90000 (45%)]	Loss: -3.6494	Cost: 20.32s
Train Epoch: 537 [61440/90000 (68%)]	Loss: -3.5985	Cost: 10.80s
Train Epoch: 537 [81920/90000 (91%)]	Loss: -3.9272	Cost: 28.49s
Train Epoch: 537 	Average Loss: -3.2858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1799

Learning rate: 0.00019998576989774803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: 0.1577	Cost: 74.83s
Train Epoch: 538 [20480/90000 (23%)]	Loss: -3.6805	Cost: 10.98s
Train Epoch: 538 [40960/90000 (45%)]	Loss: -3.9485	Cost: 23.68s
Train Epoch: 538 [61440/90000 (68%)]	Loss: -3.8382	Cost: 13.29s
Train Epoch: 538 [81920/90000 (91%)]	Loss: -4.0210	Cost: 16.29s
Train Epoch: 538 	Average Loss: -3.3989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0478

Learning rate: 0.0001999857168511454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: 0.1820	Cost: 73.54s
Train Epoch: 539 [20480/90000 (23%)]	Loss: -3.6802	Cost: 13.40s
Train Epoch: 539 [40960/90000 (45%)]	Loss: -3.8560	Cost: 23.27s
Train Epoch: 539 [61440/90000 (68%)]	Loss: -3.7668	Cost: 11.90s
Train Epoch: 539 [81920/90000 (91%)]	Loss: -3.8660	Cost: 20.47s
Train Epoch: 539 	Average Loss: -3.3809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0199

Learning rate: 0.00019998566370586085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: 0.0878	Cost: 98.44s
Train Epoch: 540 [20480/90000 (23%)]	Loss: -3.6774	Cost: 10.99s
Train Epoch: 540 [40960/90000 (45%)]	Loss: -3.9878	Cost: 20.07s
Train Epoch: 540 [61440/90000 (68%)]	Loss: -3.8147	Cost: 10.79s
Train Epoch: 540 [81920/90000 (91%)]	Loss: -4.0227	Cost: 30.13s
Train Epoch: 540 	Average Loss: -3.4487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1255

Saving model as e540_model.pt & e540_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999856104618944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: 0.1390	Cost: 84.20s
Train Epoch: 541 [20480/90000 (23%)]	Loss: -3.5245	Cost: 11.70s
Train Epoch: 541 [40960/90000 (45%)]	Loss: -3.7276	Cost: 16.47s
Train Epoch: 541 [61440/90000 (68%)]	Loss: -3.8938	Cost: 13.16s
Train Epoch: 541 [81920/90000 (91%)]	Loss: -3.8208	Cost: 21.79s
Train Epoch: 541 	Average Loss: -3.4118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0127

Learning rate: 0.0001999855571192461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: -0.3556	Cost: 100.12s
Train Epoch: 542 [20480/90000 (23%)]	Loss: -3.6881	Cost: 12.03s
Train Epoch: 542 [40960/90000 (45%)]	Loss: -3.5680	Cost: 30.50s
Train Epoch: 542 [61440/90000 (68%)]	Loss: -3.7266	Cost: 11.56s
Train Epoch: 542 [81920/90000 (91%)]	Loss: -3.6357	Cost: 24.42s
Train Epoch: 542 	Average Loss: -3.3318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3311

Learning rate: 0.00019998550367791602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: -0.1133	Cost: 91.81s
Train Epoch: 543 [20480/90000 (23%)]	Loss: -3.2815	Cost: 13.48s
Train Epoch: 543 [40960/90000 (45%)]	Loss: -3.6565	Cost: 23.36s
Train Epoch: 543 [61440/90000 (68%)]	Loss: -3.6022	Cost: 10.26s
Train Epoch: 543 [81920/90000 (91%)]	Loss: -3.8953	Cost: 30.66s
Train Epoch: 543 	Average Loss: -3.2961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0346

Learning rate: 0.0001999854501379042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: 0.3921	Cost: 80.26s
Train Epoch: 544 [20480/90000 (23%)]	Loss: -3.6184	Cost: 13.43s
Train Epoch: 544 [40960/90000 (45%)]	Loss: -3.8756	Cost: 25.88s
Train Epoch: 544 [61440/90000 (68%)]	Loss: -3.9957	Cost: 11.98s
Train Epoch: 544 [81920/90000 (91%)]	Loss: -4.0087	Cost: 20.79s
Train Epoch: 544 	Average Loss: -3.4849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1085

Learning rate: 0.00019998539649921068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: -0.2247	Cost: 77.78s
Train Epoch: 545 [20480/90000 (23%)]	Loss: -3.8351	Cost: 13.72s
Train Epoch: 545 [40960/90000 (45%)]	Loss: -2.5474	Cost: 21.99s
Train Epoch: 545 [61440/90000 (68%)]	Loss: -3.0092	Cost: 13.30s
Train Epoch: 545 [81920/90000 (91%)]	Loss: -3.4641	Cost: 24.47s
Train Epoch: 545 	Average Loss: -2.8931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2423

Learning rate: 0.00019998534276183553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: 0.1398	Cost: 23.63s
Train Epoch: 546 [20480/90000 (23%)]	Loss: -3.4924	Cost: 6.16s
Train Epoch: 546 [40960/90000 (45%)]	Loss: -3.5661	Cost: 7.75s
Train Epoch: 546 [61440/90000 (68%)]	Loss: -3.8557	Cost: 6.21s
Train Epoch: 546 [81920/90000 (91%)]	Loss: -3.9653	Cost: 6.07s
Train Epoch: 546 	Average Loss: -3.3328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2152

Saving model as e546_model.pt & e546_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998528892577877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: -0.2038	Cost: 23.70s
Train Epoch: 547 [20480/90000 (23%)]	Loss: -3.9650	Cost: 6.20s
Train Epoch: 547 [40960/90000 (45%)]	Loss: -4.1750	Cost: 9.31s
Train Epoch: 547 [61440/90000 (68%)]	Loss: -4.1828	Cost: 5.87s
Train Epoch: 547 [81920/90000 (91%)]	Loss: -4.3168	Cost: 6.14s
Train Epoch: 547 	Average Loss: -3.6838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3725

Saving model as e547_model.pt & e547_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998523499104056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: -0.0325	Cost: 26.19s
Train Epoch: 548 [20480/90000 (23%)]	Loss: -3.7771	Cost: 9.27s
Train Epoch: 548 [40960/90000 (45%)]	Loss: -3.8295	Cost: 15.03s
Train Epoch: 548 [61440/90000 (68%)]	Loss: -4.0725	Cost: 7.11s
Train Epoch: 548 [81920/90000 (91%)]	Loss: -3.9939	Cost: 12.40s
Train Epoch: 548 	Average Loss: -3.5355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0243

Learning rate: 0.0001999851809576208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: -0.1510	Cost: 22.87s
Train Epoch: 549 [20480/90000 (23%)]	Loss: -3.5699	Cost: 6.07s
Train Epoch: 549 [40960/90000 (45%)]	Loss: -3.8765	Cost: 8.31s
Train Epoch: 549 [61440/90000 (68%)]	Loss: -4.0744	Cost: 5.78s
Train Epoch: 549 [81920/90000 (91%)]	Loss: -4.1314	Cost: 6.29s
Train Epoch: 549 	Average Loss: -3.5239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3350

Learning rate: 0.00019998512682551964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: -0.7339	Cost: 23.52s
Train Epoch: 550 [20480/90000 (23%)]	Loss: -3.8150	Cost: 6.28s
Train Epoch: 550 [40960/90000 (45%)]	Loss: -4.1892	Cost: 10.99s
Train Epoch: 550 [61440/90000 (68%)]	Loss: -4.1908	Cost: 6.18s
Train Epoch: 550 [81920/90000 (91%)]	Loss: -4.2866	Cost: 10.71s
Train Epoch: 550 	Average Loss: -3.7927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5109

Saving model as e550_model.pt & e550_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998507259473715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: -0.3473	Cost: 23.80s
Train Epoch: 551 [20480/90000 (23%)]	Loss: -4.0668	Cost: 6.05s
Train Epoch: 551 [40960/90000 (45%)]	Loss: -4.3121	Cost: 7.95s
Train Epoch: 551 [61440/90000 (68%)]	Loss: -4.0862	Cost: 5.78s
Train Epoch: 551 [81920/90000 (91%)]	Loss: -4.0438	Cost: 6.23s
Train Epoch: 551 	Average Loss: -3.7250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1750

Learning rate: 0.00019998501826527334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: -0.2162	Cost: 27.89s
Train Epoch: 552 [20480/90000 (23%)]	Loss: -3.8496	Cost: 6.23s
Train Epoch: 552 [40960/90000 (45%)]	Loss: -3.9829	Cost: 10.83s
Train Epoch: 552 [61440/90000 (68%)]	Loss: -4.0967	Cost: 6.17s
Train Epoch: 552 [81920/90000 (91%)]	Loss: -4.2525	Cost: 5.75s
Train Epoch: 552 	Average Loss: -3.6688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2849

Learning rate: 0.00019998496383712825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: -0.4134	Cost: 24.27s
Train Epoch: 553 [20480/90000 (23%)]	Loss: -3.9396	Cost: 6.24s
Train Epoch: 553 [40960/90000 (45%)]	Loss: -3.9767	Cost: 9.15s
Train Epoch: 553 [61440/90000 (68%)]	Loss: -4.1945	Cost: 5.85s
Train Epoch: 553 [81920/90000 (91%)]	Loss: -4.2034	Cost: 6.10s
Train Epoch: 553 	Average Loss: -3.7800
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4278

Learning rate: 0.000199984909310302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: -0.6863	Cost: 29.81s
Train Epoch: 554 [20480/90000 (23%)]	Loss: -3.9192	Cost: 10.33s
Train Epoch: 554 [40960/90000 (45%)]	Loss: -3.8007	Cost: 11.93s
Train Epoch: 554 [61440/90000 (68%)]	Loss: -3.9795	Cost: 6.41s
Train Epoch: 554 [81920/90000 (91%)]	Loss: -4.3038	Cost: 10.84s
Train Epoch: 554 	Average Loss: -3.6438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1986

Learning rate: 0.00019998485468479454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: 0.1941	Cost: 23.75s
Train Epoch: 555 [20480/90000 (23%)]	Loss: -3.8793	Cost: 6.22s
Train Epoch: 555 [40960/90000 (45%)]	Loss: -4.0875	Cost: 8.48s
Train Epoch: 555 [61440/90000 (68%)]	Loss: -4.0412	Cost: 5.84s
Train Epoch: 555 [81920/90000 (91%)]	Loss: -4.1596	Cost: 6.61s
Train Epoch: 555 	Average Loss: -3.6287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1881

Learning rate: 0.000199984799960606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: -0.0197	Cost: 22.68s
Train Epoch: 556 [20480/90000 (23%)]	Loss: -3.9774	Cost: 6.75s
Train Epoch: 556 [40960/90000 (45%)]	Loss: -4.1641	Cost: 10.81s
Train Epoch: 556 [61440/90000 (68%)]	Loss: -4.3565	Cost: 6.32s
Train Epoch: 556 [81920/90000 (91%)]	Loss: -4.4577	Cost: 11.36s
Train Epoch: 556 	Average Loss: -3.7980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4900

Learning rate: 0.00019998474513773643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: -0.5852	Cost: 25.99s
Train Epoch: 557 [20480/90000 (23%)]	Loss: -2.7175	Cost: 6.21s
Train Epoch: 557 [40960/90000 (45%)]	Loss: -2.8803	Cost: 8.42s
Train Epoch: 557 [61440/90000 (68%)]	Loss: -3.3319	Cost: 5.69s
Train Epoch: 557 [81920/90000 (91%)]	Loss: -3.7232	Cost: 6.18s
Train Epoch: 557 	Average Loss: -2.8442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0862

Learning rate: 0.00019998469021618588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: -0.1746	Cost: 33.93s
Train Epoch: 558 [20480/90000 (23%)]	Loss: -3.8986	Cost: 6.70s
Train Epoch: 558 [40960/90000 (45%)]	Loss: -4.1906	Cost: 15.68s
Train Epoch: 558 [61440/90000 (68%)]	Loss: -4.2509	Cost: 6.22s
Train Epoch: 558 [81920/90000 (91%)]	Loss: -4.4190	Cost: 10.25s
Train Epoch: 558 	Average Loss: -3.7684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4933

Learning rate: 0.00019998463519595438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: -0.5996	Cost: 24.37s
Train Epoch: 559 [20480/90000 (23%)]	Loss: -4.2422	Cost: 6.17s
Train Epoch: 559 [40960/90000 (45%)]	Loss: -4.4567	Cost: 8.58s
Train Epoch: 559 [61440/90000 (68%)]	Loss: -4.4662	Cost: 6.02s
Train Epoch: 559 [81920/90000 (91%)]	Loss: -3.9787	Cost: 6.40s
Train Epoch: 559 	Average Loss: -3.8631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0888

Learning rate: 0.000199984580077042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: -0.2761	Cost: 22.90s
Train Epoch: 560 [20480/90000 (23%)]	Loss: -3.8694	Cost: 6.49s
Train Epoch: 560 [40960/90000 (45%)]	Loss: -4.2123	Cost: 10.24s
Train Epoch: 560 [61440/90000 (68%)]	Loss: -4.3419	Cost: 6.47s
Train Epoch: 560 [81920/90000 (91%)]	Loss: -4.3687	Cost: 10.46s
Train Epoch: 560 	Average Loss: -3.7294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4010

Learning rate: 0.00019998452485944882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: 0.0241	Cost: 22.72s
Train Epoch: 561 [20480/90000 (23%)]	Loss: -4.0455	Cost: 6.13s
Train Epoch: 561 [40960/90000 (45%)]	Loss: -4.3994	Cost: 8.46s
Train Epoch: 561 [61440/90000 (68%)]	Loss: -4.4107	Cost: 6.19s
Train Epoch: 561 [81920/90000 (91%)]	Loss: -4.6876	Cost: 5.71s
Train Epoch: 561 	Average Loss: -3.9991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6713

Saving model as e561_model.pt & e561_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998446954317485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: -0.4598	Cost: 42.96s
Train Epoch: 562 [20480/90000 (23%)]	Loss: -4.3741	Cost: 6.86s
Train Epoch: 562 [40960/90000 (45%)]	Loss: -4.4505	Cost: 12.57s
Train Epoch: 562 [61440/90000 (68%)]	Loss: -4.5308	Cost: 5.84s
Train Epoch: 562 [81920/90000 (91%)]	Loss: -4.2344	Cost: 7.40s
Train Epoch: 562 	Average Loss: -4.0351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3960

Learning rate: 0.00019998441412822013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: -0.5525	Cost: 23.79s
Train Epoch: 563 [20480/90000 (23%)]	Loss: -4.2419	Cost: 6.06s
Train Epoch: 563 [40960/90000 (45%)]	Loss: -4.5284	Cost: 7.74s
Train Epoch: 563 [61440/90000 (68%)]	Loss: -4.4947	Cost: 5.97s
Train Epoch: 563 [81920/90000 (91%)]	Loss: -4.4325	Cost: 6.03s
Train Epoch: 563 	Average Loss: -3.9703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6059

Learning rate: 0.0001999843586145848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: -0.0789	Cost: 29.46s
Train Epoch: 564 [20480/90000 (23%)]	Loss: -4.1930	Cost: 6.89s
Train Epoch: 564 [40960/90000 (45%)]	Loss: -4.5000	Cost: 10.95s
Train Epoch: 564 [61440/90000 (68%)]	Loss: -4.4290	Cost: 5.85s
Train Epoch: 564 [81920/90000 (91%)]	Loss: -4.4262	Cost: 6.73s
Train Epoch: 564 	Average Loss: -3.9959
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4260

Learning rate: 0.00019998430300226887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: -0.4107	Cost: 24.25s
Train Epoch: 565 [20480/90000 (23%)]	Loss: -4.2117	Cost: 6.13s
Train Epoch: 565 [40960/90000 (45%)]	Loss: -4.4488	Cost: 8.35s
Train Epoch: 565 [61440/90000 (68%)]	Loss: -4.5153	Cost: 5.95s
Train Epoch: 565 [81920/90000 (91%)]	Loss: -4.4169	Cost: 6.70s
Train Epoch: 565 	Average Loss: -4.0055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5297

Learning rate: 0.0001999842472912724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: -0.1854	Cost: 30.04s
Train Epoch: 566 [20480/90000 (23%)]	Loss: -4.2244	Cost: 6.18s
Train Epoch: 566 [40960/90000 (45%)]	Loss: -4.5549	Cost: 8.67s
Train Epoch: 566 [61440/90000 (68%)]	Loss: -4.4219	Cost: 5.96s
Train Epoch: 566 [81920/90000 (91%)]	Loss: -4.5834	Cost: 9.20s
Train Epoch: 566 	Average Loss: -4.0436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5980

Learning rate: 0.0001999841914815954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: -0.5236	Cost: 23.09s
Train Epoch: 567 [20480/90000 (23%)]	Loss: -4.4889	Cost: 6.16s
Train Epoch: 567 [40960/90000 (45%)]	Loss: -4.5678	Cost: 7.89s
Train Epoch: 567 [61440/90000 (68%)]	Loss: -4.3619	Cost: 6.66s
Train Epoch: 567 [81920/90000 (91%)]	Loss: -4.5266	Cost: 9.05s
Train Epoch: 567 	Average Loss: -4.1052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6201

Learning rate: 0.00019998413557323794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: -0.3507	Cost: 28.62s
Train Epoch: 568 [20480/90000 (23%)]	Loss: -4.4915	Cost: 6.51s
Train Epoch: 568 [40960/90000 (45%)]	Loss: -4.5219	Cost: 8.34s
Train Epoch: 568 [61440/90000 (68%)]	Loss: -4.6118	Cost: 6.09s
Train Epoch: 568 [81920/90000 (91%)]	Loss: -4.7439	Cost: 9.21s
Train Epoch: 568 	Average Loss: -4.1874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7567

Saving model as e568_model.pt & e568_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998407956620012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: -0.5091	Cost: 22.72s
Train Epoch: 569 [20480/90000 (23%)]	Loss: -4.5337	Cost: 6.75s
Train Epoch: 569 [40960/90000 (45%)]	Loss: -4.3729	Cost: 9.52s
Train Epoch: 569 [61440/90000 (68%)]	Loss: -4.6907	Cost: 6.51s
Train Epoch: 569 [81920/90000 (91%)]	Loss: -4.6178	Cost: 11.36s
Train Epoch: 569 	Average Loss: -4.1648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6958

Learning rate: 0.00019998402346048196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: -0.2718	Cost: 28.94s
Train Epoch: 570 [20480/90000 (23%)]	Loss: -4.3108	Cost: 6.67s
Train Epoch: 570 [40960/90000 (45%)]	Loss: -4.6657	Cost: 9.73s
Train Epoch: 570 [61440/90000 (68%)]	Loss: -4.7966	Cost: 5.80s
Train Epoch: 570 [81920/90000 (91%)]	Loss: -4.7755	Cost: 6.08s
Train Epoch: 570 	Average Loss: -4.2434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7585

Saving model as e570_model.pt & e570_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999839672560835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: -0.4228	Cost: 30.87s
Train Epoch: 571 [20480/90000 (23%)]	Loss: -4.4249	Cost: 6.17s
Train Epoch: 571 [40960/90000 (45%)]	Loss: -4.7017	Cost: 8.69s
Train Epoch: 571 [61440/90000 (68%)]	Loss: -4.6431	Cost: 6.07s
Train Epoch: 571 [81920/90000 (91%)]	Loss: -4.7894	Cost: 8.64s
Train Epoch: 571 	Average Loss: -4.2533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7267

Learning rate: 0.00019998391095300483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: -0.7396	Cost: 27.12s
Train Epoch: 572 [20480/90000 (23%)]	Loss: -4.5014	Cost: 6.38s
Train Epoch: 572 [40960/90000 (45%)]	Loss: -4.7432	Cost: 13.64s
Train Epoch: 572 [61440/90000 (68%)]	Loss: -4.1637	Cost: 6.78s
Train Epoch: 572 [81920/90000 (91%)]	Loss: -4.4595	Cost: 13.58s
Train Epoch: 572 	Average Loss: -4.1150
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6388

Learning rate: 0.00019998385455124602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: -0.7046	Cost: 27.57s
Train Epoch: 573 [20480/90000 (23%)]	Loss: -4.0157	Cost: 6.07s
Train Epoch: 573 [40960/90000 (45%)]	Loss: -4.2236	Cost: 7.95s
Train Epoch: 573 [61440/90000 (68%)]	Loss: -4.3249	Cost: 5.99s
Train Epoch: 573 [81920/90000 (91%)]	Loss: -4.7584	Cost: 7.39s
Train Epoch: 573 	Average Loss: -3.9515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7696

Saving model as e573_model.pt & e573_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998379805080712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: -0.7523	Cost: 21.97s
Train Epoch: 574 [20480/90000 (23%)]	Loss: -4.4253	Cost: 6.06s
Train Epoch: 574 [40960/90000 (45%)]	Loss: -4.7497	Cost: 8.62s
Train Epoch: 574 [61440/90000 (68%)]	Loss: -4.6627	Cost: 6.35s
Train Epoch: 574 [81920/90000 (91%)]	Loss: -4.7346	Cost: 11.57s
Train Epoch: 574 	Average Loss: -4.2636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7574

Learning rate: 0.00019998374145168815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: -0.7362	Cost: 24.05s
Train Epoch: 575 [20480/90000 (23%)]	Loss: -4.4894	Cost: 6.05s
Train Epoch: 575 [40960/90000 (45%)]	Loss: -4.7307	Cost: 8.51s
Train Epoch: 575 [61440/90000 (68%)]	Loss: -4.6645	Cost: 6.06s
Train Epoch: 575 [81920/90000 (91%)]	Loss: -4.7777	Cost: 6.57s
Train Epoch: 575 	Average Loss: -4.3049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8091

Saving model as e575_model.pt & e575_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998368475388916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: -0.4974	Cost: 25.01s
Train Epoch: 576 [20480/90000 (23%)]	Loss: -4.5014	Cost: 6.36s
Train Epoch: 576 [40960/90000 (45%)]	Loss: -4.8768	Cost: 10.94s
Train Epoch: 576 [61440/90000 (68%)]	Loss: -4.8177	Cost: 6.13s
Train Epoch: 576 [81920/90000 (91%)]	Loss: -4.8689	Cost: 9.51s
Train Epoch: 576 	Average Loss: -4.3582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6461

Learning rate: 0.00019998362795741026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: -0.8660	Cost: 24.07s
Train Epoch: 577 [20480/90000 (23%)]	Loss: -4.4161	Cost: 6.20s
Train Epoch: 577 [40960/90000 (45%)]	Loss: -4.7241	Cost: 8.62s
Train Epoch: 577 [61440/90000 (68%)]	Loss: -4.7924	Cost: 5.79s
Train Epoch: 577 [81920/90000 (91%)]	Loss: -4.7735	Cost: 6.46s
Train Epoch: 577 	Average Loss: -4.2991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7498

Learning rate: 0.00019998357106225145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: -0.2211	Cost: 22.91s
Train Epoch: 578 [20480/90000 (23%)]	Loss: -4.6436	Cost: 6.60s
Train Epoch: 578 [40960/90000 (45%)]	Loss: -4.7888	Cost: 10.83s
Train Epoch: 578 [61440/90000 (68%)]	Loss: -4.8023	Cost: 6.37s
Train Epoch: 578 [81920/90000 (91%)]	Loss: -4.8082	Cost: 11.20s
Train Epoch: 578 	Average Loss: -4.3585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9316

Saving model as e578_model.pt & e578_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998351406841282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: -0.3435	Cost: 24.78s
Train Epoch: 579 [20480/90000 (23%)]	Loss: -4.7999	Cost: 6.29s
Train Epoch: 579 [40960/90000 (45%)]	Loss: -4.9708	Cost: 8.33s
Train Epoch: 579 [61440/90000 (68%)]	Loss: -4.7857	Cost: 5.90s
Train Epoch: 579 [81920/90000 (91%)]	Loss: -5.0297	Cost: 6.46s
Train Epoch: 579 	Average Loss: -4.4135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8459

Learning rate: 0.0001999834569758944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: -0.7857	Cost: 22.50s
Train Epoch: 580 [20480/90000 (23%)]	Loss: -4.4820	Cost: 6.36s
Train Epoch: 580 [40960/90000 (45%)]	Loss: -4.8246	Cost: 9.45s
Train Epoch: 580 [61440/90000 (68%)]	Loss: -4.8185	Cost: 6.19s
Train Epoch: 580 [81920/90000 (91%)]	Loss: -5.0626	Cost: 11.16s
Train Epoch: 580 	Average Loss: -4.3967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8386

Learning rate: 0.00019998339978469627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: -1.1885	Cost: 27.19s
Train Epoch: 581 [20480/90000 (23%)]	Loss: -4.6881	Cost: 6.07s
Train Epoch: 581 [40960/90000 (45%)]	Loss: -4.7766	Cost: 9.25s
Train Epoch: 581 [61440/90000 (68%)]	Loss: -3.4713	Cost: 5.78s
Train Epoch: 581 [81920/90000 (91%)]	Loss: -3.8616	Cost: 6.29s
Train Epoch: 581 	Average Loss: -3.9131
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1303

Learning rate: 0.0001999833424948185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: 0.1036	Cost: 28.20s
Train Epoch: 582 [20480/90000 (23%)]	Loss: -3.9882	Cost: 9.92s
Train Epoch: 582 [40960/90000 (45%)]	Loss: -4.3114	Cost: 14.28s
Train Epoch: 582 [61440/90000 (68%)]	Loss: -4.5246	Cost: 6.67s
Train Epoch: 582 [81920/90000 (91%)]	Loss: -4.8326	Cost: 11.61s
Train Epoch: 582 	Average Loss: -3.9488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7945

Learning rate: 0.00019998328510626112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: -0.8707	Cost: 25.51s
Train Epoch: 583 [20480/90000 (23%)]	Loss: -4.3432	Cost: 6.11s
Train Epoch: 583 [40960/90000 (45%)]	Loss: -4.3033	Cost: 7.92s
Train Epoch: 583 [61440/90000 (68%)]	Loss: -4.3956	Cost: 6.04s
Train Epoch: 583 [81920/90000 (91%)]	Loss: -4.5038	Cost: 7.52s
Train Epoch: 583 	Average Loss: -4.0348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5136

Learning rate: 0.0001999832276190242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: -0.4503	Cost: 22.99s
Train Epoch: 584 [20480/90000 (23%)]	Loss: -4.4748	Cost: 6.07s
Train Epoch: 584 [40960/90000 (45%)]	Loss: -4.6760	Cost: 7.03s
Train Epoch: 584 [61440/90000 (68%)]	Loss: -4.7286	Cost: 6.23s
Train Epoch: 584 [81920/90000 (91%)]	Loss: -4.7400	Cost: 9.28s
Train Epoch: 584 	Average Loss: -4.2460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6375

Learning rate: 0.00019998317003310778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: -0.6142	Cost: 27.12s
Train Epoch: 585 [20480/90000 (23%)]	Loss: -4.7128	Cost: 6.22s
Train Epoch: 585 [40960/90000 (45%)]	Loss: -4.9321	Cost: 7.93s
Train Epoch: 585 [61440/90000 (68%)]	Loss: -4.8842	Cost: 5.89s
Train Epoch: 585 [81920/90000 (91%)]	Loss: -4.9728	Cost: 7.22s
Train Epoch: 585 	Average Loss: -4.4083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8612

Learning rate: 0.0001999831123485119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: -0.6884	Cost: 27.35s
Train Epoch: 586 [20480/90000 (23%)]	Loss: -4.7407	Cost: 6.47s
Train Epoch: 586 [40960/90000 (45%)]	Loss: -4.8188	Cost: 6.88s
Train Epoch: 586 [61440/90000 (68%)]	Loss: -4.5923	Cost: 6.34s
Train Epoch: 586 [81920/90000 (91%)]	Loss: -5.0687	Cost: 12.63s
Train Epoch: 586 	Average Loss: -4.4094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9380

Saving model as e586_model.pt & e586_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998305456523665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: -0.7376	Cost: 23.40s
Train Epoch: 587 [20480/90000 (23%)]	Loss: -4.6972	Cost: 6.26s
Train Epoch: 587 [40960/90000 (45%)]	Loss: -4.7827	Cost: 8.27s
Train Epoch: 587 [61440/90000 (68%)]	Loss: -5.0611	Cost: 5.81s
Train Epoch: 587 [81920/90000 (91%)]	Loss: -5.2923	Cost: 6.48s
Train Epoch: 587 	Average Loss: -4.5345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1268

Saving model as e587_model.pt & e587_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999829966832821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: -1.1130	Cost: 27.57s
Train Epoch: 588 [20480/90000 (23%)]	Loss: -5.0158	Cost: 6.21s
Train Epoch: 588 [40960/90000 (45%)]	Loss: -5.2327	Cost: 10.52s
Train Epoch: 588 [61440/90000 (68%)]	Loss: -4.9151	Cost: 5.67s
Train Epoch: 588 [81920/90000 (91%)]	Loss: -5.0991	Cost: 6.05s
Train Epoch: 588 	Average Loss: -4.6420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9384

Learning rate: 0.00019998293870264827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: -0.7676	Cost: 23.48s
Train Epoch: 589 [20480/90000 (23%)]	Loss: -4.9013	Cost: 6.07s
Train Epoch: 589 [40960/90000 (45%)]	Loss: -5.1106	Cost: 8.22s
Train Epoch: 589 [61440/90000 (68%)]	Loss: -5.0746	Cost: 5.78s
Train Epoch: 589 [81920/90000 (91%)]	Loss: -5.3019	Cost: 6.19s
Train Epoch: 589 	Average Loss: -4.6864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9806

Learning rate: 0.00019998288062333524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: -0.7578	Cost: 23.85s
Train Epoch: 590 [20480/90000 (23%)]	Loss: -4.8103	Cost: 6.51s
Train Epoch: 590 [40960/90000 (45%)]	Loss: -4.8894	Cost: 10.73s
Train Epoch: 590 [61440/90000 (68%)]	Loss: -5.0644	Cost: 6.13s
Train Epoch: 590 [81920/90000 (91%)]	Loss: -5.2998	Cost: 10.42s
Train Epoch: 590 	Average Loss: -4.5810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1004

Learning rate: 0.00019998282244534305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: -1.0951	Cost: 29.63s
Train Epoch: 591 [20480/90000 (23%)]	Loss: -5.0138	Cost: 6.36s
Train Epoch: 591 [40960/90000 (45%)]	Loss: -5.1509	Cost: 11.23s
Train Epoch: 591 [61440/90000 (68%)]	Loss: -5.0455	Cost: 6.00s
Train Epoch: 591 [81920/90000 (91%)]	Loss: -5.1938	Cost: 7.65s
Train Epoch: 591 	Average Loss: -4.7312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0050

Learning rate: 0.0001999827641686718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: -1.2101	Cost: 27.80s
Train Epoch: 592 [20480/90000 (23%)]	Loss: -4.7675	Cost: 6.22s
Train Epoch: 592 [40960/90000 (45%)]	Loss: -5.0614	Cost: 10.36s
Train Epoch: 592 [61440/90000 (68%)]	Loss: -4.8835	Cost: 5.71s
Train Epoch: 592 [81920/90000 (91%)]	Loss: -5.0827	Cost: 5.97s
Train Epoch: 592 	Average Loss: -4.5565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1082

Learning rate: 0.0001999827057933215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: -0.9451	Cost: 24.57s
Train Epoch: 593 [20480/90000 (23%)]	Loss: -4.9762	Cost: 6.08s
Train Epoch: 593 [40960/90000 (45%)]	Loss: -5.2368	Cost: 8.38s
Train Epoch: 593 [61440/90000 (68%)]	Loss: -5.1785	Cost: 5.75s
Train Epoch: 593 [81920/90000 (91%)]	Loss: -5.4172	Cost: 6.40s
Train Epoch: 593 	Average Loss: -4.7420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2162

Saving model as e593_model.pt & e593_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999826473192922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: -1.1400	Cost: 26.95s
Train Epoch: 594 [20480/90000 (23%)]	Loss: -5.0783	Cost: 6.17s
Train Epoch: 594 [40960/90000 (45%)]	Loss: -5.3030	Cost: 7.65s
Train Epoch: 594 [61440/90000 (68%)]	Loss: -5.3398	Cost: 6.04s
Train Epoch: 594 [81920/90000 (91%)]	Loss: -5.3977	Cost: 7.51s
Train Epoch: 594 	Average Loss: -4.8547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2871

Saving model as e594_model.pt & e594_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998258874658403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: -1.2170	Cost: 22.45s
Train Epoch: 595 [20480/90000 (23%)]	Loss: -5.1086	Cost: 6.02s
Train Epoch: 595 [40960/90000 (45%)]	Loss: -4.8296	Cost: 8.36s
Train Epoch: 595 [61440/90000 (68%)]	Loss: -2.4443	Cost: 6.21s
Train Epoch: 595 [81920/90000 (91%)]	Loss: -2.7851	Cost: 11.25s
Train Epoch: 595 	Average Loss: -3.5693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7135

Learning rate: 0.00019998253007519698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: 0.7390	Cost: 26.97s
Train Epoch: 596 [20480/90000 (23%)]	Loss: -3.0277	Cost: 6.13s
Train Epoch: 596 [40960/90000 (45%)]	Loss: -3.6863	Cost: 7.05s
Train Epoch: 596 [61440/90000 (68%)]	Loss: -3.8993	Cost: 6.08s
Train Epoch: 596 [81920/90000 (91%)]	Loss: -4.3368	Cost: 7.03s
Train Epoch: 596 	Average Loss: -3.2854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6008

Learning rate: 0.00019998247130513115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: -0.7434	Cost: 24.11s
Train Epoch: 597 [20480/90000 (23%)]	Loss: -4.4470	Cost: 6.13s
Train Epoch: 597 [40960/90000 (45%)]	Loss: -4.9889	Cost: 7.98s
Train Epoch: 597 [61440/90000 (68%)]	Loss: -5.0227	Cost: 5.75s
Train Epoch: 597 [81920/90000 (91%)]	Loss: -5.1412	Cost: 6.69s
Train Epoch: 597 	Average Loss: -4.5026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0727

Learning rate: 0.00019998241243638655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: -0.8028	Cost: 30.64s
Train Epoch: 598 [20480/90000 (23%)]	Loss: -4.9959	Cost: 9.31s
Train Epoch: 598 [40960/90000 (45%)]	Loss: -5.0472	Cost: 10.37s
Train Epoch: 598 [61440/90000 (68%)]	Loss: -5.3622	Cost: 6.30s
Train Epoch: 598 [81920/90000 (91%)]	Loss: -5.1941	Cost: 10.20s
Train Epoch: 598 	Average Loss: -4.7135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0532

Learning rate: 0.00019998235346896327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: -0.9554	Cost: 23.61s
Train Epoch: 599 [20480/90000 (23%)]	Loss: -4.9092	Cost: 6.09s
Train Epoch: 599 [40960/90000 (45%)]	Loss: -5.1200	Cost: 8.04s
Train Epoch: 599 [61440/90000 (68%)]	Loss: -5.2708	Cost: 5.79s
Train Epoch: 599 [81920/90000 (91%)]	Loss: -5.2509	Cost: 6.22s
Train Epoch: 599 	Average Loss: -4.7824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2452

Learning rate: 0.0001999822944028614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: -0.6267	Cost: 29.83s
Train Epoch: 600 [20480/90000 (23%)]	Loss: -5.0504	Cost: 6.35s
Train Epoch: 600 [40960/90000 (45%)]	Loss: -5.3159	Cost: 10.35s
Train Epoch: 600 [61440/90000 (68%)]	Loss: -5.4407	Cost: 5.99s
Train Epoch: 600 [81920/90000 (91%)]	Loss: -5.3944	Cost: 5.98s
Train Epoch: 600 	Average Loss: -4.8615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3104

Saving model as e600_model.pt & e600_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999822352380809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: -1.4416	Cost: 31.16s
Train Epoch: 601 [20480/90000 (23%)]	Loss: -5.2557	Cost: 6.86s
Train Epoch: 601 [40960/90000 (45%)]	Loss: -5.4155	Cost: 10.86s
Train Epoch: 601 [61440/90000 (68%)]	Loss: -5.4128	Cost: 5.96s
Train Epoch: 601 [81920/90000 (91%)]	Loss: -5.5548	Cost: 6.66s
Train Epoch: 601 	Average Loss: -4.9885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1951

Learning rate: 0.00019998217597462192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: -1.1170	Cost: 23.46s
Train Epoch: 602 [20480/90000 (23%)]	Loss: -5.1040	Cost: 6.43s
Train Epoch: 602 [40960/90000 (45%)]	Loss: -5.3719	Cost: 8.46s
Train Epoch: 602 [61440/90000 (68%)]	Loss: -5.2276	Cost: 6.75s
Train Epoch: 602 [81920/90000 (91%)]	Loss: -5.3840	Cost: 11.76s
Train Epoch: 602 	Average Loss: -4.9314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3293

Saving model as e602_model.pt & e602_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998211661248448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: -1.5102	Cost: 26.44s
Train Epoch: 603 [20480/90000 (23%)]	Loss: -5.2233	Cost: 6.46s
Train Epoch: 603 [40960/90000 (45%)]	Loss: -5.2751	Cost: 7.45s
Train Epoch: 603 [61440/90000 (68%)]	Loss: -5.3036	Cost: 6.00s
Train Epoch: 603 [81920/90000 (91%)]	Loss: -5.4740	Cost: 6.75s
Train Epoch: 603 	Average Loss: -4.9367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1787

Learning rate: 0.00019998205715166862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: -0.9333	Cost: 28.13s
Train Epoch: 604 [20480/90000 (23%)]	Loss: -5.1075	Cost: 6.47s
Train Epoch: 604 [40960/90000 (45%)]	Loss: -5.4080	Cost: 7.34s
Train Epoch: 604 [61440/90000 (68%)]	Loss: -5.4527	Cost: 6.41s
Train Epoch: 604 [81920/90000 (91%)]	Loss: -5.5436	Cost: 7.75s
Train Epoch: 604 	Average Loss: -4.9949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4010

Saving model as e604_model.pt & e604_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998199759217446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: -0.8073	Cost: 29.76s
Train Epoch: 605 [20480/90000 (23%)]	Loss: -5.3584	Cost: 6.52s
Train Epoch: 605 [40960/90000 (45%)]	Loss: -5.4131	Cost: 8.28s
Train Epoch: 605 [61440/90000 (68%)]	Loss: -5.4646	Cost: 6.28s
Train Epoch: 605 [81920/90000 (91%)]	Loss: -5.6605	Cost: 6.94s
Train Epoch: 605 	Average Loss: -5.0137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2808

Learning rate: 0.000199981937934002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: -1.4071	Cost: 32.27s
Train Epoch: 606 [20480/90000 (23%)]	Loss: -5.2609	Cost: 12.89s
Train Epoch: 606 [40960/90000 (45%)]	Loss: -5.6407	Cost: 13.41s
Train Epoch: 606 [61440/90000 (68%)]	Loss: -5.3210	Cost: 7.72s
Train Epoch: 606 [81920/90000 (91%)]	Loss: -5.4886	Cost: 10.03s
Train Epoch: 606 	Average Loss: -4.9077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2602

Learning rate: 0.00019998187817715134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: -1.2017	Cost: 27.15s
Train Epoch: 607 [20480/90000 (23%)]	Loss: -5.2631	Cost: 6.39s
Train Epoch: 607 [40960/90000 (45%)]	Loss: -5.5876	Cost: 7.87s
Train Epoch: 607 [61440/90000 (68%)]	Loss: -5.5897	Cost: 6.08s
Train Epoch: 607 [81920/90000 (91%)]	Loss: -5.6803	Cost: 6.76s
Train Epoch: 607 	Average Loss: -5.0264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3691

Learning rate: 0.00019998181832162252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: -1.6204	Cost: 25.17s
Train Epoch: 608 [20480/90000 (23%)]	Loss: -5.5450	Cost: 6.28s
Train Epoch: 608 [40960/90000 (45%)]	Loss: -5.5703	Cost: 9.54s
Train Epoch: 608 [61440/90000 (68%)]	Loss: -5.2739	Cost: 6.07s
Train Epoch: 608 [81920/90000 (91%)]	Loss: -5.4818	Cost: 6.73s
Train Epoch: 608 	Average Loss: -5.0211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0778

Learning rate: 0.0001999817583674156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: -0.9194	Cost: 23.12s
Train Epoch: 609 [20480/90000 (23%)]	Loss: -4.9886	Cost: 6.84s
Train Epoch: 609 [40960/90000 (45%)]	Loss: -5.3611	Cost: 14.25s
Train Epoch: 609 [61440/90000 (68%)]	Loss: -5.1618	Cost: 8.80s
Train Epoch: 609 [81920/90000 (91%)]	Loss: -5.4370	Cost: 11.92s
Train Epoch: 609 	Average Loss: -4.8013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1949

Learning rate: 0.00019998169831453064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: -1.4693	Cost: 27.30s
Train Epoch: 610 [20480/90000 (23%)]	Loss: -4.6037	Cost: 6.12s
Train Epoch: 610 [40960/90000 (45%)]	Loss: -4.6999	Cost: 8.85s
Train Epoch: 610 [61440/90000 (68%)]	Loss: -5.0932	Cost: 5.93s
Train Epoch: 610 [81920/90000 (91%)]	Loss: -5.3057	Cost: 6.60s
Train Epoch: 610 	Average Loss: -4.6018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9815

Learning rate: 0.0001999816381629677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: -0.6849	Cost: 23.15s
Train Epoch: 611 [20480/90000 (23%)]	Loss: -5.1713	Cost: 6.05s
Train Epoch: 611 [40960/90000 (45%)]	Loss: -5.3749	Cost: 7.31s
Train Epoch: 611 [61440/90000 (68%)]	Loss: -5.5837	Cost: 5.91s
Train Epoch: 611 [81920/90000 (91%)]	Loss: -5.5410	Cost: 6.96s
Train Epoch: 611 	Average Loss: -4.9687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4253

Saving model as e611_model.pt & e611_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998157791272685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: -1.2413	Cost: 32.82s
Train Epoch: 612 [20480/90000 (23%)]	Loss: -5.2842	Cost: 6.00s
Train Epoch: 612 [40960/90000 (45%)]	Loss: -5.4950	Cost: 7.35s
Train Epoch: 612 [61440/90000 (68%)]	Loss: -5.6412	Cost: 6.10s
Train Epoch: 612 [81920/90000 (91%)]	Loss: -5.7570	Cost: 7.79s
Train Epoch: 612 	Average Loss: -5.0941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3582

Learning rate: 0.00019998151756380812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: -1.2977	Cost: 23.02s
Train Epoch: 613 [20480/90000 (23%)]	Loss: -5.4679	Cost: 6.03s
Train Epoch: 613 [40960/90000 (45%)]	Loss: -5.4946	Cost: 8.13s
Train Epoch: 613 [61440/90000 (68%)]	Loss: -5.3565	Cost: 5.82s
Train Epoch: 613 [81920/90000 (91%)]	Loss: -5.2616	Cost: 8.06s
Train Epoch: 613 	Average Loss: -5.0261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0617

Learning rate: 0.0001999814571162116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: -1.0646	Cost: 28.18s
Train Epoch: 614 [20480/90000 (23%)]	Loss: -5.4210	Cost: 6.13s
Train Epoch: 614 [40960/90000 (45%)]	Loss: -5.5601	Cost: 8.82s
Train Epoch: 614 [61440/90000 (68%)]	Loss: -5.7086	Cost: 5.93s
Train Epoch: 614 [81920/90000 (91%)]	Loss: -5.5412	Cost: 9.03s
Train Epoch: 614 	Average Loss: -5.0555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2545

Learning rate: 0.00019998139656993732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: -1.4620	Cost: 23.09s
Train Epoch: 615 [20480/90000 (23%)]	Loss: -5.5388	Cost: 6.00s
Train Epoch: 615 [40960/90000 (45%)]	Loss: -5.4250	Cost: 7.15s
Train Epoch: 615 [61440/90000 (68%)]	Loss: -5.6447	Cost: 6.05s
Train Epoch: 615 [81920/90000 (91%)]	Loss: -5.8257	Cost: 10.29s
Train Epoch: 615 	Average Loss: -5.1230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5598

Saving model as e615_model.pt & e615_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998133592498537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: -1.3121	Cost: 33.19s
Train Epoch: 616 [20480/90000 (23%)]	Loss: -5.3881	Cost: 7.62s
Train Epoch: 616 [40960/90000 (45%)]	Loss: -5.7168	Cost: 11.06s
Train Epoch: 616 [61440/90000 (68%)]	Loss: -5.4773	Cost: 6.13s
Train Epoch: 616 [81920/90000 (91%)]	Loss: -5.5890	Cost: 9.90s
Train Epoch: 616 	Average Loss: -5.1742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2476

Learning rate: 0.00019998127518135577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: -1.0595	Cost: 23.91s
Train Epoch: 617 [20480/90000 (23%)]	Loss: -5.3081	Cost: 5.98s
Train Epoch: 617 [40960/90000 (45%)]	Loss: -5.5996	Cost: 8.01s
Train Epoch: 617 [61440/90000 (68%)]	Loss: -5.8122	Cost: 5.75s
Train Epoch: 617 [81920/90000 (91%)]	Loss: -5.4167	Cost: 6.72s
Train Epoch: 617 	Average Loss: -5.0828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9907

Learning rate: 0.0001999812143390486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: -0.8895	Cost: 28.72s
Train Epoch: 618 [20480/90000 (23%)]	Loss: -5.0555	Cost: 6.31s
Train Epoch: 618 [40960/90000 (45%)]	Loss: -5.4423	Cost: 11.34s
Train Epoch: 618 [61440/90000 (68%)]	Loss: -5.4162	Cost: 5.80s
Train Epoch: 618 [81920/90000 (91%)]	Loss: -5.6014	Cost: 7.80s
Train Epoch: 618 	Average Loss: -4.9271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4253

Learning rate: 0.00019998115339806398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: -1.5031	Cost: 24.19s
Train Epoch: 619 [20480/90000 (23%)]	Loss: -5.3846	Cost: 5.98s
Train Epoch: 619 [40960/90000 (45%)]	Loss: -5.4914	Cost: 7.06s
Train Epoch: 619 [61440/90000 (68%)]	Loss: -5.7285	Cost: 6.23s
Train Epoch: 619 [81920/90000 (91%)]	Loss: -5.7495	Cost: 5.80s
Train Epoch: 619 	Average Loss: -5.2526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4719

Learning rate: 0.00019998109235840191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: -1.5458	Cost: 28.90s
Train Epoch: 620 [20480/90000 (23%)]	Loss: -5.6494	Cost: 6.47s
Train Epoch: 620 [40960/90000 (45%)]	Loss: -5.5202	Cost: 8.24s
Train Epoch: 620 [61440/90000 (68%)]	Loss: -5.7634	Cost: 5.91s
Train Epoch: 620 [81920/90000 (91%)]	Loss: -5.7225	Cost: 7.96s
Train Epoch: 620 	Average Loss: -5.2535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5181

Learning rate: 0.00019998103122006243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: -1.5483	Cost: 30.24s
Train Epoch: 621 [20480/90000 (23%)]	Loss: -5.5891	Cost: 6.44s
Train Epoch: 621 [40960/90000 (45%)]	Loss: -5.7894	Cost: 13.51s
Train Epoch: 621 [61440/90000 (68%)]	Loss: -5.8406	Cost: 6.45s
Train Epoch: 621 [81920/90000 (91%)]	Loss: -5.8265	Cost: 10.28s
Train Epoch: 621 	Average Loss: -5.3204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6759

Saving model as e621_model.pt & e621_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998096998304565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: -1.5923	Cost: 25.15s
Train Epoch: 622 [20480/90000 (23%)]	Loss: -5.6395	Cost: 6.06s
Train Epoch: 622 [40960/90000 (45%)]	Loss: -6.0046	Cost: 8.95s
Train Epoch: 622 [61440/90000 (68%)]	Loss: -6.0508	Cost: 5.91s
Train Epoch: 622 [81920/90000 (91%)]	Loss: -5.9859	Cost: 6.91s
Train Epoch: 622 	Average Loss: -5.4688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7930

Saving model as e622_model.pt & e622_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999809086473516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: -1.6221	Cost: 26.57s
Train Epoch: 623 [20480/90000 (23%)]	Loss: -5.7153	Cost: 6.30s
Train Epoch: 623 [40960/90000 (45%)]	Loss: -5.6058	Cost: 11.42s
Train Epoch: 623 [61440/90000 (68%)]	Loss: -5.8559	Cost: 5.85s
Train Epoch: 623 [81920/90000 (91%)]	Loss: -6.0856	Cost: 7.98s
Train Epoch: 623 	Average Loss: -5.4172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6444

Learning rate: 0.00019998084721298032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: -1.5742	Cost: 24.26s
Train Epoch: 624 [20480/90000 (23%)]	Loss: -5.9479	Cost: 6.07s
Train Epoch: 624 [40960/90000 (45%)]	Loss: -5.9357	Cost: 8.44s
Train Epoch: 624 [61440/90000 (68%)]	Loss: -6.0385	Cost: 5.80s
Train Epoch: 624 [81920/90000 (91%)]	Loss: -6.1759	Cost: 5.94s
Train Epoch: 624 	Average Loss: -5.4855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7383

Learning rate: 0.00019998078567993191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: -1.0857	Cost: 24.86s
Train Epoch: 625 [20480/90000 (23%)]	Loss: -5.7924	Cost: 6.08s
Train Epoch: 625 [40960/90000 (45%)]	Loss: -5.9714	Cost: 8.26s
Train Epoch: 625 [61440/90000 (68%)]	Loss: -5.9503	Cost: 6.21s
Train Epoch: 625 [81920/90000 (91%)]	Loss: -5.8537	Cost: 9.73s
Train Epoch: 625 	Average Loss: -5.4841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4850

Learning rate: 0.00019998072404820645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: -1.4695	Cost: 44.56s
Train Epoch: 626 [20480/90000 (23%)]	Loss: -5.7210	Cost: 6.05s
Train Epoch: 626 [40960/90000 (45%)]	Loss: -5.8582	Cost: 10.87s
Train Epoch: 626 [61440/90000 (68%)]	Loss: -5.9755	Cost: 5.99s
Train Epoch: 626 [81920/90000 (91%)]	Loss: -6.0487	Cost: 9.10s
Train Epoch: 626 	Average Loss: -5.4492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4881

Learning rate: 0.00019998066231780395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: -1.9170	Cost: 23.95s
Train Epoch: 627 [20480/90000 (23%)]	Loss: -5.5570	Cost: 6.32s
Train Epoch: 627 [40960/90000 (45%)]	Loss: -5.8413	Cost: 10.97s
Train Epoch: 627 [61440/90000 (68%)]	Loss: -5.9086	Cost: 6.56s
Train Epoch: 627 [81920/90000 (91%)]	Loss: -5.8728	Cost: 11.93s
Train Epoch: 627 	Average Loss: -5.4001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6971

Learning rate: 0.0001999806004887245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: -1.7085	Cost: 24.60s
Train Epoch: 628 [20480/90000 (23%)]	Loss: -5.8005	Cost: 6.16s
Train Epoch: 628 [40960/90000 (45%)]	Loss: -6.0036	Cost: 7.56s
Train Epoch: 628 [61440/90000 (68%)]	Loss: -6.1048	Cost: 5.90s
Train Epoch: 628 [81920/90000 (91%)]	Loss: -6.2135	Cost: 5.99s
Train Epoch: 628 	Average Loss: -5.5932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8450

Saving model as e628_model.pt & e628_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998053856096817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: -1.5879	Cost: 31.70s
Train Epoch: 629 [20480/90000 (23%)]	Loss: -5.7023	Cost: 6.40s
Train Epoch: 629 [40960/90000 (45%)]	Loss: -6.1168	Cost: 10.49s
Train Epoch: 629 [61440/90000 (68%)]	Loss: -6.2273	Cost: 5.76s
Train Epoch: 629 [81920/90000 (91%)]	Loss: -5.7536	Cost: 6.28s
Train Epoch: 629 	Average Loss: -5.4688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5505

Learning rate: 0.00019998047653453497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: -1.5439	Cost: 24.73s
Train Epoch: 630 [20480/90000 (23%)]	Loss: -5.6435	Cost: 6.14s
Train Epoch: 630 [40960/90000 (45%)]	Loss: -6.0225	Cost: 6.82s
Train Epoch: 630 [61440/90000 (68%)]	Loss: -6.0437	Cost: 5.90s
Train Epoch: 630 [81920/90000 (91%)]	Loss: -6.1232	Cost: 6.16s
Train Epoch: 630 	Average Loss: -5.5201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9019

Saving model as e630_model.pt & e630_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199980414409425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: -1.3418	Cost: 29.06s
Train Epoch: 631 [20480/90000 (23%)]	Loss: -5.9653	Cost: 6.39s
Train Epoch: 631 [40960/90000 (45%)]	Loss: -5.8580	Cost: 8.87s
Train Epoch: 631 [61440/90000 (68%)]	Loss: -5.8519	Cost: 5.94s
Train Epoch: 631 [81920/90000 (91%)]	Loss: -5.9515	Cost: 5.98s
Train Epoch: 631 	Average Loss: -5.4225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5967

Learning rate: 0.0001999803521856383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: -1.4470	Cost: 23.93s
Train Epoch: 632 [20480/90000 (23%)]	Loss: -5.8666	Cost: 6.02s
Train Epoch: 632 [40960/90000 (45%)]	Loss: -6.0557	Cost: 7.36s
Train Epoch: 632 [61440/90000 (68%)]	Loss: -6.1441	Cost: 5.87s
Train Epoch: 632 [81920/90000 (91%)]	Loss: -6.1633	Cost: 6.05s
Train Epoch: 632 	Average Loss: -5.6470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9038

Saving model as e632_model.pt & e632_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998028986317499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: -1.6912	Cost: 28.31s
Train Epoch: 633 [20480/90000 (23%)]	Loss: -5.9089	Cost: 6.12s
Train Epoch: 633 [40960/90000 (45%)]	Loss: -6.4166	Cost: 9.11s
Train Epoch: 633 [61440/90000 (68%)]	Loss: -6.2968	Cost: 5.82s
Train Epoch: 633 [81920/90000 (91%)]	Loss: -5.9082	Cost: 6.23s
Train Epoch: 633 	Average Loss: -5.7050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7810

Learning rate: 0.00019998022744203506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: -1.8866	Cost: 23.45s
Train Epoch: 634 [20480/90000 (23%)]	Loss: -5.9001	Cost: 5.99s
Train Epoch: 634 [40960/90000 (45%)]	Loss: -6.2758	Cost: 7.11s
Train Epoch: 634 [61440/90000 (68%)]	Loss: -6.3401	Cost: 6.04s
Train Epoch: 634 [81920/90000 (91%)]	Loss: -6.1366	Cost: 6.55s
Train Epoch: 634 	Average Loss: -5.6991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8052

Learning rate: 0.0001999801649222186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: -1.7960	Cost: 34.73s
Train Epoch: 635 [20480/90000 (23%)]	Loss: -5.8529	Cost: 6.18s
Train Epoch: 635 [40960/90000 (45%)]	Loss: -6.2228	Cost: 9.81s
Train Epoch: 635 [61440/90000 (68%)]	Loss: -6.0902	Cost: 5.88s
Train Epoch: 635 [81920/90000 (91%)]	Loss: -5.8456	Cost: 5.77s
Train Epoch: 635 	Average Loss: -5.5385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1996

Learning rate: 0.00019998010230372565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: -1.3367	Cost: 24.72s
Train Epoch: 636 [20480/90000 (23%)]	Loss: -5.5808	Cost: 6.03s
Train Epoch: 636 [40960/90000 (45%)]	Loss: -5.7766	Cost: 8.38s
Train Epoch: 636 [61440/90000 (68%)]	Loss: -6.0180	Cost: 6.07s
Train Epoch: 636 [81920/90000 (91%)]	Loss: -6.0601	Cost: 6.09s
Train Epoch: 636 	Average Loss: -5.3625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3364

Learning rate: 0.00019998003958655633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: -1.0171	Cost: 27.78s
Train Epoch: 637 [20480/90000 (23%)]	Loss: -5.5328	Cost: 6.24s
Train Epoch: 637 [40960/90000 (45%)]	Loss: -5.7502	Cost: 9.63s
Train Epoch: 637 [61440/90000 (68%)]	Loss: -5.8611	Cost: 5.92s
Train Epoch: 637 [81920/90000 (91%)]	Loss: -6.0479	Cost: 5.78s
Train Epoch: 637 	Average Loss: -5.4032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8701

Learning rate: 0.00019997997677071068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: -1.6828	Cost: 24.27s
Train Epoch: 638 [20480/90000 (23%)]	Loss: -6.0296	Cost: 5.99s
Train Epoch: 638 [40960/90000 (45%)]	Loss: -6.1974	Cost: 7.98s
Train Epoch: 638 [61440/90000 (68%)]	Loss: -6.3977	Cost: 5.75s
Train Epoch: 638 [81920/90000 (91%)]	Loss: -6.3500	Cost: 5.94s
Train Epoch: 638 	Average Loss: -5.8135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1394

Saving model as e638_model.pt & e638_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019997991385618872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: -1.4831	Cost: 27.23s
Train Epoch: 639 [20480/90000 (23%)]	Loss: -6.0447	Cost: 6.07s
Train Epoch: 639 [40960/90000 (45%)]	Loss: -6.2468	Cost: 7.86s
Train Epoch: 639 [61440/90000 (68%)]	Loss: -6.3457	Cost: 5.92s
Train Epoch: 639 [81920/90000 (91%)]	Loss: -6.3039	Cost: 8.35s
Train Epoch: 639 	Average Loss: -5.7862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9136

Learning rate: 0.00019997985084299058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: -1.8826	Cost: 22.96s
Train Epoch: 640 [20480/90000 (23%)]	Loss: -6.4044	Cost: 5.99s
Train Epoch: 640 [40960/90000 (45%)]	Loss: -6.4710	Cost: 7.92s
Train Epoch: 640 [61440/90000 (68%)]	Loss: -6.0617	Cost: 5.73s
Train Epoch: 640 [81920/90000 (91%)]	Loss: -6.1566	Cost: 6.80s
Train Epoch: 640 	Average Loss: -5.7428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8521

Learning rate: 0.00019997978773111623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: -2.1935	Cost: 29.24s
Train Epoch: 641 [20480/90000 (23%)]	Loss: -5.7465	Cost: 6.14s
Train Epoch: 641 [40960/90000 (45%)]	Loss: -5.8744	Cost: 8.35s
Train Epoch: 641 [61440/90000 (68%)]	Loss: -6.0877	Cost: 6.20s
Train Epoch: 641 [81920/90000 (91%)]	Loss: -6.2705	Cost: 6.12s
Train Epoch: 641 	Average Loss: -5.6069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8622

Learning rate: 0.00019997972452056583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: -1.8639	Cost: 24.18s
Train Epoch: 642 [20480/90000 (23%)]	Loss: -6.0611	Cost: 6.02s
Train Epoch: 642 [40960/90000 (45%)]	Loss: -6.4248	Cost: 7.91s
Train Epoch: 642 [61440/90000 (68%)]	Loss: -6.1282	Cost: 6.11s
Train Epoch: 642 [81920/90000 (91%)]	Loss: -5.7539	Cost: 6.06s
Train Epoch: 642 	Average Loss: -5.6716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6583

Learning rate: 0.00019997966121133937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: -1.6596	Cost: 27.14s
Train Epoch: 643 [20480/90000 (23%)]	Loss: -5.8851	Cost: 6.23s
Train Epoch: 643 [40960/90000 (45%)]	Loss: -6.4331	Cost: 8.33s
Train Epoch: 643 [61440/90000 (68%)]	Loss: -6.2322	Cost: 5.90s
Train Epoch: 643 [81920/90000 (91%)]	Loss: -6.3443	Cost: 6.31s
Train Epoch: 643 	Average Loss: -5.8027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0462

Learning rate: 0.00019997959780343694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: -2.0303	Cost: 24.33s
Train Epoch: 644 [20480/90000 (23%)]	Loss: -6.1460	Cost: 5.98s
Train Epoch: 644 [40960/90000 (45%)]	Loss: -6.5170	Cost: 7.56s
Train Epoch: 644 [61440/90000 (68%)]	Loss: -6.4396	Cost: 5.72s
Train Epoch: 644 [81920/90000 (91%)]	Loss: -6.4974	Cost: 6.33s
Train Epoch: 644 	Average Loss: -5.9793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1258

Learning rate: 0.0001999795342968586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: -1.7954	Cost: 28.90s
Train Epoch: 645 [20480/90000 (23%)]	Loss: -6.2612	Cost: 6.22s
Train Epoch: 645 [40960/90000 (45%)]	Loss: -6.3793	Cost: 8.57s
Train Epoch: 645 [61440/90000 (68%)]	Loss: -6.3008	Cost: 6.01s
Train Epoch: 645 [81920/90000 (91%)]	Loss: -6.5835	Cost: 10.26s
Train Epoch: 645 	Average Loss: -5.8897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0002

Learning rate: 0.00019997947069160443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: -1.9265	Cost: 23.42s
Train Epoch: 646 [20480/90000 (23%)]	Loss: -6.3885	Cost: 5.95s
Train Epoch: 646 [40960/90000 (45%)]	Loss: -6.6591	Cost: 7.54s
Train Epoch: 646 [61440/90000 (68%)]	Loss: -6.5910	Cost: 7.73s
Train Epoch: 646 [81920/90000 (91%)]	Loss: -6.7227	Cost: 12.47s
Train Epoch: 646 	Average Loss: -6.0681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1280

Learning rate: 0.00019997940698767447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: -2.4650	Cost: 26.90s
Train Epoch: 647 [20480/90000 (23%)]	Loss: -6.2644	Cost: 6.24s
Train Epoch: 647 [40960/90000 (45%)]	Loss: -6.5164	Cost: 8.93s
Train Epoch: 647 [61440/90000 (68%)]	Loss: -6.0795	Cost: 5.74s
Train Epoch: 647 [81920/90000 (91%)]	Loss: -6.3254	Cost: 6.44s
Train Epoch: 647 	Average Loss: -5.8934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9076

Learning rate: 0.0001999793431850688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: -1.7029	Cost: 24.20s
Train Epoch: 648 [20480/90000 (23%)]	Loss: -6.2105	Cost: 6.07s
Train Epoch: 648 [40960/90000 (45%)]	Loss: -6.1919	Cost: 7.15s
Train Epoch: 648 [61440/90000 (68%)]	Loss: -6.2033	Cost: 5.82s
Train Epoch: 648 [81920/90000 (91%)]	Loss: -6.1946	Cost: 5.92s
Train Epoch: 648 	Average Loss: -5.7485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6144

Learning rate: 0.00019997927928378745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: -1.4898	Cost: 27.70s
Train Epoch: 649 [20480/90000 (23%)]	Loss: -5.7577	Cost: 6.47s
Train Epoch: 649 [40960/90000 (45%)]	Loss: -6.1059	Cost: 11.28s
Train Epoch: 649 [61440/90000 (68%)]	Loss: -6.1547	Cost: 6.25s
Train Epoch: 649 [81920/90000 (91%)]	Loss: -6.3162	Cost: 8.17s
Train Epoch: 649 	Average Loss: -5.6073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9020

Learning rate: 0.0001999792152838305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: -1.8499	Cost: 29.54s
Train Epoch: 650 [20480/90000 (23%)]	Loss: -6.1493	Cost: 6.23s
Train Epoch: 650 [40960/90000 (45%)]	Loss: -6.3081	Cost: 10.38s
Train Epoch: 650 [61440/90000 (68%)]	Loss: -6.5484	Cost: 5.79s
Train Epoch: 650 [81920/90000 (91%)]	Loss: -6.6476	Cost: 7.46s
Train Epoch: 650 	Average Loss: -5.9410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0899

Learning rate: 0.00019997915118519805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: -2.1178	Cost: 29.67s
Train Epoch: 651 [20480/90000 (23%)]	Loss: -6.1927	Cost: 6.42s
Train Epoch: 651 [40960/90000 (45%)]	Loss: -6.5784	Cost: 11.02s
Train Epoch: 651 [61440/90000 (68%)]	Loss: -6.3988	Cost: 5.76s
Train Epoch: 651 [81920/90000 (91%)]	Loss: -6.7105	Cost: 6.07s
Train Epoch: 651 	Average Loss: -6.0150
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1535

Saving model as e651_model.pt & e651_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999790869878901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: -1.9584	Cost: 22.63s
Train Epoch: 652 [20480/90000 (23%)]	Loss: -6.4217	Cost: 6.00s
Train Epoch: 652 [40960/90000 (45%)]	Loss: -5.9223	Cost: 6.86s
Train Epoch: 652 [61440/90000 (68%)]	Loss: -6.2002	Cost: 6.94s
Train Epoch: 652 [81920/90000 (91%)]	Loss: -6.5003	Cost: 11.88s
Train Epoch: 652 	Average Loss: -5.8810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0427

Learning rate: 0.00019997902269190676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: -2.1156	Cost: 27.30s
Train Epoch: 653 [20480/90000 (23%)]	Loss: -6.4175	Cost: 6.25s
Train Epoch: 653 [40960/90000 (45%)]	Loss: -6.4896	Cost: 7.89s
Train Epoch: 653 [61440/90000 (68%)]	Loss: -6.6778	Cost: 6.11s
Train Epoch: 653 [81920/90000 (91%)]	Loss: -6.8269	Cost: 6.30s
Train Epoch: 653 	Average Loss: -6.1329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2945

Saving model as e653_model.pt & e653_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999789582972481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: -1.7974	Cost: 22.33s
Train Epoch: 654 [20480/90000 (23%)]	Loss: -6.4767	Cost: 6.17s
Train Epoch: 654 [40960/90000 (45%)]	Loss: -6.7786	Cost: 8.23s
Train Epoch: 654 [61440/90000 (68%)]	Loss: -6.6663	Cost: 6.24s
Train Epoch: 654 [81920/90000 (91%)]	Loss: -6.6950	Cost: 10.90s
Train Epoch: 654 	Average Loss: -6.2394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3087

Saving model as e654_model.pt & e654_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019997889380391414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: -2.3821	Cost: 23.15s
Train Epoch: 655 [20480/90000 (23%)]	Loss: -6.5430	Cost: 6.08s
Train Epoch: 655 [40960/90000 (45%)]	Loss: -6.8379	Cost: 8.70s
Train Epoch: 655 [61440/90000 (68%)]	Loss: -6.8261	Cost: 6.04s
Train Epoch: 655 [81920/90000 (91%)]	Loss: -6.7861	Cost: 6.77s
Train Epoch: 655 	Average Loss: -6.2764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4034

Saving model as e655_model.pt & e655_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019997882921190502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: -2.2179	Cost: 31.81s
Train Epoch: 656 [20480/90000 (23%)]	Loss: -6.5363	Cost: 8.10s
Train Epoch: 656 [40960/90000 (45%)]	Loss: -6.8275	Cost: 14.79s
Train Epoch: 656 [61440/90000 (68%)]	Loss: -6.9228	Cost: 6.50s
Train Epoch: 656 [81920/90000 (91%)]	Loss: -6.8064	Cost: 12.46s
Train Epoch: 656 	Average Loss: -6.2898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3698

Learning rate: 0.00019997876452122068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: -2.1256	Cost: 24.68s
Train Epoch: 657 [20480/90000 (23%)]	Loss: -6.3360	Cost: 6.03s
Train Epoch: 657 [40960/90000 (45%)]	Loss: -6.7114	Cost: 8.35s
Train Epoch: 657 [61440/90000 (68%)]	Loss: -6.6694	Cost: 6.02s
Train Epoch: 657 [81920/90000 (91%)]	Loss: -6.8504	Cost: 6.40s
Train Epoch: 657 	Average Loss: -6.2400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
