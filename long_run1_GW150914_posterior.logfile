Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=100000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.0, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_posterior_prior/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=0, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
Loading load_all_bilby_samples...
Loading load_all_event_strain...
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 100000 epochs
Starting timer
Learning rate: 0.0002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.3362	Cost: 21.79s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.8246	Cost: 6.65s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 20.9664	Cost: 6.26s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 20.6036	Cost: 5.82s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.1899	Cost: 5.72s
Train Epoch: 1 	Average Loss: 21.3124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1354

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999995065198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 19.9881	Cost: 22.97s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 19.8822	Cost: 5.99s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.5762	Cost: 6.86s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 19.0465	Cost: 5.82s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 18.6288	Cost: 5.64s
Train Epoch: 2 	Average Loss: 19.3368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6354

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999998026079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 18.6640	Cost: 50.91s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 18.4627	Cost: 7.47s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.2538	Cost: 14.44s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 17.6202	Cost: 6.81s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 17.5113	Cost: 12.97s
Train Epoch: 3 	Average Loss: 17.9492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6037

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999995558678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 17.3750	Cost: 41.97s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 17.3651	Cost: 8.30s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 17.0372	Cost: 17.25s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 16.8059	Cost: 7.39s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 16.6351	Cost: 15.90s
Train Epoch: 4 	Average Loss: 16.9617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7892

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999921043165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 16.6076	Cost: 36.14s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 16.7442	Cost: 6.81s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 16.4672	Cost: 13.10s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 16.1684	Cost: 6.57s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 16.0715	Cost: 11.99s
Train Epoch: 5 	Average Loss: 16.3326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2011

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999876629945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 16.1185	Cost: 35.32s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 16.0802	Cost: 6.77s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 15.8492	Cost: 11.93s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 15.9234	Cost: 8.34s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 15.6606	Cost: 14.98s
Train Epoch: 6 	Average Loss: 15.8095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8557

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999822347122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 15.6398	Cost: 26.44s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 15.5609	Cost: 6.28s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 15.6911	Cost: 8.17s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 15.3342	Cost: 5.87s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 15.2009	Cost: 6.58s
Train Epoch: 7 	Average Loss: 15.4084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3052

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999758194695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 15.0766	Cost: 30.95s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 15.3076	Cost: 6.44s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 15.2015	Cost: 12.23s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 15.0639	Cost: 6.22s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 14.8665	Cost: 11.94s
Train Epoch: 8 	Average Loss: 15.0473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8519

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999684172664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 14.9189	Cost: 22.26s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 14.8190	Cost: 6.19s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 14.7363	Cost: 8.48s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 14.6699	Cost: 5.72s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 14.6727	Cost: 6.20s
Train Epoch: 9 	Average Loss: 14.7393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7490

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999600281025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 14.5631	Cost: 22.45s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 14.5942	Cost: 6.06s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 14.4472	Cost: 8.54s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 14.3649	Cost: 6.36s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 14.1778	Cost: 11.74s
Train Epoch: 10 	Average Loss: 14.3910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4016

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999506519785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 14.4126	Cost: 24.71s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 14.3929	Cost: 6.01s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 14.0830	Cost: 7.76s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 13.9917	Cost: 5.95s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 14.0603	Cost: 7.30s
Train Epoch: 11 	Average Loss: 14.1144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1122

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999402888941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 14.0689	Cost: 23.15s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 14.0620	Cost: 6.01s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 13.8420	Cost: 7.99s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 13.8403	Cost: 6.48s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 13.9160	Cost: 10.25s
Train Epoch: 12 	Average Loss: 13.8537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7943

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999289388494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 13.6078	Cost: 25.80s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 13.8404	Cost: 5.96s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 13.6884	Cost: 6.62s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 13.7250	Cost: 5.92s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 13.5664	Cost: 7.15s
Train Epoch: 13 	Average Loss: 13.5615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4344

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999916601844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 13.5610	Cost: 22.72s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 13.5547	Cost: 6.02s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 13.4606	Cost: 6.72s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 13.4742	Cost: 6.13s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 13.5063	Cost: 6.37s
Train Epoch: 14 	Average Loss: 13.3810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3616

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999032778784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 13.3992	Cost: 27.10s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 13.4927	Cost: 6.34s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 13.2676	Cost: 8.57s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 13.0883	Cost: 5.66s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 13.0603	Cost: 5.96s
Train Epoch: 15 	Average Loss: 13.2121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2427

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998889669524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 13.1845	Cost: 26.32s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 13.3276	Cost: 6.09s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 13.1691	Cost: 8.06s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 12.8697	Cost: 5.86s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 12.8193	Cost: 7.60s
Train Epoch: 16 	Average Loss: 12.9935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1048

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999873669066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 12.9040	Cost: 24.99s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 13.0600	Cost: 6.27s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 12.9693	Cost: 10.45s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 12.6170	Cost: 5.85s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 12.7626	Cost: 6.56s
Train Epoch: 17 	Average Loss: 12.8214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8480

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998573842195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 12.6806	Cost: 25.32s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 12.8896	Cost: 6.13s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 12.6407	Cost: 6.88s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 12.5617	Cost: 6.00s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 12.5260	Cost: 6.74s
Train Epoch: 18 	Average Loss: 12.6198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5675

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998401124124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 12.5389	Cost: 22.16s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 12.7621	Cost: 6.00s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 12.6379	Cost: 6.90s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 12.5418	Cost: 6.40s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 12.3884	Cost: 9.84s
Train Epoch: 19 	Average Loss: 12.4895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5928

Learning rate: 0.00019999998218536453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 12.5077	Cost: 28.06s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 12.7054	Cost: 6.27s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 12.4035	Cost: 9.68s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 12.1845	Cost: 5.81s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 12.2821	Cost: 5.61s
Train Epoch: 20 	Average Loss: 12.3437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4077

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998026079178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 12.3982	Cost: 23.26s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 12.3962	Cost: 6.01s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 12.2213	Cost: 6.92s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 12.1597	Cost: 5.80s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 12.2319	Cost: 5.81s
Train Epoch: 21 	Average Loss: 12.2267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3247

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999978237523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 12.1275	Cost: 22.99s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 12.3838	Cost: 6.22s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 12.2597	Cost: 10.76s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 11.9049	Cost: 6.15s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 12.1325	Cost: 10.60s
Train Epoch: 22 	Average Loss: 12.0897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3825

Learning rate: 0.00019999997611555822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 12.2336	Cost: 23.32s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 12.1366	Cost: 6.01s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 11.9531	Cost: 7.21s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 12.0991	Cost: 6.01s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 11.8641	Cost: 6.81s
Train Epoch: 23 	Average Loss: 11.9470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0164

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999997389489742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 11.8755	Cost: 22.58s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 12.0586	Cost: 6.89s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 11.6920	Cost: 11.25s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 11.6851	Cost: 6.25s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 11.7319	Cost: 11.16s
Train Epoch: 24 	Average Loss: 11.8055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7853

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999997157554058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 11.7151	Cost: 23.36s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 11.8575	Cost: 6.12s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 11.7760	Cost: 7.46s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 11.5660	Cost: 5.81s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 11.8781	Cost: 6.37s
Train Epoch: 25 	Average Loss: 11.6783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6791

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996915748774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 11.5584	Cost: 32.68s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 11.6795	Cost: 6.58s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 11.7710	Cost: 14.16s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 11.5217	Cost: 6.26s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 11.5408	Cost: 11.29s
Train Epoch: 26 	Average Loss: 11.5823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5832

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996664073888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 11.4382	Cost: 23.51s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 11.7986	Cost: 6.02s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 11.3748	Cost: 7.45s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 11.4683	Cost: 5.98s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 11.4772	Cost: 6.84s
Train Epoch: 27 	Average Loss: 11.4854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6306

Learning rate: 0.00019999996402529402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 11.6462	Cost: 22.28s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 11.5092	Cost: 6.08s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 11.5677	Cost: 7.82s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 11.3013	Cost: 6.44s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 11.3229	Cost: 11.32s
Train Epoch: 28 	Average Loss: 11.4065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4821

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996131115315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 11.4182	Cost: 30.08s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 11.2794	Cost: 6.73s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 11.3392	Cost: 10.62s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 11.1280	Cost: 6.10s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 11.1915	Cost: 11.27s
Train Epoch: 29 	Average Loss: 11.2516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4635

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999995849831625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 11.3173	Cost: 22.38s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 11.3623	Cost: 6.03s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 11.2124	Cost: 6.65s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 11.2528	Cost: 6.15s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 11.1240	Cost: 7.96s
Train Epoch: 30 	Average Loss: 11.2074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2395

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999995558678336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 11.0901	Cost: 27.38s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 11.3463	Cost: 6.18s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 11.3598	Cost: 9.30s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 11.0987	Cost: 5.90s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 11.1216	Cost: 6.36s
Train Epoch: 31 	Average Loss: 11.1474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1612

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999525765545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 11.1893	Cost: 23.18s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 11.0821	Cost: 6.03s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 10.9710	Cost: 7.06s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 10.9290	Cost: 5.78s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 10.9042	Cost: 6.14s
Train Epoch: 32 	Average Loss: 11.0373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0239

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999494676296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 11.0805	Cost: 25.13s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 11.0900	Cost: 6.27s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 10.9550	Cost: 10.30s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 10.9319	Cost: 6.01s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 10.8216	Cost: 8.63s
Train Epoch: 33 	Average Loss: 10.9360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9396

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999994626000874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 10.9257	Cost: 23.38s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 10.9818	Cost: 6.01s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 11.1288	Cost: 6.64s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 10.7033	Cost: 6.01s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 10.8907	Cost: 5.85s
Train Epoch: 34 	Average Loss: 10.8994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9294

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999994295369188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 10.6785	Cost: 27.55s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 10.9000	Cost: 6.34s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 10.7929	Cost: 8.98s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 10.7026	Cost: 5.81s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 10.8666	Cost: 6.01s
Train Epoch: 35 	Average Loss: 10.7750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8768

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999939548679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 10.7753	Cost: 24.50s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 10.9776	Cost: 6.17s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 10.6631	Cost: 7.88s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 10.7420	Cost: 6.07s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 10.6043	Cost: 5.77s
Train Epoch: 36 	Average Loss: 10.7237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0057

Learning rate: 0.00019999993604497015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 10.8247	Cost: 30.49s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 10.8572	Cost: 6.46s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 10.7041	Cost: 10.45s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 10.7204	Cost: 5.85s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 10.4586	Cost: 5.67s
Train Epoch: 37 	Average Loss: 10.6461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6980

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999993244256535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 10.6294	Cost: 22.54s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 10.8250	Cost: 6.01s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 10.7672	Cost: 6.53s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 10.5142	Cost: 6.04s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 10.5062	Cost: 7.56s
Train Epoch: 38 	Average Loss: 10.5692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7163

Learning rate: 0.00019999992874146456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 10.7761	Cost: 25.61s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 10.7352	Cost: 6.46s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 10.4798	Cost: 10.47s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 10.4074	Cost: 5.86s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 10.4440	Cost: 7.03s
Train Epoch: 39 	Average Loss: 10.4837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5539

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999249416678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 10.4470	Cost: 22.54s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 10.5513	Cost: 6.15s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 10.5381	Cost: 8.08s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 10.3928	Cost: 5.80s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 10.4235	Cost: 6.09s
Train Epoch: 40 	Average Loss: 10.4586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5221

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999992104317507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 10.4569	Cost: 24.18s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 10.5907	Cost: 6.26s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 10.4144	Cost: 10.61s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 10.3420	Cost: 6.12s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 10.3156	Cost: 9.20s
Train Epoch: 41 	Average Loss: 10.4060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5112

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999991704598637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 10.4123	Cost: 26.18s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 10.4962	Cost: 6.27s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 10.5021	Cost: 7.39s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 10.1495	Cost: 5.93s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 10.1673	Cost: 6.62s
Train Epoch: 42 	Average Loss: 10.3291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3751

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999991295010171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 10.3905	Cost: 29.94s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 10.6213	Cost: 6.57s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 10.1819	Cost: 10.63s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 10.2817	Cost: 5.81s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 10.1517	Cost: 5.68s
Train Epoch: 43 	Average Loss: 10.3035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4043

Learning rate: 0.00019999990875552108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 10.3860	Cost: 23.87s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 10.2506	Cost: 6.06s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 10.3247	Cost: 7.33s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 10.1374	Cost: 6.17s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 10.2491	Cost: 6.07s
Train Epoch: 44 	Average Loss: 10.2217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3893

Learning rate: 0.00019999990446224451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 10.4008	Cost: 22.35s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 10.2341	Cost: 6.44s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 10.1986	Cost: 10.31s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 10.1770	Cost: 6.28s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 10.0590	Cost: 10.99s
Train Epoch: 45 	Average Loss: 10.2011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1861

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999900070272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 10.0146	Cost: 22.96s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 10.2013	Cost: 5.99s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 10.0743	Cost: 8.52s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 10.0344	Cost: 5.73s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 10.1818	Cost: 6.42s
Train Epoch: 46 	Average Loss: 10.1192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3325

Learning rate: 0.00019999989557960353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 10.0944	Cost: 25.28s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 10.2768	Cost: 6.10s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 10.0746	Cost: 8.36s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 9.8685	Cost: 6.24s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 10.0785	Cost: 12.57s
Train Epoch: 47 	Average Loss: 10.0686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0702

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998909902391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 10.2031	Cost: 23.75s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 10.1219	Cost: 6.04s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 10.0365	Cost: 7.85s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 9.9506	Cost: 5.96s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 10.0690	Cost: 7.59s
Train Epoch: 48 	Average Loss: 10.0288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1385

Learning rate: 0.00019999988630217875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 10.1454	Cost: 22.95s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 10.3598	Cost: 6.06s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 9.9970	Cost: 7.60s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 9.9357	Cost: 5.73s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 10.0145	Cost: 5.76s
Train Epoch: 49 	Average Loss: 10.0182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0915

Learning rate: 0.00019999988151542247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 9.9323	Cost: 25.33s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 10.2739	Cost: 6.33s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 10.1650	Cost: 10.79s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 9.9318	Cost: 5.93s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 9.8850	Cost: 7.64s
Train Epoch: 50 	Average Loss: 9.9862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9827

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999987662997027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 9.8998	Cost: 22.16s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 9.9720	Cost: 6.12s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 9.9627	Cost: 7.22s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 9.7838	Cost: 5.96s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 9.8047	Cost: 5.85s
Train Epoch: 51 	Average Loss: 9.8850
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9203

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999987164582216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 9.8963	Cost: 26.65s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 9.9294	Cost: 6.13s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 9.8919	Cost: 8.72s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 9.8334	Cost: 5.87s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 9.8543	Cost: 6.21s
Train Epoch: 52 	Average Loss: 9.8707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9585

Learning rate: 0.0001999998665629781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 9.6944	Cost: 23.09s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 9.9732	Cost: 6.01s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 9.8112	Cost: 7.03s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 9.7874	Cost: 5.95s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 9.8502	Cost: 8.14s
Train Epoch: 53 	Average Loss: 9.8305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9443

Learning rate: 0.00019999986138143815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 9.8073	Cost: 25.75s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 9.7779	Cost: 6.18s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 9.8386	Cost: 10.43s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 9.8540	Cost: 5.91s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 9.8366	Cost: 6.76s
Train Epoch: 54 	Average Loss: 9.8000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8983

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999985610120227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 9.9798	Cost: 23.20s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 9.9175	Cost: 6.04s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 9.8294	Cost: 7.50s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 9.6728	Cost: 5.71s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 9.6249	Cost: 6.79s
Train Epoch: 55 	Average Loss: 9.7609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8075

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998507222705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 9.7010	Cost: 24.44s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 9.8915	Cost: 5.99s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 9.7300	Cost: 7.18s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 9.7323	Cost: 6.00s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 9.6904	Cost: 6.59s
Train Epoch: 56 	Average Loss: 9.7360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8109

Learning rate: 0.00019999984524464283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 9.9244	Cost: 24.96s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 9.8597	Cost: 6.16s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 9.7682	Cost: 8.32s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 9.5675	Cost: 5.94s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 9.5519	Cost: 5.74s
Train Epoch: 57 	Average Loss: 9.7053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7719

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998396683193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 9.7018	Cost: 28.77s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 9.8362	Cost: 6.57s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 9.7029	Cost: 10.78s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 9.6549	Cost: 6.21s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 9.6069	Cost: 6.01s
Train Epoch: 58 	Average Loss: 9.6556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8107

Learning rate: 0.00019999983399329984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 9.7436	Cost: 23.39s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 9.7352	Cost: 6.03s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 9.7451	Cost: 7.52s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 9.4527	Cost: 6.01s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 9.3657	Cost: 5.80s
Train Epoch: 59 	Average Loss: 9.5924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5938

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999982821958452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 9.6051	Cost: 28.23s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 9.6722	Cost: 6.32s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 9.4923	Cost: 8.08s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 9.4158	Cost: 5.87s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 9.5038	Cost: 5.80s
Train Epoch: 60 	Average Loss: 9.5348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5719

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999982234717332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 9.5465	Cost: 22.94s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 9.6910	Cost: 6.80s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 9.6021	Cost: 13.74s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 9.5428	Cost: 7.99s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 9.4938	Cost: 10.41s
Train Epoch: 61 	Average Loss: 9.5415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6985

Learning rate: 0.00019999981637606627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 9.5623	Cost: 27.05s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 9.6603	Cost: 6.15s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 9.4800	Cost: 7.03s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 9.4364	Cost: 6.01s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 9.3721	Cost: 7.20s
Train Epoch: 62 	Average Loss: 9.4870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6386

Learning rate: 0.00019999981030626333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 9.5290	Cost: 23.05s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 9.6712	Cost: 6.54s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 9.5509	Cost: 11.31s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 9.3879	Cost: 7.41s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 9.2622	Cost: 13.43s
Train Epoch: 63 	Average Loss: 9.4641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5299

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999980413776456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 9.5130	Cost: 26.41s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 9.5625	Cost: 6.14s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 9.4984	Cost: 6.44s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 9.2813	Cost: 6.03s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 9.2855	Cost: 7.79s
Train Epoch: 64 	Average Loss: 9.4335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5169

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999979787056995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 9.5762	Cost: 22.17s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 9.4973	Cost: 5.99s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 9.5320	Cost: 6.78s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 9.4023	Cost: 6.22s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 9.4016	Cost: 10.40s
Train Epoch: 65 	Average Loss: 9.4212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5587

Learning rate: 0.00019999979150467947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 9.6666	Cost: 26.29s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 9.4966	Cost: 6.52s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 9.3247	Cost: 10.01s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 9.2177	Cost: 5.94s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 9.2918	Cost: 6.42s
Train Epoch: 66 	Average Loss: 9.3475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4455

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999978504009312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 9.5752	Cost: 24.64s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 9.4326	Cost: 6.44s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 9.3516	Cost: 10.73s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 9.1765	Cost: 6.12s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 9.3602	Cost: 8.88s
Train Epoch: 67 	Average Loss: 9.3411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5764

Learning rate: 0.00019999977847681098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 9.5760	Cost: 26.61s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 9.4020	Cost: 6.15s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 9.3585	Cost: 10.01s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 9.2326	Cost: 5.67s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 9.2723	Cost: 5.87s
Train Epoch: 68 	Average Loss: 9.3410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4013

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999977181483299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 9.3839	Cost: 23.30s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 9.4416	Cost: 5.98s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 9.2634	Cost: 6.39s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 9.2563	Cost: 5.88s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 9.1703	Cost: 5.86s
Train Epoch: 69 	Average Loss: 9.2503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3521

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997650541592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 9.2304	Cost: 26.42s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 9.3120	Cost: 6.01s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 9.1703	Cost: 6.37s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 9.0952	Cost: 5.96s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 9.2241	Cost: 7.24s
Train Epoch: 70 	Average Loss: 9.2531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5007

Learning rate: 0.0001999997581947896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 9.4690	Cost: 22.47s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 9.3048	Cost: 6.11s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 9.2279	Cost: 6.40s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 9.0531	Cost: 6.62s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 9.0168	Cost: 9.40s
Train Epoch: 71 	Average Loss: 9.2183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3196

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997512367242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 9.2894	Cost: 23.96s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 9.2845	Cost: 6.14s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 9.3100	Cost: 8.21s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 9.1730	Cost: 5.85s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 9.1181	Cost: 6.38s
Train Epoch: 72 	Average Loss: 9.2290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3681

Learning rate: 0.000199999744179963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 9.3794	Cost: 24.31s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 9.2351	Cost: 6.41s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 9.1081	Cost: 10.08s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 9.2162	Cost: 6.24s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 9.0699	Cost: 11.43s
Train Epoch: 73 	Average Loss: 9.1590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2472

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999737024506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 9.3076	Cost: 23.28s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 9.2282	Cost: 6.00s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 9.2757	Cost: 7.60s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 9.0062	Cost: 5.73s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 9.0178	Cost: 6.07s
Train Epoch: 74 	Average Loss: 9.1763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3281

Learning rate: 0.00019999972977035322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 9.2228	Cost: 30.39s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 9.1889	Cost: 6.45s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 9.2014	Cost: 10.15s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 9.0047	Cost: 6.12s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 9.0048	Cost: 5.81s
Train Epoch: 75 	Average Loss: 9.1414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2758

Learning rate: 0.00019999972241750466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 9.1468	Cost: 24.14s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 9.3058	Cost: 6.10s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 9.0670	Cost: 7.78s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 9.0321	Cost: 6.20s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 9.1572	Cost: 7.82s
Train Epoch: 76 	Average Loss: 9.1304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2578

Learning rate: 0.0001999997149659603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 9.2515	Cost: 26.61s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 9.1270	Cost: 6.24s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 9.1206	Cost: 10.00s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 9.0013	Cost: 5.85s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 9.1591	Cost: 6.20s
Train Epoch: 77 	Average Loss: 9.1000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1505

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997074157202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 9.1242	Cost: 23.43s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 9.2056	Cost: 6.05s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 9.0175	Cost: 8.71s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 8.9565	Cost: 6.15s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 9.0665	Cost: 6.02s
Train Epoch: 78 	Average Loss: 9.0603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1398

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999969976678433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 9.1266	Cost: 24.95s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 9.1438	Cost: 6.28s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 8.9957	Cost: 10.42s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 8.9160	Cost: 6.04s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 8.9451	Cost: 8.06s
Train Epoch: 79 	Average Loss: 9.0033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1123

Saving model as e79_model.pt & e79_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999969201915272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 9.1166	Cost: 23.47s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 9.0017	Cost: 6.25s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 8.9757	Cost: 7.10s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 9.0451	Cost: 6.23s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 8.8268	Cost: 10.28s
Train Epoch: 80 	Average Loss: 8.9682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1302

Learning rate: 0.00019999968417282538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 9.0383	Cost: 23.51s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 9.0211	Cost: 6.22s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 9.0064	Cost: 10.45s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 8.9153	Cost: 6.14s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 9.1174	Cost: 10.24s
Train Epoch: 81 	Average Loss: 8.9975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0790

Saving model as e81_model.pt & e81_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999996762278023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 9.1371	Cost: 24.12s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 9.0221	Cost: 5.97s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 8.8262	Cost: 7.32s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 8.8735	Cost: 5.74s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 8.8349	Cost: 5.95s
Train Epoch: 82 	Average Loss: 8.9443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0496

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999996681840835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 9.1499	Cost: 28.20s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 9.0378	Cost: 6.14s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 9.0826	Cost: 10.48s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 8.9194	Cost: 5.82s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 8.7895	Cost: 5.68s
Train Epoch: 83 	Average Loss: 8.9258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9859

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999966004166902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 8.9853	Cost: 22.57s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 9.0233	Cost: 6.02s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 8.9695	Cost: 7.58s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 8.7606	Cost: 6.25s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 8.7242	Cost: 9.92s
Train Epoch: 84 	Average Loss: 8.8948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0385

Learning rate: 0.0001999996518005588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 9.0706	Cost: 27.89s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 9.0341	Cost: 6.06s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 8.8933	Cost: 7.28s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 8.7725	Cost: 6.05s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 8.7632	Cost: 8.26s
Train Epoch: 85 	Average Loss: 8.8959
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0822

Learning rate: 0.00019999964346075288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 8.9123	Cost: 22.75s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 8.9664	Cost: 6.07s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 8.8572	Cost: 7.94s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 8.6729	Cost: 6.42s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 8.8657	Cost: 9.15s
Train Epoch: 86 	Average Loss: 8.8681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9435

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999963502225128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 9.0465	Cost: 25.85s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 8.8874	Cost: 5.98s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 8.7935	Cost: 6.57s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 8.7097	Cost: 5.98s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 8.7382	Cost: 8.33s
Train Epoch: 87 	Average Loss: 8.8524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1000

Learning rate: 0.00019999962648505396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 8.9884	Cost: 23.55s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 8.8946	Cost: 5.99s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 8.8399	Cost: 6.98s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 8.7756	Cost: 5.75s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 8.7394	Cost: 6.05s
Train Epoch: 88 	Average Loss: 8.7905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9068

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999617849161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 8.8564	Cost: 25.62s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 8.9348	Cost: 5.95s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 8.7406	Cost: 6.68s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 8.7812	Cost: 5.96s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 8.7427	Cost: 7.76s
Train Epoch: 89 	Average Loss: 8.8037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9494

Learning rate: 0.00019999960911457236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 8.8353	Cost: 26.09s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 8.9791	Cost: 6.01s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 8.8355	Cost: 6.89s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 8.5887	Cost: 6.10s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 8.8056	Cost: 9.83s
Train Epoch: 90 	Average Loss: 8.7680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9113

Learning rate: 0.00019999960028128805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 8.9166	Cost: 26.73s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 8.8760	Cost: 6.23s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 8.7976	Cost: 9.74s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 8.5730	Cost: 5.97s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 8.6746	Cost: 6.06s
Train Epoch: 91 	Average Loss: 8.7348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8600

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999959134930808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 8.7748	Cost: 22.30s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 8.7814	Cost: 6.18s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 8.7080	Cost: 8.57s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 8.6262	Cost: 6.39s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 8.6425	Cost: 11.41s
Train Epoch: 92 	Average Loss: 8.7341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9457

Learning rate: 0.0001999995823186325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 8.8794	Cost: 25.25s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 8.8069	Cost: 5.99s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 8.7409	Cost: 7.11s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 8.6828	Cost: 6.01s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 8.7430	Cost: 7.32s
Train Epoch: 93 	Average Loss: 8.7053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9394

Learning rate: 0.00019999957318926127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 8.8856	Cost: 22.66s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 8.7345	Cost: 6.32s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 8.6075	Cost: 8.72s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 8.6233	Cost: 6.33s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 8.5337	Cost: 11.37s
Train Epoch: 94 	Average Loss: 8.6700
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8495

Saving model as e94_model.pt & e94_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999956396119442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 8.7778	Cost: 27.27s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 8.8217	Cost: 6.04s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 8.7235	Cost: 8.39s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 8.6308	Cost: 6.05s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 8.7652	Cost: 7.39s
Train Epoch: 95 	Average Loss: 8.6765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8706

Learning rate: 0.00019999955463443194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 8.7536	Cost: 22.84s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 8.7430	Cost: 5.96s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 8.6802	Cost: 7.07s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 8.7327	Cost: 6.24s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 8.5864	Cost: 10.69s
Train Epoch: 96 	Average Loss: 8.6281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8376

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999954520897388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 8.7261	Cost: 24.42s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 8.6900	Cost: 5.99s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 8.7652	Cost: 7.69s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 8.4759	Cost: 5.95s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 8.4871	Cost: 6.50s
Train Epoch: 97 	Average Loss: 8.6287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7573

Saving model as e97_model.pt & e97_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999953568482025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 8.7663	Cost: 22.68s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 8.6814	Cost: 6.02s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 8.5064	Cost: 6.89s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 8.4586	Cost: 6.21s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 8.4525	Cost: 10.77s
Train Epoch: 98 	Average Loss: 8.5656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7158

Saving model as e98_model.pt & e98_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999526061971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 8.6477	Cost: 24.36s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 8.6986	Cost: 6.15s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 8.6394	Cost: 9.10s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 8.3831	Cost: 5.94s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 8.6920	Cost: 6.48s
Train Epoch: 99 	Average Loss: 8.5930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7288

Learning rate: 0.00019999951634042617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 8.6817	Cost: 22.70s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 8.6759	Cost: 6.27s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 8.5560	Cost: 10.36s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 8.5728	Cost: 6.20s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 8.5155	Cost: 11.07s
Train Epoch: 100 	Average Loss: 8.5634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7924

Learning rate: 0.00019999950652018581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 8.8483	Cost: 23.60s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 8.7374	Cost: 6.22s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 8.5025	Cost: 9.23s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 8.5431	Cost: 5.84s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 8.4170	Cost: 6.31s
Train Epoch: 101 	Average Loss: 8.5643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8499

Learning rate: 0.00019999949660124986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 8.7976	Cost: 22.27s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 8.6704	Cost: 6.02s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 8.5294	Cost: 7.64s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 8.3978	Cost: 6.01s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 8.5202	Cost: 8.27s
Train Epoch: 102 	Average Loss: 8.5441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6775

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999948658361836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 8.6709	Cost: 25.51s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 8.5695	Cost: 6.02s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 8.3682	Cost: 7.46s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 8.5427	Cost: 6.00s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 8.4089	Cost: 8.51s
Train Epoch: 103 	Average Loss: 8.4795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6778

Learning rate: 0.00019999947646729134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 8.5823	Cost: 22.65s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 8.6080	Cost: 5.96s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 8.5373	Cost: 7.35s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 8.4349	Cost: 6.10s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 8.4082	Cost: 8.39s
Train Epoch: 104 	Average Loss: 8.4649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6103

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999946625226878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 8.6462	Cost: 26.90s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 8.5066	Cost: 6.17s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 8.4981	Cost: 7.70s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 8.3355	Cost: 5.77s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 8.4004	Cost: 7.08s
Train Epoch: 105 	Average Loss: 8.4696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7643

Learning rate: 0.00019999945593855072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 8.7139	Cost: 23.52s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 8.4908	Cost: 6.83s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 8.5341	Cost: 10.93s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 8.4833	Cost: 6.25s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 8.3407	Cost: 12.87s
Train Epoch: 106 	Average Loss: 8.4593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5756

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999944552613714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 8.6616	Cost: 31.15s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 8.5013	Cost: 17.40s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 8.3757	Cost: 17.41s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 8.2385	Cost: 17.72s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 8.3145	Cost: 18.50s
Train Epoch: 107 	Average Loss: 8.4177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5845

Learning rate: 0.00019999943501502806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 8.6512	Cost: 22.75s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 8.6328	Cost: 17.63s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 8.4183	Cost: 17.77s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 8.3082	Cost: 17.85s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 8.2777	Cost: 17.77s
Train Epoch: 108 	Average Loss: 8.4187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5555

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999994244052235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 8.3527	Cost: 24.05s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 8.4902	Cost: 17.56s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 8.4679	Cost: 17.15s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 8.2702	Cost: 17.86s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 8.2692	Cost: 17.72s
Train Epoch: 109 	Average Loss: 8.3539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5365

Saving model as e109_model.pt & e109_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999941369672346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 8.5571	Cost: 24.81s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 8.5382	Cost: 18.25s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 8.4879	Cost: 18.12s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 8.2542	Cost: 17.98s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 8.3215	Cost: 17.49s
Train Epoch: 110 	Average Loss: 8.3760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5797

Learning rate: 0.00019999940288952794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 8.5025	Cost: 25.07s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 8.4091	Cost: 17.83s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 8.6243	Cost: 17.20s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 8.2872	Cost: 17.61s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 8.3523	Cost: 17.48s
Train Epoch: 111 	Average Loss: 8.3709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5695

Learning rate: 0.000199999391983637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 8.5349	Cost: 27.60s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 8.4567	Cost: 17.44s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 8.2561	Cost: 17.48s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 8.2641	Cost: 17.22s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 8.3353	Cost: 17.14s
Train Epoch: 112 	Average Loss: 8.3351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5240

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999993809790506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 8.5906	Cost: 23.05s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 8.4638	Cost: 17.57s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 8.2646	Cost: 17.27s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 8.2986	Cost: 17.43s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 8.3448	Cost: 17.74s
Train Epoch: 113 	Average Loss: 8.3363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5365

Learning rate: 0.00019999936987576873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 8.5365	Cost: 22.64s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 8.3138	Cost: 6.17s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 8.2907	Cost: 8.30s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 8.2511	Cost: 5.82s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 8.2256	Cost: 6.03s
Train Epoch: 114 	Average Loss: 8.2797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4021

Saving model as e114_model.pt & e114_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999935867379148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 8.4525	Cost: 30.49s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 8.3824	Cost: 6.11s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 8.1801	Cost: 8.60s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 8.1263	Cost: 5.84s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 8.2255	Cost: 5.86s
Train Epoch: 115 	Average Loss: 8.2825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4809

Learning rate: 0.00019999934737311882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 8.6023	Cost: 26.66s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 8.2726	Cost: 6.54s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 8.3938	Cost: 11.94s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 8.1652	Cost: 6.91s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 8.4156	Cost: 12.63s
Train Epoch: 116 	Average Loss: 8.2867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4985

Learning rate: 0.00019999933597375074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 8.4725	Cost: 27.91s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 8.2964	Cost: 6.21s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 8.2597	Cost: 10.23s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 8.2146	Cost: 5.72s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 8.0865	Cost: 6.17s
Train Epoch: 117 	Average Loss: 8.2422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4337

Learning rate: 0.0001999993244756873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 8.4797	Cost: 23.38s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 8.3094	Cost: 6.24s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 8.1681	Cost: 10.16s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 8.0584	Cost: 6.24s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 8.0606	Cost: 11.26s
Train Epoch: 118 	Average Loss: 8.2035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3765

Saving model as e118_model.pt & e118_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999931287892846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 8.3915	Cost: 24.69s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 8.2484	Cost: 6.01s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 8.2617	Cost: 8.23s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 8.0476	Cost: 5.95s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 8.2981	Cost: 6.78s
Train Epoch: 119 	Average Loss: 8.2119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3979

Learning rate: 0.00019999930118347426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 8.4191	Cost: 22.01s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 8.2439	Cost: 6.16s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 8.1950	Cost: 8.92s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 8.0943	Cost: 6.20s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 8.1652	Cost: 11.24s
Train Epoch: 120 	Average Loss: 8.1893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4518

Learning rate: 0.0001999992893893247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 8.4913	Cost: 26.24s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 8.1743	Cost: 6.01s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 8.3104	Cost: 8.01s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 8.0342	Cost: 6.05s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 8.0073	Cost: 9.69s
Train Epoch: 121 	Average Loss: 8.1724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4050

Learning rate: 0.0001999992774964798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 8.4173	Cost: 22.31s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 8.2691	Cost: 6.01s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 8.1881	Cost: 6.82s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 7.9440	Cost: 6.02s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 8.0174	Cost: 7.98s
Train Epoch: 122 	Average Loss: 8.1219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3779

Learning rate: 0.00019999926550493962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 8.2577	Cost: 30.12s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 8.2704	Cost: 6.30s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 8.2366	Cost: 9.84s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 7.9933	Cost: 5.92s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 8.0039	Cost: 6.55s
Train Epoch: 123 	Average Loss: 8.1363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3787

Learning rate: 0.00019999925341470404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 8.3319	Cost: 23.73s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 8.2183	Cost: 6.02s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 8.1147	Cost: 7.51s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 7.9615	Cost: 5.77s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 7.9959	Cost: 6.29s
Train Epoch: 124 	Average Loss: 8.1167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3781

Learning rate: 0.0001999992412257732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 8.3137	Cost: 28.31s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 8.2219	Cost: 7.91s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 7.9575	Cost: 10.89s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 7.8580	Cost: 5.94s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 8.0304	Cost: 8.68s
Train Epoch: 125 	Average Loss: 8.0619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3720

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999922893814705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 8.5309	Cost: 23.02s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 8.2009	Cost: 6.13s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 8.1435	Cost: 8.17s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 8.0491	Cost: 5.98s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 7.9110	Cost: 5.72s
Train Epoch: 126 	Average Loss: 8.0965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3089

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999921655182562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 8.1217	Cost: 25.41s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 8.0635	Cost: 6.19s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 7.9924	Cost: 10.93s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 7.8843	Cost: 6.02s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 8.0272	Cost: 7.18s
Train Epoch: 127 	Average Loss: 8.0400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2593

Saving model as e127_model.pt & e127_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999992040668089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 8.1817	Cost: 23.51s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 8.1934	Cost: 6.00s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 7.9934	Cost: 7.05s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 7.8493	Cost: 5.79s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 7.9032	Cost: 5.74s
Train Epoch: 128 	Average Loss: 8.0256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2582

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999919148309698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 8.3513	Cost: 25.63s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 8.0645	Cost: 6.27s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 8.1340	Cost: 10.73s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 7.8774	Cost: 5.85s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 7.9187	Cost: 7.16s
Train Epoch: 129 	Average Loss: 8.0257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1997

Saving model as e129_model.pt & e129_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999917880068977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 8.2602	Cost: 23.65s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 8.1042	Cost: 6.00s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 7.9890	Cost: 7.64s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 7.8202	Cost: 5.65s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 7.9977	Cost: 6.19s
Train Epoch: 130 	Average Loss: 7.9882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2494

Learning rate: 0.00019999916601958734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 8.1339	Cost: 26.66s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 8.0729	Cost: 6.41s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 7.9526	Cost: 10.08s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 7.7441	Cost: 5.78s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 8.0146	Cost: 6.89s
Train Epoch: 131 	Average Loss: 7.9412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2814

Learning rate: 0.00019999915313978966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 8.1207	Cost: 23.50s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 8.0091	Cost: 6.05s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 7.8737	Cost: 7.93s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 7.7671	Cost: 6.07s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 7.9000	Cost: 6.12s
Train Epoch: 132 	Average Loss: 7.9357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3197

Learning rate: 0.00019999914016129682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 8.2301	Cost: 27.43s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 7.9038	Cost: 6.47s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 7.8833	Cost: 10.03s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 7.8185	Cost: 5.81s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 7.8349	Cost: 5.73s
Train Epoch: 133 	Average Loss: 7.9477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2544

Learning rate: 0.00019999912708410875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 8.1231	Cost: 23.77s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 8.0388	Cost: 6.32s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 7.9109	Cost: 7.59s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 7.7733	Cost: 5.92s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 7.7753	Cost: 6.02s
Train Epoch: 134 	Average Loss: 7.9000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2373

Learning rate: 0.00019999911390822548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 8.1672	Cost: 23.21s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 7.9378	Cost: 16.91s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 7.7993	Cost: 17.01s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 7.8141	Cost: 16.80s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 8.0089	Cost: 16.82s
Train Epoch: 135 	Average Loss: 7.9076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2432

Learning rate: 0.00019999910063364705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 8.2274	Cost: 25.06s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 8.0519	Cost: 16.69s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 7.8108	Cost: 16.42s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 7.8227	Cost: 16.43s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 7.8789	Cost: 16.45s
Train Epoch: 136 	Average Loss: 7.8879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2043

Learning rate: 0.00019999908726037348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 8.1444	Cost: 25.41s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 7.8314	Cost: 16.50s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 7.8678	Cost: 16.38s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 7.7273	Cost: 16.94s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 7.7820	Cost: 17.11s
Train Epoch: 137 	Average Loss: 7.8627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1553

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999907378840477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 8.0987	Cost: 24.99s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 7.8961	Cost: 16.72s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 7.8907	Cost: 16.78s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 7.7160	Cost: 16.96s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 7.7593	Cost: 17.45s
Train Epoch: 138 	Average Loss: 7.8459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1874

Learning rate: 0.00019999906021774094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 8.1042	Cost: 28.01s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 7.8988	Cost: 17.17s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 7.9435	Cost: 16.83s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 7.6521	Cost: 17.21s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 7.6102	Cost: 17.60s
Train Epoch: 139 	Average Loss: 7.8166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0924

Saving model as e139_model.pt & e139_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999904654838195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 7.9839	Cost: 24.36s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 7.8409	Cost: 16.67s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 7.7995	Cost: 16.52s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 7.6316	Cost: 17.16s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 7.7282	Cost: 17.43s
Train Epoch: 140 	Average Loss: 7.7933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0217

Saving model as e140_model.pt & e140_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999990327803279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 8.0509	Cost: 24.35s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 7.8155	Cost: 16.92s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 7.8533	Cost: 16.94s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 7.5693	Cost: 16.49s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 7.6752	Cost: 16.75s
Train Epoch: 141 	Average Loss: 7.7522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0695

Learning rate: 0.00019999901891357876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 8.0305	Cost: 23.21s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 7.8798	Cost: 16.97s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 7.8367	Cost: 16.67s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 7.6514	Cost: 16.92s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 7.6886	Cost: 16.96s
Train Epoch: 142 	Average Loss: 7.7757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0906

Learning rate: 0.0001999990049481345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 7.9202	Cost: 23.52s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 7.8356	Cost: 6.18s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 7.7563	Cost: 8.21s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 7.6661	Cost: 5.80s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 7.7030	Cost: 6.35s
Train Epoch: 143 	Average Loss: 7.7378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1001

Learning rate: 0.00019999899088399522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 7.9881	Cost: 23.00s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 7.8679	Cost: 16.53s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 7.6833	Cost: 16.52s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 7.4934	Cost: 17.28s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 7.6746	Cost: 16.78s
Train Epoch: 144 	Average Loss: 7.6938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0989

Learning rate: 0.0001999989767211609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 8.0458	Cost: 23.75s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 7.6912	Cost: 16.89s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 7.5728	Cost: 17.19s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 7.5573	Cost: 17.41s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 7.5304	Cost: 17.14s
Train Epoch: 145 	Average Loss: 7.6948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0576

Learning rate: 0.00019999896245963153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 7.9777	Cost: 24.01s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 7.6604	Cost: 16.73s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 7.7661	Cost: 16.41s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 7.6207	Cost: 16.92s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 7.5052	Cost: 17.13s
Train Epoch: 146 	Average Loss: 7.6851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0254

Learning rate: 0.00019999894809940715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 8.0845	Cost: 23.44s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 7.5885	Cost: 17.03s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 7.7496	Cost: 16.61s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 7.5189	Cost: 16.77s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 7.4753	Cost: 16.64s
Train Epoch: 147 	Average Loss: 7.6608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0153

Saving model as e147_model.pt & e147_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999893364048776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 7.9807	Cost: 26.88s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 7.6605	Cost: 16.87s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 7.6635	Cost: 16.43s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 7.4635	Cost: 16.52s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 7.6728	Cost: 15.77s
Train Epoch: 148 	Average Loss: 7.6431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9832

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999891908287334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 7.8716	Cost: 23.23s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 7.5888	Cost: 16.81s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 7.6247	Cost: 16.64s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 7.3731	Cost: 16.70s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 7.5184	Cost: 16.70s
Train Epoch: 149 	Average Loss: 7.5857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9297

Saving model as e149_model.pt & e149_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999890442656397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 7.9178	Cost: 23.58s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 7.6597	Cost: 16.89s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 7.7037	Cost: 16.96s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 7.5252	Cost: 17.00s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 7.4204	Cost: 16.83s
Train Epoch: 150 	Average Loss: 7.6124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9728

Learning rate: 0.00019999888967155965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 7.7914	Cost: 26.89s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 7.6325	Cost: 16.85s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 7.5146	Cost: 16.31s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 7.3689	Cost: 16.25s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 7.5553	Cost: 16.70s
Train Epoch: 151 	Average Loss: 7.5634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9827

Learning rate: 0.00019999887481786036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 7.8350	Cost: 22.29s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 7.5722	Cost: 6.18s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 7.6168	Cost: 9.01s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 7.3505	Cost: 5.83s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 7.3717	Cost: 5.68s
Train Epoch: 152 	Average Loss: 7.5515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8962

Saving model as e152_model.pt & e152_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999885986546616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 7.9028	Cost: 26.46s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 7.5951	Cost: 6.25s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 7.5365	Cost: 11.17s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 7.3113	Cost: 5.75s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 7.4366	Cost: 5.85s
Train Epoch: 153 	Average Loss: 7.4979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9464

Learning rate: 0.00019999884481437704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 7.9028	Cost: 23.47s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 7.5285	Cost: 6.05s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 7.5075	Cost: 7.90s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 7.3913	Cost: 6.13s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 7.4318	Cost: 5.91s
Train Epoch: 154 	Average Loss: 7.5241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8646

Saving model as e154_model.pt & e154_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998829664593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 7.7523	Cost: 26.81s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 7.5481	Cost: 6.12s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 7.5398	Cost: 8.88s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 7.3690	Cost: 5.96s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 7.4878	Cost: 6.20s
Train Epoch: 155 	Average Loss: 7.5167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8930

Learning rate: 0.00019999881441611406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 7.7930	Cost: 23.56s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 7.4310	Cost: 8.28s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 7.5041	Cost: 14.05s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 7.3087	Cost: 6.90s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 7.3897	Cost: 10.80s
Train Epoch: 156 	Average Loss: 7.4877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8276

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999879906894028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 7.8069	Cost: 30.72s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 7.4763	Cost: 6.49s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 7.2898	Cost: 10.51s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 7.2802	Cost: 5.75s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 7.3701	Cost: 6.33s
Train Epoch: 157 	Average Loss: 7.4671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8376

Learning rate: 0.00019999878362307163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 7.7985	Cost: 22.10s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 7.3437	Cost: 6.39s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 7.4957	Cost: 9.27s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 7.2245	Cost: 6.32s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 7.3320	Cost: 11.04s
Train Epoch: 158 	Average Loss: 7.4374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8565

Learning rate: 0.0001999987680785081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 7.7524	Cost: 23.58s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 7.4074	Cost: 6.04s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 7.5532	Cost: 8.22s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 7.1523	Cost: 5.86s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 7.4662	Cost: 6.52s
Train Epoch: 159 	Average Loss: 7.4230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7786

Saving model as e159_model.pt & e159_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999875243524977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 7.7085	Cost: 24.49s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 7.5034	Cost: 6.38s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 7.3426	Cost: 10.71s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 7.1964	Cost: 6.10s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 7.2728	Cost: 8.17s
Train Epoch: 160 	Average Loss: 7.3793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9029

Learning rate: 0.00019999873669329665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 7.8916	Cost: 23.73s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 7.4526	Cost: 6.72s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 7.2923	Cost: 11.12s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 7.1531	Cost: 6.14s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 7.2652	Cost: 9.23s
Train Epoch: 161 	Average Loss: 7.3580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7472

Saving model as e161_model.pt & e161_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999987208526487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 7.6024	Cost: 22.63s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 7.3763	Cost: 6.11s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 7.3909	Cost: 8.58s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 7.1732	Cost: 5.71s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 7.2102	Cost: 6.02s
Train Epoch: 162 	Average Loss: 7.3108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7906

Learning rate: 0.000199998704913306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 7.7765	Cost: 26.96s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 7.3890	Cost: 6.53s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 7.2877	Cost: 10.68s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 7.1714	Cost: 5.93s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 7.2120	Cost: 7.28s
Train Epoch: 163 	Average Loss: 7.2874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7202

Saving model as e163_model.pt & e163_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999868887526852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 7.7256	Cost: 22.57s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 7.3592	Cost: 5.97s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 7.2903	Cost: 7.54s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 7.0320	Cost: 5.71s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 7.1236	Cost: 6.78s
Train Epoch: 164 	Average Loss: 7.2872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7367

Learning rate: 0.0001999986727385363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 7.7650	Cost: 28.27s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 7.3306	Cost: 6.62s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 7.2644	Cost: 11.25s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 7.0916	Cost: 6.04s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 7.1208	Cost: 7.63s
Train Epoch: 165 	Average Loss: 7.2845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6787

Saving model as e165_model.pt & e165_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999986565031093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 7.6255	Cost: 22.67s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 7.2540	Cost: 6.14s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 7.3226	Cost: 7.26s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 7.0403	Cost: 5.77s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 6.9763	Cost: 7.74s
Train Epoch: 166 	Average Loss: 7.2311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6785

Saving model as e166_model.pt & e166_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999864016898762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 7.6693	Cost: 25.86s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 7.3665	Cost: 6.03s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 7.2569	Cost: 8.15s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 6.8974	Cost: 5.86s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 7.0930	Cost: 7.71s
Train Epoch: 167 	Average Loss: 7.2108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7221

Learning rate: 0.00019999862373617122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 7.5644	Cost: 22.46s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 7.2129	Cost: 6.03s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 7.1697	Cost: 7.05s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 6.9998	Cost: 6.34s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 7.0117	Cost: 14.64s
Train Epoch: 168 	Average Loss: 7.1833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6616

Saving model as e168_model.pt & e168_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999860720466015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 7.7855	Cost: 23.29s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 7.1349	Cost: 6.06s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 7.1603	Cost: 7.28s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 7.1136	Cost: 5.80s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 7.0036	Cost: 7.39s
Train Epoch: 169 	Average Loss: 7.2108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7024

Learning rate: 0.0001999985905744544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 7.7036	Cost: 26.05s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 7.2006	Cost: 6.34s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 7.1371	Cost: 10.42s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 7.0138	Cost: 6.02s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 7.1084	Cost: 8.18s
Train Epoch: 170 	Average Loss: 7.1747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6099

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998573845554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 7.5421	Cost: 23.69s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 7.2050	Cost: 6.13s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 7.1923	Cost: 7.65s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 7.0683	Cost: 6.14s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 7.0902	Cost: 6.00s
Train Epoch: 171 	Average Loss: 7.1439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7034

Learning rate: 0.00019999855701795897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 7.5933	Cost: 28.07s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 7.2634	Cost: 6.20s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 7.0797	Cost: 8.10s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 6.9527	Cost: 5.83s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 6.8954	Cost: 7.04s
Train Epoch: 172 	Average Loss: 7.1048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6385

Learning rate: 0.00019999854009166934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 7.5226	Cost: 22.80s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 7.1289	Cost: 6.05s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 7.1372	Cost: 7.49s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 6.9168	Cost: 6.30s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 6.8974	Cost: 8.68s
Train Epoch: 173 	Average Loss: 7.0726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5734

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999852306668508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 7.6021	Cost: 23.56s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 7.0968	Cost: 6.13s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 7.0501	Cost: 9.36s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 6.8849	Cost: 5.74s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 6.8465	Cost: 6.41s
Train Epoch: 174 	Average Loss: 7.0501
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5815

Learning rate: 0.00019999850594300622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 7.6165	Cost: 22.87s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 7.0171	Cost: 6.73s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 6.9607	Cost: 11.58s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 6.8579	Cost: 6.29s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 6.9556	Cost: 11.56s
Train Epoch: 175 	Average Loss: 7.0290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6332

Learning rate: 0.00019999848872063282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 7.3877	Cost: 25.14s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 7.0115	Cost: 6.10s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 6.9935	Cost: 8.71s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 6.8005	Cost: 5.81s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 6.8629	Cost: 5.82s
Train Epoch: 176 	Average Loss: 7.0035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5176

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999847139956484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 7.4459	Cost: 22.71s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 6.9702	Cost: 6.29s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 6.9842	Cost: 10.99s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 6.6697	Cost: 6.17s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 6.8849	Cost: 11.10s
Train Epoch: 177 	Average Loss: 6.9719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5817

Learning rate: 0.00019999845397980232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 7.5712	Cost: 26.94s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 7.1341	Cost: 6.05s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 6.9705	Cost: 8.33s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 6.6687	Cost: 5.97s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 6.8078	Cost: 7.05s
Train Epoch: 178 	Average Loss: 6.9774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4985

Saving model as e178_model.pt & e178_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999843646134532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 7.2676	Cost: 24.58s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 6.8705	Cost: 6.17s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 6.8962	Cost: 10.77s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 6.6961	Cost: 6.07s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 6.8847	Cost: 8.22s
Train Epoch: 179 	Average Loss: 6.9082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4727

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999841884419376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 7.4208	Cost: 23.13s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 6.9429	Cost: 6.08s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 6.8205	Cost: 7.93s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 6.7561	Cost: 5.80s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 6.7387	Cost: 6.12s
Train Epoch: 180 	Average Loss: 6.9135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4272

Saving model as e180_model.pt & e180_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999840112834775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 7.5005	Cost: 27.34s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 6.8699	Cost: 6.20s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 6.9204	Cost: 9.72s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 6.7678	Cost: 5.73s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 6.7042	Cost: 6.12s
Train Epoch: 181 	Average Loss: 6.9043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4679

Learning rate: 0.00019999838331380727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 7.3772	Cost: 24.21s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 6.8649	Cost: 6.19s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 6.8037	Cost: 8.56s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 6.7384	Cost: 5.83s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 6.7489	Cost: 8.04s
Train Epoch: 182 	Average Loss: 6.8537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4096

Saving model as e182_model.pt & e182_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999836540057235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 7.3336	Cost: 26.91s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 6.9769	Cost: 6.07s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 6.8731	Cost: 6.97s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 6.6296	Cost: 5.90s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 6.8335	Cost: 6.41s
Train Epoch: 183 	Average Loss: 6.8231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4241

Learning rate: 0.000199998347388643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 7.4402	Cost: 23.94s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 6.8037	Cost: 6.09s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 6.7513	Cost: 6.83s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 6.7191	Cost: 5.85s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 6.6766	Cost: 5.72s
Train Epoch: 184 	Average Loss: 6.8039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3939

Saving model as e184_model.pt & e184_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999832927801924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 7.4200	Cost: 29.71s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 6.8311	Cost: 6.82s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 6.7367	Cost: 11.01s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 6.5591	Cost: 5.78s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 6.9156	Cost: 7.53s
Train Epoch: 185 	Average Loss: 6.8233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4991

Learning rate: 0.00019999831106870108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 7.4531	Cost: 24.52s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 6.8594	Cost: 6.42s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 6.6520	Cost: 7.11s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 6.5873	Cost: 6.11s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 6.6223	Cost: 8.81s
Train Epoch: 186 	Average Loss: 6.7997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3618

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999829276068855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 7.4481	Cost: 38.54s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 6.6984	Cost: 6.03s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 6.7897	Cost: 8.26s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 6.5867	Cost: 5.92s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 6.5749	Cost: 8.00s
Train Epoch: 187 	Average Loss: 6.7731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3619

Learning rate: 0.00019999827435398168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 7.2636	Cost: 24.43s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 6.7163	Cost: 6.09s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 6.7521	Cost: 8.10s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 6.5206	Cost: 6.34s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 6.5635	Cost: 12.63s
Train Epoch: 188 	Average Loss: 6.7219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4476

Learning rate: 0.00019999825584858045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 7.3792	Cost: 24.43s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 6.6936	Cost: 6.10s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 6.7237	Cost: 8.42s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 6.4700	Cost: 5.81s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 6.4984	Cost: 6.26s
Train Epoch: 189 	Average Loss: 6.7091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3261

Saving model as e189_model.pt & e189_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999823724448486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 7.2351	Cost: 28.66s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 6.6460	Cost: 6.89s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 6.6052	Cost: 10.97s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 6.3560	Cost: 5.96s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 6.6608	Cost: 6.53s
Train Epoch: 190 	Average Loss: 6.6614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3036

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998218541695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 7.2893	Cost: 22.54s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 6.6482	Cost: 6.04s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 6.6005	Cost: 7.00s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 6.4906	Cost: 5.96s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 6.4968	Cost: 7.73s
Train Epoch: 191 	Average Loss: 6.6346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3515

Learning rate: 0.00019999819974021087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 7.2765	Cost: 26.40s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 6.6610	Cost: 6.01s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 6.6692	Cost: 8.02s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 6.3901	Cost: 5.94s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 6.5028	Cost: 8.61s
Train Epoch: 192 	Average Loss: 6.6210
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2718

Saving model as e192_model.pt & e192_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999818084003246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 7.2686	Cost: 22.31s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 6.5440	Cost: 6.47s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 6.4947	Cost: 10.59s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 6.4110	Cost: 6.13s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 6.4922	Cost: 11.05s
Train Epoch: 193 	Average Loss: 6.5660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3344

Learning rate: 0.00019999816184115978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 7.0981	Cost: 23.21s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 6.5286	Cost: 6.24s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 6.5251	Cost: 8.50s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 6.3222	Cost: 6.03s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 6.2768	Cost: 5.77s
Train Epoch: 194 	Average Loss: 6.5363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2977

Learning rate: 0.00019999814274359288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 7.3010	Cost: 25.83s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 6.6160	Cost: 6.66s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 6.5369	Cost: 11.51s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 6.3448	Cost: 6.23s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 6.4152	Cost: 8.80s
Train Epoch: 195 	Average Loss: 6.5403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1472

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999812354733177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 7.2351	Cost: 22.29s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 6.5140	Cost: 5.99s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 6.3545	Cost: 6.96s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 6.4097	Cost: 6.02s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 6.4476	Cost: 9.08s
Train Epoch: 196 	Average Loss: 6.5014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1693

Learning rate: 0.00019999810425237646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 7.2673	Cost: 23.47s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 6.5067	Cost: 6.17s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 6.3300	Cost: 8.51s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 6.1953	Cost: 6.05s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 6.2179	Cost: 6.39s
Train Epoch: 197 	Average Loss: 6.4776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1331

Saving model as e197_model.pt & e197_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999808485872698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 7.0992	Cost: 27.56s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 6.4980	Cost: 6.51s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 6.7230	Cost: 10.74s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 6.3493	Cost: 5.99s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 6.3934	Cost: 6.48s
Train Epoch: 198 	Average Loss: 6.5269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2156

Learning rate: 0.00019999806536638337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 7.2421	Cost: 24.36s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 6.3333	Cost: 6.62s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 6.4579	Cost: 10.23s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 6.1869	Cost: 6.22s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 6.3375	Cost: 11.32s
Train Epoch: 199 	Average Loss: 6.4597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1228

Saving model as e199_model.pt & e199_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999804577534562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 7.0586	Cost: 26.25s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 6.4262	Cost: 6.10s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 6.2974	Cost: 8.07s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 6.1173	Cost: 5.95s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 6.2339	Cost: 7.37s
Train Epoch: 200 	Average Loss: 6.3933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1425

Learning rate: 0.00019999802608561374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 7.0472	Cost: 22.42s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 6.4419	Cost: 6.44s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 6.2927	Cost: 9.23s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 6.2452	Cost: 6.25s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 6.2962	Cost: 11.75s
Train Epoch: 201 	Average Loss: 6.3950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1700

Learning rate: 0.00019999800629718777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 6.9716	Cost: 25.29s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 6.3277	Cost: 6.02s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 6.3802	Cost: 7.55s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 6.1326	Cost: 6.09s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 6.2474	Cost: 10.12s
Train Epoch: 202 	Average Loss: 6.3999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0744

Saving model as e202_model.pt & e202_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999798641006774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 7.1901	Cost: 23.00s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 6.2406	Cost: 6.80s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 6.2914	Cost: 10.76s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 6.2033	Cost: 6.17s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 6.1834	Cost: 11.47s
Train Epoch: 203 	Average Loss: 6.3207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0560

Saving model as e203_model.pt & e203_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999796642425366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 6.9718	Cost: 23.42s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 6.2788	Cost: 6.11s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 6.1466	Cost: 7.73s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 6.1146	Cost: 5.90s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 6.1319	Cost: 6.10s
Train Epoch: 204 	Average Loss: 6.3061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0293

Saving model as e204_model.pt & e204_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999794633974552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 6.9869	Cost: 23.29s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 6.3659	Cost: 6.10s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 6.2445	Cost: 8.43s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 6.0482	Cost: 6.03s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 6.0697	Cost: 6.05s
Train Epoch: 205 	Average Loss: 6.2628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9253

Saving model as e205_model.pt & e205_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999792615654335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 6.9212	Cost: 27.33s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 6.2247	Cost: 6.26s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 6.0925	Cost: 9.91s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 5.9996	Cost: 5.90s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 6.0635	Cost: 5.75s
Train Epoch: 206 	Average Loss: 6.2504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1051

Learning rate: 0.00019999790587464718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 6.9899	Cost: 23.85s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 6.2632	Cost: 6.09s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 6.1028	Cost: 7.79s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 5.8960	Cost: 6.08s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 6.0888	Cost: 6.26s
Train Epoch: 207 	Average Loss: 6.2077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9844

Learning rate: 0.00019999788549405706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 7.0669	Cost: 25.31s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 6.0854	Cost: 6.84s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 6.0532	Cost: 11.57s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 5.9499	Cost: 6.20s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 6.0578	Cost: 10.45s
Train Epoch: 208 	Average Loss: 6.2029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9989

Learning rate: 0.00019999786501477296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 6.8835	Cost: 23.25s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 6.2168	Cost: 6.24s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 6.1197	Cost: 7.93s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 5.9645	Cost: 5.77s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 5.9621	Cost: 5.68s
Train Epoch: 209 	Average Loss: 6.1671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9592

Learning rate: 0.00019999784443679492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 6.9887	Cost: 24.10s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 6.1059	Cost: 6.21s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 6.0383	Cost: 10.70s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 5.9125	Cost: 6.12s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 5.9479	Cost: 10.04s
Train Epoch: 210 	Average Loss: 6.1353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9835

Learning rate: 0.000199997823760123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 6.9214	Cost: 22.74s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 6.0912	Cost: 6.23s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 6.0677	Cost: 8.69s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 5.9624	Cost: 5.80s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 5.9308	Cost: 5.87s
Train Epoch: 211 	Average Loss: 6.1444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8817

Saving model as e211_model.pt & e211_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999780298475715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 6.9097	Cost: 26.53s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 6.0739	Cost: 6.16s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 6.0404	Cost: 8.49s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 5.8439	Cost: 5.77s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 5.9471	Cost: 6.25s
Train Epoch: 212 	Average Loss: 6.1030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9131

Learning rate: 0.00019999778211069746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 6.7076	Cost: 23.63s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 6.0909	Cost: 6.03s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 5.9663	Cost: 8.04s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 5.8472	Cost: 5.91s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 5.9017	Cost: 5.82s
Train Epoch: 213 	Average Loss: 6.0352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8556

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999977611379439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 6.7950	Cost: 27.87s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 6.0146	Cost: 6.10s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 5.8912	Cost: 8.04s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 5.7532	Cost: 5.99s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 5.9088	Cost: 8.87s
Train Epoch: 214 	Average Loss: 6.0200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9511

Learning rate: 0.00019999774006649652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 6.7580	Cost: 24.28s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 6.1086	Cost: 6.18s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 5.8267	Cost: 11.55s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 5.8805	Cost: 6.27s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 5.8667	Cost: 13.34s
Train Epoch: 215 	Average Loss: 6.0051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8623

Learning rate: 0.00019999771889635528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 6.8836	Cost: 27.71s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 6.0218	Cost: 6.13s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 5.9012	Cost: 8.63s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 5.8195	Cost: 5.94s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 6.0128	Cost: 8.96s
Train Epoch: 216 	Average Loss: 6.0301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0165

Learning rate: 0.00019999769762752028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 6.9933	Cost: 22.97s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 6.0823	Cost: 6.03s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 5.8705	Cost: 7.28s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 5.7312	Cost: 5.81s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 5.7245	Cost: 6.10s
Train Epoch: 217 	Average Loss: 6.0292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8401

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999767625999152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 6.7350	Cost: 23.72s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 5.8802	Cost: 6.03s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 5.9429	Cost: 7.11s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 5.7814	Cost: 6.09s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 5.7175	Cost: 10.59s
Train Epoch: 218 	Average Loss: 5.9514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8924

Learning rate: 0.00019999765479376897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 6.7964	Cost: 22.32s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 6.0215	Cost: 6.04s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 5.9619	Cost: 7.90s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 5.8100	Cost: 6.28s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 5.8105	Cost: 10.29s
Train Epoch: 219 	Average Loss: 5.9991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8841

Learning rate: 0.00019999763322885272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 6.7828	Cost: 26.68s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 5.9885	Cost: 6.22s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 5.8835	Cost: 10.06s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 5.5976	Cost: 5.69s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 5.6216	Cost: 5.73s
Train Epoch: 220 	Average Loss: 5.8877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7378

Saving model as e220_model.pt & e220_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999761156524275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 6.6502	Cost: 25.40s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 5.8351	Cost: 6.01s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 5.8215	Cost: 8.40s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 5.4384	Cost: 5.70s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 5.6796	Cost: 6.14s
Train Epoch: 221 	Average Loss: 5.8350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7923

Learning rate: 0.0001999975898029391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 6.7006	Cost: 36.82s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 5.8388	Cost: 10.36s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 5.7259	Cost: 11.42s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 5.6703	Cost: 6.47s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 5.5849	Cost: 10.98s
Train Epoch: 222 	Average Loss: 5.8285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7690

Learning rate: 0.00019999756794194176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 6.7025	Cost: 22.75s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 5.7039	Cost: 6.10s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 5.6401	Cost: 8.00s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 5.4908	Cost: 5.88s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 5.7074	Cost: 5.71s
Train Epoch: 223 	Average Loss: 5.7562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6885

Saving model as e223_model.pt & e223_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999975459822508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 6.6515	Cost: 36.91s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 5.7757	Cost: 6.14s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 5.7132	Cost: 9.94s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 5.6276	Cost: 6.21s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 5.5711	Cost: 8.06s
Train Epoch: 224 	Average Loss: 5.7629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6345

Saving model as e224_model.pt & e224_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999975239238662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 6.6785	Cost: 26.11s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 5.6183	Cost: 7.00s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 5.6220	Cost: 10.40s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 5.4765	Cost: 5.91s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 5.6109	Cost: 7.82s
Train Epoch: 225 	Average Loss: 5.7197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6705

Learning rate: 0.000199997501766788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 6.6952	Cost: 23.94s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 5.6915	Cost: 6.16s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 5.6588	Cost: 7.37s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 5.4198	Cost: 5.90s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 5.5364	Cost: 5.85s
Train Epoch: 226 	Average Loss: 5.6660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6737

Learning rate: 0.00019999747951101625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 6.6665	Cost: 28.79s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 5.7446	Cost: 6.35s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 5.5915	Cost: 8.67s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 5.3940	Cost: 5.94s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 5.5061	Cost: 5.85s
Train Epoch: 227 	Average Loss: 5.6768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6535

Learning rate: 0.0001999974571565509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 6.7333	Cost: 24.13s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 5.5705	Cost: 6.02s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 5.4907	Cost: 7.71s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 5.2968	Cost: 5.87s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 5.5914	Cost: 5.95s
Train Epoch: 228 	Average Loss: 5.6524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5736

Saving model as e228_model.pt & e228_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999743470339206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 6.5281	Cost: 29.01s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 5.6739	Cost: 6.68s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 5.5475	Cost: 11.10s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 5.3526	Cost: 6.17s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 5.2989	Cost: 5.75s
Train Epoch: 229 	Average Loss: 5.5972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6132

Learning rate: 0.0001999974121515397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 6.4994	Cost: 23.99s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 5.4800	Cost: 6.13s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 5.3849	Cost: 7.87s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 5.3876	Cost: 5.96s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 5.4141	Cost: 5.71s
Train Epoch: 230 	Average Loss: 5.5513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5189

Saving model as e230_model.pt & e230_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999738950099387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 6.6014	Cost: 26.61s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 5.5273	Cost: 6.04s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 5.4580	Cost: 7.20s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 5.2922	Cost: 6.04s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 5.2883	Cost: 7.13s
Train Epoch: 231 	Average Loss: 5.5385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5562

Learning rate: 0.00019999736675175452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 6.3546	Cost: 22.45s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 5.5842	Cost: 5.99s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 5.3309	Cost: 6.89s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 5.4422	Cost: 6.37s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 5.2919	Cost: 10.41s
Train Epoch: 232 	Average Loss: 5.5488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6179

Learning rate: 0.00019999734390382178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 6.4377	Cost: 26.43s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 5.5105	Cost: 6.06s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 5.4941	Cost: 8.04s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 5.3378	Cost: 5.99s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 5.4861	Cost: 7.12s
Train Epoch: 233 	Average Loss: 5.5351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4814

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999732095719557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 6.2602	Cost: 24.51s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 5.3361	Cost: 6.93s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 5.4210	Cost: 11.76s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 5.3014	Cost: 6.19s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 5.2439	Cost: 10.48s
Train Epoch: 234 	Average Loss: 5.4636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4970

Learning rate: 0.00019999729791187596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 6.4208	Cost: 22.24s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 5.4516	Cost: 6.06s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 5.4032	Cost: 8.38s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 5.1265	Cost: 5.82s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 5.2300	Cost: 6.16s
Train Epoch: 235 	Average Loss: 5.4163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4750

Saving model as e235_model.pt & e235_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199997274767863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 6.4626	Cost: 22.72s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 5.3276	Cost: 6.29s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 5.2979	Cost: 11.13s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 5.1444	Cost: 6.15s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 5.0814	Cost: 10.78s
Train Epoch: 236 	Average Loss: 5.4036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3957

Saving model as e236_model.pt & e236_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999972515251567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 6.3585	Cost: 21.82s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 5.3010	Cost: 6.10s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 5.2955	Cost: 8.82s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 5.1908	Cost: 6.03s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 5.1816	Cost: 8.56s
Train Epoch: 237 	Average Loss: 5.3568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4313

Learning rate: 0.00019999722818375706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 6.2710	Cost: 23.26s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 5.3884	Cost: 9.60s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 5.2163	Cost: 18.22s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 5.0405	Cost: 6.78s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 5.2283	Cost: 12.79s
Train Epoch: 238 	Average Loss: 5.3641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3925

Saving model as e238_model.pt & e238_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999720474366407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 6.2178	Cost: 26.59s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 5.2610	Cost: 6.05s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 5.2329	Cost: 8.17s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 5.0719	Cost: 5.90s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 5.0750	Cost: 7.97s
Train Epoch: 239 	Average Loss: 5.2940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4587

Learning rate: 0.00019999718120487783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 6.3575	Cost: 32.44s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 5.3645	Cost: 8.31s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 5.3250	Cost: 13.67s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 5.1260	Cost: 6.23s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 5.2170	Cost: 11.01s
Train Epoch: 240 	Average Loss: 5.3540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4006

Learning rate: 0.00019999715756739835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 6.2898	Cost: 23.80s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 5.2717	Cost: 6.02s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 5.1436	Cost: 7.43s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 4.9594	Cost: 5.71s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 5.1434	Cost: 5.81s
Train Epoch: 241 	Average Loss: 5.2645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4282

Learning rate: 0.00019999713383122558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 6.3167	Cost: 26.63s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 5.0578	Cost: 6.19s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 5.1262	Cost: 10.29s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 5.1427	Cost: 5.83s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 5.3502	Cost: 5.74s
Train Epoch: 242 	Average Loss: 5.2628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4954

Learning rate: 0.0001999971099963596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 6.7686	Cost: 24.39s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 5.3742	Cost: 6.01s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 5.3965	Cost: 8.02s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 5.1634	Cost: 5.69s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 5.2695	Cost: 6.22s
Train Epoch: 243 	Average Loss: 5.4364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4141

Learning rate: 0.00019999708606280046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 6.2414	Cost: 23.81s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 5.2431	Cost: 6.41s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 5.2475	Cost: 10.26s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 4.8228	Cost: 6.12s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 5.0352	Cost: 9.76s
Train Epoch: 244 	Average Loss: 5.2265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2908

Saving model as e244_model.pt & e244_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999706203054814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 6.1157	Cost: 23.01s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 5.1359	Cost: 6.20s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 5.1033	Cost: 10.25s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 4.9421	Cost: 5.73s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 4.8981	Cost: 7.14s
Train Epoch: 245 	Average Loss: 5.1657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2950

Learning rate: 0.00019999703789960266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 6.0906	Cost: 24.23s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 5.0531	Cost: 7.64s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 4.9824	Cost: 13.67s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 4.7985	Cost: 6.90s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 4.9678	Cost: 10.87s
Train Epoch: 246 	Average Loss: 5.1181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2579

Saving model as e246_model.pt & e246_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999701366996408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 6.1959	Cost: 23.45s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 4.9842	Cost: 6.14s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 4.8802	Cost: 8.93s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 4.6666	Cost: 6.36s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 4.8859	Cost: 11.77s
Train Epoch: 247 	Average Loss: 5.0381
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1553

Saving model as e247_model.pt & e247_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999969893416324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 5.9316	Cost: 23.20s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 4.9200	Cost: 6.02s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 4.9624	Cost: 7.84s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 4.7896	Cost: 5.71s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 4.8496	Cost: 6.33s
Train Epoch: 248 	Average Loss: 5.0502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1483

Saving model as e248_model.pt & e248_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999696491460766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 6.0125	Cost: 26.79s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 5.0619	Cost: 6.19s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 4.8247	Cost: 7.10s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 4.8771	Cost: 5.89s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 4.9517	Cost: 6.66s
Train Epoch: 249 	Average Loss: 5.0131
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1894

Learning rate: 0.00019999694038888986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 6.0932	Cost: 24.44s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 5.0014	Cost: 6.17s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 4.9000	Cost: 8.87s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 4.7464	Cost: 5.96s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 4.8914	Cost: 6.23s
Train Epoch: 250 	Average Loss: 5.0105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1744

Learning rate: 0.00019999691576447903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 6.1377	Cost: 25.95s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 4.9497	Cost: 6.33s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 4.8814	Cost: 12.34s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 4.7525	Cost: 6.31s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 4.7671	Cost: 10.50s
Train Epoch: 251 	Average Loss: 4.9687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1180

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999968910413752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 6.1188	Cost: 26.65s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 5.0291	Cost: 6.15s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 4.7425	Cost: 11.04s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 4.6712	Cost: 6.65s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 4.8391	Cost: 13.41s
Train Epoch: 252 	Average Loss: 4.9764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1584

Learning rate: 0.0001999968662195784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 6.0526	Cost: 27.13s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 4.8786	Cost: 6.10s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 4.7535	Cost: 8.62s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 4.7719	Cost: 6.08s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 4.8589	Cost: 6.87s
Train Epoch: 253 	Average Loss: 5.0030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1041

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999684129908864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 6.2630	Cost: 22.64s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 4.9055	Cost: 6.05s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 4.8342	Cost: 7.47s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 4.6673	Cost: 5.74s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 4.7480	Cost: 6.44s
Train Epoch: 254 	Average Loss: 4.9599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0766

Saving model as e254_model.pt & e254_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999681627990595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 6.1176	Cost: 27.12s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 4.8857	Cost: 6.24s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 4.8991	Cost: 10.86s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 4.7573	Cost: 5.82s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 4.8802	Cost: 6.04s
Train Epoch: 255 	Average Loss: 4.9680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1494

Learning rate: 0.00019999679116203034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 6.1654	Cost: 24.70s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 4.8675	Cost: 6.12s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 4.8068	Cost: 8.92s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 4.5441	Cost: 5.80s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 4.8195	Cost: 7.71s
Train Epoch: 256 	Average Loss: 4.9450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0352

Saving model as e256_model.pt & e256_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999967659454619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 5.9388	Cost: 27.01s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 4.7129	Cost: 6.04s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 4.7038	Cost: 8.08s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 4.5946	Cost: 6.03s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 4.5933	Cost: 8.24s
Train Epoch: 257 	Average Loss: 4.8242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0421

Learning rate: 0.00019999674063020056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 5.9573	Cost: 22.88s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 4.8068	Cost: 6.02s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 4.5767	Cost: 9.27s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 4.6917	Cost: 6.16s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 4.5472	Cost: 11.99s
Train Epoch: 258 	Average Loss: 4.7944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0343

Saving model as e258_model.pt & e258_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999671521624642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 5.9489	Cost: 24.94s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 4.7209	Cost: 6.07s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 4.6269	Cost: 8.99s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 4.4338	Cost: 5.65s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 4.6004	Cost: 6.02s
Train Epoch: 259 	Average Loss: 4.7084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9478

Saving model as e259_model.pt & e259_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999966897035995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 5.7439	Cost: 24.91s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 4.6327	Cost: 6.33s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 4.4946	Cost: 10.74s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 4.4297	Cost: 5.91s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 4.5103	Cost: 7.48s
Train Epoch: 260 	Average Loss: 4.6279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0082

Learning rate: 0.00019999666409225978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 5.7702	Cost: 26.39s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 4.4819	Cost: 6.09s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 4.5237	Cost: 7.86s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 4.4335	Cost: 6.01s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 4.4150	Cost: 6.52s
Train Epoch: 261 	Average Loss: 4.6325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9223

Saving model as e261_model.pt & e261_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999663838222732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 5.6575	Cost: 26.41s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 4.5361	Cost: 6.13s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 4.4685	Cost: 8.69s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 4.2963	Cost: 5.96s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 4.3473	Cost: 6.64s
Train Epoch: 262 	Average Loss: 4.6014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9098

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999661257350212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 5.7853	Cost: 22.81s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 4.6390	Cost: 6.25s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 4.3670	Cost: 8.91s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 4.3252	Cost: 6.25s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 4.3916	Cost: 11.51s
Train Epoch: 263 	Average Loss: 4.5729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8770

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999658666608423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 5.8117	Cost: 23.74s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 4.3986	Cost: 6.22s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 4.3736	Cost: 7.67s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 4.2593	Cost: 6.13s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 4.3000	Cost: 6.12s
Train Epoch: 264 	Average Loss: 4.5798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8886

Learning rate: 0.00019999656065997363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 5.6822	Cost: 26.14s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 4.5708	Cost: 6.25s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 4.5183	Cost: 10.51s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 4.4002	Cost: 5.91s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 4.3402	Cost: 7.05s
Train Epoch: 265 	Average Loss: 4.5922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8917

Learning rate: 0.00019999653455517042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 5.6603	Cost: 23.64s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 4.4609	Cost: 6.14s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 4.3636	Cost: 8.00s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 4.2788	Cost: 6.16s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 4.2775	Cost: 11.33s
Train Epoch: 266 	Average Loss: 4.5268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8126

Saving model as e266_model.pt & e266_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999650835167456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 5.7638	Cost: 33.35s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 4.3595	Cost: 8.55s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 4.3486	Cost: 9.47s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 4.3008	Cost: 5.90s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 4.2675	Cost: 6.29s
Train Epoch: 267 	Average Loss: 4.4515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8069

Saving model as e267_model.pt & e267_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999648204948613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 5.3827	Cost: 23.99s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 4.3778	Cost: 6.04s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 4.2923	Cost: 8.94s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 4.1558	Cost: 6.14s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 4.2863	Cost: 10.81s
Train Epoch: 268 	Average Loss: 4.4286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6924

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999964556486051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 5.5620	Cost: 23.70s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 4.3384	Cost: 6.10s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 4.1208	Cost: 8.58s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 4.2772	Cost: 5.74s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 4.3542	Cost: 6.05s
Train Epoch: 269 	Average Loss: 4.3992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7332

Learning rate: 0.00019999642914903155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 5.6116	Cost: 22.42s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 4.2392	Cost: 6.68s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 4.3009	Cost: 10.37s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 4.1688	Cost: 6.20s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 4.0819	Cost: 11.05s
Train Epoch: 270 	Average Loss: 4.4071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7239

Learning rate: 0.00019999640255076545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 5.6495	Cost: 25.07s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 4.2785	Cost: 6.07s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 4.2717	Cost: 8.11s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 5.6892	Cost: 5.90s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 5.4282	Cost: 6.21s
Train Epoch: 271 	Average Loss: 4.9813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6870

Learning rate: 0.0001999963758538069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 6.5030	Cost: 27.94s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 5.2006	Cost: 6.38s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 4.7743	Cost: 12.81s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 4.6938	Cost: 6.66s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 4.4806	Cost: 10.76s
Train Epoch: 272 	Average Loss: 5.0050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0368

Learning rate: 0.00019999634905815583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 5.9347	Cost: 26.12s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 4.6139	Cost: 5.99s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 4.2889	Cost: 7.54s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 4.2730	Cost: 6.06s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 4.3524	Cost: 8.47s
Train Epoch: 273 	Average Loss: 4.5065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7999

Learning rate: 0.00019999632216381234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 5.5455	Cost: 22.72s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 4.3808	Cost: 6.06s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 4.1379	Cost: 6.59s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 4.0971	Cost: 5.85s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 4.2276	Cost: 5.77s
Train Epoch: 274 	Average Loss: 4.4248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8048

Learning rate: 0.00019999629517077644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 5.7850	Cost: 26.91s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 4.2403	Cost: 6.35s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 4.4844	Cost: 10.50s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 4.4066	Cost: 5.94s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 4.4104	Cost: 6.59s
Train Epoch: 275 	Average Loss: 4.5361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9565

Learning rate: 0.00019999626807904816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 5.7372	Cost: 24.23s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 4.4335	Cost: 6.18s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 4.3963	Cost: 8.44s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 4.1311	Cost: 5.86s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 3.9958	Cost: 8.13s
Train Epoch: 276 	Average Loss: 4.4428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6698

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999962408886275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 5.5203	Cost: 26.49s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 4.2709	Cost: 6.04s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 4.2096	Cost: 7.08s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 3.9696	Cost: 5.82s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 3.9575	Cost: 7.94s
Train Epoch: 277 	Average Loss: 4.2546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6262

Saving model as e277_model.pt & e277_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999621359951451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 5.5056	Cost: 22.14s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 4.2186	Cost: 6.08s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 4.1025	Cost: 9.52s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 3.9579	Cost: 7.50s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 4.1290	Cost: 15.17s
Train Epoch: 278 	Average Loss: 4.2565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6517

Learning rate: 0.00019999618621170925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 5.5084	Cost: 26.03s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 4.2151	Cost: 6.01s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 4.0634	Cost: 7.16s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 4.1028	Cost: 5.96s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 4.0534	Cost: 7.76s
Train Epoch: 279 	Average Loss: 4.2402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5995

Saving model as e279_model.pt & e279_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999615872521166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 5.6020	Cost: 22.79s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 4.0813	Cost: 6.20s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 3.9580	Cost: 8.88s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 3.7384	Cost: 6.32s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 3.9253	Cost: 11.62s
Train Epoch: 280 	Average Loss: 4.1460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5347

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999613114002183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 5.5435	Cost: 23.40s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 4.0292	Cost: 6.30s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 4.0473	Cost: 10.73s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 3.8062	Cost: 6.16s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 3.8300	Cost: 11.38s
Train Epoch: 281 	Average Loss: 4.1137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5005

Saving model as e281_model.pt & e281_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999961034561398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 5.4221	Cost: 25.91s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 4.1241	Cost: 5.97s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 4.0050	Cost: 7.87s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 3.8961	Cost: 6.00s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 3.8700	Cost: 8.19s
Train Epoch: 282 	Average Loss: 4.1468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5802

Learning rate: 0.0001999960756735655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 5.4510	Cost: 22.71s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 3.9370	Cost: 6.01s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 3.8908	Cost: 7.93s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 3.6887	Cost: 5.73s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 3.7409	Cost: 7.04s
Train Epoch: 283 	Average Loss: 4.0259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4290

Saving model as e283_model.pt & e283_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999960477922991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 5.5520	Cost: 27.29s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 3.8833	Cost: 6.18s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 3.9293	Cost: 9.80s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 3.9299	Cost: 6.10s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 3.8478	Cost: 5.69s
Train Epoch: 284 	Average Loss: 4.0517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5441

Learning rate: 0.00019999601981234054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 5.6043	Cost: 23.38s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 3.8918	Cost: 6.15s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 3.8406	Cost: 9.61s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 3.7473	Cost: 5.78s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 3.7892	Cost: 7.47s
Train Epoch: 285 	Average Loss: 4.0014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4593

Learning rate: 0.00019999599173368987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 5.4277	Cost: 25.46s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 4.0474	Cost: 7.85s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 3.8047	Cost: 13.66s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 3.6102	Cost: 6.78s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 3.7327	Cost: 10.36s
Train Epoch: 286 	Average Loss: 3.9716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4221

Saving model as e286_model.pt & e286_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999596355634708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 5.5778	Cost: 25.49s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 3.8128	Cost: 6.05s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 3.7929	Cost: 7.06s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 3.5440	Cost: 5.96s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 3.7317	Cost: 9.72s
Train Epoch: 287 	Average Loss: 3.9392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5433

Learning rate: 0.00019999593528031228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 5.4954	Cost: 27.31s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 4.0258	Cost: 6.23s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 4.0118	Cost: 8.50s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 3.7848	Cost: 5.97s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 3.9171	Cost: 6.59s
Train Epoch: 288 	Average Loss: 4.0961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5737

Learning rate: 0.0001999959069055854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 5.3025	Cost: 22.57s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 4.0597	Cost: 6.09s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 3.9001	Cost: 6.85s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 3.6475	Cost: 6.51s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 3.7009	Cost: 9.06s
Train Epoch: 289 	Average Loss: 3.9620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3571

Saving model as e289_model.pt & e289_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999587843216654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 5.0311	Cost: 28.01s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 3.6057	Cost: 5.98s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 3.7153	Cost: 7.65s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 3.5621	Cost: 6.01s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 3.4532	Cost: 10.42s
Train Epoch: 290 	Average Loss: 3.7921
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3958

Learning rate: 0.00019999584986005571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 5.3115	Cost: 22.79s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 3.6750	Cost: 6.01s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 3.6702	Cost: 7.01s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 3.5214	Cost: 6.50s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 3.4092	Cost: 10.31s
Train Epoch: 291 	Average Loss: 3.7903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2312

Saving model as e291_model.pt & e291_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999582118925292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 5.1860	Cost: 31.53s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 3.5392	Cost: 6.15s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 3.5220	Cost: 11.04s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 3.3974	Cost: 6.04s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 3.3399	Cost: 7.89s
Train Epoch: 292 	Average Loss: 3.6857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2635

Learning rate: 0.00019999579241975824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 5.1074	Cost: 22.83s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 3.6847	Cost: 6.26s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 3.5753	Cost: 11.05s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 3.3861	Cost: 6.12s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 3.5847	Cost: 10.89s
Train Epoch: 293 	Average Loss: 3.7231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3051

Learning rate: 0.00019999576355157165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 5.2809	Cost: 23.53s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 3.5482	Cost: 6.01s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 3.5100	Cost: 6.76s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 3.2746	Cost: 5.89s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 3.3927	Cost: 6.16s
Train Epoch: 294 	Average Loss: 3.6243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2957

Learning rate: 0.0001999957345846932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 5.3277	Cost: 32.13s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 3.4335	Cost: 10.21s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 3.5625	Cost: 13.78s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 3.2851	Cost: 6.41s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 3.6102	Cost: 10.02s
Train Epoch: 295 	Average Loss: 3.6453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3457

Learning rate: 0.0001999957055191229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 5.0815	Cost: 24.20s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 3.5927	Cost: 6.04s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 3.9864	Cost: 7.46s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 3.6364	Cost: 5.74s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 3.6994	Cost: 5.87s
Train Epoch: 296 	Average Loss: 3.8692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4529

Learning rate: 0.0001999956763548608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 5.4629	Cost: 27.24s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 3.9016	Cost: 6.48s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 3.6557	Cost: 10.97s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 3.3450	Cost: 5.78s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 3.2937	Cost: 6.79s
Train Epoch: 297 	Average Loss: 3.7486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2415

Learning rate: 0.00019999564709190693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 5.1849	Cost: 23.37s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 3.6546	Cost: 6.02s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 3.4640	Cost: 7.80s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 3.2623	Cost: 5.85s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 3.4371	Cost: 6.02s
Train Epoch: 298 	Average Loss: 3.6198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2630

Learning rate: 0.00019999561773026132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 5.0725	Cost: 27.63s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 3.4564	Cost: 6.18s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 3.3584	Cost: 8.42s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 3.2769	Cost: 5.83s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 3.2273	Cost: 6.20s
Train Epoch: 299 	Average Loss: 3.5526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2050

Saving model as e299_model.pt & e299_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999558826992397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 5.0239	Cost: 22.38s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 3.3090	Cost: 6.04s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 3.2190	Cost: 7.66s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 3.3692	Cost: 5.82s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 3.2704	Cost: 8.93s
Train Epoch: 300 	Average Loss: 3.5014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1912

Saving model as e300_model.pt & e300_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999555871089494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 5.2380	Cost: 30.21s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 3.3193	Cost: 6.22s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 3.2386	Cost: 8.78s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 3.2897	Cost: 5.78s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 3.2297	Cost: 6.78s
Train Epoch: 301 	Average Loss: 3.4812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1070

Saving model as e301_model.pt & e301_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999552905317427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 5.0336	Cost: 27.40s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 3.3086	Cost: 6.17s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 3.1638	Cost: 7.08s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 3.0158	Cost: 5.99s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 3.2073	Cost: 7.70s
Train Epoch: 302 	Average Loss: 3.4028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0714

Saving model as e302_model.pt & e302_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999549929676196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 5.0037	Cost: 24.06s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 3.2683	Cost: 6.16s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 3.2508	Cost: 10.91s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 3.1321	Cost: 6.12s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 3.0912	Cost: 9.46s
Train Epoch: 303 	Average Loss: 3.3435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9422

Saving model as e303_model.pt & e303_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999546944165803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 4.8428	Cost: 23.16s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 3.1915	Cost: 6.12s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 3.1314	Cost: 8.04s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 3.0097	Cost: 5.69s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 3.1965	Cost: 5.93s
Train Epoch: 304 	Average Loss: 3.2717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9357

Saving model as e304_model.pt & e304_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999543948786254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 5.0633	Cost: 28.82s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 3.1699	Cost: 8.15s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 3.2694	Cost: 11.31s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 3.1785	Cost: 6.34s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 3.2106	Cost: 10.13s
Train Epoch: 305 	Average Loss: 3.3786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0919

Learning rate: 0.0001999954094353755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 5.2062	Cost: 22.99s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 3.2177	Cost: 6.21s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 3.2296	Cost: 8.56s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 3.4559	Cost: 5.86s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 3.3838	Cost: 6.46s
Train Epoch: 306 	Average Loss: 3.5223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2035

Learning rate: 0.00019999537928419694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 5.3465	Cost: 22.49s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 3.3784	Cost: 6.04s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 3.2368	Cost: 8.33s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 3.2174	Cost: 6.62s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 3.3227	Cost: 11.58s
Train Epoch: 307 	Average Loss: 3.5051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1928

Learning rate: 0.00019999534903432692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 4.7295	Cost: 23.47s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 3.3695	Cost: 6.12s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 3.0428	Cost: 8.71s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 2.8261	Cost: 6.18s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 3.0675	Cost: 6.14s
Train Epoch: 308 	Average Loss: 3.3274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9810

Learning rate: 0.00019999531868576542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 4.8942	Cost: 22.95s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 3.0221	Cost: 6.41s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 3.2315	Cost: 10.56s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 2.8969	Cost: 6.40s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 2.9484	Cost: 11.59s
Train Epoch: 309 	Average Loss: 3.2174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9192

Saving model as e309_model.pt & e309_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999528823851252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 5.0507	Cost: 23.94s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 3.3635	Cost: 6.18s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 3.0629	Cost: 7.90s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 2.9439	Cost: 5.85s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 2.9466	Cost: 5.89s
Train Epoch: 310 	Average Loss: 3.2287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9402

Learning rate: 0.00019999525769256822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 4.6814	Cost: 46.19s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 2.9163	Cost: 6.34s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 3.0360	Cost: 9.36s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 2.8082	Cost: 5.73s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 2.8771	Cost: 5.68s
Train Epoch: 311 	Average Loss: 3.1239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8722

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999522704793255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 4.6109	Cost: 23.16s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 3.0040	Cost: 6.06s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 2.9026	Cost: 9.12s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 2.8202	Cost: 6.15s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 2.8611	Cost: 8.51s
Train Epoch: 312 	Average Loss: 3.0956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8865

Learning rate: 0.00019999519630460553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 4.8036	Cost: 26.79s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 3.0035	Cost: 6.51s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 2.7680	Cost: 10.77s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 2.7379	Cost: 6.21s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 2.7984	Cost: 11.80s
Train Epoch: 313 	Average Loss: 3.0464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8778

Learning rate: 0.00019999516546258725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 4.7564	Cost: 22.81s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 2.9557	Cost: 6.00s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 2.8236	Cost: 8.05s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 2.8743	Cost: 6.26s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 2.7262	Cost: 10.36s
Train Epoch: 314 	Average Loss: 3.0879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8022

Saving model as e314_model.pt & e314_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999513452187764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 4.5763	Cost: 22.77s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 3.0212	Cost: 6.10s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 3.0832	Cost: 7.65s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 2.8167	Cost: 5.85s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 2.7680	Cost: 6.35s
Train Epoch: 315 	Average Loss: 3.1032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7505

Saving model as e315_model.pt & e315_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999951034824768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 4.8443	Cost: 45.23s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 2.7760	Cost: 7.71s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 2.6838	Cost: 11.24s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 2.5735	Cost: 5.83s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 2.7091	Cost: 6.83s
Train Epoch: 316 	Average Loss: 2.9742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7774

Learning rate: 0.00019999507234438478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 4.9024	Cost: 23.71s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 2.8300	Cost: 6.02s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 2.9648	Cost: 7.60s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 2.6735	Cost: 5.87s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 2.5967	Cost: 6.44s
Train Epoch: 317 	Average Loss: 2.9781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6849

Saving model as e317_model.pt & e317_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999504110760157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 4.5715	Cost: 26.97s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 2.8999	Cost: 6.14s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 3.0223	Cost: 7.64s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 2.8335	Cost: 5.81s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 2.6662	Cost: 6.63s
Train Epoch: 318 	Average Loss: 2.9775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7476

Learning rate: 0.0001999950097721272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 4.8826	Cost: 25.61s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 2.8529	Cost: 6.12s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 2.7640	Cost: 7.62s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 2.6004	Cost: 6.02s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 2.6275	Cost: 5.65s
Train Epoch: 319 	Average Loss: 2.9088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6665

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999497833796175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 4.4216	Cost: 27.40s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 2.8374	Cost: 5.99s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 2.5472	Cost: 7.82s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 2.5846	Cost: 5.98s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 2.6457	Cost: 7.88s
Train Epoch: 320 	Average Loss: 2.8510
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6652

Saving model as e320_model.pt & e320_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999494680510515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 4.5307	Cost: 22.25s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 2.6997	Cost: 6.33s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 2.5620	Cost: 10.85s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 2.5127	Cost: 7.03s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 2.4143	Cost: 12.10s
Train Epoch: 321 	Average Loss: 2.8105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5999

Saving model as e321_model.pt & e321_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999491517355754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 4.6971	Cost: 26.56s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 2.6871	Cost: 6.06s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 2.6238	Cost: 8.92s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 2.5919	Cost: 5.84s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 2.6578	Cost: 7.71s
Train Epoch: 322 	Average Loss: 2.8514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6506

Learning rate: 0.00019999488344331888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 4.7808	Cost: 39.37s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 2.8087	Cost: 7.76s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 2.7822	Cost: 11.98s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 2.3864	Cost: 6.20s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 2.4054	Cost: 10.52s
Train Epoch: 323 	Average Loss: 2.8030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6432

Learning rate: 0.00019999485161438922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 4.2342	Cost: 23.03s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 2.6518	Cost: 6.03s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 2.6256	Cost: 7.86s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 2.4239	Cost: 6.09s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 2.4873	Cost: 8.09s
Train Epoch: 324 	Average Loss: 2.7647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5757

Saving model as e324_model.pt & e324_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999948196867686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 4.5531	Cost: 26.12s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 2.5828	Cost: 6.10s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 2.5520	Cost: 6.65s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 2.3567	Cost: 6.05s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 2.4317	Cost: 7.93s
Train Epoch: 325 	Average Loss: 2.7308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6315

Learning rate: 0.00019999478766045706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 4.5142	Cost: 22.90s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 2.4222	Cost: 6.33s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 2.5123	Cost: 10.25s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 2.5056	Cost: 6.31s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 2.4652	Cost: 11.58s
Train Epoch: 326 	Average Loss: 2.7380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6807

Learning rate: 0.00019999475553545462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 4.5535	Cost: 26.68s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 2.7435	Cost: 6.28s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 2.5054	Cost: 7.91s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 2.4210	Cost: 5.84s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 2.2866	Cost: 6.41s
Train Epoch: 327 	Average Loss: 2.7893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4490

Saving model as e327_model.pt & e327_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999947233117613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 4.3848	Cost: 22.81s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 2.5542	Cost: 5.99s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 2.3474	Cost: 7.52s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 2.4916	Cost: 6.10s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 2.5633	Cost: 9.77s
Train Epoch: 328 	Average Loss: 2.6877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5381

Learning rate: 0.00019999469098937715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 4.3821	Cost: 25.92s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 2.4770	Cost: 6.03s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 2.3921	Cost: 7.29s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 2.2381	Cost: 5.97s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 2.1887	Cost: 8.09s
Train Epoch: 329 	Average Loss: 2.6209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3990

Saving model as e329_model.pt & e329_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999465856830218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 4.5310	Cost: 23.02s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 2.3284	Cost: 6.72s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 2.3257	Cost: 11.06s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 2.3735	Cost: 6.19s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 2.2752	Cost: 11.24s
Train Epoch: 330 	Average Loss: 2.5628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5309

Learning rate: 0.00019999462604853647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 4.5023	Cost: 23.16s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 2.5788	Cost: 6.16s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 2.3567	Cost: 9.39s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 2.2990	Cost: 5.95s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 2.2578	Cost: 7.72s
Train Epoch: 331 	Average Loss: 2.5722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4226

Learning rate: 0.00019999459343008003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 4.3120	Cost: 22.55s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 2.5343	Cost: 6.18s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 2.2793	Cost: 11.69s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 2.2800	Cost: 7.28s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 2.3370	Cost: 11.75s
Train Epoch: 332 	Average Loss: 2.5394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3724

Saving model as e332_model.pt & e332_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999456071293284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 4.3783	Cost: 27.38s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 2.3325	Cost: 6.19s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 2.1199	Cost: 9.62s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 2.1135	Cost: 5.68s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 2.1573	Cost: 6.39s
Train Epoch: 333 	Average Loss: 2.4448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3201

Saving model as e333_model.pt & e333_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999452789709498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 4.1070	Cost: 26.66s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 2.2018	Cost: 6.16s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 2.1884	Cost: 6.77s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 2.1240	Cost: 6.00s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 1.9964	Cost: 7.62s
Train Epoch: 334 	Average Loss: 2.3836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3904

Learning rate: 0.0001999944949825665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 4.5905	Cost: 22.20s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 2.3406	Cost: 6.05s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 2.2221	Cost: 7.95s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 2.2049	Cost: 6.23s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 2.2531	Cost: 11.63s
Train Epoch: 335 	Average Loss: 2.4941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3989

Learning rate: 0.0001999944619693474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 4.1471	Cost: 29.03s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 2.4520	Cost: 6.19s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 2.3660	Cost: 8.52s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 2.1532	Cost: 5.79s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 2.0765	Cost: 6.26s
Train Epoch: 336 	Average Loss: 2.4798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2779

Saving model as e336_model.pt & e336_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999442885743776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 4.2710	Cost: 23.17s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 2.2286	Cost: 6.05s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 2.1620	Cost: 8.70s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 2.0495	Cost: 5.88s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 2.1656	Cost: 8.16s
Train Epoch: 337 	Average Loss: 2.3319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2938

Learning rate: 0.00019999439564683753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 4.2800	Cost: 26.86s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 2.1841	Cost: 6.09s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 2.1153	Cost: 7.17s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 2.0180	Cost: 6.15s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 2.0114	Cost: 7.79s
Train Epoch: 338 	Average Loss: 2.2797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2946

Learning rate: 0.0001999943623375468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 4.0323	Cost: 24.90s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 2.1337	Cost: 6.27s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 2.0914	Cost: 9.04s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 2.0188	Cost: 5.92s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 1.9220	Cost: 6.00s
Train Epoch: 339 	Average Loss: 2.2908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2460

Saving model as e339_model.pt & e339_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999943289295656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 4.0959	Cost: 24.38s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 1.9551	Cost: 6.08s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 2.1042	Cost: 8.11s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 1.9924	Cost: 6.01s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 1.8931	Cost: 7.21s
Train Epoch: 340 	Average Loss: 2.2339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2660

Learning rate: 0.00019999429542289394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 4.2347	Cost: 25.74s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 2.1027	Cost: 6.36s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 2.1392	Cost: 11.70s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 2.0448	Cost: 6.12s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 1.8700	Cost: 9.58s
Train Epoch: 341 	Average Loss: 2.2714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1998

Saving model as e341_model.pt & e341_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999426181753187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 4.0145	Cost: 22.60s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 1.9675	Cost: 6.46s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 1.9368	Cost: 10.37s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 2.0128	Cost: 6.22s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 1.9694	Cost: 11.28s
Train Epoch: 342 	Average Loss: 2.1965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2009

Learning rate: 0.0001999942281134794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 4.2862	Cost: 24.84s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 2.0238	Cost: 6.19s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 2.0381	Cost: 8.51s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 1.8621	Cost: 6.07s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 1.8925	Cost: 6.07s
Train Epoch: 343 	Average Loss: 2.1569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1751

Saving model as e343_model.pt & e343_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999941943107366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 4.0702	Cost: 25.37s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 2.1390	Cost: 6.37s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 1.8595	Cost: 10.96s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 1.9996	Cost: 6.03s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 1.8587	Cost: 8.06s
Train Epoch: 344 	Average Loss: 2.1670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1974

Learning rate: 0.00019999416040930349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 4.4980	Cost: 23.79s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 2.1683	Cost: 6.02s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 2.0378	Cost: 8.14s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 1.8652	Cost: 6.01s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 1.8130	Cost: 5.94s
Train Epoch: 345 	Average Loss: 2.2123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2729

Learning rate: 0.0001999941264091801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 4.2455	Cost: 23.27s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 1.9707	Cost: 6.42s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 2.0456	Cost: 11.58s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 2.1226	Cost: 6.16s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 2.0451	Cost: 11.59s
Train Epoch: 346 	Average Loss: 2.2859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1634

Saving model as e346_model.pt & e346_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999409231036646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 4.0239	Cost: 24.21s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 2.1426	Cost: 6.04s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 2.1350	Cost: 8.69s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 1.9487	Cost: 6.26s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 1.9067	Cost: 11.66s
Train Epoch: 347 	Average Loss: 2.2357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1491

Saving model as e347_model.pt & e347_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999940581128626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 4.1763	Cost: 33.61s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 1.9678	Cost: 7.81s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 1.9429	Cost: 9.70s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 1.9547	Cost: 5.87s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 1.7719	Cost: 6.34s
Train Epoch: 348 	Average Loss: 2.1433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1103

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999402381666855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 4.0110	Cost: 23.75s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 1.9940	Cost: 6.08s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 2.0678	Cost: 8.14s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 1.8974	Cost: 5.81s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 1.7419	Cost: 6.10s
Train Epoch: 349 	Average Loss: 2.1495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1261

Learning rate: 0.0001999939894217844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 4.2323	Cost: 32.16s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 1.9692	Cost: 9.55s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 1.7936	Cost: 12.30s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 1.7151	Cost: 6.25s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 1.5758	Cost: 9.95s
Train Epoch: 350 	Average Loss: 2.0162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0346

Saving model as e350_model.pt & e350_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999939549282101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 3.5570	Cost: 22.65s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 1.8496	Cost: 6.03s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 1.6148	Cost: 8.01s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 1.5777	Cost: 5.87s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 1.5467	Cost: 7.74s
Train Epoch: 351 	Average Loss: 1.8931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9431

Saving model as e351_model.pt & e351_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999392033594573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 3.9042	Cost: 24.15s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 1.8505	Cost: 6.30s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 1.8399	Cost: 8.35s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 1.7162	Cost: 5.99s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 1.6824	Cost: 5.95s
Train Epoch: 352 	Average Loss: 1.9673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9872

Learning rate: 0.0001999938856449913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 3.8918	Cost: 22.39s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 1.7710	Cost: 6.85s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 1.6182	Cost: 11.43s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 1.6594	Cost: 6.30s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 1.6169	Cost: 11.43s
Train Epoch: 353 	Average Loss: 1.9491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0009

Learning rate: 0.00019999385085534688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 4.0103	Cost: 25.47s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 1.8094	Cost: 6.10s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 1.9989	Cost: 8.17s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 1.9030	Cost: 5.73s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 1.6591	Cost: 6.25s
Train Epoch: 354 	Average Loss: 2.1018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0664

Learning rate: 0.00019999381596701247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 3.7835	Cost: 28.66s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 1.8068	Cost: 7.55s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 1.6780	Cost: 12.36s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 1.5801	Cost: 6.88s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 1.5811	Cost: 10.66s
Train Epoch: 355 	Average Loss: 1.8467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9333

Saving model as e355_model.pt & e355_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999378097998813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 3.7861	Cost: 26.12s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 1.6903	Cost: 6.19s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 1.6083	Cost: 8.68s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 1.5844	Cost: 5.89s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 1.3916	Cost: 7.13s
Train Epoch: 356 	Average Loss: 1.8006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8482

Saving model as e356_model.pt & e356_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999374589427387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 3.6004	Cost: 26.64s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 1.5988	Cost: 6.18s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 1.5650	Cost: 8.65s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 1.3604	Cost: 5.75s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 1.4141	Cost: 6.87s
Train Epoch: 357 	Average Loss: 1.7550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8374

Saving model as e357_model.pt & e357_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999371070986973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 3.8208	Cost: 22.28s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 1.6575	Cost: 6.81s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 1.5217	Cost: 10.28s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 1.4216	Cost: 6.15s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 1.6101	Cost: 11.12s
Train Epoch: 358 	Average Loss: 1.7466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0310

Learning rate: 0.00019999367542677577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 3.9612	Cost: 24.26s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 1.8604	Cost: 6.02s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 1.8677	Cost: 8.44s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 1.6770	Cost: 5.89s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 1.4205	Cost: 6.55s
Train Epoch: 359 	Average Loss: 1.9504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8292

Saving model as e359_model.pt & e359_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999364004499203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 3.7293	Cost: 23.33s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 1.6209	Cost: 6.32s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 1.3360	Cost: 10.86s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 1.3528	Cost: 6.14s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 1.0930	Cost: 10.40s
Train Epoch: 360 	Average Loss: 1.6612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7399

Saving model as e360_model.pt & e360_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999936045645185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 3.7087	Cost: 24.02s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 1.5662	Cost: 5.98s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 1.3969	Cost: 7.91s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 1.3190	Cost: 5.68s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 1.3757	Cost: 6.51s
Train Epoch: 361 	Average Loss: 1.6292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7879

Learning rate: 0.00019999356898535523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 3.8010	Cost: 26.24s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 1.5661	Cost: 6.49s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 1.3220	Cost: 11.05s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 1.2588	Cost: 6.31s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 1.1408	Cost: 9.26s
Train Epoch: 362 	Average Loss: 1.5828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7344

Saving model as e362_model.pt & e362_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999935333075023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 3.7153	Cost: 23.69s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 1.3663	Cost: 6.02s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 1.3858	Cost: 8.06s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 1.5107	Cost: 5.73s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 1.3870	Cost: 5.97s
Train Epoch: 363 	Average Loss: 1.6663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8927

Learning rate: 0.0001999934975309597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 3.6582	Cost: 25.00s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 1.7854	Cost: 6.26s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 1.4783	Cost: 11.84s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 1.6380	Cost: 5.98s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 1.4918	Cost: 7.65s
Train Epoch: 364 	Average Loss: 1.7885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9058

Learning rate: 0.00019999346165572743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 3.5146	Cost: 23.70s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 1.5552	Cost: 6.09s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 1.3378	Cost: 7.75s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 1.1050	Cost: 5.90s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 1.1272	Cost: 5.74s
Train Epoch: 365 	Average Loss: 1.5443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6670

Saving model as e365_model.pt & e365_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999342568180562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 3.5036	Cost: 24.29s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 1.2791	Cost: 6.06s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 1.1605	Cost: 9.37s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 1.0709	Cost: 6.05s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 1.1073	Cost: 6.21s
Train Epoch: 366 	Average Loss: 1.4111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6892

Learning rate: 0.00019999338960919423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 3.8414	Cost: 22.04s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 1.1763	Cost: 6.35s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 1.1345	Cost: 9.28s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 1.0238	Cost: 6.31s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 1.1947	Cost: 11.23s
Train Epoch: 367 	Average Loss: 1.4394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7319

Learning rate: 0.0001999933534378933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 3.4279	Cost: 25.10s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 1.5529	Cost: 6.08s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 1.1480	Cost: 7.58s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 1.1703	Cost: 5.99s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 1.2944	Cost: 7.22s
Train Epoch: 368 	Average Loss: 1.5230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8760

Learning rate: 0.00019999331716790292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 3.8149	Cost: 22.18s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 1.6145	Cost: 5.99s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 1.3467	Cost: 7.78s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 1.1874	Cost: 6.46s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 0.9301	Cost: 10.71s
Train Epoch: 369 	Average Loss: 1.5556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6445

Saving model as e369_model.pt & e369_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999328079922307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 3.4815	Cost: 24.52s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 1.3399	Cost: 6.33s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 1.1949	Cost: 11.55s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 1.6320	Cost: 6.20s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 1.4331	Cost: 8.95s
Train Epoch: 370 	Average Loss: 1.6266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9169

Learning rate: 0.00019999324433185383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 3.6709	Cost: 22.40s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 1.3996	Cost: 6.92s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 1.2787	Cost: 10.83s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 1.2340	Cost: 6.34s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 1.0755	Cost: 11.75s
Train Epoch: 371 	Average Loss: 1.5109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6443

Saving model as e371_model.pt & e371_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999932077657952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 3.7017	Cost: 19.70s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 1.2716	Cost: 5.87s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 1.0583	Cost: 10.38s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 1.0513	Cost: 5.99s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 1.0466	Cost: 6.57s
Train Epoch: 372 	Average Loss: 1.3648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5302

Saving model as e372_model.pt & e372_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999317110104724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 3.5826	Cost: 24.85s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 1.3573	Cost: 9.40s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 1.3251	Cost: 13.74s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 1.0513	Cost: 7.42s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 0.8030	Cost: 11.15s
Train Epoch: 373 	Average Loss: 1.3485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4896

Saving model as e373_model.pt & e373_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999313433760997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 3.4013	Cost: 26.61s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 1.1601	Cost: 6.22s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 1.0603	Cost: 8.70s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 0.9314	Cost: 5.89s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 0.6989	Cost: 7.91s
Train Epoch: 374 	Average Loss: 1.2428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4248

Saving model as e374_model.pt & e374_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999309747548342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 3.3220	Cost: 26.28s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 0.9329	Cost: 6.04s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 0.9920	Cost: 6.60s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 0.9093	Cost: 6.02s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 0.9250	Cost: 8.02s
Train Epoch: 375 	Average Loss: 1.1902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4663

Learning rate: 0.00019999306051466764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 3.3737	Cost: 26.64s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 1.0235	Cost: 6.27s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 1.0051	Cost: 11.74s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 0.6855	Cost: 6.69s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 0.6803	Cost: 13.19s
Train Epoch: 376 	Average Loss: 1.1372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4648

Learning rate: 0.0001999930234551627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 3.3999	Cost: 26.76s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 1.0786	Cost: 6.13s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 0.9297	Cost: 8.43s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 0.6249	Cost: 5.76s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 0.7486	Cost: 7.33s
Train Epoch: 377 	Average Loss: 1.1227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4249

Learning rate: 0.00019999298629696857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 3.4273	Cost: 26.44s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 1.0559	Cost: 6.19s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 0.8591	Cost: 11.05s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 0.7998	Cost: 6.30s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 0.8905	Cost: 12.46s
Train Epoch: 378 	Average Loss: 1.1414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5176

Learning rate: 0.00019999294904008533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 3.3673	Cost: 26.73s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 1.1097	Cost: 5.99s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 1.1066	Cost: 7.71s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 0.8158	Cost: 6.10s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 0.9291	Cost: 8.48s
Train Epoch: 379 	Average Loss: 1.2466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5496

Learning rate: 0.000199992911684513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 3.1952	Cost: 22.50s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 1.1944	Cost: 6.07s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 0.8579	Cost: 7.65s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 0.6868	Cost: 6.46s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 0.5257	Cost: 9.67s
Train Epoch: 380 	Average Loss: 1.1146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3121

Saving model as e380_model.pt & e380_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999928742302516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 2.8973	Cost: 25.26s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 0.9322	Cost: 6.02s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 0.7087	Cost: 8.79s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 0.6905	Cost: 6.03s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 0.6860	Cost: 7.06s
Train Epoch: 381 	Average Loss: 0.9994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2907

Saving model as e381_model.pt & e381_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999283667730122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 3.2763	Cost: 24.94s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 1.1030	Cost: 7.41s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 1.0057	Cost: 10.75s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 0.8228	Cost: 6.29s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 0.5908	Cost: 12.37s
Train Epoch: 382 	Average Loss: 1.1045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3013

Learning rate: 0.00019999279902566184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 3.2238	Cost: 23.91s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 0.9303	Cost: 6.19s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 0.7596	Cost: 8.87s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 0.6746	Cost: 6.09s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 0.8195	Cost: 6.26s
Train Epoch: 383 	Average Loss: 1.0206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4009

Learning rate: 0.0001999927612753335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 3.3678	Cost: 32.29s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 0.9468	Cost: 11.74s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 0.6420	Cost: 11.93s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 0.5011	Cost: 6.82s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 0.5424	Cost: 10.16s
Train Epoch: 384 	Average Loss: 0.9440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2126

Saving model as e384_model.pt & e384_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999272342631632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 3.3153	Cost: 24.52s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 0.6534	Cost: 6.03s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 0.6271	Cost: 10.61s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 0.5570	Cost: 6.48s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 0.4583	Cost: 11.20s
Train Epoch: 385 	Average Loss: 0.8344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2593

Learning rate: 0.00019999268547861025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 3.1593	Cost: 25.01s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 0.9270	Cost: 6.84s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 0.5450	Cost: 11.74s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 0.5543	Cost: 6.22s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 0.5764	Cost: 11.27s
Train Epoch: 386 	Average Loss: 0.9248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2443

Learning rate: 0.00019999264743221536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 3.4563	Cost: 24.36s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 0.5838	Cost: 6.91s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 0.6500	Cost: 10.59s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 0.4298	Cost: 6.27s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 0.4324	Cost: 11.00s
Train Epoch: 387 	Average Loss: 0.8255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1487

Saving model as e387_model.pt & e387_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999260928713167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 3.0810	Cost: 23.74s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 0.6233	Cost: 6.03s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 0.5991	Cost: 8.61s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 0.3814	Cost: 5.85s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 0.3179	Cost: 8.05s
Train Epoch: 388 	Average Loss: 0.7904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2215

Learning rate: 0.00019999257104335924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 3.0457	Cost: 29.27s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 0.6370	Cost: 6.51s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 0.6252	Cost: 8.88s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 0.5949	Cost: 5.94s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 0.5159	Cost: 8.12s
Train Epoch: 389 	Average Loss: 0.8413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1975

Learning rate: 0.00019999253270089811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 3.0007	Cost: 29.87s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 0.6534	Cost: 8.65s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 0.3723	Cost: 12.64s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 0.3971	Cost: 6.83s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 0.3822	Cost: 13.84s
Train Epoch: 390 	Average Loss: 0.7789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1279

Saving model as e390_model.pt & e390_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999924942597483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 3.2710	Cost: 22.49s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 0.8794	Cost: 6.24s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 0.7581	Cost: 9.73s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 0.6254	Cost: 6.09s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 0.3486	Cost: 8.09s
Train Epoch: 391 	Average Loss: 0.8735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2933

Learning rate: 0.00019999245571990988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 3.2849	Cost: 25.66s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 1.1470	Cost: 9.29s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 0.7557	Cost: 16.03s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 0.6060	Cost: 7.85s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 0.5290	Cost: 10.93s
Train Epoch: 392 	Average Loss: 1.0423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1437

Learning rate: 0.00019999241708138285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 3.2893	Cost: 24.91s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 0.7989	Cost: 6.15s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 0.4928	Cost: 8.34s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 0.3404	Cost: 6.13s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 0.5480	Cost: 6.79s
Train Epoch: 393 	Average Loss: 0.8243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1683

Learning rate: 0.00019999237834416724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 3.1905	Cost: 23.36s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 0.7855	Cost: 6.07s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 0.4896	Cost: 9.36s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 0.2957	Cost: 6.29s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 0.2198	Cost: 11.26s
Train Epoch: 394 	Average Loss: 0.7082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0468

Saving model as e394_model.pt & e394_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999923395082631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 3.0835	Cost: 27.30s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 0.5392	Cost: 6.32s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 0.5746	Cost: 9.61s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 0.3301	Cost: 6.16s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 0.1671	Cost: 9.09s
Train Epoch: 395 	Average Loss: 0.6656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0226

Saving model as e395_model.pt & e395_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999923005736705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 3.2032	Cost: 30.57s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 0.2865	Cost: 5.90s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 0.3116	Cost: 8.21s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 0.2332	Cost: 6.15s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 0.0967	Cost: 7.90s
Train Epoch: 396 	Average Loss: 0.5415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9326

Saving model as e396_model.pt & e396_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999226154038944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 2.7403	Cost: 28.27s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 0.4313	Cost: 7.26s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 0.4969	Cost: 10.72s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 0.3975	Cost: 6.11s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 0.2064	Cost: 8.24s
Train Epoch: 397 	Average Loss: 0.6192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9965

Learning rate: 0.00019999222240841996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 3.0465	Cost: 24.87s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 0.5008	Cost: 6.12s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 0.2513	Cost: 8.37s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 0.1763	Cost: 5.82s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -0.0504	Cost: 6.81s
Train Epoch: 398 	Average Loss: 0.4586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8866

Saving model as e398_model.pt & e398_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999218317776212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 2.9479	Cost: 32.98s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 0.3063	Cost: 6.73s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 0.2825	Cost: 11.13s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 0.2463	Cost: 6.12s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 0.2224	Cost: 6.26s
Train Epoch: 399 	Average Loss: 0.5083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0880

Learning rate: 0.00019999214384841597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 2.9458	Cost: 24.16s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 0.5296	Cost: 6.27s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 0.2637	Cost: 9.75s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 0.2438	Cost: 6.06s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 0.1770	Cost: 6.70s
Train Epoch: 400 	Average Loss: 0.5519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9254

Learning rate: 0.00019999210442038154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 2.7267	Cost: 37.39s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 0.3089	Cost: 8.43s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 0.1817	Cost: 12.13s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 0.0242	Cost: 6.50s
Train Epoch: 401 [81920/90000 (91%)]	Loss: -0.0024	Cost: 10.07s
Train Epoch: 401 	Average Loss: 0.3891
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8381

Saving model as e401_model.pt & e401_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999206489365883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 3.0251	Cost: 24.09s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 0.1831	Cost: 7.22s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 0.0438	Cost: 10.70s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 0.1909	Cost: 6.33s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 0.2047	Cost: 10.89s
Train Epoch: 402 	Average Loss: 0.4248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9537

Learning rate: 0.0001999920252682479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 2.5568	Cost: 23.47s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 0.3987	Cost: 6.65s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 0.0434	Cost: 11.55s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 0.0635	Cost: 6.12s
Train Epoch: 403 [81920/90000 (91%)]	Loss: -0.0166	Cost: 11.30s
Train Epoch: 403 	Average Loss: 0.4392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7627

Saving model as e403_model.pt & e403_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999198554414882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 2.4752	Cost: 30.93s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 0.1760	Cost: 6.10s
Train Epoch: 404 [40960/90000 (45%)]	Loss: -0.1664	Cost: 8.44s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 0.0482	Cost: 6.01s
Train Epoch: 404 [81920/90000 (91%)]	Loss: -0.1827	Cost: 10.85s
Train Epoch: 404 	Average Loss: 0.2820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7724

Learning rate: 0.0001999919457213616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 2.4957	Cost: 23.48s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 0.2710	Cost: 6.14s
Train Epoch: 405 [40960/90000 (45%)]	Loss: -0.0397	Cost: 9.78s
Train Epoch: 405 [61440/90000 (68%)]	Loss: -0.1371	Cost: 9.04s
Train Epoch: 405 [81920/90000 (91%)]	Loss: -0.0344	Cost: 15.08s
Train Epoch: 405 	Average Loss: 0.3347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8434

Learning rate: 0.00019999190579988627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 2.7382	Cost: 26.70s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 0.2077	Cost: 6.03s
Train Epoch: 406 [40960/90000 (45%)]	Loss: -0.0764	Cost: 8.94s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 0.0016	Cost: 6.06s
Train Epoch: 406 [81920/90000 (91%)]	Loss: -0.2428	Cost: 7.48s
Train Epoch: 406 	Average Loss: 0.2864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7137

Saving model as e406_model.pt & e406_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999918657797229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 2.5476	Cost: 22.16s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 0.2253	Cost: 7.01s
Train Epoch: 407 [40960/90000 (45%)]	Loss: -0.0636	Cost: 10.34s
Train Epoch: 407 [61440/90000 (68%)]	Loss: -0.1946	Cost: 6.23s
Train Epoch: 407 [81920/90000 (91%)]	Loss: -0.1912	Cost: 11.50s
Train Epoch: 407 	Average Loss: 0.2195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7897

Learning rate: 0.00019999182566087152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 3.0885	Cost: 27.57s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 0.1057	Cost: 6.30s
Train Epoch: 408 [40960/90000 (45%)]	Loss: -0.1174	Cost: 10.11s
Train Epoch: 408 [61440/90000 (68%)]	Loss: -0.2136	Cost: 5.91s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 0.1508	Cost: 10.01s
Train Epoch: 408 	Average Loss: 0.3446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1083

Learning rate: 0.00019999178544333215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 3.0532	Cost: 32.13s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 0.3536	Cost: 10.65s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 0.4648	Cost: 11.31s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 0.4534	Cost: 6.85s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 0.4235	Cost: 10.60s
Train Epoch: 409 	Average Loss: 0.6819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0245

Learning rate: 0.00019999174512710485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 3.1471	Cost: 24.23s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 0.5648	Cost: 6.21s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 0.2070	Cost: 8.31s
Train Epoch: 410 [61440/90000 (68%)]	Loss: -0.0031	Cost: 6.12s
Train Epoch: 410 [81920/90000 (91%)]	Loss: -0.1512	Cost: 6.32s
Train Epoch: 410 	Average Loss: 0.4083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7417

Learning rate: 0.00019999170471218965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 2.7394	Cost: 30.97s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 0.0594	Cost: 7.12s
Train Epoch: 411 [40960/90000 (45%)]	Loss: -0.1970	Cost: 11.37s
Train Epoch: 411 [61440/90000 (68%)]	Loss: -0.2525	Cost: 6.20s
Train Epoch: 411 [81920/90000 (91%)]	Loss: -0.3102	Cost: 6.53s
Train Epoch: 411 	Average Loss: 0.1322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6450

Saving model as e411_model.pt & e411_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999916641985866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 2.7393	Cost: 26.38s
Train Epoch: 412 [20480/90000 (23%)]	Loss: -0.0896	Cost: 6.16s
Train Epoch: 412 [40960/90000 (45%)]	Loss: -0.1237	Cost: 8.05s
Train Epoch: 412 [61440/90000 (68%)]	Loss: -0.2457	Cost: 6.34s
Train Epoch: 412 [81920/90000 (91%)]	Loss: -0.3205	Cost: 6.14s
Train Epoch: 412 	Average Loss: 0.0706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6954

Learning rate: 0.00019999162358629572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 2.1798	Cost: 28.37s
Train Epoch: 413 [20480/90000 (23%)]	Loss: -0.1249	Cost: 6.78s
Train Epoch: 413 [40960/90000 (45%)]	Loss: -0.2385	Cost: 9.44s
Train Epoch: 413 [61440/90000 (68%)]	Loss: -0.2553	Cost: 6.05s
Train Epoch: 413 [81920/90000 (91%)]	Loss: -0.3329	Cost: 6.64s
Train Epoch: 413 	Average Loss: 0.0455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6722

Learning rate: 0.0001999915828753171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 2.4670	Cost: 26.05s
Train Epoch: 414 [20480/90000 (23%)]	Loss: -0.0167	Cost: 6.27s
Train Epoch: 414 [40960/90000 (45%)]	Loss: -0.1041	Cost: 9.21s
Train Epoch: 414 [61440/90000 (68%)]	Loss: -0.2313	Cost: 5.86s
Train Epoch: 414 [81920/90000 (91%)]	Loss: -0.0981	Cost: 7.06s
Train Epoch: 414 	Average Loss: 0.0910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6577

Learning rate: 0.0001999915420656507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 3.1181	Cost: 37.16s
Train Epoch: 415 [20480/90000 (23%)]	Loss: -0.0482	Cost: 18.40s
Train Epoch: 415 [40960/90000 (45%)]	Loss: -0.2301	Cost: 17.10s
Train Epoch: 415 [61440/90000 (68%)]	Loss: -0.2615	Cost: 17.04s
Train Epoch: 415 [81920/90000 (91%)]	Loss: -0.4666	Cost: 18.00s
Train Epoch: 415 	Average Loss: 0.0519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5316

Saving model as e415_model.pt & e415_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999915011572966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 2.5028	Cost: 25.59s
Train Epoch: 416 [20480/90000 (23%)]	Loss: -0.1319	Cost: 6.07s
Train Epoch: 416 [40960/90000 (45%)]	Loss: -0.1690	Cost: 8.51s
Train Epoch: 416 [61440/90000 (68%)]	Loss: -0.0962	Cost: 5.88s
Train Epoch: 416 [81920/90000 (91%)]	Loss: -0.2530	Cost: 6.64s
Train Epoch: 416 	Average Loss: 0.0445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6615

Learning rate: 0.0001999914601502549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 2.3481	Cost: 22.27s
Train Epoch: 417 [20480/90000 (23%)]	Loss: -0.0408	Cost: 6.55s
Train Epoch: 417 [40960/90000 (45%)]	Loss: -0.2671	Cost: 10.33s
Train Epoch: 417 [61440/90000 (68%)]	Loss: -0.3866	Cost: 6.40s
Train Epoch: 417 [81920/90000 (91%)]	Loss: -0.4276	Cost: 11.69s
Train Epoch: 417 	Average Loss: 0.0820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5807

Learning rate: 0.00019999141904452554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 2.3289	Cost: 24.96s
Train Epoch: 418 [20480/90000 (23%)]	Loss: -0.3126	Cost: 6.13s
Train Epoch: 418 [40960/90000 (45%)]	Loss: -0.4565	Cost: 8.35s
Train Epoch: 418 [61440/90000 (68%)]	Loss: -0.3124	Cost: 6.16s
Train Epoch: 418 [81920/90000 (91%)]	Loss: -0.4590	Cost: 5.84s
Train Epoch: 418 	Average Loss: -0.0877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4280

Saving model as e418_model.pt & e418_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999913778401086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 2.2591	Cost: 26.47s
Train Epoch: 419 [20480/90000 (23%)]	Loss: -0.1241	Cost: 6.84s
Train Epoch: 419 [40960/90000 (45%)]	Loss: -0.3719	Cost: 11.30s
Train Epoch: 419 [61440/90000 (68%)]	Loss: -0.7704	Cost: 6.21s
Train Epoch: 419 [81920/90000 (91%)]	Loss: -0.5693	Cost: 8.62s
Train Epoch: 419 	Average Loss: -0.1415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3881

Saving model as e419_model.pt & e419_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999133653700416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 2.1611	Cost: 23.31s
Train Epoch: 420 [20480/90000 (23%)]	Loss: -0.2681	Cost: 6.03s
Train Epoch: 420 [40960/90000 (45%)]	Loss: -0.5706	Cost: 7.49s
Train Epoch: 420 [61440/90000 (68%)]	Loss: -0.5040	Cost: 5.77s
Train Epoch: 420 [81920/90000 (91%)]	Loss: -0.3827	Cost: 5.81s
Train Epoch: 420 	Average Loss: -0.1584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4221

Learning rate: 0.0001999912951352122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 2.4828	Cost: 25.79s
Train Epoch: 421 [20480/90000 (23%)]	Loss: -0.3498	Cost: 6.26s
Train Epoch: 421 [40960/90000 (45%)]	Loss: -0.4937	Cost: 11.21s
Train Epoch: 421 [61440/90000 (68%)]	Loss: -0.6355	Cost: 5.88s
Train Epoch: 421 [81920/90000 (91%)]	Loss: -0.3973	Cost: 6.83s
Train Epoch: 421 	Average Loss: -0.1192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6570

Learning rate: 0.0001999912536347328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 2.5218	Cost: 25.91s
Train Epoch: 422 [20480/90000 (23%)]	Loss: -0.2802	Cost: 6.33s
Train Epoch: 422 [40960/90000 (45%)]	Loss: -0.3071	Cost: 11.23s
Train Epoch: 422 [61440/90000 (68%)]	Loss: -0.4739	Cost: 6.10s
Train Epoch: 422 [81920/90000 (91%)]	Loss: -0.6239	Cost: 8.35s
Train Epoch: 422 	Average Loss: -0.1029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5777

Learning rate: 0.00019999121203556597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 2.5543	Cost: 25.04s
Train Epoch: 423 [20480/90000 (23%)]	Loss: -0.3628	Cost: 5.92s
Train Epoch: 423 [40960/90000 (45%)]	Loss: -0.6394	Cost: 9.06s
Train Epoch: 423 [61440/90000 (68%)]	Loss: -0.5750	Cost: 6.21s
Train Epoch: 423 [81920/90000 (91%)]	Loss: -0.7074	Cost: 11.91s
Train Epoch: 423 	Average Loss: -0.2250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3526

Saving model as e423_model.pt & e423_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999911703377118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 2.0439	Cost: 43.49s
Train Epoch: 424 [20480/90000 (23%)]	Loss: -0.4905	Cost: 6.08s
Train Epoch: 424 [40960/90000 (45%)]	Loss: -0.7641	Cost: 9.34s
Train Epoch: 424 [61440/90000 (68%)]	Loss: -0.6273	Cost: 5.90s
Train Epoch: 424 [81920/90000 (91%)]	Loss: -0.7045	Cost: 5.83s
Train Epoch: 424 	Average Loss: -0.3748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3511

Saving model as e424_model.pt & e424_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999112854117028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 2.2428	Cost: 22.59s
Train Epoch: 425 [20480/90000 (23%)]	Loss: -0.3835	Cost: 6.43s
Train Epoch: 425 [40960/90000 (45%)]	Loss: -0.5181	Cost: 10.88s
Train Epoch: 425 [61440/90000 (68%)]	Loss: -0.6163	Cost: 6.32s
Train Epoch: 425 [81920/90000 (91%)]	Loss: -0.8412	Cost: 11.32s
Train Epoch: 425 	Average Loss: -0.3201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4097

Learning rate: 0.00019999108664594148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 2.4289	Cost: 24.14s
Train Epoch: 426 [20480/90000 (23%)]	Loss: -0.1241	Cost: 6.12s
Train Epoch: 426 [40960/90000 (45%)]	Loss: -0.2892	Cost: 9.18s
Train Epoch: 426 [61440/90000 (68%)]	Loss: -0.3891	Cost: 5.85s
Train Epoch: 426 [81920/90000 (91%)]	Loss: -0.7222	Cost: 6.48s
Train Epoch: 426 	Average Loss: -0.1628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4853

Learning rate: 0.0001999910446520254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 2.4231	Cost: 22.95s
Train Epoch: 427 [20480/90000 (23%)]	Loss: -0.2285	Cost: 6.11s
Train Epoch: 427 [40960/90000 (45%)]	Loss: -0.4141	Cost: 10.20s
Train Epoch: 427 [61440/90000 (68%)]	Loss: -0.6991	Cost: 6.20s
Train Epoch: 427 [81920/90000 (91%)]	Loss: -0.8240	Cost: 11.93s
Train Epoch: 427 	Average Loss: -0.1717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3397

Saving model as e427_model.pt & e427_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999100255942216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 2.5094	Cost: 24.43s
Train Epoch: 428 [20480/90000 (23%)]	Loss: -0.3946	Cost: 6.08s
Train Epoch: 428 [40960/90000 (45%)]	Loss: -0.6592	Cost: 8.67s
Train Epoch: 428 [61440/90000 (68%)]	Loss: -0.8115	Cost: 5.87s
Train Epoch: 428 [81920/90000 (91%)]	Loss: -0.6458	Cost: 5.67s
Train Epoch: 428 	Average Loss: -0.3189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3420

Learning rate: 0.00019999096036813171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 2.3477	Cost: 26.06s
Train Epoch: 429 [20480/90000 (23%)]	Loss: -0.2248	Cost: 7.93s
Train Epoch: 429 [40960/90000 (45%)]	Loss: -0.4208	Cost: 15.17s
Train Epoch: 429 [61440/90000 (68%)]	Loss: -0.6928	Cost: 7.12s
Train Epoch: 429 [81920/90000 (91%)]	Loss: -0.8344	Cost: 10.11s
Train Epoch: 429 	Average Loss: -0.2338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1771

Saving model as e429_model.pt & e429_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999909180781542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 2.3337	Cost: 26.25s
Train Epoch: 430 [20480/90000 (23%)]	Loss: -0.5069	Cost: 6.03s
Train Epoch: 430 [40960/90000 (45%)]	Loss: -0.7584	Cost: 8.03s
Train Epoch: 430 [61440/90000 (68%)]	Loss: -0.8308	Cost: 6.28s
Train Epoch: 430 [81920/90000 (91%)]	Loss: -0.7679	Cost: 9.73s
Train Epoch: 430 	Average Loss: -0.4135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3392

Learning rate: 0.00019999087568948958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 2.4769	Cost: 26.72s
Train Epoch: 431 [20480/90000 (23%)]	Loss: -0.5686	Cost: 6.02s
Train Epoch: 431 [40960/90000 (45%)]	Loss: -0.7877	Cost: 7.63s
Train Epoch: 431 [61440/90000 (68%)]	Loss: -1.0957	Cost: 5.88s
Train Epoch: 431 [81920/90000 (91%)]	Loss: -0.9742	Cost: 7.94s
Train Epoch: 431 	Average Loss: -0.4613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2360

Learning rate: 0.0001999908332021379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 2.2235	Cost: 22.92s
Train Epoch: 432 [20480/90000 (23%)]	Loss: -0.6357	Cost: 6.00s
Train Epoch: 432 [40960/90000 (45%)]	Loss: -0.7935	Cost: 7.73s
Train Epoch: 432 [61440/90000 (68%)]	Loss: -1.0141	Cost: 6.08s
Train Epoch: 432 [81920/90000 (91%)]	Loss: -1.0111	Cost: 6.54s
Train Epoch: 432 	Average Loss: -0.5075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1848

Learning rate: 0.00019999079061609924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 2.0377	Cost: 25.55s
Train Epoch: 433 [20480/90000 (23%)]	Loss: -0.7983	Cost: 6.33s
Train Epoch: 433 [40960/90000 (45%)]	Loss: -0.8162	Cost: 10.43s
Train Epoch: 433 [61440/90000 (68%)]	Loss: -0.9013	Cost: 6.02s
Train Epoch: 433 [81920/90000 (91%)]	Loss: -0.8952	Cost: 6.34s
Train Epoch: 433 	Average Loss: -0.5504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1046

Saving model as e433_model.pt & e433_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999074793137364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 2.3187	Cost: 23.24s
Train Epoch: 434 [20480/90000 (23%)]	Loss: -0.8344	Cost: 6.00s
Train Epoch: 434 [40960/90000 (45%)]	Loss: -1.0151	Cost: 7.72s
Train Epoch: 434 [61440/90000 (68%)]	Loss: -1.0352	Cost: 5.75s
Train Epoch: 434 [81920/90000 (91%)]	Loss: -1.0195	Cost: 6.50s
Train Epoch: 434 	Average Loss: -0.6262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1859

Learning rate: 0.00019999070514796111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 2.3119	Cost: 28.87s
Train Epoch: 435 [20480/90000 (23%)]	Loss: -0.7285	Cost: 6.23s
Train Epoch: 435 [40960/90000 (45%)]	Loss: -0.9444	Cost: 10.29s
Train Epoch: 435 [61440/90000 (68%)]	Loss: -0.7898	Cost: 5.78s
Train Epoch: 435 [81920/90000 (91%)]	Loss: -1.0936	Cost: 6.35s
Train Epoch: 435 	Average Loss: -0.5873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2570

Learning rate: 0.00019999066226586174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 2.1503	Cost: 23.76s
Train Epoch: 436 [20480/90000 (23%)]	Loss: -0.7913	Cost: 6.56s
Train Epoch: 436 [40960/90000 (45%)]	Loss: -0.9276	Cost: 11.03s
Train Epoch: 436 [61440/90000 (68%)]	Loss: -0.8482	Cost: 6.38s
Train Epoch: 436 [81920/90000 (91%)]	Loss: -0.6271	Cost: 9.27s
Train Epoch: 436 	Average Loss: -0.4770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4151

Learning rate: 0.00019999061928507552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 2.6711	Cost: 26.86s
Train Epoch: 437 [20480/90000 (23%)]	Loss: -0.4702	Cost: 6.20s
Train Epoch: 437 [40960/90000 (45%)]	Loss: -0.7632	Cost: 10.56s
Train Epoch: 437 [61440/90000 (68%)]	Loss: -0.9491	Cost: 5.67s
Train Epoch: 437 [81920/90000 (91%)]	Loss: -1.0185	Cost: 6.19s
Train Epoch: 437 	Average Loss: -0.4372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1390

Learning rate: 0.0001999905762056025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 1.9190	Cost: 22.94s
Train Epoch: 438 [20480/90000 (23%)]	Loss: -0.5821	Cost: 6.17s
Train Epoch: 438 [40960/90000 (45%)]	Loss: -0.7072	Cost: 8.27s
Train Epoch: 438 [61440/90000 (68%)]	Loss: 0.0807	Cost: 6.09s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 0.5594	Cost: 5.82s
Train Epoch: 438 	Average Loss: -0.0870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2108

Learning rate: 0.00019999053302744273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 3.1930	Cost: 22.48s
Train Epoch: 439 [20480/90000 (23%)]	Loss: 0.2624	Cost: 6.15s
Train Epoch: 439 [40960/90000 (45%)]	Loss: -0.3661	Cost: 9.11s
Train Epoch: 439 [61440/90000 (68%)]	Loss: -0.4327	Cost: 6.25s
Train Epoch: 439 [81920/90000 (91%)]	Loss: -0.5656	Cost: 11.72s
Train Epoch: 439 	Average Loss: 0.0613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5476

Learning rate: 0.00019999048975059627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 2.7885	Cost: 31.86s
Train Epoch: 440 [20480/90000 (23%)]	Loss: -0.5686	Cost: 6.79s
Train Epoch: 440 [40960/90000 (45%)]	Loss: -0.7262	Cost: 10.98s
Train Epoch: 440 [61440/90000 (68%)]	Loss: -0.9031	Cost: 5.83s
Train Epoch: 440 [81920/90000 (91%)]	Loss: -0.7818	Cost: 5.87s
Train Epoch: 440 	Average Loss: -0.3665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2094

Learning rate: 0.00019999044637506315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 1.9835	Cost: 22.32s
Train Epoch: 441 [20480/90000 (23%)]	Loss: -0.7157	Cost: 7.05s
Train Epoch: 441 [40960/90000 (45%)]	Loss: -0.8907	Cost: 10.32s
Train Epoch: 441 [61440/90000 (68%)]	Loss: -1.0046	Cost: 6.24s
Train Epoch: 441 [81920/90000 (91%)]	Loss: -1.0804	Cost: 11.19s
Train Epoch: 441 	Average Loss: -0.6340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0384

Saving model as e441_model.pt & e441_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999904029008434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 2.1651	Cost: 23.54s
Train Epoch: 442 [20480/90000 (23%)]	Loss: -0.8470	Cost: 6.17s
Train Epoch: 442 [40960/90000 (45%)]	Loss: -1.0294	Cost: 10.86s
Train Epoch: 442 [61440/90000 (68%)]	Loss: -1.0991	Cost: 6.17s
Train Epoch: 442 [81920/90000 (91%)]	Loss: -0.9536	Cost: 11.52s
Train Epoch: 442 	Average Loss: -0.6920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1689

Learning rate: 0.0001999903593279371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 1.8910	Cost: 26.74s
Train Epoch: 443 [20480/90000 (23%)]	Loss: -0.7110	Cost: 6.12s
Train Epoch: 443 [40960/90000 (45%)]	Loss: -1.0339	Cost: 10.10s
Train Epoch: 443 [61440/90000 (68%)]	Loss: -0.9857	Cost: 6.13s
Train Epoch: 443 [81920/90000 (91%)]	Loss: -1.3117	Cost: 6.11s
Train Epoch: 443 	Average Loss: -0.6613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
